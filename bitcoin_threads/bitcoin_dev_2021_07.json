[
    {
        "title": "[bitcoin-dev] Bitcoin Knots 0.21.1.knots20210629 released",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2021-07-01T05:44:17",
                "message_text_only": "Bitcoin Knots version 0.21.1.knots20210629 is now available from:\n\n  https://bitcoinknots.org/files/0.21.x/0.21.1.knots20210629/\n\nThis release includes new features, various bug fixes and performance \nimprovements, as well as updated translations.\n\nPlease report bugs using the issue tracker at GitHub:\n\n  https://github.com/bitcoinknots/bitcoin/issues\n\nTo receive security and update notifications, please subscribe to:\n\n  https://bitcoinknots.org/list/announcements/join/\n\nFor the full release notes and change log, see:\n\nhttps://github.com/bitcoinknots/bitcoin/blob/v0.21.1.knots20210629/doc/release-notes.md\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 1528 bytes\nDesc: This is a digitally signed message part.\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210701/19d621fb/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Knots 0.21.1.knots20210629 released",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Luke Dashjr"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 912
        }
    },
    {
        "title": "[bitcoin-dev] Boost Bitcoin circulation, Million Transactions Per Second with stronger privacy",
        "thread_messages": [
            {
                "author": "raymo at riseup.net",
                "date": "2021-07-01T20:11:10",
                "message_text_only": "Hi Billy,\nSorry for late reply. Let\u2019s jump in proposal.\n\n> Some more information about the benefits of this approach vs alternatives (mainly lightning)\nThe most important different is unlike the lightning, in Sabu no one\nhave to open a channel and pay Bitcoin transaction fee, subsequently no\none has to close channel and pay another Bitcoin transaction fee. It is\nthe huge improvement since it drops the overhead cost of transactions.\nSo, it will be more convenience to trade under Sabu protocol. \nIn Sabu none of parties of a transaction are obliged to block money in\nany kind of smart contract or any other m of n signature accounts\non-chain, so it provides more privacy. \nSince Sabu protocol is designed to motivate people to circulate\ntransactions (AKA debt documents) in Sabu network, if every actor act\nrationally no one will aware how much money transferred from who to\nwhom. \nIn case of fraudulent activity by issuer, the creditor will send\nGuarantee Transaction (GT) to Bitcoin network in order to recapture the\npart of his credit. So, in this case the transaction is literally\nrecorded on bitcoin blockchain.\nThere is only one another reason to recording transaction on Bitcoin\nblockchain. Where one creditor eager to pay Bitcoin transaction fee in\norder to aggregate thousands or even millions different small amount\ndebt-documents in a single transaction on Bitcoin blockchain.\ndespite these two cases, the rest of transactions all occur in the Sabu\nnetwork (supposed to be over 99%). Thus, no footprint no bottleneck and\nno over process.\n\nAnother important power point of Sabu is its pure-peer-to-peer network\narchitecture. In Sabu the mobile wallets communicating to each other\ndirectly without any central server. There is no centralization at all.\nAs a result, there will be no routing as well. \nSince only issuer and creditors are aware of the content of transaction\n(who pay how much to whom) it is a huge privacy improvement, which\ndoesn\u2019t exist in other layer 2 solutions. \n\nAbout the usability of Sabu, although the protocol based on the\ncollaborating 2 different peer-to-peer network and 3 classic\nserver/client networks, but the end user (mobile wallet user) doesn\u2019t\nsee any of these complexities. \nThe end user simply installs the mobile/desktop wallet and add her/his\nfriends to his phonebook by adding their email address or scanning their\nemail (and/or PGP public key). After that s/he can immediately start to\nsend/receive Bitcoin through Sabu network. Entire communications between\nwallets are PGP encrypted. \nAnother good point in Sabu design is, the 12 seed words are using for\nboth Bitcoin wallet private key and the PGP private key. So, it is the\nkey of user wealth and its identity as well. For more details, please\nread my previous answer to Alex Schoof. \nThe issuer, by using his UTXOs and selling them to creditors earn money.\nthe issuer creates the debt document (transaction) by which promises to\ncreditor an amount of satoshi. These debt documents are valid Bitcoin\ntransaction. The only difference is these transactions are intended to\ncirculate in Sabu protocol instead of sending to Bitcoin blockchain.  \nEach transaction is a small money transfer. 40,000 Satoshi as input and\nmaximum 20,000 Satoshi as credit and minimum 10,000 Satoshi as Bitcoin\ntransaction fee.\nThe creditors will use these received transactions as money and will pay\nit in exchange of goods or services. For each transaction the creditor\npays 10 Satoshi as Sabu-transaction-fee to issuer. \nSabu is not custodial service and the UXTOs are always under issuer\ncontrol, unless issuer or creditor send the signed transaction to\nBitcoin network. When the transaction was recorded in Bitcoin\nblockchain, the creditor can spend proper UTXO in Bitcoin network.\nImagine million people use their UTXOs in Sabu, they are issuer and\nissue/update/cancel million transactions per second. All they need is a\nmobile wallet. On the other hand, every one by knowing an issuer can buy\nsome Satoshi (whit absolutely no KYC), even 1 Dollar or less, and spend\nit, this time Alice really can buy caffe by Bitcoin ;)\nThe Bar can install the mobile wallet and every day receives thousands\nof debt documents (transactions), each worth maximum 20,000 Satoshi in\nexchange of coffee. And every evening aggregates those small\ntransactions to one single transaction and send it to Bitcoin network. \n\n\nThe security model of Sabu is pretty straight forward. \nIssuer is the owner of UTXO(s) which will be used in transactions. The\nissuer is and will the only person who creates transactions and sign\nthem. The transactions are valid transaction which either issuer or\ncreditor can send them to Bitcoin network, but they will never send\nthese transactions to Bitcoin network, because of the high Bitcoin\ntransaction fee for each single transaction. \nSince issuer is the only one who can sign transaction (spend UTXOs),\nthere is a risk of issuer cheating. And no one can stop issuer from\ncheating, because these are his UTXOs and he has the proper private\nkeys. \nThe Sabu solution is Guarantee transaction. It is a valid transaction\nthat issuer has to sign it alongside the Main transaction. In GT both\nissuer and creditor cut a part of their output in favor of Bitcoin\ntransaction fee. \nWe suppose miners always seeking for more profit, thus in a case there\nare 2 or more transaction are spending same UTXO as input, miner will\nchoose transaction with highest feeRate. There is no economically\nbenefit for issuer to cheat creditors and pay less transaction fee\nsimultaneously. So rationally the issuer won\u2019t cheat creditor.\nIt was the simplest explanation of Sabu security model.\n\n> I agree with others that using email is probably not appropriate for a protocol like this. I would highly recommend making your protocol transport-agnostic, allowing users of your protocol to use any transport they want.\nIndeed, the protocol is transparent-agnostic, if I insist of email as a\nuser identifier and communicating tool is because of the idea of\nreforming part of internet architecture and make it more decentralized.\nThe wallet users can choose classic architecture. In this case mobile\nwallets will connect to a central server and communicate through that\nserver (pretty much like all existed mobile wallets). While some users\ndecide to use a pure peer-to-peer communication. I knew email has some\nprivacy issues but as always it is a tradeoff. Users can decide between\nan unstoppable, permission less, self-sovereignty and decentralized pure\npeer-to-peer communication network (with some resolvable privacy issues)\nor some efficient central limited network. \nLet me know the critics about email. Hopefully this would lead us to\nimprove email instead of letting it die. I strongly suggest email\nbecause it is the ONLY neutral, free \u201cnonproprietary\u201d and open\nprotocol/technology for communication in the world that its\ninfrastructure is well-established and is accessible all over the glob.\n\nI tried to explain it more, hope was useful. By the way the complete\nexplanation is here\nhttps://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n\n\n\nRegards\nRaymo \n\n\n\nOn 2021-06-22 18:20, Billy Tetrud wrote:\n> I would be interested in seeing some more information about the\n> benefits of this approach vs alternatives up front in this write up.\n> Eg how does the security, cost, usability, and privacy compare to the\n> lightning network, which would be the most likely competitor to this\n> idea. It seems clear that there is more counterparty risk here, so it\n> would probably also be very helpful to compare against traditional\n> custodial solutions as well. If you have specific claims on how this\n> system is better than eg lightning in certain contexts, it would be\n> far easier to evaluate the protocol against those claims, and would\n> also be a lot easier for readers to be motivated to read the whole\n> protocol and do a more full analysis. \n> \n> I agree with others that using email is probably not appropriate for a\n> protocol like this. I would highly recommend making your protocol\n> transport-agnostic, allowing users of your protocol to use any\n> transport they want. \n> \n> On Sat, Jun 19, 2021 at 7:00 PM James Hilliard via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n>> I think you're making a number of assumptions about mining that are\n>> not accurate.\n>>\n>>> First of all, how much chance in finding next block the corrupted\n>> miners have? One percent of all Bitcoin hash powers? Or maximum 5\n>> percent or 10? The cheaters must come up in dividing that 1.2\n>> Bitcoin between. After all the risk/reward must fit them. They can\n>> not be a big mining pool since there is no benefit, so they will be\n>> small miners with low hash rate. If they solve the puzzle and\n>> broadcast the block, no one in the entire Bitcoin network has block\n>> transactions or seen it before in their mempool!\n>>\n>> You're making the assumption that miners won't build on top of a\n>> block\n>> with transactions they have not seen before or transactions that may\n>> contain double spends of unconfirmed inputs, this is not how mining\n>> works, as long as the block passes the consensus rules effectively\n>> all\n>> miners will mine on top of it by default, this behavior is\n>> fundamental\n>> to how mining currently works and is fairly deeply baked into the\n>> current mining infrastructure.\n>>\n>>> Will they accept this block? In theory it is possible and have\n>> 0.01 percent chance but we can eliminate this small possibilities by\n>> a simple BIP for miners.\n>>\n>> What would this BIP look like? I don't see how this could work in a\n>> decentralized way as you would need another way of reaching\n>> consensus\n>> on what defines a valid block. Right now the chance is nearly 100\n>> percent that a miner will mine on top of the latest valid block,\n>> many\n>> pools(most last I checked) will even mine on the next block before\n>> they validate the latest block fully(ie validationless mining) to\n>> reduce their orphan rates.\n>>\n>>> We suppose the miners always control transactions with\n>> doc-watchers and avoid accepting transaction with same UTXO but\n>> different output.\n>>\n>> Miners have different mempool policy/rules for what transactions\n>> they\n>> themselves mine but all miners must mine on the most work chain of\n>> valid blocks otherwise they risk their own blocks being orphaned,\n>> any\n>> miner that does not do this is effectively guaranteed to have their\n>> block orphaned right now.\n>>\n>>> Because of high Bitcoin transaction fee, this guarantee\n>> transaction will take place in next block, even if other transaction\n>> which are using the same UTXO as input existed in mempool.\n>>\n>> When a new transaction is broadcast miners do not immediately start\n>> mining on a block template that includes that transaction, the\n>> template won't even be generated immediately when it enters a miners\n>> mempool in practice, for bandwidth/network efficiency reasons mining\n>> pools batch update the stratum templates/jobs they mine against so\n>> there can be significant latency between the time a transaction is\n>> actually broadcast and hits the miners mempool and the time the\n>> miners\n>> actually switch to mining on top it, these batched updates are\n>> essentially like point in time snapshots of the mempool and\n>> typically\n>> remain valid(as in the pool will accept shares submitted against\n>> that\n>> job as valid) until the bitcoin network finds the next block. I\n>> don't\n>> think these batch updates are done more often than every 30 seconds\n>> typically, while often it is on the order of multiple minutes\n>> depending on the pool.\n>>\n>> Regards,\n>> James\n>>\n>> On Thu, Jun 17, 2021 at 2:14 PM raymo via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>> Hi,\n>>> I have a proposal for improve Bitcoin TPS and privacy, here is the\n>> post.\n>>>\n>>\n> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n>>> https://bitcointalk.org/index.php?topic=5344020.0\n>>> Can you please read it and share your idea about it.\n>>>\n>>> Cheers\n>>> Raymo\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Erik Aronesty",
                "date": "2021-07-01T20:49:16",
                "message_text_only": "your protocol should always assume the email system is fully\ncompromised, and only send public information over email:\n\n- public keys / addresses are sent\n- other routing data encrypted with public keys (not sure how data is\nrouted in sabu)\n\nyour end user should be able to verify public keys  / addresses\n\n - use QR-codes\n - phone calls with users reading BIP words out loud\n - other in-person information exchange\n\nseparate the Sabu protocol from the app... allow others to implement\ndesktop version, or other versions that use other routing systems\n\n-  you can allow direct-entry of a BIP-word-representation of a public\nkey/address to avoid privacy/central system concerns\n\nOn Thu, Jul 1, 2021 at 4:20 PM raymo via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Hi Billy,\n> Sorry for late reply. Let\u2019s jump in proposal.\n>\n> > Some more information about the benefits of this approach vs alternatives (mainly lightning)\n> The most important different is unlike the lightning, in Sabu no one\n> have to open a channel and pay Bitcoin transaction fee, subsequently no\n> one has to close channel and pay another Bitcoin transaction fee. It is\n> the huge improvement since it drops the overhead cost of transactions.\n> So, it will be more convenience to trade under Sabu protocol.\n> In Sabu none of parties of a transaction are obliged to block money in\n> any kind of smart contract or any other m of n signature accounts\n> on-chain, so it provides more privacy.\n> Since Sabu protocol is designed to motivate people to circulate\n> transactions (AKA debt documents) in Sabu network, if every actor act\n> rationally no one will aware how much money transferred from who to\n> whom.\n> In case of fraudulent activity by issuer, the creditor will send\n> Guarantee Transaction (GT) to Bitcoin network in order to recapture the\n> part of his credit. So, in this case the transaction is literally\n> recorded on bitcoin blockchain.\n> There is only one another reason to recording transaction on Bitcoin\n> blockchain. Where one creditor eager to pay Bitcoin transaction fee in\n> order to aggregate thousands or even millions different small amount\n> debt-documents in a single transaction on Bitcoin blockchain.\n> despite these two cases, the rest of transactions all occur in the Sabu\n> network (supposed to be over 99%). Thus, no footprint no bottleneck and\n> no over process.\n>\n> Another important power point of Sabu is its pure-peer-to-peer network\n> architecture. In Sabu the mobile wallets communicating to each other\n> directly without any central server. There is no centralization at all.\n> As a result, there will be no routing as well.\n> Since only issuer and creditors are aware of the content of transaction\n> (who pay how much to whom) it is a huge privacy improvement, which\n> doesn\u2019t exist in other layer 2 solutions.\n>\n> About the usability of Sabu, although the protocol based on the\n> collaborating 2 different peer-to-peer network and 3 classic\n> server/client networks, but the end user (mobile wallet user) doesn\u2019t\n> see any of these complexities.\n> The end user simply installs the mobile/desktop wallet and add her/his\n> friends to his phonebook by adding their email address or scanning their\n> email (and/or PGP public key). After that s/he can immediately start to\n> send/receive Bitcoin through Sabu network. Entire communications between\n> wallets are PGP encrypted.\n> Another good point in Sabu design is, the 12 seed words are using for\n> both Bitcoin wallet private key and the PGP private key. So, it is the\n> key of user wealth and its identity as well. For more details, please\n> read my previous answer to Alex Schoof.\n> The issuer, by using his UTXOs and selling them to creditors earn money.\n> the issuer creates the debt document (transaction) by which promises to\n> creditor an amount of satoshi. These debt documents are valid Bitcoin\n> transaction. The only difference is these transactions are intended to\n> circulate in Sabu protocol instead of sending to Bitcoin blockchain.\n> Each transaction is a small money transfer. 40,000 Satoshi as input and\n> maximum 20,000 Satoshi as credit and minimum 10,000 Satoshi as Bitcoin\n> transaction fee.\n> The creditors will use these received transactions as money and will pay\n> it in exchange of goods or services. For each transaction the creditor\n> pays 10 Satoshi as Sabu-transaction-fee to issuer.\n> Sabu is not custodial service and the UXTOs are always under issuer\n> control, unless issuer or creditor send the signed transaction to\n> Bitcoin network. When the transaction was recorded in Bitcoin\n> blockchain, the creditor can spend proper UTXO in Bitcoin network.\n> Imagine million people use their UTXOs in Sabu, they are issuer and\n> issue/update/cancel million transactions per second. All they need is a\n> mobile wallet. On the other hand, every one by knowing an issuer can buy\n> some Satoshi (whit absolutely no KYC), even 1 Dollar or less, and spend\n> it, this time Alice really can buy caffe by Bitcoin ;)\n> The Bar can install the mobile wallet and every day receives thousands\n> of debt documents (transactions), each worth maximum 20,000 Satoshi in\n> exchange of coffee. And every evening aggregates those small\n> transactions to one single transaction and send it to Bitcoin network.\n>\n>\n> The security model of Sabu is pretty straight forward.\n> Issuer is the owner of UTXO(s) which will be used in transactions. The\n> issuer is and will the only person who creates transactions and sign\n> them. The transactions are valid transaction which either issuer or\n> creditor can send them to Bitcoin network, but they will never send\n> these transactions to Bitcoin network, because of the high Bitcoin\n> transaction fee for each single transaction.\n> Since issuer is the only one who can sign transaction (spend UTXOs),\n> there is a risk of issuer cheating. And no one can stop issuer from\n> cheating, because these are his UTXOs and he has the proper private\n> keys.\n> The Sabu solution is Guarantee transaction. It is a valid transaction\n> that issuer has to sign it alongside the Main transaction. In GT both\n> issuer and creditor cut a part of their output in favor of Bitcoin\n> transaction fee.\n> We suppose miners always seeking for more profit, thus in a case there\n> are 2 or more transaction are spending same UTXO as input, miner will\n> choose transaction with highest feeRate. There is no economically\n> benefit for issuer to cheat creditors and pay less transaction fee\n> simultaneously. So rationally the issuer won\u2019t cheat creditor.\n> It was the simplest explanation of Sabu security model.\n>\n> > I agree with others that using email is probably not appropriate for a protocol like this. I would highly recommend making your protocol transport-agnostic, allowing users of your protocol to use any transport they want.\n> Indeed, the protocol is transparent-agnostic, if I insist of email as a\n> user identifier and communicating tool is because of the idea of\n> reforming part of internet architecture and make it more decentralized.\n> The wallet users can choose classic architecture. In this case mobile\n> wallets will connect to a central server and communicate through that\n> server (pretty much like all existed mobile wallets). While some users\n> decide to use a pure peer-to-peer communication. I knew email has some\n> privacy issues but as always it is a tradeoff. Users can decide between\n> an unstoppable, permission less, self-sovereignty and decentralized pure\n> peer-to-peer communication network (with some resolvable privacy issues)\n> or some efficient central limited network.\n> Let me know the critics about email. Hopefully this would lead us to\n> improve email instead of letting it die. I strongly suggest email\n> because it is the ONLY neutral, free \u201cnonproprietary\u201d and open\n> protocol/technology for communication in the world that its\n> infrastructure is well-established and is accessible all over the glob.\n>\n> I tried to explain it more, hope was useful. By the way the complete\n> explanation is here\n> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n>\n>\n>\n> Regards\n> Raymo\n>\n>\n>\n> On 2021-06-22 18:20, Billy Tetrud wrote:\n> > I would be interested in seeing some more information about the\n> > benefits of this approach vs alternatives up front in this write up.\n> > Eg how does the security, cost, usability, and privacy compare to the\n> > lightning network, which would be the most likely competitor to this\n> > idea. It seems clear that there is more counterparty risk here, so it\n> > would probably also be very helpful to compare against traditional\n> > custodial solutions as well. If you have specific claims on how this\n> > system is better than eg lightning in certain contexts, it would be\n> > far easier to evaluate the protocol against those claims, and would\n> > also be a lot easier for readers to be motivated to read the whole\n> > protocol and do a more full analysis.\n> >\n> > I agree with others that using email is probably not appropriate for a\n> > protocol like this. I would highly recommend making your protocol\n> > transport-agnostic, allowing users of your protocol to use any\n> > transport they want.\n> >\n> > On Sat, Jun 19, 2021 at 7:00 PM James Hilliard via bitcoin-dev\n> > <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >\n> >> I think you're making a number of assumptions about mining that are\n> >> not accurate.\n> >>\n> >>> First of all, how much chance in finding next block the corrupted\n> >> miners have? One percent of all Bitcoin hash powers? Or maximum 5\n> >> percent or 10? The cheaters must come up in dividing that 1.2\n> >> Bitcoin between. After all the risk/reward must fit them. They can\n> >> not be a big mining pool since there is no benefit, so they will be\n> >> small miners with low hash rate. If they solve the puzzle and\n> >> broadcast the block, no one in the entire Bitcoin network has block\n> >> transactions or seen it before in their mempool!\n> >>\n> >> You're making the assumption that miners won't build on top of a\n> >> block\n> >> with transactions they have not seen before or transactions that may\n> >> contain double spends of unconfirmed inputs, this is not how mining\n> >> works, as long as the block passes the consensus rules effectively\n> >> all\n> >> miners will mine on top of it by default, this behavior is\n> >> fundamental\n> >> to how mining currently works and is fairly deeply baked into the\n> >> current mining infrastructure.\n> >>\n> >>> Will they accept this block? In theory it is possible and have\n> >> 0.01 percent chance but we can eliminate this small possibilities by\n> >> a simple BIP for miners.\n> >>\n> >> What would this BIP look like? I don't see how this could work in a\n> >> decentralized way as you would need another way of reaching\n> >> consensus\n> >> on what defines a valid block. Right now the chance is nearly 100\n> >> percent that a miner will mine on top of the latest valid block,\n> >> many\n> >> pools(most last I checked) will even mine on the next block before\n> >> they validate the latest block fully(ie validationless mining) to\n> >> reduce their orphan rates.\n> >>\n> >>> We suppose the miners always control transactions with\n> >> doc-watchers and avoid accepting transaction with same UTXO but\n> >> different output.\n> >>\n> >> Miners have different mempool policy/rules for what transactions\n> >> they\n> >> themselves mine but all miners must mine on the most work chain of\n> >> valid blocks otherwise they risk their own blocks being orphaned,\n> >> any\n> >> miner that does not do this is effectively guaranteed to have their\n> >> block orphaned right now.\n> >>\n> >>> Because of high Bitcoin transaction fee, this guarantee\n> >> transaction will take place in next block, even if other transaction\n> >> which are using the same UTXO as input existed in mempool.\n> >>\n> >> When a new transaction is broadcast miners do not immediately start\n> >> mining on a block template that includes that transaction, the\n> >> template won't even be generated immediately when it enters a miners\n> >> mempool in practice, for bandwidth/network efficiency reasons mining\n> >> pools batch update the stratum templates/jobs they mine against so\n> >> there can be significant latency between the time a transaction is\n> >> actually broadcast and hits the miners mempool and the time the\n> >> miners\n> >> actually switch to mining on top it, these batched updates are\n> >> essentially like point in time snapshots of the mempool and\n> >> typically\n> >> remain valid(as in the pool will accept shares submitted against\n> >> that\n> >> job as valid) until the bitcoin network finds the next block. I\n> >> don't\n> >> think these batch updates are done more often than every 30 seconds\n> >> typically, while often it is on the order of multiple minutes\n> >> depending on the pool.\n> >>\n> >> Regards,\n> >> James\n> >>\n> >> On Thu, Jun 17, 2021 at 2:14 PM raymo via bitcoin-dev\n> >> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>>\n> >>> Hi,\n> >>> I have a proposal for improve Bitcoin TPS and privacy, here is the\n> >> post.\n> >>>\n> >>\n> > https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n> >>> https://bitcointalk.org/index.php?topic=5344020.0\n> >>> Can you please read it and share your idea about it.\n> >>>\n> >>> Cheers\n> >>> Raymo\n> >>> _______________________________________________\n> >>> bitcoin-dev mailing list\n> >>> bitcoin-dev at lists.linuxfoundation.org\n> >>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >> _______________________________________________\n> >> bitcoin-dev mailing list\n> >> bitcoin-dev at lists.linuxfoundation.org\n> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "raymo at riseup.net",
                "date": "2021-07-01T22:15:13",
                "message_text_only": "Hi Erik\n\nPlease correct me if I misunderstood.\n\n> email is fully compromised. \n\nWhat I got is:\nEmail is not good because the sender and receiver are compromised.\nEmail is not good because the message content is revealed.\nI can claim same argue about any other client/server model. Since the\nserver (website) service provider will ask some sort of KYC. And even if\nthe server uses end-to-end encryption, the provider company still can\nread the packets content.\nIn my model the passive listener only can discover who is communicate to\nwhom and make a graph of connections. Although it is a threat for\nprivacy but the server/client model has this flaw inherently, since\nprovider already knew everything about everyone. In my model at least\nusers can make some fake connections and send some fake emails in order\nto inject noise to communications.\nPlease note the fact that entire communication between mobile wallets\n(via emails) are asymmetric PGP encrypted. The PGP keys are controlled\nby end users unlike ALL pretending secure messengers (e.g whatsApp,\nsignal, zoom,\u2026).\nIf you are worried about the way of exchanging PGP public key, you are\nright. The most secure way is in-person PGP key exchanging.\nAfter that for payments the wallets communicate in pgp encrypted\nmessages and they can transfer Bitcoin address through an PGP encrypted\ncipher, thus no revealing Bitcoin address to public would occur. Neither\nthe amounts of transactions will be reviled. \nThere for it would be a good practice for shops to put their email and\nPGP public key on shop website and/or PGP public key servers, instead of\nputting Bitcoin address on website or using 3rd parties services to hide\ntheir Bitcoin payment addresses.\n\nIf I missed some points about \u201cfully compromised\u201d please write it to me.\n\n\n> public keys / addresses are sent\nAs I told before ALL communication in Sabu are PGP encrypted.\n\n> other routing data encrypted with public keys \n>(not sure how data is routed in sabu)\n\nSabu is not responsible for routing at all. It simply sends emails.\nIndeed the wallets peer-to-peer network in Sabu is pretty straight\nforward. Each mobile wallet has one email address as its handler and\nidentifier in mobile-wallets-network. Each mobile can send message to\nanother mobile by knowing its email address and the PGP public key. \nThis information can be prepared in first face-to-face contact of mobile\nowners, or later (something like signing the other\u2019s public key in web\nof trust) when a creditor wants to spend his money and transfer it to\nanother creditor. The creditor1 send the signed money transfer request\nalongside the email and public key of creditor2 all in a PGP encrypted\nmessage to issuer.\n\n\n\n> separate the Sabu protocol from the app... allow others to implement \n> desktop version, or other versions that use other routing systems\n\nIndeed, it is my approach too. As I told before users will decide\nbetween an unstoppable, permission less, self-sovereignty and\ndecentralized pure peer-to-peer communication network (with some\nresolvable privacy issues) or some efficient, privacy-mimic central\nlimited network. \n\n\n> you can allow direct-entry of a BIP-word-representation \n> of a public key/address to avoid privacy/central system concerns\nAgree. Actually, I was thinking about an easy mechanism to share your\npublic key like what you suggested here. \nBut what I consider for a \u201ccentral system concerns\u201d is the ability of\ncommunication without dependency to any company. \nAs an example, what can you do if the twitter bans your account?\nNothing! Your content and entire connections will be lost. \nBut if you form your friends list in your mobile (or computer) and have\ntheir PGP public keys and they have yours, and use email as a dual\npurpose tool. First as a handler (the tool for finding and to be found\nin internet) and second as a communication tool.\nThus, no one can stop you, ban you or limit you to send/receive\ntransaction to/from anyone. \nWhat I am trying to say is using email is far better than account\n(username) in a limited central service like twitter, Facebook,\ntelegram... or even in future Sabu servers!\nYou have your connections under your control in your phone. You can\neasily change your email and use a new email or even a new service\nprovider without losing your connections and your control over it. \nYou just sign your new email address and send it to your friends circle\nand notify them about changes. \nOf course, email is not good for millions of followers but it is\nobviously good for managing your payment network of hundreds of people\n(either issuers or creditors).\n\nBest\nRaymo\n\nOn 2021-07-01 20:49, Erik Aronesty wrote:\n> your protocol should always assume the email system is fully\n> compromised, and only send public information over email:\n> \n> - public keys / addresses are sent\n> - other routing data encrypted with public keys (not sure how data is\n> routed in sabu)\n> \n> your end user should be able to verify public keys  / addresses\n> \n>  - use QR-codes\n>  - phone calls with users reading BIP words out loud\n>  - other in-person information exchange\n> \n> separate the Sabu protocol from the app... allow others to implement\n> desktop version, or other versions that use other routing systems\n> \n> -  you can allow direct-entry of a BIP-word-representation of a public\n> key/address to avoid privacy/central system concerns\n> \n> On Thu, Jul 1, 2021 at 4:20 PM raymo via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> Hi Billy,\n>> Sorry for late reply. Let\u2019s jump in proposal.\n>>\n>> > Some more information about the benefits of this approach vs alternatives (mainly lightning)\n>> The most important different is unlike the lightning, in Sabu no one\n>> have to open a channel and pay Bitcoin transaction fee, subsequently no\n>> one has to close channel and pay another Bitcoin transaction fee. It is\n>> the huge improvement since it drops the overhead cost of transactions.\n>> So, it will be more convenience to trade under Sabu protocol.\n>> In Sabu none of parties of a transaction are obliged to block money in\n>> any kind of smart contract or any other m of n signature accounts\n>> on-chain, so it provides more privacy.\n>> Since Sabu protocol is designed to motivate people to circulate\n>> transactions (AKA debt documents) in Sabu network, if every actor act\n>> rationally no one will aware how much money transferred from who to\n>> whom.\n>> In case of fraudulent activity by issuer, the creditor will send\n>> Guarantee Transaction (GT) to Bitcoin network in order to recapture the\n>> part of his credit. So, in this case the transaction is literally\n>> recorded on bitcoin blockchain.\n>> There is only one another reason to recording transaction on Bitcoin\n>> blockchain. Where one creditor eager to pay Bitcoin transaction fee in\n>> order to aggregate thousands or even millions different small amount\n>> debt-documents in a single transaction on Bitcoin blockchain.\n>> despite these two cases, the rest of transactions all occur in the Sabu\n>> network (supposed to be over 99%). Thus, no footprint no bottleneck and\n>> no over process.\n>>\n>> Another important power point of Sabu is its pure-peer-to-peer network\n>> architecture. In Sabu the mobile wallets communicating to each other\n>> directly without any central server. There is no centralization at all.\n>> As a result, there will be no routing as well.\n>> Since only issuer and creditors are aware of the content of transaction\n>> (who pay how much to whom) it is a huge privacy improvement, which\n>> doesn\u2019t exist in other layer 2 solutions.\n>>\n>> About the usability of Sabu, although the protocol based on the\n>> collaborating 2 different peer-to-peer network and 3 classic\n>> server/client networks, but the end user (mobile wallet user) doesn\u2019t\n>> see any of these complexities.\n>> The end user simply installs the mobile/desktop wallet and add her/his\n>> friends to his phonebook by adding their email address or scanning their\n>> email (and/or PGP public key). After that s/he can immediately start to\n>> send/receive Bitcoin through Sabu network. Entire communications between\n>> wallets are PGP encrypted.\n>> Another good point in Sabu design is, the 12 seed words are using for\n>> both Bitcoin wallet private key and the PGP private key. So, it is the\n>> key of user wealth and its identity as well. For more details, please\n>> read my previous answer to Alex Schoof.\n>> The issuer, by using his UTXOs and selling them to creditors earn money.\n>> the issuer creates the debt document (transaction) by which promises to\n>> creditor an amount of satoshi. These debt documents are valid Bitcoin\n>> transaction. The only difference is these transactions are intended to\n>> circulate in Sabu protocol instead of sending to Bitcoin blockchain.\n>> Each transaction is a small money transfer. 40,000 Satoshi as input and\n>> maximum 20,000 Satoshi as credit and minimum 10,000 Satoshi as Bitcoin\n>> transaction fee.\n>> The creditors will use these received transactions as money and will pay\n>> it in exchange of goods or services. For each transaction the creditor\n>> pays 10 Satoshi as Sabu-transaction-fee to issuer.\n>> Sabu is not custodial service and the UXTOs are always under issuer\n>> control, unless issuer or creditor send the signed transaction to\n>> Bitcoin network. When the transaction was recorded in Bitcoin\n>> blockchain, the creditor can spend proper UTXO in Bitcoin network.\n>> Imagine million people use their UTXOs in Sabu, they are issuer and\n>> issue/update/cancel million transactions per second. All they need is a\n>> mobile wallet. On the other hand, every one by knowing an issuer can buy\n>> some Satoshi (whit absolutely no KYC), even 1 Dollar or less, and spend\n>> it, this time Alice really can buy caffe by Bitcoin ;)\n>> The Bar can install the mobile wallet and every day receives thousands\n>> of debt documents (transactions), each worth maximum 20,000 Satoshi in\n>> exchange of coffee. And every evening aggregates those small\n>> transactions to one single transaction and send it to Bitcoin network.\n>>\n>>\n>> The security model of Sabu is pretty straight forward.\n>> Issuer is the owner of UTXO(s) which will be used in transactions. The\n>> issuer is and will the only person who creates transactions and sign\n>> them. The transactions are valid transaction which either issuer or\n>> creditor can send them to Bitcoin network, but they will never send\n>> these transactions to Bitcoin network, because of the high Bitcoin\n>> transaction fee for each single transaction.\n>> Since issuer is the only one who can sign transaction (spend UTXOs),\n>> there is a risk of issuer cheating. And no one can stop issuer from\n>> cheating, because these are his UTXOs and he has the proper private\n>> keys.\n>> The Sabu solution is Guarantee transaction. It is a valid transaction\n>> that issuer has to sign it alongside the Main transaction. In GT both\n>> issuer and creditor cut a part of their output in favor of Bitcoin\n>> transaction fee.\n>> We suppose miners always seeking for more profit, thus in a case there\n>> are 2 or more transaction are spending same UTXO as input, miner will\n>> choose transaction with highest feeRate. There is no economically\n>> benefit for issuer to cheat creditors and pay less transaction fee\n>> simultaneously. So rationally the issuer won\u2019t cheat creditor.\n>> It was the simplest explanation of Sabu security model.\n>>\n>> > I agree with others that using email is probably not appropriate for a protocol like this. I would highly recommend making your protocol transport-agnostic, allowing users of your protocol to use any transport they want.\n>> Indeed, the protocol is transparent-agnostic, if I insist of email as a\n>> user identifier and communicating tool is because of the idea of\n>> reforming part of internet architecture and make it more decentralized.\n>> The wallet users can choose classic architecture. In this case mobile\n>> wallets will connect to a central server and communicate through that\n>> server (pretty much like all existed mobile wallets). While some users\n>> decide to use a pure peer-to-peer communication. I knew email has some\n>> privacy issues but as always it is a tradeoff. Users can decide between\n>> an unstoppable, permission less, self-sovereignty and decentralized pure\n>> peer-to-peer communication network (with some resolvable privacy issues)\n>> or some efficient central limited network.\n>> Let me know the critics about email. Hopefully this would lead us to\n>> improve email instead of letting it die. I strongly suggest email\n>> because it is the ONLY neutral, free \u201cnonproprietary\u201d and open\n>> protocol/technology for communication in the world that its\n>> infrastructure is well-established and is accessible all over the glob.\n>>\n>> I tried to explain it more, hope was useful. By the way the complete\n>> explanation is here\n>> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n>>\n>>\n>>\n>> Regards\n>> Raymo\n>>\n>>\n>>\n>> On 2021-06-22 18:20, Billy Tetrud wrote:\n>> > I would be interested in seeing some more information about the\n>> > benefits of this approach vs alternatives up front in this write up.\n>> > Eg how does the security, cost, usability, and privacy compare to the\n>> > lightning network, which would be the most likely competitor to this\n>> > idea. It seems clear that there is more counterparty risk here, so it\n>> > would probably also be very helpful to compare against traditional\n>> > custodial solutions as well. If you have specific claims on how this\n>> > system is better than eg lightning in certain contexts, it would be\n>> > far easier to evaluate the protocol against those claims, and would\n>> > also be a lot easier for readers to be motivated to read the whole\n>> > protocol and do a more full analysis.\n>> >\n>> > I agree with others that using email is probably not appropriate for a\n>> > protocol like this. I would highly recommend making your protocol\n>> > transport-agnostic, allowing users of your protocol to use any\n>> > transport they want.\n>> >\n>> > On Sat, Jun 19, 2021 at 7:00 PM James Hilliard via bitcoin-dev\n>> > <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> >\n>> >> I think you're making a number of assumptions about mining that are\n>> >> not accurate.\n>> >>\n>> >>> First of all, how much chance in finding next block the corrupted\n>> >> miners have? One percent of all Bitcoin hash powers? Or maximum 5\n>> >> percent or 10? The cheaters must come up in dividing that 1.2\n>> >> Bitcoin between. After all the risk/reward must fit them. They can\n>> >> not be a big mining pool since there is no benefit, so they will be\n>> >> small miners with low hash rate. If they solve the puzzle and\n>> >> broadcast the block, no one in the entire Bitcoin network has block\n>> >> transactions or seen it before in their mempool!\n>> >>\n>> >> You're making the assumption that miners won't build on top of a\n>> >> block\n>> >> with transactions they have not seen before or transactions that may\n>> >> contain double spends of unconfirmed inputs, this is not how mining\n>> >> works, as long as the block passes the consensus rules effectively\n>> >> all\n>> >> miners will mine on top of it by default, this behavior is\n>> >> fundamental\n>> >> to how mining currently works and is fairly deeply baked into the\n>> >> current mining infrastructure.\n>> >>\n>> >>> Will they accept this block? In theory it is possible and have\n>> >> 0.01 percent chance but we can eliminate this small possibilities by\n>> >> a simple BIP for miners.\n>> >>\n>> >> What would this BIP look like? I don't see how this could work in a\n>> >> decentralized way as you would need another way of reaching\n>> >> consensus\n>> >> on what defines a valid block. Right now the chance is nearly 100\n>> >> percent that a miner will mine on top of the latest valid block,\n>> >> many\n>> >> pools(most last I checked) will even mine on the next block before\n>> >> they validate the latest block fully(ie validationless mining) to\n>> >> reduce their orphan rates.\n>> >>\n>> >>> We suppose the miners always control transactions with\n>> >> doc-watchers and avoid accepting transaction with same UTXO but\n>> >> different output.\n>> >>\n>> >> Miners have different mempool policy/rules for what transactions\n>> >> they\n>> >> themselves mine but all miners must mine on the most work chain of\n>> >> valid blocks otherwise they risk their own blocks being orphaned,\n>> >> any\n>> >> miner that does not do this is effectively guaranteed to have their\n>> >> block orphaned right now.\n>> >>\n>> >>> Because of high Bitcoin transaction fee, this guarantee\n>> >> transaction will take place in next block, even if other transaction\n>> >> which are using the same UTXO as input existed in mempool.\n>> >>\n>> >> When a new transaction is broadcast miners do not immediately start\n>> >> mining on a block template that includes that transaction, the\n>> >> template won't even be generated immediately when it enters a miners\n>> >> mempool in practice, for bandwidth/network efficiency reasons mining\n>> >> pools batch update the stratum templates/jobs they mine against so\n>> >> there can be significant latency between the time a transaction is\n>> >> actually broadcast and hits the miners mempool and the time the\n>> >> miners\n>> >> actually switch to mining on top it, these batched updates are\n>> >> essentially like point in time snapshots of the mempool and\n>> >> typically\n>> >> remain valid(as in the pool will accept shares submitted against\n>> >> that\n>> >> job as valid) until the bitcoin network finds the next block. I\n>> >> don't\n>> >> think these batch updates are done more often than every 30 seconds\n>> >> typically, while often it is on the order of multiple minutes\n>> >> depending on the pool.\n>> >>\n>> >> Regards,\n>> >> James\n>> >>\n>> >> On Thu, Jun 17, 2021 at 2:14 PM raymo via bitcoin-dev\n>> >> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> >>>\n>> >>> Hi,\n>> >>> I have a proposal for improve Bitcoin TPS and privacy, here is the\n>> >> post.\n>> >>>\n>> >>\n>> > https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n>> >>> https://bitcointalk.org/index.php?topic=5344020.0\n>> >>> Can you please read it and share your idea about it.\n>> >>>\n>> >>> Cheers\n>> >>> Raymo\n>> >>> _______________________________________________\n>> >>> bitcoin-dev mailing list\n>> >>> bitcoin-dev at lists.linuxfoundation.org\n>> >>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> >> _______________________________________________\n>> >> bitcoin-dev mailing list\n>> >> bitcoin-dev at lists.linuxfoundation.org\n>> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Billy Tetrud",
                "date": "2021-07-02T17:57:54",
                "message_text_only": "Thanks for the details Raymo. A thought occurred to me. Given the fact that\nminers can abuse this system without penalty, it would be useful to be able\nto fix this. What if it was possible for the creditor to claw back the\nfunds even if the cheating transaction was mined instead of the guarantee\ntransaction? Let's say there was a way to sign a transaction that gives the\nreceiver of that transaction the ability to override any other transaction\nthat uses the UTXO? If this were possible, the issuer could give the\ncreditor this kind of transaction as the guarantee transaction, and in the\ncase a cheat was done, the creditor could still use the GT to reallocate\nthat UTXO to themselves.\n\nNow there are issues with this. First of all, it could give anyone the\nability to double spend. So it would be prudent to limit this in some way.\nThe revocation probably should only be valid for up to 6 blocks, such that\nif the transaction has 6 confirmations, it can no longer be reallocated\n(thus preserving the 6 block finality rule). It could also be required that\nthe UTXO be marked as opting into this behavior (so receivers would know\nabout the possibility it could get revoked). This second requirement would\nrequire Sabu issuers to make an on-chain transaction to set themselves\nup as an issuer.\n\nAnother issue is that this would make it possible for transactions to\nexpire. Any claw-back transaction would expire 6 blocks after the initial\ntransaction happened. This has been generally avoided in bitcoin, but I\nthink the relevant issues are solvable. You can find additional discussion\nof that in this thread\n<https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-June/019050.html>\n.\n\nI would imagine this kind of ability would be pretty controversial, but\nsince it can close out the possibility for miners to escape punishment, it\ncould make this protocol viable.\n\nOn Thu, Jul 1, 2021 at 3:15 PM <raymo at riseup.net> wrote:\n\n>\n> Hi Erik\n>\n> Please correct me if I misunderstood.\n>\n> > email is fully compromised.\n>\n> What I got is:\n> Email is not good because the sender and receiver are compromised.\n> Email is not good because the message content is revealed.\n> I can claim same argue about any other client/server model. Since the\n> server (website) service provider will ask some sort of KYC. And even if\n> the server uses end-to-end encryption, the provider company still can\n> read the packets content.\n> In my model the passive listener only can discover who is communicate to\n> whom and make a graph of connections. Although it is a threat for\n> privacy but the server/client model has this flaw inherently, since\n> provider already knew everything about everyone. In my model at least\n> users can make some fake connections and send some fake emails in order\n> to inject noise to communications.\n> Please note the fact that entire communication between mobile wallets\n> (via emails) are asymmetric PGP encrypted. The PGP keys are controlled\n> by end users unlike ALL pretending secure messengers (e.g whatsApp,\n> signal, zoom,\u2026).\n> If you are worried about the way of exchanging PGP public key, you are\n> right. The most secure way is in-person PGP key exchanging.\n> After that for payments the wallets communicate in pgp encrypted\n> messages and they can transfer Bitcoin address through an PGP encrypted\n> cipher, thus no revealing Bitcoin address to public would occur. Neither\n> the amounts of transactions will be reviled.\n> There for it would be a good practice for shops to put their email and\n> PGP public key on shop website and/or PGP public key servers, instead of\n> putting Bitcoin address on website or using 3rd parties services to hide\n> their Bitcoin payment addresses.\n>\n> If I missed some points about \u201cfully compromised\u201d please write it to me.\n>\n>\n> > public keys / addresses are sent\n> As I told before ALL communication in Sabu are PGP encrypted.\n>\n> > other routing data encrypted with public keys\n> >(not sure how data is routed in sabu)\n>\n> Sabu is not responsible for routing at all. It simply sends emails.\n> Indeed the wallets peer-to-peer network in Sabu is pretty straight\n> forward. Each mobile wallet has one email address as its handler and\n> identifier in mobile-wallets-network. Each mobile can send message to\n> another mobile by knowing its email address and the PGP public key.\n> This information can be prepared in first face-to-face contact of mobile\n> owners, or later (something like signing the other\u2019s public key in web\n> of trust) when a creditor wants to spend his money and transfer it to\n> another creditor. The creditor1 send the signed money transfer request\n> alongside the email and public key of creditor2 all in a PGP encrypted\n> message to issuer.\n>\n>\n>\n> > separate the Sabu protocol from the app... allow others to implement\n> > desktop version, or other versions that use other routing systems\n>\n> Indeed, it is my approach too. As I told before users will decide\n> between an unstoppable, permission less, self-sovereignty and\n> decentralized pure peer-to-peer communication network (with some\n> resolvable privacy issues) or some efficient, privacy-mimic central\n> limited network.\n>\n>\n> > you can allow direct-entry of a BIP-word-representation\n> > of a public key/address to avoid privacy/central system concerns\n> Agree. Actually, I was thinking about an easy mechanism to share your\n> public key like what you suggested here.\n> But what I consider for a \u201ccentral system concerns\u201d is the ability of\n> communication without dependency to any company.\n> As an example, what can you do if the twitter bans your account?\n> Nothing! Your content and entire connections will be lost.\n> But if you form your friends list in your mobile (or computer) and have\n> their PGP public keys and they have yours, and use email as a dual\n> purpose tool. First as a handler (the tool for finding and to be found\n> in internet) and second as a communication tool.\n> Thus, no one can stop you, ban you or limit you to send/receive\n> transaction to/from anyone.\n> What I am trying to say is using email is far better than account\n> (username) in a limited central service like twitter, Facebook,\n> telegram... or even in future Sabu servers!\n> You have your connections under your control in your phone. You can\n> easily change your email and use a new email or even a new service\n> provider without losing your connections and your control over it.\n> You just sign your new email address and send it to your friends circle\n> and notify them about changes.\n> Of course, email is not good for millions of followers but it is\n> obviously good for managing your payment network of hundreds of people\n> (either issuers or creditors).\n>\n> Best\n> Raymo\n>\n> On 2021-07-01 20:49, Erik Aronesty wrote:\n> > your protocol should always assume the email system is fully\n> > compromised, and only send public information over email:\n> >\n> > - public keys / addresses are sent\n> > - other routing data encrypted with public keys (not sure how data is\n> > routed in sabu)\n> >\n> > your end user should be able to verify public keys  / addresses\n> >\n> >  - use QR-codes\n> >  - phone calls with users reading BIP words out loud\n> >  - other in-person information exchange\n> >\n> > separate the Sabu protocol from the app... allow others to implement\n> > desktop version, or other versions that use other routing systems\n> >\n> > -  you can allow direct-entry of a BIP-word-representation of a public\n> > key/address to avoid privacy/central system concerns\n> >\n> > On Thu, Jul 1, 2021 at 4:20 PM raymo via bitcoin-dev\n> > <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>\n> >> Hi Billy,\n> >> Sorry for late reply. Let\u2019s jump in proposal.\n> >>\n> >> > Some more information about the benefits of this approach vs\n> alternatives (mainly lightning)\n> >> The most important different is unlike the lightning, in Sabu no one\n> >> have to open a channel and pay Bitcoin transaction fee, subsequently no\n> >> one has to close channel and pay another Bitcoin transaction fee. It is\n> >> the huge improvement since it drops the overhead cost of transactions.\n> >> So, it will be more convenience to trade under Sabu protocol.\n> >> In Sabu none of parties of a transaction are obliged to block money in\n> >> any kind of smart contract or any other m of n signature accounts\n> >> on-chain, so it provides more privacy.\n> >> Since Sabu protocol is designed to motivate people to circulate\n> >> transactions (AKA debt documents) in Sabu network, if every actor act\n> >> rationally no one will aware how much money transferred from who to\n> >> whom.\n> >> In case of fraudulent activity by issuer, the creditor will send\n> >> Guarantee Transaction (GT) to Bitcoin network in order to recapture the\n> >> part of his credit. So, in this case the transaction is literally\n> >> recorded on bitcoin blockchain.\n> >> There is only one another reason to recording transaction on Bitcoin\n> >> blockchain. Where one creditor eager to pay Bitcoin transaction fee in\n> >> order to aggregate thousands or even millions different small amount\n> >> debt-documents in a single transaction on Bitcoin blockchain.\n> >> despite these two cases, the rest of transactions all occur in the Sabu\n> >> network (supposed to be over 99%). Thus, no footprint no bottleneck and\n> >> no over process.\n> >>\n> >> Another important power point of Sabu is its pure-peer-to-peer network\n> >> architecture. In Sabu the mobile wallets communicating to each other\n> >> directly without any central server. There is no centralization at all.\n> >> As a result, there will be no routing as well.\n> >> Since only issuer and creditors are aware of the content of transaction\n> >> (who pay how much to whom) it is a huge privacy improvement, which\n> >> doesn\u2019t exist in other layer 2 solutions.\n> >>\n> >> About the usability of Sabu, although the protocol based on the\n> >> collaborating 2 different peer-to-peer network and 3 classic\n> >> server/client networks, but the end user (mobile wallet user) doesn\u2019t\n> >> see any of these complexities.\n> >> The end user simply installs the mobile/desktop wallet and add her/his\n> >> friends to his phonebook by adding their email address or scanning their\n> >> email (and/or PGP public key). After that s/he can immediately start to\n> >> send/receive Bitcoin through Sabu network. Entire communications between\n> >> wallets are PGP encrypted.\n> >> Another good point in Sabu design is, the 12 seed words are using for\n> >> both Bitcoin wallet private key and the PGP private key. So, it is the\n> >> key of user wealth and its identity as well. For more details, please\n> >> read my previous answer to Alex Schoof.\n> >> The issuer, by using his UTXOs and selling them to creditors earn money.\n> >> the issuer creates the debt document (transaction) by which promises to\n> >> creditor an amount of satoshi. These debt documents are valid Bitcoin\n> >> transaction. The only difference is these transactions are intended to\n> >> circulate in Sabu protocol instead of sending to Bitcoin blockchain.\n> >> Each transaction is a small money transfer. 40,000 Satoshi as input and\n> >> maximum 20,000 Satoshi as credit and minimum 10,000 Satoshi as Bitcoin\n> >> transaction fee.\n> >> The creditors will use these received transactions as money and will pay\n> >> it in exchange of goods or services. For each transaction the creditor\n> >> pays 10 Satoshi as Sabu-transaction-fee to issuer.\n> >> Sabu is not custodial service and the UXTOs are always under issuer\n> >> control, unless issuer or creditor send the signed transaction to\n> >> Bitcoin network. When the transaction was recorded in Bitcoin\n> >> blockchain, the creditor can spend proper UTXO in Bitcoin network.\n> >> Imagine million people use their UTXOs in Sabu, they are issuer and\n> >> issue/update/cancel million transactions per second. All they need is a\n> >> mobile wallet. On the other hand, every one by knowing an issuer can buy\n> >> some Satoshi (whit absolutely no KYC), even 1 Dollar or less, and spend\n> >> it, this time Alice really can buy caffe by Bitcoin ;)\n> >> The Bar can install the mobile wallet and every day receives thousands\n> >> of debt documents (transactions), each worth maximum 20,000 Satoshi in\n> >> exchange of coffee. And every evening aggregates those small\n> >> transactions to one single transaction and send it to Bitcoin network.\n> >>\n> >>\n> >> The security model of Sabu is pretty straight forward.\n> >> Issuer is the owner of UTXO(s) which will be used in transactions. The\n> >> issuer is and will the only person who creates transactions and sign\n> >> them. The transactions are valid transaction which either issuer or\n> >> creditor can send them to Bitcoin network, but they will never send\n> >> these transactions to Bitcoin network, because of the high Bitcoin\n> >> transaction fee for each single transaction.\n> >> Since issuer is the only one who can sign transaction (spend UTXOs),\n> >> there is a risk of issuer cheating. And no one can stop issuer from\n> >> cheating, because these are his UTXOs and he has the proper private\n> >> keys.\n> >> The Sabu solution is Guarantee transaction. It is a valid transaction\n> >> that issuer has to sign it alongside the Main transaction. In GT both\n> >> issuer and creditor cut a part of their output in favor of Bitcoin\n> >> transaction fee.\n> >> We suppose miners always seeking for more profit, thus in a case there\n> >> are 2 or more transaction are spending same UTXO as input, miner will\n> >> choose transaction with highest feeRate. There is no economically\n> >> benefit for issuer to cheat creditors and pay less transaction fee\n> >> simultaneously. So rationally the issuer won\u2019t cheat creditor.\n> >> It was the simplest explanation of Sabu security model.\n> >>\n> >> > I agree with others that using email is probably not appropriate for\n> a protocol like this. I would highly recommend making your protocol\n> transport-agnostic, allowing users of your protocol to use any transport\n> they want.\n> >> Indeed, the protocol is transparent-agnostic, if I insist of email as a\n> >> user identifier and communicating tool is because of the idea of\n> >> reforming part of internet architecture and make it more decentralized.\n> >> The wallet users can choose classic architecture. In this case mobile\n> >> wallets will connect to a central server and communicate through that\n> >> server (pretty much like all existed mobile wallets). While some users\n> >> decide to use a pure peer-to-peer communication. I knew email has some\n> >> privacy issues but as always it is a tradeoff. Users can decide between\n> >> an unstoppable, permission less, self-sovereignty and decentralized pure\n> >> peer-to-peer communication network (with some resolvable privacy issues)\n> >> or some efficient central limited network.\n> >> Let me know the critics about email. Hopefully this would lead us to\n> >> improve email instead of letting it die. I strongly suggest email\n> >> because it is the ONLY neutral, free \u201cnonproprietary\u201d and open\n> >> protocol/technology for communication in the world that its\n> >> infrastructure is well-established and is accessible all over the glob.\n> >>\n> >> I tried to explain it more, hope was useful. By the way the complete\n> >> explanation is here\n> >>\n> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n> >>\n> >>\n> >>\n> >> Regards\n> >> Raymo\n> >>\n> >>\n> >>\n> >> On 2021-06-22 18:20, Billy Tetrud wrote:\n> >> > I would be interested in seeing some more information about the\n> >> > benefits of this approach vs alternatives up front in this write up.\n> >> > Eg how does the security, cost, usability, and privacy compare to the\n> >> > lightning network, which would be the most likely competitor to this\n> >> > idea. It seems clear that there is more counterparty risk here, so it\n> >> > would probably also be very helpful to compare against traditional\n> >> > custodial solutions as well. If you have specific claims on how this\n> >> > system is better than eg lightning in certain contexts, it would be\n> >> > far easier to evaluate the protocol against those claims, and would\n> >> > also be a lot easier for readers to be motivated to read the whole\n> >> > protocol and do a more full analysis.\n> >> >\n> >> > I agree with others that using email is probably not appropriate for a\n> >> > protocol like this. I would highly recommend making your protocol\n> >> > transport-agnostic, allowing users of your protocol to use any\n> >> > transport they want.\n> >> >\n> >> > On Sat, Jun 19, 2021 at 7:00 PM James Hilliard via bitcoin-dev\n> >> > <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >> >\n> >> >> I think you're making a number of assumptions about mining that are\n> >> >> not accurate.\n> >> >>\n> >> >>> First of all, how much chance in finding next block the corrupted\n> >> >> miners have? One percent of all Bitcoin hash powers? Or maximum 5\n> >> >> percent or 10? The cheaters must come up in dividing that 1.2\n> >> >> Bitcoin between. After all the risk/reward must fit them. They can\n> >> >> not be a big mining pool since there is no benefit, so they will be\n> >> >> small miners with low hash rate. If they solve the puzzle and\n> >> >> broadcast the block, no one in the entire Bitcoin network has block\n> >> >> transactions or seen it before in their mempool!\n> >> >>\n> >> >> You're making the assumption that miners won't build on top of a\n> >> >> block\n> >> >> with transactions they have not seen before or transactions that may\n> >> >> contain double spends of unconfirmed inputs, this is not how mining\n> >> >> works, as long as the block passes the consensus rules effectively\n> >> >> all\n> >> >> miners will mine on top of it by default, this behavior is\n> >> >> fundamental\n> >> >> to how mining currently works and is fairly deeply baked into the\n> >> >> current mining infrastructure.\n> >> >>\n> >> >>> Will they accept this block? In theory it is possible and have\n> >> >> 0.01 percent chance but we can eliminate this small possibilities by\n> >> >> a simple BIP for miners.\n> >> >>\n> >> >> What would this BIP look like? I don't see how this could work in a\n> >> >> decentralized way as you would need another way of reaching\n> >> >> consensus\n> >> >> on what defines a valid block. Right now the chance is nearly 100\n> >> >> percent that a miner will mine on top of the latest valid block,\n> >> >> many\n> >> >> pools(most last I checked) will even mine on the next block before\n> >> >> they validate the latest block fully(ie validationless mining) to\n> >> >> reduce their orphan rates.\n> >> >>\n> >> >>> We suppose the miners always control transactions with\n> >> >> doc-watchers and avoid accepting transaction with same UTXO but\n> >> >> different output.\n> >> >>\n> >> >> Miners have different mempool policy/rules for what transactions\n> >> >> they\n> >> >> themselves mine but all miners must mine on the most work chain of\n> >> >> valid blocks otherwise they risk their own blocks being orphaned,\n> >> >> any\n> >> >> miner that does not do this is effectively guaranteed to have their\n> >> >> block orphaned right now.\n> >> >>\n> >> >>> Because of high Bitcoin transaction fee, this guarantee\n> >> >> transaction will take place in next block, even if other transaction\n> >> >> which are using the same UTXO as input existed in mempool.\n> >> >>\n> >> >> When a new transaction is broadcast miners do not immediately start\n> >> >> mining on a block template that includes that transaction, the\n> >> >> template won't even be generated immediately when it enters a miners\n> >> >> mempool in practice, for bandwidth/network efficiency reasons mining\n> >> >> pools batch update the stratum templates/jobs they mine against so\n> >> >> there can be significant latency between the time a transaction is\n> >> >> actually broadcast and hits the miners mempool and the time the\n> >> >> miners\n> >> >> actually switch to mining on top it, these batched updates are\n> >> >> essentially like point in time snapshots of the mempool and\n> >> >> typically\n> >> >> remain valid(as in the pool will accept shares submitted against\n> >> >> that\n> >> >> job as valid) until the bitcoin network finds the next block. I\n> >> >> don't\n> >> >> think these batch updates are done more often than every 30 seconds\n> >> >> typically, while often it is on the order of multiple minutes\n> >> >> depending on the pool.\n> >> >>\n> >> >> Regards,\n> >> >> James\n> >> >>\n> >> >> On Thu, Jun 17, 2021 at 2:14 PM raymo via bitcoin-dev\n> >> >> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >> >>>\n> >> >>> Hi,\n> >> >>> I have a proposal for improve Bitcoin TPS and privacy, here is the\n> >> >> post.\n> >> >>>\n> >> >>\n> >> >\n> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n> >> >>> https://bitcointalk.org/index.php?topic=5344020.0\n> >> >>> Can you please read it and share your idea about it.\n> >> >>>\n> >> >>> Cheers\n> >> >>> Raymo\n> >> >>> _______________________________________________\n> >> >>> bitcoin-dev mailing list\n> >> >>> bitcoin-dev at lists.linuxfoundation.org\n> >> >>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >> >> _______________________________________________\n> >> >> bitcoin-dev mailing list\n> >> >> bitcoin-dev at lists.linuxfoundation.org\n> >> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >> _______________________________________________\n> >> bitcoin-dev mailing list\n> >> bitcoin-dev at lists.linuxfoundation.org\n> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210702/ba3a3221/attachment-0001.html>"
            },
            {
                "author": "raymo at riseup.net",
                "date": "2021-07-03T08:02:09",
                "message_text_only": "Hi Billy,\n\n> What if it was possible for the creditor to claw back the funds\nAs far as I know the \u201cclaw back\u201d mechanism doesn\u2019t exist in Bitcoin\nsystem, and probably most Bitcoiners won\u2019t be agree on it. \nEven if we want to add claw back to Bitcoin in general, and Sabu in\nparticular, it would add too complexities and uncertainty to Bitcoin. \nSo, it would be better to not touch that part, instead focusing on\nreduce the cheating risk by putting some penalty for both issuers,\ncreditors and miners. \nWe already have the penalties for both issuers and creditors. \nIt looks the miners still can abuse Sabu, but as I told before the miner\nor better say the mining pool must be issuer (to be able to sign the\npromised UTXO in cheating way) or must be creditor (in order to have a\ncopy of GT and not lose his money in favor of a stranger miner. Remember\nthe fact that creditor will lose 70% of their money in favor of Bitcoin\ntransaction fee in a typical GT) or collaborate one of them in a\nconspiracy. Otherwise, there will be no economic benefit in this attack.\n \nAll these 3 cases of the attacks, theoretically could be happened, but\nthe risk to reward ratio is enough high to hinder potential malevolent\nfrom a practical act.\nEven this very small risk of miner attacks (which don\u2019t care the attack\ncosts, since he is not interested in economic benefit, but he wants to\nruin Sabu), would be resolved by a slightly upgrade in Bitcoin protocol\nby applying the BIPxxx \u201cfor flagging/unflagging promised UTXOs\u201d. \nI am not in rush to apply this upgrade on Bitcoin protocol, instead I am\nactively working in order to realize the Sabu protocol and Gazin wallet.\nLater the Sabu community will carry the BIPxxx.\n\nBest\n\nOn 2021-07-02 17:57, Billy Tetrud wrote:\n> Thanks for the details Raymo. A thought occurred to me. Given the fact\n> that miners can abuse this system without penalty, it would be useful\n> to be able to fix this. What if it was possible for the creditor to\n> claw back the funds even if the cheating transaction was mined instead\n> of the guarantee transaction? Let's say there was a way to sign a\n> transaction that gives the receiver of that transaction the ability to\n> override any other transaction that uses the UTXO? If this were\n> possible, the issuer could give the creditor this kind of transaction\n> as the guarantee transaction, and in the case a cheat was done, the\n> creditor could still use the GT to reallocate that UTXO to themselves.\n> \n> Now there are issues with this. First of all, it could give anyone the\n> ability to double spend. So it would be prudent to limit this in some\n> way. The revocation probably should only be valid for up to 6 blocks,\n> such that if the transaction has 6 confirmations, it can no longer be\n> reallocated (thus preserving the 6 block finality rule). It could also\n> be required that the UTXO be marked as opting into this behavior (so\n> receivers would know about the possibility it could get revoked). This\n> second requirement would require Sabu issuers to make an on-chain\n> transaction to set themselves up as an issuer. \n> \n> Another issue is that this would make it possible for transactions to\n> expire. Any claw-back transaction would expire 6 blocks after the\n> initial transaction happened. This has been generally avoided in\n> bitcoin, but I think the relevant issues are solvable. You can find\n> additional discussion of that in this thread [1].\n> \n> I would imagine this kind of ability would be pretty controversial,\n> but since it can close out the possibility for miners to escape\n> punishment, it could make this protocol viable. \n> \n> On Thu, Jul 1, 2021 at 3:15 PM <raymo at riseup.net> wrote:\n> \n>> Hi Erik\n>>\n>> Please correct me if I misunderstood.\n>>\n>>> email is fully compromised.\n>>\n>> What I got is:\n>> Email is not good because the sender and receiver are compromised.\n>> Email is not good because the message content is revealed.\n>> I can claim same argue about any other client/server model. Since\n>> the\n>> server (website) service provider will ask some sort of KYC. And\n>> even if\n>> the server uses end-to-end encryption, the provider company still\n>> can\n>> read the packets content.\n>> In my model the passive listener only can discover who is\n>> communicate to\n>> whom and make a graph of connections. Although it is a threat for\n>> privacy but the server/client model has this flaw inherently, since\n>> provider already knew everything about everyone. In my model at\n>> least\n>> users can make some fake connections and send some fake emails in\n>> order\n>> to inject noise to communications.\n>> Please note the fact that entire communication between mobile\n>> wallets\n>> (via emails) are asymmetric PGP encrypted. The PGP keys are\n>> controlled\n>> by end users unlike ALL pretending secure messengers (e.g whatsApp,\n>> signal, zoom,\u2026).\n>> If you are worried about the way of exchanging PGP public key, you\n>> are\n>> right. The most secure way is in-person PGP key exchanging.\n>> After that for payments the wallets communicate in pgp encrypted\n>> messages and they can transfer Bitcoin address through an PGP\n>> encrypted\n>> cipher, thus no revealing Bitcoin address to public would occur.\n>> Neither\n>> the amounts of transactions will be reviled.\n>> There for it would be a good practice for shops to put their email\n>> and\n>> PGP public key on shop website and/or PGP public key servers,\n>> instead of\n>> putting Bitcoin address on website or using 3rd parties services to\n>> hide\n>> their Bitcoin payment addresses.\n>>\n>> If I missed some points about \u201cfully compromised\u201d please write\n>> it to me.\n>>\n>>> public keys / addresses are sent\n>> As I told before ALL communication in Sabu are PGP encrypted.\n>>\n>>> other routing data encrypted with public keys\n>>> (not sure how data is routed in sabu)\n>>\n>> Sabu is not responsible for routing at all. It simply sends emails.\n>> Indeed the wallets peer-to-peer network in Sabu is pretty straight\n>> forward. Each mobile wallet has one email address as its handler and\n>> identifier in mobile-wallets-network. Each mobile can send message\n>> to\n>> another mobile by knowing its email address and the PGP public key.\n>> This information can be prepared in first face-to-face contact of\n>> mobile\n>> owners, or later (something like signing the other\u2019s public key in\n>> web\n>> of trust) when a creditor wants to spend his money and transfer it\n>> to\n>> another creditor. The creditor1 send the signed money transfer\n>> request\n>> alongside the email and public key of creditor2 all in a PGP\n>> encrypted\n>> message to issuer.\n>>\n>>> separate the Sabu protocol from the app... allow others to\n>> implement\n>>> desktop version, or other versions that use other routing systems\n>>\n>> Indeed, it is my approach too. As I told before users will decide\n>> between an unstoppable, permission less, self-sovereignty and\n>> decentralized pure peer-to-peer communication network (with some\n>> resolvable privacy issues) or some efficient, privacy-mimic central\n>> limited network.\n>>\n>>> you can allow direct-entry of a BIP-word-representation\n>>> of a public key/address to avoid privacy/central system concerns\n>> Agree. Actually, I was thinking about an easy mechanism to share\n>> your\n>> public key like what you suggested here.\n>> But what I consider for a \u201ccentral system concerns\u201d is the\n>> ability of\n>> communication without dependency to any company.\n>> As an example, what can you do if the twitter bans your account?\n>> Nothing! Your content and entire connections will be lost.\n>> But if you form your friends list in your mobile (or computer) and\n>> have\n>> their PGP public keys and they have yours, and use email as a dual\n>> purpose tool. First as a handler (the tool for finding and to be\n>> found\n>> in internet) and second as a communication tool.\n>> Thus, no one can stop you, ban you or limit you to send/receive\n>> transaction to/from anyone.\n>> What I am trying to say is using email is far better than account\n>> (username) in a limited central service like twitter, Facebook,\n>> telegram... or even in future Sabu servers!\n>> You have your connections under your control in your phone. You can\n>> easily change your email and use a new email or even a new service\n>> provider without losing your connections and your control over it.\n>> You just sign your new email address and send it to your friends\n>> circle\n>> and notify them about changes.\n>> Of course, email is not good for millions of followers but it is\n>> obviously good for managing your payment network of hundreds of\n>> people\n>> (either issuers or creditors).\n>>\n>> Best\n>> Raymo\n>>\n>> On 2021-07-01 20:49, Erik Aronesty wrote:\n>>> your protocol should always assume the email system is fully\n>>> compromised, and only send public information over email:\n>>>\n>>> - public keys / addresses are sent\n>>> - other routing data encrypted with public keys (not sure how data\n>> is\n>>> routed in sabu)\n>>>\n>>> your end user should be able to verify public keys  / addresses\n>>>\n>>> - use QR-codes\n>>> - phone calls with users reading BIP words out loud\n>>> - other in-person information exchange\n>>>\n>>> separate the Sabu protocol from the app... allow others to\n>> implement\n>>> desktop version, or other versions that use other routing systems\n>>>\n>>> -  you can allow direct-entry of a BIP-word-representation of a\n>> public\n>>> key/address to avoid privacy/central system concerns\n>>>\n>>> On Thu, Jul 1, 2021 at 4:20 PM raymo via bitcoin-dev\n>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>\n>>>> Hi Billy,\n>>>> Sorry for late reply. Let\u2019s jump in proposal.\n>>>>\n>>>>> Some more information about the benefits of this approach vs\n>> alternatives (mainly lightning)\n>>>> The most important different is unlike the lightning, in Sabu no\n>> one\n>>>> have to open a channel and pay Bitcoin transaction fee,\n>> subsequently no\n>>>> one has to close channel and pay another Bitcoin transaction fee.\n>> It is\n>>>> the huge improvement since it drops the overhead cost of\n>> transactions.\n>>>> So, it will be more convenience to trade under Sabu protocol.\n>>>> In Sabu none of parties of a transaction are obliged to block\n>> money in\n>>>> any kind of smart contract or any other m of n signature accounts\n>>>> on-chain, so it provides more privacy.\n>>>> Since Sabu protocol is designed to motivate people to circulate\n>>>> transactions (AKA debt documents) in Sabu network, if every actor\n>> act\n>>>> rationally no one will aware how much money transferred from who\n>> to\n>>>> whom.\n>>>> In case of fraudulent activity by issuer, the creditor will send\n>>>> Guarantee Transaction (GT) to Bitcoin network in order to\n>> recapture the\n>>>> part of his credit. So, in this case the transaction is literally\n>>>> recorded on bitcoin blockchain.\n>>>> There is only one another reason to recording transaction on\n>> Bitcoin\n>>>> blockchain. Where one creditor eager to pay Bitcoin transaction\n>> fee in\n>>>> order to aggregate thousands or even millions different small\n>> amount\n>>>> debt-documents in a single transaction on Bitcoin blockchain.\n>>>> despite these two cases, the rest of transactions all occur in\n>> the Sabu\n>>>> network (supposed to be over 99%). Thus, no footprint no\n>> bottleneck and\n>>>> no over process.\n>>>>\n>>>> Another important power point of Sabu is its pure-peer-to-peer\n>> network\n>>>> architecture. In Sabu the mobile wallets communicating to each\n>> other\n>>>> directly without any central server. There is no centralization\n>> at all.\n>>>> As a result, there will be no routing as well.\n>>>> Since only issuer and creditors are aware of the content of\n>> transaction\n>>>> (who pay how much to whom) it is a huge privacy improvement,\n>> which\n>>>> doesn\u2019t exist in other layer 2 solutions.\n>>>>\n>>>> About the usability of Sabu, although the protocol based on the\n>>>> collaborating 2 different peer-to-peer network and 3 classic\n>>>> server/client networks, but the end user (mobile wallet user)\n>> doesn\u2019t\n>>>> see any of these complexities.\n>>>> The end user simply installs the mobile/desktop wallet and add\n>> her/his\n>>>> friends to his phonebook by adding their email address or\n>> scanning their\n>>>> email (and/or PGP public key). After that s/he can immediately\n>> start to\n>>>> send/receive Bitcoin through Sabu network. Entire communications\n>> between\n>>>> wallets are PGP encrypted.\n>>>> Another good point in Sabu design is, the 12 seed words are using\n>> for\n>>>> both Bitcoin wallet private key and the PGP private key. So, it\n>> is the\n>>>> key of user wealth and its identity as well. For more details,\n>> please\n>>>> read my previous answer to Alex Schoof.\n>>>> The issuer, by using his UTXOs and selling them to creditors earn\n>> money.\n>>>> the issuer creates the debt document (transaction) by which\n>> promises to\n>>>> creditor an amount of satoshi. These debt documents are valid\n>> Bitcoin\n>>>> transaction. The only difference is these transactions are\n>> intended to\n>>>> circulate in Sabu protocol instead of sending to Bitcoin\n>> blockchain.\n>>>> Each transaction is a small money transfer. 40,000 Satoshi as\n>> input and\n>>>> maximum 20,000 Satoshi as credit and minimum 10,000 Satoshi as\n>> Bitcoin\n>>>> transaction fee.\n>>>> The creditors will use these received transactions as money and\n>> will pay\n>>>> it in exchange of goods or services. For each transaction the\n>> creditor\n>>>> pays 10 Satoshi as Sabu-transaction-fee to issuer.\n>>>> Sabu is not custodial service and the UXTOs are always under\n>> issuer\n>>>> control, unless issuer or creditor send the signed transaction to\n>>>> Bitcoin network. When the transaction was recorded in Bitcoin\n>>>> blockchain, the creditor can spend proper UTXO in Bitcoin\n>> network.\n>>>> Imagine million people use their UTXOs in Sabu, they are issuer\n>> and\n>>>> issue/update/cancel million transactions per second. All they\n>> need is a\n>>>> mobile wallet. On the other hand, every one by knowing an issuer\n>> can buy\n>>>> some Satoshi (whit absolutely no KYC), even 1 Dollar or less, and\n>> spend\n>>>> it, this time Alice really can buy caffe by Bitcoin ;)\n>>>> The Bar can install the mobile wallet and every day receives\n>> thousands\n>>>> of debt documents (transactions), each worth maximum 20,000\n>> Satoshi in\n>>>> exchange of coffee. And every evening aggregates those small\n>>>> transactions to one single transaction and send it to Bitcoin\n>> network.\n>>>>\n>>>>\n>>>> The security model of Sabu is pretty straight forward.\n>>>> Issuer is the owner of UTXO(s) which will be used in\n>> transactions. The\n>>>> issuer is and will the only person who creates transactions and\n>> sign\n>>>> them. The transactions are valid transaction which either issuer\n>> or\n>>>> creditor can send them to Bitcoin network, but they will never\n>> send\n>>>> these transactions to Bitcoin network, because of the high\n>> Bitcoin\n>>>> transaction fee for each single transaction.\n>>>> Since issuer is the only one who can sign transaction (spend\n>> UTXOs),\n>>>> there is a risk of issuer cheating. And no one can stop issuer\n>> from\n>>>> cheating, because these are his UTXOs and he has the proper\n>> private\n>>>> keys.\n>>>> The Sabu solution is Guarantee transaction. It is a valid\n>> transaction\n>>>> that issuer has to sign it alongside the Main transaction. In GT\n>> both\n>>>> issuer and creditor cut a part of their output in favor of\n>> Bitcoin\n>>>> transaction fee.\n>>>> We suppose miners always seeking for more profit, thus in a case\n>> there\n>>>> are 2 or more transaction are spending same UTXO as input, miner\n>> will\n>>>> choose transaction with highest feeRate. There is no economically\n>>>> benefit for issuer to cheat creditors and pay less transaction\n>> fee\n>>>> simultaneously. So rationally the issuer won\u2019t cheat creditor.\n>>>> It was the simplest explanation of Sabu security model.\n>>>>\n>>>>> I agree with others that using email is probably not\n>> appropriate for a protocol like this. I would highly recommend\n>> making your protocol transport-agnostic, allowing users of your\n>> protocol to use any transport they want.\n>>>> Indeed, the protocol is transparent-agnostic, if I insist of\n>> email as a\n>>>> user identifier and communicating tool is because of the idea of\n>>>> reforming part of internet architecture and make it more\n>> decentralized.\n>>>> The wallet users can choose classic architecture. In this case\n>> mobile\n>>>> wallets will connect to a central server and communicate through\n>> that\n>>>> server (pretty much like all existed mobile wallets). While some\n>> users\n>>>> decide to use a pure peer-to-peer communication. I knew email has\n>> some\n>>>> privacy issues but as always it is a tradeoff. Users can decide\n>> between\n>>>> an unstoppable, permission less, self-sovereignty and\n>> decentralized pure\n>>>> peer-to-peer communication network (with some resolvable privacy\n>> issues)\n>>>> or some efficient central limited network.\n>>>> Let me know the critics about email. Hopefully this would lead us\n>> to\n>>>> improve email instead of letting it die. I strongly suggest email\n>>>> because it is the ONLY neutral, free \u201cnonproprietary\u201d and\n>> open\n>>>> protocol/technology for communication in the world that its\n>>>> infrastructure is well-established and is accessible all over the\n>> glob.\n>>>>\n>>>> I tried to explain it more, hope was useful. By the way the\n>> complete\n>>>> explanation is here\n>>>>\n>>\n> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n>>>>\n>>>>\n>>>>\n>>>> Regards\n>>>> Raymo\n>>>>\n>>>>\n>>>>\n>>>> On 2021-06-22 18:20, Billy Tetrud wrote:\n>>>>> I would be interested in seeing some more information about the\n>>>>> benefits of this approach vs alternatives up front in this\n>> write up.\n>>>>> Eg how does the security, cost, usability, and privacy compare\n>> to the\n>>>>> lightning network, which would be the most likely competitor to\n>> this\n>>>>> idea. It seems clear that there is more counterparty risk here,\n>> so it\n>>>>> would probably also be very helpful to compare against\n>> traditional\n>>>>> custodial solutions as well. If you have specific claims on how\n>> this\n>>>>> system is better than eg lightning in certain contexts, it\n>> would be\n>>>>> far easier to evaluate the protocol against those claims, and\n>> would\n>>>>> also be a lot easier for readers to be motivated to read the\n>> whole\n>>>>> protocol and do a more full analysis.\n>>>>>\n>>>>> I agree with others that using email is probably not\n>> appropriate for a\n>>>>> protocol like this. I would highly recommend making your\n>> protocol\n>>>>> transport-agnostic, allowing users of your protocol to use any\n>>>>> transport they want.\n>>>>>\n>>>>> On Sat, Jun 19, 2021 at 7:00 PM James Hilliard via bitcoin-dev\n>>>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>>\n>>>>>> I think you're making a number of assumptions about mining\n>> that are\n>>>>>> not accurate.\n>>>>>>\n>>>>>>> First of all, how much chance in finding next block the\n>> corrupted\n>>>>>> miners have? One percent of all Bitcoin hash powers? Or\n>> maximum 5\n>>>>>> percent or 10? The cheaters must come up in dividing that 1.2\n>>>>>> Bitcoin between. After all the risk/reward must fit them. They\n>> can\n>>>>>> not be a big mining pool since there is no benefit, so they\n>> will be\n>>>>>> small miners with low hash rate. If they solve the puzzle and\n>>>>>> broadcast the block, no one in the entire Bitcoin network has\n>> block\n>>>>>> transactions or seen it before in their mempool!\n>>>>>>\n>>>>>> You're making the assumption that miners won't build on top of\n>> a\n>>>>>> block\n>>>>>> with transactions they have not seen before or transactions\n>> that may\n>>>>>> contain double spends of unconfirmed inputs, this is not how\n>> mining\n>>>>>> works, as long as the block passes the consensus rules\n>> effectively\n>>>>>> all\n>>>>>> miners will mine on top of it by default, this behavior is\n>>>>>> fundamental\n>>>>>> to how mining currently works and is fairly deeply baked into\n>> the\n>>>>>> current mining infrastructure.\n>>>>>>\n>>>>>>> Will they accept this block? In theory it is possible and\n>> have\n>>>>>> 0.01 percent chance but we can eliminate this small\n>> possibilities by\n>>>>>> a simple BIP for miners.\n>>>>>>\n>>>>>> What would this BIP look like? I don't see how this could work\n>> in a\n>>>>>> decentralized way as you would need another way of reaching\n>>>>>> consensus\n>>>>>> on what defines a valid block. Right now the chance is nearly\n>> 100\n>>>>>> percent that a miner will mine on top of the latest valid\n>> block,\n>>>>>> many\n>>>>>> pools(most last I checked) will even mine on the next block\n>> before\n>>>>>> they validate the latest block fully(ie validationless mining)\n>> to\n>>>>>> reduce their orphan rates.\n>>>>>>\n>>>>>>> We suppose the miners always control transactions with\n>>>>>> doc-watchers and avoid accepting transaction with same UTXO\n>> but\n>>>>>> different output.\n>>>>>>\n>>>>>> Miners have different mempool policy/rules for what\n>> transactions\n>>>>>> they\n>>>>>> themselves mine but all miners must mine on the most work\n>> chain of\n>>>>>> valid blocks otherwise they risk their own blocks being\n>> orphaned,\n>>>>>> any\n>>>>>> miner that does not do this is effectively guaranteed to have\n>> their\n>>>>>> block orphaned right now.\n>>>>>>\n>>>>>>> Because of high Bitcoin transaction fee, this guarantee\n>>>>>> transaction will take place in next block, even if other\n>> transaction\n>>>>>> which are using the same UTXO as input existed in mempool.\n>>>>>>\n>>>>>> When a new transaction is broadcast miners do not immediately\n>> start\n>>>>>> mining on a block template that includes that transaction, the\n>>>>>> template won't even be generated immediately when it enters a\n>> miners\n>>>>>> mempool in practice, for bandwidth/network efficiency reasons\n>> mining\n>>>>>> pools batch update the stratum templates/jobs they mine\n>> against so\n>>>>>> there can be significant latency between the time a\n>> transaction is\n>>>>>> actually broadcast and hits the miners mempool and the time\n>> the\n>>>>>> miners\n>>>>>> actually switch to mining on top it, these batched updates are\n>>>>>> essentially like point in time snapshots of the mempool and\n>>>>>> typically\n>>>>>> remain valid(as in the pool will accept shares submitted\n>> against\n>>>>>> that\n>>>>>> job as valid) until the bitcoin network finds the next block.\n>> I\n>>>>>> don't\n>>>>>> think these batch updates are done more often than every 30\n>> seconds\n>>>>>> typically, while often it is on the order of multiple minutes\n>>>>>> depending on the pool.\n>>>>>>\n>>>>>> Regards,\n>>>>>> James\n>>>>>>\n>>>>>> On Thu, Jun 17, 2021 at 2:14 PM raymo via bitcoin-dev\n>>>>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>>>>\n>>>>>>> Hi,\n>>>>>>> I have a proposal for improve Bitcoin TPS and privacy, here\n>> is the\n>>>>>> post.\n>>>>>>>\n>>>>>>\n>>>>>\n>>\n> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n>>>>>>> https://bitcointalk.org/index.php?topic=5344020.0\n>>>>>>> Can you please read it and share your idea about it.\n>>>>>>>\n>>>>>>> Cheers\n>>>>>>> Raymo\n>>>>>>> _______________________________________________\n>>>>>>> bitcoin-dev mailing list\n>>>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>>>>\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>> _______________________________________________\n>>>>>> bitcoin-dev mailing list\n>>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>  \n> \n> Links:\n> ------\n> [1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-June/019050.html"
            },
            {
                "author": "Billy Tetrud",
                "date": "2021-07-07T03:20:38",
                "message_text_only": ">  As far as I know the \u201cclaw back\u201d mechanism doesn\u2019t exist in Bitcoin\nsystem, and probably most Bitcoiners won\u2019t be agree on it.\n\nIt certainly doesn't. And it would definitely be a hard sell.\n\n> It looks the miners still can abuse Sabu, but as I told before the miner\nor better say the mining pool must be issuer .. or must be creditor .. or\ncollaborate one of them in a\nconspiracy.\n\nYes. But it certainly incentivizes miners to become creditors and scam\npeople. Even if a small miner who mines one block a year does this, they\ncan mine all Guarantee Transactions in their possession. Larger miners that\nmine one block every few days can scam that much more often. Even with $5\ncredits, that could be an extra $9000 gained in a block. That's pretty\nsubstantial when fees are totaling around $45,000 per block.\n\n> would be resolved by a slightly upgrade in Bitcoin protocol by applying\nthe BIPxxx \u201cfor flagging/unflagging promised UTXOs\u201d\n\nAs others have mentioned tho, doing something like that would be at very\nleast quite complex, and at worst impossible to do securely. The whole\nreason why bitcoin's blockchain exists in the first place is to be a single\nsource of truth for transactions. The mempool is not a source of truth for\nconsensus. The Sabu network could not be a source of truth either for\nconsensus, without some serious innovations (that may not be possible). It\nisn't as simple as you seem to be thinking.\n\n>  The new transaction will use same 40,000 UTXO as input and the outputs\nwill be 6,500 Sat for creditor (he pays 2,500 Sat for transaction fee)\n4,500 Sat for creditor 2\n\nThis is the part I was unable to find/understand quickly enough in the\noriginal write up. So for creditor 1 to pay creditor 2, a new main\ntransaction and guarantee transaction are created that credit the\nappropriate people, right? FYI, the MT and GT acronyms make it harder for\nme to read/understand, so I'm preferring to write them out. But that helps.\nLet me write this out in a different (more compact) way:\n\n1. Creditor A $5 -> Issuer\n\n2. Issuer creates and shares transactions:\n\nMain Transaction (40k sats):\n* Issuer: 19k sats\n* Creditor A: 11k sats\n* Fee: 10k sats (4k from creditor, 6k from issuer)\n\nGuarantee Transaction (40k sats):\n* Issuer: 13,300 sats\n* Creditor A: 1650 sats\n* Fee: 25,050 sats\n\n3. Creditor A, 6k sats -> Creditor B. Issuer creates and shares\ntransactions:\n\nMain Transaction (40k sats):\n* Issuer: 19k sats\n* Creditor A:  6,500 sats\n* Creditor B:  4,500 sats\n* Fee: 10k sats (4k from creditor, 6k from issuer)\n\nGuarantee Transaction (40k sats):\n* Issuer: 13300 sats\n* Creditor A: 975 sats\n* Creditor B: 675 sats\n* Fee: 25050 sats\n\nIs this right?\n\n> The miner attack is just a failed plan as I explained before\n\nI thought you acknowledged that the miner attack is an issue above. No?\n\n>> Sabu has slightly greater risk comparing lightning\n> It is not true,\n\nWhat I mean is that a violation of trust results in more damaging effects\nwith Sabu than with lightning. In lightning, if your channel partner\ncheats, at worst you must simply pay a normal transaction fee. With Sabu,\nif a creditor cheats, you will likely pay an abnormally large transaction\nfee. This is what I mean by \"greater risk\". Some attackers are what's known\nas griefers - these are people willing to spend time and money hurting\nsomeone else, even if they don't make a profit from it (other\nthan schadenfreude). It seems clear there is a greater risk of being\ngriefed in Sabu than in lightning.\n\nFurthermore, while in lightning, if you perform the protocol properly, your\nfunds can never be stolen except in very extreme circumstances (eg\nwidespread long-running network congestion that prevents confirming a\nrevoke transaction). By contrast, Sabu has a significant likelihood that a\ncheating transaction could be mined instead of the guarantee transaction.\nPerhaps the likelihood is approximately 2 seconds / 10 minutes (0.3%\nchance), but a 0.3% is clearly larger than approximately 0% chance in\nlightning. Again, this is another part of what I mean by \"higher risk\".\n\nThese are both real counterparty risks that you shouldn't simply ignore. It\nmay be true that no rational actor will attempt an attack, however not all\nactors are rational. People also make mistakes, write buggy software, etc\netc. The existence of risk doesn't ruin your idea - every protocol has\nrisks. But identifying the specific risks is the only way to compare the\nproperties against alternatives (like on chain transactions or the\nlightning network). I think its important to acknowledge these risks in\nyour write up.\n\n> I explained before this kind of attacks will not happened never\n\nIf people use your protocol, some will inevitably use it wrong. Those that\nuse it wrong should be the ones that pay the price for it - but it is a\ndownside of the protocol if the counter party of the person that makes a\nmistake (or attempts something malicious) is harmed as a result. Again,\nthese kinds of trade offs are ok, but you should not be assuming that\nattacks like this will never happen. They will happen sometimes. You must\nassume that. The question is what is the result when an attack is\nattempted? And how will that affect what kinds of actors will attempt an\nattack (malicious, profit seeking, honest, stupid, wreckless, incompetent,\nother types of actors etc etc)?\n\n> I didn\u2019t find any case Lightning can compete with Sabu.\n\nAs I explained above related to risk, there are trade offs. I would like to\nsee in your write up a clear list of these trade offs. The additional risk\n(as I explained it above) is one trade off. It sounds like there are limits\nin which a creditor or issuer can safely rely on incentives to prevent\nattacks. Did you specify what those limits are? The Lightning network also\nhas limits - eg a lightning node can't allow its channel partner to spend\n100% of their coins without taking on additional risk of attack. How do\nthose limits compare in Sabu? For example, an issuer couldn't allow any\ncreditor to spend so much of their credited bitcoin that their credit goes\nbelow the amount they would receive in any past Guarantee Transaction\nwithout taking on the risk that the creditor would post that guarantee\ntransaction and receive coins they shouldn't own anymore. I would love to\nsee a more detailed comparison of Sabu to lightning.\n\nIf your protocol works out, there are obvious benefits: transactions that\ncould be done with no on-chain footprint. However, even if the protocol\nworks out, there are trade offs and those trade offs should be made very\nclear. Even if the comparative downsides are small.\n\n~BT\n\nHi Billy\n> > high-level overview of how all the pieces (How Sabu protocol works).\n> > how normal transactions happen in their entirety.\n> Ok, lets re-explain Sabu. In Sabu protocol we have two type of actors.\n> The issuers who own Bitcoin (they own UTXOs on Bitcoin blockchain), and\n> the creditors who will own Bitcoins (the UTXOs on Bitcoin blockchain),\n> if the issuer or the creditor sends the prepared transaction to Bitcoin\n> network. But for know creditors have the transaction in their hand.\n> Before sending this transaction to Bitcoin network it acts (in Sabu\n> protocol and Sabu network) as a liability of issuer.\n> The story always starts from issuer, the person who get money or goods\n> or services from a creditor and in exchange creates and sings a valid\n> Bitcoin transaction by which the issuer spends his UTXO and as a one of\n> the outputs of the transaction, there will be an output for creditor\u2019s\n> address equal to the money issuer already get paid.\n> This transaction is a valid transaction which is signed \u201conly\u201d by\n> issuer. The outputs of transaction are just and exact balance of the\n> parties (issuer and creditor).\n> Lets, imagine the creditor payed 5$ (almost equal to 15,000 Sat) to\n> issuer. Thus, issuer will create and sign a transaction by which he\n> spends 40,000 Sat and the outputs will be\n> 11,000 for creditor (the creditor has to pay 4,000 Sat in favor of\n> transaction fee),\n> 10,000 for Bitcoin-transaction-fee (4,000 by creditor and 6,000 by\n> issuer) and\n> 19,000 change back to issuer account address.\n> It is our Main Transaction (MT) which is a pretty normal and valid\n> transaction.\n> Alongside the MT, issuer creates and signs a Guarantee Transaction (GT).\n> In GT issuer spends same 40,000 Sat UTXO as input, and as outputs\n> the creditor will get 15% of his 11,000 Sat in Main Transaction. Thus\n> the creditor output will be 1,650 Sat and the rest of creditor\u2019s money\n> (11,000 \u2013 1,650 = 9,350 Sat) will be added to transaction fee.\n> In GT also issuer will lose a part of his money. New output for issuer\n> will be 19,000 * 70% = 13,300 and the rest will be added to transaction\n> fee (19,000 \u2013 13,300 = 5,700 Sat)\n> Thus, the new transaction fee in GT will be 10,000 + 9,350 + 5,700 =\n> 25,050 Sat\n> Now the creditor has 2 valid transactions (MT and GT) in his hands. He\n> can send either MT or GT or both to Bitcoin Network. But in all cases,\n> he will lose a portion of his money in favor of transaction fee (miner\u2019s\n> income). So, rationally he will never send transactions to Bitcoin\n> network unless he wants consciously hurt himself.\n> The creditor always prefers to spend his credit inside the Sabu\n> protocol. It is \u201chow normal transactions happen in their entirety.\u201d\n> Creditor has equal to 15,000 Sat credit. Say he wants to buy a caffe\n> worth 6,000 Sat. He has to ask the issuer to nullify previous MT and GT,\n> and create and sign new transaction and cut 6,000 Sat from his credit\n> and transfer it to a new creditor (say C2).\n> The new transaction will use same 40,000 UTXO as input and the outputs\n> will be\n> 6,500 Sat for creditor (he pays 2,500 Sat for transaction fee)\n> 4,500 Sat for creditor 2 (he has to pay 1,500 Sat for transaction fee as\n> well)\n> 10,000 for Bitcoin-transaction-fee (4,000 by two creditors and 6,000 by\n> issuer) and\n> 19,000 change back to issuer account address.\n> This is the new MT, and as you can see the C1 and C2 have their new\n> credit in transaction.\n> You can calculate the new GT as well.\n> Note: due to simplicity I just rounded the numbers and skipped the\n> Sabu-transaction-fee\n> I just wrote this long story to explain how creditors just transfer\n> money in between.\n> If we take a snapshot of Sabu network, we will see millions of valid\n> transactions flowing in network and none of the issuers or creditors\n> will send these transactions to Bitcoin network due the transaction fee,\n> while in Bitcoin blockchain nothing is changed! The UTXOs are untouched,\n> and no one can say which UTXO is promised to who.\n> It is a pretty secure off-chain protocol.\n> Although I expected more Bitcoiners to react about Sabu proposal and\n> comment for or against it, so far, I have not seen any serious criticism\n> or real threat about protocol.\n> The miner attack is just a failed plan as I explained before.\n> > Sabu has slightly greater risk comparing lightning\n> It is not true, since creditors can manage they risk, and limit their\n> credit to 5, 10 or 20 Dollar or 50$. It is totally up to creditor to\n> accept more liability from issuers or not.\n> The creditor can keep his credit around a fix number. That is, the\n> creditor spends a part of his credit and then again increase its credit.\n> Let imagine you already payed 5$ to a issuer and you got 15,000 Sat\n> credit in your wallet. So, you will spend this 15,000 Sat (buy coffee,\n> ice-cream, etc.) till your wallet run out of Satoshi and again you will\n> pay another 5$ to issuer and get new 15,000 sat credit. Since all of\n> these transactions has near zero cost you are not obliged to charge your\n> wallet 200$ in one shot.\n> It is absolutely low risk deal. In worst case the creditor (you) will\n> lose 5$. And as I explained before this kind of attacks will not\n> happened never. And as you told Sabu provides cheaper and a larger\n> number of transactions.\n> > This would be essentially worse than the lightning network in some ways,\n> Disagree! Please explain the scenario exactly. I didn\u2019t find any case\n> Lightning can compete with Sabu.\n> > ledger of accounts and their balances, along with proof that the entity\n> owns\u2026\n> It is almost what I designed in Sabu. They are doc-watcher servers. They\n> are a set of records of UTXOs and the proper Merkle root hash of related\n> transaction in Sabu network. The intention was stopping issuer from\n> spend and promises same UTXO to different people (that they are not\n> aware of the existence of the other). So, any individual creditor (or\n> their software) could verify that total liabilities (in account\n> balances) are less than the half of the total bitcoins the entity owns.\n> And if something doesn't match up, they won\u2019t yell, instead they refuse\n> the deal in first place, or send the GT to Bitcoin network and hurt the\n> cheater issuer by slashing his money. it is \u201cTit-for-tat\u201d.\n> > I think it likely has critical security holes. Perhaps you can fix them!\n> There is no critical security hole. Please refer it by facts, numbers\n> and proves.\n> I think I already fixed all critics.\n>\n> Billy! I am actively working on this proposal and if no one cannot show\n> a real problem or security issue in the project, I will start\n> implementing it.\n> Just imagine people regularly using Sabu protocol and send/receive\n> Bitcoin (Satoshi) in billions of small amount transactions every day.\n> This protocol will outspread Bitcoin and will attract a new crowd of\n> penny investors to Bitcoin. The people who can afford 20$ or less\n> monthly to invest on Bitcoin.\n> Sabu brings Bitcoin to a whole new life.\n> It will be the true scalable and mass adaption, and I do not know how to\n> attract more real Bitcoin fans to this proposal!\n> Guys! Here is the Bitcoin renascence.\n> Maybe you can help it.\n> Regards\n> Raymo\n\n\n\nOn Sat, Jul 3, 2021 at 1:02 AM <raymo at riseup.net> wrote:\n\n> Hi Billy,\n>\n> > What if it was possible for the creditor to claw back the funds\n> As far as I know the \u201cclaw back\u201d mechanism doesn\u2019t exist in Bitcoin\n> system, and probably most Bitcoiners won\u2019t be agree on it.\n> Even if we want to add claw back to Bitcoin in general, and Sabu in\n> particular, it would add too complexities and uncertainty to Bitcoin.\n> So, it would be better to not touch that part, instead focusing on\n> reduce the cheating risk by putting some penalty for both issuers,\n> creditors and miners.\n> We already have the penalties for both issuers and creditors.\n> It looks the miners still can abuse Sabu, but as I told before the miner\n> or better say the mining pool must be issuer (to be able to sign the\n> promised UTXO in cheating way) or must be creditor (in order to have a\n> copy of GT and not lose his money in favor of a stranger miner. Remember\n> the fact that creditor will lose 70% of their money in favor of Bitcoin\n> transaction fee in a typical GT) or collaborate one of them in a\n> conspiracy. Otherwise, there will be no economic benefit in this attack.\n>\n> All these 3 cases of the attacks, theoretically could be happened, but\n> the risk to reward ratio is enough high to hinder potential malevolent\n> from a practical act.\n> Even this very small risk of miner attacks (which don\u2019t care the attack\n> costs, since he is not interested in economic benefit, but he wants to\n> ruin Sabu), would be resolved by a slightly upgrade in Bitcoin protocol\n> by applying the BIPxxx \u201cfor flagging/unflagging promised UTXOs\u201d.\n> I am not in rush to apply this upgrade on Bitcoin protocol, instead I am\n> actively working in order to realize the Sabu protocol and Gazin wallet.\n> Later the Sabu community will carry the BIPxxx.\n>\n> Best\n>\n> On 2021-07-02 17:57, Billy Tetrud wrote:\n> > Thanks for the details Raymo. A thought occurred to me. Given the fact\n> > that miners can abuse this system without penalty, it would be useful\n> > to be able to fix this. What if it was possible for the creditor to\n> > claw back the funds even if the cheating transaction was mined instead\n> > of the guarantee transaction? Let's say there was a way to sign a\n> > transaction that gives the receiver of that transaction the ability to\n> > override any other transaction that uses the UTXO? If this were\n> > possible, the issuer could give the creditor this kind of transaction\n> > as the guarantee transaction, and in the case a cheat was done, the\n> > creditor could still use the GT to reallocate that UTXO to themselves.\n> >\n> > Now there are issues with this. First of all, it could give anyone the\n> > ability to double spend. So it would be prudent to limit this in some\n> > way. The revocation probably should only be valid for up to 6 blocks,\n> > such that if the transaction has 6 confirmations, it can no longer be\n> > reallocated (thus preserving the 6 block finality rule). It could also\n> > be required that the UTXO be marked as opting into this behavior (so\n> > receivers would know about the possibility it could get revoked). This\n> > second requirement would require Sabu issuers to make an on-chain\n> > transaction to set themselves up as an issuer.\n> >\n> > Another issue is that this would make it possible for transactions to\n> > expire. Any claw-back transaction would expire 6 blocks after the\n> > initial transaction happened. This has been generally avoided in\n> > bitcoin, but I think the relevant issues are solvable. You can find\n> > additional discussion of that in this thread [1].\n> >\n> > I would imagine this kind of ability would be pretty controversial,\n> > but since it can close out the possibility for miners to escape\n> > punishment, it could make this protocol viable.\n> >\n> > On Thu, Jul 1, 2021 at 3:15 PM <raymo at riseup.net> wrote:\n> >\n> >> Hi Erik\n> >>\n> >> Please correct me if I misunderstood.\n> >>\n> >>> email is fully compromised.\n> >>\n> >> What I got is:\n> >> Email is not good because the sender and receiver are compromised.\n> >> Email is not good because the message content is revealed.\n> >> I can claim same argue about any other client/server model. Since\n> >> the\n> >> server (website) service provider will ask some sort of KYC. And\n> >> even if\n> >> the server uses end-to-end encryption, the provider company still\n> >> can\n> >> read the packets content.\n> >> In my model the passive listener only can discover who is\n> >> communicate to\n> >> whom and make a graph of connections. Although it is a threat for\n> >> privacy but the server/client model has this flaw inherently, since\n> >> provider already knew everything about everyone. In my model at\n> >> least\n> >> users can make some fake connections and send some fake emails in\n> >> order\n> >> to inject noise to communications.\n> >> Please note the fact that entire communication between mobile\n> >> wallets\n> >> (via emails) are asymmetric PGP encrypted. The PGP keys are\n> >> controlled\n> >> by end users unlike ALL pretending secure messengers (e.g whatsApp,\n> >> signal, zoom,\u2026).\n> >> If you are worried about the way of exchanging PGP public key, you\n> >> are\n> >> right. The most secure way is in-person PGP key exchanging.\n> >> After that for payments the wallets communicate in pgp encrypted\n> >> messages and they can transfer Bitcoin address through an PGP\n> >> encrypted\n> >> cipher, thus no revealing Bitcoin address to public would occur.\n> >> Neither\n> >> the amounts of transactions will be reviled.\n> >> There for it would be a good practice for shops to put their email\n> >> and\n> >> PGP public key on shop website and/or PGP public key servers,\n> >> instead of\n> >> putting Bitcoin address on website or using 3rd parties services to\n> >> hide\n> >> their Bitcoin payment addresses.\n> >>\n> >> If I missed some points about \u201cfully compromised\u201d please write\n> >> it to me.\n> >>\n> >>> public keys / addresses are sent\n> >> As I told before ALL communication in Sabu are PGP encrypted.\n> >>\n> >>> other routing data encrypted with public keys\n> >>> (not sure how data is routed in sabu)\n> >>\n> >> Sabu is not responsible for routing at all. It simply sends emails.\n> >> Indeed the wallets peer-to-peer network in Sabu is pretty straight\n> >> forward. Each mobile wallet has one email address as its handler and\n> >> identifier in mobile-wallets-network. Each mobile can send message\n> >> to\n> >> another mobile by knowing its email address and the PGP public key.\n> >> This information can be prepared in first face-to-face contact of\n> >> mobile\n> >> owners, or later (something like signing the other\u2019s public key in\n> >> web\n> >> of trust) when a creditor wants to spend his money and transfer it\n> >> to\n> >> another creditor. The creditor1 send the signed money transfer\n> >> request\n> >> alongside the email and public key of creditor2 all in a PGP\n> >> encrypted\n> >> message to issuer.\n> >>\n> >>> separate the Sabu protocol from the app... allow others to\n> >> implement\n> >>> desktop version, or other versions that use other routing systems\n> >>\n> >> Indeed, it is my approach too. As I told before users will decide\n> >> between an unstoppable, permission less, self-sovereignty and\n> >> decentralized pure peer-to-peer communication network (with some\n> >> resolvable privacy issues) or some efficient, privacy-mimic central\n> >> limited network.\n> >>\n> >>> you can allow direct-entry of a BIP-word-representation\n> >>> of a public key/address to avoid privacy/central system concerns\n> >> Agree. Actually, I was thinking about an easy mechanism to share\n> >> your\n> >> public key like what you suggested here.\n> >> But what I consider for a \u201ccentral system concerns\u201d is the\n> >> ability of\n> >> communication without dependency to any company.\n> >> As an example, what can you do if the twitter bans your account?\n> >> Nothing! Your content and entire connections will be lost.\n> >> But if you form your friends list in your mobile (or computer) and\n> >> have\n> >> their PGP public keys and they have yours, and use email as a dual\n> >> purpose tool. First as a handler (the tool for finding and to be\n> >> found\n> >> in internet) and second as a communication tool.\n> >> Thus, no one can stop you, ban you or limit you to send/receive\n> >> transaction to/from anyone.\n> >> What I am trying to say is using email is far better than account\n> >> (username) in a limited central service like twitter, Facebook,\n> >> telegram... or even in future Sabu servers!\n> >> You have your connections under your control in your phone. You can\n> >> easily change your email and use a new email or even a new service\n> >> provider without losing your connections and your control over it.\n> >> You just sign your new email address and send it to your friends\n> >> circle\n> >> and notify them about changes.\n> >> Of course, email is not good for millions of followers but it is\n> >> obviously good for managing your payment network of hundreds of\n> >> people\n> >> (either issuers or creditors).\n> >>\n> >> Best\n> >> Raymo\n> >>\n> >> On 2021-07-01 20:49, Erik Aronesty wrote:\n> >>> your protocol should always assume the email system is fully\n> >>> compromised, and only send public information over email:\n> >>>\n> >>> - public keys / addresses are sent\n> >>> - other routing data encrypted with public keys (not sure how data\n> >> is\n> >>> routed in sabu)\n> >>>\n> >>> your end user should be able to verify public keys  / addresses\n> >>>\n> >>> - use QR-codes\n> >>> - phone calls with users reading BIP words out loud\n> >>> - other in-person information exchange\n> >>>\n> >>> separate the Sabu protocol from the app... allow others to\n> >> implement\n> >>> desktop version, or other versions that use other routing systems\n> >>>\n> >>> -  you can allow direct-entry of a BIP-word-representation of a\n> >> public\n> >>> key/address to avoid privacy/central system concerns\n> >>>\n> >>> On Thu, Jul 1, 2021 at 4:20 PM raymo via bitcoin-dev\n> >>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>>>\n> >>>> Hi Billy,\n> >>>> Sorry for late reply. Let\u2019s jump in proposal.\n> >>>>\n> >>>>> Some more information about the benefits of this approach vs\n> >> alternatives (mainly lightning)\n> >>>> The most important different is unlike the lightning, in Sabu no\n> >> one\n> >>>> have to open a channel and pay Bitcoin transaction fee,\n> >> subsequently no\n> >>>> one has to close channel and pay another Bitcoin transaction fee.\n> >> It is\n> >>>> the huge improvement since it drops the overhead cost of\n> >> transactions.\n> >>>> So, it will be more convenience to trade under Sabu protocol.\n> >>>> In Sabu none of parties of a transaction are obliged to block\n> >> money in\n> >>>> any kind of smart contract or any other m of n signature accounts\n> >>>> on-chain, so it provides more privacy.\n> >>>> Since Sabu protocol is designed to motivate people to circulate\n> >>>> transactions (AKA debt documents) in Sabu network, if every actor\n> >> act\n> >>>> rationally no one will aware how much money transferred from who\n> >> to\n> >>>> whom.\n> >>>> In case of fraudulent activity by issuer, the creditor will send\n> >>>> Guarantee Transaction (GT) to Bitcoin network in order to\n> >> recapture the\n> >>>> part of his credit. So, in this case the transaction is literally\n> >>>> recorded on bitcoin blockchain.\n> >>>> There is only one another reason to recording transaction on\n> >> Bitcoin\n> >>>> blockchain. Where one creditor eager to pay Bitcoin transaction\n> >> fee in\n> >>>> order to aggregate thousands or even millions different small\n> >> amount\n> >>>> debt-documents in a single transaction on Bitcoin blockchain.\n> >>>> despite these two cases, the rest of transactions all occur in\n> >> the Sabu\n> >>>> network (supposed to be over 99%). Thus, no footprint no\n> >> bottleneck and\n> >>>> no over process.\n> >>>>\n> >>>> Another important power point of Sabu is its pure-peer-to-peer\n> >> network\n> >>>> architecture. In Sabu the mobile wallets communicating to each\n> >> other\n> >>>> directly without any central server. There is no centralization\n> >> at all.\n> >>>> As a result, there will be no routing as well.\n> >>>> Since only issuer and creditors are aware of the content of\n> >> transaction\n> >>>> (who pay how much to whom) it is a huge privacy improvement,\n> >> which\n> >>>> doesn\u2019t exist in other layer 2 solutions.\n> >>>>\n> >>>> About the usability of Sabu, although the protocol based on the\n> >>>> collaborating 2 different peer-to-peer network and 3 classic\n> >>>> server/client networks, but the end user (mobile wallet user)\n> >> doesn\u2019t\n> >>>> see any of these complexities.\n> >>>> The end user simply installs the mobile/desktop wallet and add\n> >> her/his\n> >>>> friends to his phonebook by adding their email address or\n> >> scanning their\n> >>>> email (and/or PGP public key). After that s/he can immediately\n> >> start to\n> >>>> send/receive Bitcoin through Sabu network. Entire communications\n> >> between\n> >>>> wallets are PGP encrypted.\n> >>>> Another good point in Sabu design is, the 12 seed words are using\n> >> for\n> >>>> both Bitcoin wallet private key and the PGP private key. So, it\n> >> is the\n> >>>> key of user wealth and its identity as well. For more details,\n> >> please\n> >>>> read my previous answer to Alex Schoof.\n> >>>> The issuer, by using his UTXOs and selling them to creditors earn\n> >> money.\n> >>>> the issuer creates the debt document (transaction) by which\n> >> promises to\n> >>>> creditor an amount of satoshi. These debt documents are valid\n> >> Bitcoin\n> >>>> transaction. The only difference is these transactions are\n> >> intended to\n> >>>> circulate in Sabu protocol instead of sending to Bitcoin\n> >> blockchain.\n> >>>> Each transaction is a small money transfer. 40,000 Satoshi as\n> >> input and\n> >>>> maximum 20,000 Satoshi as credit and minimum 10,000 Satoshi as\n> >> Bitcoin\n> >>>> transaction fee.\n> >>>> The creditors will use these received transactions as money and\n> >> will pay\n> >>>> it in exchange of goods or services. For each transaction the\n> >> creditor\n> >>>> pays 10 Satoshi as Sabu-transaction-fee to issuer.\n> >>>> Sabu is not custodial service and the UXTOs are always under\n> >> issuer\n> >>>> control, unless issuer or creditor send the signed transaction to\n> >>>> Bitcoin network. When the transaction was recorded in Bitcoin\n> >>>> blockchain, the creditor can spend proper UTXO in Bitcoin\n> >> network.\n> >>>> Imagine million people use their UTXOs in Sabu, they are issuer\n> >> and\n> >>>> issue/update/cancel million transactions per second. All they\n> >> need is a\n> >>>> mobile wallet. On the other hand, every one by knowing an issuer\n> >> can buy\n> >>>> some Satoshi (whit absolutely no KYC), even 1 Dollar or less, and\n> >> spend\n> >>>> it, this time Alice really can buy caffe by Bitcoin ;)\n> >>>> The Bar can install the mobile wallet and every day receives\n> >> thousands\n> >>>> of debt documents (transactions), each worth maximum 20,000\n> >> Satoshi in\n> >>>> exchange of coffee. And every evening aggregates those small\n> >>>> transactions to one single transaction and send it to Bitcoin\n> >> network.\n> >>>>\n> >>>>\n> >>>> The security model of Sabu is pretty straight forward.\n> >>>> Issuer is the owner of UTXO(s) which will be used in\n> >> transactions. The\n> >>>> issuer is and will the only person who creates transactions and\n> >> sign\n> >>>> them. The transactions are valid transaction which either issuer\n> >> or\n> >>>> creditor can send them to Bitcoin network, but they will never\n> >> send\n> >>>> these transactions to Bitcoin network, because of the high\n> >> Bitcoin\n> >>>> transaction fee for each single transaction.\n> >>>> Since issuer is the only one who can sign transaction (spend\n> >> UTXOs),\n> >>>> there is a risk of issuer cheating. And no one can stop issuer\n> >> from\n> >>>> cheating, because these are his UTXOs and he has the proper\n> >> private\n> >>>> keys.\n> >>>> The Sabu solution is Guarantee transaction. It is a valid\n> >> transaction\n> >>>> that issuer has to sign it alongside the Main transaction. In GT\n> >> both\n> >>>> issuer and creditor cut a part of their output in favor of\n> >> Bitcoin\n> >>>> transaction fee.\n> >>>> We suppose miners always seeking for more profit, thus in a case\n> >> there\n> >>>> are 2 or more transaction are spending same UTXO as input, miner\n> >> will\n> >>>> choose transaction with highest feeRate. There is no economically\n> >>>> benefit for issuer to cheat creditors and pay less transaction\n> >> fee\n> >>>> simultaneously. So rationally the issuer won\u2019t cheat creditor.\n> >>>> It was the simplest explanation of Sabu security model.\n> >>>>\n> >>>>> I agree with others that using email is probably not\n> >> appropriate for a protocol like this. I would highly recommend\n> >> making your protocol transport-agnostic, allowing users of your\n> >> protocol to use any transport they want.\n> >>>> Indeed, the protocol is transparent-agnostic, if I insist of\n> >> email as a\n> >>>> user identifier and communicating tool is because of the idea of\n> >>>> reforming part of internet architecture and make it more\n> >> decentralized.\n> >>>> The wallet users can choose classic architecture. In this case\n> >> mobile\n> >>>> wallets will connect to a central server and communicate through\n> >> that\n> >>>> server (pretty much like all existed mobile wallets). While some\n> >> users\n> >>>> decide to use a pure peer-to-peer communication. I knew email has\n> >> some\n> >>>> privacy issues but as always it is a tradeoff. Users can decide\n> >> between\n> >>>> an unstoppable, permission less, self-sovereignty and\n> >> decentralized pure\n> >>>> peer-to-peer communication network (with some resolvable privacy\n> >> issues)\n> >>>> or some efficient central limited network.\n> >>>> Let me know the critics about email. Hopefully this would lead us\n> >> to\n> >>>> improve email instead of letting it die. I strongly suggest email\n> >>>> because it is the ONLY neutral, free \u201cnonproprietary\u201d and\n> >> open\n> >>>> protocol/technology for communication in the world that its\n> >>>> infrastructure is well-established and is accessible all over the\n> >> glob.\n> >>>>\n> >>>> I tried to explain it more, hope was useful. By the way the\n> >> complete\n> >>>> explanation is here\n> >>>>\n> >>\n> >\n> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n> >>>>\n> >>>>\n> >>>>\n> >>>> Regards\n> >>>> Raymo\n> >>>>\n> >>>>\n> >>>>\n> >>>> On 2021-06-22 18:20, Billy Tetrud wrote:\n> >>>>> I would be interested in seeing some more information about the\n> >>>>> benefits of this approach vs alternatives up front in this\n> >> write up.\n> >>>>> Eg how does the security, cost, usability, and privacy compare\n> >> to the\n> >>>>> lightning network, which would be the most likely competitor to\n> >> this\n> >>>>> idea. It seems clear that there is more counterparty risk here,\n> >> so it\n> >>>>> would probably also be very helpful to compare against\n> >> traditional\n> >>>>> custodial solutions as well. If you have specific claims on how\n> >> this\n> >>>>> system is better than eg lightning in certain contexts, it\n> >> would be\n> >>>>> far easier to evaluate the protocol against those claims, and\n> >> would\n> >>>>> also be a lot easier for readers to be motivated to read the\n> >> whole\n> >>>>> protocol and do a more full analysis.\n> >>>>>\n> >>>>> I agree with others that using email is probably not\n> >> appropriate for a\n> >>>>> protocol like this. I would highly recommend making your\n> >> protocol\n> >>>>> transport-agnostic, allowing users of your protocol to use any\n> >>>>> transport they want.\n> >>>>>\n> >>>>> On Sat, Jun 19, 2021 at 7:00 PM James Hilliard via bitcoin-dev\n> >>>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>>>>\n> >>>>>> I think you're making a number of assumptions about mining\n> >> that are\n> >>>>>> not accurate.\n> >>>>>>\n> >>>>>>> First of all, how much chance in finding next block the\n> >> corrupted\n> >>>>>> miners have? One percent of all Bitcoin hash powers? Or\n> >> maximum 5\n> >>>>>> percent or 10? The cheaters must come up in dividing that 1.2\n> >>>>>> Bitcoin between. After all the risk/reward must fit them. They\n> >> can\n> >>>>>> not be a big mining pool since there is no benefit, so they\n> >> will be\n> >>>>>> small miners with low hash rate. If they solve the puzzle and\n> >>>>>> broadcast the block, no one in the entire Bitcoin network has\n> >> block\n> >>>>>> transactions or seen it before in their mempool!\n> >>>>>>\n> >>>>>> You're making the assumption that miners won't build on top of\n> >> a\n> >>>>>> block\n> >>>>>> with transactions they have not seen before or transactions\n> >> that may\n> >>>>>> contain double spends of unconfirmed inputs, this is not how\n> >> mining\n> >>>>>> works, as long as the block passes the consensus rules\n> >> effectively\n> >>>>>> all\n> >>>>>> miners will mine on top of it by default, this behavior is\n> >>>>>> fundamental\n> >>>>>> to how mining currently works and is fairly deeply baked into\n> >> the\n> >>>>>> current mining infrastructure.\n> >>>>>>\n> >>>>>>> Will they accept this block? In theory it is possible and\n> >> have\n> >>>>>> 0.01 percent chance but we can eliminate this small\n> >> possibilities by\n> >>>>>> a simple BIP for miners.\n> >>>>>>\n> >>>>>> What would this BIP look like? I don't see how this could work\n> >> in a\n> >>>>>> decentralized way as you would need another way of reaching\n> >>>>>> consensus\n> >>>>>> on what defines a valid block. Right now the chance is nearly\n> >> 100\n> >>>>>> percent that a miner will mine on top of the latest valid\n> >> block,\n> >>>>>> many\n> >>>>>> pools(most last I checked) will even mine on the next block\n> >> before\n> >>>>>> they validate the latest block fully(ie validationless mining)\n> >> to\n> >>>>>> reduce their orphan rates.\n> >>>>>>\n> >>>>>>> We suppose the miners always control transactions with\n> >>>>>> doc-watchers and avoid accepting transaction with same UTXO\n> >> but\n> >>>>>> different output.\n> >>>>>>\n> >>>>>> Miners have different mempool policy/rules for what\n> >> transactions\n> >>>>>> they\n> >>>>>> themselves mine but all miners must mine on the most work\n> >> chain of\n> >>>>>> valid blocks otherwise they risk their own blocks being\n> >> orphaned,\n> >>>>>> any\n> >>>>>> miner that does not do this is effectively guaranteed to have\n> >> their\n> >>>>>> block orphaned right now.\n> >>>>>>\n> >>>>>>> Because of high Bitcoin transaction fee, this guarantee\n> >>>>>> transaction will take place in next block, even if other\n> >> transaction\n> >>>>>> which are using the same UTXO as input existed in mempool.\n> >>>>>>\n> >>>>>> When a new transaction is broadcast miners do not immediately\n> >> start\n> >>>>>> mining on a block template that includes that transaction, the\n> >>>>>> template won't even be generated immediately when it enters a\n> >> miners\n> >>>>>> mempool in practice, for bandwidth/network efficiency reasons\n> >> mining\n> >>>>>> pools batch update the stratum templates/jobs they mine\n> >> against so\n> >>>>>> there can be significant latency between the time a\n> >> transaction is\n> >>>>>> actually broadcast and hits the miners mempool and the time\n> >> the\n> >>>>>> miners\n> >>>>>> actually switch to mining on top it, these batched updates are\n> >>>>>> essentially like point in time snapshots of the mempool and\n> >>>>>> typically\n> >>>>>> remain valid(as in the pool will accept shares submitted\n> >> against\n> >>>>>> that\n> >>>>>> job as valid) until the bitcoin network finds the next block.\n> >> I\n> >>>>>> don't\n> >>>>>> think these batch updates are done more often than every 30\n> >> seconds\n> >>>>>> typically, while often it is on the order of multiple minutes\n> >>>>>> depending on the pool.\n> >>>>>>\n> >>>>>> Regards,\n> >>>>>> James\n> >>>>>>\n> >>>>>> On Thu, Jun 17, 2021 at 2:14 PM raymo via bitcoin-dev\n> >>>>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>>>>>>\n> >>>>>>> Hi,\n> >>>>>>> I have a proposal for improve Bitcoin TPS and privacy, here\n> >> is the\n> >>>>>> post.\n> >>>>>>>\n> >>>>>>\n> >>>>>\n> >>\n> >\n> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n> >>>>>>> https://bitcointalk.org/index.php?topic=5344020.0\n> >>>>>>> Can you please read it and share your idea about it.\n> >>>>>>>\n> >>>>>>> Cheers\n> >>>>>>> Raymo\n> >>>>>>> _______________________________________________\n> >>>>>>> bitcoin-dev mailing list\n> >>>>>>> bitcoin-dev at lists.linuxfoundation.org\n> >>>>>>>\n> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >>>>>> _______________________________________________\n> >>>>>> bitcoin-dev mailing list\n> >>>>>> bitcoin-dev at lists.linuxfoundation.org\n> >>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >>>> _______________________________________________\n> >>>> bitcoin-dev mailing list\n> >>>> bitcoin-dev at lists.linuxfoundation.org\n> >>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n> >\n> > Links:\n> > ------\n> > [1]\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-June/019050.html\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210706/d1701ad9/attachment-0001.html>"
            },
            {
                "author": "raymo at riseup.net",
                "date": "2021-07-17T15:50:30",
                "message_text_only": "After introducing Sabu protocol as a solution for Bitcoin scaling\n(https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180),\nI shared this idea with Bitcoin developers through the bitcoin-dev\nmailing list.\nI got some constructive feedbacks and critiques leading me to add this\npart to the proposal which I was skipped due to brevity of proposal\nintroduction.\n\nHere I will investigate on more real live scenarios, general usages and\ncorner cases, and the consequences of some attacks or buggy\nimplementation of protocol, as well as different actors (malicious,\nirrational, profit seeker, griefer, stupid, reckless, incompetent, etc.)\nactivity effects.\n\nIn proposal introduction (previous post), I did not talk about Lightning\ndeliberately, although it seems that this solution is an alternative to\nLightning.\nMost of readers misunderstood Sabu and asking what differs it from\nLightning?\nIndeed, Sabu has nothing with Lightning. It has totally different\ndesign, network architecture, security model and implementation. The\nonly thing in common with Lightning is both are intended to cover micro\npayments.\nThe good thing about Bitcoin is that it does not require any kind of\npermission. Consequently, related products do not need to ask permission\ntoo. We are in a permission-less free market. I think Sabu will work\nperfectly and if a group of users think like me, we are done. Sabu will\nwork parallel the other scaling solutions without need to drive them\nout.\nHowever, I have made a comparison between Sabu, on-chain and Lightning\ntransactions to get a clearer understanding of the advantages and\ndisadvantages of Sabu and answer to \u201cwhy we should implement and use\nSabu in our day-to-day deals\u201d.\nMost probably this paper is not comprehensive document, therefore this\narticle will be updated.\n\nYou will find the complete post here:\nhttps://raymo-49157.medium.com/scaling-bitcoin-by-sabu-protocol-risks-and-benefits-62157f8a664e\n\nRaymo\n\nOn 2021-07-07 03:20, Billy Tetrud wrote:\n>>  As far as I know the \u201cclaw back\u201d mechanism doesn\u2019t exist in\n> Bitcoin\n> system, and probably most Bitcoiners won\u2019t be agree on it.\n> \n> It certainly doesn't. And it would definitely be a hard sell.\n> \n>> It looks the miners still can abuse Sabu, but as I told before the\n> mineror better say the mining pool must be issuer .. or must be\n> creditor .. or collaborate one of them in a\n> conspiracy.\n> \n> Yes. But it certainly incentivizes miners to become creditors and scam\n> people. Even if a small miner who mines one block a year does this,\n> they can mine all Guarantee Transactions in their possession. Larger\n> miners that mine one block every few days can scam that much more\n> often. Even with $5 credits, that could be an extra $9000 gained in a\n> block. That's pretty substantial when fees are totaling around $45,000\n> per block.\n> \n>> would be resolved by a slightly upgrade in Bitcoin protocol by\n> applying the BIPxxx \u201cfor flagging/unflagging promised UTXOs\u201d\n> \n> As others have mentioned tho, doing something like that would be at\n> very least quite complex, and at worst impossible to do securely. The\n> whole reason why bitcoin's blockchain exists in the first place is to\n> be a single source of truth for transactions. The mempool is not a\n> source of truth for consensus. The Sabu network could not be a source\n> of truth either for consensus, without some serious innovations (that\n> may not be possible). It isn't as simple as you seem to be thinking.\n> \n>>  The new transaction will use same 40,000 UTXO as input and the\n> outputs will be 6,500 Sat for creditor (he pays 2,500 Sat for\n> transaction fee) 4,500 Sat for creditor 2\n> \n> This is the part I was unable to find/understand quickly enough in the\n> original write up. So for creditor 1 to pay creditor 2, a new main\n> transaction and guarantee transaction are created that credit the\n> appropriate people, right? FYI, the MT and GT acronyms make it harder\n> for me to read/understand, so I'm preferring to write them out. But\n> that helps. Let me write this out in a different (more compact) way:\n> \n> 1. Creditor A $5 -> Issuer\n> \n> 2. Issuer creates and shares transactions:\n> \n> Main Transaction (40k sats):\n> * Issuer: 19k sats\n> * Creditor A: 11k sats\n> * Fee: 10k sats (4k from creditor, 6k from issuer)\n> \n> Guarantee Transaction (40k sats):\n> * Issuer: 13,300 sats\n> * Creditor A: 1650 sats\n> * Fee: 25,050 sats\n> \n> 3. Creditor A, 6k sats -> Creditor B. Issuer creates and shares\n> transactions:\n> \n> Main Transaction (40k sats):\n> * Issuer: 19k sats* Creditor A:  6,500 sats\n> * Creditor B:  4,500 sats\n> \n> * Fee: 10k sats (4k from creditor, 6k from issuer)\n> \n> Guarantee Transaction (40k sats):\n> * Issuer: 13300 sats* Creditor A: 975 sats\n> * Creditor B: 675 sats\n> * Fee: 25050 sats\n> \n> Is this right?\n> \n>> The miner attack is just a failed plan as I explained before\n> \n> I thought you acknowledged that the miner attack is an issue above.\n> No?\n> \n>>> Sabu has slightly greater risk comparing lightning\n>> It is not true,\n> \n> What I mean is that a violation of trust results in more damaging\n> effects with Sabu than with lightning. In lightning, if your channel\n> partner cheats, at worst you must simply pay a normal transaction fee.\n> With Sabu, if a creditor cheats, you will likely pay an abnormally\n> large transaction fee. This is what I mean by \"greater risk\". Some\n> attackers are what's known as griefers - these are people willing to\n> spend time and money hurting someone else, even if they don't make a\n> profit from it (other than schadenfreude). It seems clear there is a\n> greater risk of being griefed in Sabu than in lightning.\n> \n> Furthermore, while in lightning, if you perform the protocol properly,\n> your funds can never be stolen except in very extreme circumstances\n> (eg widespread long-running network congestion that prevents\n> confirming a revoke transaction). By contrast, Sabu has a significant\n> likelihood that a cheating transaction could be mined instead of the\n> guarantee transaction. Perhaps the likelihood is approximately 2\n> seconds / 10 minutes (0.3% chance), but a 0.3% is clearly larger than\n> approximately 0% chance in lightning. Again, this is another part of\n> what I mean by \"higher risk\".\n> \n> These are both real counterparty risks that you shouldn't simply\n> ignore. It may be true that no rational actor will attempt an attack,\n> however not all actors are rational. People also make mistakes, write\n> buggy software, etc etc. The existence of risk doesn't ruin your idea\n> - every protocol has risks. But identifying the specific risks is the\n> only way to compare the properties against alternatives (like on chain\n> transactions or the lightning network). I think its important to\n> acknowledge these risks in your write up.\n> \n>> I explained before this kind of attacks will not happened never\n> \n> If people use your protocol, some will inevitably use it wrong. Those\n> that use it wrong should be the ones that pay the price for it - but\n> it is a downside of the protocol if the counter party of the person\n> that makes a mistake (or attempts something malicious) is harmed as a\n> result. Again, these kinds of trade offs are ok, but you should not be\n> assuming that attacks like this will never happen. They will happen\n> sometimes. You must assume that. The question is what is the result\n> when an attack is attempted? And how will that affect what kinds of\n> actors will attempt an attack (malicious, profit seeking, honest,\n> stupid, wreckless, incompetent, other types of actors etc etc)?\n> \n>> I didn\u2019t find any case Lightning can compete with Sabu.\n> \n> As I explained above related to risk, there are trade offs. I would\n> like to see in your write up a clear list of these trade offs. The\n> additional risk (as I explained it above) is one trade off. It sounds\n> like there are limits in which a creditor or issuer can safely rely on\n> incentives to prevent attacks. Did you specify what those limits are?\n> The Lightning network also has limits - eg a lightning node can't\n> allow its channel partner to spend 100% of their coins without taking\n> on additional risk of attack. How do those limits compare in Sabu? For\n> example, an issuer couldn't allow any creditor to spend so much of\n> their credited bitcoin that their credit goes below the amount they\n> would receive in any past Guarantee Transaction without taking on the\n> risk that the creditor would post that guarantee transaction and\n> receive coins they shouldn't own anymore. I would love to see a more\n> detailed comparison of Sabu to lightning.\n> \n> If your protocol works out, there are obvious benefits: transactions\n> that could be done with no on-chain footprint. However, even if the\n> protocol works out, there are trade offs and those trade offs should\n> be made very clear. Even if the comparative downsides are small.\n> \n> ~BT\n> \n>> Hi Billy\n>>> high-level overview of how all the pieces (How Sabu protocol\n>> works).\n>>> how normal transactions happen in their entirety.\n>> Ok, lets re-explain Sabu. In Sabu protocol we have two type of\n>> actors.\n>> The issuers who own Bitcoin (they own UTXOs on Bitcoin blockchain),\n>> and\n>> the creditors who will own Bitcoins (the UTXOs on Bitcoin\n>> blockchain),\n>> if the issuer or the creditor sends the prepared transaction to\n>> Bitcoin\n>> network. But for know creditors have the transaction in their hand.\n>> Before sending this transaction to Bitcoin network it acts (in Sabu\n>> protocol and Sabu network) as a liability of issuer.\n>> The story always starts from issuer, the person who get money or\n>> goods\n>> or services from a creditor and in exchange creates and sings a\n>> valid\n>> Bitcoin transaction by which the issuer spends his UTXO and as a one\n>> of\n>> the outputs of the transaction, there will be an output for\n>> creditor\u2019s\n>> address equal to the money issuer already get paid.\n>> This transaction is a valid transaction which is signed \u201conly\u201d\n>> by\n>> issuer. The outputs of transaction are just and exact balance of the\n>> parties (issuer and creditor).\n>> Lets, imagine the creditor payed 5$ (almost equal to 15,000 Sat) to\n>> issuer. Thus, issuer will create and sign a transaction by which he\n>> spends 40,000 Sat and the outputs will be\n>> 11,000 for creditor (the creditor has to pay 4,000 Sat in favor of\n>> transaction fee),\n>> 10,000 for Bitcoin-transaction-fee (4,000 by creditor and 6,000 by\n>> issuer) and\n>> 19,000 change back to issuer account address.\n>> It is our Main Transaction (MT) which is a pretty normal and valid\n>> transaction.\n>> Alongside the MT, issuer creates and signs a Guarantee Transaction\n>> (GT).\n>> In GT issuer spends same 40,000 Sat UTXO as input, and as outputs\n>> the creditor will get 15% of his 11,000 Sat in Main Transaction.\n>> Thus\n>> the creditor output will be 1,650 Sat and the rest of creditor\u2019s\n>> money\n>> (11,000 \u2013 1,650 = 9,350 Sat) will be added to transaction fee.\n>> In GT also issuer will lose a part of his money. New output for\n>> issuer\n>> will be 19,000 * 70% = 13,300 and the rest will be added to\n>> transaction\n>> fee (19,000 \u2013 13,300 = 5,700 Sat)\n>> Thus, the new transaction fee in GT will be 10,000 + 9,350 + 5,700 =\n>> 25,050 Sat\n>> Now the creditor has 2 valid transactions (MT and GT) in his hands.\n>> He\n>> can send either MT or GT or both to Bitcoin Network. But in all\n>> cases,\n>> he will lose a portion of his money in favor of transaction fee\n>> (miner\u2019s\n>> income). So, rationally he will never send transactions to Bitcoin\n>> network unless he wants consciously hurt himself.\n>> The creditor always prefers to spend his credit inside the Sabu\n>> protocol. It is \u201chow normal transactions happen in their\n>> entirety.\u201d\n>> Creditor has equal to 15,000 Sat credit. Say he wants to buy a caffe\n>> worth 6,000 Sat. He has to ask the issuer to nullify previous MT and\n>> GT,\n>> and create and sign new transaction and cut 6,000 Sat from his\n>> credit\n>> and transfer it to a new creditor (say C2).\n>> The new transaction will use same 40,000 UTXO as input and the\n>> outputs\n>> will be\n>> 6,500 Sat for creditor (he pays 2,500 Sat for transaction fee)\n>> 4,500 Sat for creditor 2 (he has to pay 1,500 Sat for transaction\n>> fee as\n>> well)\n>> 10,000 for Bitcoin-transaction-fee (4,000 by two creditors and 6,000\n>> by\n>> issuer) and\n>> 19,000 change back to issuer account address.\n>> This is the new MT, and as you can see the C1 and C2 have their new\n>> credit in transaction.\n>> You can calculate the new GT as well.\n>> Note: due to simplicity I just rounded the numbers and skipped the\n>> Sabu-transaction-fee\n>> I just wrote this long story to explain how creditors just transfer\n>> money in between.\n>> If we take a snapshot of Sabu network, we will see millions of valid\n>> transactions flowing in network and none of the issuers or creditors\n>> will send these transactions to Bitcoin network due the transaction\n>> fee,\n>> while in Bitcoin blockchain nothing is changed! The UTXOs are\n>> untouched,\n>> and no one can say which UTXO is promised to who.\n>> It is a pretty secure off-chain protocol.\n>> Although I expected more Bitcoiners to react about Sabu proposal and\n>> comment for or against it, so far, I have not seen any serious\n>> criticism\n>> or real threat about protocol.\n>> The miner attack is just a failed plan as I explained before.\n>>> Sabu has slightly greater risk comparing lightning\n>> It is not true, since creditors can manage they risk, and limit\n>> their\n>> credit to 5, 10 or 20 Dollar or 50$. It is totally up to creditor to\n>> accept more liability from issuers or not.\n>> The creditor can keep his credit around a fix number. That is, the\n>> creditor spends a part of his credit and then again increase its\n>> credit.\n>> Let imagine you already payed 5$ to a issuer and you got 15,000 Sat\n>> credit in your wallet. So, you will spend this 15,000 Sat (buy\n>> coffee,\n>> ice-cream, etc.) till your wallet run out of Satoshi and again you\n>> will\n>> pay another 5$ to issuer and get new 15,000 sat credit. Since all of\n>> these transactions has near zero cost you are not obliged to charge\n>> your\n>> wallet 200$ in one shot.\n>> It is absolutely low risk deal. In worst case the creditor (you)\n>> will\n>> lose 5$. And as I explained before this kind of attacks will not\n>> happened never. And as you told Sabu provides cheaper and a larger\n>> number of transactions.\n>>> This would be essentially worse than the lightning network in some\n>> ways,\n>> Disagree! Please explain the scenario exactly. I didn\u2019t find any\n>> case\n>> Lightning can compete with Sabu.\n>>> ledger of accounts and their balances, along with proof that the\n>> entity owns\u2026\n>> It is almost what I designed in Sabu. They are doc-watcher servers.\n>> They\n>> are a set of records of UTXOs and the proper Merkle root hash of\n>> related\n>> transaction in Sabu network. The intention was stopping issuer from\n>> spend and promises same UTXO to different people (that they are not\n>> aware of the existence of the other). So, any individual creditor\n>> (or\n>> their software) could verify that total liabilities (in account\n>> balances) are less than the half of the total bitcoins the entity\n>> owns.\n>> And if something doesn't match up, they won\u2019t yell, instead they\n>> refuse\n>> the deal in first place, or send the GT to Bitcoin network and hurt\n>> the\n>> cheater issuer by slashing his money. it is \u201cTit-for-tat\u201d.\n>>> I think it likely has critical security holes. Perhaps you can fix\n>> them!\n>> There is no critical security hole. Please refer it by facts,\n>> numbers\n>> and proves.\n>> I think I already fixed all critics.\n>> \n>> Billy! I am actively working on this proposal and if no one cannot\n>> show\n>> a real problem or security issue in the project, I will start\n>> implementing it.\n>> Just imagine people regularly using Sabu protocol and send/receive\n>> Bitcoin (Satoshi) in billions of small amount transactions every\n>> day.\n>> This protocol will outspread Bitcoin and will attract a new crowd of\n>> penny investors to Bitcoin. The people who can afford 20$ or less\n>> monthly to invest on Bitcoin.\n>> Sabu brings Bitcoin to a whole new life.\n>> It will be the true scalable and mass adaption, and I do not know\n>> how to\n>> attract more real Bitcoin fans to this proposal!\n>> Guys! Here is the Bitcoin renascence.\n>> Maybe you can help it.\n>> Regards\n>> Raymo\n> \n> On Sat, Jul 3, 2021 at 1:02 AM <raymo at riseup.net> wrote:\n> \n>> Hi Billy,\n>> \n>>> What if it was possible for the creditor to claw back the funds\n>> As far as I know the \u201cclaw back\u201d mechanism doesn\u2019t exist in\n>> Bitcoin\n>> system, and probably most Bitcoiners won\u2019t be agree on it.\n>> Even if we want to add claw back to Bitcoin in general, and Sabu in\n>> particular, it would add too complexities and uncertainty to\n>> Bitcoin.\n>> So, it would be better to not touch that part, instead focusing on\n>> reduce the cheating risk by putting some penalty for both issuers,\n>> creditors and miners.\n>> We already have the penalties for both issuers and creditors.\n>> It looks the miners still can abuse Sabu, but as I told before the\n>> miner\n>> or better say the mining pool must be issuer (to be able to sign the\n>> promised UTXO in cheating way) or must be creditor (in order to have\n>> a\n>> copy of GT and not lose his money in favor of a stranger miner.\n>> Remember\n>> the fact that creditor will lose 70% of their money in favor of\n>> Bitcoin\n>> transaction fee in a typical GT) or collaborate one of them in a\n>> conspiracy. Otherwise, there will be no economic benefit in this\n>> attack.\n>> \n>> All these 3 cases of the attacks, theoretically could be happened,\n>> but\n>> the risk to reward ratio is enough high to hinder potential\n>> malevolent\n>> from a practical act.\n>> Even this very small risk of miner attacks (which don\u2019t care the\n>> attack\n>> costs, since he is not interested in economic benefit, but he wants\n>> to\n>> ruin Sabu), would be resolved by a slightly upgrade in Bitcoin\n>> protocol\n>> by applying the BIPxxx \u201cfor flagging/unflagging promised UTXOs\u201d.\n>> \n>> I am not in rush to apply this upgrade on Bitcoin protocol, instead\n>> I am\n>> actively working in order to realize the Sabu protocol and Gazin\n>> wallet.\n>> Later the Sabu community will carry the BIPxxx.\n>> \n>> Best\n>> \n>> On 2021-07-02 17:57, Billy Tetrud wrote:\n>>> Thanks for the details Raymo. A thought occurred to me. Given the\n>> fact\n>>> that miners can abuse this system without penalty, it would be\n>> useful\n>>> to be able to fix this. What if it was possible for the creditor\n>> to\n>>> claw back the funds even if the cheating transaction was mined\n>> instead\n>>> of the guarantee transaction? Let's say there was a way to sign a\n>>> transaction that gives the receiver of that transaction the\n>> ability to\n>>> override any other transaction that uses the UTXO? If this were\n>>> possible, the issuer could give the creditor this kind of\n>> transaction\n>>> as the guarantee transaction, and in the case a cheat was done,\n>> the\n>>> creditor could still use the GT to reallocate that UTXO to\n>> themselves.\n>>> \n>>> Now there are issues with this. First of all, it could give anyone\n>> the\n>>> ability to double spend. So it would be prudent to limit this in\n>> some\n>>> way. The revocation probably should only be valid for up to 6\n>> blocks,\n>>> such that if the transaction has 6 confirmations, it can no longer\n>> be\n>>> reallocated (thus preserving the 6 block finality rule). It could\n>> also\n>>> be required that the UTXO be marked as opting into this behavior\n>> (so\n>>> receivers would know about the possibility it could get revoked).\n>> This\n>>> second requirement would require Sabu issuers to make an on-chain\n>>> transaction to set themselves up as an issuer.\n>>> \n>>> Another issue is that this would make it possible for transactions\n>> to\n>>> expire. Any claw-back transaction would expire 6 blocks after the\n>>> initial transaction happened. This has been generally avoided in\n>>> bitcoin, but I think the relevant issues are solvable. You can\n>> find\n>>> additional discussion of that in this thread [1].\n>>> \n>>> I would imagine this kind of ability would be pretty\n>> controversial,\n>>> but since it can close out the possibility for miners to escape\n>>> punishment, it could make this protocol viable.\n>>> \n>>> On Thu, Jul 1, 2021 at 3:15 PM <raymo at riseup.net> wrote:\n>>> \n>>>> Hi Erik\n>>>> \n>>>> Please correct me if I misunderstood.\n>>>> \n>>>>> email is fully compromised.\n>>>> \n>>>> What I got is:\n>>>> Email is not good because the sender and receiver are\n>> compromised.\n>>>> Email is not good because the message content is revealed.\n>>>> I can claim same argue about any other client/server model. Since\n>>>> the\n>>>> server (website) service provider will ask some sort of KYC. And\n>>>> even if\n>>>> the server uses end-to-end encryption, the provider company still\n>>>> can\n>>>> read the packets content.\n>>>> In my model the passive listener only can discover who is\n>>>> communicate to\n>>>> whom and make a graph of connections. Although it is a threat for\n>>>> privacy but the server/client model has this flaw inherently,\n>> since\n>>>> provider already knew everything about everyone. In my model at\n>>>> least\n>>>> users can make some fake connections and send some fake emails in\n>>>> order\n>>>> to inject noise to communications.\n>>>> Please note the fact that entire communication between mobile\n>>>> wallets\n>>>> (via emails) are asymmetric PGP encrypted. The PGP keys are\n>>>> controlled\n>>>> by end users unlike ALL pretending secure messengers (e.g\n>> whatsApp,\n>>>> signal, zoom,\u2026).\n>>>> If you are worried about the way of exchanging PGP public key,\n>> you\n>>>> are\n>>>> right. The most secure way is in-person PGP key exchanging.\n>>>> After that for payments the wallets communicate in pgp encrypted\n>>>> messages and they can transfer Bitcoin address through an PGP\n>>>> encrypted\n>>>> cipher, thus no revealing Bitcoin address to public would occur.\n>>>> Neither\n>>>> the amounts of transactions will be reviled.\n>>>> There for it would be a good practice for shops to put their\n>> email\n>>>> and\n>>>> PGP public key on shop website and/or PGP public key servers,\n>>>> instead of\n>>>> putting Bitcoin address on website or using 3rd parties services\n>> to\n>>>> hide\n>>>> their Bitcoin payment addresses.\n>>>> \n>>>> If I missed some points about \u201cfully compromised\u201d please\n>> write\n>>>> it to me.\n>>>> \n>>>>> public keys / addresses are sent\n>>>> As I told before ALL communication in Sabu are PGP encrypted.\n>>>> \n>>>>> other routing data encrypted with public keys\n>>>>> (not sure how data is routed in sabu)\n>>>> \n>>>> Sabu is not responsible for routing at all. It simply sends\n>> emails.\n>>>> Indeed the wallets peer-to-peer network in Sabu is pretty\n>> straight\n>>>> forward. Each mobile wallet has one email address as its handler\n>> and\n>>>> identifier in mobile-wallets-network. Each mobile can send\n>> message\n>>>> to\n>>>> another mobile by knowing its email address and the PGP public\n>> key.\n>>>> This information can be prepared in first face-to-face contact of\n>>>> mobile\n>>>> owners, or later (something like signing the other\u2019s public key\n>> in\n>>>> web\n>>>> of trust) when a creditor wants to spend his money and transfer\n>> it\n>>>> to\n>>>> another creditor. The creditor1 send the signed money transfer\n>>>> request\n>>>> alongside the email and public key of creditor2 all in a PGP\n>>>> encrypted\n>>>> message to issuer.\n>>>> \n>>>>> separate the Sabu protocol from the app... allow others to\n>>>> implement\n>>>>> desktop version, or other versions that use other routing\n>> systems\n>>>> \n>>>> Indeed, it is my approach too. As I told before users will decide\n>>>> between an unstoppable, permission less, self-sovereignty and\n>>>> decentralized pure peer-to-peer communication network (with some\n>>>> resolvable privacy issues) or some efficient, privacy-mimic\n>> central\n>>>> limited network.\n>>>> \n>>>>> you can allow direct-entry of a BIP-word-representation\n>>>>> of a public key/address to avoid privacy/central system concerns\n>>>> Agree. Actually, I was thinking about an easy mechanism to share\n>>>> your\n>>>> public key like what you suggested here.\n>>>> But what I consider for a \u201ccentral system concerns\u201d is the\n>>>> ability of\n>>>> communication without dependency to any company.\n>>>> As an example, what can you do if the twitter bans your account?\n>>>> Nothing! Your content and entire connections will be lost.\n>>>> But if you form your friends list in your mobile (or computer)\n>> and\n>>>> have\n>>>> their PGP public keys and they have yours, and use email as a\n>> dual\n>>>> purpose tool. First as a handler (the tool for finding and to be\n>>>> found\n>>>> in internet) and second as a communication tool.\n>>>> Thus, no one can stop you, ban you or limit you to send/receive\n>>>> transaction to/from anyone.\n>>>> What I am trying to say is using email is far better than account\n>>>> (username) in a limited central service like twitter, Facebook,\n>>>> telegram... or even in future Sabu servers!\n>>>> You have your connections under your control in your phone. You\n>> can\n>>>> easily change your email and use a new email or even a new\n>> service\n>>>> provider without losing your connections and your control over\n>> it.\n>>>> You just sign your new email address and send it to your friends\n>>>> circle\n>>>> and notify them about changes.\n>>>> Of course, email is not good for millions of followers but it is\n>>>> obviously good for managing your payment network of hundreds of\n>>>> people\n>>>> (either issuers or creditors).\n>>>> \n>>>> Best\n>>>> Raymo\n>>>> \n>>>> On 2021-07-01 20:49, Erik Aronesty wrote:\n>>>>> your protocol should always assume the email system is fully\n>>>>> compromised, and only send public information over email:\n>>>>> \n>>>>> - public keys / addresses are sent\n>>>>> - other routing data encrypted with public keys (not sure how\n>> data\n>>>> is\n>>>>> routed in sabu)\n>>>>> \n>>>>> your end user should be able to verify public keys  / addresses\n>>>>> \n>>>>> - use QR-codes\n>>>>> - phone calls with users reading BIP words out loud\n>>>>> - other in-person information exchange\n>>>>> \n>>>>> separate the Sabu protocol from the app... allow others to\n>>>> implement\n>>>>> desktop version, or other versions that use other routing\n>> systems\n>>>>> \n>>>>> -  you can allow direct-entry of a BIP-word-representation of a\n>>>> public\n>>>>> key/address to avoid privacy/central system concerns\n>>>>> \n>>>>> On Thu, Jul 1, 2021 at 4:20 PM raymo via bitcoin-dev\n>>>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>>> \n>>>>>> Hi Billy,\n>>>>>> Sorry for late reply. Let\u2019s jump in proposal.\n>>>>>> \n>>>>>>> Some more information about the benefits of this approach vs\n>>>> alternatives (mainly lightning)\n>>>>>> The most important different is unlike the lightning, in Sabu\n>> no\n>>>> one\n>>>>>> have to open a channel and pay Bitcoin transaction fee,\n>>>> subsequently no\n>>>>>> one has to close channel and pay another Bitcoin transaction\n>> fee.\n>>>> It is\n>>>>>> the huge improvement since it drops the overhead cost of\n>>>> transactions.\n>>>>>> So, it will be more convenience to trade under Sabu protocol.\n>>>>>> In Sabu none of parties of a transaction are obliged to block\n>>>> money in\n>>>>>> any kind of smart contract or any other m of n signature\n>> accounts\n>>>>>> on-chain, so it provides more privacy.\n>>>>>> Since Sabu protocol is designed to motivate people to circulate\n>>>>>> transactions (AKA debt documents) in Sabu network, if every\n>> actor\n>>>> act\n>>>>>> rationally no one will aware how much money transferred from\n>> who\n>>>> to\n>>>>>> whom.\n>>>>>> In case of fraudulent activity by issuer, the creditor will\n>> send\n>>>>>> Guarantee Transaction (GT) to Bitcoin network in order to\n>>>> recapture the\n>>>>>> part of his credit. So, in this case the transaction is\n>> literally\n>>>>>> recorded on bitcoin blockchain.\n>>>>>> There is only one another reason to recording transaction on\n>>>> Bitcoin\n>>>>>> blockchain. Where one creditor eager to pay Bitcoin transaction\n>>>> fee in\n>>>>>> order to aggregate thousands or even millions different small\n>>>> amount\n>>>>>> debt-documents in a single transaction on Bitcoin blockchain.\n>>>>>> despite these two cases, the rest of transactions all occur in\n>>>> the Sabu\n>>>>>> network (supposed to be over 99%). Thus, no footprint no\n>>>> bottleneck and\n>>>>>> no over process.\n>>>>>> \n>>>>>> Another important power point of Sabu is its pure-peer-to-peer\n>>>> network\n>>>>>> architecture. In Sabu the mobile wallets communicating to each\n>>>> other\n>>>>>> directly without any central server. There is no centralization\n>>>> at all.\n>>>>>> As a result, there will be no routing as well.\n>>>>>> Since only issuer and creditors are aware of the content of\n>>>> transaction\n>>>>>> (who pay how much to whom) it is a huge privacy improvement,\n>>>> which\n>>>>>> doesn\u2019t exist in other layer 2 solutions.\n>>>>>> \n>>>>>> About the usability of Sabu, although the protocol based on the\n>>>>>> collaborating 2 different peer-to-peer network and 3 classic\n>>>>>> server/client networks, but the end user (mobile wallet user)\n>>>> doesn\u2019t\n>>>>>> see any of these complexities.\n>>>>>> The end user simply installs the mobile/desktop wallet and add\n>>>> her/his\n>>>>>> friends to his phonebook by adding their email address or\n>>>> scanning their\n>>>>>> email (and/or PGP public key). After that s/he can immediately\n>>>> start to\n>>>>>> send/receive Bitcoin through Sabu network. Entire\n>> communications\n>>>> between\n>>>>>> wallets are PGP encrypted.\n>>>>>> Another good point in Sabu design is, the 12 seed words are\n>> using\n>>>> for\n>>>>>> both Bitcoin wallet private key and the PGP private key. So, it\n>>>> is the\n>>>>>> key of user wealth and its identity as well. For more details,\n>>>> please\n>>>>>> read my previous answer to Alex Schoof.\n>>>>>> The issuer, by using his UTXOs and selling them to creditors\n>> earn\n>>>> money.\n>>>>>> the issuer creates the debt document (transaction) by which\n>>>> promises to\n>>>>>> creditor an amount of satoshi. These debt documents are valid\n>>>> Bitcoin\n>>>>>> transaction. The only difference is these transactions are\n>>>> intended to\n>>>>>> circulate in Sabu protocol instead of sending to Bitcoin\n>>>> blockchain.\n>>>>>> Each transaction is a small money transfer. 40,000 Satoshi as\n>>>> input and\n>>>>>> maximum 20,000 Satoshi as credit and minimum 10,000 Satoshi as\n>>>> Bitcoin\n>>>>>> transaction fee.\n>>>>>> The creditors will use these received transactions as money and\n>>>> will pay\n>>>>>> it in exchange of goods or services. For each transaction the\n>>>> creditor\n>>>>>> pays 10 Satoshi as Sabu-transaction-fee to issuer.\n>>>>>> Sabu is not custodial service and the UXTOs are always under\n>>>> issuer\n>>>>>> control, unless issuer or creditor send the signed transaction\n>> to\n>>>>>> Bitcoin network. When the transaction was recorded in Bitcoin\n>>>>>> blockchain, the creditor can spend proper UTXO in Bitcoin\n>>>> network.\n>>>>>> Imagine million people use their UTXOs in Sabu, they are issuer\n>>>> and\n>>>>>> issue/update/cancel million transactions per second. All they\n>>>> need is a\n>>>>>> mobile wallet. On the other hand, every one by knowing an\n>> issuer\n>>>> can buy\n>>>>>> some Satoshi (whit absolutely no KYC), even 1 Dollar or less,\n>> and\n>>>> spend\n>>>>>> it, this time Alice really can buy caffe by Bitcoin ;)\n>>>>>> The Bar can install the mobile wallet and every day receives\n>>>> thousands\n>>>>>> of debt documents (transactions), each worth maximum 20,000\n>>>> Satoshi in\n>>>>>> exchange of coffee. And every evening aggregates those small\n>>>>>> transactions to one single transaction and send it to Bitcoin\n>>>> network.\n>>>>>> \n>>>>>> \n>>>>>> The security model of Sabu is pretty straight forward.\n>>>>>> Issuer is the owner of UTXO(s) which will be used in\n>>>> transactions. The\n>>>>>> issuer is and will the only person who creates transactions and\n>>>> sign\n>>>>>> them. The transactions are valid transaction which either\n>> issuer\n>>>> or\n>>>>>> creditor can send them to Bitcoin network, but they will never\n>>>> send\n>>>>>> these transactions to Bitcoin network, because of the high\n>>>> Bitcoin\n>>>>>> transaction fee for each single transaction.\n>>>>>> Since issuer is the only one who can sign transaction (spend\n>>>> UTXOs),\n>>>>>> there is a risk of issuer cheating. And no one can stop issuer\n>>>> from\n>>>>>> cheating, because these are his UTXOs and he has the proper\n>>>> private\n>>>>>> keys.\n>>>>>> The Sabu solution is Guarantee transaction. It is a valid\n>>>> transaction\n>>>>>> that issuer has to sign it alongside the Main transaction. In\n>> GT\n>>>> both\n>>>>>> issuer and creditor cut a part of their output in favor of\n>>>> Bitcoin\n>>>>>> transaction fee.\n>>>>>> We suppose miners always seeking for more profit, thus in a\n>> case\n>>>> there\n>>>>>> are 2 or more transaction are spending same UTXO as input,\n>> miner\n>>>> will\n>>>>>> choose transaction with highest feeRate. There is no\n>> economically\n>>>>>> benefit for issuer to cheat creditors and pay less transaction\n>>>> fee\n>>>>>> simultaneously. So rationally the issuer won\u2019t cheat\n>> creditor.\n>>>>>> It was the simplest explanation of Sabu security model.\n>>>>>> \n>>>>>>> I agree with others that using email is probably not\n>>>> appropriate for a protocol like this. I would highly recommend\n>>>> making your protocol transport-agnostic, allowing users of your\n>>>> protocol to use any transport they want.\n>>>>>> Indeed, the protocol is transparent-agnostic, if I insist of\n>>>> email as a\n>>>>>> user identifier and communicating tool is because of the idea\n>> of\n>>>>>> reforming part of internet architecture and make it more\n>>>> decentralized.\n>>>>>> The wallet users can choose classic architecture. In this case\n>>>> mobile\n>>>>>> wallets will connect to a central server and communicate\n>> through\n>>>> that\n>>>>>> server (pretty much like all existed mobile wallets). While\n>> some\n>>>> users\n>>>>>> decide to use a pure peer-to-peer communication. I knew email\n>> has\n>>>> some\n>>>>>> privacy issues but as always it is a tradeoff. Users can decide\n>>>> between\n>>>>>> an unstoppable, permission less, self-sovereignty and\n>>>> decentralized pure\n>>>>>> peer-to-peer communication network (with some resolvable\n>> privacy\n>>>> issues)\n>>>>>> or some efficient central limited network.\n>>>>>> Let me know the critics about email. Hopefully this would lead\n>> us\n>>>> to\n>>>>>> improve email instead of letting it die. I strongly suggest\n>> email\n>>>>>> because it is the ONLY neutral, free \u201cnonproprietary\u201d and\n>>>> open\n>>>>>> protocol/technology for communication in the world that its\n>>>>>> infrastructure is well-established and is accessible all over\n>> the\n>>>> glob.\n>>>>>> \n>>>>>> I tried to explain it more, hope was useful. By the way the\n>>>> complete\n>>>>>> explanation is here\n>>>>>> \n>>>> \n>>> \n>> \n> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n>>>>>> \n>>>>>> \n>>>>>> \n>>>>>> Regards\n>>>>>> Raymo\n>>>>>> \n>>>>>> \n>>>>>> \n>>>>>> On 2021-06-22 18:20, Billy Tetrud wrote:\n>>>>>>> I would be interested in seeing some more information about\n>> the\n>>>>>>> benefits of this approach vs alternatives up front in this\n>>>> write up.\n>>>>>>> Eg how does the security, cost, usability, and privacy compare\n>>>> to the\n>>>>>>> lightning network, which would be the most likely competitor\n>> to\n>>>> this\n>>>>>>> idea. It seems clear that there is more counterparty risk\n>> here,\n>>>> so it\n>>>>>>> would probably also be very helpful to compare against\n>>>> traditional\n>>>>>>> custodial solutions as well. If you have specific claims on\n>> how\n>>>> this\n>>>>>>> system is better than eg lightning in certain contexts, it\n>>>> would be\n>>>>>>> far easier to evaluate the protocol against those claims, and\n>>>> would\n>>>>>>> also be a lot easier for readers to be motivated to read the\n>>>> whole\n>>>>>>> protocol and do a more full analysis.\n>>>>>>> \n>>>>>>> I agree with others that using email is probably not\n>>>> appropriate for a\n>>>>>>> protocol like this. I would highly recommend making your\n>>>> protocol\n>>>>>>> transport-agnostic, allowing users of your protocol to use any\n>>>>>>> transport they want.\n>>>>>>> \n>>>>>>> On Sat, Jun 19, 2021 at 7:00 PM James Hilliard via bitcoin-dev\n>>>>>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>>>> \n>>>>>>>> I think you're making a number of assumptions about mining\n>>>> that are\n>>>>>>>> not accurate.\n>>>>>>>> \n>>>>>>>>> First of all, how much chance in finding next block the\n>>>> corrupted\n>>>>>>>> miners have? One percent of all Bitcoin hash powers? Or\n>>>> maximum 5\n>>>>>>>> percent or 10? The cheaters must come up in dividing that 1.2\n>>>>>>>> Bitcoin between. After all the risk/reward must fit them.\n>> They\n>>>> can\n>>>>>>>> not be a big mining pool since there is no benefit, so they\n>>>> will be\n>>>>>>>> small miners with low hash rate. If they solve the puzzle and\n>>>>>>>> broadcast the block, no one in the entire Bitcoin network has\n>>>> block\n>>>>>>>> transactions or seen it before in their mempool!\n>>>>>>>> \n>>>>>>>> You're making the assumption that miners won't build on top\n>> of\n>>>> a\n>>>>>>>> block\n>>>>>>>> with transactions they have not seen before or transactions\n>>>> that may\n>>>>>>>> contain double spends of unconfirmed inputs, this is not how\n>>>> mining\n>>>>>>>> works, as long as the block passes the consensus rules\n>>>> effectively\n>>>>>>>> all\n>>>>>>>> miners will mine on top of it by default, this behavior is\n>>>>>>>> fundamental\n>>>>>>>> to how mining currently works and is fairly deeply baked into\n>>>> the\n>>>>>>>> current mining infrastructure.\n>>>>>>>> \n>>>>>>>>> Will they accept this block? In theory it is possible and\n>>>> have\n>>>>>>>> 0.01 percent chance but we can eliminate this small\n>>>> possibilities by\n>>>>>>>> a simple BIP for miners.\n>>>>>>>> \n>>>>>>>> What would this BIP look like? I don't see how this could\n>> work\n>>>> in a\n>>>>>>>> decentralized way as you would need another way of reaching\n>>>>>>>> consensus\n>>>>>>>> on what defines a valid block. Right now the chance is nearly\n>>>> 100\n>>>>>>>> percent that a miner will mine on top of the latest valid\n>>>> block,\n>>>>>>>> many\n>>>>>>>> pools(most last I checked) will even mine on the next block\n>>>> before\n>>>>>>>> they validate the latest block fully(ie validationless\n>> mining)\n>>>> to\n>>>>>>>> reduce their orphan rates.\n>>>>>>>> \n>>>>>>>>> We suppose the miners always control transactions with\n>>>>>>>> doc-watchers and avoid accepting transaction with same UTXO\n>>>> but\n>>>>>>>> different output.\n>>>>>>>> \n>>>>>>>> Miners have different mempool policy/rules for what\n>>>> transactions\n>>>>>>>> they\n>>>>>>>> themselves mine but all miners must mine on the most work\n>>>> chain of\n>>>>>>>> valid blocks otherwise they risk their own blocks being\n>>>> orphaned,\n>>>>>>>> any\n>>>>>>>> miner that does not do this is effectively guaranteed to have\n>>>> their\n>>>>>>>> block orphaned right now.\n>>>>>>>> \n>>>>>>>>> Because of high Bitcoin transaction fee, this guarantee\n>>>>>>>> transaction will take place in next block, even if other\n>>>> transaction\n>>>>>>>> which are using the same UTXO as input existed in mempool.\n>>>>>>>> \n>>>>>>>> When a new transaction is broadcast miners do not immediately\n>>>> start\n>>>>>>>> mining on a block template that includes that transaction,\n>> the\n>>>>>>>> template won't even be generated immediately when it enters a\n>>>> miners\n>>>>>>>> mempool in practice, for bandwidth/network efficiency reasons\n>>>> mining\n>>>>>>>> pools batch update the stratum templates/jobs they mine\n>>>> against so\n>>>>>>>> there can be significant latency between the time a\n>>>> transaction is\n>>>>>>>> actually broadcast and hits the miners mempool and the time\n>>>> the\n>>>>>>>> miners\n>>>>>>>> actually switch to mining on top it, these batched updates\n>> are\n>>>>>>>> essentially like point in time snapshots of the mempool and\n>>>>>>>> typically\n>>>>>>>> remain valid(as in the pool will accept shares submitted\n>>>> against\n>>>>>>>> that\n>>>>>>>> job as valid) until the bitcoin network finds the next block.\n>>>> I\n>>>>>>>> don't\n>>>>>>>> think these batch updates are done more often than every 30\n>>>> seconds\n>>>>>>>> typically, while often it is on the order of multiple minutes\n>>>>>>>> depending on the pool.\n>>>>>>>> \n>>>>>>>> Regards,\n>>>>>>>> James\n>>>>>>>> \n>>>>>>>> On Thu, Jun 17, 2021 at 2:14 PM raymo via bitcoin-dev\n>>>>>>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>>>>>> \n>>>>>>>>> Hi,\n>>>>>>>>> I have a proposal for improve Bitcoin TPS and privacy, here\n>>>> is the\n>>>>>>>> post.\n>>>>>>>>> \n>>>>>>>> \n>>>>>>> \n>>>> \n>>> \n>> \n> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n>>>>>>>>> https://bitcointalk.org/index.php?topic=5344020.0\n>>>>>>>>> Can you please read it and share your idea about it.\n>>>>>>>>> \n>>>>>>>>> Cheers\n>>>>>>>>> Raymo\n>>>>>>>>> _______________________________________________\n>>>>>>>>> bitcoin-dev mailing list\n>>>>>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>>>>>> \n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>>>> _______________________________________________\n>>>>>>>> bitcoin-dev mailing list\n>>>>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>>>>> \n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>> _______________________________________________\n>>>>>> bitcoin-dev mailing list\n>>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>> \n>>> \n>>> Links:\n>>> ------\n>>> [1]\n>> \n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-June/019050.html"
            },
            {
                "author": "Tao Effect",
                "date": "2021-07-17T18:54:22",
                "message_text_only": "Hi Raymo,\n\nI personally am excited about what you\u2019re working on, and wish you the best of luck with it!\n\nCheers,\nGreg\n\n> On Jul 17, 2021, at 8:50 AM, raymo via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> After introducing Sabu protocol as a solution for Bitcoin scaling\n> (https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180),\n> I shared this idea with Bitcoin developers through the bitcoin-dev\n> mailing list.\n> I got some constructive feedbacks and critiques leading me to add this\n> part to the proposal which I was skipped due to brevity of proposal\n> introduction.\n>  [..]"
            }
        ],
        "thread_summary": {
            "title": "Boost Bitcoin circulation, Million Transactions Per Second with stronger privacy",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "raymo at riseup.net",
                "Tao Effect",
                "Billy Tetrud",
                "Erik Aronesty"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 172822
        }
    },
    {
        "title": "[bitcoin-dev] Derivation Paths for Single Key Taproot Scripts",
        "thread_messages": [
            {
                "author": "Andrew Chow",
                "date": "2021-07-02T20:03:20",
                "message_text_only": "This was assigned BIP number 86, so the purpose level path will be m/86'\n\nAndrew\n\nOn 6/22/21 9:17 PM, Andrew Chow wrote:\n> Hi All,\n>\n> I would like to propose a simple derivation path scheme for keys to be\n> used in single key Taproot scripts. This is based on BIP 44 so it is\n> basically identical to BIPs 49 and 84. Like with those BIPs, the actual\n> value to be used in the purpose level will be set to the BIP number,\n> once assigned.\n>\n> Note that the keys derived in this method should be for the Taproot\n> internal key, which should then be tweaked with the hash of itself as\n> recommended by BIP 341. The keys derived at this path should not be used\n> directly as the Taproot output pubkey. Additionally, this BIP does not\n> specify new version bytes for extended key serialization because, with\n> the advent of descriptors, I think that is unnecessary. In fact, this\n> BIP feels somewhat unnecessary to me, but it seems like it will be\n> needed for now in order to drive adoption and implementation of Taproot\n> into software and hardware wallets.\n>\n> The text can be viewed below, with the rendered text available at\n> https://github.com/achow101/bips/blob/taproot-bip44/bip-taproot-bip44.mediawiki\n>\n> Andrew Chow\n>\n> ---\n>\n> <pre>\n>   \u00a0 BIP: bip-taproot-bip44\n>   \u00a0 Layer: Applications\n>   \u00a0 Title: Derivation scheme for P2TR based accounts\n>   \u00a0 Author: Andrew Chow <andrew at achow101.com>\n>   \u00a0 Comments-Summary: No comments yet.\n>   \u00a0 Comments-URI:\n> https://github.com/bitcoin/bips/wiki/Comments:BIP-taproot-bip44\n>   \u00a0 Status: Draft\n>   \u00a0 Type: Informational\n>   \u00a0 Created: 2021-06-22\n>   \u00a0 License: BSD-2-Clause\n> </pre>\n>\n> ==Abstract==\n>\n> This document suggests a derivation scheme for HD wallets whose keys are\n> involved in single key\n> P2TR ([[bip-0341.mediawiki|BIP 341]]) outputs as the Taproot internal key.\n>\n> ===Copyright===\n>\n> This BIP is licensed under the 2-clause BSD license.\n>\n> ==Motivation==\n>\n> With the usage of single key P2TR transactions, it is useful to have a\n> common derivation scheme so\n> that HD wallets that only have a backup of the HD seed can be likely to\n> recover single key Taproot\n> outputs. Although there are now solutions which obviate the need for\n> fixed derivation paths for\n> specific script types, many software wallets and hardware signers still\n> use seed backups which\n> lack derivation path and script information. Thus we largely use the\n> same approach used in BIPs\n> [[bip-0049.mediawiki|49]] and [[bip-0084.mediawiki|84]] for ease of\n> implementation.\n>\n> ==Specifications==\n>\n> This BIP defines the two needed steps to derive multiple deterministic\n> addresses based on a\n> [[bip-0032.mediawiki|BIP 32]] master private key.\n>\n> ===Public key derivation===\n>\n> To derive a public key from the root account, this BIP uses the same\n> account-structure as\n> defined in BIPs [[bip-0044.mediawiki|44]], [[bip-0049.mediawiki|49]],\n> and [[bip-0084.mediawiki|84]],\n> but with a different purpose value for the script type.\n>\n> <pre>\n> m / purpose' / coin_type' / account' / change / address_index\n> </pre>\n>\n> For the <tt>purpose</tt>-path level it uses <tt><BIPNUMBER>'</tt>.\n> The rest of the levels are used as defined in BIPs 44, 49, and 84.\n>\n> ===Address derivation===\n>\n> To derive the output key used in the P2TR script from the derived public\n> key, we use the method\n> recommended in\n> [[bip-0341.mediawiki#constructing-and-spending-taproot-outputs|BIP 341]]:\n>\n> <pre>\n> internal_key:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 lift_x(derived_key)\n> 32_byte_output_key: internal_key + int(HashTapTweak(bytes(internal_key)))G\n> </pre>\n>\n> In a transaction, the scripts and witnesses are as defined in\n> [[bip-0341.mediawiki#specification|BIP 341]]:\n>\n> <pre>\n> witness:\u00a0\u00a0\u00a0\u00a0\u00a0 <signature>\n> scriptSig:\u00a0\u00a0\u00a0 (empty)\n> scriptPubKey: 1 <32_byte_output_key>\n>   \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 (0x5120{32_byte_output_key})\n> </pre>\n>\n> ==Backwards Compatibility==\n>\n> This BIP is not backwards compatible by design.\n> An incompatible wallet will not discover these accounts at all and the\n> user will notice that\n> something is wrong.\n>\n> However this BIP uses the same method used in BIPs 44, 49, and 84, so it\n> should not be difficult\n> to implement.\n>\n> ==Test vectors==\n>\n> TBD\n>\n> ==Reference==\n>\n> * [[bip-0032.mediawiki|BIP32 - Hierarchical Deterministic Wallets]]\n> * [[bip-0043.mediawiki|BIP43 - Purpose Field for Deterministic Wallets]]\n> * [[bip-0044.mediawiki|BIP44 - Multi-Account Hierarchy for Deterministic\n> Wallets]]\n> * [[bip-0049.mediawiki|BIP49 - Derivation scheme for\n> P2WPKH-nested-in-P2SH based accounts]]\n> * [[bip-0084.mediawiki|BIP84 - Derivation scheme for P2WPKH based accounts]]\n> * [[bip-0341.mediawiki|BIP341 - Taproot: SegWit version 1 spending rules]]\n>"
            }
        ],
        "thread_summary": {
            "title": "Derivation Paths for Single Key Taproot Scripts",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Andrew Chow"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4703
        }
    },
    {
        "title": "[bitcoin-dev] BIP Proposals for Output Script Descriptors",
        "thread_messages": [
            {
                "author": "Andrew Chow",
                "date": "2021-07-02T20:05:45",
                "message_text_only": "I've opened a PR against my own BIPs fork for review: https://github.com/achow101/bips/pull/3\n\nAndrew\n\nOn 6/29/21 11:41 PM, Jeremy wrote:\n\n> Kudos, this is fantastic!\n>\n> It might be easier, since there is a ton of content here, for you to open up some WIP PRs to collect feedback?\n> --\n> [@JeremyRubin](https://twitter.com/JeremyRubin)\n>\n> On Tue, Jun 29, 2021 at 2:15 PM Andrew Chow via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi All,\n>>\n>> I've been working on formalizing the Output Script Descriptors that have\n>> been available in Bitcoin Core for a while into BIPs. Since descriptors\n>> are modular and have optional components, I've decided to split it into\n>> 7 BIPs, rather than a single one. The first describes descriptors in\n>> general and does not specify any particular descriptor. However it does\n>> describe the general operation, key expressions (including derivation\n>> paths and key origin info), and the descriptor checksum. The following 6\n>> BIPs specify the actual descriptors themselves. These are non-segwit\n>> descriptor (pk, pkh, sh), segwit descriptors (wpkh, wsh), multisig\n>> descriptors (multi, sortedmulti), the taproot descriptor (tr), the combo\n>> descriptor, and opaque descriptors (raw, addr). This separation is so\n>> that implementors can choose to not implement some descriptors and still\n>> say which descriptors they support without being too difficult to\n>> understand.\n>>\n>> The text of all of the documents are below, and they can also be found\n>> on github:https://github.com/achow101/bips/tree/descriptors/\n>>\n>> Thanks,\n>> Andrew Chow\n>>\n>> ---\n>>\n>> <pre>\n>> BIP: bip-descriptors-general\n>> Layer: Applications\n>> Title: Output Script Descriptors General Operation\n>> Author: Pieter Wuille <pieter at wuille.net>\n>> Andrew Chow <andrew at achow101.com>\n>> Comments-Summary: No comments yet.\n>> Comments-URI:\n>> https://github.com/bitcoin/bips/wiki/Comments:BIP-descriptors-general\n>> Status: Draft\n>> Type: Informational\n>> Created: 2021-06-27\n>> License: BSD-2-Clause\n>> </pre>\n>>\n>> ==Abstract==\n>>\n>> Output Script Descriptors are a simple language which can be used to\n>> describe collections ofoutput scripts.\n>> There can be many different descriptor fragments and functions.\n>> This document describes the general syntax for descriptors, descriptor\n>> checksums, and common expressions.\n>>\n>> ==Copyright==\n>>\n>> This BIP is licensed under the BSD 2-clause license.\n>>\n>> ==Motivation==\n>>\n>> Bitcoin wallets traditionally have stored a set of keys which are later\n>> serialized and mutated to produce the output scripts that the wallet\n>> watches and the addresses it provides to users.\n>> Typically backups have consisted of solely the private keys, nowadays\n>> primarily in the form of BIP 39 mnemonics.\n>> However this backup solution is insuffient, especially since the\n>> introduction of Segregated Witness which added new output types.\n>> Given just the private keys, it is not possible for restored wallets to\n>> know which kinds of output scripts and addresses to produce.\n>> This has lead to incompatibilities between wallets when restoring a\n>> backup or exporting data for a watch only wallet.\n>>\n>> Further complicating matters are BIP 32 derivation paths.\n>> Although BIPs 44, 49, and 84 have specified standard BIP 32 derivation\n>> paths for different output scripts and addresses, not all wallets\n>> support them nor use those derivation paths.\n>> The lack of derivation path information in these backups and exports\n>> leads to further incompatibilities between wallets.\n>>\n>> Current solutions to these issues have not been generic and can be\n>> viewed as being layer violations.\n>> Solutions such as introducing different version bytes for extended key\n>> serialization both are a layer violation (key derivation should be\n>> separate from script type meaning) and specific only to a particular\n>> derivation path and script type.\n>>\n>> Output Script Descriptors introduces a generic solution to these issues.\n>> Script types are specified explicitly through the use of Script Expressions.\n>> Key derivation paths are specified explicitly in Key Expressions.\n>> These allow for creating wallet backups and exports which specify the\n>> exact scripts, subscripts (redeemScript, witnessScript, etc.), and keys\n>> to produce.\n>> With the general structure specified in this BIP, new Script Expressions\n>> can be introduced as new script types are added.\n>> Lastly, the use of common terminology and existing standards allow for\n>> Output Script Descriptors to be engineer readable so that the results\n>> can be understood at a glance.\n>>\n>> ==Specification==\n>>\n>> Descriptors consist of several types of expressions.\n>> The top level expression is a <tt>SCRIPT</tt>.\n>> This expression may be followed by <tt>#CHECKSUM</tt>, where\n>> <tt>CHECKSUM</tt> is an 8 character alphanumeric descriptor checksum.\n>>\n>> ===Script Expressions===\n>>\n>> Script Expressions (denoted <tt>SCRIPT</tt>) are expressions which\n>> correspond directly with a Bitcoin script.\n>> These expressions are written as functions and take arguments.\n>> Such expressions have a script template which is filled with the\n>> arguments correspondingly.\n>> Expressions are written with a human readable identifier string with the\n>> arguments enclosed with parentheses.\n>> The identifier string should be alphanumeric and may include underscores.\n>>\n>> The arguments to a script expression are defined by that expression itself.\n>> They could be a script expression, a key expression, or some other\n>> expression entirely.\n>>\n>> ===Key Expressions===\n>>\n>> A common expression used as an argument to script expressions are key\n>> expressions (denoted <tt>KEY</tt>).\n>> These represent a public or private key and, optionally, information\n>> about the origin of that key.\n>> Key expressions can only be used as arguments to script expressions.\n>>\n>> Key expressions consist of:\n>> * Optionally, key origin information, consisting of:\n>> ** An open bracket <tt>[</tt>\n>> ** Exactly 8 hex characters for the fingerprint of the key where the\n>> derivation starts (see BIP 32 for details)\n>> ** Followed by zero or more <tt>/NUM</tt> or <tt>/NUM'</tt> path\n>> elements to indicate the unhardened or hardened derivation steps between\n>> the fingerprint and the key that follows.\n>> ** A closing bracket <tt>]</tt>\n>> * Followed by the actual key, which is either:\n>> ** A hex encoded public key, which depending the script expression, may\n>> be either:\n>> *** 66 hex character string beginning with <tt>02</tt> or <tt>03</tt>\n>> representing a compressed public key\n>> *** 130 hex character string beginning with <tt>04</tt> representing an\n>> uncompressed public key\n>> *** 64 hex character string representing an x-only public key\n>> ** A [[[https://en.bitcoin.it/wiki/Wallet_import_format|WIF](https://en.bitcoin.it/wiki/Wallet_import_format%7CWIF)]] encoded\n>> private key\n>> ** <tt>xpub</tt> encoded extended public key or <tt>xprv</tt> encoded\n>> extended private key (as defined in BIP 32)\n>> *** Followed by zero or more <tt>/NUM</tt> or <tt>/NUM'</tt> path\n>> elements indicating BIP 32 derivation steps to be taken after the given\n>> extended key.\n>> *** Optionally followed by a single <tt>/*</tt> or <tt>/*'</tt> final\n>> step to denote all direct unhardened or hardened children.\n>>\n>> If the <tt>KEY</tt> is a BIP 32 extended key, before output scripts can\n>> be created, child keys must be derived using the derivation information\n>> that follows the extended key.\n>> When the final step is <tt>/*</tt> or <tt>/*'</tt>, an output script\n>> will be produced for every child key index.\n>> The derived key must be serialized as a compressed public key.\n>>\n>> In the above specification, the hardened indicator <tt>'</tt> may be\n>> replaced with alternative hardnened indicators of <tt>h</tt> or <tt>H</tt>.\n>>\n>> ===Character Set===\n>>\n>> The expressions used in descriptors must only contain characters within\n>> this character set so that the descriptor checksum will work.\n>>\n>> The allowed characters are:\n>> <pre>\n>> 0123456789()[],'/*abcdefgh@:$%{}\n>> IJKLMNOPQRSTUVWXYZ&+-.;<=>?!^_|~\n>> ijklmnopqrstuvwxyzABCDEFGH`#\"\\<space>\n>> </pre>\n>> Note that <tt><space></tt> on the last line is a space character.\n>>\n>> This character set is written as 3 groups of 32 characters in this\n>> specific order so that the checksum below can identify more errors.\n>> The first group are the most common \"unprotected\" characters (i.e.\n>> things such as hex and keypaths that do not already have their own\n>> checksums).\n>> Case errors cause an offset that is a multiple of 32 while as many\n>> alphabetic characters are in the same group while following the previous\n>> restrictions.\n>>\n>> ===Checksum===\n>>\n>> Follwing the top level script expression is a single octothorpe\n>> (<tt>#</tt>) followed by the 8 character checksum.\n>> The checksum is an error correcting checksum similar to bech32.\n>>\n>> The checksum has the following properties:\n>> * Mistakes in a descriptor string are measured in \"symbol errors\". The\n>> higher the number of symbol errors, the harder it is to detect:\n>> ** An error substituting a character from\n>> <tt>0123456789()[],'/*abcdefgh@:$%{}</tt> for another in that set always\n>> counts as 1 symbol error.\n>> *** Note that hex encoded keys are covered by these characters. Extended\n>> keys (<tt>xpub</tt> and <tt>xprv</tt>) use other characters too, but\n>> also have their own checksum mechansim.\n>> *** <tt>SCRIPT</tt> expression function names use other characters, but\n>> mistakes in these would generally result in an unparsable descriptor.\n>> ** A case error always counts as 1 symbol error.\n>> ** Any other 1 character substitution error counts as 1 or 2 symbol errors.\n>> * Any 1 symbol error is always detected.\n>> * Any 2 or 3 symbol error in a descriptor of up to 49154 characters is\n>> always detected.\n>> * Any 4 symbol error in a descriptor of up to 507 characters is always\n>> detected.\n>> * Any 5 symbol error in a descriptor of up to 77 characters is always\n>> detected.\n>> * Is optimized to minimize the chance of a 5 symbol error in a\n>> descriptor up to 387 characters is undetected\n>> * Random errors have a chance of 1 in 2<super>40</super> of being\n>> undetected.\n>>\n>> The checksum itself uses the same character set as bech32:\n>> <tt>qpzry9x8gf2tvdw0s3jn54khce6mua7l</tt>\n>>\n>> Valid descriptor strings with a checksum must pass the criteria for\n>> validity specified by the Python3 code snippet below.\n>> The function <tt>descsum_check</tt> must return true when its argument\n>> <tt>s</tt> is a descriptor consisting in the form <tt>SCRIPT#CHECKSUM</tt>.\n>>\n>> <pre>\n>> INPUT_CHARSET =\n>> \"0123456789()[],'/*abcdefgh@:$%{}IJKLMNOPQRSTUVWXYZ&+-.;<=>?!^_|~ijklmnopqrstuvwxyzABCDEFGH`#\\\"\\\\\n>> \"\n>> CHECKSUM_CHARSET = \"qpzry9x8gf2tvdw0s3jn54khce6mua7l\"\n>> GENERATOR = [0xf5dee51989, 0xa9fdca3312, 0x1bab10e32d, 0x3706b1677a,\n>> 0x644d626ffd]\n>>\n>> def descsum_polymod(symbols):\n>> \"\"\"Internal function that computes the descriptor checksum.\"\"\"\n>> chk = 1\n>> for value in symbols:\n>> top = chk >> 35\n>> chk = (chk & 0x7ffffffff) << 5 ^ value\n>> for i in range(5):\n>> chk ^= GENERATOR[i] if ((top >> i) & 1) else 0\n>> return chk\n>>\n>> def descsum_expand(s):\n>> \"\"\"Internal function that does the character to symbol expansion\"\"\"\n>> groups = []\n>> symbols = []\n>> for c in s:\n>> if not c in INPUT_CHARSET:\n>> return None\n>> v = INPUT_CHARSET.find(c)\n>> symbols.append(v & 31)\n>> groups.append(v >> 5)\n>> if len(groups) == 3:\n>> symbols.append(groups[0] * 9 + groups[1] * 3 + groups[2])\n>> groups = []\n>> if len(groups) == 1:\n>> symbols.append(groups[0])\n>> elif len(groups) == 2:\n>> symbols.append(groups[0] * 3 + groups[1])\n>> return symbols\n>>\n>> def descsum_check(s):\n>> \"\"\"Verify that the checksum is correct in a descriptor\"\"\"\n>> if s[-9] != '#':\n>> return False\n>> if not all(x in CHECKSUM_CHARSET for x in s[-8:]):\n>> return False\n>> symbols = descsum_expand(s[:-9]) + [CHECKSUM_CHARSET.find(x) for x\n>> in s[-8:]]\n>> return descsum_polymod(symbols) == 1\n>> </pre>\n>>\n>> This implements a BCH code that has the properties described above.\n>> The entire descriptor string is first processed into an array of symbols.\n>> The symbol for each character is its position within its group.\n>> After every 3rd symbol, a 4th symbol is inserted which represents the\n>> group numbers combined together.\n>> This means that a change that only affects the position within a group,\n>> or only a group number change, will only affect a single symbol.\n>>\n>> To construct a valid checksum given a script expression, the code below\n>> can be used:\n>>\n>> <pre>\n>> def descsum_create(s):\n>> \"\"\"Add a checksum to a descriptor without\"\"\"\n>> symbols = descsum_expand(s) + [0, 0, 0, 0, 0, 0, 0, 0]\n>> checksum = descsum_polymod(symbols) ^ 1\n>> return s + '#' + ''.join(CHECKSUM_CHARSET[(checksum >> (5 * (7 -\n>> i))) & 31] for i in range(8))\n>>\n>> </pre>\n>>\n>> ==Backwards Compatibility==\n>>\n>> Output script descriptors are an entirely new language which is not\n>> compatible with any existing software.\n>> However many components of the expressions reuse encodings and\n>> serializations defined by previous BIPs.\n>>\n>> Output script descriptors are designed for future extension with further\n>> fragment types and new script expressions.\n>> These will be specified in additional BIPs.\n>>\n>> ==Reference Implemntation==\n>>\n>> Descriptors have been implemented in Bitcoin Core since version 0.17.\n>>\n>> ---\n>>\n>> <pre>\n>> BIP: bip-descriptors-segwit\n>> Layer: Applications\n>> Title: segwit Output Script Descriptors\n>> Author: Pieter Wuille <pieter at wuille.net>\n>> Andrew Chow <andrew at achow101.com>\n>> Comments-Summary: No comments yet.\n>> Comments-URI:\n>> https://github.com/bitcoin/bips/wiki/Comments:BIP-descriptors-segwit\n>> Status: Draft\n>> Type: Informational\n>> Created: 2021-06-27\n>> License: BSD-2-Clause\n>> </pre>\n>>\n>> ==Abstract==\n>>\n>> This document specifies <tt>wpkh()</tt>, and <tt>wsh()</tt> output\n>> script descriptors.\n>> <tt>wpkh()</tt> descriptors take a key and produces a P2WPKH output script.\n>> <tt>wsh()</tt> descriptors take a script and produces a P2WSH output script.\n>>\n>> ==Copyright==\n>>\n>> This BIP is licensed under the BSD 2-clause license.\n>>\n>> ==Motivation==\n>>\n>> Segregated Witness added 2 additional standard output script formats:\n>> P2WPKH and P2WSH.\n>> These expressions allow specifying those formats as a descriptor.\n>>\n>> ==Specification==\n>>\n>> Two new script expressions are defined: <tt>wpkh()</tt>, and <tt>wsh()</tt>.\n>>\n>> ===<tt>wpkh()</tt>===\n>>\n>> The <tt>wpkh(KEY)</tt> expression can be used as a top level expression,\n>> or inside of a <tt>sh()</tt> descriptor.\n>> It takes a single key expression as an argument and produces a P2WPKH\n>> output script.\n>> Only keys which are/has compressed public keys can be contained in a\n>> <tt>wpkh()</tt> expression.\n>>\n>> The output script produced is:\n>> <pre>\n>> OP_0 <KEY_hash160>\n>> </pre>\n>>\n>> ===<tt>wsh()</tt>===\n>>\n>> The <tt>wsh(SCRIPT)</tt> expression can be used as a top level\n>> expression, or inside of a <tt>sh()</tt> descriptor.\n>> It takes a single script expression as an argument and produces a P2WSH\n>> output script.\n>> <tt>wsh()</tt> expressions also create a witnessScript which is required\n>> in order to spend outputs which use its output script.\n>> This redeemScript is the output script produced by the <tt>SCRIPT</tt>\n>> argument to <tt>wsh()</tt>.\n>> Any key expression found in any script expression contained by a\n>> <tt>wsh()</tt> expression must only produce compresed public keys.\n>>\n>> The output script produced is:\n>> <pre>\n>> OP_0 <SCRIPT_sha256>\n>> </pre>\n>>\n>> ==Test Vectors==\n>>\n>> TBD\n>>\n>> ==Backwards Compatibility==\n>>\n>> <tt>wpkh()</tt>, and <tt>wsh()</tt> descriptors use the format and\n>> general operation specified in\n>> [[bip-descriptor-general.mediawiki|bip-descriptor-general]].\n>> As these are a wholly new descriptors, they are not compatible with any\n>> implementation.\n>> However the scripts produced are standard scripts so existing software\n>> are likely to be familiar with them.\n>>\n>> ==Reference Implemntation==\n>>\n>> <tt>wpkh()</tt>, and <tt>wsh()</tt> descriptors have been implemented in\n>> Bitcoin Core since version 0.17.\n>>\n>> ---\n>>\n>> <pre>\n>> BIP: bip-descriptors-non-segwit\n>> Layer: Applications\n>> Title: Non-segwit Output Script Descriptors\n>> Author: Pieter Wuille <pieter at wuille.net>\n>> Andrew Chow <andrew at achow101.com>\n>> Comments-Summary: No comments yet.\n>> Comments-URI:\n>> https://github.com/bitcoin/bips/wiki/Comments:BIP-descriptors-non-segwit\n>> Status: Draft\n>> Type: Informational\n>> Created: 2021-06-27\n>> License: BSD-2-Clause\n>> </pre>\n>>\n>> ==Abstract==\n>>\n>> This document specifies <tt>pk()</tt>, <tt>pkh()</tt>, and <tt>sh()</tt>\n>> output script descriptors.\n>> <tt>pk()</tt> descriptors take a key and produces a P2PK output script.\n>> <tt>pkh()</tt> descriptors take a key and produces a P2PKH output script.\n>> <tt>sh()</tt> descriptors take a script and produces a P2SH output script.\n>>\n>> ==Copyright==\n>>\n>> This BIP is licensed under the BSD 2-clause license.\n>>\n>> ==Motivation==\n>>\n>> Prior to the activation of Segregated Witness, there were 3 main\n>> standard output script formats: P2PK, P2PKH, and P2SH.\n>> These expressions allow specifying those formats as a descriptor.\n>>\n>> ==Specification==\n>>\n>> Three new script expressions are defined: <tt>pk()</tt>, <tt>pkh()</tt>,\n>> and <tt>sh()</tt>.\n>>\n>> ===<tt>pk()</tt>===\n>>\n>> The <tt>pk(KEY)</tt> expression can be used in any context or level of a\n>> descriptor.\n>> It takes a single key expression as an argument and produces a P2PK\n>> output script.\n>> Depending on the higher level descriptors, there may be restrictions on\n>> the type of public keys that can be included.\n>> Such restrictions will be specified by those descriptors.\n>>\n>> The output script produced is:\n>> <pre>\n>> <KEY> OP_CHECKSIG\n>> </pre>\n>>\n>> ===<tt>pkh()</tt>===\n>>\n>> The <tt>pkh(KEY)</tt> expression can be used as a top level expression,\n>> or inside of either a <tt>sh()</tt> or <tt>wsh()</tt> descriptor.\n>> It takes a single key expression as an argument and produces a P2PKH\n>> output script.\n>> Depending on the higher level descriptors, there may be restrictions on\n>> the type of public keys that can be included.\n>> Such restrictions will be specified by those descriptors.\n>>\n>> The output script produced is:\n>> <pre>\n>> OP_DUP OP_HASH160 <KEY_hash160> OP_EQUALVERIFY OP_CHECKSIG\n>> </pre>\n>>\n>> ===<tt>sh()</tt>===\n>>\n>> The <tt>sh(SCRIPT)</tt> expression can only be used as a top level\n>> expression.\n>> It takes a single script expression as an argument and produces a P2SH\n>> output script.\n>> <tt>sh()</tt> expressions also create a redeemScript which is required\n>> in order to spend outputs which use its output script.\n>> This redeemScript is the output script produced by the <tt>SCRIPT</tt>\n>> argument to <tt>sh()</tt>.\n>>\n>> The output script produced is:\n>> <pre>\n>> OP_HASH160 <SCRIPT_hash160> OP_EQUAL\n>> </pre>\n>>\n>> ==Test Vectors==\n>>\n>> TBD\n>>\n>> ==Backwards Compatibility==\n>>\n>> <tt>pk()</tt>, <tt>pkh()</tt>, and <tt>sh()</tt> descriptors use the\n>> format and general operation specified in\n>> [[bip-descriptor-general.mediawiki|bip-descriptor-general]].\n>> As these are a wholly new descriptors, they are not compatible with any\n>> implementation.\n>> However the scripts produced are standard scripts so existing software\n>> are likely to be familiar with them.\n>>\n>> ==Reference Implemntation==\n>>\n>> <tt>pk()</tt>, <tt>pkh()</tt>, and <tt>sh()</tt> descriptors have been\n>> implemented in Bitcoin Core since version 0.17.\n>>\n>> ---\n>>\n>> <pre>\n>> BIP: bip-descriptors-tr\n>> Layer: Applications\n>> Title: tr() Output Script Descriptors\n>> Author: Pieter Wuille <pieter at wuille.net>\n>> Andrew Chow <andrew at achow101.com>\n>> Comments-Summary: No comments yet.\n>> Comments-URI:\n>> https://github.com/bitcoin/bips/wiki/Comments:BIP-descriptors-tr\n>> Status: Draft\n>> Type: Informational\n>> Created: 2021-06-27\n>> License: BSD-2-Clause\n>> </pre>\n>>\n>> ==Abstract==\n>>\n>> This document specifies <tt>tr()</tt> output script descriptors.\n>> <tt>tr()</tt> descriptors take a key and optionally a tree of scripts\n>> and produces a P2TR output script.\n>>\n>> ==Copyright==\n>>\n>> This BIP is licensed under the BSD 2-clause license.\n>>\n>> ==Motivation==\n>>\n>> Taproot added one additional standard output script format: P2TR.\n>> These expressions allow specifying those formats as a descriptor.\n>>\n>> ==Specification==\n>>\n>> A new script expressions are defined: <tt>tr()</tt>.\n>> A new expression is defined: Tree Expressions\n>>\n>> ===Tree Expression===\n>>\n>> A Tree Expression (denoted <tt>TREE</tt>) is an expression which\n>> represents a tree of scripts.\n>> The way the tree is represented in an output script is dependent on the\n>> higher level expressions.\n>>\n>> A Tree Expression is:\n>> * Any Script Expression that is allowed at the level this Tree\n>> Expression is in.\n>> * A pair of Tree Expressions consisting of:\n>> ** An open brace <tt>{</tt>\n>> ** A Tree Expression\n>> ** A comma <tt>,</tt>\n>> ** A Tree Expression\n>> ** A closing brance <tt>}</tt>\n>>\n>> ===<tt>tr()</tt>===\n>>\n>> The <tt>tr(KEY)</tt> or <tt>tr(KEY, TREE)</tt> expression can only be\n>> used as a top level expression.\n>> All key expressions under any <tt>tr()</tt> expression must create\n>> x-only public keys.\n>>\n>> <tt>tr(KEY</tt> takes a single key expression as an argument and\n>> produces a P2TR output script which does not have a script path.\n>> The keys produced by the key expression are used as the internal key as\n>> specified by [[bip-0341.mediawiki#cite_ref-22-0|BIP 341]].\n>> Specifically, \"If the spending conditions do not require a script path,\n>> the output key should commit to an unspendable script path instead of\n>> having no script path.\n>> This can be achieved by computing the output key point as ''Q = P +\n>> int(hash<sub>TapTweak</sub>(bytes(P)))G''.\"\n>>\n>> <pre>\n>> internal_key: lift_x(KEY)\n>> 32_byte_output_key: internal_key + int(HashTapTweak(bytes(internal_key)))G\n>> scriptPubKey: OP_1 <32_byte_output_key>\n>> </pre>\n>>\n>> <tt>tr(KEY, TREE)</tt> takes a key expression as the first argument, and\n>> a tree expression as the second argument and produces a P2TR output\n>> script which has a script path.\n>> The keys produced by the first key expression are used as the internal\n>> key as specified by\n>> [[bip-0341.mediawiki#Constructing_and_spending_Taproot_outputs|BIP 341]].\n>> The Tree expression becomes the Taproot script tree as described in BIP 341.\n>> A merkle root is computed from this tree and combined with the internal\n>> key to create the Taproot output key.\n>>\n>> <pre>\n>> internal_key: lift_x(KEY)\n>> merkle_root: HashTapBranch(TREE)\n>> 32_byte_output_key: internal_key + int(HashTapTweak(bytes(internal_key)\n>> || merkle_root))G\n>> scriptPubKey: OP_1 <32_byte_output_key>\n>> </pre>\n>>\n>> ==Test Vectors==\n>>\n>> TBD\n>>\n>> ==Backwards Compatibility==\n>>\n>> <tt>tr()</tt> descriptors use the format and general operation specified\n>> in [[bip-descriptor-general.mediawiki|bip-descriptor-general]].\n>> As these are a wholly new descriptors, they are not compatible with any\n>> implementation.\n>> However the scripts produced are standard scripts so existing software\n>> are likely to be familiar with them.\n>>\n>> Tree Expressions are largely incompatible with existing script\n>> expressions due to the restrictions in those expressions.\n>> As of 2021-06-27, the only allowed script expression that can be used in\n>> a tree expression is <tt>pk()</tt>.\n>> However there will be future BIPs that specify script expressions that\n>> can be used in tree expressions.\n>>\n>> ==Reference Implemntation==\n>>\n>> <tt>tr()</tt> descriptors have been implemented in Bitcoin Core since\n>> version 22.0.\n>>\n>> ---\n>>\n>> <pre>\n>> BIP: bip-descriptors-multi\n>> Layer: Applications\n>> Title: Multisig Output Script Descriptors\n>> Author: Pieter Wuille <pieter at wuille.net>\n>> Andrew Chow <andrew at achow101.com>\n>> Comments-Summary: No comments yet.\n>> Comments-URI:\n>> https://github.com/bitcoin/bips/wiki/Comments:BIP-descriptors-multi\n>> Status: Draft\n>> Type: Informational\n>> Created: 2021-06-27\n>> License: BSD-2-Clause\n>> </pre>\n>>\n>> ==Abstract==\n>>\n>> This document specifies <tt>multi()</tt>, and <tt>sortedmulti()</tt>\n>> output script descriptors.\n>> Both functions take a threshold and one or more public keys and produce\n>> a multisig output script.\n>> <tt>multi()</tt> specifies the public keys in the output script in the\n>> order given in the descriptor while <tt>sortedmulti()</tt> sorts the\n>> public keys lexicographically when the output script is produced.\n>>\n>> ==Copyright==\n>>\n>> This BIP is licensed under the BSD 2-clause license.\n>>\n>> ==Motivation==\n>>\n>> The most common complex script used in Bitcoin is a threshold multisig.\n>> These expressions allow specifying multisig scripts as a descriptor.\n>>\n>> ==Specification==\n>>\n>> Two new script expressions are defined: <tt>multi()</tt>, and\n>> <tt>sortedmulti()</tt>.\n>> Both expressions produce the scripts of the same template and take the\n>> same arguments.\n>> They are written as <tt>multi(k,KEY_1,KEY_2,...,KEY_n)</tt>.\n>> <tt>k</tt> is the threshold - the number of keys that must sign the\n>> input for the script to be valid.\n>> <tt>KEY_1,KEY_2,...,KEY_n</tt> are the key expressions for the multisig.\n>> <tt>k</tt> must be less than or equal to <tt>n<tt>.\n>>\n>> <tt>multi()</tt> and <tt>sortedmulti()</tt> expressions can be used as a\n>> top level expression, or inside of either a <tt>sh()</tt> or\n>> <tt>wsh()</tt> descriptor.\n>> Depending on the higher level descriptors, there may be restrictions on\n>> the type of public keys that can be included.\n>>\n>> Depending on the higher level descriptors, there are also restrictions\n>> on the number of keys that can be present, i.e. the maximum value of\n>> <tt>n</tt>.\n>> When used at the top level, there can only be at most 3 keys.\n>> When used inside of a <tt>sh()</tt> expression, there can only be most\n>> 15 compressed public keys (this is limited by the P2SH script limit).\n>> Otherwise the maximum number of keys is 20.\n>>\n>> The output script produced also depends on the value of <tt>k</tt>. If\n>> <tt>k</tt> is less than or equal to 16:\n>> <pre>\n>> OP_k KEY_1 KEY_2 ... KEY_n OP_CHECKMULTISIG\n>> </pre>\n>>\n>> if <tt>k</tt> is greater than 16:\n>> <pre>\n>> k KEY_1 KEY_2 ... KEY_n OP_CHECKMULTISIG\n>> </pre>\n>>\n>> ===<tt>sortedmulti()</tt>===\n>>\n>> The only change for <tt>sortedmulti()</tt> is that the keys are sorted\n>> lexicographically prior to the creation of the output script.\n>> This sorting is on the keys that are to be put into the output script,\n>> i.e. after all extended keys are derived.\n>>\n>> ===Multiple Extended Keys</tt>===\n>>\n>> When one or more the key expressions in a <tt>multi()</tt> or\n>> <tt>sortedmulti()</tt> expression are extended keys, the derived keys\n>> use the same child index.\n>> This changes the keys in lockstep and allows for output scripts to be\n>> indexed in the same way that the derived keys are indexed.\n>>\n>> ==Test Vectors==\n>>\n>> TBD\n>>\n>> ==Backwards Compatibility==\n>>\n>> <tt>multi()</tt>, and <tt>sortedmulti()</tt> descriptors use the format\n>> and general operation specified in\n>> [[bip-descriptor-general.mediawiki|bip-descriptor-general]].\n>> As these are a wholly new descriptors, they are not compatible with any\n>> implementation.\n>> However the scripts produced are standard scripts so existing software\n>> are likely to be familiar with them.\n>>\n>> ==Reference Implemntation==\n>>\n>> <tt>multi()</tt>, and <tt>multi()</tt> descriptors have been implemented\n>> in Bitcoin Core since version 0.17.\n>>\n>> ---\n>>\n>> <pre>\n>> BIP: bip-descriptors-combo\n>> Layer: Applications\n>> Title: combo() Output Script Descriptors\n>> Author: Pieter Wuille <pieter at wuille.net>\n>> Andrew Chow <andrew at achow101.com>\n>> Comments-Summary: No comments yet.\n>> Comments-URI:\n>> https://github.com/bitcoin/bips/wiki/Comments:BIP-descriptors-combo\n>> Status: Draft\n>> Type: Informational\n>> Created: 2021-06-27\n>> License: BSD-2-Clause\n>> </pre>\n>>\n>> ==Abstract==\n>>\n>> This document specifies <tt>combo()</tt> output script descriptors.\n>> These take a key and produce P2PK, P2PKH, P2WPKH, and P2SH-P2WPKH output\n>> scripts if applicable to the key.\n>>\n>> ==Copyright==\n>>\n>> This BIP is licensed under the BSD 2-clause license.\n>>\n>> ==Motivation==\n>>\n>> In order to make the transition from traditional key based wallets to\n>> descriptor based wallets easier, it is useful to be able to take a key\n>> and produce the scripts which have traditionally been produced by wallet\n>> software.\n>>\n>> ==Specification==\n>>\n>> A new top level script expression is defined: <tt>combo(KEY)</tt>.\n>> This expression can only be used as a top level expression.\n>> It takes a single key expression as an argument and produces either 2 or\n>> 4 output scripts, depending on the key.\n>> A <tt>combo()</tt> expression always produces a P2PK and P2PKH script,\n>> the same as putting the key in both a <tt>pk()</tt> and a <tt>pkh()</tt>\n>> expression.\n>> If the key is/has a compressed public key, then P2WPKH and P2SH-P2WPKH\n>> scripts are also produced, the same as putting the key in both a\n>> <tt>wpkh()</tt> and <tt>sh(wpkh())</tt> expression.\n>>\n>> ==Test Vectors==\n>>\n>> TBD\n>>\n>> ==Backwards Compatibility==\n>>\n>> <tt>combo()</tt> descriptors use the format and general operation\n>> specified in [[bip-descriptor-general.mediawiki|bip-descriptor-general]].\n>> As this is a wholly new descriptor, it is not compatible with any\n>> implementation.\n>> However the scripts produced are standard scripts so existing software\n>> are likely to be familiar with them.\n>>\n>> ==Reference Implemntation==\n>>\n>> <tt>combo</tt> descriptors have been implemented in Bitcoin Core since\n>> version 0.17.\n>>\n>> ---\n>>\n>> <pre>\n>> BIP: bip-descriptors-encap\n>> Layer: Applications\n>> Title: raw() and addr() Output Script Descriptors\n>> Author: Andrew Chow <andrew at achow101.com>\n>> Pieter Wuille <pieter at wuille.net>\n>> Comments-Summary: No comments yet.\n>> Comments-URI:\n>> https://github.com/bitcoin/bips/wiki/Comments:BIP-descriptors-raw\n>> Status: Draft\n>> Type: Informational\n>> Created: 2021-06-27\n>> License: BSD-2-Clause\n>> </pre>\n>>\n>> ==Abstract==\n>>\n>> This document specifies <tt>raw()</tt> and <tt>addr()</tt> output script\n>> descriptors.\n>> <tt>raw()</tt> encapsulates a raw script as a descriptor.\n>> <tt>addr()</tt> encapsulates an address as a descriptor.\n>>\n>> ==Copyright==\n>>\n>> This BIP is licensed under the BSD 2-clause license.\n>>\n>> ==Motivation==\n>>\n>> In order to make descriptors maximally compatible with scripts in use\n>> today, it is useful to be able to wrap any arbitrary output script or an\n>> address into a descriptor.\n>>\n>> ==Specification==\n>>\n>> Two new script expressions are defined: <tt>raw()</tt> and <tt>addr()</tt>.\n>>\n>> ===<tt>raw()</tt>===\n>>\n>> The <tt>raw(HEX)</tt> expression can only be used as a top level descriptor.\n>> As the argument, it takes a hex string representing a Bitcoin script.\n>> The output script produced by this descriptor is the script represented\n>> by <tt>HEX</tt>.\n>>\n>> ===<tt>addr()</tt>===\n>>\n>> The <tt>addr(ADDR)</tt> expression can only be used as a top level\n>> descriptor.\n>> It takes an address as its single argument.\n>> The output script produced by this descriptor is the output script\n>> produced by the address <tt>ADDR</tt>.\n>>\n>> ==Test Vectors==\n>>\n>> TBD\n>>\n>> ==Backwards Compatibility==\n>>\n>> <tt>raw()</tt> and <tt>addr()</tt> descriptors use the format and\n>> general operation specified in\n>> [[bip-descriptor-general.mediawiki|bip-descriptor-general]].\n>> As this is a wholly new descriptor, it is not compatible with any\n>> implementation.\n>> The reuse of existing Bitcoin addresses allows for this to be more\n>> easily implemented.\n>>\n>> ==Reference Implemntation==\n>>\n>> <tt>raw()</tt> and <tt>addr</tt> descriptors have been implemented in\n>> Bitcoin Core since version 0.17.\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210702/12a7e13b/attachment-0001.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2021-07-03T03:24:05",
                "message_text_only": "On Tue, Jun 29, 2021 at 09:14:39PM +0000, Andrew Chow via bitcoin-dev wrote:\n> *** Optionally followed by a single <tt>/*</tt> or <tt>/*'</tt> final\n> step to denote all direct unhardened or hardened children.\n> \n> [...]\n> \n> In the above specification, the hardened indicator <tt>'</tt> may be\n> replaced with alternative hardnened indicators of <tt>h</tt> or <tt>H</tt>.\n\nIs there any chance we can take this opportunity to make \"h\"/\"H\" the\npreferred aliases?  Using \"'\" in bourne-style shells is very\nannoying[1], and I suspect it's also creating unnecessary complications\nelsewhere.\n\nAlternatives:\n\n- Completely kill \"'\" (I'd prefer this, but I realize it's complicated\n  with descriptors already being used widely).  If \"h\"/\"H\" are made the\n  preferred aliases, maybe it'd be enough to make implementing \"'\" a\n  SHOULD rather than a MUST; this would push implementations towards\n  displaying descriptors using the h versions for maximum compatibility.\n\n- Calculate the checksum over s/(h|H)/'/ (again, I know that's\n  complicated with descriptors already widely used)\n\nThanks,\n\n-Dave\n\n[1] https://github.com/bitcoin/bitcoin/issues/15740#issuecomment-695815432\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210702/ea8e1323/attachment.sig>"
            },
            {
                "author": "Andrew Chow",
                "date": "2021-07-03T05:12:35",
                "message_text_only": "On 7/2/21 11:24 PM, David A. Harding wrote:\n> Is there any chance we can take this opportunity to make \"h\"/\"H\" the\n> preferred aliases?  Using \"'\" in bourne-style shells is very\n> annoying[1], and I suspect it's also creating unnecessary complications\n> elsewhere.\nI've updated the text to use \"h\".\n> Alternatives:\n>\n> - Completely kill \"'\" (I'd prefer this, but I realize it's complicated\n>    with descriptors already being used widely).  If \"h\"/\"H\" are made the\n>    preferred aliases, maybe it'd be enough to make implementing \"'\" a\n>    SHOULD rather than a MUST; this would push implementations towards\n>    displaying descriptors using the h versions for maximum compatibility.\nSince there already are software implementing descriptors, I don't think\nwe can do this. I'm not sure about making \"'\" a SHOULD either.\n> - Calculate the checksum over s/(h|H)/'/ (again, I know that's\n>    complicated with descriptors already widely used)\nThis has been discussed in the past and the conclusion was that the\nchecksum should be strictly over the string itself. This would allow for\ndumb checksum checkers which don't have to be able to parse descriptors\nin order to check the checksum.\n\nThanks,\nAndrew\n\n>\n> Thanks,\n>\n> -Dave\n>\n> [1] https://github.com/bitcoin/bitcoin/issues/15740#issuecomment-695815432"
            },
            {
                "author": "Craig Raw",
                "date": "2021-07-03T08:35:48",
                "message_text_only": "There is a downside to using \"h\"/\"H\" from a UX perspective - taking up more\nspace and appearing as alphanumeric characters similar to the path numbers,\nthey make derivation paths and descriptors more difficult to read. Also,\nalthough not as important, less efficient when making metal backups.\n\nOn Sat, Jul 3, 2021 at 7:13 AM Andrew Chow via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On 7/2/21 11:24 PM, David A. Harding wrote:\n> > Is there any chance we can take this opportunity to make \"h\"/\"H\" the\n> > preferred aliases?  Using \"'\" in bourne-style shells is very\n> > annoying[1], and I suspect it's also creating unnecessary complications\n> > elsewhere.\n> I've updated the text to use \"h\".\n> > Alternatives:\n> >\n> > - Completely kill \"'\" (I'd prefer this, but I realize it's complicated\n> >    with descriptors already being used widely).  If \"h\"/\"H\" are made the\n> >    preferred aliases, maybe it'd be enough to make implementing \"'\" a\n> >    SHOULD rather than a MUST; this would push implementations towards\n> >    displaying descriptors using the h versions for maximum compatibility.\n> Since there already are software implementing descriptors, I don't think\n> we can do this. I'm not sure about making \"'\" a SHOULD either.\n> > - Calculate the checksum over s/(h|H)/'/ (again, I know that's\n> >    complicated with descriptors already widely used)\n> This has been discussed in the past and the conclusion was that the\n> checksum should be strictly over the string itself. This would allow for\n> dumb checksum checkers which don't have to be able to parse descriptors\n> in order to check the checksum.\n>\n> Thanks,\n> Andrew\n>\n> >\n> > Thanks,\n> >\n> > -Dave\n> >\n> > [1]\n> https://github.com/bitcoin/bitcoin/issues/15740#issuecomment-695815432\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210703/204d7572/attachment-0001.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2021-07-03T10:05:40",
                "message_text_only": "On Sat, Jul 03, 2021 at 10:35:48AM +0200, Craig Raw wrote:\n> There is a downside to using \"h\"/\"H\" from a UX perspective - taking up more\n> space \n\nIs this a serious concern of yours?  An apostrophe is 1/2 en; an \"h\" is\n1 en; the following descriptor contains three hardened derivations in 149\ncharacters; assuming the average non-'/h character width is 1.5 en, the\ndifference between 207 en and 208.5 en is barely more than half a\npercent.\n\n    pkh([d34db33f/44h/0h/0h]xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL/1/*)#ml40v0wf\n\nHere's a direct visual comparison: https://gist.github.com/harding/2fbbf2bfdce04c3e4110082f03ae3c80\n\n> appearing as alphanumeric characters similar to the path numbers\n\nFirst, I think you'd have to be using an awful font to confuse \"h\" with\nany arabic numeral.  Second, avoiding transcription errors is exactly\nwhy descriptors now have checksums.\n\n> they make derivation paths and descriptors more difficult to read.\n\nThe example descriptor pasted above looks equally (un)readable to me\nwhether it uses ' or h.\n\n> Also, although not as important, less efficient when making metal\n> backups.\n\nI think many metal backup schemes are using stamps or punch grids that\nare fixed-width in nature, so there's no difference either way.  (And\nyou can argue that h is better since it's part of both the base58check\nand bech32 character sets, so you already need a stamp or a grid row for\nit---but ' is otherwise unused, so a stamp or grid row for it would be\nspecial).\n\nBut even if people are manually etching descriptors into metal, we're\nback to the original point where we're looking at something like a 0.7%\ndifference in \"efficiency\".\n\nBy comparison, the Bitcoin Core issue I cited in my earlier post\ncontains several examples of actual users needing technical support\nbecause they tried to use '-containing descriptors in a bourne-style\nshell.  (And I've personally lost time to that class of problems.)  In\nthe worst case, a shell-quoting accident can cause loss of money by\nsending bitcoins to the descriptor for a key your hardware signing\ndevice won't sign for.  I think these problems are much more serious\nthan using a tiny bit of extra space in a GUI or on a physical backup\nmedium.\n\n-Dave\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210703/ac399f1f/attachment-0001.sig>"
            },
            {
                "author": "Craig Raw",
                "date": "2021-07-03T14:00:51",
                "message_text_only": "It's a consideration, not a serious concern.\n\nWhen I made the point around alphanumeric characters being similar to the\npath numbers, I was actually thinking of the output descriptor appearing in\na fixed character width font, which I prefer as more appropriate for\ndisplaying hexidecimal values. In this case, the apostrophe provides more\nwhitespace which makes the path easier to parse visually. It's difficult to\nreduce this to a mathematical argument, as is true for many UX\nconsiderations. Your example in fixed width here:\nhttps://gist.github.com/craigraw/fc98b9031a7e01e1bc5d75a77bdb72e5\n\nThat said you make good arguments around the shell quoting and stamps for\nmetal backups, and therefore I agree it is preferable to use the lowercase\n\"h\". Thanks for the detailed reply.\n\nCraig\n\nOn Sat, Jul 3, 2021 at 12:11 PM David A. Harding <dave at dtrt.org> wrote:\n\n> On Sat, Jul 03, 2021 at 10:35:48AM +0200, Craig Raw wrote:\n> > There is a downside to using \"h\"/\"H\" from a UX perspective - taking up\n> more\n> > space\n>\n> Is this a serious concern of yours?  An apostrophe is 1/2 en; an \"h\" is\n> 1 en; the following descriptor contains three hardened derivations in 149\n> characters; assuming the average non-'/h character width is 1.5 en, the\n> difference between 207 en and 208.5 en is barely more than half a\n> percent.\n>\n>\n> pkh([d34db33f/44h/0h/0h]xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL/1/*)#ml40v0wf\n>\n> Here's a direct visual comparison:\n> https://gist.github.com/harding/2fbbf2bfdce04c3e4110082f03ae3c80\n>\n> > appearing as alphanumeric characters similar to the path numbers\n>\n> First, I think you'd have to be using an awful font to confuse \"h\" with\n> any arabic numeral.  Second, avoiding transcription errors is exactly\n> why descriptors now have checksums.\n>\n> > they make derivation paths and descriptors more difficult to read.\n>\n> The example descriptor pasted above looks equally (un)readable to me\n> whether it uses ' or h.\n>\n> > Also, although not as important, less efficient when making metal\n> > backups.\n>\n> I think many metal backup schemes are using stamps or punch grids that\n> are fixed-width in nature, so there's no difference either way.  (And\n> you can argue that h is better since it's part of both the base58check\n> and bech32 character sets, so you already need a stamp or a grid row for\n> it---but ' is otherwise unused, so a stamp or grid row for it would be\n> special).\n>\n> But even if people are manually etching descriptors into metal, we're\n> back to the original point where we're looking at something like a 0.7%\n> difference in \"efficiency\".\n>\n> By comparison, the Bitcoin Core issue I cited in my earlier post\n> contains several examples of actual users needing technical support\n> because they tried to use '-containing descriptors in a bourne-style\n> shell.  (And I've personally lost time to that class of problems.)  In\n> the worst case, a shell-quoting accident can cause loss of money by\n> sending bitcoins to the descriptor for a key your hardware signing\n> device won't sign for.  I think these problems are much more serious\n> than using a tiny bit of extra space in a GUI or on a physical backup\n> medium.\n>\n> -Dave\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210703/3a46f38d/attachment.html>"
            },
            {
                "author": "Daniel Bayerdorffer",
                "date": "2021-07-04T17:56:28",
                "message_text_only": "Hello, \n\nI just wanted to put my two cents in, on the metal backup aspect. We make the Bitcoin Recovery Tag for a similar purpose. We use a fixed font, so using ' (apostrophe) or H/h are both acceptable. Most metal stamping tools are fixed width fonts. \n\nYou can see a picture here... \n[ https://cyphersafe.io/product/bitcoin-recovery-tag/ | https://cyphersafe.io/product/bitcoin-recovery-tag/ ] \n\nThanks, \nDaniel \n\n-- \nDaniel Bayerdorffer, VP danielb at numberall.com \nNumberall Stamp & Tool Co., Inc. www.numberall.com \nReuleaux Models www.reuleauxmodels.com \nCypherSafe www.cyphersafe.io \nPO BOX 187, Sangerville, ME 04479 USA \nTEL: 207-876-3541 FAX: 207-876-3566 \n\n\nFrom: \"Craig Raw via bitcoin-dev\" <bitcoin-dev at lists.linuxfoundation.org> \nTo: \"David A. Harding\" <dave at dtrt.org> \nCc: \"Bitcoin Protocol Discussion\" <bitcoin-dev at lists.linuxfoundation.org> \nSent: Saturday, July 3, 2021 10:00:51 AM \nSubject: Re: [bitcoin-dev] BIP Proposals for Output Script Descriptors \n\nIt's a consideration, not a serious concern. \nWhen I made the point around alphanumeric characters being similar to the path numbers, I was actually thinking of the output descriptor appearing in a fixed character width font, which I prefer as more appropriate for displaying hexidecimal values. In this case, the apostrophe provides more whitespace which makes the path easier to parse visually. It's difficult to reduce this to a mathematical argument, as is true for many UX considerations. Your example in fixed width here: [ https://gist.github.com/craigraw/fc98b9031a7e01e1bc5d75a77bdb72e5 | https://gist.github.com/craigraw/fc98b9031a7e01e1bc5d75a77bdb72e5 ] \n\nThat said you make good arguments around the shell quoting and stamps for metal backups, and therefore I agree it is preferable to use the lowercase \"h\". Thanks for the detailed reply. \n\nCraig \n\nOn Sat, Jul 3, 2021 at 12:11 PM David A. Harding < [ mailto:dave at dtrt.org | dave at dtrt.org ] > wrote: \n\n\nOn Sat, Jul 03, 2021 at 10:35:48AM +0200, Craig Raw wrote: \n> There is a downside to using \"h\"/\"H\" from a UX perspective - taking up more \n> space \n\nIs this a serious concern of yours? An apostrophe is 1/2 en; an \"h\" is \n1 en; the following descriptor contains three hardened derivations in 149 \ncharacters; assuming the average non-'/h character width is 1.5 en, the \ndifference between 207 en and 208.5 en is barely more than half a \npercent. \n\npkh([d34db33f/44h/0h/0h]xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL/1/*)#ml40v0wf \n\nHere's a direct visual comparison: [ https://gist.github.com/harding/2fbbf2bfdce04c3e4110082f03ae3c80 | https://gist.github.com/harding/2fbbf2bfdce04c3e4110082f03ae3c80 ] \n\n> appearing as alphanumeric characters similar to the path numbers \n\nFirst, I think you'd have to be using an awful font to confuse \"h\" with \nany arabic numeral. Second, avoiding transcription errors is exactly \nwhy descriptors now have checksums. \n\n> they make derivation paths and descriptors more difficult to read. \n\nThe example descriptor pasted above looks equally (un)readable to me \nwhether it uses ' or h. \n\n> Also, although not as important, less efficient when making metal \n> backups. \n\nI think many metal backup schemes are using stamps or punch grids that \nare fixed-width in nature, so there's no difference either way. (And \nyou can argue that h is better since it's part of both the base58check \nand bech32 character sets, so you already need a stamp or a grid row for \nit---but ' is otherwise unused, so a stamp or grid row for it would be \nspecial). \n\nBut even if people are manually etching descriptors into metal, we're \nback to the original point where we're looking at something like a 0.7% \ndifference in \"efficiency\". \n\nBy comparison, the Bitcoin Core issue I cited in my earlier post \ncontains several examples of actual users needing technical support \nbecause they tried to use '-containing descriptors in a bourne-style \nshell. (And I've personally lost time to that class of problems.) In \nthe worst case, a shell-quoting accident can cause loss of money by \nsending bitcoins to the descriptor for a key your hardware signing \ndevice won't sign for. I think these problems are much more serious \nthan using a tiny bit of extra space in a GUI or on a physical backup \nmedium. \n\n-Dave \n\n\n\n\n_______________________________________________ \nbitcoin-dev mailing list \nbitcoin-dev at lists.linuxfoundation.org \nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev \n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210704/5ab210fd/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP Proposals for Output Script Descriptors",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Andrew Chow",
                "Craig Raw",
                "David A. Harding",
                "Daniel Bayerdorffer"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 48105
        }
    },
    {
        "title": "[bitcoin-dev] CheckSigFromStack for Arithmetic Values",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2021-07-02T22:20:16",
                "message_text_only": "Dear Bitcoin Devs,\n\nIt recently occurred to me that it's possible to do a lamport signature in\nscript for arithmetic values by using a binary expanded representation.\nThere are some applications that might benefit from this and I don't recall\nseeing it discussed elsewhere, but would be happy for a citation/reference\nto the technique.\n\nblog post here, https://rubin.io/blog/2021/07/02/signing-5-bytes/, text\nreproduced below\n\nThere are two insights in this post:\n\n1. to use a bitwise expansion of the number\n2. to use a lamport signature\n\nLet's look at the code in python and then translate to bitcoin script:\n\n```python\ndef add_bit(idx, preimage, image_0, image_1):\n    s = sha256(preimage)\n    if s == image_1:\n        return (1 << idx)\n    if s == image_0:\n        return 0\n    else:\n        assert False\n\ndef get_signed_number(witnesses : List[Hash], keys : List[Tuple[Hash,\nHash]]):\n    acc = 0\n    for (idx, preimage) in enumerate(witnesses):\n        acc += add_bit(idx, preimage, keys[idx][0], keys[idx][1])\n    return x\n```\n\nSo what's going on here? The signer generates a key which is a list of\npairs of\nhash images to create the script.\n\nTo sign, the signer provides a witness of a list of preimages that match\none or the other.\n\nDuring validation, the network adds up a weighted value per preimage and\nchecks\nthat there are no left out values.\n\nLet's imagine a concrete use case: I want a third party to post-hoc sign a\nsequence lock. This is 16 bits.\nI can form the following script:\n\n\n```\n<pk> checksigverify\n0\nSWAP sha256 DUP <H(K_0_1)> EQUAL IF DROP <1> ADD ELSE <H(K_0_0)>\nEQUALVERIFY ENDIF\nSWAP sha256 DUP <H(K_1_1)> EQUAL IF DROP <1<<1> ADD ELSE <H(K_1_0)>\nEQUALVERIFY ENDIF\nSWAP sha256 DUP <H(K_2_1)> EQUAL IF DROP <1<<2> ADD ELSE <H(K_2_0)>\nEQUALVERIFY ENDIF\nSWAP sha256 DUP <H(K_3_1)> EQUAL IF DROP <1<<3> ADD ELSE <H(K_3_0)>\nEQUALVERIFY ENDIF\nSWAP sha256 DUP <H(K_4_1)> EQUAL IF DROP <1<<4> ADD ELSE <H(K_4_0)>\nEQUALVERIFY ENDIF\nSWAP sha256 DUP <H(K_5_1)> EQUAL IF DROP <1<<5> ADD ELSE <H(K_5_0)>\nEQUALVERIFY ENDIF\nSWAP sha256 DUP <H(K_6_1)> EQUAL IF DROP <1<<6> ADD ELSE <H(K_6_0)>\nEQUALVERIFY ENDIF\nSWAP sha256 DUP <H(K_7_1)> EQUAL IF DROP <1<<7> ADD ELSE <H(K_7_0)>\nEQUALVERIFY ENDIF\nSWAP sha256 DUP <H(K_8_1)> EQUAL IF DROP <1<<8> ADD ELSE <H(K_8_0)>\nEQUALVERIFY ENDIF\nSWAP sha256 DUP <H(K_9_1)> EQUAL IF DROP <1<<9> ADD ELSE <H(K_9_0)>\nEQUALVERIFY ENDIF\nSWAP sha256 DUP <H(K_10_1)> EQUAL IF DROP <1<<10> ADD ELSE <H(K_10_0)>\nEQUALVERIFY ENDIF\nSWAP sha256 DUP <H(K_11_1)> EQUAL IF DROP <1<<11> ADD ELSE <H(K_11_0)>\nEQUALVERIFY ENDIF\nSWAP sha256 DUP <H(K_12_1)> EQUAL IF DROP <1<<12> ADD ELSE <H(K_12_0)>\nEQUALVERIFY ENDIF\nSWAP sha256 DUP <H(K_13_1)> EQUAL IF DROP <1<<13> ADD ELSE <H(K_13_0)>\nEQUALVERIFY ENDIF\nSWAP sha256 DUP <H(K_14_1)> EQUAL IF DROP <1<<14> ADD ELSE <H(K_14_0)>\nEQUALVERIFY ENDIF\nSWAP sha256 DUP <H(K_15_1)> EQUAL IF DROP <1<<15> ADD ELSE <H(K_15_0)>\nEQUALVERIFY ENDIF\nCHECKSEQUENCEVERIFY\n```\n\nIn order to sign a 16 bit value V, the owner of K simply puts on the stack\nthe\nbinary representation of V indexed into the K. E.g., to sign `53593`, first\nexpand to binary `0b1101000101011001`, then put the appropriate K values on\nthe\nstack.\n\n```\nK_15_1\nK_14_1\nK_13_0\nK_12_1\nK_11_0\nK_10_0\nK_9_0\nK_8_1\nK_7_0\nK_6_1\nK_5_0\nK_4_1\nK_3_1\nK_2_0\nK_1_0\nK_0_1\n<sig>\n```\n\n\nThis technique is kind of bulky! It's around 80x16 = 1280 length for the\ngadget, and 528 bytes for the witnesses. So it is _doable_, if not a bit\nexpensive. There might be some more efficient scripts for this -- would a\ntrinary representation be more efficient?\n\nThe values that can be signed can be range limited either post-hoc (using\nOP\\_WITHIN) or internally as was done with the 16 bit value circuit where\nit's\nimpossible to do more than 16 bits.\n\nKeys *can* be reused across scripts, but signatures may only be constructed\none\ntime because a third party could take two signed messages and construct an\nunintended value (e.g., if you sign both 4 and 2 then a third party could\nconstruct 6).\n\nThere are certain applications where this could be used for an effect -- for\nexample, an oracle might have a bonding contract whereby possessing any\nK\\_i\\_0\nand K\\_i\\_1 allows the burning of funds.\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210702/35d44430/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-07-02T23:58:14",
                "message_text_only": "Good morning Jeremy,\n\n> Dear Bitcoin Devs,\n>\n> It recently occurred to me that it's possible to do a lamport signature in script for arithmetic values by using a binary expanded representation. There are some applications that might benefit from this and I don't recall seeing it discussed elsewhere, but would be happy for a citation/reference to the technique.\n>\n> blog post here, https://rubin.io/blog/2021/07/02/signing-5-bytes/, text reproduced below\n>\n> There are two insights in this post:\n> 1. to use a bitwise expansion of the number\n> 2. to use a lamport signature\n> Let's look at the code in python and then translate to bitcoin script:\n> ```python\n> def add_bit(idx, preimage, image_0, image_1):\n> \u00a0 \u00a0 s = sha256(preimage)\n> \u00a0 \u00a0 if s == image_1:\n> \u00a0 \u00a0 \u00a0 \u00a0 return (1 << idx)\n> \u00a0 \u00a0 if s == image_0:\n> \u00a0 \u00a0 \u00a0 \u00a0 return 0\n> \u00a0 \u00a0 else:\n> \u00a0 \u00a0 \u00a0 \u00a0 assert False\n> def get_signed_number(witnesses : List[Hash], keys : List[Tuple[Hash, Hash]]):\n> \u00a0 \u00a0 acc = 0\n> \u00a0 \u00a0 for (idx, preimage) in enumerate(witnesses):\n> \u00a0 \u00a0 \u00a0 \u00a0 acc += add_bit(idx, preimage, keys[idx][0], keys[idx][1])\n> \u00a0 \u00a0 return x\n> ```\n> So what's going on here? The signer generates a key which is a list of pairs of\n> hash images to create the script.\n> To sign, the signer provides a witness of a list of preimages that match one or the other.\n> During validation, the network adds up a weighted value per preimage and checks\n> that there are no left out values.\n> Let's imagine a concrete use case: I want a third party to post-hoc sign a sequence lock. This is 16 bits.\n> I can form the following script:\n> ```\n> <pk> checksigverify\n> 0\n> SWAP sha256 DUP <H(K_0_1)> EQUAL IF DROP <1> ADD ELSE <H(K_0_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_1_1)> EQUAL IF DROP <1<<1> ADD ELSE <H(K_1_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_2_1)> EQUAL IF DROP <1<<2> ADD ELSE <H(K_2_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_3_1)> EQUAL IF DROP <1<<3> ADD ELSE <H(K_3_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_4_1)> EQUAL IF DROP <1<<4> ADD ELSE <H(K_4_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_5_1)> EQUAL IF DROP <1<<5> ADD ELSE <H(K_5_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_6_1)> EQUAL IF DROP <1<<6> ADD ELSE <H(K_6_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_7_1)> EQUAL IF DROP <1<<7> ADD ELSE <H(K_7_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_8_1)> EQUAL IF DROP <1<<8> ADD ELSE <H(K_8_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_9_1)> EQUAL IF DROP <1<<9> ADD ELSE <H(K_9_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_10_1)> EQUAL IF DROP <1<<10> ADD ELSE <H(K_10_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_11_1)> EQUAL IF DROP <1<<11> ADD ELSE <H(K_11_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_12_1)> EQUAL IF DROP <1<<12> ADD ELSE <H(K_12_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_13_1)> EQUAL IF DROP <1<<13> ADD ELSE <H(K_13_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_14_1)> EQUAL IF DROP <1<<14> ADD ELSE <H(K_14_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_15_1)> EQUAL IF DROP <1<<15> ADD ELSE <H(K_15_0)> EQUALVERIFY ENDIF\n> CHECKSEQUENCEVERIFY\n> ```\n\nThis took a bit of thinking to understand, mostly because you use the `<<` operator in a syntax that uses `< >` as delimiters, which was mildly confusing --- at first I thought you were pushing some kind of nested SCRIPT representation, but in any case, replacing it with the actual numbers is a little less confusing on the syntax front, and I think (hope?) most people who can understand `1<<1` have also memorized the first few powers of 2....\n\n> ```\n> <pk> checksigverify\n> 0\n> SWAP sha256 DUP <H(K_0_1)> EQUAL IF DROP <1> ADD ELSE <H(K_0_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_1_1)> EQUAL IF DROP <2> ADD ELSE <H(K_1_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_2_1)> EQUAL IF DROP <4> ADD ELSE <H(K_2_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_3_1)> EQUAL IF DROP <8> ADD ELSE <H(K_3_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_4_1)> EQUAL IF DROP <16> ADD ELSE <H(K_4_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_5_1)> EQUAL IF DROP <32> ADD ELSE <H(K_5_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_6_1)> EQUAL IF DROP <64> ADD ELSE <H(K_6_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_7_1)> EQUAL IF DROP <128> ADD ELSE <H(K_7_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_8_1)> EQUAL IF DROP <256> ADD ELSE <H(K_8_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_9_1)> EQUAL IF DROP <512> ADD ELSE <H(K_9_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_10_1)> EQUAL IF DROP <1024> ADD ELSE <H(K_10_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_11_1)> EQUAL IF DROP <2048> ADD ELSE <H(K_11_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_12_1)> EQUAL IF DROP <4096> ADD ELSE <H(K_12_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_13_1)> EQUAL IF DROP <8192> ADD ELSE <H(K_13_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_14_1)> EQUAL IF DROP <16384> ADD ELSE <H(K_14_0)> EQUALVERIFY ENDIF\n> SWAP sha256 DUP <H(K_15_1)> EQUAL IF DROP <32768> ADD ELSE <H(K_15_0)> EQUALVERIFY ENDIF\n> CHECKSEQUENCEVERIFY\n> ```\n\nOn the other hand LOL WTF, this is cool.\n\nBasically you are showing that if we enable something as innocuous as `OP_ADD`, we can implement Lamport signatures for **arbitrary** values representable in small binary numbers (16 bits in the above example).\n\nI was thinking \"why not Merkle signatures\" since the pubkey would be much smaller but the signature would be much larger, but (a) the SCRIPT would be much more complicated and (b) in modern Bitcoin, the above SCRIPT would be in the witness stack anyway so there is no advantage to pushing the size towards the signature rather than the pubkey, they all have the same weight, and since both Lamport and Merkle are single-use-only and we do not want to encourage pubkey reuse even if they were not, the Merkle has much larger signature size, so Merkle sigs end up more expensive.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Jeremy",
                "date": "2021-07-03T04:01:01",
                "message_text_only": "Yep -- sorry for the confusing notation but seems like you got it. C++\ntemplates have this issue too btw :)\n\nOne cool thing is that if you have op_add for arbitrary width integers or\nop_cat you can also make a quantum proof signature by signing the signature\nmade with checksig with the lamport.\n\nThere are a couple gotchas wrt crypto assumptions on that but I'll write it\nup soon \ud83d\ude42 it also works better in segwit V0 because there's no keypath\nspend -- that breaks the quantum proofness of this scheme.\n\nOn Fri, Jul 2, 2021, 4:58 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Jeremy,\n>\n> > Dear Bitcoin Devs,\n> >\n> > It recently occurred to me that it's possible to do a lamport signature\n> in script for arithmetic values by using a binary expanded representation.\n> There are some applications that might benefit from this and I don't recall\n> seeing it discussed elsewhere, but would be happy for a citation/reference\n> to the technique.\n> >\n> > blog post here, https://rubin.io/blog/2021/07/02/signing-5-bytes/, text\n> reproduced below\n> >\n> > There are two insights in this post:\n> > 1. to use a bitwise expansion of the number\n> > 2. to use a lamport signature\n> > Let's look at the code in python and then translate to bitcoin script:\n> > ```python\n> > def add_bit(idx, preimage, image_0, image_1):\n> >     s = sha256(preimage)\n> >     if s == image_1:\n> >         return (1 << idx)\n> >     if s == image_0:\n> >         return 0\n> >     else:\n> >         assert False\n> > def get_signed_number(witnesses : List[Hash], keys : List[Tuple[Hash,\n> Hash]]):\n> >     acc = 0\n> >     for (idx, preimage) in enumerate(witnesses):\n> >         acc += add_bit(idx, preimage, keys[idx][0], keys[idx][1])\n> >     return x\n> > ```\n> > So what's going on here? The signer generates a key which is a list of\n> pairs of\n> > hash images to create the script.\n> > To sign, the signer provides a witness of a list of preimages that match\n> one or the other.\n> > During validation, the network adds up a weighted value per preimage and\n> checks\n> > that there are no left out values.\n> > Let's imagine a concrete use case: I want a third party to post-hoc sign\n> a sequence lock. This is 16 bits.\n> > I can form the following script:\n> > ```\n> > <pk> checksigverify\n> > 0\n> > SWAP sha256 DUP <H(K_0_1)> EQUAL IF DROP <1> ADD ELSE <H(K_0_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_1_1)> EQUAL IF DROP <1<<1> ADD ELSE <H(K_1_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_2_1)> EQUAL IF DROP <1<<2> ADD ELSE <H(K_2_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_3_1)> EQUAL IF DROP <1<<3> ADD ELSE <H(K_3_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_4_1)> EQUAL IF DROP <1<<4> ADD ELSE <H(K_4_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_5_1)> EQUAL IF DROP <1<<5> ADD ELSE <H(K_5_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_6_1)> EQUAL IF DROP <1<<6> ADD ELSE <H(K_6_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_7_1)> EQUAL IF DROP <1<<7> ADD ELSE <H(K_7_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_8_1)> EQUAL IF DROP <1<<8> ADD ELSE <H(K_8_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_9_1)> EQUAL IF DROP <1<<9> ADD ELSE <H(K_9_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_10_1)> EQUAL IF DROP <1<<10> ADD ELSE <H(K_10_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_11_1)> EQUAL IF DROP <1<<11> ADD ELSE <H(K_11_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_12_1)> EQUAL IF DROP <1<<12> ADD ELSE <H(K_12_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_13_1)> EQUAL IF DROP <1<<13> ADD ELSE <H(K_13_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_14_1)> EQUAL IF DROP <1<<14> ADD ELSE <H(K_14_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_15_1)> EQUAL IF DROP <1<<15> ADD ELSE <H(K_15_0)>\n> EQUALVERIFY ENDIF\n> > CHECKSEQUENCEVERIFY\n> > ```\n>\n> This took a bit of thinking to understand, mostly because you use the `<<`\n> operator in a syntax that uses `< >` as delimiters, which was mildly\n> confusing --- at first I thought you were pushing some kind of nested\n> SCRIPT representation, but in any case, replacing it with the actual\n> numbers is a little less confusing on the syntax front, and I think (hope?)\n> most people who can understand `1<<1` have also memorized the first few\n> powers of 2....\n>\n> > ```\n> > <pk> checksigverify\n> > 0\n> > SWAP sha256 DUP <H(K_0_1)> EQUAL IF DROP <1> ADD ELSE <H(K_0_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_1_1)> EQUAL IF DROP <2> ADD ELSE <H(K_1_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_2_1)> EQUAL IF DROP <4> ADD ELSE <H(K_2_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_3_1)> EQUAL IF DROP <8> ADD ELSE <H(K_3_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_4_1)> EQUAL IF DROP <16> ADD ELSE <H(K_4_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_5_1)> EQUAL IF DROP <32> ADD ELSE <H(K_5_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_6_1)> EQUAL IF DROP <64> ADD ELSE <H(K_6_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_7_1)> EQUAL IF DROP <128> ADD ELSE <H(K_7_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_8_1)> EQUAL IF DROP <256> ADD ELSE <H(K_8_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_9_1)> EQUAL IF DROP <512> ADD ELSE <H(K_9_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_10_1)> EQUAL IF DROP <1024> ADD ELSE <H(K_10_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_11_1)> EQUAL IF DROP <2048> ADD ELSE <H(K_11_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_12_1)> EQUAL IF DROP <4096> ADD ELSE <H(K_12_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_13_1)> EQUAL IF DROP <8192> ADD ELSE <H(K_13_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_14_1)> EQUAL IF DROP <16384> ADD ELSE <H(K_14_0)>\n> EQUALVERIFY ENDIF\n> > SWAP sha256 DUP <H(K_15_1)> EQUAL IF DROP <32768> ADD ELSE <H(K_15_0)>\n> EQUALVERIFY ENDIF\n> > CHECKSEQUENCEVERIFY\n> > ```\n>\n> On the other hand LOL WTF, this is cool.\n>\n> Basically you are showing that if we enable something as innocuous as\n> `OP_ADD`, we can implement Lamport signatures for **arbitrary** values\n> representable in small binary numbers (16 bits in the above example).\n>\n> I was thinking \"why not Merkle signatures\" since the pubkey would be much\n> smaller but the signature would be much larger, but (a) the SCRIPT would be\n> much more complicated and (b) in modern Bitcoin, the above SCRIPT would be\n> in the witness stack anyway so there is no advantage to pushing the size\n> towards the signature rather than the pubkey, they all have the same\n> weight, and since both Lamport and Merkle are single-use-only and we do not\n> want to encourage pubkey reuse even if they were not, the Merkle has much\n> larger signature size, so Merkle sigs end up more expensive.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210702/e507efdd/attachment-0001.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2021-07-03T11:31:04",
                "message_text_only": "i may be ignorant here but i have a question:\n\nGiven that schnorr signatures now allow signers to perform complex\narithmetic signing operations out-of-band using their own communications\ntechniques, couldn't you just perform the publishing and accumulation of\nthese signature components without using a bitcoin script?\n\nIn other words, push the effort of combination and computation off of the\nbitcoin network and nodes.\n\n\nOn Sat, Jul 3, 2021 at 12:01 AM Jeremy via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Yep -- sorry for the confusing notation but seems like you got it. C++\n> templates have this issue too btw :)\n>\n> One cool thing is that if you have op_add for arbitrary width integers or\n> op_cat you can also make a quantum proof signature by signing the signature\n> made with checksig with the lamport.\n>\n> There are a couple gotchas wrt crypto assumptions on that but I'll write\n> it up soon \ud83d\ude42 it also works better in segwit V0 because there's no keypath\n> spend -- that breaks the quantum proofness of this scheme.\n>\n> On Fri, Jul 2, 2021, 4:58 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n>> Good morning Jeremy,\n>>\n>> > Dear Bitcoin Devs,\n>> >\n>> > It recently occurred to me that it's possible to do a lamport signature\n>> in script for arithmetic values by using a binary expanded representation.\n>> There are some applications that might benefit from this and I don't recall\n>> seeing it discussed elsewhere, but would be happy for a citation/reference\n>> to the technique.\n>> >\n>> > blog post here, https://rubin.io/blog/2021/07/02/signing-5-bytes/,\n>> text reproduced below\n>> >\n>> > There are two insights in this post:\n>> > 1. to use a bitwise expansion of the number\n>> > 2. to use a lamport signature\n>> > Let's look at the code in python and then translate to bitcoin script:\n>> > ```python\n>> > def add_bit(idx, preimage, image_0, image_1):\n>> >     s = sha256(preimage)\n>> >     if s == image_1:\n>> >         return (1 << idx)\n>> >     if s == image_0:\n>> >         return 0\n>> >     else:\n>> >         assert False\n>> > def get_signed_number(witnesses : List[Hash], keys : List[Tuple[Hash,\n>> Hash]]):\n>> >     acc = 0\n>> >     for (idx, preimage) in enumerate(witnesses):\n>> >         acc += add_bit(idx, preimage, keys[idx][0], keys[idx][1])\n>> >     return x\n>> > ```\n>> > So what's going on here? The signer generates a key which is a list of\n>> pairs of\n>> > hash images to create the script.\n>> > To sign, the signer provides a witness of a list of preimages that\n>> match one or the other.\n>> > During validation, the network adds up a weighted value per preimage\n>> and checks\n>> > that there are no left out values.\n>> > Let's imagine a concrete use case: I want a third party to post-hoc\n>> sign a sequence lock. This is 16 bits.\n>> > I can form the following script:\n>> > ```\n>> > <pk> checksigverify\n>> > 0\n>> > SWAP sha256 DUP <H(K_0_1)> EQUAL IF DROP <1> ADD ELSE <H(K_0_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_1_1)> EQUAL IF DROP <1<<1> ADD ELSE <H(K_1_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_2_1)> EQUAL IF DROP <1<<2> ADD ELSE <H(K_2_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_3_1)> EQUAL IF DROP <1<<3> ADD ELSE <H(K_3_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_4_1)> EQUAL IF DROP <1<<4> ADD ELSE <H(K_4_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_5_1)> EQUAL IF DROP <1<<5> ADD ELSE <H(K_5_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_6_1)> EQUAL IF DROP <1<<6> ADD ELSE <H(K_6_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_7_1)> EQUAL IF DROP <1<<7> ADD ELSE <H(K_7_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_8_1)> EQUAL IF DROP <1<<8> ADD ELSE <H(K_8_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_9_1)> EQUAL IF DROP <1<<9> ADD ELSE <H(K_9_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_10_1)> EQUAL IF DROP <1<<10> ADD ELSE <H(K_10_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_11_1)> EQUAL IF DROP <1<<11> ADD ELSE <H(K_11_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_12_1)> EQUAL IF DROP <1<<12> ADD ELSE <H(K_12_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_13_1)> EQUAL IF DROP <1<<13> ADD ELSE <H(K_13_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_14_1)> EQUAL IF DROP <1<<14> ADD ELSE <H(K_14_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_15_1)> EQUAL IF DROP <1<<15> ADD ELSE <H(K_15_0)>\n>> EQUALVERIFY ENDIF\n>> > CHECKSEQUENCEVERIFY\n>> > ```\n>>\n>> This took a bit of thinking to understand, mostly because you use the\n>> `<<` operator in a syntax that uses `< >` as delimiters, which was mildly\n>> confusing --- at first I thought you were pushing some kind of nested\n>> SCRIPT representation, but in any case, replacing it with the actual\n>> numbers is a little less confusing on the syntax front, and I think (hope?)\n>> most people who can understand `1<<1` have also memorized the first few\n>> powers of 2....\n>>\n>> > ```\n>> > <pk> checksigverify\n>> > 0\n>> > SWAP sha256 DUP <H(K_0_1)> EQUAL IF DROP <1> ADD ELSE <H(K_0_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_1_1)> EQUAL IF DROP <2> ADD ELSE <H(K_1_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_2_1)> EQUAL IF DROP <4> ADD ELSE <H(K_2_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_3_1)> EQUAL IF DROP <8> ADD ELSE <H(K_3_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_4_1)> EQUAL IF DROP <16> ADD ELSE <H(K_4_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_5_1)> EQUAL IF DROP <32> ADD ELSE <H(K_5_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_6_1)> EQUAL IF DROP <64> ADD ELSE <H(K_6_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_7_1)> EQUAL IF DROP <128> ADD ELSE <H(K_7_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_8_1)> EQUAL IF DROP <256> ADD ELSE <H(K_8_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_9_1)> EQUAL IF DROP <512> ADD ELSE <H(K_9_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_10_1)> EQUAL IF DROP <1024> ADD ELSE <H(K_10_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_11_1)> EQUAL IF DROP <2048> ADD ELSE <H(K_11_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_12_1)> EQUAL IF DROP <4096> ADD ELSE <H(K_12_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_13_1)> EQUAL IF DROP <8192> ADD ELSE <H(K_13_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_14_1)> EQUAL IF DROP <16384> ADD ELSE <H(K_14_0)>\n>> EQUALVERIFY ENDIF\n>> > SWAP sha256 DUP <H(K_15_1)> EQUAL IF DROP <32768> ADD ELSE <H(K_15_0)>\n>> EQUALVERIFY ENDIF\n>> > CHECKSEQUENCEVERIFY\n>> > ```\n>>\n>> On the other hand LOL WTF, this is cool.\n>>\n>> Basically you are showing that if we enable something as innocuous as\n>> `OP_ADD`, we can implement Lamport signatures for **arbitrary** values\n>> representable in small binary numbers (16 bits in the above example).\n>>\n>> I was thinking \"why not Merkle signatures\" since the pubkey would be much\n>> smaller but the signature would be much larger, but (a) the SCRIPT would be\n>> much more complicated and (b) in modern Bitcoin, the above SCRIPT would be\n>> in the witness stack anyway so there is no advantage to pushing the size\n>> towards the signature rather than the pubkey, they all have the same\n>> weight, and since both Lamport and Merkle are single-use-only and we do not\n>> want to encourage pubkey reuse even if they were not, the Merkle has much\n>> larger signature size, so Merkle sigs end up more expensive.\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210703/265a6217/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-07-04T00:22:18",
                "message_text_only": "Good morning Erik,\n\n> i may be ignorant here but i have a question:\n>\n> Given that schnorr signatures now allow signers to perform complex arithmetic signing operations out-of-band using their own communications techniques, couldn't you just perform the publishing and accumulation of these signature components without using a bitcoin script?\n>\n> In other\u00a0words, push the effort of combination and computation off of the bitcoin network and nodes.\n\nActually the post is not about *doing* Arithmetic using signing operations, it is about enabling signing operations *at all* using arithmetic operation `OP_ADD`.\nJeremy in the initial post is not doing arithmetic, he is using arithmetic to implement Lamport signatures (which cannot support arithmetic signing operations anyway, being a hash-based signing scheme).\n\nThe \"for\" arithmetic here is largely to mean that this cleverness allows an implementation of `OP_CHECKSIGFROMSTACK`, using arithmetic operation `OP_ADD`.\n\nTo my mind this cleverness is more of an argument against ever enabling `OP_ADD` and friends, LOL.\nThis is more of a \"bad but ridiculously clever thing\" post than a \"Bitcoin should totally use this thing\" post.\n\nRegards,\nZmnSCPxj\n\n>\n> On Sat, Jul 3, 2021 at 12:01 AM Jeremy via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> > Yep -- sorry for the confusing notation but seems like you got it. C++ templates have this issue too btw :)\n> >\n> > One cool thing is that if you have op_add for arbitrary width integers or op_cat you can also make a quantum proof signature by signing the signature made with checksig with the lamport.\n> >\n> > There are a couple gotchas wrt crypto assumptions on that but I'll write it up soon \ud83d\ude42 it also works better in segwit V0 because there's no keypath spend -- that breaks the quantum proofness of this scheme.\n> >\n> > On Fri, Jul 2, 2021, 4:58 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n> >\n> > > Good morning Jeremy,\n> > >\n> > > > Dear Bitcoin Devs,\n> > > >\n> > > > It recently occurred to me that it's possible to do a lamport signature in script for arithmetic values by using a binary expanded representation. There are some applications that might benefit from this and I don't recall seeing it discussed elsewhere, but would be happy for a citation/reference to the technique.\n> > > >\n> > > > blog post here, https://rubin.io/blog/2021/07/02/signing-5-bytes/, text reproduced below\n> > > >\n> > > > There are two insights in this post:\n> > > > 1. to use a bitwise expansion of the number\n> > > > 2. to use a lamport signature\n> > > > Let's look at the code in python and then translate to bitcoin script:\n> > > > ```python\n> > > > def add_bit(idx, preimage, image_0, image_1):\n> > > > \u00a0 \u00a0 s = sha256(preimage)\n> > > > \u00a0 \u00a0 if s == image_1:\n> > > > \u00a0 \u00a0 \u00a0 \u00a0 return (1 << idx)\n> > > > \u00a0 \u00a0 if s == image_0:\n> > > > \u00a0 \u00a0 \u00a0 \u00a0 return 0\n> > > > \u00a0 \u00a0 else:\n> > > > \u00a0 \u00a0 \u00a0 \u00a0 assert False\n> > > > def get_signed_number(witnesses : List[Hash], keys : List[Tuple[Hash, Hash]]):\n> > > > \u00a0 \u00a0 acc = 0\n> > > > \u00a0 \u00a0 for (idx, preimage) in enumerate(witnesses):\n> > > > \u00a0 \u00a0 \u00a0 \u00a0 acc += add_bit(idx, preimage, keys[idx][0], keys[idx][1])\n> > > > \u00a0 \u00a0 return x\n> > > > ```\n> > > > So what's going on here? The signer generates a key which is a list of pairs of\n> > > > hash images to create the script.\n> > > > To sign, the signer provides a witness of a list of preimages that match one or the other.\n> > > > During validation, the network adds up a weighted value per preimage and checks\n> > > > that there are no left out values.\n> > > > Let's imagine a concrete use case: I want a third party to post-hoc sign a sequence lock. This is 16 bits.\n> > > > I can form the following script:\n> > > > ```\n> > > > <pk> checksigverify\n> > > > 0\n> > > > SWAP sha256 DUP <H(K_0_1)> EQUAL IF DROP <1> ADD ELSE <H(K_0_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_1_1)> EQUAL IF DROP <1<<1> ADD ELSE <H(K_1_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_2_1)> EQUAL IF DROP <1<<2> ADD ELSE <H(K_2_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_3_1)> EQUAL IF DROP <1<<3> ADD ELSE <H(K_3_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_4_1)> EQUAL IF DROP <1<<4> ADD ELSE <H(K_4_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_5_1)> EQUAL IF DROP <1<<5> ADD ELSE <H(K_5_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_6_1)> EQUAL IF DROP <1<<6> ADD ELSE <H(K_6_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_7_1)> EQUAL IF DROP <1<<7> ADD ELSE <H(K_7_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_8_1)> EQUAL IF DROP <1<<8> ADD ELSE <H(K_8_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_9_1)> EQUAL IF DROP <1<<9> ADD ELSE <H(K_9_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_10_1)> EQUAL IF DROP <1<<10> ADD ELSE <H(K_10_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_11_1)> EQUAL IF DROP <1<<11> ADD ELSE <H(K_11_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_12_1)> EQUAL IF DROP <1<<12> ADD ELSE <H(K_12_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_13_1)> EQUAL IF DROP <1<<13> ADD ELSE <H(K_13_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_14_1)> EQUAL IF DROP <1<<14> ADD ELSE <H(K_14_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_15_1)> EQUAL IF DROP <1<<15> ADD ELSE <H(K_15_0)> EQUALVERIFY ENDIF\n> > > > CHECKSEQUENCEVERIFY\n> > > > ```\n> > >\n> > > This took a bit of thinking to understand, mostly because you use the `<<` operator in a syntax that uses `< >` as delimiters, which was mildly confusing --- at first I thought you were pushing some kind of nested SCRIPT representation, but in any case, replacing it with the actual numbers is a little less confusing on the syntax front, and I think (hope?) most people who can understand `1<<1` have also memorized the first few powers of 2....\n> > >\n> > > > ```\n> > > > <pk> checksigverify\n> > > > 0\n> > > > SWAP sha256 DUP <H(K_0_1)> EQUAL IF DROP <1> ADD ELSE <H(K_0_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_1_1)> EQUAL IF DROP <2> ADD ELSE <H(K_1_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_2_1)> EQUAL IF DROP <4> ADD ELSE <H(K_2_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_3_1)> EQUAL IF DROP <8> ADD ELSE <H(K_3_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_4_1)> EQUAL IF DROP <16> ADD ELSE <H(K_4_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_5_1)> EQUAL IF DROP <32> ADD ELSE <H(K_5_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_6_1)> EQUAL IF DROP <64> ADD ELSE <H(K_6_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_7_1)> EQUAL IF DROP <128> ADD ELSE <H(K_7_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_8_1)> EQUAL IF DROP <256> ADD ELSE <H(K_8_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_9_1)> EQUAL IF DROP <512> ADD ELSE <H(K_9_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_10_1)> EQUAL IF DROP <1024> ADD ELSE <H(K_10_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_11_1)> EQUAL IF DROP <2048> ADD ELSE <H(K_11_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_12_1)> EQUAL IF DROP <4096> ADD ELSE <H(K_12_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_13_1)> EQUAL IF DROP <8192> ADD ELSE <H(K_13_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_14_1)> EQUAL IF DROP <16384> ADD ELSE <H(K_14_0)> EQUALVERIFY ENDIF\n> > > > SWAP sha256 DUP <H(K_15_1)> EQUAL IF DROP <32768> ADD ELSE <H(K_15_0)> EQUALVERIFY ENDIF\n> > > > CHECKSEQUENCEVERIFY\n> > > > ```\n> > >\n> > > On the other hand LOL WTF, this is cool.\n> > >\n> > > Basically you are showing that if we enable something as innocuous as `OP_ADD`, we can implement Lamport signatures for **arbitrary** values representable in small binary numbers (16 bits in the above example).\n> > >\n> > > I was thinking \"why not Merkle signatures\" since the pubkey would be much smaller but the signature would be much larger, but (a) the SCRIPT would be much more complicated and (b) in modern Bitcoin, the above SCRIPT would be in the witness stack anyway so there is no advantage to pushing the size towards the signature rather than the pubkey, they all have the same weight, and since both Lamport and Merkle are single-use-only and we do not want to encourage pubkey reuse even if they were not, the Merkle has much larger signature size, so Merkle sigs end up more expensive.\n> > >\n> > > Regards,\n> > > ZmnSCPxj\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-07-04T13:10:36",
                "message_text_only": "Good morning Erik and Jeremy,\n\n> The \"for\" arithmetic here is largely to mean that this cleverness allows an implementation of `OP_CHECKSIGFROMSTACK`, using arithmetic operation `OP_ADD`.\n>\n> To my mind this cleverness is more of an argument against ever enabling `OP_ADD` and friends, LOL.\n> This is more of a \"bad but ridiculously clever thing\" post than a \"Bitcoin should totally use this thing\" post.\n\nTurns out `OP_ADD` is actually still enabled in Bitcoin, LOL, I thought it was hit in the same banhammer that hit `OP_CAT` and `OP_MUL`.\nLimited to 32 bits, but that simply means that you just validate longer bitvectors (e.g. the `s` in the \"lamport-sign the EC signature\") in sections of 32 bits.\n\nIn any case, the point still mostly stands, I think this is more of a \"overall bad but still ridiculously clever\" idea; the script and witness sizes are fairly awful.\nMostly just worth discussing just in case it triggers somebody else to think of a related idea that takes some of the cleverness but is overall better.\n\nOn the other hand if we can actually implement the \"Lamport-sign the EC sig\" idea (I imagine the 32-bit limit requires some kind of `OP_CAT` or similar, or other bit or vector slicing operetion), that does mean Bitcoin is already quantum-safe (but has a fairly lousy quantum-safe signing scheme, I really do not know the characteristics of better ones though).\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "CheckSigFromStack for Arithmetic Values",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Jeremy",
                "Erik Aronesty"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 34760
        }
    },
    {
        "title": "[bitcoin-dev] Templates, Eltoo, and Covenants, Oh My!",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2021-07-02T22:32:24",
                "message_text_only": "Dear Bitcoin Devs,\n\nI recently put a blog post up which is of interest for this list. Post\navailable here: https://rubin.io/blog/2021/07/02/covenants/ (text\nreproduced below for archives).\n\nThe main technical points of interest for this list are:\n\n1) There's a similar protocol to Eltoo built with CSFS + CTV\n2) There may be a similar protocol to Eltoo with exclusively CSFS\n\nI'm curious if there's any sentiment around if a soft fork enabling CSFS is\ncontroversial? Or if there are any thoughts on the design questions posed\nbelow (e.g., splitting r and s value).\n\nBest,\n\nJeremy\n\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nIf you've been following The Discourse, you probably know that Taproot is\nmerged, locked in, and will activate later this November. What you might not\nknow is what's coming next... and you wouldn't be alone in that. There are a\nnumber of fantastic proposals floating around to further improve Bitcoin,\nbut\nthere's no clear picture on what is ready to be added next and on what\ntimeline. No one -- core developer, technically enlightened individuals,\npower\nusers, or plebs -- can claim to know otherwise.\n\n\nIn this post I'm going to describe 4 loosely related possible upgrades to\nBitcoin -- SH_APO (BIP-118), OP_CAT, OP_CSFS, and OP_CTV (BIP-119). These\nfour\nupgrades all relate to how the next generation of stateful smart contracts\ncan\nbe built on top of bitcoin. As such, there's natural overlap -- and\ncompetition\n-- for mindshare for review and deployment. This post is my attempt to\nstitch\ntogether a path we might take to roll them out and why that ordering makes\nsense. This post is for developers and engineers building in the Bitcoin\nspace,\nbut is intended to be followable by anyone technical or not who has a keen\ninterest in Bitcoin.\n\n\n## Bitcoin Eschews Roadmaps and Agendas.\n\n\nI provide this maxim to make clear that this document is by no means an\nofficial roadmap, narrative, or prioritization. However, it is my own\nassessment of what the current most pragmatic approach to upgrading Bitcoin\nis,\nbased on my understanding of the state of outstanding proposals and their\ninteractions.\n\n\nMy priorities in producing this are to open a discussion on potential new\nfeatures, risk minimization, and pragmatic design for Bitcoin.\n\n\n### Upgrade Summaries\n\n\nBelow follows summaries of what each upgrade would enable and how it works.\nYou\nmight be tempted to skip it if you're already familiar with the upgrades,\nbut I\nrecommend reading in any case as there are a few non obvious insights.\n\n\n#### APO: SIGHASH_ANYPREVOUT, SIGHASH_ANYPREVOUTANYSCRIPT\n\n\nCurrently proposed as\n[BIP-118](\nhttps://github.com/bitcoin/bips/blob/d616d5492bc6e6566af1b9f9e43b660bcd48ca29/bip-0118.mediawiki).\n\n\n\nAPO provides two new signature digest algorithms that do not commit to the\ncoin\nbeing spent, or the current script additionally. Essentially allowing\nscripts\nto use outputs that didn\u2019t exist at the time the script was made. This\nwould be\na new promise enforced by Bitcoin (ex. \u201cYou can close this Lightning channel\nand receive these coins if you give me the right proof. If a newer proof\ncomes\nin later I\u2019ll trust that one instead.\u201d).\n\n\nAPO\u2019s primary purpose is to enable off chain protocols like\n[Eltoo](https://blockstream.com/2018/04/30/en-eltoo-next-lightning/), an\nimproved non-punitive payment channel protocol.\n\n\nAPO can also\n[emulate](\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-June/017038.html\n)\nsome of the main features of CTV and could be made to work with Sapio,\npartially. See the complimentary upgrades section for more detail.\n\n\n#### CAT (+ variants)\n\n\nCurrently no BIP. However, CAT exists in\n[Elements](\nhttps://github.com/ElementsProject/elements/blob/bd2e2d5c64d38286b2ca0519f1215bed228e4dcf/src/script/interpreter.cpp#L914-L933\n)\nand [Bitcoin\nCash](\nhttps://github.com/bitcoincashorg/bitcoincash.org/blob/3e2e6da8c38dab7ba12149d327bc4b259aaad684/spec/may-2018-reenabled-opcodes.md\n)\nas a 520 byte limited form, so a proposal for Bitcoin can crib heavily from\neither.\n\n\nCat enables appending data onto other pieces of data. Diabolically simple\nfunctionality that has many advanced use cases by itself and in concert with\nother opcodes. There are many \"straightforward\" use cases of cat like\nrequiring\nsighash types, requiring specific R values, etc, but there are too many\ndevious\nuse cases to list here.  Andrew Poelstra has a decent blogpost series ([part\n1](https://www.wpsoftware.net/andrew/blog/cat-and-schnorr-tricks-i.html) and\n[part\nii](https://www.wpsoftware.net/andrew/blog/cat-and-schnorr-tricks-ii.html))\nif\nyou're interested to read more. In particular, with much cleverness, it\nseems\npossible one could implement full covenants with just CAT, which covers\n(inefficiently) most of the other techniques discussed in this post.\n\n\n#### CSFS: CHECKSIGFROMSTACK\n\n\nCurrently no BIP. However, CSFS exists in\n[Elements](\nhttps://github.com/ElementsProject/elements/blob/bd2e2d5c64d38286b2ca0519f1215bed228e4dcf/src/script/interpreter.cpp#L1580-L1618\n)\nand in [Bitcoin\nCash](\nhttps://github.com/bitcoincashorg/bitcoincash.org/blob/master/spec/op_checkdatasig.md\n),\nso a proposal for Bitcoin can crib heavily from either.\n\n\nCSFS enables checking of a signature against a message and key from the\nstack\nwithout including any transaction data.\n\n\nUse cases include oracle protocols, key delegations, a [channel update\ninvalidation\nvariant](\nhttps://stanford2017.scalingbitcoin.org/files/Day1/SB2017_script_2_0.pdf)\n(Laolu claims this can be tweaked to be fully non punitive like eltoo, but\nyou'll need to bug him to write it up), and (+CAT) full covenants.\n\n\n\n\n#### CTV: OP_CHECKTEMPLATEVERIFY\n\n\nCurrently proposed as\n[BIP-119](https://github.com/bitcoin/bips/blob/master/bip-0119.mediawiki).\n\n\nCTV enables committing to a specific \"next\" transaction from script. This is\nthe ability to make an unbreakable promise on chain which Bitcoin can\nenforce\n(e.g. \u201cThis coin can only be spent to my multisig, or my backup after a\ntimelock\u201d). This is a departure from normal script which is traditionally\nonly\nconcerned with restrictions on the sender, CTV imposes restrictions on the\nrecipient. More technically, CTV is essentially the ability to embed a\nsignature of a specific transaction inside of a script without needing any\nelliptic curve operations. The validation costs are low. For more advanced\nlogic, you can nest multiple different CTV Hashes either using taproot or\nup to\nthe script length limits in regular script.\n\n\nCTV can be used for vaults, channels, and [many other\nuses](https://utxos.org/uses/). There\u2019s also\n[Sapio](https://learn.sapio-lang.org) which is a language and toolkit for\ncreating many kinds of programs with CTV.\n\n\nCTV compliments CSFS to be able to emulate APO-like functionality\nsufficient to build Eltoo, potentially making APO feature-wise redundant.\n\n\n## Comparative Analysis\n\n\nNow that we've got the basics covered, let's explore these upgrades\ncomparatively across several dimensions.\n\n\n### Design Specificity\n\n\n\"Design Specificity\" is a subjective measure of how substantially an upgrade\ncould change from its current design while still meeting the features\ngoals. It\nis not to be confused with security or safety. Ranked in order from most to\nleast design specific, with non-exhaustive lists of design questions based\non\nongoing community discourse as well as my own personal understanding of what\nmight be desirable.\n\n\n1. CSFS\n2. CTV\n3. CAT\n4. APO\n\n\n#### Explanations & Open Questions:\n1. CSFS is very simple and there is essentially a single way to implement\nit. Three open questions are:\n   1. Should CSFS require some sort of tagged hash? Very likely answer is\nno --\n      tags interfere with certain use cases)\n   2. Should CSFS split the signature's R & S value stack items for some\n      applications that otherwise may require OP_CAT? E.g. using a pinned R\n    value allows you to extract a private key if ever double signed, using\n2 R\n    values allows pay-to-reveal-key contracts. Most likely answer is no, if\nthat is\n    desired then OP_CAT can be introduced\n   3. Should CSFS support a cheap way to reference the taproot internal or\n      external key? Perhaps, can be handled with undefined upgradeable\n    keytypes. One might want to use the internal key, if the signed data\nshould be\n    valid independent of the tapscript tree.  One might want to use the\nexternal\n    key, if the data should only be valid for a single tapscript key + tree.\n2. CTV is a commitment to all data that can malleate TXID besides the inputs\n   being spent, therefore CTV does not have much space for variation on\ndesign.\n   1. Should the digest be reordered or formatted differently? If there were\n      more data on what types of covenants might be built in the future, a\n    better order could be picked. Some thought has already gone into an\norder and\n    commitments that make covenants easier, see the BIP for more. It's also\n    possible the serialization format for the variable length fields\n(scriptsigs,\n    outputs) could be changed to make it easier to work with from script.\n(Maybe,\n    minor change)\n   2. Should CTV include more template types? Possibly, CTV includes an\nupgrade\n      mechanism baked in for new template types, so it is extensible for\nfuture\n    purposes.\n   3. Should CTV commit to the amounts? CTV does not commit to the amount\nthat\n      a coin has. Input-inspecting functionality should be handled by\nseparate\n    opcodes, as CTV would be overly restrictive otherwise. E.g. dynamic fees\n    through new inputs would be harder: given CTV's design it is not\npossible to\n    detect which field did not match therefore it is not possible to script\nagainst\n    unexpected amount sent errors without some compromise (e.g. timeouts).\n3. CAT is simplistic, and there are really few ways to implement it.\nHowever,\n   because it requires some restrictions for security, there are difficult\nto\n    answer open design questions:\n   1. What is the appropriate maximum stack size CAT should permit?\nCurrently\n      the design in Elements is 520 bytes, the max general stack size\npermitted\n    in script.\n   2. Should CAT be introduced or\n      [SHASTREAM](https://github.com/ElementsProject/elements/pull/817),\n    SUBSTRING, or another variant? There is a strong argument for SHASTREAM\nbecause\n    when constructing covenants (e.g. for use with CTV) based on TX data\nit's\n    possible for size of a data field (e.g., serialization of all outputs)\nto\n    exceed 520 bytes.\n4. There are many tough questions that the community has grappled with\nduring\n   APO's design and engineering process, generally asking how APO-like\n    techniques can be made 'Generally Safe' given iit breaks current\nassumptions\n    around address reuse.\n   1. Should APO require chaperone signatures (in order to ensure that\nreplay\n      is not done by 3rd parties)? Current Answer: No, anyone is free to\nburn\n    their keys by revealing them to similar effect.\n   2. Should APO use key tagging to mark keys that can use APO: Current\nAnswer:\n      yes, APO should be \"double opt-in\" (both requiring a tag and a signer\nto\n    produce such a signature)\n   3. Should APO allow signing with the external taproot key: Current\nAnswer:\n      no, because it makes APO not \"double opt-in\".\n   4. Should APO optimize signing with the internal taproot key? Answer:\n      default key 0x01 refers to taproot internal key, so it can be made\n    cheaper if you're going to need it without having to repeat the entire\nkey.\n   5. Should APO commit to the signing script? Answer: let's do two\nvariants.\n   6. Should APO instead be a larger refactoring of sighash logic that\n      encapsulates APO (e.g. sighash bitmasks)? Current Answer: No, APO is\ngood\n    enough to ship as is and doesn't preclude future work.\n\n\n### Safety\n\n\nThis category covers how \"safe\" each change is ranked from safest to least\nsafe. What makes a change more or less safe is how limited and foreseeable\nthe\nuses are of a specific opcode, in other words, how well we understand what\nit\ncan do or where it might interact poorly with deployed infrastructure.\n\n1. CTV\n2. CSFS\n3. APO\n4. CAT\n\n\nCTV is the safest new feature since fundamentally what it introduces is very\nsimilar to what can be done with pre-signed transactions, so it is only a\npivot\non trust and interactivity. Where there is some risk from CTV is that\naddresses\n(or rather, invoices) that are reused might have the same program behind\nthem\nwhich could cause unintended behavior. This differs from the reuse problem\nin\nAPO because the problem is stateless, that is, if you verify what is behind\nan\naddress you will know what exists and does not exist. E.g., two payment\nchannel\naddresses will create distinct payment channels that updates cannot be\nreplayed\nacross. In contrast with APO, paying one APO using address twice creates two\ninstances of the same channel, state updates from one channel can be used on\nthe other.\n\n\nCSFS is the next safest, it is just a small piece of authenticated data.\nCSFS\nand CTV are relatively close in terms of safety, but CSFS is slightly less\nsafe\ngiven a remote possibility of surprising  uses of it to perform unforeseen\nelliptic curve operations. This functionality already exists for up to\n5-byte\nmessages. A hash preimage revelation can emulate a signer compactly. Using\nbinary expansions and addition could be used to allow signing of values more\ncompactly (e.g., 2x16x32 byte hashes could be used to construct a signature\nof\na post-hoc selected Sequence lock). [Read more\nhere](/blog/2021/07/02/signing-5-bytes/). Therefore it is appropriate to\nthink of\nCSFS as an expansion of the efficiency of this technique, reusability of\nkeys,\nand the types of data that can be signed over. Although CSFS is famously\nused\nto build covenants by comparing a CSFS signature to a CHECKSIG signature and\ngetting transaction data onto the stack, CSFS cannot do that without CAT.\n\n\nAPO. This is the next safest because APO has some questions around key reuse\nsafety and statefulness of information. See the above description in CTV for\nwhy this is tangibly worse for APO than CTV. [See more discussion of APO's\nsafety & design trade offs\nhere](\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2019-September/002176.html).\n\n\n\nCAT is the least 'safe' in terms of extant Bitcoin concepts as it is highly\nlikely CAT introduces at least advanced covenants if added, especially in\nconjunction with the above opcodes, but may also enable other unintended\nfunctionality. CAT is a source of continual surprise with regards to what it\nenables in composition with existing opcodes, therefore a systematic review\nof\ncomposability and known uses should be done before considering it. That CAT\nwas\nforked out by Satoshi is of limited relevance as the variant proposed for\nreintroduction would not have the vulnerability present initially.\n\n\n### Complimentary Upgrades\n\n\nPairings of upgrades can work together to deliver functionality that neither\ncould alone:\n\n\n1. CAT + CSFS: full blown arbitrary covenants\n   1. With arbitrary covenants you can deploy many different kinds of smart\n      contracts which are out of scope for this article.\n2. CAT + CTV: Expanded covenants\n   1. slightly simpler to use interface but fewer features than CSFS + CAT\nwhich can\n      covenant over witness data and inputs.\n3. CTV + CSFS: Eltoo\n    1. This can add very similar functionality to eltoo with the script\nfragment:\n    `CTV <musig(pka, pkb)> CSFS <S+1> CLTV`\n    The protocol is essentially identical to the Eltoo paper, however there\nare\n    a couple subtle differences required for dynamic fee rates.\n4. CTV + APO: Slightly Different\n   1. It's commonly claimed that APO is a perfect substitute for CTV. This\nis\n      false. Their digests are slightly different, as such there are some\nniche\n    smart contracts that could use the differences in commitment structure\nfor\n    interesting effects (CTV commits to all scriptsigs and sequences, APO\ncannot\n    cover that data but can cover a few variants of less data covered).\n\n\nBy all means not an exhaustive list -- feel free to message me with\nadditions.\n\n\n### Recommendation\n\n\nMy recommendation is to deliver the upgrades described in this document in\nthe\nfollowing order:\n\n\n1. CTV\n2. CSFS\n3. APO\n4. CAT/SHASTREAM/SUBSTRING/etc\n\n\nThis recommendation comes as a synthesis of the thoughts above on the\ncomposability, safety, and open design considerations of the various\nproposals\ncurrently in flight.\n\n\nWith CTV in place, we can begin experimenting with a wide variety of\ncontracts\nusing the Sapio toolchain, as well as improve and invest in maturing the\ntoolchain. Mature toolchains will make it easier to safely engineer and\ndeploy\napplications making use of CTV and future upgrades.\n\n\nCSFS is an independent change that can be deployed/developed in parallel to\nor\nbefore CTV, the implementation from Elements could be easily ported to\nBitcoin.\nWith CSFS and CTV, Eltoo-like constructions will be possible as well.\n\n\nAPO can then be deployed as an optimization to existing use patterns driven\nby\nmarket adoption of CTV+CSFS based use. This also gives us time to kick the\ncan\ndown the road on the design questions that APO prompts around\ngeneralization of\nsignature digests and key reuse safety.  A similar approach was [discussed\non\nthe mailing\nlist](\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-May/016996.html\n),\nbut without the insight that CSFS + CTV was sufficient for Eltoo like\nconstructions, requiring CAT instead.\n\n\nLastly, OP_CAT can be delivered as part of an effort towards generalized\narbitrary covenants and perhaps in conjunction with some special purpose\nopcodes (such as OP_CHECKINPUT) that can more easily handle common cases.\nCAT,\nalthough it has safe implementations used in Elements, deserves very strict\nscrutiny given it's documented surprising uses.\n\n\nThis approach represents a gradual relaxation of Bitcoin's restrictions\naround\nsmart contract programming that introduces useful, safe primitives and gives\nthe community time to build and deploy useful infrastructure. The path\ndescribed in this post is an opportunity to upgrade bitcoin with simple\nprimitives that compose nicely for permissionless innovation.\n\n\n_Thanks to those who reviewed drafts of this post and provided valuable\nfeedback improving the clarity and accuracy of this post, including\n[pyskell](https://github.com/pyskell), [Keagan\nMcClelland](https://twitter.com/ProofOfKeags), [Ryan\nGentry](https://twitter.com/RyanTheGentry), and [Olaoluwa\nOsuntokun](https://twitter.com/roasbeef). Edit + Feedback \u2260\nEndorsement._\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210702/cd70c3e7/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Templates, Eltoo, and Covenants, Oh My!",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 19029
        }
    },
    {
        "title": "[bitcoin-dev] CHECKSIGFROMSTACK/{Verify} BIP for Bitcoin",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2021-07-03T16:31:57",
                "message_text_only": "Reproduced below is the BIP text from Bitcoin Cash's (MIT-Licensed)\nspecification for \"CheckDataSig\", more or less the same thing as\nCHECKSIGFROMSTACK\nhttps://github.com/bitcoincashorg/bitcoincash.org/blob/master/spec/op_checkdatasig.md.\nIn contrast to Element's implementation, it does not have Element's bugs\naround verify semantics and uses the nullfail rule, and there is a\nspecification document so it seemed like the easiest starting point for\ndiscussion v.s. drafting something from scratch.\n\nDoes anyone have any issue with adapting this exact text and implementation\nto a BIP for Bitcoin using 2 OP_SUCCESSX opcodes?\n\nNote that with *just* CheckSigFromStack, while you can do some very\nvaluable use cases, but without OP_CAT it does not enable sophisticated\ncovenants (and as per\nhttps://www.wpsoftware.net/andrew/blog/cat-and-schnorr-tricks-i.html just\nCAT alone enables such uses).\n\nDesign questions worth considering as modifications:\n\n1. Should CSFS require some sort of tagged hash? Very likely answer is no \u2013\ntags interfere with certain use cases\n2. Should CSFS split the signature\u2019s R & S value stack items for some\napplications that otherwise may require OP_CAT? E.g. using a pinned R value\nallows you to extract a private key if ever double signed, using 2 R values\nallows pay-to-reveal-key contracts. Most likely answer is no, if that is\ndesired then OP_CAT can be introduced\n3. Should CSFS support a cheap way to reference the taproot internal or\nexternal key? Perhaps, can be handled with undefined upgradeable keytypes.\nOne might want to use the internal key, if the signed data should be valid\nindependent of the tapscript tree. One might want to use the external key,\nif the data should only be valid for a single tapscript key + tree.\n4. Should invalid public keys types be a NOP to support future extended\npubkey types?\n\n\n\nBest,\n\n\nJeremy\n\n\n---\nlayout: specification\ntitle: OP_CHECKDATASIG and OP_CHECKDATASIGVERIFY Specification\ncategory: spec\ndate: 2018-08-20\nactivation: 1542300000\nversion: 0.6\n---\n\nOP_CHECKDATASIG\n===============\n\nOP_CHECKDATASIG and OP_CHECKDATASIGVERIFY check whether a signature is\nvalid with respect to a message and a public key.\n\nOP_CHECKDATASIG permits data to be imported into a script, and have\nits validity checked against some signing authority such as an\n\"Oracle\".\n\nOP_CHECKDATASIG and OP_CHECKDATASIGVERIFY are designed to be\nimplemented similarly to OP_CHECKSIG [1]. Conceptually, one could\nimagine OP_CHECKSIG functionality being replaced by OP_CHECKDATASIG,\nalong with a separate Op Code to create a hash from the transaction\nbased on the SigHash algorithm.\n\nOP_CHECKDATASIG Specification\n-----------------------------\n\n### Semantics\n\nOP_CHECKDATASIG fails immediately if the stack is not well formed. To\nbe well formed, the stack must contain at least three elements\n[`<sig>`, `<msg>`, `<pubKey>`] in this order where `<pubKey>` is the\ntop element and\n  * `<pubKey>` must be a validly encoded public key\n  * `<msg>` can be any string\n  * `<sig>` must follow the strict DER encoding as described in [2]\nand the S-value of `<sig>` must be at most the curve order divided by\n2 as described in [3]\n\nIf the stack is well formed, then OP_CHECKDATASIG pops the top three\nelements [`<sig>`, `<msg>`, `<pubKey>`] from the stack and pushes true\nonto the stack if `<sig>` is valid with respect to the raw\nsingle-SHA256 hash of `<msg>` and `<pubKey>` using the secp256k1\nelliptic curve. Otherwise, it pops three elements and pushes false\nonto the stack in the case that `<sig>` is the empty string and fails\nin all other cases.\n\nNullfail is enforced the same as for OP_CHECKSIG [3]. If the signature\ndoes not match the supplied public key and message hash, and the\nsignature is not an empty byte array, the entire script fails.\n\n### Opcode Number\n\nOP_CHECKDATASIG uses the previously unused opcode number 186 (0xba in\nhex encoding)\n\n### SigOps\n\nSignature operations accounting for OP_CHECKDATASIG shall be\ncalculated the same as OP_CHECKSIG. This means that each\nOP_CHECKDATASIG shall be counted as one (1) SigOp.\n\n### Activation\n\nUse of OP_CHECKDATASIG, unless occuring in an unexecuted OP_IF branch,\nwill make the transaction invalid if it is included in a block where\nthe median timestamp of the prior 11 blocks is less than 1542300000.\n\n### Unit Tests\n\n - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if 15 November 2018\nprotocol upgrade is not yet activated.\n - `<sig> <msg> OP_CHECKDATASIG` fails if there are fewer than 3 items on stack.\n - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if `<pubKey>` is not a\nvalidly encoded public key.\n - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if `<sig>` is not a\nvalidly encoded signature with strict DER encoding.\n - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if signature `<sig>`\nis not empty and does not pass the Low S check.\n - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if signature `<sig>`\nis not empty and does not pass signature validation of `<msg>` and\n`<pubKey>`.\n - `<sig> <msg> <pubKey> OP_CHECKDATASIG` pops three elements and\npushes false onto the stack if `<sig>` is an empty byte array.\n - `<sig> <msg> <pubKey> OP_CHECKDATASIG` pops three elements and\npushes true onto the stack if `<sig>` is a valid signature of `<msg>`\nwith respect to `<pubKey>`.\n\nOP_CHECKDATASIGVERIFY Specification\n-----------------------------------\n\n### Semantics\n\nOP_CHECKDATASIGVERIFY is equivalent to OP_CHECKDATASIG followed by\nOP_VERIFY. It leaves nothing on the stack, and will cause the script\nto fail immediately if the signature check does not pass.\n\n### Opcode Number\n\nOP_CHECKDATASIGVERIFY uses the previously unused opcode number 187\n(0xbb in hex encoding)\n\n### SigOps\n\nSignature operations accounting for OP_CHECKDATASIGVERIFY shall be\ncalculated the same as OP_CHECKSIGVERIFY. This means that each\nOP_CHECKDATASIGVERIFY shall be counted as one (1) SigOp.\n\n### Activation\n\nUse of OP_CHECKDATASIGVERIFY, unless occuring in an unexecuted OP_IF\nbranch, will make the transaction invalid if it is included in a block\nwhere the median timestamp of the prior 11 blocks is less than\n1542300000.\n\n### Unit Tests\n\n - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` fails if 15 November\n2018 protocol upgrade is not yet activated.\n - `<sig> <msg> OP_CHECKDATASIGVERIFY` fails if there are fewer than 3\nitem on stack.\n - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY`fails if `<pubKey>` is\nnot a validly encoded public key.\n - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` fails if `<sig>` is\nnot a validly encoded signature with strict DER encoding.\n - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` fails if signature\n`<sig>` is not empty and does not pass the Low S check.\n - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` fails if `<sig>` is\nnot a valid signature of `<msg>` with respect to `<pubKey>`.\n - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` pops the top three\nstack elements if `<sig>` is a valid signature of `<msg>` with respect\nto `<pubKey>`.\n\nSample Implementation [4, 5]\n----------------------------\n\n```c++\n                    case OP_CHECKDATASIG:\n                    case OP_CHECKDATASIGVERIFY: {\n                        // Make sure this remains an error before activation.\n                        if ((flags & SCRIPT_ENABLE_CHECKDATASIG) == 0) {\n                            return set_error(serror, SCRIPT_ERR_BAD_OPCODE);\n                        }\n\n                        // (sig message pubkey -- bool)\n                        if (stack.size() < 3) {\n                            return set_error(\n                                serror, SCRIPT_ERR_INVALID_STACK_OPERATION);\n                        }\n\n                        valtype &vchSig = stacktop(-3);\n                        valtype &vchMessage = stacktop(-2);\n                        valtype &vchPubKey = stacktop(-1);\n\n                        if (!CheckDataSignatureEncoding(vchSig, flags,\n                                                        serror) ||\n                            !CheckPubKeyEncoding(vchPubKey, flags, serror)) {\n                            // serror is set\n                            return false;\n                        }\n\n                        bool fSuccess = false;\n                        if (vchSig.size()) {\n                            valtype vchHash(32);\n                            CSHA256()\n                                .Write(vchMessage.data(), vchMessage.size())\n                                .Finalize(vchHash.data());\n                            uint256 message(vchHash);\n                            CPubKey pubkey(vchPubKey);\n                            fSuccess = pubkey.Verify(message, vchSig);\n                        }\n\n                        if (!fSuccess && (flags & SCRIPT_VERIFY_NULLFAIL) &&\n                            vchSig.size()) {\n                            return set_error(serror, SCRIPT_ERR_SIG_NULLFAIL);\n                        }\n\n                        popstack(stack);\n                        popstack(stack);\n                        popstack(stack);\n                        stack.push_back(fSuccess ? vchTrue : vchFalse);\n                        if (opcode == OP_CHECKDATASIGVERIFY) {\n                            if (fSuccess) {\n                                popstack(stack);\n                            } else {\n                                return set_error(serror,\n                                                 SCRIPT_ERR_CHECKDATASIGVERIFY);\n                            }\n                        }\n                    } break;\n```\n\nSample Usage\n------------\n\nThe following example shows a spend and redeem script for a basic use\nof CHECKDATASIG.  This example validates the signature of some data,\nprovides a placeholder where you would then process that data, and\nfinally allows one of 2 signatures to spend based on the outcome of\nthe data processing.\n\n### spend script:\n```\npush txsignature\npush txpubkey\npush msg\npush sig\n```\n### redeem script:\n```\n                                (txsig, txpubkey msg, sig)\nOP_OVER                         (txsig, txpubkey, msg, sig, msg)\npush data pubkey                (txsig, txpubkey, msg, sig, msg, pubkey)\nOP_CHECKDATASIGVERIFY           (txsig, txpubkey, msg)\n```\nNow that msg is on the stack top, the script can write predicates on it,\nresulting in the message being consumed and a true/false condition\nleft on the stack: (txpubkey, txsig, boolean)\n```\nOP_IF                           (txsig, txpubkey)\n  OP_DUP                        (txsig, txpubkey, txpubkey)\n  OP_HASH160                    (txsig, txpubkey, address)\n  push <p2pkh spend address>    (txsig, txpubkey, address, p2pkh spend address)\n  OP_EQUALVERIFY                (txsig, txpubkey)\n  OP_CHECKSIG\nOP_ELSE\n  (same as if clause but a different <p2pkh spend address>)\nOP_ENDIF\n```\n\nHistory\n-------\n\nThis specification is based on Andrew Stone\u2019s OP_DATASIGVERIFY\nproposal [6, 7]. It is modified from Stone's original proposal based\non a synthesis of all the peer-review and feedback received [8].\n\nReferences\n----------\n\n[1] [OP_CHECKSIG](https://en.bitcoin.it/wiki/OP_CHECKSIG)\n\n[2] [Strict DER\nEncoding](https://github.com/bitcoin/bips/blob/master/bip-0066.mediawiki)\n\n[3] [Low-S and Nullfail\nSpecification](https://github.com/bitcoin/bips/blob/master/bip-0146.mediawiki)\n\n[4] [Bitcoin ABC implementation](https://reviews.bitcoinabc.org/D1621)\n\n[5] [Bitcoin ABC implementation update](https://reviews.bitcoinabc.org/D1646)\n\n[6] [Andrew Stone\u2019s\nOP_DATASIGVERIFY](https://github.com/BitcoinUnlimited/BitcoinUnlimited/blob/bucash1.3.0.0/doc/opdatasigverify.md)\n\n[7] [Andrew Stone's article on\nScripting](https://medium.com/@g.andrew.stone/bitcoin-scripting-applications-decision-based-spending-8e7b93d7bdb9)\n\n[8] [Peer Review of Andrew Stone's\nProposal](https://github.com/bitcoincashorg/bitcoincash.org/pull/10)\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210703/f38c654f/attachment-0001.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2021-07-03T17:50:21",
                "message_text_only": "Hi Jermy,\n\nAs you are aware, we, and by we I mean mostly Sanket, are developing an\nupdated OP_CHECKSIGFROMSTACK implementation for tapscript on elements.  The\nplan here would be to effectively support the an interface to the\nvariable-length extension of BIP-0340 schnorr signatures.\n\nBIP-0340 would dispense with DER encoding (good riddance).\nBIP-0340 signatures are batch verifiable along with other BIP-0340\ntransaction signatures and taproot tweak verification.\nSupport for variable length messages in BIP-0340 has been discussed in <\nhttps://github.com/sipa/bips/issues/207> and an implementation has recently\nbeen merged in <https://github.com/bitcoin-core/secp256k1/pull/844>.  The\nBIP has not yet been updated but the difference is that the message m does\nnot have to be 32-bytes (it is recommended that the message be a 32-bit\ntagged hash or a message with a 64-bit application specific prefix). The\nCHECKSIGFROMSTACK operation (in tapscript) would use a stack item for this\nm value to BIP-0340 signature verification and would not necessarily have\nto be 32 bytes.\n\nI think this design we are aiming for would be perfectly suited for Bitcoin\nas well.\n\nOn Sat, Jul 3, 2021 at 12:32 PM Jeremy via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Reproduced below is the BIP text from Bitcoin Cash's (MIT-Licensed)\n> specification for \"CheckDataSig\", more or less the same thing as\n> CHECKSIGFROMSTACK\n> https://github.com/bitcoincashorg/bitcoincash.org/blob/master/spec/op_checkdatasig.md.\n> In contrast to Element's implementation, it does not have Element's bugs\n> around verify semantics and uses the nullfail rule, and there is a\n> specification document so it seemed like the easiest starting point for\n> discussion v.s. drafting something from scratch.\n>\n> Does anyone have any issue with adapting this exact text and\n> implementation to a BIP for Bitcoin using 2 OP_SUCCESSX opcodes?\n>\n> Note that with *just* CheckSigFromStack, while you can do some very\n> valuable use cases, but without OP_CAT it does not enable sophisticated\n> covenants (and as per\n> https://www.wpsoftware.net/andrew/blog/cat-and-schnorr-tricks-i.html just\n> CAT alone enables such uses).\n>\n> Design questions worth considering as modifications:\n>\n> 1. Should CSFS require some sort of tagged hash? Very likely answer is no\n> \u2013 tags interfere with certain use cases\n> 2. Should CSFS split the signature\u2019s R & S value stack items for some\n> applications that otherwise may require OP_CAT? E.g. using a pinned R value\n> allows you to extract a private key if ever double signed, using 2 R values\n> allows pay-to-reveal-key contracts. Most likely answer is no, if that is\n> desired then OP_CAT can be introduced\n> 3. Should CSFS support a cheap way to reference the taproot internal or\n> external key? Perhaps, can be handled with undefined upgradeable keytypes.\n> One might want to use the internal key, if the signed data should be valid\n> independent of the tapscript tree. One might want to use the external key,\n> if the data should only be valid for a single tapscript key + tree.\n> 4. Should invalid public keys types be a NOP to support future extended\n> pubkey types?\n>\n>\n>\n> Best,\n>\n>\n> Jeremy\n>\n>\n> ---\n> layout: specification\n> title: OP_CHECKDATASIG and OP_CHECKDATASIGVERIFY Specification\n> category: spec\n> date: 2018-08-20\n> activation: 1542300000\n> version: 0.6\n> ---\n>\n> OP_CHECKDATASIG\n> ===============\n>\n> OP_CHECKDATASIG and OP_CHECKDATASIGVERIFY check whether a signature is valid with respect to a message and a public key.\n>\n> OP_CHECKDATASIG permits data to be imported into a script, and have its validity checked against some signing authority such as an \"Oracle\".\n>\n> OP_CHECKDATASIG and OP_CHECKDATASIGVERIFY are designed to be implemented similarly to OP_CHECKSIG [1]. Conceptually, one could imagine OP_CHECKSIG functionality being replaced by OP_CHECKDATASIG, along with a separate Op Code to create a hash from the transaction based on the SigHash algorithm.\n>\n> OP_CHECKDATASIG Specification\n> -----------------------------\n>\n> ### Semantics\n>\n> OP_CHECKDATASIG fails immediately if the stack is not well formed. To be well formed, the stack must contain at least three elements [`<sig>`, `<msg>`, `<pubKey>`] in this order where `<pubKey>` is the top element and\n>   * `<pubKey>` must be a validly encoded public key\n>   * `<msg>` can be any string\n>   * `<sig>` must follow the strict DER encoding as described in [2] and the S-value of `<sig>` must be at most the curve order divided by 2 as described in [3]\n>\n> If the stack is well formed, then OP_CHECKDATASIG pops the top three elements [`<sig>`, `<msg>`, `<pubKey>`] from the stack and pushes true onto the stack if `<sig>` is valid with respect to the raw single-SHA256 hash of `<msg>` and `<pubKey>` using the secp256k1 elliptic curve. Otherwise, it pops three elements and pushes false onto the stack in the case that `<sig>` is the empty string and fails in all other cases.\n>\n> Nullfail is enforced the same as for OP_CHECKSIG [3]. If the signature does not match the supplied public key and message hash, and the signature is not an empty byte array, the entire script fails.\n>\n> ### Opcode Number\n>\n> OP_CHECKDATASIG uses the previously unused opcode number 186 (0xba in hex encoding)\n>\n> ### SigOps\n>\n> Signature operations accounting for OP_CHECKDATASIG shall be calculated the same as OP_CHECKSIG. This means that each OP_CHECKDATASIG shall be counted as one (1) SigOp.\n>\n> ### Activation\n>\n> Use of OP_CHECKDATASIG, unless occuring in an unexecuted OP_IF branch, will make the transaction invalid if it is included in a block where the median timestamp of the prior 11 blocks is less than 1542300000.\n>\n> ### Unit Tests\n>\n>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if 15 November 2018 protocol upgrade is not yet activated.\n>  - `<sig> <msg> OP_CHECKDATASIG` fails if there are fewer than 3 items on stack.\n>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if `<pubKey>` is not a validly encoded public key.\n>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if `<sig>` is not a validly encoded signature with strict DER encoding.\n>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if signature `<sig>` is not empty and does not pass the Low S check.\n>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if signature `<sig>` is not empty and does not pass signature validation of `<msg>` and `<pubKey>`.\n>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` pops three elements and pushes false onto the stack if `<sig>` is an empty byte array.\n>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` pops three elements and pushes true onto the stack if `<sig>` is a valid signature of `<msg>` with respect to `<pubKey>`.\n>\n> OP_CHECKDATASIGVERIFY Specification\n> -----------------------------------\n>\n> ### Semantics\n>\n> OP_CHECKDATASIGVERIFY is equivalent to OP_CHECKDATASIG followed by OP_VERIFY. It leaves nothing on the stack, and will cause the script to fail immediately if the signature check does not pass.\n>\n> ### Opcode Number\n>\n> OP_CHECKDATASIGVERIFY uses the previously unused opcode number 187 (0xbb in hex encoding)\n>\n> ### SigOps\n>\n> Signature operations accounting for OP_CHECKDATASIGVERIFY shall be calculated the same as OP_CHECKSIGVERIFY. This means that each OP_CHECKDATASIGVERIFY shall be counted as one (1) SigOp.\n>\n> ### Activation\n>\n> Use of OP_CHECKDATASIGVERIFY, unless occuring in an unexecuted OP_IF branch, will make the transaction invalid if it is included in a block where the median timestamp of the prior 11 blocks is less than 1542300000.\n>\n> ### Unit Tests\n>\n>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` fails if 15 November 2018 protocol upgrade is not yet activated.\n>  - `<sig> <msg> OP_CHECKDATASIGVERIFY` fails if there are fewer than 3 item on stack.\n>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY`fails if `<pubKey>` is not a validly encoded public key.\n>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` fails if `<sig>` is not a validly encoded signature with strict DER encoding.\n>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` fails if signature `<sig>` is not empty and does not pass the Low S check.\n>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` fails if `<sig>` is not a valid signature of `<msg>` with respect to `<pubKey>`.\n>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` pops the top three stack elements if `<sig>` is a valid signature of `<msg>` with respect to `<pubKey>`.\n>\n> Sample Implementation [4, 5]\n> ----------------------------\n>\n> ```c++\n>                     case OP_CHECKDATASIG:\n>                     case OP_CHECKDATASIGVERIFY: {\n>                         // Make sure this remains an error before activation.\n>                         if ((flags & SCRIPT_ENABLE_CHECKDATASIG) == 0) {\n>                             return set_error(serror, SCRIPT_ERR_BAD_OPCODE);\n>                         }\n>\n>                         // (sig message pubkey -- bool)\n>                         if (stack.size() < 3) {\n>                             return set_error(\n>                                 serror, SCRIPT_ERR_INVALID_STACK_OPERATION);\n>                         }\n>\n>                         valtype &vchSig = stacktop(-3);\n>                         valtype &vchMessage = stacktop(-2);\n>                         valtype &vchPubKey = stacktop(-1);\n>\n>                         if (!CheckDataSignatureEncoding(vchSig, flags,\n>                                                         serror) ||\n>                             !CheckPubKeyEncoding(vchPubKey, flags, serror)) {\n>                             // serror is set\n>                             return false;\n>                         }\n>\n>                         bool fSuccess = false;\n>                         if (vchSig.size()) {\n>                             valtype vchHash(32);\n>                             CSHA256()\n>                                 .Write(vchMessage.data(), vchMessage.size())\n>                                 .Finalize(vchHash.data());\n>                             uint256 message(vchHash);\n>                             CPubKey pubkey(vchPubKey);\n>                             fSuccess = pubkey.Verify(message, vchSig);\n>                         }\n>\n>                         if (!fSuccess && (flags & SCRIPT_VERIFY_NULLFAIL) &&\n>                             vchSig.size()) {\n>                             return set_error(serror, SCRIPT_ERR_SIG_NULLFAIL);\n>                         }\n>\n>                         popstack(stack);\n>                         popstack(stack);\n>                         popstack(stack);\n>                         stack.push_back(fSuccess ? vchTrue : vchFalse);\n>                         if (opcode == OP_CHECKDATASIGVERIFY) {\n>                             if (fSuccess) {\n>                                 popstack(stack);\n>                             } else {\n>                                 return set_error(serror,\n>                                                  SCRIPT_ERR_CHECKDATASIGVERIFY);\n>                             }\n>                         }\n>                     } break;\n> ```\n>\n> Sample Usage\n> ------------\n>\n> The following example shows a spend and redeem script for a basic use of CHECKDATASIG.  This example validates the signature of some data, provides a placeholder where you would then process that data, and finally allows one of 2 signatures to spend based on the outcome of the data processing.\n>\n> ### spend script:\n> ```\n> push txsignature\n> push txpubkey\n> push msg\n> push sig\n> ```\n> ### redeem script:\n> ```\n>                                 (txsig, txpubkey msg, sig)\n> OP_OVER                         (txsig, txpubkey, msg, sig, msg)\n> push data pubkey                (txsig, txpubkey, msg, sig, msg, pubkey)\n> OP_CHECKDATASIGVERIFY           (txsig, txpubkey, msg)\n> ```\n> Now that msg is on the stack top, the script can write predicates on it,\n> resulting in the message being consumed and a true/false condition left on the stack: (txpubkey, txsig, boolean)\n> ```\n> OP_IF                           (txsig, txpubkey)\n>   OP_DUP                        (txsig, txpubkey, txpubkey)\n>   OP_HASH160                    (txsig, txpubkey, address)\n>   push <p2pkh spend address>    (txsig, txpubkey, address, p2pkh spend address)\n>   OP_EQUALVERIFY                (txsig, txpubkey)\n>   OP_CHECKSIG\n> OP_ELSE\n>   (same as if clause but a different <p2pkh spend address>)\n> OP_ENDIF\n> ```\n>\n> History\n> -------\n>\n> This specification is based on Andrew Stone\u2019s OP_DATASIGVERIFY proposal [6, 7]. It is modified from Stone's original proposal based on a synthesis of all the peer-review and feedback received [8].\n>\n> References\n> ----------\n>\n> [1] [OP_CHECKSIG](https://en.bitcoin.it/wiki/OP_CHECKSIG)\n>\n> [2] [Strict DER Encoding](https://github.com/bitcoin/bips/blob/master/bip-0066.mediawiki)\n>\n> [3] [Low-S and Nullfail Specification](https://github.com/bitcoin/bips/blob/master/bip-0146.mediawiki)\n>\n> [4] [Bitcoin ABC implementation](https://reviews.bitcoinabc.org/D1621)\n>\n> [5] [Bitcoin ABC implementation update](https://reviews.bitcoinabc.org/D1646)\n>\n> [6] [Andrew Stone\u2019s OP_DATASIGVERIFY](https://github.com/BitcoinUnlimited/BitcoinUnlimited/blob/bucash1.3.0.0/doc/opdatasigverify.md)\n>\n> [7] [Andrew Stone's article on Scripting](https://medium.com/@g.andrew.stone/bitcoin-scripting-applications-decision-based-spending-8e7b93d7bdb9)\n>\n> [8] [Peer Review of Andrew Stone's Proposal](https://github.com/bitcoincashorg/bitcoincash.org/pull/10)\n>\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210703/ce1d831d/attachment-0001.html>"
            },
            {
                "author": "Jeremy",
                "date": "2021-07-03T18:30:45",
                "message_text_only": "Awesome to hear that!\n\nActually I don't think I did know (or I forgot/didn't catch it) that there\nwas an updated spec for elements, I searched around for what I could find\nand came up empty handed. Do you have any links for that? That sounds\nperfect to me.\n\n\nOn Sat, Jul 3, 2021, 10:50 AM Russell O'Connor <roconnor at blockstream.com>\nwrote:\n\n> Hi Jermy,\n>\n> As you are aware, we, and by we I mean mostly Sanket, are developing an\n> updated OP_CHECKSIGFROMSTACK implementation for tapscript on elements.  The\n> plan here would be to effectively support the an interface to the\n> variable-length extension of BIP-0340 schnorr signatures.\n>\n> BIP-0340 would dispense with DER encoding (good riddance).\n> BIP-0340 signatures are batch verifiable along with other BIP-0340\n> transaction signatures and taproot tweak verification.\n> Support for variable length messages in BIP-0340 has been discussed in <\n> https://github.com/sipa/bips/issues/207> and an implementation has\n> recently been merged in <\n> https://github.com/bitcoin-core/secp256k1/pull/844>.  The BIP has not yet\n> been updated but the difference is that the message m does not have to be\n> 32-bytes (it is recommended that the message be a 32-bit tagged hash or a\n> message with a 64-bit application specific prefix). The CHECKSIGFROMSTACK\n> operation (in tapscript) would use a stack item for this m value to\n> BIP-0340 signature verification and would not necessarily have to be 32\n> bytes.\n>\n> I think this design we are aiming for would be perfectly suited for\n> Bitcoin as well.\n>\n> On Sat, Jul 3, 2021 at 12:32 PM Jeremy via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Reproduced below is the BIP text from Bitcoin Cash's (MIT-Licensed)\n>> specification for \"CheckDataSig\", more or less the same thing as\n>> CHECKSIGFROMSTACK\n>> https://github.com/bitcoincashorg/bitcoincash.org/blob/master/spec/op_checkdatasig.md.\n>> In contrast to Element's implementation, it does not have Element's bugs\n>> around verify semantics and uses the nullfail rule, and there is a\n>> specification document so it seemed like the easiest starting point for\n>> discussion v.s. drafting something from scratch.\n>>\n>> Does anyone have any issue with adapting this exact text and\n>> implementation to a BIP for Bitcoin using 2 OP_SUCCESSX opcodes?\n>>\n>> Note that with *just* CheckSigFromStack, while you can do some very\n>> valuable use cases, but without OP_CAT it does not enable sophisticated\n>> covenants (and as per\n>> https://www.wpsoftware.net/andrew/blog/cat-and-schnorr-tricks-i.html\n>> just CAT alone enables such uses).\n>>\n>> Design questions worth considering as modifications:\n>>\n>> 1. Should CSFS require some sort of tagged hash? Very likely answer is no\n>> \u2013 tags interfere with certain use cases\n>> 2. Should CSFS split the signature\u2019s R & S value stack items for some\n>> applications that otherwise may require OP_CAT? E.g. using a pinned R value\n>> allows you to extract a private key if ever double signed, using 2 R values\n>> allows pay-to-reveal-key contracts. Most likely answer is no, if that is\n>> desired then OP_CAT can be introduced\n>> 3. Should CSFS support a cheap way to reference the taproot internal or\n>> external key? Perhaps, can be handled with undefined upgradeable keytypes.\n>> One might want to use the internal key, if the signed data should be valid\n>> independent of the tapscript tree. One might want to use the external key,\n>> if the data should only be valid for a single tapscript key + tree.\n>> 4. Should invalid public keys types be a NOP to support future extended\n>> pubkey types?\n>>\n>>\n>>\n>> Best,\n>>\n>>\n>> Jeremy\n>>\n>>\n>> ---\n>> layout: specification\n>> title: OP_CHECKDATASIG and OP_CHECKDATASIGVERIFY Specification\n>> category: spec\n>> date: 2018-08-20\n>> activation: 1542300000\n>> version: 0.6\n>> ---\n>>\n>> OP_CHECKDATASIG\n>> ===============\n>>\n>> OP_CHECKDATASIG and OP_CHECKDATASIGVERIFY check whether a signature is valid with respect to a message and a public key.\n>>\n>> OP_CHECKDATASIG permits data to be imported into a script, and have its validity checked against some signing authority such as an \"Oracle\".\n>>\n>> OP_CHECKDATASIG and OP_CHECKDATASIGVERIFY are designed to be implemented similarly to OP_CHECKSIG [1]. Conceptually, one could imagine OP_CHECKSIG functionality being replaced by OP_CHECKDATASIG, along with a separate Op Code to create a hash from the transaction based on the SigHash algorithm.\n>>\n>> OP_CHECKDATASIG Specification\n>> -----------------------------\n>>\n>> ### Semantics\n>>\n>> OP_CHECKDATASIG fails immediately if the stack is not well formed. To be well formed, the stack must contain at least three elements [`<sig>`, `<msg>`, `<pubKey>`] in this order where `<pubKey>` is the top element and\n>>   * `<pubKey>` must be a validly encoded public key\n>>   * `<msg>` can be any string\n>>   * `<sig>` must follow the strict DER encoding as described in [2] and the S-value of `<sig>` must be at most the curve order divided by 2 as described in [3]\n>>\n>> If the stack is well formed, then OP_CHECKDATASIG pops the top three elements [`<sig>`, `<msg>`, `<pubKey>`] from the stack and pushes true onto the stack if `<sig>` is valid with respect to the raw single-SHA256 hash of `<msg>` and `<pubKey>` using the secp256k1 elliptic curve. Otherwise, it pops three elements and pushes false onto the stack in the case that `<sig>` is the empty string and fails in all other cases.\n>>\n>> Nullfail is enforced the same as for OP_CHECKSIG [3]. If the signature does not match the supplied public key and message hash, and the signature is not an empty byte array, the entire script fails.\n>>\n>> ### Opcode Number\n>>\n>> OP_CHECKDATASIG uses the previously unused opcode number 186 (0xba in hex encoding)\n>>\n>> ### SigOps\n>>\n>> Signature operations accounting for OP_CHECKDATASIG shall be calculated the same as OP_CHECKSIG. This means that each OP_CHECKDATASIG shall be counted as one (1) SigOp.\n>>\n>> ### Activation\n>>\n>> Use of OP_CHECKDATASIG, unless occuring in an unexecuted OP_IF branch, will make the transaction invalid if it is included in a block where the median timestamp of the prior 11 blocks is less than 1542300000.\n>>\n>> ### Unit Tests\n>>\n>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if 15 November 2018 protocol upgrade is not yet activated.\n>>  - `<sig> <msg> OP_CHECKDATASIG` fails if there are fewer than 3 items on stack.\n>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if `<pubKey>` is not a validly encoded public key.\n>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if `<sig>` is not a validly encoded signature with strict DER encoding.\n>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if signature `<sig>` is not empty and does not pass the Low S check.\n>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if signature `<sig>` is not empty and does not pass signature validation of `<msg>` and `<pubKey>`.\n>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` pops three elements and pushes false onto the stack if `<sig>` is an empty byte array.\n>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` pops three elements and pushes true onto the stack if `<sig>` is a valid signature of `<msg>` with respect to `<pubKey>`.\n>>\n>> OP_CHECKDATASIGVERIFY Specification\n>> -----------------------------------\n>>\n>> ### Semantics\n>>\n>> OP_CHECKDATASIGVERIFY is equivalent to OP_CHECKDATASIG followed by OP_VERIFY. It leaves nothing on the stack, and will cause the script to fail immediately if the signature check does not pass.\n>>\n>> ### Opcode Number\n>>\n>> OP_CHECKDATASIGVERIFY uses the previously unused opcode number 187 (0xbb in hex encoding)\n>>\n>> ### SigOps\n>>\n>> Signature operations accounting for OP_CHECKDATASIGVERIFY shall be calculated the same as OP_CHECKSIGVERIFY. This means that each OP_CHECKDATASIGVERIFY shall be counted as one (1) SigOp.\n>>\n>> ### Activation\n>>\n>> Use of OP_CHECKDATASIGVERIFY, unless occuring in an unexecuted OP_IF branch, will make the transaction invalid if it is included in a block where the median timestamp of the prior 11 blocks is less than 1542300000.\n>>\n>> ### Unit Tests\n>>\n>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` fails if 15 November 2018 protocol upgrade is not yet activated.\n>>  - `<sig> <msg> OP_CHECKDATASIGVERIFY` fails if there are fewer than 3 item on stack.\n>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY`fails if `<pubKey>` is not a validly encoded public key.\n>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` fails if `<sig>` is not a validly encoded signature with strict DER encoding.\n>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` fails if signature `<sig>` is not empty and does not pass the Low S check.\n>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` fails if `<sig>` is not a valid signature of `<msg>` with respect to `<pubKey>`.\n>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` pops the top three stack elements if `<sig>` is a valid signature of `<msg>` with respect to `<pubKey>`.\n>>\n>> Sample Implementation [4, 5]\n>> ----------------------------\n>>\n>> ```c++\n>>                     case OP_CHECKDATASIG:\n>>                     case OP_CHECKDATASIGVERIFY: {\n>>                         // Make sure this remains an error before activation.\n>>                         if ((flags & SCRIPT_ENABLE_CHECKDATASIG) == 0) {\n>>                             return set_error(serror, SCRIPT_ERR_BAD_OPCODE);\n>>                         }\n>>\n>>                         // (sig message pubkey -- bool)\n>>                         if (stack.size() < 3) {\n>>                             return set_error(\n>>                                 serror, SCRIPT_ERR_INVALID_STACK_OPERATION);\n>>                         }\n>>\n>>                         valtype &vchSig = stacktop(-3);\n>>                         valtype &vchMessage = stacktop(-2);\n>>                         valtype &vchPubKey = stacktop(-1);\n>>\n>>                         if (!CheckDataSignatureEncoding(vchSig, flags,\n>>                                                         serror) ||\n>>                             !CheckPubKeyEncoding(vchPubKey, flags, serror)) {\n>>                             // serror is set\n>>                             return false;\n>>                         }\n>>\n>>                         bool fSuccess = false;\n>>                         if (vchSig.size()) {\n>>                             valtype vchHash(32);\n>>                             CSHA256()\n>>                                 .Write(vchMessage.data(), vchMessage.size())\n>>                                 .Finalize(vchHash.data());\n>>                             uint256 message(vchHash);\n>>                             CPubKey pubkey(vchPubKey);\n>>                             fSuccess = pubkey.Verify(message, vchSig);\n>>                         }\n>>\n>>                         if (!fSuccess && (flags & SCRIPT_VERIFY_NULLFAIL) &&\n>>                             vchSig.size()) {\n>>                             return set_error(serror, SCRIPT_ERR_SIG_NULLFAIL);\n>>                         }\n>>\n>>                         popstack(stack);\n>>                         popstack(stack);\n>>                         popstack(stack);\n>>                         stack.push_back(fSuccess ? vchTrue : vchFalse);\n>>                         if (opcode == OP_CHECKDATASIGVERIFY) {\n>>                             if (fSuccess) {\n>>                                 popstack(stack);\n>>                             } else {\n>>                                 return set_error(serror,\n>>                                                  SCRIPT_ERR_CHECKDATASIGVERIFY);\n>>                             }\n>>                         }\n>>                     } break;\n>> ```\n>>\n>> Sample Usage\n>> ------------\n>>\n>> The following example shows a spend and redeem script for a basic use of CHECKDATASIG.  This example validates the signature of some data, provides a placeholder where you would then process that data, and finally allows one of 2 signatures to spend based on the outcome of the data processing.\n>>\n>> ### spend script:\n>> ```\n>> push txsignature\n>> push txpubkey\n>> push msg\n>> push sig\n>> ```\n>> ### redeem script:\n>> ```\n>>                                 (txsig, txpubkey msg, sig)\n>> OP_OVER                         (txsig, txpubkey, msg, sig, msg)\n>> push data pubkey                (txsig, txpubkey, msg, sig, msg, pubkey)\n>> OP_CHECKDATASIGVERIFY           (txsig, txpubkey, msg)\n>> ```\n>> Now that msg is on the stack top, the script can write predicates on it,\n>> resulting in the message being consumed and a true/false condition left on the stack: (txpubkey, txsig, boolean)\n>> ```\n>> OP_IF                           (txsig, txpubkey)\n>>   OP_DUP                        (txsig, txpubkey, txpubkey)\n>>   OP_HASH160                    (txsig, txpubkey, address)\n>>   push <p2pkh spend address>    (txsig, txpubkey, address, p2pkh spend address)\n>>   OP_EQUALVERIFY                (txsig, txpubkey)\n>>   OP_CHECKSIG\n>> OP_ELSE\n>>   (same as if clause but a different <p2pkh spend address>)\n>> OP_ENDIF\n>> ```\n>>\n>> History\n>> -------\n>>\n>> This specification is based on Andrew Stone\u2019s OP_DATASIGVERIFY proposal [6, 7]. It is modified from Stone's original proposal based on a synthesis of all the peer-review and feedback received [8].\n>>\n>> References\n>> ----------\n>>\n>> [1] [OP_CHECKSIG](https://en.bitcoin.it/wiki/OP_CHECKSIG)\n>>\n>> [2] [Strict DER Encoding](https://github.com/bitcoin/bips/blob/master/bip-0066.mediawiki)\n>>\n>> [3] [Low-S and Nullfail Specification](https://github.com/bitcoin/bips/blob/master/bip-0146.mediawiki)\n>>\n>> [4] [Bitcoin ABC implementation](https://reviews.bitcoinabc.org/D1621)\n>>\n>> [5] [Bitcoin ABC implementation update](https://reviews.bitcoinabc.org/D1646)\n>>\n>> [6] [Andrew Stone\u2019s OP_DATASIGVERIFY](https://github.com/BitcoinUnlimited/BitcoinUnlimited/blob/bucash1.3.0.0/doc/opdatasigverify.md)\n>>\n>> [7] [Andrew Stone's article on Scripting](https://medium.com/@g.andrew.stone/bitcoin-scripting-applications-decision-based-spending-8e7b93d7bdb9)\n>>\n>> [8] [Peer Review of Andrew Stone's Proposal](https://github.com/bitcoincashorg/bitcoincash.org/pull/10)\n>>\n>>\n>> --\n>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>> <https://twitter.com/JeremyRubin>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210703/ba67ab0b/attachment-0001.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2021-07-03T20:12:51",
                "message_text_only": "There is one line written at\nhttps://github.com/ElementsProject/elements/pull/949/files#r660130155. I\nsuppose we need to decide on which variants of *VERIFY and *ADD we want to\ninclude (presumably all of them) and choose which opcodes they will be\nassigned to.  And I guess for CHECKSIGFROMSTACKADD will want to place the n\nvalue between the signature and the message on the stack.  ... So I suppose\nwe will need more than one sentence.\n\nThe semantics would be basically to call secp256k1_schnorrsig_verify <\nhttps://github.com/bitcoin-core/secp256k1/blob/0440945fb5ce69d335fed32827b5166e84b02e05/include/secp256k1_schnorrsig.h#L158>,\ntreating pubkeys and signatures the same way the other CHECKSIG operations\ndo, and in passing the (variable length) message from the stack.\nCHECKSIGFROMSTACK would also be subject to the same sigops budget that\nCHECKSIG has in tapscript.\n\nOn Sat, Jul 3, 2021 at 2:30 PM Jeremy <jlrubin at mit.edu> wrote:\n\n> Awesome to hear that!\n>\n> Actually I don't think I did know (or I forgot/didn't catch it) that there\n> was an updated spec for elements, I searched around for what I could find\n> and came up empty handed. Do you have any links for that? That sounds\n> perfect to me.\n>\n>\n> On Sat, Jul 3, 2021, 10:50 AM Russell O'Connor <roconnor at blockstream.com>\n> wrote:\n>\n>> Hi Jermy,\n>>\n>> As you are aware, we, and by we I mean mostly Sanket, are developing an\n>> updated OP_CHECKSIGFROMSTACK implementation for tapscript on elements.  The\n>> plan here would be to effectively support the an interface to the\n>> variable-length extension of BIP-0340 schnorr signatures.\n>>\n>> BIP-0340 would dispense with DER encoding (good riddance).\n>> BIP-0340 signatures are batch verifiable along with other BIP-0340\n>> transaction signatures and taproot tweak verification.\n>> Support for variable length messages in BIP-0340 has been discussed in <\n>> https://github.com/sipa/bips/issues/207> and an implementation has\n>> recently been merged in <\n>> https://github.com/bitcoin-core/secp256k1/pull/844>.  The BIP has not\n>> yet been updated but the difference is that the message m does not have to\n>> be 32-bytes (it is recommended that the message be a 32-bit tagged hash or\n>> a message with a 64-bit application specific prefix). The CHECKSIGFROMSTACK\n>> operation (in tapscript) would use a stack item for this m value to\n>> BIP-0340 signature verification and would not necessarily have to be 32\n>> bytes.\n>>\n>> I think this design we are aiming for would be perfectly suited for\n>> Bitcoin as well.\n>>\n>> On Sat, Jul 3, 2021 at 12:32 PM Jeremy via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Reproduced below is the BIP text from Bitcoin Cash's (MIT-Licensed)\n>>> specification for \"CheckDataSig\", more or less the same thing as\n>>> CHECKSIGFROMSTACK\n>>> https://github.com/bitcoincashorg/bitcoincash.org/blob/master/spec/op_checkdatasig.md.\n>>> In contrast to Element's implementation, it does not have Element's bugs\n>>> around verify semantics and uses the nullfail rule, and there is a\n>>> specification document so it seemed like the easiest starting point for\n>>> discussion v.s. drafting something from scratch.\n>>>\n>>> Does anyone have any issue with adapting this exact text and\n>>> implementation to a BIP for Bitcoin using 2 OP_SUCCESSX opcodes?\n>>>\n>>> Note that with *just* CheckSigFromStack, while you can do some very\n>>> valuable use cases, but without OP_CAT it does not enable sophisticated\n>>> covenants (and as per\n>>> https://www.wpsoftware.net/andrew/blog/cat-and-schnorr-tricks-i.html\n>>> just CAT alone enables such uses).\n>>>\n>>> Design questions worth considering as modifications:\n>>>\n>>> 1. Should CSFS require some sort of tagged hash? Very likely answer is\n>>> no \u2013 tags interfere with certain use cases\n>>> 2. Should CSFS split the signature\u2019s R & S value stack items for some\n>>> applications that otherwise may require OP_CAT? E.g. using a pinned R value\n>>> allows you to extract a private key if ever double signed, using 2 R values\n>>> allows pay-to-reveal-key contracts. Most likely answer is no, if that is\n>>> desired then OP_CAT can be introduced\n>>> 3. Should CSFS support a cheap way to reference the taproot internal or\n>>> external key? Perhaps, can be handled with undefined upgradeable keytypes.\n>>> One might want to use the internal key, if the signed data should be valid\n>>> independent of the tapscript tree. One might want to use the external key,\n>>> if the data should only be valid for a single tapscript key + tree.\n>>> 4. Should invalid public keys types be a NOP to support future extended\n>>> pubkey types?\n>>>\n>>>\n>>>\n>>> Best,\n>>>\n>>>\n>>> Jeremy\n>>>\n>>>\n>>> ---\n>>> layout: specification\n>>> title: OP_CHECKDATASIG and OP_CHECKDATASIGVERIFY Specification\n>>> category: spec\n>>> date: 2018-08-20\n>>> activation: 1542300000\n>>> version: 0.6\n>>> ---\n>>>\n>>> OP_CHECKDATASIG\n>>> ===============\n>>>\n>>> OP_CHECKDATASIG and OP_CHECKDATASIGVERIFY check whether a signature is valid with respect to a message and a public key.\n>>>\n>>> OP_CHECKDATASIG permits data to be imported into a script, and have its validity checked against some signing authority such as an \"Oracle\".\n>>>\n>>> OP_CHECKDATASIG and OP_CHECKDATASIGVERIFY are designed to be implemented similarly to OP_CHECKSIG [1]. Conceptually, one could imagine OP_CHECKSIG functionality being replaced by OP_CHECKDATASIG, along with a separate Op Code to create a hash from the transaction based on the SigHash algorithm.\n>>>\n>>> OP_CHECKDATASIG Specification\n>>> -----------------------------\n>>>\n>>> ### Semantics\n>>>\n>>> OP_CHECKDATASIG fails immediately if the stack is not well formed. To be well formed, the stack must contain at least three elements [`<sig>`, `<msg>`, `<pubKey>`] in this order where `<pubKey>` is the top element and\n>>>   * `<pubKey>` must be a validly encoded public key\n>>>   * `<msg>` can be any string\n>>>   * `<sig>` must follow the strict DER encoding as described in [2] and the S-value of `<sig>` must be at most the curve order divided by 2 as described in [3]\n>>>\n>>> If the stack is well formed, then OP_CHECKDATASIG pops the top three elements [`<sig>`, `<msg>`, `<pubKey>`] from the stack and pushes true onto the stack if `<sig>` is valid with respect to the raw single-SHA256 hash of `<msg>` and `<pubKey>` using the secp256k1 elliptic curve. Otherwise, it pops three elements and pushes false onto the stack in the case that `<sig>` is the empty string and fails in all other cases.\n>>>\n>>> Nullfail is enforced the same as for OP_CHECKSIG [3]. If the signature does not match the supplied public key and message hash, and the signature is not an empty byte array, the entire script fails.\n>>>\n>>> ### Opcode Number\n>>>\n>>> OP_CHECKDATASIG uses the previously unused opcode number 186 (0xba in hex encoding)\n>>>\n>>> ### SigOps\n>>>\n>>> Signature operations accounting for OP_CHECKDATASIG shall be calculated the same as OP_CHECKSIG. This means that each OP_CHECKDATASIG shall be counted as one (1) SigOp.\n>>>\n>>> ### Activation\n>>>\n>>> Use of OP_CHECKDATASIG, unless occuring in an unexecuted OP_IF branch, will make the transaction invalid if it is included in a block where the median timestamp of the prior 11 blocks is less than 1542300000.\n>>>\n>>> ### Unit Tests\n>>>\n>>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if 15 November 2018 protocol upgrade is not yet activated.\n>>>  - `<sig> <msg> OP_CHECKDATASIG` fails if there are fewer than 3 items on stack.\n>>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if `<pubKey>` is not a validly encoded public key.\n>>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if `<sig>` is not a validly encoded signature with strict DER encoding.\n>>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if signature `<sig>` is not empty and does not pass the Low S check.\n>>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` fails if signature `<sig>` is not empty and does not pass signature validation of `<msg>` and `<pubKey>`.\n>>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` pops three elements and pushes false onto the stack if `<sig>` is an empty byte array.\n>>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIG` pops three elements and pushes true onto the stack if `<sig>` is a valid signature of `<msg>` with respect to `<pubKey>`.\n>>>\n>>> OP_CHECKDATASIGVERIFY Specification\n>>> -----------------------------------\n>>>\n>>> ### Semantics\n>>>\n>>> OP_CHECKDATASIGVERIFY is equivalent to OP_CHECKDATASIG followed by OP_VERIFY. It leaves nothing on the stack, and will cause the script to fail immediately if the signature check does not pass.\n>>>\n>>> ### Opcode Number\n>>>\n>>> OP_CHECKDATASIGVERIFY uses the previously unused opcode number 187 (0xbb in hex encoding)\n>>>\n>>> ### SigOps\n>>>\n>>> Signature operations accounting for OP_CHECKDATASIGVERIFY shall be calculated the same as OP_CHECKSIGVERIFY. This means that each OP_CHECKDATASIGVERIFY shall be counted as one (1) SigOp.\n>>>\n>>> ### Activation\n>>>\n>>> Use of OP_CHECKDATASIGVERIFY, unless occuring in an unexecuted OP_IF branch, will make the transaction invalid if it is included in a block where the median timestamp of the prior 11 blocks is less than 1542300000.\n>>>\n>>> ### Unit Tests\n>>>\n>>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` fails if 15 November 2018 protocol upgrade is not yet activated.\n>>>  - `<sig> <msg> OP_CHECKDATASIGVERIFY` fails if there are fewer than 3 item on stack.\n>>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY`fails if `<pubKey>` is not a validly encoded public key.\n>>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` fails if `<sig>` is not a validly encoded signature with strict DER encoding.\n>>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` fails if signature `<sig>` is not empty and does not pass the Low S check.\n>>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` fails if `<sig>` is not a valid signature of `<msg>` with respect to `<pubKey>`.\n>>>  - `<sig> <msg> <pubKey> OP_CHECKDATASIGVERIFY` pops the top three stack elements if `<sig>` is a valid signature of `<msg>` with respect to `<pubKey>`.\n>>>\n>>> Sample Implementation [4, 5]\n>>> ----------------------------\n>>>\n>>> ```c++\n>>>                     case OP_CHECKDATASIG:\n>>>                     case OP_CHECKDATASIGVERIFY: {\n>>>                         // Make sure this remains an error before activation.\n>>>                         if ((flags & SCRIPT_ENABLE_CHECKDATASIG) == 0) {\n>>>                             return set_error(serror, SCRIPT_ERR_BAD_OPCODE);\n>>>                         }\n>>>\n>>>                         // (sig message pubkey -- bool)\n>>>                         if (stack.size() < 3) {\n>>>                             return set_error(\n>>>                                 serror, SCRIPT_ERR_INVALID_STACK_OPERATION);\n>>>                         }\n>>>\n>>>                         valtype &vchSig = stacktop(-3);\n>>>                         valtype &vchMessage = stacktop(-2);\n>>>                         valtype &vchPubKey = stacktop(-1);\n>>>\n>>>                         if (!CheckDataSignatureEncoding(vchSig, flags,\n>>>                                                         serror) ||\n>>>                             !CheckPubKeyEncoding(vchPubKey, flags, serror)) {\n>>>                             // serror is set\n>>>                             return false;\n>>>                         }\n>>>\n>>>                         bool fSuccess = false;\n>>>                         if (vchSig.size()) {\n>>>                             valtype vchHash(32);\n>>>                             CSHA256()\n>>>                                 .Write(vchMessage.data(), vchMessage.size())\n>>>                                 .Finalize(vchHash.data());\n>>>                             uint256 message(vchHash);\n>>>                             CPubKey pubkey(vchPubKey);\n>>>                             fSuccess = pubkey.Verify(message, vchSig);\n>>>                         }\n>>>\n>>>                         if (!fSuccess && (flags & SCRIPT_VERIFY_NULLFAIL) &&\n>>>                             vchSig.size()) {\n>>>                             return set_error(serror, SCRIPT_ERR_SIG_NULLFAIL);\n>>>                         }\n>>>\n>>>                         popstack(stack);\n>>>                         popstack(stack);\n>>>                         popstack(stack);\n>>>                         stack.push_back(fSuccess ? vchTrue : vchFalse);\n>>>                         if (opcode == OP_CHECKDATASIGVERIFY) {\n>>>                             if (fSuccess) {\n>>>                                 popstack(stack);\n>>>                             } else {\n>>>                                 return set_error(serror,\n>>>                                                  SCRIPT_ERR_CHECKDATASIGVERIFY);\n>>>                             }\n>>>                         }\n>>>                     } break;\n>>> ```\n>>>\n>>> Sample Usage\n>>> ------------\n>>>\n>>> The following example shows a spend and redeem script for a basic use of CHECKDATASIG.  This example validates the signature of some data, provides a placeholder where you would then process that data, and finally allows one of 2 signatures to spend based on the outcome of the data processing.\n>>>\n>>> ### spend script:\n>>> ```\n>>> push txsignature\n>>> push txpubkey\n>>> push msg\n>>> push sig\n>>> ```\n>>> ### redeem script:\n>>> ```\n>>>                                 (txsig, txpubkey msg, sig)\n>>> OP_OVER                         (txsig, txpubkey, msg, sig, msg)\n>>> push data pubkey                (txsig, txpubkey, msg, sig, msg, pubkey)\n>>> OP_CHECKDATASIGVERIFY           (txsig, txpubkey, msg)\n>>> ```\n>>> Now that msg is on the stack top, the script can write predicates on it,\n>>> resulting in the message being consumed and a true/false condition left on the stack: (txpubkey, txsig, boolean)\n>>> ```\n>>> OP_IF                           (txsig, txpubkey)\n>>>   OP_DUP                        (txsig, txpubkey, txpubkey)\n>>>   OP_HASH160                    (txsig, txpubkey, address)\n>>>   push <p2pkh spend address>    (txsig, txpubkey, address, p2pkh spend address)\n>>>   OP_EQUALVERIFY                (txsig, txpubkey)\n>>>   OP_CHECKSIG\n>>> OP_ELSE\n>>>   (same as if clause but a different <p2pkh spend address>)\n>>> OP_ENDIF\n>>> ```\n>>>\n>>> History\n>>> -------\n>>>\n>>> This specification is based on Andrew Stone\u2019s OP_DATASIGVERIFY proposal [6, 7]. It is modified from Stone's original proposal based on a synthesis of all the peer-review and feedback received [8].\n>>>\n>>> References\n>>> ----------\n>>>\n>>> [1] [OP_CHECKSIG](https://en.bitcoin.it/wiki/OP_CHECKSIG)\n>>>\n>>> [2] [Strict DER Encoding](https://github.com/bitcoin/bips/blob/master/bip-0066.mediawiki)\n>>>\n>>> [3] [Low-S and Nullfail Specification](https://github.com/bitcoin/bips/blob/master/bip-0146.mediawiki)\n>>>\n>>> [4] [Bitcoin ABC implementation](https://reviews.bitcoinabc.org/D1621)\n>>>\n>>> [5] [Bitcoin ABC implementation update](https://reviews.bitcoinabc.org/D1646)\n>>>\n>>> [6] [Andrew Stone\u2019s OP_DATASIGVERIFY](https://github.com/BitcoinUnlimited/BitcoinUnlimited/blob/bucash1.3.0.0/doc/opdatasigverify.md)\n>>>\n>>> [7] [Andrew Stone's article on Scripting](https://medium.com/@g.andrew.stone/bitcoin-scripting-applications-decision-based-spending-8e7b93d7bdb9)\n>>>\n>>> [8] [Peer Review of Andrew Stone's Proposal](https://github.com/bitcoincashorg/bitcoincash.org/pull/10)\n>>>\n>>>\n>>> --\n>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>> <https://twitter.com/JeremyRubin>\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210703/e56d5b04/attachment-0001.html>"
            },
            {
                "author": "Jeremy",
                "date": "2021-07-04T17:30:18",
                "message_text_only": "I don't really see the point of CHECKSIGFROMSTACKADD since it's not bound\nto the txdata? When might you use this?\n\nAnd yes -- \"Add OP_CHECKSIGFROMSTACK and OP_CHECKSIGFROMSTACKVERIFY to\nfollow the semantics from bip340-342 when witness program is v1.\" is a bit\nlight on detail for what the BIP would end up looking like. If you're able\nto open up the design process a bit more on that it would be good as I\nthink there are some topics worth discussing at large before things proceed\nwith Elements (assuming feature compatibility remains a goal).\n\nThe non-prehashed argument seems OK (at the cost of an extra byte...) but\nare there specific applications for !=32 arguments? I can't think of a\nparticular one beyond perhaps efficiency. Can we safely use 0-520 byte\narguments?\n\nAlso do you have thoughts on the other questions i posed above? E.g.\nsplitting R/S could be helpful w/o CAT.\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Sat, Jul 3, 2021 at 1:13 PM Russell O'Connor <roconnor at blockstream.com>\nwrote:\n\n> There is one line written at\n> https://github.com/ElementsProject/elements/pull/949/files#r660130155.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210704/0301926c/attachment.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2021-07-04T19:03:40",
                "message_text_only": "On Sun, Jul 4, 2021 at 1:30 PM Jeremy <jlrubin at mit.edu> wrote:\n\n> I don't really see the point of CHECKSIGFROMSTACKADD since it's not bound\n> to the txdata? When might you use this?\n>\n\nI don't feel strongly about *ADD.  I just figured it might be useful to do\na 2-of-3 between Alice, Bob and an Oracle signed value.  But I don't have\nany particular use case in mind.  Either way the *ADD functionality can be\nreplicated by various SWAPs and ADDs etc, so we could just leave it out\nuntil it is wanted.\n\n\n> And yes -- \"Add OP_CHECKSIGFROMSTACK and OP_CHECKSIGFROMSTACKVERIFY to\n> follow the semantics from bip340-342 when witness program is v1.\" is a bit\n> light on detail for what the BIP would end up looking like. If you're able\n> to open up the design process a bit more on that it would be good as I\n> think there are some topics worth discussing at large before things proceed\n> with Elements (assuming feature compatibility remains a goal).\n>\n\nI'm certainly open to a wider design process.  We can open a specific issue\non the Elements repo.  That said, I don't see a particularly wide design\nspace on this front.\n\n\n> The non-prehashed argument seems OK (at the cost of an extra byte...) but\n> are there specific applications for !=32 arguments? I can't think of a\n> particular one beyond perhaps efficiency. Can we safely use 0-520 byte\n> arguments?\n>\n\nOne of the reasons given in the issue (yes, the thread there is very long)\nwas that hashing the message requires the hash to be collision resistant\nwhile if you give the message directly it only requires the hash to be\n\"random-prefix\" collision / preimage resistant.  For example SHA-1 is\nclearly not collision resistant but it appears to still be random-prefix\ncollision resistant AFAIU.  Another reason is that it allows for extremely\nfast signing oracles because and R value and the midstate of the hash can\nbe precomputed all the way upto the application prefix, and if the message\nbeing signed is less than 55 bytes or so, the signing cost can be as low as\none compression function and a little bit of non-EC modular arithmetic to\ncompute S.  If the message were required to be prehashed, then it would\ntake a minimum of 2 compression function calls to sign, nearly doubling the\nsigning time needed for the fast oracle.\n\nEven if BIP-0340 kept its requirements that the message be exactly 32\nbytes, I would still be inclined to design CHECKSIGFROMSTACK for tapscript\nto take the 32-byte message from the stack instead of hashing a message\nitself (BIP-0340 does it's own hashing, so prehashing the message isn't a\nsecurity concern in the same way it is for ECDSA.)  This would keep the\nmessage off the blockchain, saving space and adding some amount of privacy\nand making the operation compatible with rolling SHA256 opcodes.  But given\nthat BIP-0340 is going to be extended to support non-32 byte messages, then\nthere is no reason to impose a message length restriction on\nCHECKSIGFROMSTACK.  Yes the operation will still be subject to stack item\nlength restrictions.  This is something script writers will have to be\naware of, but I see little reason to support messages split across multiple\nstack items when we expect, by far, most messages to be 32-bytes, and I\nexpect those rare non-32 byte messages are expected to be reasonably short.\n\n\n> Also do you have thoughts on the other questions i posed above? E.g.\n> splitting R/S could be helpful w/o CAT.\n>\n\nRegarding  internal pubkeys and invalid pubkeys, I see no reason to deviate\nfrom whatever tapscript CHECKSIG* do.\n\nRegarding splitting R/S, This is harder because Elements does have CAT and\nI think we should add CAT to Bitcoin too.  This game of trying to prevent\ncovenants by restricting script to the point where we are not even allowed\nto have a CAT operation is a losing game.  It's just a matter of time\nbefore we accidently introduce some way to enable covenants anyways, and it\nis not worth cutting off vast amounts of functionality in pursuit of this\nquestionable goal.  And I say this as someone who was originally of the\nopinion that we should be very very cautious before enabling new\nexpressivity such as covenants.  All the scary scenarios of covenants that\nI am aware of can be more easily, cheaply, and flexibility implemented by\njust having a counterparty in a multi-party signature that enforces their\nown policy that they only sign transactions that pay to outputs that they\nremain a party to.  And even if scary covenants were scarier than what can\nalready be done by multisig and policy, I still don't think they are scary\nenough to warrant keeping CAT disabled.\n\nSo I don't think we should get fancy with CHECKSIGFROMSTACK.  Just take a\nnormal 64-byte signature value as a stack item.  But I don't feel strongly\nabout this, and I wouldn't oppose splitting R and S in Bitcoin if that is\nwhere consensus lies.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210704/b7f6ae05/attachment.html>"
            },
            {
                "author": "Jeremy",
                "date": "2021-07-06T17:54:57",
                "message_text_only": "Re-threading Sanket's comment on split R value:\n\nI also am in general support of the `OP_CHECKSIGFROMSTACK` opcode. We would\n> need to update the suggestion to BIP340, and add it to sigops budget. I\n> have no strong preference for splitting R and s values or variable-length\n> messages.\n>\n\nBack to my comment:\n\n\nI see a few options:\n\n1) Making a new 64 byte PK standard which is (R, PK)\n2) Splitting (R,S)\n3) Different opcodes\n4) CAT\n\nThe drawback of option 1 is that it's designed to support only very\nspecific use cases. The main drawback of splitting via option 2 is that you\nentail an extra push byte for every use. Option 3 wastes opcodes. CAT has\nthe general drawbacks of CAT, but worth noting that CAT will likely\neventually land making the splitting feature redundant.\n\n\nBefore getting too in the weeds, it might be worth listing out interesting\nscript fragments that people are aware of with split R/S so we can see how\nuseful it might be?\n\nUse a specific R Value\n- <S> <M> || <R> SWAP <PK> CSFS\n\nReuse arbitrary R for a specific M (pay to leak key)\n-  <R> <S1> <S2>  ||  DUP2 EQUAL NOT VERIFY 2 PICK SWAP <M> DUP TOALTSTACK\nCSFSV FROMALTSTACK CSFS\n\nVerify 2 different messages reuse the same R.\n- <S1> <R> <M1> <S2> <M2> ||  2 PICK EQUAL NOT VERIFY 3 PICK <PK> DUP\nTOALTSTACK CSFSV FROMALTSTACK CSFS\n\nUse a R Value signed by an oracle:\n- <S> <M> <S_oracle> <R_oracle> <R> || DUP TOALTSTACK <PK_oracle> CSFSV\nFROMALTSTACK SWAP <PK> CSFS\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210706/b480247e/attachment.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2021-07-06T18:21:33",
                "message_text_only": "If the main outstanding issue is whether to split R or S, I think as far as\nElements goes, I am inclined to go with the CAT option regardless of\nwhether Bitcoin chooses to split R/S or not (not that I'm necessarily a\ndecision maker here).\n\nThe issue here is that (a) Elements already has CAT, and (b) updating\nCHECKSIGFROMSTACK is effectively a blocking issue for deploying Taproot on\nElements.  I don't think we will be holding up CHECKSIGFROMSTACK for this\nissue even if it risks being incompatible with an eventual Bitcoin\nCHECKSIGFROMSTACK.\n\nTo be clear, I don't mean to prejudice this discussion by this statement.\nThis just happens to be what makes sense for the Elements project at this\ntime, and what makes sense for Elements may not necessarily make sense for\nBitcoin.\n\nOf course, I think we should just go for CAT compatibility.  Otherwise we\nare just going to have a proliferation of trusted CAT oracles paid for with\nlightning by people wanting to perform CAT operations.\n\nOn Tue, Jul 6, 2021 at 1:55 PM Jeremy via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Re-threading Sanket's comment on split R value:\n>\n> I also am in general support of the `OP_CHECKSIGFROMSTACK` opcode. We\n>> would need to update the suggestion to BIP340, and add it to sigops budget.\n>> I have no strong preference for splitting R and s values or variable-length\n>> messages.\n>>\n>\n> Back to my comment:\n>\n>\n> I see a few options:\n>\n> 1) Making a new 64 byte PK standard which is (R, PK)\n> 2) Splitting (R,S)\n> 3) Different opcodes\n> 4) CAT\n>\n> The drawback of option 1 is that it's designed to support only very\n> specific use cases. The main drawback of splitting via option 2 is that you\n> entail an extra push byte for every use. Option 3 wastes opcodes. CAT has\n> the general drawbacks of CAT, but worth noting that CAT will likely\n> eventually land making the splitting feature redundant.\n>\n>\n> Before getting too in the weeds, it might be worth listing out interesting\n> script fragments that people are aware of with split R/S so we can see how\n> useful it might be?\n>\n> Use a specific R Value\n> - <S> <M> || <R> SWAP <PK> CSFS\n>\n> Reuse arbitrary R for a specific M (pay to leak key)\n> -  <R> <S1> <S2>  ||  DUP2 EQUAL NOT VERIFY 2 PICK SWAP <M> DUP TOALTSTACK\n> CSFSV FROMALTSTACK CSFS\n>\n> Verify 2 different messages reuse the same R.\n> - <S1> <R> <M1> <S2> <M2> ||  2 PICK EQUAL NOT VERIFY 3 PICK <PK> DUP\n> TOALTSTACK CSFSV FROMALTSTACK CSFS\n>\n> Use a R Value signed by an oracle:\n> - <S> <M> <S_oracle> <R_oracle> <R> || DUP TOALTSTACK <PK_oracle> CSFSV\n> FROMALTSTACK SWAP <PK> CSFS\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210706/d047ffd2/attachment.html>"
            },
            {
                "author": "Jeremy",
                "date": "2021-07-06T18:53:32",
                "message_text_only": "I don't think Elements engineering decisions or management timelines should\nhave any bearing on what Bitcoin adopts, beyond learning what\nworks/doesn't. Same as litecoin, dogecoin, or bitcoin cash :)\n\nWith my understanding of elements it makes sense that you wouldn't want to\nbreak compatibility script version to script version, although that seems\ninevitable that you will need to either hard fork or break compatibility if\nyou want to fix the CHECKSIGFROMSTACK has verify semantics bug. But perhaps\nthat's a smaller change than the # of stack elements popped? It makes sense\nhaving CAT that adding a split CSFS wouldn't be a priority. However, I'd\nsuggest that as far as elements is concerned, if the bitcoin community\ndecides on something that is incompatible, elements can use up some\naddition opcodes or a keytype to add CSFS_BITCOIN_COMPAT ops.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210706/8660390f/attachment-0001.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2021-07-04T01:13:41",
                "message_text_only": "On Sat, Jul 03, 2021 at 09:31:57AM -0700, Jeremy via bitcoin-dev wrote:\n> Note that with *just* CheckSigFromStack, while you can do some very\n> valuable use cases, but without OP_CAT it does not enable sophisticated\n> covenants\n\nDo you have concerns about sophisticated covenants, and if so, would you\nmind describing them?  Your BIP119 CTV also mentions[1] being designed\nto avoid sophisticated covenants.  If this is some sort of design\nprinciple, I'd like to understand the logic behind it.\n\nI'm a fan of CSFS, even mentioning it on zndtoshi's recent survey[2],\nbut it seems artificially limited without OP_CAT.  (I also stand by my\nanswer on that survey of believing there's a deep lack of developer\ninterest in CSFS at the moment.  But, if you'd like to tilt at that\nwindmill, I won't stop you.)\n\n-Dave\n\n[1] https://github.com/bitcoin/bips/blob/master/bip-0119.mediawiki#design-tradeoffs-and-risks\n\n[2] https://twitter.com/zndtoshi/status/1405235814712422402\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210703/0e0be72f/attachment.sig>"
            },
            {
                "author": "Jeremy",
                "date": "2021-07-04T18:39:44",
                "message_text_only": ">\n> Do you have concerns about sophisticated covenants, and if so, would you\n> mind describing them?\n\n\nPersonally, not in particular worried about arbitrary covenants as I think\nthat: 1 validation costs can be kept in check; 2 you're free to burn your\ncoins it you want to.\n\nI *do* care that when we enable covenants we don't make people jump through\ntoo many hoops, but I also respect Russel's points that we can enable\nfunctionality and then later figure out how to make it more efficient or\nuseful guided by use cases.\n\n\nHowever, I think the broader community is unconvinced by the cost benefit\nof arbitrary covenants. See\nhttps://medium.com/block-digest-mempool/my-worries-about-too-generalized-covenants-5eff33affbb6\nas a recent example. Therefore as a critical part of building consensus on\nvarious techniques I've worked to emphasize that specific additions do not\nentail risk of accidentally introducing more than was bargained for to\nrespect the concerns of others.\n\n\n>\n> I'm a fan of CSFS, even mentioning it on zndtoshi's recent survey[2],\n> but it seems artificially limited without OP_CAT.  (I also stand by my\n> answer on that survey of believing there's a deep lack of developer\n> interest in CSFS at the moment.  But, if you'd like to tilt at that\n> windmill, I won't stop you.)\n\n\nWell if you're a fan of it, I'm a fan of it, Russel's a fan of it, and\nSanket's a fan of it that sounds like a good amount of dev interest :) I\nknow Olaoluwa is also a fan of it too and has some cool L2 protocols using\nit.\n\nI think it might not be *hype* because it's been around a while and has\nalways been bundled with cat so been a non starter for the reasons above. I\nthink as an independent non-bundle it's exciting and acceptable to a number\nof devs. I also believe upgrades can be developed and tracked in parallel\nso I'm taking on the windmill tilting personally to spearhead that -- on\nthe shoulders of Giants who have been creating specs for this already of\ncourse.\n\nBest,\n\nJeremy\n\nP.s. icymi https://rubin.io/blog/2021/07/02/covenants/ covers my current\nthinking about how to proceed w.r.t. deploying and developing covenant\nsystems for bitcoin\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210704/186f65c4/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "CHECKSIGFROMSTACK/{Verify} BIP for Bitcoin",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Russell O'Connor",
                "Jeremy",
                "David A. Harding"
            ],
            "messages_count": 11,
            "total_messages_chars_count": 72005
        }
    },
    {
        "title": "[bitcoin-dev] Unlimited covenants, was Re:  CHECKSIGFROMSTACK/{Verify} BIP for Bitcoin",
        "thread_messages": [
            {
                "author": "David A. Harding",
                "date": "2021-07-04T20:32:30",
                "message_text_only": "On Sun, Jul 04, 2021 at 11:39:44AM -0700, Jeremy wrote:\n> However, I think the broader community is unconvinced by the cost benefit\n> of arbitrary covenants. See\n> https://medium.com/block-digest-mempool/my-worries-about-too-generalized-covenants-5eff33affbb6\n> as a recent example. Therefore as a critical part of building consensus on\n> various techniques I've worked to emphasize that specific additions do not\n> entail risk of accidentally introducing more than was bargained for to\n> respect the concerns of others.\n\nRespecting the concerns of others doesn't require lobotomizing useful\ntools.  Being respectful can also be accomplished by politely showing\nthat their concerns are unfounded (or at least less severe than they\nthought).  This is almost always the better course IMO---it takes much\nmore effort to satisfy additional engineering constraints (and prove to\nreviewers that you've done so!) than it does to simply discuss those\nconcerns with reasonable stakeholders.  As a demonstration, let's look\nat the concerns from Shinobi's post linked above:\n\nThey seem to be worried that some Bitcoin users will choose to accept\ncoins that can't subsequently be fungibily mixed with other bitcoins.\nBut that's already been the case for a decade: users can accept altcoins\nthat are non-fungible with bitcoins.\n\nThey talk about covenants where spending is controlled by governments,\nbut that seems to me exactly like China's CBDC trial.\n\nThey talk about exchanges depositing users' BTC into a covenant, but \nthat's just a variation on the classic not-your-keys-not-your-bitcoins\nproblem.  For all you know, your local exchange is keeping most of its\nBTC balance commitments in ETH or USDT.\n\nTo me, it seems like the worst-case problems Shinobi describes with\ncovenants are some of the same problems that already exist with\naltcoins.  I don't see how recursive covenants could make any of those\nproblems worse, and so I don't see any point in limiting Bitcoin's\nflexibility to avoid those problems when there are so many interesting\nand useful things that unlimited covenants could do.\n\n-Dave\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210704/141168f5/attachment.sig>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-07-05T00:50:50",
                "message_text_only": "Good morning Dave,\n\n> On Sun, Jul 04, 2021 at 11:39:44AM -0700, Jeremy wrote:\n>\n> > However, I think the broader community is unconvinced by the cost benefit\n> > of arbitrary covenants. See\n> > https://medium.com/block-digest-mempool/my-worries-about-too-generalized-covenants-5eff33affbb6\n> > as a recent example. Therefore as a critical part of building consensus on\n> > various techniques I've worked to emphasize that specific additions do not\n> > entail risk of accidentally introducing more than was bargained for to\n> > respect the concerns of others.\n>\n> Respecting the concerns of others doesn't require lobotomizing useful\n> tools. Being respectful can also be accomplished by politely showing\n> that their concerns are unfounded (or at least less severe than they\n> thought). This is almost always the better course IMO---it takes much\n> more effort to satisfy additional engineering constraints (and prove to\n> reviewers that you've done so!) than it does to simply discuss those\n> concerns with reasonable stakeholders. As a demonstration, let's look\n> at the concerns from Shinobi's post linked above:\n>\n> They seem to be worried that some Bitcoin users will choose to accept\n> coins that can't subsequently be fungibily mixed with other bitcoins.\n> But that's already been the case for a decade: users can accept altcoins\n> that are non-fungible with bitcoins.\n>\n> They talk about covenants where spending is controlled by governments,\n> but that seems to me exactly like China's CBDC trial.\n>\n> They talk about exchanges depositing users' BTC into a covenant, but\n> that's just a variation on the classic not-your-keys-not-your-bitcoins\n> problem. For all you know, your local exchange is keeping most of its\n> BTC balance commitments in ETH or USDT.\n>\n> To me, it seems like the worst-case problems Shinobi describes with\n> covenants are some of the same problems that already exist with\n> altcoins. I don't see how recursive covenants could make any of those\n> problems worse, and so I don't see any point in limiting Bitcoin's\n> flexibility to avoid those problems when there are so many interesting\n> and useful things that unlimited covenants could do.\n\nThe \"altcoins are even worse\" argument does seem quite convincing, and if Bitcoin can survive altcoins, surely it can survive covenants too?\n\nIn before \"turns out covenants are the next ICO\".\ni.e. ICOs are just colored coins, which are useful for keeping track of various stuff, but have then been used as a vehicle to scam people.\nBut I suppose that is a problem that humans will always have: limited cognition, so that *good* popular things that are outside your specific field of study are indistinguishable from *bad* popular things.\nSo perhaps it should not be a concern on a technical level.\nMaybe we should instead make articles about covenants so boring nobody will hype about it (^^;)v.\n\nIncreased functionality implies increased processing, and hopefully computation devices are getting cheap enough that the increased processing implied by new features should not be too onerous.\n\n\n\nTo my mind, an \"inescapable\" covenant (i.e. one that requires the output to be paid to the same covenant) is basically a Turing machine, and equivalent to a `while (true);` loop.\nIn a `while (true);` loop, the state of the machine reverts back to the same state, and it repeats again.\nIn an inescpable covenant, the control of some amount of funds reverts back to the same controlling SCRIPT, and it repeats again.\nYes, you can certainly add more functionality on top of that loop, just think of program main loops for games or daemons, which are, in essence, \"just\" `while (true) ...`.\nBut basically, such unbounded infinite loops are possible only under Turing machines, thus I consider covenants to be Turing-complete.\nPrinciple of Least Power should make us wonder if we need full Turing machines for the functionality.\n\nOn the other hand --- codata processing *does* allow for unbounded loops, without requiring full Turing-completeness; they just require total functionality, not partial (and Turing-completeness is partial, not total).\nBasically, data structures are unbounded storage, while codata structures are unbounded processing.\nPerhaps covenants can encode an upper bound on the number of recursions, which prevents full Turing-completeness while allowing for a large number of use-cases.\n\n(if the above paragraph makes no sense to you, hopefully this Wikipedia article will help: https://en.wikipedia.org/wiki/Total_functional_programming )\n(basically my argument here is based on academic programming stuff, and might not actually matter in real life)\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Unlimited covenants, was Re:  CHECKSIGFROMSTACK/{Verify} BIP for Bitcoin",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "David A. Harding"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 7024
        }
    },
    {
        "title": "[bitcoin-dev] Unlimited covenants, was Re: CHECKSIGFROMSTACK/{Verify} BIP for Bitcoin",
        "thread_messages": [
            {
                "author": "Billy Tetrud",
                "date": "2021-07-04T20:50:43",
                "message_text_only": "I agree with you David. I think rather unconstrained covenants are\nincredibly useful and important. Yes you can burn coins with them, you can\nalso permanently limit the usability of certain coins (which is less\ndestructive than burning them). But as Jeremy said, people are free to burn\ntheir coins. People would also be free (in general) to reject coins\nencumbered by weird government provisions or unknown provisions in hidden\nscripts. A person/wallet shouldn't accept coins encumbered by scripts it\ndoesn't recognize.\n\nEven if 99% of bitcoins became permanently encumbered by weird covenants,\nthe other 1% could still be plenty of bitcoins to run the economy, because\nof its potentially infinite divisibility. Losing these coins, or someone\nbasically turning them into altcoin-like bitcoins shouldn't be a concern\nreally. What's the risk exactly? That people will be forced to take these\nencumbered coins? A government can already force people to take whatever\naltcoin they want to force on people - covenants don't make this worse.\n\nShinobi asks: \"What if you extorted users with your 51% attack to move into\nthose?\"\n\nWell, you could do this anyway even without covenants existing already. The\n51% attack could simply extort people to use whatever rules they want just\nas easily (which isn't to say that easily - most users would probably\nrefuse to be extorted in either case). So I don't really think this is very\nvalid.\n\nOn Sun, Jul 4, 2021 at 1:33 PM David A. Harding via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Sun, Jul 04, 2021 at 11:39:44AM -0700, Jeremy wrote:\n> > However, I think the broader community is unconvinced by the cost benefit\n> > of arbitrary covenants. See\n> >\n> https://medium.com/block-digest-mempool/my-worries-about-too-generalized-covenants-5eff33affbb6\n> > as a recent example. Therefore as a critical part of building consensus\n> on\n> > various techniques I've worked to emphasize that specific additions do\n> not\n> > entail risk of accidentally introducing more than was bargained for to\n> > respect the concerns of others.\n>\n> Respecting the concerns of others doesn't require lobotomizing useful\n> tools.  Being respectful can also be accomplished by politely showing\n> that their concerns are unfounded (or at least less severe than they\n> thought).  This is almost always the better course IMO---it takes much\n> more effort to satisfy additional engineering constraints (and prove to\n> reviewers that you've done so!) than it does to simply discuss those\n> concerns with reasonable stakeholders.  As a demonstration, let's look\n> at the concerns from Shinobi's post linked above:\n>\n> They seem to be worried that some Bitcoin users will choose to accept\n> coins that can't subsequently be fungibily mixed with other bitcoins.\n> But that's already been the case for a decade: users can accept altcoins\n> that are non-fungible with bitcoins.\n>\n> They talk about covenants where spending is controlled by governments,\n> but that seems to me exactly like China's CBDC trial.\n>\n> They talk about exchanges depositing users' BTC into a covenant, but\n> that's just a variation on the classic not-your-keys-not-your-bitcoins\n> problem.  For all you know, your local exchange is keeping most of its\n> BTC balance commitments in ETH or USDT.\n>\n> To me, it seems like the worst-case problems Shinobi describes with\n> covenants are some of the same problems that already exist with\n> altcoins.  I don't see how recursive covenants could make any of those\n> problems worse, and so I don't see any point in limiting Bitcoin's\n> flexibility to avoid those problems when there are so many interesting\n> and useful things that unlimited covenants could do.\n>\n> -Dave\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210704/f743e180/attachment-0001.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2021-07-05T01:02:25",
                "message_text_only": "Bear in mind that when people are talking about enabling covenants, we are\ntalking about whether OP_CAT should be allowed or not.\n\nThat said, recursive covenants, the type that are most worrying, seems to\nrequire some kind of OP_TWEAK operation, and I haven't yet seen any\nevidence that this can be simulated with CHECKSIG(FROMSTACK).  So maybe we\nshould leave such worries for the OP_TWEAK operation.\n\nOn Sun, Jul 4, 2021 at 8:51 PM ZmnSCPxj via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Dave,\n>\n> > On Sun, Jul 04, 2021 at 11:39:44AM -0700, Jeremy wrote:\n> >\n> > > However, I think the broader community is unconvinced by the cost\n> benefit\n> > > of arbitrary covenants. See\n> > >\n> https://medium.com/block-digest-mempool/my-worries-about-too-generalized-covenants-5eff33affbb6\n> > > as a recent example. Therefore as a critical part of building\n> consensus on\n> > > various techniques I've worked to emphasize that specific additions do\n> not\n> > > entail risk of accidentally introducing more than was bargained for to\n> > > respect the concerns of others.\n> >\n> > Respecting the concerns of others doesn't require lobotomizing useful\n> > tools. Being respectful can also be accomplished by politely showing\n> > that their concerns are unfounded (or at least less severe than they\n> > thought). This is almost always the better course IMO---it takes much\n> > more effort to satisfy additional engineering constraints (and prove to\n> > reviewers that you've done so!) than it does to simply discuss those\n> > concerns with reasonable stakeholders. As a demonstration, let's look\n> > at the concerns from Shinobi's post linked above:\n> >\n> > They seem to be worried that some Bitcoin users will choose to accept\n> > coins that can't subsequently be fungibily mixed with other bitcoins.\n> > But that's already been the case for a decade: users can accept altcoins\n> > that are non-fungible with bitcoins.\n> >\n> > They talk about covenants where spending is controlled by governments,\n> > but that seems to me exactly like China's CBDC trial.\n> >\n> > They talk about exchanges depositing users' BTC into a covenant, but\n> > that's just a variation on the classic not-your-keys-not-your-bitcoins\n> > problem. For all you know, your local exchange is keeping most of its\n> > BTC balance commitments in ETH or USDT.\n> >\n> > To me, it seems like the worst-case problems Shinobi describes with\n> > covenants are some of the same problems that already exist with\n> > altcoins. I don't see how recursive covenants could make any of those\n> > problems worse, and so I don't see any point in limiting Bitcoin's\n> > flexibility to avoid those problems when there are so many interesting\n> > and useful things that unlimited covenants could do.\n>\n> The \"altcoins are even worse\" argument does seem quite convincing, and if\n> Bitcoin can survive altcoins, surely it can survive covenants too?\n>\n> In before \"turns out covenants are the next ICO\".\n> i.e. ICOs are just colored coins, which are useful for keeping track of\n> various stuff, but have then been used as a vehicle to scam people.\n> But I suppose that is a problem that humans will always have: limited\n> cognition, so that *good* popular things that are outside your specific\n> field of study are indistinguishable from *bad* popular things.\n> So perhaps it should not be a concern on a technical level.\n> Maybe we should instead make articles about covenants so boring nobody\n> will hype about it (^^;)v.\n>\n> Increased functionality implies increased processing, and hopefully\n> computation devices are getting cheap enough that the increased processing\n> implied by new features should not be too onerous.\n>\n>\n>\n> To my mind, an \"inescapable\" covenant (i.e. one that requires the output\n> to be paid to the same covenant) is basically a Turing machine, and\n> equivalent to a `while (true);` loop.\n> In a `while (true);` loop, the state of the machine reverts back to the\n> same state, and it repeats again.\n> In an inescpable covenant, the control of some amount of funds reverts\n> back to the same controlling SCRIPT, and it repeats again.\n> Yes, you can certainly add more functionality on top of that loop, just\n> think of program main loops for games or daemons, which are, in essence,\n> \"just\" `while (true) ...`.\n> But basically, such unbounded infinite loops are possible only under\n> Turing machines, thus I consider covenants to be Turing-complete.\n> Principle of Least Power should make us wonder if we need full Turing\n> machines for the functionality.\n>\n> On the other hand --- codata processing *does* allow for unbounded loops,\n> without requiring full Turing-completeness; they just require total\n> functionality, not partial (and Turing-completeness is partial, not total).\n> Basically, data structures are unbounded storage, while codata structures\n> are unbounded processing.\n> Perhaps covenants can encode an upper bound on the number of recursions,\n> which prevents full Turing-completeness while allowing for a large number\n> of use-cases.\n>\n> (if the above paragraph makes no sense to you, hopefully this Wikipedia\n> article will help:\n> https://en.wikipedia.org/wiki/Total_functional_programming )\n> (basically my argument here is based on academic programming stuff, and\n> might not actually matter in real life)\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210704/21a239fc/attachment.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2021-07-05T02:10:17",
                "message_text_only": "On Sun, Jul 4, 2021 at 9:02 PM Russell O'Connor <roconnor at blockstream.com>\nwrote:\n\n> Bear in mind that when people are talking about enabling covenants, we are\n> talking about whether OP_CAT should be allowed or not.\n>\n> That said, recursive covenants, the type that are most worrying, seems to\n> require some kind of OP_TWEAK operation, and I haven't yet seen any\n> evidence that this can be simulated with CHECKSIG(FROMSTACK).  So maybe we\n> should leave such worries for the OP_TWEAK operation.\n>\n\nUpon further thought, you can probably make recursive covenants even with a\nfixed scritpubkey by sneaking the state into a few bits of the UTXO's\namount.  Or if you try really hard, you may be able to stash your state\ninto a sibling output that is accessed via the txid embedded in the\nprevoutpoint.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210704/b5a2a3f1/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-07-05T02:39:08",
                "message_text_only": "Good morning Russell,\n\n\n> On Sun, Jul 4, 2021 at 9:02 PM Russell O'Connor <roconnor at blockstream.com> wrote:\n>\n> > Bear in mind that when people are talking about enabling covenants, we are talking about whether OP_CAT should be allowed or not.\n> >\n> > That said, recursive covenants, the type that are most worrying, seems to require some kind of OP_TWEAK operation, and I haven't yet seen any evidence that this can be simulated with CHECKSIG(FROMSTACK).\u00a0 So maybe we should leave such worries for the OP_TWEAK operation.\n>\n> Upon further thought, you can probably make recursive covenants even with a fixed scritpubkey by sneaking the state into a few bits of the UTXO's amount.\u00a0 Or if you try really hard, you may be able to stash your state into a sibling output that is accessed via the txid embedded in the prevoutpoint.\n\nWhich is kind of the point of avoiding giving too much power, because people can be very clever and start doing unexpected things from what you think is already a limited subset.\n\"Give an inch and they will take a mile\".\n\nStill, as pointed out, altcoins already exist and are substantially worse, and altcoin implementations are all going to run on Turing machines anyway (which are powerful enough to offer Turing-machine functionality), so maybe this is not really giving too much power, people can already fork Bitcoin and add full EVM support on it.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Anthony Towns",
                "date": "2021-07-05T05:04:21",
                "message_text_only": "On Sun, Jul 04, 2021 at 09:02:25PM -0400, Russell O'Connor via bitcoin-dev wrote:\n> Bear in mind that when people are talking about enabling covenants, we are\n> talking about whether OP_CAT should be allowed or not.\n\nIn some sense multisig *alone* enables recursive covenants: a government\nthat wants to enforce KYC can require that funds be deposited into\na multisig of \"2 <recipient> <gov_key> 2 CHECKMULTISIG\", and that\n\"recipient\" has gone through KYC. Once deposited to such an address,\nthe gov can refus to sign with gov_key unless the funds are being spent\nto a new address that follows the same rules.\n\n(That's also more efficient than an explicit covenant since it's all\noff-chain -- recipient/gov_key can jointly sign via taproot/MuSig at\nthat point, so that full nodes are only validating a single pubkey and\nsignature per spend, rather than having to do analysis of whatever the\nunderlying covenant is supposed to be [0])\n\nThis is essentially what Liquid already does -- it locks bitcoins into\na multisig and enforces an \"off-chain\" covenant that those bitcoins can\nonly be redeemed after some valid set of signatures are entered into\nthe Liquid blockchain. Likewise for the various BTC-on-Ethereum tokens.\nTo some extent, likewise for coins held in exchanges/custodial wallets\nwhere funds can be transferred between customers off-chain.\n\nYou can \"escape\" from that recursive covenant by having the government\n(or Liquid functionaries, or exchange admins) change their signing\npolicy of course; but you could equally escape any consensus-enforced\ncovenant by having a hard fork to stop doing consensus-enforcement (cf\nETH Classic?). To me, that looks more like a difference of procedure\nand difficulty, rather than a fundamental difference in kind.\n\nCheers,\naj\n\n[0] https://twitter.com/pwuille/status/1411533549224693762"
            },
            {
                "author": "Matt Corallo",
                "date": "2021-07-05T13:46:21",
                "message_text_only": "I find this point to be incredibly important. Indeed I, like several others, have historically been concerned with \ncovenants in the unbounded form. However, as more and more research has been done in what they can accomplish, the \nweighting of such arguments naturally has to be reduced. More importantly, AJ's point here neuters anti-covanent \narguments rather strongly.\n\nMatt\n\nOn 7/5/21 01:04, Anthony Towns via bitcoin-dev wrote:\n> On Sun, Jul 04, 2021 at 09:02:25PM -0400, Russell O'Connor via bitcoin-dev wrote:\n>> Bear in mind that when people are talking about enabling covenants, we are\n>> talking about whether OP_CAT should be allowed or not.\n> \n> In some sense multisig *alone* enables recursive covenants: a government\n> that wants to enforce KYC can require that funds be deposited into\n> a multisig of \"2 <recipient> <gov_key> 2 CHECKMULTISIG\", and that\n> \"recipient\" has gone through KYC. Once deposited to such an address,\n> the gov can refus to sign with gov_key unless the funds are being spent\n> to a new address that follows the same rules.\n> \n> (That's also more efficient than an explicit covenant since it's all\n> off-chain -- recipient/gov_key can jointly sign via taproot/MuSig at\n> that point, so that full nodes are only validating a single pubkey and\n> signature per spend, rather than having to do analysis of whatever the\n> underlying covenant is supposed to be [0])\n> \n> This is essentially what Liquid already does -- it locks bitcoins into\n> a multisig and enforces an \"off-chain\" covenant that those bitcoins can\n> only be redeemed after some valid set of signatures are entered into\n> the Liquid blockchain. Likewise for the various BTC-on-Ethereum tokens.\n> To some extent, likewise for coins held in exchanges/custodial wallets\n> where funds can be transferred between customers off-chain.\n> \n> You can \"escape\" from that recursive covenant by having the government\n> (or Liquid functionaries, or exchange admins) change their signing\n> policy of course; but you could equally escape any consensus-enforced\n> covenant by having a hard fork to stop doing consensus-enforcement (cf\n> ETH Classic?). To me, that looks more like a difference of procedure\n> and difficulty, rather than a fundamental difference in kind.\n> \n> Cheers,\n> aj\n> \n> [0] https://twitter.com/pwuille/status/1411533549224693762\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Greg Sanders",
                "date": "2021-07-05T13:51:25",
                "message_text_only": "Funny AJ mentions the multisig idea, because I know for a fact it's being\nused in certain permissioned systems in this exact way. Regulators will\ndream up these ideas with or without more useful covenants!\n\nOn Mon, Jul 5, 2021 at 9:46 PM Matt Corallo via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I find this point to be incredibly important. Indeed I, like several\n> others, have historically been concerned with\n> covenants in the unbounded form. However, as more and more research has\n> been done in what they can accomplish, the\n> weighting of such arguments naturally has to be reduced. More importantly,\n> AJ's point here neuters anti-covanent\n> arguments rather strongly.\n>\n> Matt\n>\n> On 7/5/21 01:04, Anthony Towns via bitcoin-dev wrote:\n> > On Sun, Jul 04, 2021 at 09:02:25PM -0400, Russell O'Connor via\n> bitcoin-dev wrote:\n> >> Bear in mind that when people are talking about enabling covenants, we\n> are\n> >> talking about whether OP_CAT should be allowed or not.\n> >\n> > In some sense multisig *alone* enables recursive covenants: a government\n> > that wants to enforce KYC can require that funds be deposited into\n> > a multisig of \"2 <recipient> <gov_key> 2 CHECKMULTISIG\", and that\n> > \"recipient\" has gone through KYC. Once deposited to such an address,\n> > the gov can refus to sign with gov_key unless the funds are being spent\n> > to a new address that follows the same rules.\n> >\n> > (That's also more efficient than an explicit covenant since it's all\n> > off-chain -- recipient/gov_key can jointly sign via taproot/MuSig at\n> > that point, so that full nodes are only validating a single pubkey and\n> > signature per spend, rather than having to do analysis of whatever the\n> > underlying covenant is supposed to be [0])\n> >\n> > This is essentially what Liquid already does -- it locks bitcoins into\n> > a multisig and enforces an \"off-chain\" covenant that those bitcoins can\n> > only be redeemed after some valid set of signatures are entered into\n> > the Liquid blockchain. Likewise for the various BTC-on-Ethereum tokens.\n> > To some extent, likewise for coins held in exchanges/custodial wallets\n> > where funds can be transferred between customers off-chain.\n> >\n> > You can \"escape\" from that recursive covenant by having the government\n> > (or Liquid functionaries, or exchange admins) change their signing\n> > policy of course; but you could equally escape any consensus-enforced\n> > covenant by having a hard fork to stop doing consensus-enforcement (cf\n> > ETH Classic?). To me, that looks more like a difference of procedure\n> > and difficulty, rather than a fundamental difference in kind.\n> >\n> > Cheers,\n> > aj\n> >\n> > [0] https://twitter.com/pwuille/status/1411533549224693762\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210705/091783a4/attachment.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2021-07-05T17:20:22",
                "message_text_only": "Hi ZmnSCPxj,\n\nI don't believe we need to ban Turing completeness for the sake of banning\nTuring completeness.  My concerns have always been around ensuring that\ntransaction and block validation is not unduly burdensome for nodes.  So\nfor Bitcoin Script, we want to bound the amount of resources needed to\nexecute it, preferably as a linear function of weight[1], and preferably\nhave it clear what the evaluation costs are going to be prior to\nevaluation[2].  We also want to keep Script execution as a pure function of\nthe transaction data so that nodes do not need to reevaluate their mempool\non every new block.  For consensus purposes we prefer to have simple\nprimitive operations that have clear and precise semantics that are as\nlikely as possible to be reimplemented correctly if they are reimplemented\n(or at least let us not make this problem worse than it already is).  In\nparticular, Script needs to be easy to parse to avoid weird parsing\nmachines that lead to security vulnerabilities within node software.\n\nWhile the above design constraints imply a prohibition on Turing complete\ncomputation within a single Script, they do not imply a prohibition on\narbitrary, covenant-enabled computations that spans across multiple\ntransactions.  Neither would these constraints prohibit some kind of STARK\nor SNARK tapleaf version that was somehow capable of succinctly\nrepresenting arbitrary computations, so long as validation costs remain\nbounded.\n\nAnd while it is true that covenant-enabled computations could allow users\nto put their funds at risk through weird machines that manipulate their\nmoney on the blockchain, as longs as that weirdness stays at that level of\nthe abstract Bitcoin Script machine, then I suppose it is *caveat emptor*;\ndon't send your funds to random unverified Bitcoin Scripts, advice that is\nalready the case today.  We can keep that potential weirdness at bay by\nkeeping Script simple, and maintaining our understanding that the Script\nprograms (like the rest of the blockchain data) are untrusted inputs and\nthey need to be validated and scrutinized before interpretation.\n\n[1] In tapscript I believe all operations are linear time with the\nexception of OP_ROLL.  However OP_ROLL is still constrained by global\nlimits on stack size, etc.\n[2] In Bitcoin Script, without loops of any kind, every opcode is evaluated\nat most once, so counting opcodes is an easy way to put an upper bound on\nyour costs before evaluation.\n\nOn Sun, Jul 4, 2021 at 8:51 PM ZmnSCPxj via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Dave,\n>\n> > On Sun, Jul 04, 2021 at 11:39:44AM -0700, Jeremy wrote:\n> >\n> > > However, I think the broader community is unconvinced by the cost\n> benefit\n> > > of arbitrary covenants. See\n> > >\n> https://medium.com/block-digest-mempool/my-worries-about-too-generalized-covenants-5eff33affbb6\n> > > as a recent example. Therefore as a critical part of building\n> consensus on\n> > > various techniques I've worked to emphasize that specific additions do\n> not\n> > > entail risk of accidentally introducing more than was bargained for to\n> > > respect the concerns of others.\n> >\n> > Respecting the concerns of others doesn't require lobotomizing useful\n> > tools. Being respectful can also be accomplished by politely showing\n> > that their concerns are unfounded (or at least less severe than they\n> > thought). This is almost always the better course IMO---it takes much\n> > more effort to satisfy additional engineering constraints (and prove to\n> > reviewers that you've done so!) than it does to simply discuss those\n> > concerns with reasonable stakeholders. As a demonstration, let's look\n> > at the concerns from Shinobi's post linked above:\n> >\n> > They seem to be worried that some Bitcoin users will choose to accept\n> > coins that can't subsequently be fungibily mixed with other bitcoins.\n> > But that's already been the case for a decade: users can accept altcoins\n> > that are non-fungible with bitcoins.\n> >\n> > They talk about covenants where spending is controlled by governments,\n> > but that seems to me exactly like China's CBDC trial.\n> >\n> > They talk about exchanges depositing users' BTC into a covenant, but\n> > that's just a variation on the classic not-your-keys-not-your-bitcoins\n> > problem. For all you know, your local exchange is keeping most of its\n> > BTC balance commitments in ETH or USDT.\n> >\n> > To me, it seems like the worst-case problems Shinobi describes with\n> > covenants are some of the same problems that already exist with\n> > altcoins. I don't see how recursive covenants could make any of those\n> > problems worse, and so I don't see any point in limiting Bitcoin's\n> > flexibility to avoid those problems when there are so many interesting\n> > and useful things that unlimited covenants could do.\n>\n> The \"altcoins are even worse\" argument does seem quite convincing, and if\n> Bitcoin can survive altcoins, surely it can survive covenants too?\n>\n> In before \"turns out covenants are the next ICO\".\n> i.e. ICOs are just colored coins, which are useful for keeping track of\n> various stuff, but have then been used as a vehicle to scam people.\n> But I suppose that is a problem that humans will always have: limited\n> cognition, so that *good* popular things that are outside your specific\n> field of study are indistinguishable from *bad* popular things.\n> So perhaps it should not be a concern on a technical level.\n> Maybe we should instead make articles about covenants so boring nobody\n> will hype about it (^^;)v.\n>\n> Increased functionality implies increased processing, and hopefully\n> computation devices are getting cheap enough that the increased processing\n> implied by new features should not be too onerous.\n>\n>\n>\n> To my mind, an \"inescapable\" covenant (i.e. one that requires the output\n> to be paid to the same covenant) is basically a Turing machine, and\n> equivalent to a `while (true);` loop.\n> In a `while (true);` loop, the state of the machine reverts back to the\n> same state, and it repeats again.\n> In an inescpable covenant, the control of some amount of funds reverts\n> back to the same controlling SCRIPT, and it repeats again.\n> Yes, you can certainly add more functionality on top of that loop, just\n> think of program main loops for games or daemons, which are, in essence,\n> \"just\" `while (true) ...`.\n> But basically, such unbounded infinite loops are possible only under\n> Turing machines, thus I consider covenants to be Turing-complete.\n> Principle of Least Power should make us wonder if we need full Turing\n> machines for the functionality.\n>\n> On the other hand --- codata processing *does* allow for unbounded loops,\n> without requiring full Turing-completeness; they just require total\n> functionality, not partial (and Turing-completeness is partial, not total).\n> Basically, data structures are unbounded storage, while codata structures\n> are unbounded processing.\n> Perhaps covenants can encode an upper bound on the number of recursions,\n> which prevents full Turing-completeness while allowing for a large number\n> of use-cases.\n>\n> (if the above paragraph makes no sense to you, hopefully this Wikipedia\n> article will help:\n> https://en.wikipedia.org/wiki/Total_functional_programming )\n> (basically my argument here is based on academic programming stuff, and\n> might not actually matter in real life)\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210705/67abbcb9/attachment-0001.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2021-07-06T06:25:48",
                "message_text_only": ">  when people are talking about enabling covenants, we are talking about\nwhether OP_CAT should be allowed or not\n\nAre they? Are you implying that anything that enables covenants is\nequivalent to enabling OP_CAT? Generally when I think about enabling\ncovenants, I'm thinking more about OP_CTV (or some similarly specific opcode\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/bip-constraindestination.md>\n).\n\n> OP_TWEAK\n\nI wasn't able to find anything about what that is. Would you mind\nclarifying what that concept is?\n\nOn Mon, Jul 5, 2021 at 10:20 AM Russell O'Connor via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi ZmnSCPxj,\n>\n> I don't believe we need to ban Turing completeness for the sake of banning\n> Turing completeness.  My concerns have always been around ensuring that\n> transaction and block validation is not unduly burdensome for nodes.  So\n> for Bitcoin Script, we want to bound the amount of resources needed to\n> execute it, preferably as a linear function of weight[1], and preferably\n> have it clear what the evaluation costs are going to be prior to\n> evaluation[2].  We also want to keep Script execution as a pure function of\n> the transaction data so that nodes do not need to reevaluate their mempool\n> on every new block.  For consensus purposes we prefer to have simple\n> primitive operations that have clear and precise semantics that are as\n> likely as possible to be reimplemented correctly if they are reimplemented\n> (or at least let us not make this problem worse than it already is).  In\n> particular, Script needs to be easy to parse to avoid weird parsing\n> machines that lead to security vulnerabilities within node software.\n>\n> While the above design constraints imply a prohibition on Turing complete\n> computation within a single Script, they do not imply a prohibition on\n> arbitrary, covenant-enabled computations that spans across multiple\n> transactions.  Neither would these constraints prohibit some kind of STARK\n> or SNARK tapleaf version that was somehow capable of succinctly\n> representing arbitrary computations, so long as validation costs remain\n> bounded.\n>\n> And while it is true that covenant-enabled computations could allow users\n> to put their funds at risk through weird machines that manipulate their\n> money on the blockchain, as longs as that weirdness stays at that level of\n> the abstract Bitcoin Script machine, then I suppose it is *caveat emptor*;\n> don't send your funds to random unverified Bitcoin Scripts, advice that is\n> already the case today.  We can keep that potential weirdness at bay by\n> keeping Script simple, and maintaining our understanding that the Script\n> programs (like the rest of the blockchain data) are untrusted inputs and\n> they need to be validated and scrutinized before interpretation.\n>\n> [1] In tapscript I believe all operations are linear time with the\n> exception of OP_ROLL.  However OP_ROLL is still constrained by global\n> limits on stack size, etc.\n> [2] In Bitcoin Script, without loops of any kind, every opcode is\n> evaluated at most once, so counting opcodes is an easy way to put an upper\n> bound on your costs before evaluation.\n>\n> On Sun, Jul 4, 2021 at 8:51 PM ZmnSCPxj via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Good morning Dave,\n>>\n>> > On Sun, Jul 04, 2021 at 11:39:44AM -0700, Jeremy wrote:\n>> >\n>> > > However, I think the broader community is unconvinced by the cost\n>> benefit\n>> > > of arbitrary covenants. See\n>> > >\n>> https://medium.com/block-digest-mempool/my-worries-about-too-generalized-covenants-5eff33affbb6\n>> > > as a recent example. Therefore as a critical part of building\n>> consensus on\n>> > > various techniques I've worked to emphasize that specific additions\n>> do not\n>> > > entail risk of accidentally introducing more than was bargained for to\n>> > > respect the concerns of others.\n>> >\n>> > Respecting the concerns of others doesn't require lobotomizing useful\n>> > tools. Being respectful can also be accomplished by politely showing\n>> > that their concerns are unfounded (or at least less severe than they\n>> > thought). This is almost always the better course IMO---it takes much\n>> > more effort to satisfy additional engineering constraints (and prove to\n>> > reviewers that you've done so!) than it does to simply discuss those\n>> > concerns with reasonable stakeholders. As a demonstration, let's look\n>> > at the concerns from Shinobi's post linked above:\n>> >\n>> > They seem to be worried that some Bitcoin users will choose to accept\n>> > coins that can't subsequently be fungibily mixed with other bitcoins.\n>> > But that's already been the case for a decade: users can accept altcoins\n>> > that are non-fungible with bitcoins.\n>> >\n>> > They talk about covenants where spending is controlled by governments,\n>> > but that seems to me exactly like China's CBDC trial.\n>> >\n>> > They talk about exchanges depositing users' BTC into a covenant, but\n>> > that's just a variation on the classic not-your-keys-not-your-bitcoins\n>> > problem. For all you know, your local exchange is keeping most of its\n>> > BTC balance commitments in ETH or USDT.\n>> >\n>> > To me, it seems like the worst-case problems Shinobi describes with\n>> > covenants are some of the same problems that already exist with\n>> > altcoins. I don't see how recursive covenants could make any of those\n>> > problems worse, and so I don't see any point in limiting Bitcoin's\n>> > flexibility to avoid those problems when there are so many interesting\n>> > and useful things that unlimited covenants could do.\n>>\n>> The \"altcoins are even worse\" argument does seem quite convincing, and if\n>> Bitcoin can survive altcoins, surely it can survive covenants too?\n>>\n>> In before \"turns out covenants are the next ICO\".\n>> i.e. ICOs are just colored coins, which are useful for keeping track of\n>> various stuff, but have then been used as a vehicle to scam people.\n>> But I suppose that is a problem that humans will always have: limited\n>> cognition, so that *good* popular things that are outside your specific\n>> field of study are indistinguishable from *bad* popular things.\n>> So perhaps it should not be a concern on a technical level.\n>> Maybe we should instead make articles about covenants so boring nobody\n>> will hype about it (^^;)v.\n>>\n>> Increased functionality implies increased processing, and hopefully\n>> computation devices are getting cheap enough that the increased processing\n>> implied by new features should not be too onerous.\n>>\n>>\n>>\n>> To my mind, an \"inescapable\" covenant (i.e. one that requires the output\n>> to be paid to the same covenant) is basically a Turing machine, and\n>> equivalent to a `while (true);` loop.\n>> In a `while (true);` loop, the state of the machine reverts back to the\n>> same state, and it repeats again.\n>> In an inescpable covenant, the control of some amount of funds reverts\n>> back to the same controlling SCRIPT, and it repeats again.\n>> Yes, you can certainly add more functionality on top of that loop, just\n>> think of program main loops for games or daemons, which are, in essence,\n>> \"just\" `while (true) ...`.\n>> But basically, such unbounded infinite loops are possible only under\n>> Turing machines, thus I consider covenants to be Turing-complete.\n>> Principle of Least Power should make us wonder if we need full Turing\n>> machines for the functionality.\n>>\n>> On the other hand --- codata processing *does* allow for unbounded loops,\n>> without requiring full Turing-completeness; they just require total\n>> functionality, not partial (and Turing-completeness is partial, not total).\n>> Basically, data structures are unbounded storage, while codata structures\n>> are unbounded processing.\n>> Perhaps covenants can encode an upper bound on the number of recursions,\n>> which prevents full Turing-completeness while allowing for a large number\n>> of use-cases.\n>>\n>> (if the above paragraph makes no sense to you, hopefully this Wikipedia\n>> article will help:\n>> https://en.wikipedia.org/wiki/Total_functional_programming )\n>> (basically my argument here is based on academic programming stuff, and\n>> might not actually matter in real life)\n>>\n>> Regards,\n>> ZmnSCPxj\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210705/b9e7f0c5/attachment.html>"
            },
            {
                "author": "Sanket Kanjalkar",
                "date": "2021-07-06T10:20:53",
                "message_text_only": "After some brainstorming about the possible drawbacks of enabling\ncovenants, I have also slowly become more comfortable with the idea of\n\"unlimited\" covenants. AJs example clearly shows that _all_ possible\n\"misuses\" of covenants are already possible by Multi-Sig today, so it's not\na new vector that we are adding today.\n\n>  My concerns have always been around ensuring that transaction and block\nvalidation is not unduly burdensome for nodes.  So for Bitcoin Script, we\nwant to bound the amount of resources needed to execute it, preferably as a\nlinear function of weight[1], and preferably have it clear what the\nevaluation costs are going to be prior to evaluation[2].  We also want to\nkeep Script execution as a pure function of the transaction data so that\nnodes do not need to reevaluate their mempool on every new block.\n\nMany bitcoin upgrades, in particular, Segwit, and tapscript sigops budget\nhave been along with the same principle. And as mentioned before, none of\nthese go against enabling recursive covenants.\n\n> Are they? Are you implying that anything that enables covenants is\nequivalent to enabling OP_CAT?\n\nNo, it is not equivalent. Russell is referring to a way to do covenants by\nonly using `OP_CAT`(along with Schnorr sigs that we already have) as\nmentioned by Andrew Poelstra here\n<https://medium.com/blockstream/cat-and-schnorr-tricks-i-faf1b59bd298> .\n\nI also am in general support of the `OP_CHECKSIGFROMSTACK` opcode. We would\nneed to update the suggestion to BIP340, and add it to sigops budget. I\nhave no strong preference for splitting R and s values or variable-length\nmessages.\n\n\nOn Tue, Jul 6, 2021 at 1:36 AM Billy Tetrud via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> >  when people are talking about enabling covenants, we are talking about\n> whether OP_CAT should be allowed or not\n>\n> Are they? Are you implying that anything that enables covenants is\n> equivalent to enabling OP_CAT? Generally when I think about enabling\n> covenants, I'm thinking more about OP_CTV (or some similarly specific\n> opcode\n> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/bip-constraindestination.md>\n> ).\n>\n> > OP_TWEAK\n>\n> I wasn't able to find anything about what that is. Would you mind\n> clarifying what that concept is?\n>\n> On Mon, Jul 5, 2021 at 10:20 AM Russell O'Connor via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi ZmnSCPxj,\n>>\n>> I don't believe we need to ban Turing completeness for the sake of\n>> banning Turing completeness.  My concerns have always been around ensuring\n>> that transaction and block validation is not unduly burdensome for nodes.\n>> So for Bitcoin Script, we want to bound the amount of resources needed to\n>> execute it, preferably as a linear function of weight[1], and preferably\n>> have it clear what the evaluation costs are going to be prior to\n>> evaluation[2].  We also want to keep Script execution as a pure function of\n>> the transaction data so that nodes do not need to reevaluate their mempool\n>> on every new block.  For consensus purposes we prefer to have simple\n>> primitive operations that have clear and precise semantics that are as\n>> likely as possible to be reimplemented correctly if they are reimplemented\n>> (or at least let us not make this problem worse than it already is).  In\n>> particular, Script needs to be easy to parse to avoid weird parsing\n>> machines that lead to security vulnerabilities within node software.\n>>\n>> While the above design constraints imply a prohibition on Turing complete\n>> computation within a single Script, they do not imply a prohibition on\n>> arbitrary, covenant-enabled computations that spans across multiple\n>> transactions.  Neither would these constraints prohibit some kind of STARK\n>> or SNARK tapleaf version that was somehow capable of succinctly\n>> representing arbitrary computations, so long as validation costs remain\n>> bounded.\n>>\n>> And while it is true that covenant-enabled computations could allow users\n>> to put their funds at risk through weird machines that manipulate their\n>> money on the blockchain, as longs as that weirdness stays at that level of\n>> the abstract Bitcoin Script machine, then I suppose it is *caveat emptor*;\n>> don't send your funds to random unverified Bitcoin Scripts, advice that is\n>> already the case today.  We can keep that potential weirdness at bay by\n>> keeping Script simple, and maintaining our understanding that the Script\n>> programs (like the rest of the blockchain data) are untrusted inputs and\n>> they need to be validated and scrutinized before interpretation.\n>>\n>> [1] In tapscript I believe all operations are linear time with the\n>> exception of OP_ROLL.  However OP_ROLL is still constrained by global\n>> limits on stack size, etc.\n>> [2] In Bitcoin Script, without loops of any kind, every opcode is\n>> evaluated at most once, so counting opcodes is an easy way to put an upper\n>> bound on your costs before evaluation.\n>>\n>> On Sun, Jul 4, 2021 at 8:51 PM ZmnSCPxj via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Good morning Dave,\n>>>\n>>> > On Sun, Jul 04, 2021 at 11:39:44AM -0700, Jeremy wrote:\n>>> >\n>>> > > However, I think the broader community is unconvinced by the cost\n>>> benefit\n>>> > > of arbitrary covenants. See\n>>> > >\n>>> https://medium.com/block-digest-mempool/my-worries-about-too-generalized-covenants-5eff33affbb6\n>>> > > as a recent example. Therefore as a critical part of building\n>>> consensus on\n>>> > > various techniques I've worked to emphasize that specific additions\n>>> do not\n>>> > > entail risk of accidentally introducing more than was bargained for\n>>> to\n>>> > > respect the concerns of others.\n>>> >\n>>> > Respecting the concerns of others doesn't require lobotomizing useful\n>>> > tools. Being respectful can also be accomplished by politely showing\n>>> > that their concerns are unfounded (or at least less severe than they\n>>> > thought). This is almost always the better course IMO---it takes much\n>>> > more effort to satisfy additional engineering constraints (and prove to\n>>> > reviewers that you've done so!) than it does to simply discuss those\n>>> > concerns with reasonable stakeholders. As a demonstration, let's look\n>>> > at the concerns from Shinobi's post linked above:\n>>> >\n>>> > They seem to be worried that some Bitcoin users will choose to accept\n>>> > coins that can't subsequently be fungibily mixed with other bitcoins.\n>>> > But that's already been the case for a decade: users can accept\n>>> altcoins\n>>> > that are non-fungible with bitcoins.\n>>> >\n>>> > They talk about covenants where spending is controlled by governments,\n>>> > but that seems to me exactly like China's CBDC trial.\n>>> >\n>>> > They talk about exchanges depositing users' BTC into a covenant, but\n>>> > that's just a variation on the classic not-your-keys-not-your-bitcoins\n>>> > problem. For all you know, your local exchange is keeping most of its\n>>> > BTC balance commitments in ETH or USDT.\n>>> >\n>>> > To me, it seems like the worst-case problems Shinobi describes with\n>>> > covenants are some of the same problems that already exist with\n>>> > altcoins. I don't see how recursive covenants could make any of those\n>>> > problems worse, and so I don't see any point in limiting Bitcoin's\n>>> > flexibility to avoid those problems when there are so many interesting\n>>> > and useful things that unlimited covenants could do.\n>>>\n>>> The \"altcoins are even worse\" argument does seem quite convincing, and\n>>> if Bitcoin can survive altcoins, surely it can survive covenants too?\n>>>\n>>> In before \"turns out covenants are the next ICO\".\n>>> i.e. ICOs are just colored coins, which are useful for keeping track of\n>>> various stuff, but have then been used as a vehicle to scam people.\n>>> But I suppose that is a problem that humans will always have: limited\n>>> cognition, so that *good* popular things that are outside your specific\n>>> field of study are indistinguishable from *bad* popular things.\n>>> So perhaps it should not be a concern on a technical level.\n>>> Maybe we should instead make articles about covenants so boring nobody\n>>> will hype about it (^^;)v.\n>>>\n>>> Increased functionality implies increased processing, and hopefully\n>>> computation devices are getting cheap enough that the increased processing\n>>> implied by new features should not be too onerous.\n>>>\n>>>\n>>>\n>>> To my mind, an \"inescapable\" covenant (i.e. one that requires the output\n>>> to be paid to the same covenant) is basically a Turing machine, and\n>>> equivalent to a `while (true);` loop.\n>>> In a `while (true);` loop, the state of the machine reverts back to the\n>>> same state, and it repeats again.\n>>> In an inescpable covenant, the control of some amount of funds reverts\n>>> back to the same controlling SCRIPT, and it repeats again.\n>>> Yes, you can certainly add more functionality on top of that loop, just\n>>> think of program main loops for games or daemons, which are, in essence,\n>>> \"just\" `while (true) ...`.\n>>> But basically, such unbounded infinite loops are possible only under\n>>> Turing machines, thus I consider covenants to be Turing-complete.\n>>> Principle of Least Power should make us wonder if we need full Turing\n>>> machines for the functionality.\n>>>\n>>> On the other hand --- codata processing *does* allow for unbounded\n>>> loops, without requiring full Turing-completeness; they just require total\n>>> functionality, not partial (and Turing-completeness is partial, not total).\n>>> Basically, data structures are unbounded storage, while codata\n>>> structures are unbounded processing.\n>>> Perhaps covenants can encode an upper bound on the number of recursions,\n>>> which prevents full Turing-completeness while allowing for a large number\n>>> of use-cases.\n>>>\n>>> (if the above paragraph makes no sense to you, hopefully this Wikipedia\n>>> article will help:\n>>> https://en.wikipedia.org/wiki/Total_functional_programming )\n>>> (basically my argument here is based on academic programming stuff, and\n>>> might not actually matter in real life)\n>>>\n>>> Regards,\n>>> ZmnSCPxj\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n-- \nSanket Kanjalkar\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210706/d62d9096/attachment-0001.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2021-07-06T11:26:28",
                "message_text_only": "On Tue, Jul 6, 2021 at 2:26 AM Billy Tetrud <billy.tetrud at gmail.com> wrote:\n\n> >  when people are talking about enabling covenants, we are talking about\n> whether OP_CAT should be allowed or not\n>\n> Are they? Are you implying that anything that enables covenants is\n> equivalent to enabling OP_CAT? Generally when I think about enabling\n> covenants, I'm thinking more about OP_CTV (or some similarly specific\n> opcode\n> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/bip-constraindestination.md>\n> ).\n>\n> > OP_TWEAK\n>\n> I wasn't able to find anything about what that is. Would you mind\n> clarifying what that concept is?\n>\n\nIn tapscript one can generally recover the current input's scriptPubkey\nthrough sighash introspection via the usual covenant tricks.  This allows\nyou to make a recursive covenant by spending funds back to the same\nidentical scriptPubkey.  However, in order for a recursive covenant to be\nactually interesting, there needs to be some sort of state update in each\ntransition.  If there is no state update then sending funds back to itself\nis of very limited value.  It will reset the timer on relative locks, but\nthat is about all.\n\nThe \"normal\" way of writing useful recursive covenants is to modify the\nscriptPubkey by changing a fragment of it that contains some sort of\nstate.  However in order to update a tapscript pubkey one needs to apply\nnot only hashing, to create a Merkel root, but also to create a tweaked\ntaproot pubkey that commits to this root.  While script currently comes\nwith a SHA-256 hashing opcode, there is no opcode that will let you perform\nthe necessary tweaking to create a taproot scriptPubkey.\n\nBut as I mentioned afterwards, there are other places in the UTXO that you\ncould put data in order to perform a state update.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210706/e7b418bc/attachment.html>"
            },
            {
                "author": "Jeremy",
                "date": "2021-07-06T18:36:31",
                "message_text_only": "heh -- I pointed out these evil multisig covenants in 2015 :)\nhttps://medium.com/@jeremyrubin/regulating-bitcoin-by-mining-the-regulator-miner-attack-c8fd51185b78\nI'm relatively unconcerned by it except to the extent that mining\ncentralizes to the point of censoring other traffic.\n\nOverall, I think this is a great conversation to be having.\n\nHowever, I want to push back on David's claim that  \"Respecting the\nconcerns of others doesn't require lobotomizing useful tools.\".\n\nCHECKSIGFROMSTACK is a primitive and the opcode is not being nerfed in any\nway shape or form. The argument here is that doing CSFS and not CAT is\nnerfing CSFS... but CSFS is an independently useful and cool opcode that\nhas many of it's own merits.\n\nFurther, as described in my [blog post](\nhttps://rubin.io/blog/2021/07/02/covenants/), CSFS has very high \"design\nspecificity\"... that is there's not *that* many design choices that could\npossibly go into it. It's checking a signature. From the stack. That's all\nfolks! There are no design compromises in it. No lobotomy.\n\nOP_CAT is more or less completely unrelated to CSFS. As Andrew has\n[demonstrated](\nhttps://www.wpsoftware.net/andrew/blog/cat-and-schnorr-tricks-i.html),\n*just* OP_CAT alone (no CSFS) gives you covenants (albeit in a hacky way)\nwith Schnorr.\n\nI think roconnor agrees that CAT(+CSFS?) are not really a \"fantastic\" way\nto do covenants, that there are more direct approaches that will be better\nor neccessary such as TWEAK or UPDATETAPLEAF. Let's work on those! But\nlet's also not hold up progress on other useful things while those are\nbrewing.\n\nNon-Redundancy should be a non-goal for script -- although we strive to be\nminimal, redundancy is inevitable. For example, OP_SWAP has identical\nsemantics to <1> ROLL, but SWAP is a common enough use that it is pragmatic\nto assign it an opcode and OP_ROLL does something distinctly enhanced.\nSimilarly, even if we add CAT we will surely come up with saner ways to\nimplement covenant logic than Andrew's Schnorr tricks.\n\nCTV in particular is designed to be a part of that story -- enough\nfunctionality w/o OP_CAT to work *today* and serve a purpose long into the\nfuture, but with OP_CAT (or shastream preferably) enhances it's\nfunctionality in a useful way and with introspection opcodes (perhaps like\nthose being developed by elements) further gains functionality. Perhaps the\nfunctionality available today will be redundant with a future way of doing\nthings, but we can only see so far into the future. However, we can see\nthat there are good things to build with it today.\n\nIt's the inverse of a lobotomy. Independent components that can come\ntogether for a newer greater purpose rather than parts being torn apart\nirreparably.\n\nIn the future when we have specific use cases in mind that *aren't* served\nwell (either efficiently or at all) by the existing primitives, it's\ncompletely acceptable to add something new even if it makes an existing\nfeature redundant. APO, for example, will be redundant (afaict) will Glen\nWillen's [Bitmask SigHash Flags](\nhttps://bc-2.jp/archive/season2/materials/0203_NewElementsFeaturesEn.pdf)\nshould we ever get those.\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210706/4bf5525a/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-07-07T04:26:31",
                "message_text_only": "Good morning Russell,\n\n> Hi ZmnSCPxj,\n>\n> I don't believe we need to ban Turing completeness for the sake of banning Turing completeness.\n\nWell I believe we should ban partial Turing-completeness, but allow total Turing-completeness.\n\nI just think that unlimited recursive covenants (with or without a convenient way to transform state at each iteration) are **not** partial Turing-complete, but *are* total Turing-complete. (^^)\n\n(The rest of this writeup is mostly programming languages nerdery so anyone who is not interested in Haskell (or purely functional programming) and programming language nerdery can feel free to skip the rest of this post.\nBasically, ZmnSCPxj thinks we should still ban Turing-completeness, but unbounded covenants get a pass because they are not, on a technicality, Turing-complete)\n\nFor now, let us first taboo the term \"Turing-complete\", and instead focus on what I think matters here, the distinction between partial and total,\n\nIn a total programming language we have a distinction between data and codata:\n\n* Data is defined according to its constructors, i.e. an algebraic data type.\n* Codata is defined according to its destructors, i.e. according to a \"behavior\" the codata has when a particular \"action\" is applied to it.\n\nFor example, a singly-linked list data type would be defined as follows:\n\n    data List a where\n        Cons :: a -> List a -> List a\n        Nil :: List a\n\nOn the other hand, an infinite codata stream of objects would be defined as follows:\n\n    codata Stream a where\n        head :: Stream a -> a\n        tail :: Stream a -> Stream a\n\nFor `data` types, the result type for each constructor listed in the definition *must* be the type being defined.\nThat is why `Cons` is declared as resulting in a `List a`.\nWe declare data according to its constructors.\n\nFor `codata` types, the *first argument* for each destructor listed in the definition *must* be the type being defined.\nThat is why `head` accepts as its first argument the `Stream a` type.\n\nThis is relevant because in a total function programming language, there exists some programming rule that restricts recursion.\nThe simplest such restriction is substructural recursion:\n\n* If a function recurs:\n  * Every self-call should pass in a substructure of an argument as that argument.\n\nEvery program that passes the above rule provably terminates.\nSince every recursion passes in a smaller part of an argument, eventually we will reach an indivisible primitive object being passed in, and processing will stop recursing and can return some value.\n\nThus, a programing language that has substructural recursion rule check (and rejects programs that fail the substrucutral recursion check) are not \"Turing-complete\".\nThe reason is that Turing-complete languages cannot solve the Halting Problem.\nBut a language that includes the substructural recursion rule *does* have a Halting Problem solution: every program that passes the substructural recursion rule halts and the Halting Problem is decidable for all programs that pass the substructural recursion rule.\n(i.e. we are deliberately restricting ourselves to a subset of programs that pass substructural recursion, and reject programs that do not pass this rule as \"not really programs\", so every program halts)\n\nFor example, the following definition of `mapList` is valid under substructural recursion:\n\n    mapList :: (a -> b) -> (List a -> List b)\n    mapList f Nil            = Nil\n    mapList f (Cons a as)    = Cons (f a) (mapList f as)\n\nThe second sub-definition has a recursive call `mapList f as`.\nThe second argument to that call, however, is a substructure of the second argument `Cons a as` on the LHS of the definition, thus it is a substructural recursive call, and accepted in a total programming language.\n*Every* recursion in `mapList` should then be a substructural call on the second argument of `mapList`.\n\nNow let us consider the following definition of `fibonacci`:\n\n    -- to use: fibonacci 1 1\n    fibonacci :: Integer -> Integer -> List Integer\n    fibonacci x y = Cons x (fibonacci y (x + y))\n\nThe above is not substructural recursive, neither argument in the recursive `fibonacci y (x + y)` call is a substructure of the arguments in the LHS of the `fibonacci` definition `fibonacci x y`.\n\nThus, we prevent certain unbounded computations like the above infinite sequence of fibonacci numbers.\n\nNow, let us consider a definition of `mapStream`, the similar function on streams, using copattern matching rather than pattern matching:\n\n    mapStream :: (a -> b) -> (Stream a -> Stream b)\n    head (mapStream f as) = f (head as)\n    tail (mapStream f as) = mapStream f (tail as)\n\nNow the interesting thing here is that in the substructural recursion check, what is being defined in the above stanza is ***not*** `mapStream`, but `head` and `tail`!\nThus, it ignores the `mapStream f (tail as)`, because it is **not** recursion --- what is being defined here is `tail`.\n\nLooking at the above stanza, we can see that the `head` definition recurses, in the call `head as`.\nThe first argument to `head as` is `as`, which is a substructure of the first argument of the LHS, `mapstream f as`.\nSimilarly for the `tail` definition, there is a recursive call `tail as` which is substructural recursive, since the LHS has the first argument as `mapStream f as` and `as` is a substructure of that call.\n\n(Indeed, copatterns are an important advance in total programming languages, prior to copatterns people were bashing their heads trying to figure out a simple algorithm to ensure corecursion termination, and it turns out that copatterns make corecursion termination as trivial as substructural recursion on the destructurs)\n\nNow let us consider the following alternate definition of `fibonacci` which returns a `Stream Integer` rather than a `List Integer`:\n\n    fibonacci :: Integer -> Integer -> Stream Integer\n    head (fibonacci x y) = x\n    tail (fibonacci x y) = fibonacci y (x + y)\n\nThe first definition `head (fibonacci x y) = ...` is nonrecursive.\nThe sceon definition `tail (fibonacci x y) = ...` is ***also*** nonrecursive because what is being defined is `tail`, and `tail` does not even appear in the RHS of the definition!\n\nWith the syntax and its rules defined, let us now consider how to implement arbitrary-bound recursion in our total language.\n\nLet us define the following types:\n\n    data RecResult a where\n        Complete ::     a -> RecResult a\n        Continue :: Rec a -> RecResult a\n\n    codata Rec a where\n        step :: Rec a -> RecResult a\n\n`Rec a` is a monad:\n\n    instance Monad Rec where\n        step (return a) = Complete a\n        step (ma >>= f) = case (step ma) of\n                            Complete a   -> Continue (f a)\n                            Continue ma' -> Continue (ma' >>= f)\n        -- pretend we do not have the Haskellian `fail` ^^\n\nThe definition of `step (ma >>= f)` is recursive, but it is a substructural recursion: we recurse on `(step ma)` but `ma` is a substructure of the first argument on the LHS, `ma >>= f`, thus the above still is provably corecursive terminating.\n\nThe above is sufficient to define an infinite loop:\n\n    infiniteLoop :: Rec a\n    step infiniteLoop = Continue infiniteLoop\n\nThe above is still accepted, since there is no recursion involved --- the RHS does not contain the function `step` being defined, thus no recursion.\n\nNow the important thing to note here is that the above `Rec` type is a perfectly fine definition for the Haskellian `IO` type.\n\nThen, the `main` program, of type `Rec ()`/`IO ()`, would then be passed to a driving function, written in C.\nThis C function would replace the C-level `main` function, and would just call `step` on the Haskell-level `main`.\nIf it results in `Complete ()`, the C function exits.\nIf it results in `Continue ma`, then it calls `step` again on the `ma` and checks the result again, in a loop.\n\n    int main() {\n        HaskellObject* ma = haskell_get_main_function();\n        for (;;) {\n            HaskellObject* result = haskell_step(ma);\n            if (haskell_is_Complete(result))\n                 break;\n            ma = haskell_destructure_Continue(result);\n        }\n        return 0;\n    }\n\nThe important point here is that *within* the total language, everything terminates.\nWe put all the dirty non-termination \"outside\", in the C function that drives the entire processing, and have a very simple infinite loop in it that is easy to audit for correctness.\nThen, we can have significantly more confidence in the correctness of our program, since any infinite recursion would have to somehow resolve to some `IO` type, which explicitly allows for infinite recursion, and we can focus auditing on that part of the program alone.\n\nSimilarly, when we consider recursive covenants, we note always that there has to be some external driving program, written in something other than Bitcoin SCRIPT, which will continuously create transactions that will keep returning the funds to the same covenant (plus or minus some state update).\nOtherwise, the funds will just sit there behind their protecting SCRIPT, just like every other UTXO owned by long-term HODLers.\n\nSuch a program that continually pays a fund to \"the same\" covenant is no different, in principle, from the above C driving function for our total-functional-programming dialect of Haskell.\n\nWhich is to say that I mostly agree with roconnor here (other than on exact definition of terms; I think my definition of \"Turing-complete\" is more restrictive than his, such that covenants are not in fact **technically** Turing-complete, but that is just semantics and I can live with that), I think that the recursive covenants in Bitcoin work equivalently to the `codata` types in total functional languages.\nAs long as Bitcoin SCRIPT itself is provably terminating, I have no objections to the fact that we get arbitrary-bound processing by use of covenants, as they are \"outside\" the SCRIPT and have to be operated separately by a separate program.\n\nIndeed, we note as well that we can encode state in other parts of the TX anyway, so that we can write something more substantive than `while (true) { /* do nothing */ }`.\nSo we might as well make it easy on us and just add `OP_TWEAK` (and maybe convenience opcodes for building Taproot Merkle trees?) as well.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Billy Tetrud",
                "date": "2021-07-07T06:12:24",
                "message_text_only": "Thanks for the clarifications Sanket and Russel!\n\n> OP_TWEAK\n\nAh gotcha. I'm very much in support of recursive covenants. I was lead to\nthem as a way to create more efficient and flexible wallet vaults. I\nactually wrote a proposal\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/bip-pushoutputstack.md>\nfor an opcode to add state to an output. Its pretty useless without an\naccompanying covenant opcode, but it seems a bit more straightforward than\nthe tricks you mentioned (op_tweak and otherwise). I don't plan on starting\na discussion on it yet tho, more work to be done on it and other things\nto open discussion on first.\n\nIn any case, its nice to see so much general agreement on a topic that\ncould easily be embroidered in contention.\n\nOn Tue, Jul 6, 2021 at 9:26 PM ZmnSCPxj via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Russell,\n>\n> > Hi ZmnSCPxj,\n> >\n> > I don't believe we need to ban Turing completeness for the sake of\n> banning Turing completeness.\n>\n> Well I believe we should ban partial Turing-completeness, but allow total\n> Turing-completeness.\n>\n> I just think that unlimited recursive covenants (with or without a\n> convenient way to transform state at each iteration) are **not** partial\n> Turing-complete, but *are* total Turing-complete. (^^)\n>\n> (The rest of this writeup is mostly programming languages nerdery so\n> anyone who is not interested in Haskell (or purely functional programming)\n> and programming language nerdery can feel free to skip the rest of this\n> post.\n> Basically, ZmnSCPxj thinks we should still ban Turing-completeness, but\n> unbounded covenants get a pass because they are not, on a technicality,\n> Turing-complete)\n>\n> For now, let us first taboo the term \"Turing-complete\", and instead focus\n> on what I think matters here, the distinction between partial and total,\n>\n> In a total programming language we have a distinction between data and\n> codata:\n>\n> * Data is defined according to its constructors, i.e. an algebraic data\n> type.\n> * Codata is defined according to its destructors, i.e. according to a\n> \"behavior\" the codata has when a particular \"action\" is applied to it.\n>\n> For example, a singly-linked list data type would be defined as follows:\n>\n>     data List a where\n>         Cons :: a -> List a -> List a\n>         Nil :: List a\n>\n> On the other hand, an infinite codata stream of objects would be defined\n> as follows:\n>\n>     codata Stream a where\n>         head :: Stream a -> a\n>         tail :: Stream a -> Stream a\n>\n> For `data` types, the result type for each constructor listed in the\n> definition *must* be the type being defined.\n> That is why `Cons` is declared as resulting in a `List a`.\n> We declare data according to its constructors.\n>\n> For `codata` types, the *first argument* for each destructor listed in the\n> definition *must* be the type being defined.\n> That is why `head` accepts as its first argument the `Stream a` type.\n>\n> This is relevant because in a total function programming language, there\n> exists some programming rule that restricts recursion.\n> The simplest such restriction is substructural recursion:\n>\n> * If a function recurs:\n>   * Every self-call should pass in a substructure of an argument as that\n> argument.\n>\n> Every program that passes the above rule provably terminates.\n> Since every recursion passes in a smaller part of an argument, eventually\n> we will reach an indivisible primitive object being passed in, and\n> processing will stop recursing and can return some value.\n>\n> Thus, a programing language that has substructural recursion rule check\n> (and rejects programs that fail the substrucutral recursion check) are not\n> \"Turing-complete\".\n> The reason is that Turing-complete languages cannot solve the Halting\n> Problem.\n> But a language that includes the substructural recursion rule *does* have\n> a Halting Problem solution: every program that passes the substructural\n> recursion rule halts and the Halting Problem is decidable for all programs\n> that pass the substructural recursion rule.\n> (i.e. we are deliberately restricting ourselves to a subset of programs\n> that pass substructural recursion, and reject programs that do not pass\n> this rule as \"not really programs\", so every program halts)\n>\n> For example, the following definition of `mapList` is valid under\n> substructural recursion:\n>\n>     mapList :: (a -> b) -> (List a -> List b)\n>     mapList f Nil            = Nil\n>     mapList f (Cons a as)    = Cons (f a) (mapList f as)\n>\n> The second sub-definition has a recursive call `mapList f as`.\n> The second argument to that call, however, is a substructure of the second\n> argument `Cons a as` on the LHS of the definition, thus it is a\n> substructural recursive call, and accepted in a total programming language.\n> *Every* recursion in `mapList` should then be a substructural call on the\n> second argument of `mapList`.\n>\n> Now let us consider the following definition of `fibonacci`:\n>\n>     -- to use: fibonacci 1 1\n>     fibonacci :: Integer -> Integer -> List Integer\n>     fibonacci x y = Cons x (fibonacci y (x + y))\n>\n> The above is not substructural recursive, neither argument in the\n> recursive `fibonacci y (x + y)` call is a substructure of the arguments in\n> the LHS of the `fibonacci` definition `fibonacci x y`.\n>\n> Thus, we prevent certain unbounded computations like the above infinite\n> sequence of fibonacci numbers.\n>\n> Now, let us consider a definition of `mapStream`, the similar function on\n> streams, using copattern matching rather than pattern matching:\n>\n>     mapStream :: (a -> b) -> (Stream a -> Stream b)\n>     head (mapStream f as) = f (head as)\n>     tail (mapStream f as) = mapStream f (tail as)\n>\n> Now the interesting thing here is that in the substructural recursion\n> check, what is being defined in the above stanza is ***not*** `mapStream`,\n> but `head` and `tail`!\n> Thus, it ignores the `mapStream f (tail as)`, because it is **not**\n> recursion --- what is being defined here is `tail`.\n>\n> Looking at the above stanza, we can see that the `head` definition\n> recurses, in the call `head as`.\n> The first argument to `head as` is `as`, which is a substructure of the\n> first argument of the LHS, `mapstream f as`.\n> Similarly for the `tail` definition, there is a recursive call `tail as`\n> which is substructural recursive, since the LHS has the first argument as\n> `mapStream f as` and `as` is a substructure of that call.\n>\n> (Indeed, copatterns are an important advance in total programming\n> languages, prior to copatterns people were bashing their heads trying to\n> figure out a simple algorithm to ensure corecursion termination, and it\n> turns out that copatterns make corecursion termination as trivial as\n> substructural recursion on the destructurs)\n>\n> Now let us consider the following alternate definition of `fibonacci`\n> which returns a `Stream Integer` rather than a `List Integer`:\n>\n>     fibonacci :: Integer -> Integer -> Stream Integer\n>     head (fibonacci x y) = x\n>     tail (fibonacci x y) = fibonacci y (x + y)\n>\n> The first definition `head (fibonacci x y) = ...` is nonrecursive.\n> The sceon definition `tail (fibonacci x y) = ...` is ***also***\n> nonrecursive because what is being defined is `tail`, and `tail` does not\n> even appear in the RHS of the definition!\n>\n> With the syntax and its rules defined, let us now consider how to\n> implement arbitrary-bound recursion in our total language.\n>\n> Let us define the following types:\n>\n>     data RecResult a where\n>         Complete ::     a -> RecResult a\n>         Continue :: Rec a -> RecResult a\n>\n>     codata Rec a where\n>         step :: Rec a -> RecResult a\n>\n> `Rec a` is a monad:\n>\n>     instance Monad Rec where\n>         step (return a) = Complete a\n>         step (ma >>= f) = case (step ma) of\n>                             Complete a   -> Continue (f a)\n>                             Continue ma' -> Continue (ma' >>= f)\n>         -- pretend we do not have the Haskellian `fail` ^^\n>\n> The definition of `step (ma >>= f)` is recursive, but it is a\n> substructural recursion: we recurse on `(step ma)` but `ma` is a\n> substructure of the first argument on the LHS, `ma >>= f`, thus the above\n> still is provably corecursive terminating.\n>\n> The above is sufficient to define an infinite loop:\n>\n>     infiniteLoop :: Rec a\n>     step infiniteLoop = Continue infiniteLoop\n>\n> The above is still accepted, since there is no recursion involved --- the\n> RHS does not contain the function `step` being defined, thus no recursion.\n>\n> Now the important thing to note here is that the above `Rec` type is a\n> perfectly fine definition for the Haskellian `IO` type.\n>\n> Then, the `main` program, of type `Rec ()`/`IO ()`, would then be passed\n> to a driving function, written in C.\n> This C function would replace the C-level `main` function, and would just\n> call `step` on the Haskell-level `main`.\n> If it results in `Complete ()`, the C function exits.\n> If it results in `Continue ma`, then it calls `step` again on the `ma` and\n> checks the result again, in a loop.\n>\n>     int main() {\n>         HaskellObject* ma = haskell_get_main_function();\n>         for (;;) {\n>             HaskellObject* result = haskell_step(ma);\n>             if (haskell_is_Complete(result))\n>                  break;\n>             ma = haskell_destructure_Continue(result);\n>         }\n>         return 0;\n>     }\n>\n> The important point here is that *within* the total language, everything\n> terminates.\n> We put all the dirty non-termination \"outside\", in the C function that\n> drives the entire processing, and have a very simple infinite loop in it\n> that is easy to audit for correctness.\n> Then, we can have significantly more confidence in the correctness of our\n> program, since any infinite recursion would have to somehow resolve to some\n> `IO` type, which explicitly allows for infinite recursion, and we can focus\n> auditing on that part of the program alone.\n>\n> Similarly, when we consider recursive covenants, we note always that there\n> has to be some external driving program, written in something other than\n> Bitcoin SCRIPT, which will continuously create transactions that will keep\n> returning the funds to the same covenant (plus or minus some state update).\n> Otherwise, the funds will just sit there behind their protecting SCRIPT,\n> just like every other UTXO owned by long-term HODLers.\n>\n> Such a program that continually pays a fund to \"the same\" covenant is no\n> different, in principle, from the above C driving function for our\n> total-functional-programming dialect of Haskell.\n>\n> Which is to say that I mostly agree with roconnor here (other than on\n> exact definition of terms; I think my definition of \"Turing-complete\" is\n> more restrictive than his, such that covenants are not in fact\n> **technically** Turing-complete, but that is just semantics and I can live\n> with that), I think that the recursive covenants in Bitcoin work\n> equivalently to the `codata` types in total functional languages.\n> As long as Bitcoin SCRIPT itself is provably terminating, I have no\n> objections to the fact that we get arbitrary-bound processing by use of\n> covenants, as they are \"outside\" the SCRIPT and have to be operated\n> separately by a separate program.\n>\n> Indeed, we note as well that we can encode state in other parts of the TX\n> anyway, so that we can write something more substantive than `while (true)\n> { /* do nothing */ }`.\n> So we might as well make it easy on us and just add `OP_TWEAK` (and maybe\n> convenience opcodes for building Taproot Merkle trees?) as well.\n>\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210706/5186d9c3/attachment-0001.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2021-07-07T13:12:58",
                "message_text_only": "On Wed, Jul 7, 2021 at 12:26 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Russell,\n>\n> > Hi ZmnSCPxj,\n> >\n> > I don't believe we need to ban Turing completeness for the sake of\n> banning Turing completeness.\n>\n> Well I believe we should ban partial Turing-completeness, but allow total\n> Turing-completeness.\n>\n\nUnfortunately, when it comes to cross-transaction computations, it is\ninfeasible to ban non-terminating computation.\n\nThe nature of recursive covenants is that the program \"writes\" the *source\ncode* next step of the computation to the scriptPubKey to one of the\noutputs of its transaction. Technically speaking it verifies that the\nscriptPubKey is a commitment to the source code of the next step of the\nprogram, but morally that is the same as writing the source code.  Then the\nnext step of the computation is invoked by someone \"evaluating* that next\nstep's source code by creating a valid transaction that spends the\ngenerated output.\n\nThe point is this ability to create new source code and then evaluate it\nleads to the ability to write universal (i.e non-terminating)\ncomputations.  The only way to prevent it is to ban source code\nmanipulation, but since Bitcoin Script source code is just a string of\nbytes, it would mean banning the manipulation of strings of bytes.  But the\nentire Bitcoin Script language works by manipulating strings of bytes\nwithin a stack machine.  Indeed the most trivial of non-terminating\nprograms can be implemented by extracting the current input's scriptPubKey\nfrom the sighash and \"writing\" the identical scriptPubKey to one of its\noutputs.  That example hardly takes any manipulation at all to implement.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210707/1a038896/attachment.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2021-07-07T14:24:17",
                "message_text_only": "On Wed, Jul 7, 2021 at 9:12 AM Russell O'Connor <roconnor at blockstream.com>\nwrote:\n\n>\n> On Wed, Jul 7, 2021 at 12:26 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n>> Good morning Russell,\n>>\n>> > Hi ZmnSCPxj,\n>> >\n>> > I don't believe we need to ban Turing completeness for the sake of\n>> banning Turing completeness.\n>>\n>> Well I believe we should ban partial Turing-completeness, but allow total\n>> Turing-completeness.\n>>\n>\n> Unfortunately, when it comes to cross-transaction computations, it is\n> infeasible to ban non-terminating computation.\n>\n> The nature of recursive covenants is that the program \"writes\" the *source\n> code* next step of the computation to the scriptPubKey to one of the\n> outputs of its transaction. Technically speaking it verifies that the\n> scriptPubKey is a commitment to the source code of the next step of the\n> program, but morally that is the same as writing the source code.  Then the\n> next step of the computation is invoked by someone \"evaluating* that next\n> step's source code by creating a valid transaction that spends the\n> generated output.\n>\n> The point is this ability to create new source code and then evaluate it\n> leads to the ability to write universal (i.e non-terminating)\n> computations.  The only way to prevent it is to ban source code\n> manipulation, but since Bitcoin Script source code is just a string of\n> bytes, it would mean banning the manipulation of strings of bytes.  But the\n> entire Bitcoin Script language works by manipulating strings of bytes\n> within a stack machine.  Indeed the most trivial of non-terminating\n> programs can be implemented by extracting the current input's scriptPubKey\n> from the sighash and \"writing\" the identical scriptPubKey to one of its\n> outputs.  That example hardly takes any manipulation at all to implement.\n>\n\nA follow up:  Because recursive covenants need to be sent to a new\ntransaction in order to recurse, you might choose to view this stepping\nmechanism as productive by modeling each transaction step as the continue\nconstructor in your RecResult codata type.  Indeed after (drinking coffee\nand) rereading your mailing list item, it seems that this is the point you\nwere making.\n\nSo sorry for my hasty response.  I believe we are largely in agreement here.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210707/9a33d4a0/attachment.html>"
            },
            {
                "author": "Jeremy",
                "date": "2021-07-07T17:26:38",
                "message_text_only": "Hah -- ZmnSCPxj that post's a doozy -- but it more or less makes sense the\nargument you're making in favor of permitting recursion at the transaction\nlevel.\n\nOne part that's less clear is if you can make a case against being\nrecursive in Script fragments themselves -- ignoring bitcoin script for the\nmoment, what would be wrong with a small VM that a spender is able to\n\"purchase\" a number of cycles and available memory via the annex, and the\nprogram must execute and halt within that time? Then, per block/txn, you\ncan enforce a total cycle and memory limit. This still isn't quite the EVM,\nsince there's no cross object calling convention and the output is still\nUTXOs. What are the arguments against this model from a safety perspective?\n\n<new topic>\n\nOne of my general concerns with recursive covenants is the ability to \"go\nwrong\" in surprising ways. Consider the following program (Sapio\n<http://learn.sapio-lang.org>-pseudocode), which is a non recursive\ncovenant (i.e., doable today with presigning oracles) that demonstrates the\nissue.\n\nstruct Pool {\n    members: Vec<(Amount, Key)>,\n}\nimpl Pool {\n    then!{\n        fn withdraw(self, ctx) {\n            let mut builder = ctx.template();\n            for (a, k) in self.members.iter() {\n                builder = builder.add_output(a, k.into(), None)?;\n            }\n            builder.into()\n        }\n    }\n    guard! {\n        fn all_signed(self, ctx) {\n            Clause::And(self.members.iter().map(|(a,k)|\nClause::Key(k.clone())).into())\n        }\n    }\n    finish! {\n        guarded_by: [all_signed]\n        fn add_member(self, ctx, o_member: Option<(Amount, Key)>) {\n            let member = o_member.into()?;\n            let mut new_members = self.members.clone();\n            new_members.push(member.clone());\n            ctx.template().add_output(ctx.funds() + member.0,\n                  Pool {members: new_members}, None)?.into()\n        }\n    }\n}\n\nEssentially this is a recursive covenant that allows either Complete via\nthe withdraw call or Continue via add_member, while preserving the same\nunderlying code. In this case, all_signed must be signed by all current\nparticipants to admit a new member.\n\nThis type of program is subtly \"wrong\" because the state transition of\nadd_member does not verify that the Pool's future withdraw call will be\nvalid. E.g., we could add more than a 1MB of outputs, and then our program\nwould be \"stuck\". So it's critical that in our \"production grade\" covenant\nsystem we do some static analysis before proceeding to a next step to\nensure that all future txns are valid. This is a strength of the CTV/Sapio\nmodel presently, you always output a list of future txns to aid static\nanalysis.\n\nHowever, when we make the leap to \"automatic\" covenants, I posit that it\nwill be *incredibly* difficult to prove that recursive covenants don't have\na \"premature termination\" where a state transition that should be valid in\nan idealized setting is accidentally invalid in the actual bitcoin\nenvironment and the program reaches a untimely demise.\n\nFor instance, OP_CAT has this footgun -- by only permitting 520 bytes, you\nhit covenant limits at around 13 outputs assuming you are length checking\neach one and not permitting bare script. We can avoid this specific footgun\nsome of the time by using SHA256STREAM instead, of course.\n\nHowever, it is generally very difficult to avoid all sorts of issues. E.g.,\nwith the ability to generate/update tapscript trees, what happens when\nthrough updating a well formed tapscript tree 128 times you bump an\nimportant clause past the 129 depth limit?\n\nI don't think that these sorts of challenges mean that we shouldn't enable\ncovenants or avoid enabling them, but rather that as we explore we should\nadd primitives in a methodical way and give users/toolchain builders\nprimitives that enable and or encourage safety and good program design.\n\nMy personal view is that CTV/Sapio with it's AOT compilation of automated\nstate transitions and ability to statically analyze is a concept that can\nmature and be used in production in the near term. But the tooling to\nsafely do recursive computations at the txn level will take quite a bit\nlonger to mature, and we should be investing effort in producing\ncompilers/frameworks for emitting well formed programs before we get too in\nthe weeds on things like OP_TWEAK. (side note -- there's an easy path for\nadding this sort of experimental feature to Sapio if anyone is looking for\na place to start)\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210707/b4ed93fc/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Unlimited covenants, was Re: CHECKSIGFROMSTACK/{Verify} BIP for Bitcoin",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy",
                "Anthony Towns",
                "Russell O'Connor",
                "ZmnSCPxj",
                "Sanket Kanjalkar",
                "Matt Corallo",
                "Billy Tetrud",
                "Greg Sanders"
            ],
            "messages_count": 17,
            "total_messages_chars_count": 84159
        }
    },
    {
        "title": "[bitcoin-dev] Fee estimation requirements",
        "thread_messages": [
            {
                "author": "Dave Scotese",
                "date": "2021-07-05T16:39:40",
                "message_text_only": "At https://github.com/bitcoin/bitcoin/issues/22404#issuecomment-874168305\nno explanation is given for a peculiar rule about estimating fees, that \"you\nhave to wait around for a couple of blocks *after* being synced before fee\nestimation will work.\"  The rule is true, but it needn't be true, and the\nsoftware would be more useful if it were not true.  If it does seem\nimpossible to break this rule, perhaps some brainstorming is in order.  I\nestimate fees quite often on my own, although I am trusting the block\nexplorers in their reporting of the fees for the most recent blocks.  The\nsoftware doesn't need to trust anything once it has been synced.\n\nIf this is simply a matter of priorities, it would be useful to point that\nout.\n\nDave.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210705/cd63d653/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Fee estimation requirements",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Dave Scotese"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 921
        }
    },
    {
        "title": "[bitcoin-dev] Proof of reserves - recording",
        "thread_messages": [
            {
                "author": "Billy Tetrud",
                "date": "2021-07-05T18:24:36",
                "message_text_only": "I had the idea recently for proof of reserves\n<https://niccarter.info/proof-of-reserves/> done in a way that can be used\nto verify reserves are sufficient on an ongoing basis. I'm curious if there\nare any current approaches out there to proof of reserves that are similar.\n\nThe idea is to have users create actual private keys using a seed in pretty\nmuch the normal way. Users would generate a public key from this seed to\nrepresent their account, and would give the public key to the custodian to\nrepresent their account in a public record of account balances.\n\nWhen a user's account is credited, the custodian would update a map of\naddresses (created from the public key of each account) to balances - this\nmap could be structured into a merkle tree in the usual \"merkle approach\".\nThe custodian would also store funds on one or more HD wallets (each with\nmany addresses) and create a proof that they own each HD wallet. The proof\ncould be as simple as a single signature created with the xpub for the\nwallet, which would be sufficient for proving ownership over the whole\nlist/tree of addresses.\n\nThese two structures (the map and the HD wallet) would be combined and\nhashed, and the hash published in an on chain transaction (possibly along\nwith a URI where the full data can be found), on something like a daily\nbasis. Software for each user could continuously validate that their\naccount has a balance that matches what it's supposed to have, and could\nalso verify that owned addresses have funds that have at least as many\ncoins as promised to accounts. If these things aren't verifiable (either\nbecause the balances total to more than the HD wallet contains, or because\nof data unavailability), people can raise hell about it.\n\nTo give user's additional proving ability, a receipt system could be added.\nUsers could request a receipt for any balance update. Eg the user would\ncreate a message with a timestamp, their custodial \"address\", and the new\nbalance. The user would sign this receipt and send it to the custodian, who\nwould also sign it and send it back. This way, if something goes wrong, a\nuser can use this signed receipt to show that the custodian did in fact\npromise a new updated balance at a particular time (which would cover the\ncase that the custodian records the wrong value in their map). Conversely,\nthe receipt would be useful to honest custodians as well, since they could\nshow the user's signed receipt request in the case a user is trying to lie\nabout what balance they should have. There is still the case that the\ncustodian simply refuses to return a signed receipt, in which case the\nuser's only recourse is to yell about it immediately and demand a receipt\nor a refund.\n\nWhy record it on chain? Doing that gives a clear record of proof of\nreserves that can be verified later by anyone in the future. It prevents a\ncustodian from being able to change history when it suits them (by creating\na new records with false timestamps in the past). Many of these records\ncould be aggregated together and recorded in the same transaction (with a\nsingle hash), so a single transaction per day could record the records of\nall participating custodians. If all custodians are using a standard\nsystem, one can cross verify that addresses claimed by one custodian aren't\nalso claimed by another custodian.\n\nEven tho the user is responsible for their keys in order to properly\nverify, losing the keys isn't that big of a deal, since they could simply\ncreate a new seed and give a new public key to the custodian - who would\nhave other identifying information they could use to validate that they own\nthe account. So it places less responsibility on the user, while still\nintroducing people, in a light-weight way, to self custody of keys.\n\nHaving a record like this every day would reduce the possibility of\nshenanigans like taking a short term loan of a large amount of\ncryptocurrency. Sure, they could take a 10 minute loan once per day, but it\nwould also be possible to trace on-chain transactions so you could tell if\nsuch a thing was going on. I wonder if there would be some way to include\nthe ability to prove balances held on the lightning network, but I suspect\nthat isn't generally possible.\n\nIn any case, I'm curious what people think of this kind of thing, and if\nsystems with similar properties are already out there.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210705/fc1967cb/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-07-05T23:26:23",
                "message_text_only": "Good morning Billy,\n\n> I wonder if there would be some way to include the ability to prove balances held on the lightning network, but I suspect that isn't generally possible.\u00a0\n\nThinking about this in terms of economic logic:\n\nEvery channel is anchored onchain, and that anchor (the funding txout) is proof of the existence, and size, of the channel.\n\nThe two participants in the channel can sign a plaintext containing their node pubkeys and how much each owns.\nOne of the participants should provably be the custodian.\n\n* If the counterparty is a true third party, it has no incentive to lie about its money.\n  * Especially if the counterparty is *another* custodian who wants proof-of-reserves, it has every incentive to overreport, but then the first party will refuse to sign.\n    It has a disincentive to underreport, and would itself refuse to sign a dishonest report that assigns more funds to the first party.\n    The only case that would be acceptable to both custodians would be to honestly report their holdings in the Lightning channel.\n* If the counterparty is a sockpuppet of the custodian, then the entire channel is owned by the custodian and it would be fairly dumb of he custodian to claim to have less funds than the entire channel.\n\nPerhaps a more practical problem is that Lightning channel states change fairly quickly, and there are possible race conditions, due to network latency (remember, both nodes need to sign, meaning both of them need to communicate with each other, thus hit by network latency and other race conditions) where a custodian Lightning node is unable to \"freeze\" a snapshot of its current state and make an atomic proof-of-reserves of *all* channels.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Eric Voskuil",
                "date": "2021-07-05T23:32:04",
                "message_text_only": "If only one could prove that he won\u2019t get into a boating accident.\n\ne\n\n> On Jul 5, 2021, at 16:26, ZmnSCPxj via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> \ufeffGood morning Billy,\n> \n>> I wonder if there would be some way to include the ability to prove balances held on the lightning network, but I suspect that isn't generally possible. \n> \n> Thinking about this in terms of economic logic:\n> \n> Every channel is anchored onchain, and that anchor (the funding txout) is proof of the existence, and size, of the channel.\n> \n> The two participants in the channel can sign a plaintext containing their node pubkeys and how much each owns.\n> One of the participants should provably be the custodian.\n> \n> * If the counterparty is a true third party, it has no incentive to lie about its money.\n>  * Especially if the counterparty is *another* custodian who wants proof-of-reserves, it has every incentive to overreport, but then the first party will refuse to sign.\n>    It has a disincentive to underreport, and would itself refuse to sign a dishonest report that assigns more funds to the first party.\n>    The only case that would be acceptable to both custodians would be to honestly report their holdings in the Lightning channel.\n> * If the counterparty is a sockpuppet of the custodian, then the entire channel is owned by the custodian and it would be fairly dumb of he custodian to claim to have less funds than the entire channel.\n> \n> Perhaps a more practical problem is that Lightning channel states change fairly quickly, and there are possible race conditions, due to network latency (remember, both nodes need to sign, meaning both of them need to communicate with each other, thus hit by network latency and other race conditions) where a custodian Lightning node is unable to \"freeze\" a snapshot of its current state and make an atomic proof-of-reserves of *all* channels.\n> \n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-07-06T00:09:25",
                "message_text_only": "Good morning e,\n\n\n> If only one could prove that he won\u2019t get into a boating accident.\n\nAt least in the context of Lightning channels, if one party in the channel loses its key in a boating accident, the other party (assuming it is a true separate person and not a sockpuppet) has every incentive to unilaterally close the channel, which reveals the exact amounts (though not necessarily who owns which).\nIf the other party then uses its funds in a new proof-of-reserves, then obviously the other output of the unilateral close was the one lost in the boating accident.\n\nOn the other hand, yes, custodians losing custodied funds in boating accidents is much too common.\nI believe it is one reason why custodian proof-of-reserves is not that popular --- it only proves that the funds were owned under a particular key at some snapshot of the past, it does not prove that the key will not get lost (or \"lost and then salvaged by a scuba diver\") later.\n\n\nRegards,\nZmnSCPxj\n\n>\n> e\n>\n> > On Jul 5, 2021, at 16:26, ZmnSCPxj via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:\n> > Good morning Billy,\n> >\n> > > I wonder if there would be some way to include the ability to prove balances held on the lightning network, but I suspect that isn't generally possible.\n> >\n> > Thinking about this in terms of economic logic:\n> > Every channel is anchored onchain, and that anchor (the funding txout) is proof of the existence, and size, of the channel.\n> > The two participants in the channel can sign a plaintext containing their node pubkeys and how much each owns.\n> > One of the participants should provably be the custodian.\n> >\n> > -   If the counterparty is a true third party, it has no incentive to lie about its money.\n> > -   Especially if the counterparty is another custodian who wants proof-of-reserves, it has every incentive to overreport, but then the first party will refuse to sign.\n> >     It has a disincentive to underreport, and would itself refuse to sign a dishonest report that assigns more funds to the first party.\n> >     The only case that would be acceptable to both custodians would be to honestly report their holdings in the Lightning channel.\n> >\n> > -   If the counterparty is a sockpuppet of the custodian, then the entire channel is owned by the custodian and it would be fairly dumb of he custodian to claim to have less funds than the entire channel.\n> >\n> > Perhaps a more practical problem is that Lightning channel states change fairly quickly, and there are possible race conditions, due to network latency (remember, both nodes need to sign, meaning both of them need to communicate with each other, thus hit by network latency and other race conditions) where a custodian Lightning node is unable to \"freeze\" a snapshot of its current state and make an atomic proof-of-reserves of all channels.\n> > Regards,\n> > ZmnSCPxj\n> >\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Billy Tetrud",
                "date": "2021-07-06T01:34:53",
                "message_text_only": "@ ZmnSCPxj, Good Evening\n\n>  The two participants in the channel can sign a plaintext containing\ntheir node pubkeys and how much each owns\n\nSure, but even if both participants in the channel sign a correct statement\nof truth, one of the participants can send funds out in the next second,\ninvalidating that truth. While proof of ownership of on-chain UTXOs can be\nseen publicly in real time if they are spent, LN transactions aren't public\nlike that. So any balance attestation is at best only valid the instant its\ntaken, and can't be used as verification the money is still owned by the\nsame channel partner in the next second.\n\n>  a custodian Lightning node is unable to \"freeze\" a snapshot of its\ncurrent state and make an atomic proof-of-reserves of *all* channels\n\nThat would be a neat trick. But yeah, I don't know how that would be\npossible.\n\n>  I believe it is one reason why custodian proof-of-reserves is not that\npopular ... it does not prove that the key will not get lost\n\nTrue, but at least if funds do get lost, it would be come clear far\nquicker. Today, an insolvent company could go many months without the\npublic finding out.\n\nOn Mon, Jul 5, 2021 at 5:09 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning e,\n>\n>\n> > If only one could prove that he won\u2019t get into a boating accident.\n>\n> At least in the context of Lightning channels, if one party in the channel\n> loses its key in a boating accident, the other party (assuming it is a true\n> separate person and not a sockpuppet) has every incentive to unilaterally\n> close the channel, which reveals the exact amounts (though not necessarily\n> who owns which).\n> If the other party then uses its funds in a new proof-of-reserves, then\n> obviously the other output of the unilateral close was the one lost in the\n> boating accident.\n>\n> On the other hand, yes, custodians losing custodied funds in boating\n> accidents is much too common.\n> I believe it is one reason why custodian proof-of-reserves is not that\n> popular --- it only proves that the funds were owned under a particular key\n> at some snapshot of the past, it does not prove that the key will not get\n> lost (or \"lost and then salvaged by a scuba diver\") later.\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n> >\n> > e\n> >\n> > > On Jul 5, 2021, at 16:26, ZmnSCPxj via bitcoin-dev\n> bitcoin-dev at lists.linuxfoundation.org wrote:\n> > > Good morning Billy,\n> > >\n> > > > I wonder if there would be some way to include the ability to prove\n> balances held on the lightning network, but I suspect that isn't generally\n> possible.\n> > >\n> > > Thinking about this in terms of economic logic:\n> > > Every channel is anchored onchain, and that anchor (the funding txout)\n> is proof of the existence, and size, of the channel.\n> > > The two participants in the channel can sign a plaintext containing\n> their node pubkeys and how much each owns.\n> > > One of the participants should provably be the custodian.\n> > >\n> > > -   If the counterparty is a true third party, it has no incentive to\n> lie about its money.\n> > > -   Especially if the counterparty is another custodian who wants\n> proof-of-reserves, it has every incentive to overreport, but then the first\n> party will refuse to sign.\n> > >     It has a disincentive to underreport, and would itself refuse to\n> sign a dishonest report that assigns more funds to the first party.\n> > >     The only case that would be acceptable to both custodians would be\n> to honestly report their holdings in the Lightning channel.\n> > >\n> > > -   If the counterparty is a sockpuppet of the custodian, then the\n> entire channel is owned by the custodian and it would be fairly dumb of he\n> custodian to claim to have less funds than the entire channel.\n> > >\n> > > Perhaps a more practical problem is that Lightning channel states\n> change fairly quickly, and there are possible race conditions, due to\n> network latency (remember, both nodes need to sign, meaning both of them\n> need to communicate with each other, thus hit by network latency and other\n> race conditions) where a custodian Lightning node is unable to \"freeze\" a\n> snapshot of its current state and make an atomic proof-of-reserves of all\n> channels.\n> > > Regards,\n> > > ZmnSCPxj\n> > >\n> > > bitcoin-dev mailing list\n> > > bitcoin-dev at lists.linuxfoundation.org\n> > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210705/8f6b1e68/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-07-06T04:54:11",
                "message_text_only": "Good morning Billy,\n\n\n>\n> >\u00a0 The two participants in the channel can sign a plaintext containing their node pubkeys and how much each owns\n>\n> Sure, but even if both participants in the channel sign a correct statement of truth, one of the participants can send funds out in the next second, invalidating that truth. While proof of ownership of on-chain UTXOs can be seen publicly in real time if they are spent, LN transactions aren't public like that. So any balance attestation is at best only valid the instant its taken, and can't be used as verification the money is still owned by the same channel partner in the next second.\u00a0\n\nThe same problem really also exists onchain --- a thief (or \"thief\") who has gotten a copy of the key can sign a transaction that spends it, one second after the proof-of-reserves is made.\n\nReally, though, the issue is that ownership of funds is conditional on *knowledge* of keys.\nAnd *knowledge* is easily copyable.\n\nThus, it is possible that the funds that are \"proven\" to be the reserve of a custodian is actually *also* owned by someone else who has gotten to the privkeys (e.g. somebody threw a copy of it from a boating accident and a fearless scuba diver rescued it), and thus can also move the funds outside of the control of the custodian.\nThis condition can remain for many months or years, as well, without knowledge of the custodian clients, *or* of the custodian itself.\n\nThere is no way to prove that there is no alternate copy of the privkeys, hence \"if only one could prove that he won't get into a boating accident\".\n\nOn the other hand, one could argue that at least the onchain proof requires more conditions to occur, so we might plausibly live with \"we cannot prove we will never get into a boating accident but we can show evidence that we live in a landlocked city far from any lakes, seas, or rivers\".\n\nRegards,\nZmnSCPxj\n\n>\n> >\u00a0 a custodian Lightning node is unable to \"freeze\" a snapshot of its current state and make an atomic proof-of-reserves of *all* channels\n>\n> That would be a neat trick. But yeah, I don't know how that would be possible.\u00a0\n>\n> >\u00a0 I believe it is one reason why custodian proof-of-reserves is not that popular ... it does not prove that the key will not get lost\n>\n> True, but at least if funds do get lost, it would be come clear far quicker. Today, an insolvent company could go many months without the public finding out.\u00a0\n>\n> On Mon, Jul 5, 2021 at 5:09 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n> > Good morning e,\n> >\n> > > If only one could prove that he won\u2019t get into a boating accident.\n> >\n> > At least in the context of Lightning channels, if one party in the channel loses its key in a boating accident, the other party (assuming it is a true separate person and not a sockpuppet) has every incentive to unilaterally close the channel, which reveals the exact amounts (though not necessarily who owns which).\n> > If the other party then uses its funds in a new proof-of-reserves, then obviously the other output of the unilateral close was the one lost in the boating accident.\n> >\n> > On the other hand, yes, custodians losing custodied funds in boating accidents is much too common.\n> > I believe it is one reason why custodian proof-of-reserves is not that popular --- it only proves that the funds were owned under a particular key at some snapshot of the past, it does not prove that the key will not get lost (or \"lost and then salvaged by a scuba diver\") later.\n> >\n> > Regards,\n> > ZmnSCPxj\n> >\n> > >\n> > > e\n> > >\n> > > > On Jul 5, 2021, at 16:26, ZmnSCPxj via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:\n> > > > Good morning Billy,\n> > > >\n> > > > > I wonder if there would be some way to include the ability to prove balances held on the lightning network, but I suspect that isn't generally possible.\n> > > >\n> > > > Thinking about this in terms of economic logic:\n> > > > Every channel is anchored onchain, and that anchor (the funding txout) is proof of the existence, and size, of the channel.\n> > > > The two participants in the channel can sign a plaintext containing their node pubkeys and how much each owns.\n> > > > One of the participants should provably be the custodian.\n> > > >\n> > > > -\u00a0 \u00a0If the counterparty is a true third party, it has no incentive to lie about its money.\n> > > > -\u00a0 \u00a0Especially if the counterparty is another custodian who wants proof-of-reserves, it has every incentive to overreport, but then the first party will refuse to sign.\n> > > >\u00a0 \u00a0 \u00a0It has a disincentive to underreport, and would itself refuse to sign a dishonest report that assigns more funds to the first party.\n> > > >\u00a0 \u00a0 \u00a0The only case that would be acceptable to both custodians would be to honestly report their holdings in the Lightning channel.\n> > > >\n> > > > -\u00a0 \u00a0If the counterparty is a sockpuppet of the custodian, then the entire channel is owned by the custodian and it would be fairly dumb of he custodian to claim to have less funds than the entire channel.\n> > > >\n> > > > Perhaps a more practical problem is that Lightning channel states change fairly quickly, and there are possible race conditions, due to network latency (remember, both nodes need to sign, meaning both of them need to communicate with each other, thus hit by network latency and other race conditions) where a custodian Lightning node is unable to \"freeze\" a snapshot of its current state and make an atomic proof-of-reserves of all channels.\n> > > > Regards,\n> > > > ZmnSCPxj\n> > > >\n> > > > bitcoin-dev mailing list\n> > > > bitcoin-dev at lists.linuxfoundation.org\n> > > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Eric Voskuil",
                "date": "2021-07-06T05:09:59",
                "message_text_only": "https://github.com/libbitcoin/libbitcoin-system/wiki/Auditability-Fallacy\n\n> On Jul 5, 2021, at 21:54, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n> \n> \ufeffGood morning Billy,\n> \n> \n>> \n>>>   The two participants in the channel can sign a plaintext containing their node pubkeys and how much each owns\n>> \n>> Sure, but even if both participants in the channel sign a correct statement of truth, one of the participants can send funds out in the next second, invalidating that truth. While proof of ownership of on-chain UTXOs can be seen publicly in real time if they are spent, LN transactions aren't public like that. So any balance attestation is at best only valid the instant its taken, and can't be used as verification the money is still owned by the same channel partner in the next second. \n> \n> The same problem really also exists onchain --- a thief (or \"thief\") who has gotten a copy of the key can sign a transaction that spends it, one second after the proof-of-reserves is made.\n> \n> Really, though, the issue is that ownership of funds is conditional on *knowledge* of keys.\n> And *knowledge* is easily copyable.\n> \n> Thus, it is possible that the funds that are \"proven\" to be the reserve of a custodian is actually *also* owned by someone else who has gotten to the privkeys (e.g. somebody threw a copy of it from a boating accident and a fearless scuba diver rescued it), and thus can also move the funds outside of the control of the custodian.\n> This condition can remain for many months or years, as well, without knowledge of the custodian clients, *or* of the custodian itself.\n> \n> There is no way to prove that there is no alternate copy of the privkeys, hence \"if only one could prove that he won't get into a boating accident\".\n> \n> On the other hand, one could argue that at least the onchain proof requires more conditions to occur, so we might plausibly live with \"we cannot prove we will never get into a boating accident but we can show evidence that we live in a landlocked city far from any lakes, seas, or rivers\".\n> \n> Regards,\n> ZmnSCPxj\n> \n>> \n>>>   a custodian Lightning node is unable to \"freeze\" a snapshot of its current state and make an atomic proof-of-reserves of *all* channels\n>> \n>> That would be a neat trick. But yeah, I don't know how that would be possible. \n>> \n>>>   I believe it is one reason why custodian proof-of-reserves is not that popular ... it does not prove that the key will not get lost\n>> \n>> True, but at least if funds do get lost, it would be come clear far quicker. Today, an insolvent company could go many months without the public finding out. \n>> \n>> On Mon, Jul 5, 2021 at 5:09 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>> \n>>> Good morning e,\n>>> \n>>>> If only one could prove that he won\u2019t get into a boating accident.\n>>> \n>>> At least in the context of Lightning channels, if one party in the channel loses its key in a boating accident, the other party (assuming it is a true separate person and not a sockpuppet) has every incentive to unilaterally close the channel, which reveals the exact amounts (though not necessarily who owns which).\n>>> If the other party then uses its funds in a new proof-of-reserves, then obviously the other output of the unilateral close was the one lost in the boating accident.\n>>> \n>>> On the other hand, yes, custodians losing custodied funds in boating accidents is much too common.\n>>> I believe it is one reason why custodian proof-of-reserves is not that popular --- it only proves that the funds were owned under a particular key at some snapshot of the past, it does not prove that the key will not get lost (or \"lost and then salvaged by a scuba diver\") later.\n>>> \n>>> Regards,\n>>> ZmnSCPxj\n>>> \n>>>> \n>>>> e\n>>>> \n>>>>> On Jul 5, 2021, at 16:26, ZmnSCPxj via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:\n>>>>> Good morning Billy,\n>>>>> \n>>>>>> I wonder if there would be some way to include the ability to prove balances held on the lightning network, but I suspect that isn't generally possible.\n>>>>> \n>>>>> Thinking about this in terms of economic logic:\n>>>>> Every channel is anchored onchain, and that anchor (the funding txout) is proof of the existence, and size, of the channel.\n>>>>> The two participants in the channel can sign a plaintext containing their node pubkeys and how much each owns.\n>>>>> One of the participants should provably be the custodian.\n>>>>> \n>>>>> -   If the counterparty is a true third party, it has no incentive to lie about its money.\n>>>>> -   Especially if the counterparty is another custodian who wants proof-of-reserves, it has every incentive to overreport, but then the first party will refuse to sign.\n>>>>>      It has a disincentive to underreport, and would itself refuse to sign a dishonest report that assigns more funds to the first party.\n>>>>>      The only case that would be acceptable to both custodians would be to honestly report their holdings in the Lightning channel.\n>>>>> \n>>>>> -   If the counterparty is a sockpuppet of the custodian, then the entire channel is owned by the custodian and it would be fairly dumb of he custodian to claim to have less funds than the entire channel.\n>>>>> \n>>>>> Perhaps a more practical problem is that Lightning channel states change fairly quickly, and there are possible race conditions, due to network latency (remember, both nodes need to sign, meaning both of them need to communicate with each other, thus hit by network latency and other race conditions) where a custodian Lightning node is unable to \"freeze\" a snapshot of its current state and make an atomic proof-of-reserves of all channels.\n>>>>> Regards,\n>>>>> ZmnSCPxj\n>>>>> \n>>>>> bitcoin-dev mailing list\n>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n> \n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210705/60070878/attachment-0001.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2021-07-06T06:02:45",
                "message_text_only": "@ZmnSCPxj\n>  a thief (or \"thief\") who has gotten a copy of the key can sign a\ntransaction that spends it, one second after the proof-of-reserves is made.\n\nSure, but anyone can easily see that transaction happen and can discount\nthat part of the attestation. The same isn't true on lightning.\n\n> *knowledge* is easily copyable.\n\nKnowledge isn't even really needed. Custodians could collude to sign each\nother's balance attestations. However, if the network of proof of reserves\nis cohesive, people could validate that addresses (and their balances)\naren't shared by anyone that's part of that PoR network.\n\n> There is no way to prove that there is no alternate copy of the privkeys\n\nWell there are only really 2 cases:\n\n1. Only one entity has the keys\n2. Two entities have the keys and trust each other\n\nIn case 1, the attestation is accurate. In case 2, its really another way\nof saying case 1: you can view the two trusting entities as a single\nentity. In the case there are 2 non-trusting entities, its very likely that\none would steal from the other, or that they would be very uncomfortable\nwith the situation such that it wouldn't last long.\n\nBut you can't prove that someone won't steal the reserves. You can't prove\ncryptographically that the reserves aren't promised to someone else in a\nlegal contract (unless of course you make the proof of reserves system\nlegally binding). But this is why anyone that recommends PoR also\nrecommends independent audits to attest that the PoR actually matches\nreality.\n\nSo yes, there are limitations, but I don't think that means that PoR isn't\nworth doing. Is that what you're implying?\n\n> we can show evidence that we live in a landlocked city far from any\nlakes, seas, or rivers\n\nI think that's the idea, if I understand you correctly.\n\n@Eric\nAuditability Fallacy\n<https://github.com/libbitcoin/libbitcoin-system/wiki/Auditability-Fallacy>\n\n> A solvency audit requires simultaneous (atomic) proof of both the full\namount of the asset held by a custodian and the securities issued against\nit.\n\n> in the case where the security is issued on a distinct public chain the\natomicity requirement is not satisfied.\n\nI think what its saying is that you can't get atomicity of both the\nsecurity and the reserve. While this is true, what you can get is a system\nwhere the order of events can be established to a degree of precision. Ie,\nyou can know that between reserve-snapshot A and B, the balances add up to\nX. Each user can validate that their balance was indeed that value between\nA and B. With reserve snapshots and balance snapshots frequent enough, this\ncan allow reasonably high accuracy of estimated solvency. However, it does\nseem clear that perfect accuracy is not possible.\n\n> Historically it has not been difficult to detect such deviations. The\ndifficulty arises in stopping them.\n\nI disagree here that it has not been difficult to detect deviations\n(insolvency). I mean, \"difficulty\" isn't the right word. These things\nalways become clear eventually. But I think its important to detect\ninsolvency quickly. Historically insolvency has certainly not been detected\nquickly. Insolvency is instead practically perpetual, and the question is\nonly how insolvent and when will it explode?\n\nI'm of the opinion that you can't prevent insolvency. Places will have\nmoney troubles and will try to cover it up, since usually there is no\ndownside (admitting insolvency can lead to bankrupcy, and failure to\nconceal insolvency has the same result - so why not try to conceal it and\nhope you can shore it up). However, its important that people know the\ninstitutions they have their money in are insolvent, or to what degree they\nare. If that information were well tracked, it could become clear over time\nthat a 10% insolvent company rarely goes out of business, but a 20%\ninsolvent company usually does. Then people can have parameters where\nthey're ok with a certain measurable degree of insolvency, but react\nswiftly and strongly when a company is too reckless. Currently the amount\nof recklessness any given company engages in is basically a company secret\nthat their clients don't have insight into. PoR would greatly help this I\nthink. You don't think so?\n\nOn Mon, Jul 5, 2021 at 10:10 PM Eric Voskuil <eric at voskuil.org> wrote:\n\n> https://github.com/libbitcoin/libbitcoin-system/wiki/Auditability-Fallacy\n>\n> On Jul 5, 2021, at 21:54, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n> \ufeffGood morning Billy,\n>\n>\n>\n>   The two participants in the channel can sign a plaintext containing\n> their node pubkeys and how much each owns\n>\n>\n> Sure, but even if both participants in the channel sign a correct\n> statement of truth, one of the participants can send funds out in the next\n> second, invalidating that truth. While proof of ownership of on-chain UTXOs\n> can be seen publicly in real time if they are spent, LN transactions aren't\n> public like that. So any balance attestation is at best only valid the\n> instant its taken, and can't be used as verification the money is still\n> owned by the same channel partner in the next second.\n>\n>\n> The same problem really also exists onchain --- a thief (or \"thief\") who\n> has gotten a copy of the key can sign a transaction that spends it, one\n> second after the proof-of-reserves is made.\n>\n> Really, though, the issue is that ownership of funds is conditional on\n> *knowledge* of keys.\n> And *knowledge* is easily copyable.\n>\n> Thus, it is possible that the funds that are \"proven\" to be the reserve of\n> a custodian is actually *also* owned by someone else who has gotten to the\n> privkeys (e.g. somebody threw a copy of it from a boating accident and a\n> fearless scuba diver rescued it), and thus can also move the funds outside\n> of the control of the custodian.\n> This condition can remain for many months or years, as well, without\n> knowledge of the custodian clients, *or* of the custodian itself.\n>\n> There is no way to prove that there is no alternate copy of the privkeys,\n> hence \"if only one could prove that he won't get into a boating accident\".\n>\n> On the other hand, one could argue that at least the onchain proof\n> requires more conditions to occur, so we might plausibly live with \"we\n> cannot prove we will never get into a boating accident but we can show\n> evidence that we live in a landlocked city far from any lakes, seas, or\n> rivers\".\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n>   a custodian Lightning node is unable to \"freeze\" a snapshot of its\n> current state and make an atomic proof-of-reserves of *all* channels\n>\n>\n> That would be a neat trick. But yeah, I don't know how that would be\n> possible.\n>\n>\n>   I believe it is one reason why custodian proof-of-reserves is not that\n> popular ... it does not prove that the key will not get lost\n>\n>\n> True, but at least if funds do get lost, it would be come clear far\n> quicker. Today, an insolvent company could go many months without the\n> public finding out.\n>\n>\n> On Mon, Jul 5, 2021 at 5:09 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n>\n> Good morning e,\n>\n>\n> If only one could prove that he won\u2019t get into a boating accident.\n>\n>\n> At least in the context of Lightning channels, if one party in the channel\n> loses its key in a boating accident, the other party (assuming it is a true\n> separate person and not a sockpuppet) has every incentive to unilaterally\n> close the channel, which reveals the exact amounts (though not necessarily\n> who owns which).\n>\n> If the other party then uses its funds in a new proof-of-reserves, then\n> obviously the other output of the unilateral close was the one lost in the\n> boating accident.\n>\n>\n> On the other hand, yes, custodians losing custodied funds in boating\n> accidents is much too common.\n>\n> I believe it is one reason why custodian proof-of-reserves is not that\n> popular --- it only proves that the funds were owned under a particular key\n> at some snapshot of the past, it does not prove that the key will not get\n> lost (or \"lost and then salvaged by a scuba diver\") later.\n>\n>\n> Regards,\n>\n> ZmnSCPxj\n>\n>\n>\n> e\n>\n>\n> On Jul 5, 2021, at 16:26, ZmnSCPxj via bitcoin-dev\n> bitcoin-dev at lists.linuxfoundation.org wrote:\n>\n> Good morning Billy,\n>\n>\n> I wonder if there would be some way to include the ability to prove\n> balances held on the lightning network, but I suspect that isn't generally\n> possible.\n>\n>\n> Thinking about this in terms of economic logic:\n>\n> Every channel is anchored onchain, and that anchor (the funding txout) is\n> proof of the existence, and size, of the channel.\n>\n> The two participants in the channel can sign a plaintext containing their\n> node pubkeys and how much each owns.\n>\n> One of the participants should provably be the custodian.\n>\n>\n> -   If the counterparty is a true third party, it has no incentive to lie\n> about its money.\n>\n> -   Especially if the counterparty is another custodian who wants\n> proof-of-reserves, it has every incentive to overreport, but then the first\n> party will refuse to sign.\n>\n>      It has a disincentive to underreport, and would itself refuse to sign\n> a dishonest report that assigns more funds to the first party.\n>\n>      The only case that would be acceptable to both custodians would be to\n> honestly report their holdings in the Lightning channel.\n>\n>\n> -   If the counterparty is a sockpuppet of the custodian, then the entire\n> channel is owned by the custodian and it would be fairly dumb of he\n> custodian to claim to have less funds than the entire channel.\n>\n>\n> Perhaps a more practical problem is that Lightning channel states change\n> fairly quickly, and there are possible race conditions, due to network\n> latency (remember, both nodes need to sign, meaning both of them need to\n> communicate with each other, thus hit by network latency and other race\n> conditions) where a custodian Lightning node is unable to \"freeze\" a\n> snapshot of its current state and make an atomic proof-of-reserves of all\n> channels.\n>\n> Regards,\n>\n> ZmnSCPxj\n>\n>\n> bitcoin-dev mailing list\n>\n> bitcoin-dev at lists.linuxfoundation.org\n>\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210705/b2c7cab2/attachment-0001.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2021-07-06T07:37:07",
                "message_text_only": "> @Eric\n> Auditability Fallacy\n> \n> > A solvency audit requires simultaneous (atomic) proof of both the full amount of the asset held by a custodian and the securities issued against it.\n> \n> > in the case where the security is issued on a distinct public chain the atomicity requirement is not satisfied.\n> \n> I think what its saying is that you can't get atomicity of both the security and the reserve. While this is true, what you can get is a system where the order of events can be established to a degree of precision. Ie, you can know that between reserve-snapshot A and B, the balances add up to X. Each user can validate that their balance was indeed that value between A and B. With reserve snapshots and balance snapshots frequent enough, this can allow reasonably high accuracy of estimated solvency. However, it does seem clear that perfect accuracy is not possible.\n\nIf perfect is not possible, it\u2019s not possible. It reduces to trust, which is the status quo.\n\nAll \u201cusers\u201d need to simultaneously share their individual and temporary audits with each other (ie publicly).\n\n> > Historically it has not been difficult to detect such deviations. The difficulty arises in stopping them.\n> \n> I disagree here that it has not been difficult to detect deviations (insolvency).\n\nIt is not hard to spot price inflation. Stopping or avoiding it is the actual issue. No \u201cproof\u201d of reserve can do this. The federal reserve was clearly insolvent from its early days, as that was its purpose.\n\n> I mean, \"difficulty\" isn't the right word. These things always become clear eventually. But I think its important to detect insolvency quickly. Historically insolvency has certainly not been detected quickly. Insolvency is instead practically perpetual, and the question is only how insolvent and when will it explode?\n\nThere is no \u201cproof\u201d that answers this question.\n\n> I'm of the opinion that you can't prevent insolvency.\n\nIt\u2019s not a matter of opinion. Lending implies risk. When you invest you are in fact the owner of the insolvency, not someone else.\n\n> Places will have money troubles and will try to cover it up, since usually there is no downside (admitting insolvency can lead to bankrupcy, and failure to conceal insolvency has the same result - so why not try to conceal it and hope you can shore it up). However, its important that people know the institutions they have their money in are insolvent, or to what degree they are. If that information were well tracked, it could become clear over time that a 10% insolvent company rarely goes out of business, but a 20% insolvent company usually does.\n\nNonsense, any business can fail, regardless of temporal cash reserves.\n\n> Then people can have parameters where they're ok with a certain measurable degree of insolvency, but react swiftly and strongly when a company is too reckless. Currently the amount of recklessness any given company engages in is basically a company secret that their clients don't have insight into. PoR would greatly help this I think. You don't think so? \n\nReckless is a subjective term. Proofs will not insure any investment.\n\ne\n\n>> On Mon, Jul 5, 2021 at 10:10 PM Eric Voskuil <eric at voskuil.org> wrote:\n>> https://github.com/libbitcoin/libbitcoin-system/wiki/Auditability-Fallacy\n>> \n>>>> On Jul 5, 2021, at 21:54, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>>>> \n>>> \ufeffGood morning Billy,\n>>> \n>>> \n>>>> \n>>>>>   The two participants in the channel can sign a plaintext containing their node pubkeys and how much each owns\n>>>> \n>>>> Sure, but even if both participants in the channel sign a correct statement of truth, one of the participants can send funds out in the next second, invalidating that truth. While proof of ownership of on-chain UTXOs can be seen publicly in real time if they are spent, LN transactions aren't public like that. So any balance attestation is at best only valid the instant its taken, and can't be used as verification the money is still owned by the same channel partner in the next second. \n>>> \n>>> The same problem really also exists onchain --- a thief (or \"thief\") who has gotten a copy of the key can sign a transaction that spends it, one second after the proof-of-reserves is made.\n>>> \n>>> Really, though, the issue is that ownership of funds is conditional on *knowledge* of keys.\n>>> And *knowledge* is easily copyable.\n>>> \n>>> Thus, it is possible that the funds that are \"proven\" to be the reserve of a custodian is actually *also* owned by someone else who has gotten to the privkeys (e.g. somebody threw a copy of it from a boating accident and a fearless scuba diver rescued it), and thus can also move the funds outside of the control of the custodian.\n>>> This condition can remain for many months or years, as well, without knowledge of the custodian clients, *or* of the custodian itself.\n>>> \n>>> There is no way to prove that there is no alternate copy of the privkeys, hence \"if only one could prove that he won't get into a boating accident\".\n>>> \n>>> On the other hand, one could argue that at least the onchain proof requires more conditions to occur, so we might plausibly live with \"we cannot prove we will never get into a boating accident but we can show evidence that we live in a landlocked city far from any lakes, seas, or rivers\".\n>>> \n>>> Regards,\n>>> ZmnSCPxj\n>>> \n>>>> \n>>>>>   a custodian Lightning node is unable to \"freeze\" a snapshot of its current state and make an atomic proof-of-reserves of *all* channels\n>>>> \n>>>> That would be a neat trick. But yeah, I don't know how that would be possible. \n>>>> \n>>>>>   I believe it is one reason why custodian proof-of-reserves is not that popular ... it does not prove that the key will not get lost\n>>>> \n>>>> True, but at least if funds do get lost, it would be come clear far quicker. Today, an insolvent company could go many months without the public finding out. \n>>>> \n>>>>> On Mon, Jul 5, 2021 at 5:09 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>>>>> \n>>>>> Good morning e,\n>>>>> \n>>>>>> If only one could prove that he won\u2019t get into a boating accident.\n>>>>> \n>>>>> At least in the context of Lightning channels, if one party in the channel loses its key in a boating accident, the other party (assuming it is a true separate person and not a sockpuppet) has every incentive to unilaterally close the channel, which reveals the exact amounts (though not necessarily who owns which).\n>>>>> If the other party then uses its funds in a new proof-of-reserves, then obviously the other output of the unilateral close was the one lost in the boating accident.\n>>>>> \n>>>>> On the other hand, yes, custodians losing custodied funds in boating accidents is much too common.\n>>>>> I believe it is one reason why custodian proof-of-reserves is not that popular --- it only proves that the funds were owned under a particular key at some snapshot of the past, it does not prove that the key will not get lost (or \"lost and then salvaged by a scuba diver\") later.\n>>>>> \n>>>>> Regards,\n>>>>> ZmnSCPxj\n>>>>> \n>>>>>> \n>>>>>> e\n>>>>>> \n>>>>>>> On Jul 5, 2021, at 16:26, ZmnSCPxj via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:\n>>>>>>> Good morning Billy,\n>>>>>>> \n>>>>>>>> I wonder if there would be some way to include the ability to prove balances held on the lightning network, but I suspect that isn't generally possible.\n>>>>>>> \n>>>>>>> Thinking about this in terms of economic logic:\n>>>>>>> Every channel is anchored onchain, and that anchor (the funding txout) is proof of the existence, and size, of the channel.\n>>>>>>> The two participants in the channel can sign a plaintext containing their node pubkeys and how much each owns.\n>>>>>>> One of the participants should provably be the custodian.\n>>>>>>> \n>>>>>>> -   If the counterparty is a true third party, it has no incentive to lie about its money.\n>>>>>>> -   Especially if the counterparty is another custodian who wants proof-of-reserves, it has every incentive to overreport, but then the first party will refuse to sign.\n>>>>>>>      It has a disincentive to underreport, and would itself refuse to sign a dishonest report that assigns more funds to the first party.\n>>>>>>>      The only case that would be acceptable to both custodians would be to honestly report their holdings in the Lightning channel.\n>>>>>>> \n>>>>>>> -   If the counterparty is a sockpuppet of the custodian, then the entire channel is owned by the custodian and it would be fairly dumb of he custodian to claim to have less funds than the entire channel.\n>>>>>>> \n>>>>>>> Perhaps a more practical problem is that Lightning channel states change fairly quickly, and there are possible race conditions, due to network latency (remember, both nodes need to sign, meaning both of them need to communicate with each other, thus hit by network latency and other race conditions) where a custodian Lightning node is unable to \"freeze\" a snapshot of its current state and make an atomic proof-of-reserves of all channels.\n>>>>>>> Regards,\n>>>>>>> ZmnSCPxj\n>>>>>>> \n>>>>>>> bitcoin-dev mailing list\n>>>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>> \n>>> \n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210706/fdd3ae32/attachment-0001.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2021-07-06T16:39:36",
                "message_text_only": "you should check out some of the earlier work done here:\n\nhttps://github.com/olalonde/proof-of-solvency#assets-proof\n\nto be honest, if any exchange supported that proof, it would be more\nthan enough.\n\nthere's really no way to prevent a smash-and-grab, but this does\nprevent a slow-leak\n\n\nOn Mon, Jul 5, 2021 at 5:10 PM Billy Tetrud via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> I had the idea recently for proof of reserves done in a way that can be used to verify reserves are sufficient on an ongoing basis. I'm curious if there are any current approaches out there to proof of reserves that are similar.\n>\n> The idea is to have users create actual private keys using a seed in pretty much the normal way. Users would generate a public key from this seed to represent their account, and would give the public key to the custodian to represent their account in a public record of account balances.\n>\n> When a user's account is credited, the custodian would update a map of addresses (created from the public key of each account) to balances - this map could be structured into a merkle tree in the usual \"merkle approach\". The custodian would also store funds on one or more HD wallets (each with many addresses) and create a proof that they own each HD wallet. The proof could be as simple as a single signature created with the xpub for the wallet, which would be sufficient for proving ownership over the whole list/tree of addresses.\n>\n> These two structures (the map and the HD wallet) would be combined and hashed, and the hash published in an on chain transaction (possibly along with a URI where the full data can be found), on something like a daily basis. Software for each user could continuously validate that their account has a balance that matches what it's supposed to have, and could also verify that owned addresses have funds that have at least as many coins as promised to accounts. If these things aren't verifiable (either because the balances total to more than the HD wallet contains, or because of data unavailability), people can raise hell about it.\n>\n> To give user's additional proving ability, a receipt system could be added. Users could request a receipt for any balance update. Eg the user would create a message with a timestamp, their custodial \"address\", and the new balance. The user would sign this receipt and send it to the custodian, who would also sign it and send it back. This way, if something goes wrong, a user can use this signed receipt to show that the custodian did in fact promise a new updated balance at a particular time (which would cover the case that the custodian records the wrong value in their map). Conversely, the receipt would be useful to honest custodians as well, since they could show the user's signed receipt request in the case a user is trying to lie about what balance they should have. There is still the case that the custodian simply refuses to return a signed receipt, in which case the user's only recourse is to yell about it immediately and demand a receipt or a refund.\n>\n> Why record it on chain? Doing that gives a clear record of proof of reserves that can be verified later by anyone in the future. It prevents a custodian from being able to change history when it suits them (by creating a new records with false timestamps in the past). Many of these records could be aggregated together and recorded in the same transaction (with a single hash), so a single transaction per day could record the records of all participating custodians. If all custodians are using a standard system, one can cross verify that addresses claimed by one custodian aren't also claimed by another custodian.\n>\n> Even tho the user is responsible for their keys in order to properly verify, losing the keys isn't that big of a deal, since they could simply create a new seed and give a new public key to the custodian - who would have other identifying information they could use to validate that they own the account. So it places less responsibility on the user, while still introducing people, in a light-weight way, to self custody of keys.\n>\n> Having a record like this every day would reduce the possibility of shenanigans like taking a short term loan of a large amount of cryptocurrency. Sure, they could take a 10 minute loan once per day, but it would also be possible to trace on-chain transactions so you could tell if such a thing was going on. I wonder if there would be some way to include the ability to prove balances held on the lightning network, but I suspect that isn't generally possible.\n>\n> In any case, I'm curious what people think of this kind of thing, and if systems with similar properties are already out there.\n>\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "eric at voskuil.org",
                "date": "2021-07-06T18:40:35",
                "message_text_only": "> you should check out some of the earlier work done here:\n> \n> https://github.com/olalonde/proof-of-solvency#assets-proofNothing in this \n\nNothing here refutes what I have said. Furthermore it relies on the\nassumption that all assets and liabilities are provable. This is clearly\nprohibitive.\n\n> more than enough.\n\nArbitrary and subjective.\n\nA business raises money (investment) so that it can spend more than it\npreviously had. This is net \"insolvency\" until (and assuming) it produces\nand earns over time an amount sufficient to cover its capitalization and\ntime value.\n\nThese sort of schemes are relevant only to what Rothbard calls a money\n\"warehouse\" (a literal vault), which is explicitly not a \"bank\" (banks\nlend). Warehousing Bitcoin is a strange idea to start with. And given that\nthey are so larded with trust and race conditions it's hardly an improvement\nover holding your own keys.\n\ne\n\n> -----Original Message-----\n> From: bitcoin-dev <bitcoin-dev-bounces at lists.linuxfoundation.org> On\n> Behalf Of Erik Aronesty via bitcoin-dev\n> Sent: Tuesday, July 6, 2021 9:40 AM\n> To: Billy Tetrud <billy.tetrud at gmail.com>; Bitcoin Protocol Discussion\n> <bitcoin-dev at lists.linuxfoundation.org>\n> Subject: Re: [bitcoin-dev] Proof of reserves - recording\n> \n> you should check out some of the earlier work done here:\n> \n> https://github.com/olalonde/proof-of-solvency#assets-proof\n> \n> to be honest, if any exchange supported that proof, it would be more than\n> enough.\n> \n> there's really no way to prevent a smash-and-grab, but this does prevent a\n> slow-leak\n> \n> \n> On Mon, Jul 5, 2021 at 5:10 PM Billy Tetrud via bitcoin-dev <bitcoin-\n> dev at lists.linuxfoundation.org> wrote:\n> >\n> > I had the idea recently for proof of reserves done in a way that can be\nused\n> to verify reserves are sufficient on an ongoing basis. I'm curious if\nthere are\n> any current approaches out there to proof of reserves that are similar.\n> >\n> > The idea is to have users create actual private keys using a seed in\npretty\n> much the normal way. Users would generate a public key from this seed to\n> represent their account, and would give the public key to the custodian to\n> represent their account in a public record of account balances.\n> >\n> > When a user's account is credited, the custodian would update a map of\n> addresses (created from the public key of each account) to balances - this\n> map could be structured into a merkle tree in the usual \"merkle approach\".\n> The custodian would also store funds on one or more HD wallets (each with\n> many addresses) and create a proof that they own each HD wallet. The proof\n> could be as simple as a single signature created with the xpub for the\nwallet,\n> which would be sufficient for proving ownership over the whole list/tree\nof\n> addresses.\n> >\n> > These two structures (the map and the HD wallet) would be combined and\n> hashed, and the hash published in an on chain transaction (possibly along\n> with a URI where the full data can be found), on something like a daily\nbasis.\n> Software for each user could continuously validate that their account has\na\n> balance that matches what it's supposed to have, and could also verify\nthat\n> owned addresses have funds that have at least as many coins as promised to\n> accounts. If these things aren't verifiable (either because the balances\ntotal\n> to more than the HD wallet contains, or because of data unavailability),\n> people can raise hell about it.\n> >\n> > To give user's additional proving ability, a receipt system could be\nadded.\n> Users could request a receipt for any balance update. Eg the user would\n> create a message with a timestamp, their custodial \"address\", and the new\n> balance. The user would sign this receipt and send it to the custodian,\nwho\n> would also sign it and send it back. This way, if something goes wrong, a\nuser\n> can use this signed receipt to show that the custodian did in fact promise\na\n> new updated balance at a particular time (which would cover the case that\n> the custodian records the wrong value in their map). Conversely, the\nreceipt\n> would be useful to honest custodians as well, since they could show the\n> user's signed receipt request in the case a user is trying to lie about\nwhat\n> balance they should have. There is still the case that the custodian\nsimply\n> refuses to return a signed receipt, in which case the user's only recourse\nis to\n> yell about it immediately and demand a receipt or a refund.\n> >\n> > Why record it on chain? Doing that gives a clear record of proof of\nreserves\n> that can be verified later by anyone in the future. It prevents a\ncustodian\n> from being able to change history when it suits them (by creating a new\n> records with false timestamps in the past). Many of these records could be\n> aggregated together and recorded in the same transaction (with a single\n> hash), so a single transaction per day could record the records of all\n> participating custodians. If all custodians are using a standard system,\none can\n> cross verify that addresses claimed by one custodian aren't also claimed\nby\n> another custodian.\n> >\n> > Even tho the user is responsible for their keys in order to properly\nverify,\n> losing the keys isn't that big of a deal, since they could simply create a\nnew\n> seed and give a new public key to the custodian - who would have other\n> identifying information they could use to validate that they own the\naccount.\n> So it places less responsibility on the user, while still introducing\npeople, in a\n> light-weight way, to self custody of keys.\n> >\n> > Having a record like this every day would reduce the possibility of\n> shenanigans like taking a short term loan of a large amount of\n> cryptocurrency. Sure, they could take a 10 minute loan once per day, but\nit\n> would also be possible to trace on-chain transactions so you could tell if\nsuch\n> a thing was going on. I wonder if there would be some way to include the\n> ability to prove balances held on the lightning network, but I suspect\nthat\n> isn't generally possible.\n> >\n> > In any case, I'm curious what people think of this kind of thing, and if\n> systems with similar properties are already out there.\n> >\n> >\n> >\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Billy Tetrud",
                "date": "2021-07-07T06:18:58",
                "message_text_only": "I wanted to relay an interesting related link that Melvin PMed me:\nhttps://petertodd.org/2016/commitments-and-single-use-seals\n\n@Aronesty\nThanks, that system looks interesting, I'll have a closer look!\n\n@Voskuil\nI think we must disagree on at least one fundamental point. I'm finding\nmyself disagreeing with most of what you're saying.\n\n> If perfect is not possible, it\u2019s not possible. It reduces to trust, which\nis the status quo.\n\nLet not perfect be the enemy of good. Trust cannot be eliminated.\nPerfection cannot be achieved. However trust can be reduced further than it\nexists today, and we can clearly make things better than they are now. Are\nyou really saying that if its not perfect, its worthless?\n\n> All \u201cusers\u201d need to simultaneously share their individual and temporary\naudits with each other (ie publicly).\n\nThis is not the case. In both the mechanism I briefly described and Peter\nTodd's mechanism from Melvin's link (top of this message), users need not\nshare any information with other users unless that information is \"my\nbalance doesn't match the record\". It doesn't even need to be in a timely\nmanner if these records are committed to the blockchain - one could\ntheoretically look back years and compare their personal records to the\nrecords published by the custodian, and then tell the community about it if\nthey don't match. All that is required is that a critical mass of users\nverify their balance (ideally using software that regularly checks\nautomatically).\n\n> It is not hard to spot price inflation\n\nI don't know why you think that's the case. Inflation is today vehemently\nargued about. Are high real estate prices indications of inflation? What\nabout recovering stock prices? Is inflation temporary or will we expect it\nto last more long term? If one company is inflating perceived supply, this\nwould almost certainly not show up as significant economy-wide inflation.\nAnd if the majority of companies are doing it, how can you stop it if you\ndon't have any idea which ones are doing it? I do think spotting the\ninflation in any kind of timely manner is indeed hard.\n\n> Stopping or avoiding it is the actual issue. No \u201cproof\u201d of reserve can do\nthis.\n\nI of course agree that proof of reserves cannot stop inflation/insolvency.\nI disagree with the idea that this is the \"actual\" issue - which seems to\nimply to me that its the only issue that matters. Even if we can't stop a\ncompany from promising more coins than they have in reserves, we can limit\nhow long these events happen for - and how big these bubbles can get. Don't\nyou agree that would be very helpful, if it were it possible (which it\nseems you think it isn't)?\n\n> The federal reserve was clearly insolvent from its early days, as that\nwas its purpose.\n\nDo you have a source as evidence that it was widely understood that the Fed\nwas insolvent from its early days? I really don't think it was seen as the\npurpose by the vast majority of people in the US. People were lead to\nbelieve every dollar was backed by a unique chunk of gold. Had it been\npossible to do a kind of proof of reserves (or estimate of reserves) as\nwe're talking about, it would have been clear much earlier that the Fed was\ndoing a lot of shinanigans. I think that would have been very useful\ninformation for the public back then. Perhaps they wouldn't have been able\nto do anything about the Fed (or maybe they would have). But people can\ncertainly pull their money out of companies that can't show solvency.\n\n> Nonsense, any business can fail, regardless of temporal cash reserves.\n\nI agree that any business can fail. But a bank that pretends it can serve\ncash on demand is not a normal business, and cash reserves absolutely\nrelate to their ability to survive as a bank. Its honestly confusing to me\nhow you could think otherwise. Also, calling my thoughts \"nonsense\" is\nrude, please check yourself, Eric.\n\n> it's hardly an improvement over holding your own keys.\n\nNo one is claiming that proof of reserves is \"an improvement\" over holding\nyour own keys. Clearly holding your own keys is ideal. However, not\neveryone is comfortable with that. The fact of the matter is that many will\nchoose a custodial wallet, for better or worse. PoR attempts to make thing\non the \"better\" side than the \"worse\" side.\n\nOn Tue, Jul 6, 2021 at 9:39 AM Erik Aronesty <erik at q32.com> wrote:\n\n> you should check out some of the earlier work done here:\n>\n> https://github.com/olalonde/proof-of-solvency#assets-proof\n>\n> to be honest, if any exchange supported that proof, it would be more\n> than enough.\n>\n> there's really no way to prevent a smash-and-grab, but this does\n> prevent a slow-leak\n>\n>\n> On Mon, Jul 5, 2021 at 5:10 PM Billy Tetrud via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >\n> > I had the idea recently for proof of reserves done in a way that can be\n> used to verify reserves are sufficient on an ongoing basis. I'm curious if\n> there are any current approaches out there to proof of reserves that are\n> similar.\n> >\n> > The idea is to have users create actual private keys using a seed in\n> pretty much the normal way. Users would generate a public key from this\n> seed to represent their account, and would give the public key to the\n> custodian to represent their account in a public record of account balances.\n> >\n> > When a user's account is credited, the custodian would update a map of\n> addresses (created from the public key of each account) to balances - this\n> map could be structured into a merkle tree in the usual \"merkle approach\".\n> The custodian would also store funds on one or more HD wallets (each with\n> many addresses) and create a proof that they own each HD wallet. The proof\n> could be as simple as a single signature created with the xpub for the\n> wallet, which would be sufficient for proving ownership over the whole\n> list/tree of addresses.\n> >\n> > These two structures (the map and the HD wallet) would be combined and\n> hashed, and the hash published in an on chain transaction (possibly along\n> with a URI where the full data can be found), on something like a daily\n> basis. Software for each user could continuously validate that their\n> account has a balance that matches what it's supposed to have, and could\n> also verify that owned addresses have funds that have at least as many\n> coins as promised to accounts. If these things aren't verifiable (either\n> because the balances total to more than the HD wallet contains, or because\n> of data unavailability), people can raise hell about it.\n> >\n> > To give user's additional proving ability, a receipt system could be\n> added. Users could request a receipt for any balance update. Eg the user\n> would create a message with a timestamp, their custodial \"address\", and the\n> new balance. The user would sign this receipt and send it to the custodian,\n> who would also sign it and send it back. This way, if something goes wrong,\n> a user can use this signed receipt to show that the custodian did in fact\n> promise a new updated balance at a particular time (which would cover the\n> case that the custodian records the wrong value in their map). Conversely,\n> the receipt would be useful to honest custodians as well, since they could\n> show the user's signed receipt request in the case a user is trying to lie\n> about what balance they should have. There is still the case that the\n> custodian simply refuses to return a signed receipt, in which case the\n> user's only recourse is to yell about it immediately and demand a receipt\n> or a refund.\n> >\n> > Why record it on chain? Doing that gives a clear record of proof of\n> reserves that can be verified later by anyone in the future. It prevents a\n> custodian from being able to change history when it suits them (by creating\n> a new records with false timestamps in the past). Many of these records\n> could be aggregated together and recorded in the same transaction (with a\n> single hash), so a single transaction per day could record the records of\n> all participating custodians. If all custodians are using a standard\n> system, one can cross verify that addresses claimed by one custodian aren't\n> also claimed by another custodian.\n> >\n> > Even tho the user is responsible for their keys in order to properly\n> verify, losing the keys isn't that big of a deal, since they could simply\n> create a new seed and give a new public key to the custodian - who would\n> have other identifying information they could use to validate that they own\n> the account. So it places less responsibility on the user, while still\n> introducing people, in a light-weight way, to self custody of keys.\n> >\n> > Having a record like this every day would reduce the possibility of\n> shenanigans like taking a short term loan of a large amount of\n> cryptocurrency. Sure, they could take a 10 minute loan once per day, but it\n> would also be possible to trace on-chain transactions so you could tell if\n> such a thing was going on. I wonder if there would be some way to include\n> the ability to prove balances held on the lightning network, but I suspect\n> that isn't generally possible.\n> >\n> > In any case, I'm curious what people think of this kind of thing, and if\n> systems with similar properties are already out there.\n> >\n> >\n> >\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210706/e5d86df3/attachment.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2021-07-09T14:55:14",
                "message_text_only": "> On Jul 7, 2021, at 01:20, Billy Tetrud via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> But people can certainly pull their money out of companies that can't show solvency. \n\nAs I pointed out previously there is an unsupportable leap being made here between a vault (money warehouse) and any company (including a bank).\n\nA company cannot possibly show that it has all of the money that every person has invested into it. At times a solvent company may even have zero cash. It is also not possible for a company provide cryptographic proof of its many necessarily non-crypto assets and liabilities. What is presumed here is a community-verified sort of crypto balance sheet, with no considerations of risk - a central aspect of business.\n\nAs I said, if you want a vault, you can just use your own wallet. Solvency does not in any way imply 100% cash balance of the amounts invested. Raising money under such terms is pointless for both company and investors (the owners of the company).\n\n> > Nonsense, any business can fail, regardless of temporal cash reserves.\n> \n> I agree that any business can fail. But a bank that pretends it can serve cash on demand is not a normal business,\n\nBanks (lending institutions) do not operate under any such pretense. US banks require 7 day time deposits for all interest bearing accounts (read your depositor agreement), and it should be clear that your uninsured balance is at risk. Banks are investment funds, not money warehouses (in Rothbard\u2019s terminology).\n\nWith a 100% of investment cash hoard, there is zero lending and zero return. This is true for all business.\n\n> and cash reserves absolutely relate to their ability to survive as a bank.\n\n\u201crelate to\u201d is a far cry from 100% \u201creserve\u201d. At 100% reserve an investment fund would most certainly fail. At 20% it would fail. Money markets (banks without a reserve requirement) don\u2019t break the buck, compete effectively with banks with reserve requirements (required by the taxpayer who is insuring deposits and providing discount credit), and maintain around 10% reserve. This is consistent with a world of people with time preference that creates around a 10% interest rate (return on investment).\n\n> Its honestly confusing to me how you could think otherwise.\n\nIt\u2019s confusing to me how anyone would put money into a business and expect (even want) it to sit there.\n\n> Also, calling my thoughts \"nonsense\" is rude, please check yourself, Eric. \n\nCheck myself? Nonsense is English for \u201cdoesn\u2019t make sense\u201d. It\u2019s not an insult.\n\ne"
            },
            {
                "author": "Billy Tetrud",
                "date": "2021-07-09T17:43:47",
                "message_text_only": ">  there is an unsupportable leap being made here\n\nYou think that because you're misinterpreting me. I'm in no way claiming\nthat any solvent company can prove it, I'm simply claiming that any company\ncan prove that they have bitcoin reserves to cover bitcoins promised as\naccount balances.\n\n> Banks (lending institutions) do not operate under any such pretense\n\nYou seem to be saying that banks are under no legal obligation to serve\ncash on demand to customers. While you might be right, again you're\nmisinterpreting me. Banks do in fact make claims to their customers that\nthey'll be able to get cash out of their account on demand. They're called\ndemand deposit accounts for a reason. And certainly customers expect to be\nable to withdraw their cash on demand.\n\n> With a 100% of investment cash hoard, there is zero lending and zero\nreturn\n\nI did say \"pretend\" did I not?\n\n> \u201crelate to\u201d is a far cry from 100% \u201creserve\u201d\n\nIndeed. Again, you seem to be misunderstanding me. You're putting the words\n\"100% reserve\" in my mouth, when I never said any such thing. Proof of\n80%/50%/20% reserves is still useful if that's the clear expectation for\nthe customer/client.\n\n> Nonsense is English for \u201cdoesn\u2019t make sense\u201d\n\nLiterally, sure. But in actual use it carries a dismissive and rude\nconnotation.\n\n\nOn Fri, Jul 9, 2021 at 7:55 AM Eric Voskuil <eric at voskuil.org> wrote:\n\n>\n> > On Jul 7, 2021, at 01:20, Billy Tetrud via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> > But people can certainly pull their money out of companies that can't\n> show solvency.\n>\n> As I pointed out previously there is an unsupportable leap being made here\n> between a vault (money warehouse) and any company (including a bank).\n>\n> A company cannot possibly show that it has all of the money that every\n> person has invested into it. At times a solvent company may even have zero\n> cash. It is also not possible for a company provide cryptographic proof of\n> its many necessarily non-crypto assets and liabilities. What is presumed\n> here is a community-verified sort of crypto balance sheet, with no\n> considerations of risk - a central aspect of business.\n>\n> As I said, if you want a vault, you can just use your own wallet. Solvency\n> does not in any way imply 100% cash balance of the amounts invested.\n> Raising money under such terms is pointless for both company and investors\n> (the owners of the company).\n>\n> > > Nonsense, any business can fail, regardless of temporal cash reserves.\n> >\n> > I agree that any business can fail. But a bank that pretends it can\n> serve cash on demand is not a normal business,\n>\n> Banks (lending institutions) do not operate under any such pretense. US\n> banks require 7 day time deposits for all interest bearing accounts (read\n> your depositor agreement), and it should be clear that your uninsured\n> balance is at risk. Banks are investment funds, not money warehouses (in\n> Rothbard\u2019s terminology).\n>\n> With a 100% of investment cash hoard, there is zero lending and zero\n> return. This is true for all business.\n>\n> > and cash reserves absolutely relate to their ability to survive as a\n> bank.\n>\n> \u201crelate to\u201d is a far cry from 100% \u201creserve\u201d. At 100% reserve an\n> investment fund would most certainly fail. At 20% it would fail. Money\n> markets (banks without a reserve requirement) don\u2019t break the buck, compete\n> effectively with banks with reserve requirements (required by the taxpayer\n> who is insuring deposits and providing discount credit), and maintain\n> around 10% reserve. This is consistent with a world of people with time\n> preference that creates around a 10% interest rate (return on investment).\n>\n> > Its honestly confusing to me how you could think otherwise.\n>\n> It\u2019s confusing to me how anyone would put money into a business and expect\n> (even want) it to sit there.\n>\n> > Also, calling my thoughts \"nonsense\" is rude, please check yourself,\n> Eric.\n>\n> Check myself? Nonsense is English for \u201cdoesn\u2019t make sense\u201d. It\u2019s not an\n> insult.\n>\n> e\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210709/52b8cdb6/attachment-0001.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2021-07-09T18:32:12",
                "message_text_only": "> On Jul 9, 2021, at 10:44, Billy Tetrud <billy.tetrud at gmail.com> wrote:\n> \n> >  there is an unsupportable leap being made here\n> \n> You think that because you're misinterpreting me. I'm in no way claiming that any solvent company can prove it, I'm simply claiming that any company can prove that they have bitcoin reserves to cover bitcoins promised as account balances. \n\nYou can prove that in your own wallet. All other scenarios imply lending (which is what is implied by \u201creserve\u201d) and lending cannot be 100% reserve.\n\n> > Banks (lending institutions) do not operate under any such pretense\n> \n> You seem to be saying that banks are under no legal obligation to serve cash on demand to customers. While you might be right,\n\nI am, as banks are lending institutions.\n\n> again you're misinterpreting me. Banks do in fact make claims to their customers that they'll be able to get cash out of their account on demand.\n\nUp to the insured limit, in 7 days. This is of course true because the taxpayer has insured the bank to that level.\n\n> They're called demand deposit accounts for a reason.\n\nThey are time deposits, read your bank agreement. Not that it makes any difference. How the contract is satisfied is not a term of the contract, just that it is. And as I pointed out, money markets have had no reserve requirement and have a nearly spotless record of satisfying their obligations.\n\n> And certainly customers expect to be able to withdraw their cash on demand. \n\nIrrelevant.\n\n> > With a 100% of investment cash hoard, there is zero lending and zero return\n> \n> I did say \"pretend\" did I not?\n\nSee above.\n\n> > \u201crelate to\u201d is a far cry from 100% \u201creserve\u201d\n> \n> Indeed. Again, you seem to be misunderstanding me. You're putting the words \"100% reserve\" in my mouth, when I never said any such thing. Proof of 80%/50%/20% reserves is still useful if that's the clear expectation for the customer/client.\n\nWithout 100% \u201creserve\u201d there is no way to cryptographically demonstrate \u201csolvency\u201d. And even with that, investors would have to accept the promise that there are no other liabilities.\n\nThe schemes don\u2019t preclude hacks, insider or otherwise, bankruptcy, or state seizure, no matter what the reserve.\n\nIt\u2019s information, sure, but it\u2019s not what people seem to think. If one wants full reserve banking, use a wallet. If one wants to invest, the money will be spent - that\u2019s why it was raised. There can be no covenant placed on it that will ensure it\u2019s return.\n\ne"
            },
            {
                "author": "Billy Tetrud",
                "date": "2021-07-09T22:02:23",
                "message_text_only": "@Voskuil\n> You can prove that in your own wallet. All other scenarios imply lending\n(which is what is implied by \u201creserve\u201d) and lending cannot be 100% reserve.\n\nYou're using terms in non-standard ways. Putting money into a bank is not\nconsidered \"lending\" to the bank. You may make a case that you're lending\nto a bank, and that they legally owe you repayment of that money on demand\nlimited by the terms you mentioned. But regardless of a case that can be\nmade there, pretty much no one considers that \"lending\". Since you you like\ndefining things legally, depositing money in a bank is legally not defined\nas lending to the bank.\n\nSo no, all other scenarios do not imply lending. You can have your coins in\ncustody with someone else, and that someone else can keep 100% reserves if\nthey choose (or agreed to) and can prove it to you via the method I\ndescribed or the methods others have linked to.\n\n> They are time deposits, read your bank agreement.\n\nYou are not correct\n<https://www.investopedia.com/terms/t/timedeposit.asp#:~:text=A%20time%20deposit%20is%20an,pre%2Dset%20date%20of%20maturity.&text=Time%20deposits%20generally%20pay%20a,of%20investment%20is%20term%20deposit.>.\nAnother source\n<https://www.slsp.sk/en/personal/faq/what-is-the-difference-between-a-term-deposit-and-savings-account>\nif you don't believe me. The only way you would be correct is if banks were\ncommitting fraud and calling something a \"savings account\" when it isn't in\nfact a savings account.\n\n> money markets have had no reserve requirement and have a nearly spotless\nrecord of satisfying their obligations.\n\nLol, money markets are so new that they've had no opportunity to show their\ntrue risk. In the finance world, things work fine for a long time until\nthey fail spectacularly, losing more than the gain they made in the first\nplace. This is a regular occurence. Its the reason bitcoin was created.\n\n> Irrelevant.\n\nIt is certainly not irrelevant. People have been lead to believe that they\ncan withdraw their money from their accounts. People expect this. Banks are\ndoing nothing to educate people on the limitations of that fact. PoR would\ngive people the ability to see quite accurately how much reserves there are\nand can use this knowledge to put pressure on institutions to keep the\nreserves those people think they should keep.\n\n> Without 100% \u201creserve\u201d there is no way to cryptographically demonstrate\n\u201csolvency\u201d.\n\nYou can show proof that you're 80% solvent, and then claim the other 20% is\nin other assets. This is, again, still useful.\n\n>The schemes don\u2019t preclude hacks, insider or otherwise, bankruptcy, or\nstate seizure, no matter what the reserve\n\nYou're right, but that's irrelevant.\n\nBut it seems like you're not interested in understanding what I'm saying or\ndiscussing these things honestly. So I'm going to end my conversation with\nyou here.\n\n\nOn Fri, Jul 9, 2021 at 11:32 AM Eric Voskuil via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> > On Jul 9, 2021, at 10:44, Billy Tetrud <billy.tetrud at gmail.com> wrote:\n> >\n> > >  there is an unsupportable leap being made here\n> >\n> > You think that because you're misinterpreting me. I'm in no way claiming\n> that any solvent company can prove it, I'm simply claiming that any company\n> can prove that they have bitcoin reserves to cover bitcoins promised as\n> account balances.\n>\n> You can prove that in your own wallet. All other scenarios imply lending\n> (which is what is implied by \u201creserve\u201d) and lending cannot be 100% reserve.\n>\n> > > Banks (lending institutions) do not operate under any such pretense\n> >\n> > You seem to be saying that banks are under no legal obligation to serve\n> cash on demand to customers. While you might be right,\n>\n> I am, as banks are lending institutions.\n>\n> > again you're misinterpreting me. Banks do in fact make claims to their\n> customers that they'll be able to get cash out of their account on demand.\n>\n> Up to the insured limit, in 7 days. This is of course true because the\n> taxpayer has insured the bank to that level.\n>\n> > They're called demand deposit accounts for a reason.\n>\n> They are time deposits, read your bank agreement. Not that it makes any\n> difference. How the contract is satisfied is not a term of the contract,\n> just that it is. And as I pointed out, money markets have had no reserve\n> requirement and have a nearly spotless record of satisfying their\n> obligations.\n>\n> > And certainly customers expect to be able to withdraw their cash on\n> demand.\n>\n> Irrelevant.\n>\n> > > With a 100% of investment cash hoard, there is zero lending and zero\n> return\n> >\n> > I did say \"pretend\" did I not?\n>\n> See above.\n>\n> > > \u201crelate to\u201d is a far cry from 100% \u201creserve\u201d\n> >\n> > Indeed. Again, you seem to be misunderstanding me. You're putting the\n> words \"100% reserve\" in my mouth, when I never said any such thing. Proof\n> of 80%/50%/20% reserves is still useful if that's the clear expectation for\n> the customer/client.\n>\n> Without 100% \u201creserve\u201d there is no way to cryptographically demonstrate\n> \u201csolvency\u201d. And even with that, investors would have to accept the promise\n> that there are no other liabilities.\n>\n> The schemes don\u2019t preclude hacks, insider or otherwise, bankruptcy, or\n> state seizure, no matter what the reserve.\n>\n> It\u2019s information, sure, but it\u2019s not what people seem to think. If one\n> wants full reserve banking, use a wallet. If one wants to invest, the money\n> will be spent - that\u2019s why it was raised. There can be no covenant placed\n> on it that will ensure it\u2019s return.\n>\n> e\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210709/35b046ea/attachment.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2021-07-09T23:18:26",
                "message_text_only": ">> You can prove that in your own wallet. All other scenarios imply lending (which is what is implied by \u201creserve\u201d) and lending cannot be 100% reserve.\n\n>You're using terms in non-standard ways. Putting money into a bank is not considered \"lending\" to the bank.\n\nWhat people consider is irrelevant, all that matters is what is correct. A bank account as you are referring to it is indistinguishable from a money market (investment) fund in all aspects but federal reserve membership and regulatory controls. Interest (and offset expenses) derives directly from their earnings on this *investment*. Describing it otherwise is either an error (leading to false conclusions) or a lie.\n\n> You may make a case that you're lending to a bank, and that they legally owe you repayment of that money on demand limited by the terms you mentioned. But regardless of a case that can be made there, pretty much no one considers that \"lending\". Since you you like defining things legally, depositing money in a bank is legally not defined as lending to the bank.\n\nPlease don\u2019t bother to try and use statue as if it was at all relevant regarding economic concepts.\n\n> So no, all other scenarios do not imply lending. You can have your coins in custody with someone else, and that someone else can keep 100% reserves if they choose (or agreed to) and can prove it to you via the method I described or the methods others have linked to. \n\nThat\u2019s what Rothbard calls a \u201cwarehouse\u201d - in order to distinguish it from investment. I\u2019ve already made this distinction. Easier to prove with your own wallet, as I said. You are conflating this with banking, which should be obvious.\n\n>> They are time deposits, read your bank agreement.\n\n> You are https://www.investopedia.com/terms/t/timedeposit.asp#:~:text=A%20time%20deposit%20is%20an,pre%2Dset%20date%20of%20maturity.&text=Time%20deposits%20generally%20pay%20a,of%20investment%20is%20term%20deposit.. https://www.slsp.sk/en/personal/faq/what-is-the-difference-between-a-term-deposit-and-savings-account if you don't believe me. The only way you would be correct is if banks were committing fraud and calling something a \"savings account\" when it isn't in fact a savings account.\n\nNo, I am not wrong. It's not a question of believing you, it's a question of understanding the concepts. You will find this language in your deposit agreement (as required by statute):\n\n\"9. Our right to require advance notice of withdrawals\nFor all savings accounts and all personal interest-bearing checking accounts, we reserve the right to require seven days\u2019 prior written notice of withdrawal.\"\nhttps://www.chase.com/content/dam/chasecom/en/checking/documents/deposit_account_agreement.pdf\n\n\"When a man deposits goods at a warehouse, he is given a receipt and pays the owner of the warehouse a certain sum for the service of storage. He still retains ownership of the property; the owner of the warehouse is simply guarding it for him. When the warehouse receipt is presented, the owner is obligated to restore the good deposited. A warehouse specializing in money is known as a \"bank.\"\"\n- Rothbard\n\nAs you can see, he is not talking about what you are talking about when it comes to colloquial use of the term \"bank\", he is clear to define what he means by \"bank\".\n\n\"Someone else's property is taken by the warehouse and used for its own money-making purposes. It is not borrowed, since no interest is paid for the use of the money.\"\n- Rothbard\n\nAny expectation of interest implies *borrowing*, in other words, a *loan* to the bank.\n\n\"Whether saved capital is channeled into investments via stocks or via loans is unimportant. The only difference is in the legal technicalities. Indeed, even the legal difference between the creditor and the owner is a negligible one.\"\n- Rothbard\n\n> You're using terms in non-standard ways. Putting money into a bank is not considered \"lending\" to the bank.\n\nI think it's quite clear that Rothbard considers it lending. I'm not big on appeal to authority, but sometimes it helps open minds. Links here:\n\nhttps://github.com/libbitcoin/libbitcoin-system/wiki/Full-Reserve-Fallacy\n\n>> money markets have had no reserve requirement and have a nearly spotless record of satisfying their obligations.\n\n> Lol, money markets are so new that they've had no opportunity to show their true risk.\n\n1971, 50 years.\nhttps://en.wikipedia.org/wiki/Money_market_fund\n\n> In the finance world, things work fine for a long time until they fail spectacularly, losing more than the gain they made in the first place. This is a regular occurence. Its the reason bitcoin was created.\n\nregular occurrence...\n\n\"Buck breaking has rarely happened. Up to the 2008 financial crisis, only three money funds had broken the buck in the 37-year history of money funds... The first money market mutual fund to break the buck was First Multifund for Daily Income (FMDI) in 1978, liquidating and restating NAV at 94 cents per share\"\n\nAn investment loss of 6%.\n\n\"The Community Bankers US Government Fund broke the buck in 1994, paying investors 96 cents per share.\"\n\nAn investment loss of 4%.\n\n\"This was only the second failure in the then 23-year history of money funds and there were no further failures for 14 years... No further failures occurred until September 2008, a month that saw tumultuous events for money funds.\"\n\nIt was a \"tumultuous\" month for nearly all investments. The feds of course doled out the pork, and the funds had to take it (as if their competition did and they didn't they would fail due to higher relative capital costs and thereby lower rates). In the past, absent pork, they had raised money where necessary to maintain their NAV (just as banks do, but they go to the taxpayer, and just as all business do from time to time).\n\nThese are remarkably stable in terms of NAV. And people seem to be satisfied with them:\n\n\"At the end of 2011, there were 632 money market funds in operation,[19] with total assets of nearly US$2.7 trillion.[19] Of this $2.7 trillion, retail money market funds had $940 billion in Assets Under Management (AUM). Institutional funds had $1.75 trillion under management.[19]\"\n\nThe point being, that this is as close to free market bank-based investing as exists in the white market. In a money market fund, the NAV is reflected in the share price, so any losses are evenly distributed - no different than when all those HODLers take a hit when Elon farts, and the reserve they maintain has been very effective in maintaining their $1/share *target* despite paying *interest* on *investments*. They are merely shifting market returns into interest, just like banks. Market returns over short periods aren't always positive. No surprise. The larger point being, BANKS ARE INVESTMENT FUNDS.\n\n>> Irrelevant.\n\n> It is certainly not irrelevant. People have been lead to believe that they can withdraw their money from their accounts. People expect this.\n\nIrrelevant, people have minds and free will and can read the contracts they are actually signing. Contracts are the *actual* Law associated with non-aggression.\n\n> Banks are doing nothing to educate people on the limitations of that fact.\n\nAgain, irrelevant. And wholly unnecessary given compulsory taxpayer deposit insurance.\n\n> PoR would give people the ability to see quite accurately how much reserves there are and can use this knowledge to put pressure on institutions to keep the reserves those people think they should keep. \n\nFor all of the reasons I've stated, it's a fairly pointless exercise, but people can do what they want. But if they are doing this with a deeply flawed understanding of banking to start with, they will be disappointed in the outcome.\n\n>> Without 100% \u201creserve\u201d there is no way to cryptographically demonstrate \u201csolvency\u201d. \n\n> You can show proof that you're 80% solvent, and then claim the other 20% is in other assets. This is, again, still useful. \n\n80% solvent ... 50% pregnant.\n\n>>The schemes don\u2019t preclude hacks, insider or otherwise, bankruptcy, or state seizure, no matter what the reserve\n\n> You're right, but that's irrelevant. \n\nI'll leave that to the reader. The alternative is to use your own wallet.\n\n> But it seems like you're not interested in understanding what I'm saying or discussing these things honestly.\n\nI'm not interested in allowing flawed concepts to be perpetuated without question. This is just a drain on capital that could be put to much better use. How many times have I heard the oxymoron \"full reserve banking\", and how much capital has been burned on this futile exercise, simply due to a failure to understand these concepts.\n\n> So I'm going to end my conversation with you here.\n\nWhile seemingly off-topic, these are things that need to be aired in this community. Thanks for the discourse.\n\ne\n\nOn Fri, Jul 9, 2021 at 11:32 AM Eric Voskuil via bitcoin-dev <mailto:bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Jul 9, 2021, at 10:44, Billy Tetrud <mailto:billy.tetrud at gmail.com> wrote:\n> \n> >  there is an unsupportable leap being made here\n> \n> You think that because you're misinterpreting me. I'm in no way claiming that any solvent company can prove it, I'm simply claiming that any company can prove that they have bitcoin reserves to cover bitcoins promised as account balances. \n\nYou can prove that in your own wallet. All other scenarios imply lending (which is what is implied by \u201creserve\u201d) and lending cannot be 100% reserve.\n\n> > Banks (lending institutions) do not operate under any such pretense\n> \n> You seem to be saying that banks are under no legal obligation to serve cash on demand to customers. While you might be right,\n\nI am, as banks are lending institutions.\n\n> again you're misinterpreting me. Banks do in fact make claims to their customers that they'll be able to get cash out of their account on demand.\n\nUp to the insured limit, in 7 days. This is of course true because the taxpayer has insured the bank to that level.\n\n> They're called demand deposit accounts for a reason.\n\nThey are time deposits, read your bank agreement. Not that it makes any difference. How the contract is satisfied is not a term of the contract, just that it is. And as I pointed out, money markets have had no reserve requirement and have a nearly spotless record of satisfying their obligations.\n\n> And certainly customers expect to be able to withdraw their cash on demand. \n\nIrrelevant.\n\n> > With a 100% of investment cash hoard, there is zero lending and zero return\n> \n> I did say \"pretend\" did I not?\n\nSee above.\n\n> > \u201crelate to\u201d is a far cry from 100% \u201creserve\u201d\n> \n> Indeed. Again, you seem to be misunderstanding me. You're putting the words \"100% reserve\" in my mouth, when I never said any such thing. Proof of 80%/50%/20% reserves is still useful if that's the clear expectation for the customer/client.\n\nWithout 100% \u201creserve\u201d there is no way to cryptographically demonstrate \u201csolvency\u201d. And even with that, investors would have to accept the promise that there are no other liabilities.\n\nThe schemes don\u2019t preclude hacks, insider or otherwise, bankruptcy, or state seizure, no matter what the reserve.\n\nIt\u2019s information, sure, but it\u2019s not what people seem to think. If one wants full reserve banking, use a wallet. If one wants to invest, the money will be spent - that\u2019s why it was raised. There can be no covenant placed on it that will ensure it\u2019s return.\n\ne\n_______________________________________________\nbitcoin-dev mailing list\nmailto:bitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-07-09T23:50:45",
                "message_text_only": "Good morning e,\n\n\n>     Any expectation of interest implies borrowing, in other words, a loan to the bank.\n\nPerhaps this is the key point of contention?\n\nIn cases where Bitcoin is given over to an exchange, there is no expectation of interest, at least in the sense that there is no expectation that the number of Bitcoins deposited in the exchange *increase* over time.\n(There may be an expectation of an increase in the number of green-ink historical commemoration papers it can buy, but the point is that the number of Bitcoins held in behalf of the user is not expected to change)\n\nThe expectation is that exchanges earn money from the difference between buy-price and sell-price, and the money-warehousing service they provide is simply provided for free to facilitate their *main* business (i.e. brokers for *exchange*).\nThus, the expectation is that the exchange provides a warehouse service, not a bank service, and this service is provided for free since it enables their *real* business of earning from bid-ask spreads.\n\nOn the other hand, not your keys not your coins, so anyone who uses such a warehouse has whatever happens to the funds coming for them...\n\nAnd of course exchanges need not earn money *just* from bid-ask spreads *in practice*, so they are unlikely to provide proof-of-reserves either.\n\nIndeed, money warehousing may very well be provided by means other than proof-of-reserves, such as by using multisig the way Green wallet does, with better security.\nPerhaps \"pure exchanges\" would be more amenable to such a scheme rather than proof-of-reserves.\n\nRegards,\nZmnSCPxj\n\n>\n>     \"Whether saved capital is channeled into investments via stocks or via loans is unimportant. The only difference is in the legal technicalities. Indeed, even the legal difference between the creditor and the owner is a negligible one.\"\n>\n> -   Rothbard\n>\n> > You're using terms in non-standard ways. Putting money into a bank is not considered \"lending\" to the bank.\n>\n> I think it's quite clear that Rothbard considers it lending. I'm not big on appeal to authority, but sometimes it helps open minds. Links here:\n>\n> https://github.com/libbitcoin/libbitcoin-system/wiki/Full-Reserve-Fallacy\n>\n> > > money markets have had no reserve requirement and have a nearly spotless record of satisfying their obligations.\n>\n> > Lol, money markets are so new that they've had no opportunity to show their true risk.\n>\n> 1971, 50 years.\n> https://en.wikipedia.org/wiki/Money_market_fund\n>\n> > In the finance world, things work fine for a long time until they fail spectacularly, losing more than the gain they made in the first place. This is a regular occurence. Its the reason bitcoin was created.\n>\n> regular occurrence...\n>\n> \"Buck breaking has rarely happened. Up to the 2008 financial crisis, only three money funds had broken the buck in the 37-year history of money funds... The first money market mutual fund to break the buck was First Multifund for Daily Income (FMDI) in 1978, liquidating and restating NAV at 94 cents per share\"\n>\n> An investment loss of 6%.\n>\n> \"The Community Bankers US Government Fund broke the buck in 1994, paying investors 96 cents per share.\"\n>\n> An investment loss of 4%.\n>\n> \"This was only the second failure in the then 23-year history of money funds and there were no further failures for 14 years... No further failures occurred until September 2008, a month that saw tumultuous events for money funds.\"\n>\n> It was a \"tumultuous\" month for nearly all investments. The feds of course doled out the pork, and the funds had to take it (as if their competition did and they didn't they would fail due to higher relative capital costs and thereby lower rates). In the past, absent pork, they had raised money where necessary to maintain their NAV (just as banks do, but they go to the taxpayer, and just as all business do from time to time).\n>\n> These are remarkably stable in terms of NAV. And people seem to be satisfied with them:\n>\n> \"At the end of 2011, there were 632 money market funds in operation,[19] with total assets of nearly US$2.7 trillion.[19] Of this $2.7 trillion, retail money market funds had $940 billion in Assets Under Management (AUM). Institutional funds had $1.75 trillion under management.[19]\"\n>\n> The point being, that this is as close to free market bank-based investing as exists in the white market. In a money market fund, the NAV is reflected in the share price, so any losses are evenly distributed - no different than when all those HODLers take a hit when Elon farts, and the reserve they maintain has been very effective in maintaining their $1/share target despite paying interest on investments. They are merely shifting market returns into interest, just like banks. Market returns over short periods aren't always positive. No surprise. The larger point being, BANKS ARE INVESTMENT FUNDS.\n>\n> > > Irrelevant.\n>\n> > It is certainly not irrelevant. People have been lead to believe that they can withdraw their money from their accounts. People expect this.\n>\n> Irrelevant, people have minds and free will and can read the contracts they are actually signing. Contracts are theactual Law associated with non-aggression.\n>\n> > Banks are doing nothing to educate people on the limitations of that fact.\n>\n> Again, irrelevant. And wholly unnecessary given compulsory taxpayer deposit insurance.\n>\n> > PoR would give people the ability to see quite accurately how much reserves there are and can use this knowledge to put pressure on institutions to keep the reserves those people think they should keep.\n>\n> For all of the reasons I've stated, it's a fairly pointless exercise, but people can do what they want. But if they are doing this with a deeply flawed understanding of banking to start with, they will be disappointed in the outcome.\n>\n> > > Without 100% \u201creserve\u201d there is no way to cryptographically demonstrate \u201csolvency\u201d.\n>\n> > You can show proof that you're 80% solvent, and then claim the other 20% is in other assets. This is, again, still useful.\n>\n> 80% solvent ... 50% pregnant.\n>\n> > > The schemes don\u2019t preclude hacks, insider or otherwise, bankruptcy, or state seizure, no matter what the reserve\n>\n> > You're right, but that's irrelevant.\n>\n> I'll leave that to the reader. The alternative is to use your own wallet.\n>\n> > But it seems like you're not interested in understanding what I'm saying or discussing these things honestly.\n>\n> I'm not interested in allowing flawed concepts to be perpetuated without question. This is just a drain on capital that could be put to much better use. How many times have I heard the oxymoron \"full reserve banking\", and how much capital has been burned on this futile exercise, simply due to a failure to understand these concepts.\n>\n> > So I'm going to end my conversation with you here.\n>\n> While seemingly off-topic, these are things that need to be aired in this community. Thanks for the discourse.\n>\n> e\n>\n> On Fri, Jul 9, 2021 at 11:32 AM Eric Voskuil via bitcoin-dev mailto:bitcoin-dev at lists.linuxfoundation.org wrote:\n>\n> > On Jul 9, 2021, at 10:44, Billy Tetrud mailto:billy.tetrud at gmail.com wrote:\n> >\n> > > there is an unsupportable leap being made here\n> >\n> > You think that because you're misinterpreting me. I'm in no way claiming that any solvent company can prove it, I'm simply claiming that any company can prove that they have bitcoin reserves to cover bitcoins promised as account balances.\n>\n> You can prove that in your own wallet. All other scenarios imply lending (which is what is implied by \u201creserve\u201d) and lending cannot be 100% reserve.\n>\n> > > Banks (lending institutions) do not operate under any such pretense\n> >\n> > You seem to be saying that banks are under no legal obligation to serve cash on demand to customers. While you might be right,\n>\n> I am, as banks are lending institutions.\n>\n> > again you're misinterpreting me. Banks do in fact make claims to their customers that they'll be able to get cash out of their account on demand.\n>\n> Up to the insured limit, in 7 days. This is of course true because the taxpayer has insured the bank to that level.\n>\n> > They're called demand deposit accounts for a reason.\n>\n> They are time deposits, read your bank agreement. Not that it makes any difference. How the contract is satisfied is not a term of the contract, just that it is. And as I pointed out, money markets have had no reserve requirement and have a nearly spotless record of satisfying their obligations.\n>\n> > And certainly customers expect to be able to withdraw their cash on demand.\n>\n> Irrelevant.\n>\n> > > With a 100% of investment cash hoard, there is zero lending and zero return\n> >\n> > I did say \"pretend\" did I not?\n>\n> See above.\n>\n> > > \u201crelate to\u201d is a far cry from 100% \u201creserve\u201d\n> >\n> > Indeed. Again, you seem to be misunderstanding me. You're putting the words \"100% reserve\" in my mouth, when I never said any such thing. Proof of 80%/50%/20% reserves is still useful if that's the clear expectation for the customer/client.\n>\n> Without 100% \u201creserve\u201d there is no way to cryptographically demonstrate \u201csolvency\u201d. And even with that, investors would have to accept the promise that there are no other liabilities.\n>\n> The schemes don\u2019t preclude hacks, insider or otherwise, bankruptcy, or state seizure, no matter what the reserve.\n>\n> It\u2019s information, sure, but it\u2019s not what people seem to think. If one wants full reserve banking, use a wallet. If one wants to invest, the money will be spent - that\u2019s why it was raised. There can be no covenant placed on it that will ensure it\u2019s return.\n>\n> e\n>\n> bitcoin-dev mailing list\n> mailto:bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "eric at voskuil.org",
                "date": "2021-07-10T00:49:52",
                "message_text_only": "> Good morning e,\n\nGood afternoon Z.\n\n> >     Any expectation of interest implies borrowing, in other words, a loan to\n> the bank.\n> \n> Perhaps this is the key point of contention?\n\nI'm not sure, but from my observations it's long been a point of confusion in Bitcoiner understanding of banking.\n\nTo put a finer point on it, Rothbard's criteria is a vague in a couple ways. Earnings that offset fees are also \"interest\" in the economic context - in which he writes. So even a zero-interest account (or negative up to the full cost of maintaining the account) qualifies under this criterion. Yet he is careful to say \"implies\". The arrangement may of course be explicit, in which case one no longer relies on implied contract, one relies on explicit contract. Finally, one may \"expect\" no interest, and even pay fees, but it may nonetheless be a loan. This is what contracts are for.\n\nIf one contracts for warehousing service, such Safe Deposit, as opposed to a time deposit, such as Certificate of Deposit, Savings Account, or Checking Account, then one gets a warehousing service - full fees and a contractual obligation to maintain 100% of the deposit. There are also money transmission services that move money around for a fee. The inability to distinguish money from credit (including money substitutes) and warehousing from investment (including \"banking\") leads directly to false conclusions regarding money and banking. Unfortunately a good number of self-described \"Austrians\" perpetuate these errors.\n\n> In cases where Bitcoin is given over to an exchange, there is no expectation\n> of interest, at least in the sense that there is no expectation that the number\n> of Bitcoins deposited in the exchange *increase* over time.\n> (There may be an expectation of an increase in the number of green-ink\n> historical commemoration papers it can buy, but the point is that the number\n> of Bitcoins held in behalf of the user is not expected to change)\n> \n> The expectation is that exchanges earn money from the difference between\n> buy-price and sell-price, and the money-warehousing service they provide is\n> simply provided for free to facilitate their *main* business (i.e. brokers for\n> *exchange*).\n> Thus, the expectation is that the exchange provides a warehouse service,\n> not a bank service, and this service is provided for free since it enables their\n> *real* business of earning from bid-ask spreads.\n\nI'm not aware of what are people's expectations, nor would I judge what qualifies as someone's \"real\" business, but a warehouse that facilitates trades for a fee is of course a possible business model. PayPal's intended (real?) business model was to earn from the float. That didn't pan out, because people didn't retain money in their transmitter service. \n\nExchanges that deal in monopoly money must move this through traditional finance. This incurs all manner of risk. When someone sends them monopoly money, there is no crypto-surety possible. This is part of their \"reserve\" just as is the other side of trades.\n\nWhat matters is what people contract for - agree to, voluntarily.\n\n> On the other hand, not your keys not your coins, so anyone who uses such a\n> warehouse has whatever happens to the funds coming for them...\n\nOne of the essential benefits of Bitcoin being that you can be your own warehouse, and be your own money transmitter.\n\nBut all production requires investment, which inherently entails letting go of your money, producing something with it, and selling it to people for other money. All investment is from someone's \"reserve\". Full reserve investment (including banking) is an oxymoron. So whether through exchanges or otherwise, there will be production, risk, loss and earnings. Otherwise there will be nothing at all to buy, and all money will be worthless. This idea of assuring that money is fully reserved applies only to that which one does not invest (one's hoard); it does not apply to banks, or the capital of any other companies. If it can help people feel better about their Safe Deposit (warehousing), I'm all for it. But if one wants a 20% bitcoin reserve, one can certainly place 20% into cold storage.\n\n> And of course exchanges need not earn money *just* from bid-ask spreads\n> *in practice*, so they are unlikely to provide proof-of-reserves either.\n\nIf they did not earn money as a bank, the explicit cost of their services would be that much higher. Which people prefer is of course entirely up to them. I don't know which is more likely.\n\n> Indeed, money warehousing may very well be provided by means other than\n> proof-of-reserves, such as by using multisig the way Green wallet does, with\n> better security.\n\nRight, this is an aspect of using your own wallet.\n\n> Perhaps \"pure exchanges\" would be more amenable to such a scheme\n> rather than proof-of-reserves.\n\nOr simply pairing traders, which is of course an existing model.\n\nBest,\ne\n\n> Regards,\n> ZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-07-10T01:26:14",
                "message_text_only": "Good morning e,\n\nOkay, it seems to me that what you are saying is something like this:\n\n> Proof-of-reserves would (partially) work for a \"pure\" warehousing service (i.e. user pays some fee, service keeps money and provides proofs that money is kept).\n> However, \"pure\" warehousing is not what a typical exchange does (else the explicit fees in their exchanges would be higher), as it takes on risk due to having to deal with non-Bitcoin monopoly money (by definition, since they are *exchanges*).\n> Further, with Bitcoin you can be your own warehouse (including Green-like multisig schemes where you own your own keys that are part of the scheme), which is an alternative choice to hiring a \"pure warehouse\" (i.e. Safe Deposit).\n\nWould that be a fair (if somewhat rough and undetailed) restatement?\n\nRegards,\nZmnSCPxj\n\n> > Good morning e,\n>\n> Good afternoon Z.\n>\n> > >     Any expectation of interest implies borrowing, in other words, a loan to\n> > >\n> >\n> > the bank.\n> > Perhaps this is the key point of contention?\n>\n> I'm not sure, but from my observations it's long been a point of confusion in Bitcoiner understanding of banking.\n>\n> To put a finer point on it, Rothbard's criteria is a vague in a couple ways. Earnings that offset fees are also \"interest\" in the economic context - in which he writes. So even a zero-interest account (or negative up to the full cost of maintaining the account) qualifies under this criterion. Yet he is careful to say \"implies\". The arrangement may of course be explicit, in which case one no longer relies on implied contract, one relies on explicit contract. Finally, one may \"expect\" no interest, and even pay fees, but it may nonetheless be a loan. This is what contracts are for.\n>\n> If one contracts for warehousing service, such Safe Deposit, as opposed to a time deposit, such as Certificate of Deposit, Savings Account, or Checking Account, then one gets a warehousing service - full fees and a contractual obligation to maintain 100% of the deposit. There are also money transmission services that move money around for a fee. The inability to distinguish money from credit (including money substitutes) and warehousing from investment (including \"banking\") leads directly to false conclusions regarding money and banking. Unfortunately a good number of self-described \"Austrians\" perpetuate these errors.\n>\n> > In cases where Bitcoin is given over to an exchange, there is no expectation\n> > of interest, at least in the sense that there is no expectation that the number\n> > of Bitcoins deposited in the exchange increase over time.\n> > (There may be an expectation of an increase in the number of green-ink\n> > historical commemoration papers it can buy, but the point is that the number\n> > of Bitcoins held in behalf of the user is not expected to change)\n> > The expectation is that exchanges earn money from the difference between\n> > buy-price and sell-price, and the money-warehousing service they provide is\n> > simply provided for free to facilitate their main business (i.e. brokers for\n> > exchange).\n> > Thus, the expectation is that the exchange provides a warehouse service,\n> > not a bank service, and this service is provided for free since it enables their\n> > real business of earning from bid-ask spreads.\n>\n> I'm not aware of what are people's expectations, nor would I judge what qualifies as someone's \"real\" business, but a warehouse that facilitates trades for a fee is of course a possible business model. PayPal's intended (real?) business model was to earn from the float. That didn't pan out, because people didn't retain money in their transmitter service.\n>\n> Exchanges that deal in monopoly money must move this through traditional finance. This incurs all manner of risk. When someone sends them monopoly money, there is no crypto-surety possible. This is part of their \"reserve\" just as is the other side of trades.\n>\n> What matters is what people contract for - agree to, voluntarily.\n>\n> > On the other hand, not your keys not your coins, so anyone who uses such a\n> > warehouse has whatever happens to the funds coming for them...\n>\n> One of the essential benefits of Bitcoin being that you can be your own warehouse, and be your own money transmitter.\n>\n> But all production requires investment, which inherently entails letting go of your money, producing something with it, and selling it to people for other money. All investment is from someone's \"reserve\". Full reserve investment (including banking) is an oxymoron. So whether through exchanges or otherwise, there will be production, risk, loss and earnings. Otherwise there will be nothing at all to buy, and all money will be worthless. This idea of assuring that money is fully reserved applies only to that which one does not invest (one's hoard); it does not apply to banks, or the capital of any other companies. If it can help people feel better about their Safe Deposit (warehousing), I'm all for it. But if one wants a 20% bitcoin reserve, one can certainly place 20% into cold storage.\n>\n> > And of course exchanges need not earn money just from bid-ask spreads\n> > in practice, so they are unlikely to provide proof-of-reserves either.\n>\n> If they did not earn money as a bank, the explicit cost of their services would be that much higher. Which people prefer is of course entirely up to them. I don't know which is more likely.\n>\n> > Indeed, money warehousing may very well be provided by means other than\n> > proof-of-reserves, such as by using multisig the way Green wallet does, with\n> > better security.\n>\n> Right, this is an aspect of using your own wallet.\n>\n> > Perhaps \"pure exchanges\" would be more amenable to such a scheme\n> > rather than proof-of-reserves.\n>\n> Or simply pairing traders, which is of course an existing model.\n>\n> Best,\n> e\n>\n> > Regards,\n> > ZmnSCPxj"
            },
            {
                "author": "eric at voskuil.org",
                "date": "2021-07-10T01:49:37",
                "message_text_only": "All reasonable.\n\ne\n\n> Okay, it seems to me that what you are saying is something like this:\n> \n> > Proof-of-reserves would (partially) work for a \"pure\" warehousing service\n> (i.e. user pays some fee, service keeps money and provides proofs that\n> money is kept).\n> > However, \"pure\" warehousing is not what a typical exchange does (else\n> the explicit fees in their exchanges would be higher), as it takes on risk due\n> to having to deal with non-Bitcoin monopoly money (by definition, since they\n> are *exchanges*).\n> > Further, with Bitcoin you can be your own warehouse (including Green-like\n> multisig schemes where you own your own keys that are part of the\n> scheme), which is an alternative choice to hiring a \"pure warehouse\" (i.e.\n> Safe Deposit).\n> \n> Would that be a fair (if somewhat rough and undetailed) restatement?\n> \n> Regards,\n> ZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Proof of reserves - recording",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Eric Voskuil",
                "eric at voskuil.org",
                "ZmnSCPxj",
                "Erik Aronesty",
                "Billy Tetrud"
            ],
            "messages_count": 21,
            "total_messages_chars_count": 116604
        }
    },
    {
        "title": "[bitcoin-dev] OP_CAT Makes Bitcoin Quantum Secure [was CheckSigFromStack for Arithmetic Values]",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2021-07-07T05:58:15",
                "message_text_only": "Dear Bitcoin Devs,\n\nAs mentioned previously, OP_CAT (or similar operation) can be used to make\nBitcoin \"quantum safe\" by signing an EC signature. This should work in both\nSegwit V0 and Tapscript, although you have to use HASH160 for it to fit in\nSegwit V0.\n\nSee [my blog](https://rubin.io/blog/2021/07/06/quantum-bitcoin/) for the\nspecific construction, reproduced below.\n\nYet another entry to the \"OP_CAT can do that too\" list.\n\nBest,\n\nJeremy\n-----\n\n\nI recently published [a blog\npost](https://rubin.io/blog/2021/07/02/signing-5-bytes/) about signing up\nto a\n5 byte value using Bitcoin script arithmetic and Lamport signatures.\n\nBy itself, this is neat, but a little limited. What if we could sign longer\nmessages? If we can sign up to 20 bytes, we could sign a HASH160 digest\nwhich\nis most likely quantum safe...\n\nWhat would it mean if we signed the HASH160 digest of a signature? What the\nwhat? Why would we do that?\n\nWell, as it turns out, even if a quantum computer were able to crack ECDSA,\nit\nwould yield revealing the private key but not the ability to malleate the\ncontent of what was actually signed.  I asked my good friend and\ncryptographer\n[Madars Virza](https://madars.org/) if my intuition was correct, and he\nconfirmed that it should be sufficient, but it's definitely worth closer\nanalysis before relying on this. While the ECDSA signature can be malleated\nto a\ndifferent, negative form, if the signature is otherwise made immalleable\nthere\nshould only be one value the commitment can be opened to.\n\nIf we required the ECDSA signature be signed with a quantum proof signature\nalgorithm, then we'd have a quantum proof Bitcoin! And the 5 byte signing\nscheme\nwe discussed previously is a Lamport signature, which is quantum secure.\nUnfortunately, we need at least 20 contiguous bytes... so we need some sort\nof\nOP\\_CAT like operation.\n\nOP\\_CAT can't be directly soft forked to Segwit v0 because it modifies the\nstack, so instead we'll (for simplicity) also show how to use a new opcode\nthat\nuses verify semantics, OP\\_SUBSTRINGEQUALVERIFY that checks a splice of a\nstring\nfor equality.\n\n```\n... FOR j in 0..=5\n    <0>\n    ... FOR i in 0..=31\n        SWAP hash160 DUP <H(K_j_i_1)> EQUAL IF DROP <2**i> ADD ELSE\n<H(K_j_i_0)> EQUALVERIFY ENDIF\n    ... END FOR\n    TOALTSTACK\n... END FOR\n\nDUP HASH160\n\n... IF CAT AVAILABLE\n    FROMALTSTACK\n    ... FOR j in 0..=5\n        FROMALTSTACK\n        CAT\n    ... END FOR\n    EQUALVERIFY\n... ELSE SUBSTRINGEQUALVERIFY AVAILABLE\n    ... FOR j in 0..=5\n        FROMALTSTACK <0+j*4> <4+j*4> SUBSTRINGEQUALVERIFY DROP DROP DROP\n    ...  END FOR\n    DROP\n... END IF\n\n<pk> CHECKSIG\n```\n\nThat's a long script... but will it fit? We need to verify 20 bytes of\nmessage\neach bit takes around 10 bytes script, an average of 3.375 bytes per number\n(counting pushes), and two 21 bytes keys = 55.375 bytes of program space\nand 21\nbytes of witness element per bit.\n\nIt fits! `20*8*55.375 = 8860`, which leaves 1140 bytes less than the limit\nfor\nthe rest of the logic, which is plenty (around 15-40 bytes required for the\nrest\nof the logic, leaving 1100 free for custom signature checking). The stack\nsize\nis 160 elements for the hash gadget, 3360 bytes.\n\nThis can probably be made a bit more efficient by expanding to a ternary\nrepresentation.\n\n```\n        SWAP hash160 DUP <H(K_j_i_0)> EQUAL  IF DROP  ELSE <3**i> SWAP DUP\n<H(K_j_i_T)> EQUAL IF DROP SUB ELSE <H(K_j_i_1)> EQUALVERIFY ADD  ENDIF\nENDIF\n```\n\nThis should bring it up to roughly 85 bytes per trit, and there should be\n101\ntrits (`log(2**160)/log(3) == 100.94`), so about 8560 bytes... a bit\ncheaper!\nBut the witness stack is \"only\" `2121` bytes...\n\nAs a homework exercise, maybe someone can prove the optimal choice of radix\nfor\nthis protocol... My guess is that base 4 is optimal!\n\n## Taproot?\n\nWhat about Taproot? As far as I'm aware the commitment scheme (`Q = pG +\nhash(pG\n|| m)G`) can be securely opened to m even with a quantum computer (finding\n`q`\nsuch that `qG = Q` might be trivial, but suppose key path was disabled, then\nfinding m and p such that the taproot equation holds should be difficult\nbecause\nof the hash, but I'd need to certify that claim better).  Therefore this\nscript can nest inside of a Tapscript path -- Tapscript also does not\nimpose a\nlength limit, 32 byte hashes could be used as well.\n\nFurther, to make keys reusable, there could be many Lamport keys comitted\ninside\na taproot tree so that an address could be used for thousands of times\nbefore\nexpiring. This could be used as a measure to protect accidental use rather\nthan\nto support it.\n\nLastly, Schnorr actually has a stronger non-malleability property than\nECDSA,\nthe signatures will be binding to the approved transaction and once Lamport\nsigned, even a quantum computer could not steal the funds.\n\n\n\n\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210706/3942eac0/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-07-08T08:12:01",
                "message_text_only": "Good morning Jeremy,\n\nYes, quite neat indeed, too bad Lamport signatures are so huge (a couple kilobytes)... blocksize increase *cough*\n\nSince a quantum computer can derive the EC privkey from the EC pubkey and this scheme is resistant to that, I think you can use a single well-known EC privkey, you just need a unique Lamport keypair for each UTXO (uniqueness being mandatory due to Lamport requiring preimage revelation).\n\nRegards,\nZmnSCPxj\n\n\n> Dear Bitcoin Devs,\n>\n> As mentioned previously, OP_CAT (or similar operation) can be used to make Bitcoin \"quantum safe\" by signing an EC signature. This should work in both Segwit V0 and Tapscript, although you have to use HASH160 for it to fit in Segwit V0.\n>\n> See [my blog](https://rubin.io/blog/2021/07/06/quantum-bitcoin/) for the specific construction, reproduced below.\n>\n> Yet another entry to the \"OP_CAT can do that too\" list.\n>\n> Best,\n>\n> Jeremy\n> -----\n>\n> I recently published [a blog\n> post](https://rubin.io/blog/2021/07/02/signing-5-bytes/) about signing up to a\n> 5 byte value using Bitcoin script arithmetic and Lamport signatures.\n>\n> By itself, this is neat, but a little limited. What if we could sign longer\n> messages? If we can sign up to 20 bytes, we could sign a HASH160 digest which\n> is most likely quantum safe...\n>\n> What would it mean if we signed the HASH160 digest of a signature? What the\n> what? Why would we do that?\n>\n> Well, as it turns out, even if a quantum computer were able to crack ECDSA, it\n> would yield revealing the private key but not the ability to malleate the\n> content of what was actually signed.\u00a0 I asked my good friend and cryptographer\n> [Madars Virza](https://madars.org/) if my intuition was correct, and he\n> confirmed that it should be sufficient, but it's definitely worth closer\n> analysis before relying on this. While the ECDSA signature can be malleated to a\n> different, negative form, if the signature is otherwise made immalleable there\n> should only be one value the commitment can be opened to.\n>\n> If we required the ECDSA signature be signed with a quantum proof signature\n> algorithm, then we'd have a quantum proof Bitcoin! And the 5 byte signing scheme\n> we discussed previously is a Lamport signature, which is quantum secure.\n> Unfortunately, we need at least 20 contiguous bytes... so we need some sort of\n> OP\\_CAT like operation.\n>\n> OP\\_CAT can't be directly soft forked to Segwit v0 because it modifies the\n> stack, so instead we'll (for simplicity) also show how to use a new opcode that\n> uses verify semantics, OP\\_SUBSTRINGEQUALVERIFY that checks a splice of a string\n> for equality.\n>\n> ```\n> ... FOR j in 0..=5\n> \u00a0 \u00a0 <0>\n> \u00a0 \u00a0 ... FOR i in 0..=31\n> \u00a0 \u00a0 \u00a0 \u00a0 SWAP hash160 DUP <H(K_j_i_1)> EQUAL IF DROP <2**i> ADD ELSE <H(K_j_i_0)> EQUALVERIFY ENDIF\n> \u00a0 \u00a0 ... END FOR\n> \u00a0 \u00a0 TOALTSTACK\n> ... END FOR\n>\n> DUP HASH160\n>\n> ... IF CAT AVAILABLE\n> \u00a0 \u00a0 FROMALTSTACK\n> \u00a0 \u00a0 ... FOR j in 0..=5\n> \u00a0 \u00a0 \u00a0 \u00a0 FROMALTSTACK\n> \u00a0 \u00a0 \u00a0 \u00a0 CAT\n> \u00a0 \u00a0 ... END FOR\n> \u00a0 \u00a0 EQUALVERIFY\n> ... ELSE SUBSTRINGEQUALVERIFY AVAILABLE\n> \u00a0 \u00a0 ... FOR j in 0..=5\n> \u00a0 \u00a0 \u00a0 \u00a0 FROMALTSTACK <0+j*4> <4+j*4> SUBSTRINGEQUALVERIFY DROP DROP DROP\n> \u00a0 \u00a0 ...\u00a0 END FOR\n> \u00a0 \u00a0 DROP\n> ... END IF\n>\n> <pk> CHECKSIG\n> ```\n>\n> That's a long script... but will it fit? We need to verify 20 bytes of message\n> each bit takes around 10 bytes script, an average of 3.375 bytes per number\n> (counting pushes), and two 21 bytes keys = 55.375 bytes of program space and 21\n> bytes of witness element per bit.\n>\n> It fits! `20*8*55.375 = 8860`, which leaves 1140 bytes less than the limit for\n> the rest of the logic, which is plenty (around 15-40 bytes required for the rest\n> of the logic, leaving 1100 free for custom signature checking). The stack size\n> is 160 elements for the hash gadget, 3360 bytes.\n>\n> This can probably be made a bit more efficient by expanding to a ternary\n> representation.\n>\n> ```\n> \u00a0 \u00a0 \u00a0 \u00a0 SWAP hash160 DUP <H(K_j_i_0)> EQUAL \u00a0IF DROP \u00a0ELSE <3**i> SWAP DUP <H(K_j_i_T)> EQUAL IF DROP SUB ELSE <H(K_j_i_1)> EQUALVERIFY ADD \u00a0ENDIF ENDIF\n> ```\n>\n> This should bring it up to roughly 85 bytes per trit, and there should be 101\n> trits (`log(2**160)/log(3) == 100.94`), so about 8560 bytes... a bit cheaper!\n> But the witness stack is \"only\" `2121` bytes...\n>\n> As a homework exercise, maybe someone can prove the optimal choice of radix for\n> this protocol... My guess is that base 4 is optimal!\n>\n> ## Taproot?\n>\n> What about Taproot? As far as I'm aware the commitment scheme (`Q = pG + hash(pG\n> || m)G`) can be securely opened to m even with a quantum computer (finding `q`\n> such that `qG = Q` might be trivial, but suppose key path was disabled, then\n> finding m and p such that the taproot equation holds should be difficult because\n> of the hash, but I'd need to certify that claim better).\u00a0 Therefore this\n> script can nest inside of a Tapscript path -- Tapscript also does not impose a\n> length limit, 32 byte hashes could be used as well.\n>\n> Further, to make keys reusable, there could be many Lamport keys comitted inside\n> a taproot tree so that an address could be used for thousands of times before\n> expiring. This could be used as a measure to protect accidental use rather than\n> to support it.\n>\n> Lastly, Schnorr actually has a stronger non-malleability property than ECDSA,\n> the signatures will be binding to the approved transaction and once Lamport\n> signed, even a quantum computer could not steal the funds.\n>\n> --\n> @JeremyRubin"
            },
            {
                "author": "Ethan Heilman",
                "date": "2021-07-09T19:02:15",
                "message_text_only": ">Yes, quite neat indeed, too bad Lamport signatures are so huge (a couple kilobytes)... blocksize increase *cough*\n\nCouldn't you significantly compress the signatures by using either\nWinternitz OTS or by using OP_CAT to build a merkle tree so that the\nfull signature can be derived during script execution from a much\nshorter set of seed values?\n\nOn Thu, Jul 8, 2021 at 4:12 AM ZmnSCPxj via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>\n> Good morning Jeremy,\n>\n> Yes, quite neat indeed, too bad Lamport signatures are so huge (a couple kilobytes)... blocksize increase *cough*\n>\n> Since a quantum computer can derive the EC privkey from the EC pubkey and this scheme is resistant to that, I think you can use a single well-known EC privkey, you just need a unique Lamport keypair for each UTXO (uniqueness being mandatory due to Lamport requiring preimage revelation).\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> > Dear Bitcoin Devs,\n> >\n> > As mentioned previously, OP_CAT (or similar operation) can be used to make Bitcoin \"quantum safe\" by signing an EC signature. This should work in both Segwit V0 and Tapscript, although you have to use HASH160 for it to fit in Segwit V0.\n> >\n> > See [my blog](https://rubin.io/blog/2021/07/06/quantum-bitcoin/) for the specific construction, reproduced below.\n> >\n> > Yet another entry to the \"OP_CAT can do that too\" list.\n> >\n> > Best,\n> >\n> > Jeremy\n> > -----\n> >\n> > I recently published [a blog\n> > post](https://rubin.io/blog/2021/07/02/signing-5-bytes/) about signing up to a\n> > 5 byte value using Bitcoin script arithmetic and Lamport signatures.\n> >\n> > By itself, this is neat, but a little limited. What if we could sign longer\n> > messages? If we can sign up to 20 bytes, we could sign a HASH160 digest which\n> > is most likely quantum safe...\n> >\n> > What would it mean if we signed the HASH160 digest of a signature? What the\n> > what? Why would we do that?\n> >\n> > Well, as it turns out, even if a quantum computer were able to crack ECDSA, it\n> > would yield revealing the private key but not the ability to malleate the\n> > content of what was actually signed.  I asked my good friend and cryptographer\n> > [Madars Virza](https://madars.org/) if my intuition was correct, and he\n> > confirmed that it should be sufficient, but it's definitely worth closer\n> > analysis before relying on this. While the ECDSA signature can be malleated to a\n> > different, negative form, if the signature is otherwise made immalleable there\n> > should only be one value the commitment can be opened to.\n> >\n> > If we required the ECDSA signature be signed with a quantum proof signature\n> > algorithm, then we'd have a quantum proof Bitcoin! And the 5 byte signing scheme\n> > we discussed previously is a Lamport signature, which is quantum secure.\n> > Unfortunately, we need at least 20 contiguous bytes... so we need some sort of\n> > OP\\_CAT like operation.\n> >\n> > OP\\_CAT can't be directly soft forked to Segwit v0 because it modifies the\n> > stack, so instead we'll (for simplicity) also show how to use a new opcode that\n> > uses verify semantics, OP\\_SUBSTRINGEQUALVERIFY that checks a splice of a string\n> > for equality.\n> >\n> > ```\n> > ... FOR j in 0..=5\n> >     <0>\n> >     ... FOR i in 0..=31\n> >         SWAP hash160 DUP <H(K_j_i_1)> EQUAL IF DROP <2**i> ADD ELSE <H(K_j_i_0)> EQUALVERIFY ENDIF\n> >     ... END FOR\n> >     TOALTSTACK\n> > ... END FOR\n> >\n> > DUP HASH160\n> >\n> > ... IF CAT AVAILABLE\n> >     FROMALTSTACK\n> >     ... FOR j in 0..=5\n> >         FROMALTSTACK\n> >         CAT\n> >     ... END FOR\n> >     EQUALVERIFY\n> > ... ELSE SUBSTRINGEQUALVERIFY AVAILABLE\n> >     ... FOR j in 0..=5\n> >         FROMALTSTACK <0+j*4> <4+j*4> SUBSTRINGEQUALVERIFY DROP DROP DROP\n> >     ...  END FOR\n> >     DROP\n> > ... END IF\n> >\n> > <pk> CHECKSIG\n> > ```\n> >\n> > That's a long script... but will it fit? We need to verify 20 bytes of message\n> > each bit takes around 10 bytes script, an average of 3.375 bytes per number\n> > (counting pushes), and two 21 bytes keys = 55.375 bytes of program space and 21\n> > bytes of witness element per bit.\n> >\n> > It fits! `20*8*55.375 = 8860`, which leaves 1140 bytes less than the limit for\n> > the rest of the logic, which is plenty (around 15-40 bytes required for the rest\n> > of the logic, leaving 1100 free for custom signature checking). The stack size\n> > is 160 elements for the hash gadget, 3360 bytes.\n> >\n> > This can probably be made a bit more efficient by expanding to a ternary\n> > representation.\n> >\n> > ```\n> >         SWAP hash160 DUP <H(K_j_i_0)> EQUAL  IF DROP  ELSE <3**i> SWAP DUP <H(K_j_i_T)> EQUAL IF DROP SUB ELSE <H(K_j_i_1)> EQUALVERIFY ADD  ENDIF ENDIF\n> > ```\n> >\n> > This should bring it up to roughly 85 bytes per trit, and there should be 101\n> > trits (`log(2**160)/log(3) == 100.94`), so about 8560 bytes... a bit cheaper!\n> > But the witness stack is \"only\" `2121` bytes...\n> >\n> > As a homework exercise, maybe someone can prove the optimal choice of radix for\n> > this protocol... My guess is that base 4 is optimal!\n> >\n> > ## Taproot?\n> >\n> > What about Taproot? As far as I'm aware the commitment scheme (`Q = pG + hash(pG\n> > || m)G`) can be securely opened to m even with a quantum computer (finding `q`\n> > such that `qG = Q` might be trivial, but suppose key path was disabled, then\n> > finding m and p such that the taproot equation holds should be difficult because\n> > of the hash, but I'd need to certify that claim better).  Therefore this\n> > script can nest inside of a Tapscript path -- Tapscript also does not impose a\n> > length limit, 32 byte hashes could be used as well.\n> >\n> > Further, to make keys reusable, there could be many Lamport keys comitted inside\n> > a taproot tree so that an address could be used for thousands of times before\n> > expiring. This could be used as a measure to protect accidental use rather than\n> > to support it.\n> >\n> > Lastly, Schnorr actually has a stronger non-malleability property than ECDSA,\n> > the signatures will be binding to the approved transaction and once Lamport\n> > signed, even a quantum computer could not steal the funds.\n> >\n> > --\n> > @JeremyRubin\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-07-09T22:38:18",
                "message_text_only": "Good morning Ethan,\n\n> > Yes, quite neat indeed, too bad Lamport signatures are so huge (a couple kilobytes)... blocksize increase cough\n>\n> Couldn't you significantly compress the signatures by using either\n> Winternitz OTS or by using OP_CAT to build a merkle tree so that the\n> full signature can be derived during script execution from a much\n> shorter set of seed values?\n\nTo implement Winternitz we need some kind of limited-repeat construct, which is not available in SCRIPT, but may be emulatable with enough `OP_IF` and sheer brute force.\nBut what you gain in smaller signatures, you lose in a more complex and longer SCRIPT, and there are limits to SCRIPT size (in order to limit the processing done in each node).\n\nMerkle signatures trade off shorter pubkeys for longer signatures (signatures need to provide the hash of the *other* preimage you are not revealing), but in the modern post-SegWit Bitcoin context both pubkeys and signatures are stored in the witness area, which have the same weight, thus it is actually a loss compared to Lamport.\n\n\nSo yes, maybe Winternitz (could be a replacement for the \"trinary\" Jeremy refers to), Merkle not so much.\n\nRegards,\nZmnSCPxj\n\n> On Thu, Jul 8, 2021 at 4:12 AM ZmnSCPxj via bitcoin-dev\n> bitcoin-dev at lists.linuxfoundation.org wrote:\n>\n> > Good morning Jeremy,\n> > Yes, quite neat indeed, too bad Lamport signatures are so huge (a couple kilobytes)... blocksize increase cough\n> > Since a quantum computer can derive the EC privkey from the EC pubkey and this scheme is resistant to that, I think you can use a single well-known EC privkey, you just need a unique Lamport keypair for each UTXO (uniqueness being mandatory due to Lamport requiring preimage revelation).\n> > Regards,\n> > ZmnSCPxj\n> >\n> > > Dear Bitcoin Devs,\n> > > As mentioned previously, OP_CAT (or similar operation) can be used to make Bitcoin \"quantum safe\" by signing an EC signature. This should work in both Segwit V0 and Tapscript, although you have to use HASH160 for it to fit in Segwit V0.\n> > > See my blog for the specific construction, reproduced below.\n> > > Yet another entry to the \"OP_CAT can do that too\" list.\n> > > Best,\n> > >\n> > > Jeremy\n> > >\n> > > -------\n> > >\n> > > I recently published a blogpost about signing up to a5 byte value using Bitcoin script arithmetic and Lamport signatures.\n> > > By itself, this is neat, but a little limited. What if we could sign longer\n> > > messages? If we can sign up to 20 bytes, we could sign a HASH160 digest which\n> > > is most likely quantum safe...\n> > > What would it mean if we signed the HASH160 digest of a signature? What the\n> > > what? Why would we do that?\n> > > Well, as it turns out, even if a quantum computer were able to crack ECDSA, it\n> > > would yield revealing the private key but not the ability to malleate the\n> > > content of what was actually signed. I asked my good friend and cryptographer\n> > > Madars Virza if my intuition was correct, and he\n> > > confirmed that it should be sufficient, but it's definitely worth closer\n> > > analysis before relying on this. While the ECDSA signature can be malleated to a\n> > > different, negative form, if the signature is otherwise made immalleable there\n> > > should only be one value the commitment can be opened to.\n> > > If we required the ECDSA signature be signed with a quantum proof signature\n> > > algorithm, then we'd have a quantum proof Bitcoin! And the 5 byte signing scheme\n> > > we discussed previously is a Lamport signature, which is quantum secure.\n> > > Unfortunately, we need at least 20 contiguous bytes... so we need some sort of\n> > > OP\\_CAT like operation.\n> > > OP\\_CAT can't be directly soft forked to Segwit v0 because it modifies the\n> > > stack, so instead we'll (for simplicity) also show how to use a new opcode that\n> > > uses verify semantics, OP\\_SUBSTRINGEQUALVERIFY that checks a splice of a string\n> > > for equality.\n> > >\n> > >     ... FOR j in 0..=5\n> > >         <0>\n> > >         ... FOR i in 0..=31\n> > >             SWAP hash160 DUP <H(K_j_i_1)> EQUAL IF DROP <2**i> ADD ELSE <H(K_j_i_0)> EQUALVERIFY ENDIF\n> > >         ... END FOR\n> > >         TOALTSTACK\n> > >     ... END FOR\n> > >\n> > >     DUP HASH160\n> > >\n> > >     ... IF CAT AVAILABLE\n> > >         FROMALTSTACK\n> > >         ... FOR j in 0..=5\n> > >             FROMALTSTACK\n> > >             CAT\n> > >         ... END FOR\n> > >         EQUALVERIFY\n> > >     ... ELSE SUBSTRINGEQUALVERIFY AVAILABLE\n> > >         ... FOR j in 0..=5\n> > >             FROMALTSTACK <0+j*4> <4+j*4> SUBSTRINGEQUALVERIFY DROP DROP DROP\n> > >         ...  END FOR\n> > >         DROP\n> > >     ... END IF\n> > >\n> > >     <pk> CHECKSIG\n> > >\n> > >\n> > > That's a long script... but will it fit? We need to verify 20 bytes of message\n> > > each bit takes around 10 bytes script, an average of 3.375 bytes per number\n> > > (counting pushes), and two 21 bytes keys = 55.375 bytes of program space and 21\n> > > bytes of witness element per bit.\n> > > It fits! `20*8*55.375 = 8860`, which leaves 1140 bytes less than the limit for\n> > > the rest of the logic, which is plenty (around 15-40 bytes required for the rest\n> > > of the logic, leaving 1100 free for custom signature checking). The stack size\n> > > is 160 elements for the hash gadget, 3360 bytes.\n> > > This can probably be made a bit more efficient by expanding to a ternary\n> > > representation.\n> > >\n> > >             SWAP hash160 DUP <H(K_j_i_0)> EQUAL  IF DROP  ELSE <3**i> SWAP DUP <H(K_j_i_T)> EQUAL IF DROP SUB ELSE <H(K_j_i_1)> EQUALVERIFY ADD  ENDIF ENDIF\n> > >\n> > >\n> > > This should bring it up to roughly 85 bytes per trit, and there should be 101\n> > > trits (`log(2**160)/log(3) == 100.94`), so about 8560 bytes... a bit cheaper!\n> > > But the witness stack is \"only\" `2121` bytes...\n> > > As a homework exercise, maybe someone can prove the optimal choice of radix for\n> > > this protocol... My guess is that base 4 is optimal!\n> > >\n> > > Taproot?\n> > >\n> > > ---------\n> > >\n> > > What about Taproot? As far as I'm aware the commitment scheme (`Q = pG + hash(pG || m)G`) can be securely opened to m even with a quantum computer (finding `q`\n> > > such that `qG = Q` might be trivial, but suppose key path was disabled, then\n> > > finding m and p such that the taproot equation holds should be difficult because\n> > > of the hash, but I'd need to certify that claim better). Therefore this\n> > > script can nest inside of a Tapscript path -- Tapscript also does not impose a\n> > > length limit, 32 byte hashes could be used as well.\n> > > Further, to make keys reusable, there could be many Lamport keys comitted inside\n> > > a taproot tree so that an address could be used for thousands of times before\n> > > expiring. This could be used as a measure to protect accidental use rather than\n> > > to support it.\n> > > Lastly, Schnorr actually has a stronger non-malleability property than ECDSA,\n> > > the signatures will be binding to the approved transaction and once Lamport\n> > > signed, even a quantum computer could not steal the funds.\n> > > --\n> > > @JeremyRubin\n> >\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Ethan Heilman",
                "date": "2021-07-09T23:25:06",
                "message_text_only": ">To implement Winternitz we need some kind of limited-repeat construct, which is not available in SCRIPT, but may be emulatable with enough `OP_IF` and sheer brute force.\nBut what you gain in smaller signatures, you lose in a more complex\nand longer SCRIPT, and there are limits to SCRIPT size (in order to\nlimit the processing done in each node).\n\nUsing depth 4 Winternitz would increase the number of instructions in\nSCRIPT by 4*(signature bits/2) instructions, but decrease the\nsignature size by (signature bits/2) hash preimages. Given that\ninstructions are significantly smaller in size than the hash preimages\nused, it seems like this would significantly reduce total size.\n\n>Merkle signatures trade off shorter pubkeys for longer signatures (signatures need to provide the hash of the *other* preimage you are not revealing), but in the modern post-SegWit Bitcoin context both pubkeys and signatures are stored in the witness area, which have the same weight, thus it is actually a loss compared to Lamport.\n\nI wasn't proposing using plain merkle signatures, rather I was\nthinking about something where if particular chunks of the message fit\na pattern you could release a seed higher in the commitment tree. For\ninstance 1,1,1 could be signed as by releasing H(01||H(01||H(01||x))),\n H(11||H(11||H(11||x))), H(21||H(21||H(21||x))), or by releasing X.\nHowever, you would want to only release X in that one specific case\n(1,1,1) but no others. Again this would bloat the SCRIPT and decrease\nsignature size but at a favorable ratio.\n\nI am not convinced anyone should do these things, but they are fun to\nthink about and I suspect with more thought such signature sizes and\nSCRIPT sizes could be even further reduced.\n\nOn Fri, Jul 9, 2021 at 6:38 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n> Good morning Ethan,\n>\n> > > Yes, quite neat indeed, too bad Lamport signatures are so huge (a couple kilobytes)... blocksize increase cough\n> >\n> > Couldn't you significantly compress the signatures by using either\n> > Winternitz OTS or by using OP_CAT to build a merkle tree so that the\n> > full signature can be derived during script execution from a much\n> > shorter set of seed values?\n>\n> To implement Winternitz we need some kind of limited-repeat construct, which is not available in SCRIPT, but may be emulatable with enough `OP_IF` and sheer brute force.\n> But what you gain in smaller signatures, you lose in a more complex and longer SCRIPT, and there are limits to SCRIPT size (in order to limit the processing done in each node).\n>\n> Merkle signatures trade off shorter pubkeys for longer signatures (signatures need to provide the hash of the *other* preimage you are not revealing), but in the modern post-SegWit Bitcoin context both pubkeys and signatures are stored in the witness area, which have the same weight, thus it is actually a loss compared to Lamport.\n>\n>\n> So yes, maybe Winternitz (could be a replacement for the \"trinary\" Jeremy refers to), Merkle not so much.\n>\n> Regards,\n> ZmnSCPxj\n>\n> > On Thu, Jul 8, 2021 at 4:12 AM ZmnSCPxj via bitcoin-dev\n> > bitcoin-dev at lists.linuxfoundation.org wrote:\n> >\n> > > Good morning Jeremy,\n> > > Yes, quite neat indeed, too bad Lamport signatures are so huge (a couple kilobytes)... blocksize increase cough\n> > > Since a quantum computer can derive the EC privkey from the EC pubkey and this scheme is resistant to that, I think you can use a single well-known EC privkey, you just need a unique Lamport keypair for each UTXO (uniqueness being mandatory due to Lamport requiring preimage revelation).\n> > > Regards,\n> > > ZmnSCPxj\n> > >\n> > > > Dear Bitcoin Devs,\n> > > > As mentioned previously, OP_CAT (or similar operation) can be used to make Bitcoin \"quantum safe\" by signing an EC signature. This should work in both Segwit V0 and Tapscript, although you have to use HASH160 for it to fit in Segwit V0.\n> > > > See my blog for the specific construction, reproduced below.\n> > > > Yet another entry to the \"OP_CAT can do that too\" list.\n> > > > Best,\n> > > >\n> > > > Jeremy\n> > > >\n> > > > -------\n> > > >\n> > > > I recently published a blogpost about signing up to a5 byte value using Bitcoin script arithmetic and Lamport signatures.\n> > > > By itself, this is neat, but a little limited. What if we could sign longer\n> > > > messages? If we can sign up to 20 bytes, we could sign a HASH160 digest which\n> > > > is most likely quantum safe...\n> > > > What would it mean if we signed the HASH160 digest of a signature? What the\n> > > > what? Why would we do that?\n> > > > Well, as it turns out, even if a quantum computer were able to crack ECDSA, it\n> > > > would yield revealing the private key but not the ability to malleate the\n> > > > content of what was actually signed. I asked my good friend and cryptographer\n> > > > Madars Virza if my intuition was correct, and he\n> > > > confirmed that it should be sufficient, but it's definitely worth closer\n> > > > analysis before relying on this. While the ECDSA signature can be malleated to a\n> > > > different, negative form, if the signature is otherwise made immalleable there\n> > > > should only be one value the commitment can be opened to.\n> > > > If we required the ECDSA signature be signed with a quantum proof signature\n> > > > algorithm, then we'd have a quantum proof Bitcoin! And the 5 byte signing scheme\n> > > > we discussed previously is a Lamport signature, which is quantum secure.\n> > > > Unfortunately, we need at least 20 contiguous bytes... so we need some sort of\n> > > > OP\\_CAT like operation.\n> > > > OP\\_CAT can't be directly soft forked to Segwit v0 because it modifies the\n> > > > stack, so instead we'll (for simplicity) also show how to use a new opcode that\n> > > > uses verify semantics, OP\\_SUBSTRINGEQUALVERIFY that checks a splice of a string\n> > > > for equality.\n> > > >\n> > > >     ... FOR j in 0..=5\n> > > >         <0>\n> > > >         ... FOR i in 0..=31\n> > > >             SWAP hash160 DUP <H(K_j_i_1)> EQUAL IF DROP <2**i> ADD ELSE <H(K_j_i_0)> EQUALVERIFY ENDIF\n> > > >         ... END FOR\n> > > >         TOALTSTACK\n> > > >     ... END FOR\n> > > >\n> > > >     DUP HASH160\n> > > >\n> > > >     ... IF CAT AVAILABLE\n> > > >         FROMALTSTACK\n> > > >         ... FOR j in 0..=5\n> > > >             FROMALTSTACK\n> > > >             CAT\n> > > >         ... END FOR\n> > > >         EQUALVERIFY\n> > > >     ... ELSE SUBSTRINGEQUALVERIFY AVAILABLE\n> > > >         ... FOR j in 0..=5\n> > > >             FROMALTSTACK <0+j*4> <4+j*4> SUBSTRINGEQUALVERIFY DROP DROP DROP\n> > > >         ...  END FOR\n> > > >         DROP\n> > > >     ... END IF\n> > > >\n> > > >     <pk> CHECKSIG\n> > > >\n> > > >\n> > > > That's a long script... but will it fit? We need to verify 20 bytes of message\n> > > > each bit takes around 10 bytes script, an average of 3.375 bytes per number\n> > > > (counting pushes), and two 21 bytes keys = 55.375 bytes of program space and 21\n> > > > bytes of witness element per bit.\n> > > > It fits! `20*8*55.375 = 8860`, which leaves 1140 bytes less than the limit for\n> > > > the rest of the logic, which is plenty (around 15-40 bytes required for the rest\n> > > > of the logic, leaving 1100 free for custom signature checking). The stack size\n> > > > is 160 elements for the hash gadget, 3360 bytes.\n> > > > This can probably be made a bit more efficient by expanding to a ternary\n> > > > representation.\n> > > >\n> > > >             SWAP hash160 DUP <H(K_j_i_0)> EQUAL  IF DROP  ELSE <3**i> SWAP DUP <H(K_j_i_T)> EQUAL IF DROP SUB ELSE <H(K_j_i_1)> EQUALVERIFY ADD  ENDIF ENDIF\n> > > >\n> > > >\n> > > > This should bring it up to roughly 85 bytes per trit, and there should be 101\n> > > > trits (`log(2**160)/log(3) == 100.94`), so about 8560 bytes... a bit cheaper!\n> > > > But the witness stack is \"only\" `2121` bytes...\n> > > > As a homework exercise, maybe someone can prove the optimal choice of radix for\n> > > > this protocol... My guess is that base 4 is optimal!\n> > > >\n> > > > Taproot?\n> > > >\n> > > > ---------\n> > > >\n> > > > What about Taproot? As far as I'm aware the commitment scheme (`Q = pG + hash(pG || m)G`) can be securely opened to m even with a quantum computer (finding `q`\n> > > > such that `qG = Q` might be trivial, but suppose key path was disabled, then\n> > > > finding m and p such that the taproot equation holds should be difficult because\n> > > > of the hash, but I'd need to certify that claim better). Therefore this\n> > > > script can nest inside of a Tapscript path -- Tapscript also does not impose a\n> > > > length limit, 32 byte hashes could be used as well.\n> > > > Further, to make keys reusable, there could be many Lamport keys comitted inside\n> > > > a taproot tree so that an address could be used for thousands of times before\n> > > > expiring. This could be used as a measure to protect accidental use rather than\n> > > > to support it.\n> > > > Lastly, Schnorr actually has a stronger non-malleability property than ECDSA,\n> > > > the signatures will be binding to the approved transaction and once Lamport\n> > > > signed, even a quantum computer could not steal the funds.\n> > > > --\n> > > > @JeremyRubin\n> > >\n> > > bitcoin-dev mailing list\n> > > bitcoin-dev at lists.linuxfoundation.org\n> > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>"
            },
            {
                "author": "Jeremy",
                "date": "2021-07-09T22:52:56",
                "message_text_only": "I thought about this, but at the time of writing I couldn't come up with\nsomething I thought was substantially better. I spent a few more cycles\nthinking on it -- you can definitely do better. It's not clear how much\nbetter Winternitz might be, or if it would be secure in this context?\nHere's some exploration...\n\nmaybe you can do something like:\n\n<x0> <H(x1)> <dir in {0,1}> || IF SWAP HASH SWAP ELSE HASH FROMALTSTACK\n<2**n> TOALTSTACK ADD ENDIF CAT\n\nyou can process this (assume HASH160) into chunks of 26 bits, cat them all\ntogether, and then stash that hash. You would need 6 gadgets, and then 1\noverflow + 4 bare hashes for the final key hash (e.g. your tree looks like)\nH(H(26x20) || H(26x20)...H(bit)|| H(bit) || H(bit) || H(bit)). It doesn't\nmake sense to have a \"nice\" merkle tree, just fit in as much data as\npossible per call (520 bytes). If OP_SHASTREAM, this is even better since\nyou can ignore structuring...\n\nThis would bring your cost down by about 20 bytes per bit, for 160 bits, so\naround a savings of 3200 bytes... not bad! 1/3 cheaper.\n\nScript is about 15x160 = 2400 and change, witness is 43x160 = 6880\n\nIf you were to convert to 3-ary, you could cut this down to 101 gates with\na script like:\n\nwitnesses:\n<H(xT)> <H(x1)>   <0> <x0>\n<H(x0) || H(x1)> <1> <xT>\n<H(xT) || H(x0)>  <2> <x1>\n\nscript:\nHASH SWAP\nIFDUP\nNOTIF    # 0 passed in (0)\n    SWAP CAT\nELSE\n    <3**n> TOALT\n    1SUB\n    IF # 2 passed in (+1)\n        FROMALT # do nothing\n    ELSE # 1 passed in (T)\n        SWAP # Swaps H(xT) to back\n        FROMALT NEGATE # negate\n    END\n    FROMALT ADD TOALT # add to accumulator\nENDIF\nCAT\n\n\nyou would end up having to publish ~64x101 data in the witness, so only\n6464 total (and about 24x101 = 2424 and change for the script)\n\nMaking the script smaller also means that choice of hash160/sha256 doesn't\nchange script size much, just witness. And the witnesses are free to\nprovide their own preimages, so it would be OK to use something > 20 bytes,\n< 32 for more variable security/length tradeoff.\n\n\nAt the cost of marginally bigger script (by about 6x101 bytes), you can\nsave 20x101 off the witness stack by making each key H(H(xT) || H(x0)) ||\nH(x1). 43x101 + 30x101 = 7373 + change for the final grouping.\n\nwitnesses:\n<H(xT)> <H(x1)>   <0> <x0>\n<H(x0)> <H(x1)> <1> <xT>\n<H(H(xT) || H(x0))>  <2> <x1>\n\nscript:\nHASH SWAP\nIFDUP\nNOTIF    # 0 passed in (0)\n    ROT SWAP CAT HASH\nELSE\n    <3**n> TOALT\n    1SUB\n    IF # 2 passed in (+1)\n        FROMALT # do nothing\n    ELSE # 1 passed in (T)\n        TOALTSTACK CAT HASH FROMALTSTACK SWAP # Swaps H(xT) to back\n        FROMALT NEGATE # negate\n    END\n    FROMALT ADD TOALT # add to accumulator\nENDIF\nCAT\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Fri, Jul 9, 2021 at 12:03 PM Ethan Heilman <eth3rs at gmail.com> wrote:\n\n> >Yes, quite neat indeed, too bad Lamport signatures are so huge (a couple\n> kilobytes)... blocksize increase *cough*\n>\n> Couldn't you significantly compress the signatures by using either\n> Winternitz OTS or by using OP_CAT to build a merkle tree so that the\n> full signature can be derived during script execution from a much\n> shorter set of seed values?\n>\n> On Thu, Jul 8, 2021 at 4:12 AM ZmnSCPxj via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >\n> >\n> > Good morning Jeremy,\n> >\n> > Yes, quite neat indeed, too bad Lamport signatures are so huge (a couple\n> kilobytes)... blocksize increase *cough*\n> >\n> > Since a quantum computer can derive the EC privkey from the EC pubkey\n> and this scheme is resistant to that, I think you can use a single\n> well-known EC privkey, you just need a unique Lamport keypair for each UTXO\n> (uniqueness being mandatory due to Lamport requiring preimage revelation).\n> >\n> > Regards,\n> > ZmnSCPxj\n> >\n> >\n> > > Dear Bitcoin Devs,\n> > >\n> > > As mentioned previously, OP_CAT (or similar operation) can be used to\n> make Bitcoin \"quantum safe\" by signing an EC signature. This should work in\n> both Segwit V0 and Tapscript, although you have to use HASH160 for it to\n> fit in Segwit V0.\n> > >\n> > > See [my blog](https://rubin.io/blog/2021/07/06/quantum-bitcoin/) for\n> the specific construction, reproduced below.\n> > >\n> > > Yet another entry to the \"OP_CAT can do that too\" list.\n> > >\n> > > Best,\n> > >\n> > > Jeremy\n> > > -----\n> > >\n> > > I recently published [a blog\n> > > post](https://rubin.io/blog/2021/07/02/signing-5-bytes/) about\n> signing up to a\n> > > 5 byte value using Bitcoin script arithmetic and Lamport signatures.\n> > >\n> > > By itself, this is neat, but a little limited. What if we could sign\n> longer\n> > > messages? If we can sign up to 20 bytes, we could sign a HASH160\n> digest which\n> > > is most likely quantum safe...\n> > >\n> > > What would it mean if we signed the HASH160 digest of a signature?\n> What the\n> > > what? Why would we do that?\n> > >\n> > > Well, as it turns out, even if a quantum computer were able to crack\n> ECDSA, it\n> > > would yield revealing the private key but not the ability to malleate\n> the\n> > > content of what was actually signed.  I asked my good friend and\n> cryptographer\n> > > [Madars Virza](https://madars.org/) if my intuition was correct, and\n> he\n> > > confirmed that it should be sufficient, but it's definitely worth\n> closer\n> > > analysis before relying on this. While the ECDSA signature can be\n> malleated to a\n> > > different, negative form, if the signature is otherwise made\n> immalleable there\n> > > should only be one value the commitment can be opened to.\n> > >\n> > > If we required the ECDSA signature be signed with a quantum proof\n> signature\n> > > algorithm, then we'd have a quantum proof Bitcoin! And the 5 byte\n> signing scheme\n> > > we discussed previously is a Lamport signature, which is quantum\n> secure.\n> > > Unfortunately, we need at least 20 contiguous bytes... so we need some\n> sort of\n> > > OP\\_CAT like operation.\n> > >\n> > > OP\\_CAT can't be directly soft forked to Segwit v0 because it modifies\n> the\n> > > stack, so instead we'll (for simplicity) also show how to use a new\n> opcode that\n> > > uses verify semantics, OP\\_SUBSTRINGEQUALVERIFY that checks a splice\n> of a string\n> > > for equality.\n> > >\n> > > ```\n> > > ... FOR j in 0..=5\n> > >     <0>\n> > >     ... FOR i in 0..=31\n> > >         SWAP hash160 DUP <H(K_j_i_1)> EQUAL IF DROP <2**i> ADD ELSE\n> <H(K_j_i_0)> EQUALVERIFY ENDIF\n> > >     ... END FOR\n> > >     TOALTSTACK\n> > > ... END FOR\n> > >\n> > > DUP HASH160\n> > >\n> > > ... IF CAT AVAILABLE\n> > >     FROMALTSTACK\n> > >     ... FOR j in 0..=5\n> > >         FROMALTSTACK\n> > >         CAT\n> > >     ... END FOR\n> > >     EQUALVERIFY\n> > > ... ELSE SUBSTRINGEQUALVERIFY AVAILABLE\n> > >     ... FOR j in 0..=5\n> > >         FROMALTSTACK <0+j*4> <4+j*4> SUBSTRINGEQUALVERIFY DROP DROP\n> DROP\n> > >     ...  END FOR\n> > >     DROP\n> > > ... END IF\n> > >\n> > > <pk> CHECKSIG\n> > > ```\n> > >\n> > > That's a long script... but will it fit? We need to verify 20 bytes of\n> message\n> > > each bit takes around 10 bytes script, an average of 3.375 bytes per\n> number\n> > > (counting pushes), and two 21 bytes keys = 55.375 bytes of program\n> space and 21\n> > > bytes of witness element per bit.\n> > >\n> > > It fits! `20*8*55.375 = 8860`, which leaves 1140 bytes less than the\n> limit for\n> > > the rest of the logic, which is plenty (around 15-40 bytes required\n> for the rest\n> > > of the logic, leaving 1100 free for custom signature checking). The\n> stack size\n> > > is 160 elements for the hash gadget, 3360 bytes.\n> > >\n> > > This can probably be made a bit more efficient by expanding to a\n> ternary\n> > > representation.\n> > >\n> > > ```\n> > >         SWAP hash160 DUP <H(K_j_i_0)> EQUAL  IF DROP  ELSE <3**i> SWAP\n> DUP <H(K_j_i_T)> EQUAL IF DROP SUB ELSE <H(K_j_i_1)> EQUALVERIFY ADD  ENDIF\n> ENDIF\n> > > ```\n> > >\n> > > This should bring it up to roughly 85 bytes per trit, and there should\n> be 101\n> > > trits (`log(2**160)/log(3) == 100.94`), so about 8560 bytes... a bit\n> cheaper!\n> > > But the witness stack is \"only\" `2121` bytes...\n> > >\n> > > As a homework exercise, maybe someone can prove the optimal choice of\n> radix for\n> > > this protocol... My guess is that base 4 is optimal!\n> > >\n> > > ## Taproot?\n> > >\n> > > What about Taproot? As far as I'm aware the commitment scheme (`Q = pG\n> + hash(pG\n> > > || m)G`) can be securely opened to m even with a quantum computer\n> (finding `q`\n> > > such that `qG = Q` might be trivial, but suppose key path was\n> disabled, then\n> > > finding m and p such that the taproot equation holds should be\n> difficult because\n> > > of the hash, but I'd need to certify that claim better).  Therefore\n> this\n> > > script can nest inside of a Tapscript path -- Tapscript also does not\n> impose a\n> > > length limit, 32 byte hashes could be used as well.\n> > >\n> > > Further, to make keys reusable, there could be many Lamport keys\n> comitted inside\n> > > a taproot tree so that an address could be used for thousands of times\n> before\n> > > expiring. This could be used as a measure to protect accidental use\n> rather than\n> > > to support it.\n> > >\n> > > Lastly, Schnorr actually has a stronger non-malleability property than\n> ECDSA,\n> > > the signatures will be binding to the approved transaction and once\n> Lamport\n> > > signed, even a quantum computer could not steal the funds.\n> > >\n> > > --\n> > > @JeremyRubin\n> >\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210709/61192298/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "OP_CAT Makes Bitcoin Quantum Secure ",
            "categories": [
                "bitcoin-dev",
                "was CheckSigFromStack for Arithmetic Values"
            ],
            "authors": [
                "ZmnSCPxj",
                "Jeremy",
                "Ethan Heilman"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 43165
        }
    },
    {
        "title": "[bitcoin-dev] Eltoo / Anyprevout & Baked in Sequences",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2021-07-08T01:00:20",
                "message_text_only": "I made a comment on\nhttps://github.com/bitcoin/bips/pull/943#issuecomment-876034559 but it\noccurred to me it is more ML appropriate.\n\nIn general, one thing that strikes me is that when anyprevout is used for\neltoo you're generally doing a script like:\n\n```\nIF\n    10 CSV DROP\n    1::musigkey(As,Bs) CHECKSIG\nELSE\n    <S+1> CLTV DROP\n   1::musigkey(Au,Bu) CHECKSIG\nENDIF\n```\n\nThis means that you're overloading the CLTV clause, which means it's\nimpossible to use Eltoo and use a absolute lock time, it also means you\nhave to use fewer than a billion sequences, and if you pick a random # to\nmask how many payments you've done / pick random gaps let's say that\nreduces your numbers in half. That may be enough, but is still relatively\nlimited. There is also the issue that multiple inputs cannot be combined\ninto a transaction if they have signed on different locktimes.\n\nSince Eltoo is the primary motivation for ANYPREVOUT, it's worth making\nsure we have all the parts we'd need bundled together to see it be\nsuccessful.\n\nA few options come to mind that might be desirable in order to better serve\nthe eltoo usecase\n\n1) Define a new CSV type (e.g. define (1<<31 && 1<<30) as being dedicated\nto eltoo sequences). This has the benefit of giving a per input sequence,\nbut the drawback of using a CSV bit. Because there's only 1 CSV per input,\nthis technique cannot be used with a sequence tag.\n2) CSFS -- it would be possible to take a signature from stack for an\narbitrary higher number, e.g.:\n```\nIF\n    10 CSV DROP\n    1::musigkey(As,Bs) CHECKSIG\nELSE\n    DUP musigkey(Aseq, BSeq) CSFSV <S+1> GTE VERIFY\n   1::musigkey(Au,Bu) CHECKSIG\nENDIF\n```\nThen, posession of a higher signed sequence would allow for the use of the\nupdate path. However, the downside is that there would be no guarantee that\nthe new state provided for update would be higher than the past one without\na more advanced covenant.\n3) Sequenced Signature: It could be set up such that ANYPREVOUT keys are\ntagged with a N byte sequence (instead of 1), and a part of the process of\nsignature verification includes hashing a sequence on the signature itself.\n\nE.g.\n\n```\nIF\n    10 CSV DROP\n    1::musigkey(As,Bs) CHECKSIG\nELSE\n   <N>::musigkey(Au,Bu) CHECKSIG\nENDIF\n```\nTo satisfy this clause, a signature `<N+1>::S` would be required. When\nvalidating the signature S, the APO digest would have to include the value\n<N+1>. It is non cryptographically checked that N+1 > N.\n5) Similar to 3, but look at more values off the stack. This is also OK,\nbut violates the principle of not making opcodes take variable numbers of\nthings off the stack. Verify semantics on the extra data fields could\nameliorate this concern, and it might make sense to do it that way.\n4) Something in the Annex: It would also be possible to define a new\ngeneric place for lock times in the annex (to permit dual height/time\nrelative/absolute, all per input. The pro of this approach is that it would\nbe solving an outstanding problem for script that we want to solve anyways,\nthe downside is that the Annex is totally undefined presently so it's\nunclear that this is an appropriate use for it.\n5) Do Nothing :)\n\n\nOverall I'm somewhat partial to option 3 as it seems to be closest to\nmaking ANYPREVOUT more precisely designed to support Eltoo. It would also\nbe possible to make it such that if the tag N=1, then the behavior is\nidentical to the proposal currently.\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210707/9e3fa6d7/attachment.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2021-07-08T08:44:16",
                "message_text_only": "On Wed, Jul 07, 2021 at 06:00:20PM -0700, Jeremy via bitcoin-dev wrote:\n> This means that you're overloading the CLTV clause, which means it's impossible\n> to use Eltoo and use a absolute lock time,\n\nIt's already impossible to simultaneously spend two inputs if one\nrequires a locktime specified by mediantime and the other by block\nheight. Having per-input locktimes would satisfy both concerns.\n\n> 1) Define a new CSV type (e.g. define (1<<31 && 1<<30) as being dedicated to\n> eltoo sequences). This has the benefit of giving a per input sequence, but the\n> drawback of using a CSV bit. Because there's only 1 CSV per input, this\n> technique cannot be used with a sequence tag.\n\nThis would disallow using a relative locktime and an absolute locktime\nfor the same input. I don't think I've seen a use case for that so far,\nbut ruling it out seems suboptimal.\n\nAdding a per-input absolute locktime to the annex is what I've had in\nmind. That could also be used to cheaply add a commitment to an historical\nblock hash (eg \"the block at height 650,000 ended in cc6a\") in order to\ndisambiguate which branch of a chain split or reorg your tx is valid for.\n\nCheers,\naj"
            },
            {
                "author": "Jeremy",
                "date": "2021-07-08T15:48:14",
                "message_text_only": ">\n> This would disallow using a relative locktime and an absolute locktime\n> for the same input. I don't think I've seen a use case for that so far,\n> but ruling it out seems suboptimal.\n\n\nI think you meant disallowing a relative locktime and a sequence locktime?\nI agree it is suboptimal.\n\n\nWhat do you make of sequence tagged keys?\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210708/6512bb4f/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Eltoo / Anyprevout & Baked in Sequences",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Anthony Towns",
                "Jeremy"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 5345
        }
    },
    {
        "title": "[bitcoin-dev] [Lightning-dev] Eltoo / Anyprevout & Baked in Sequences",
        "thread_messages": [
            {
                "author": "Anthony Towns",
                "date": "2021-07-12T05:01:15",
                "message_text_only": "On Thu, Jul 08, 2021 at 08:48:14AM -0700, Jeremy wrote:\n>     This would disallow using a relative locktime and an absolute locktime\n>     for the same input. I don't think I've seen a use case for that so far,\n>     but ruling it out seems suboptimal.\n> I think you meant disallowing a relative locktime and a sequence locktime? I\n> agree it is suboptimal.\n\nNo? If you overload the nSequence for a per-input absolute locktime\n(well in the past for eltoo), then you can't reuse the same input's\nnSequence for a per-input relative locktime (ie CSV).\n\nApparently I have thought of a use for it now -- cut-through of PTLC\nrefunds when the timeout expires well after the channel settlement delay\nhas passed. (You want a signature that's valid after a relative locktime\nof the delay and after the absolute timeout)\n\n> What do you make of sequence tagged keys?\n\nI think we want sequencing restrictions to be obvious from some (simple)\ncombination of nlocktime/nsequence/annex so that you don't have to\nevaluate scripts/signatures in order to determine if a transaction\nis final.\n\nPerhaps there's a more general principle -- evaluating a script should\nonly return one bit of info: \"bool tx_is_invalid_script_failed\"; every\nother bit of information -- how much is paid in fees (cf ethereum gas\ncalculations), when the tx is final, if the tx is only valid in some\nchain fork, if other txs have to have already been mined / can't have\nbeen mined, who loses funds and who gets funds, etc... -- should already\nbe obvious from a \"simple\" parsing of the tx.\n\nCheers,\naj"
            },
            {
                "author": "Jeremy",
                "date": "2021-07-12T22:07:29",
                "message_text_only": "On Sun, Jul 11, 2021 at 10:01 PM Anthony Towns <aj at erisian.com.au> wrote:\n\n> On Thu, Jul 08, 2021 at 08:48:14AM -0700, Jeremy wrote:\n> >     This would disallow using a relative locktime and an absolute\n> locktime\n> >     for the same input. I don't think I've seen a use case for that so\n> far,\n> >     but ruling it out seems suboptimal.\n> > I think you meant disallowing a relative locktime and a sequence\n> locktime? I\n> > agree it is suboptimal.\n>\n> No? If you overload the nSequence for a per-input absolute locktime\n> (well in the past for eltoo), then you can't reuse the same input's\n> nSequence for a per-input relative locktime (ie CSV).\n>\n> Apparently I have thought of a use for it now -- cut-through of PTLC\n> refunds when the timeout expires well after the channel settlement delay\n> has passed. (You want a signature that's valid after a relative locktime\n> of the delay and after the absolute timeout)\n>\n\nAh -- I didn't mean a per input abs locktime, I mean the  tx global\nlocktime.\n\nI agree that at some point we should just separate all locktime types per\ninput so we get rid of all weirdness/overlap.\n\n\n\n>\n> > What do you make of sequence tagged keys?\n>\n> I think we want sequencing restrictions to be obvious from some (simple)\n> combination of nlocktime/nsequence/annex so that you don't have to\n> evaluate scripts/signatures in order to determine if a transaction\n> is final.\n>\n> Perhaps there's a more general principle -- evaluating a script should\n> only return one bit of info: \"bool tx_is_invalid_script_failed\"; every\n> other bit of information -- how much is paid in fees (cf ethereum gas\n> calculations), when the tx is final, if the tx is only valid in some\n> chain fork, if other txs have to have already been mined / can't have\n> been mined, who loses funds and who gets funds, etc... -- should already\n> be obvious from a \"simple\" parsing of the tx.\n>\n> Cheers,\n> aj\n>\n>\nI don't think we have this property as is.\n\nE.g. consider the transaction:\n\nTX:\n   locktime: None\n   sequence: 100\n   scriptpubkey: 101 CSV\n\nHow will you tell it is able to be included without running the script?\n\nI agree this is a useful property, but I don't think we can do it\npractically.\n\nWhat's nice is the transaction in this form cannot go from invalid to valid\n-- once invalid it is always invalid for a given UTXO.\n\nsequence tagged keys have this property -- a txn is either valid or invalid\nand that never changes w/o any external information needing to be passed up.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210712/d6b5a929/attachment.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2021-07-14T03:32:00",
                "message_text_only": "On Mon, Jul 12, 2021 at 03:07:29PM -0700, Jeremy wrote:\n>     Perhaps there's a more general principle -- evaluating a script should\n>     only return one bit of info: \"bool tx_is_invalid_script_failed\"; every\n>     other bit of information -- how much is paid in fees (cf ethereum gas\n>     calculations), when the tx is final, if the tx is only valid in some\n>     chain fork, if other txs have to have already been mined / can't have\n>     been mined, who loses funds and who gets funds, etc... -- should already\n>     be obvious from a \"simple\" parsing of the tx.\n> I don't think we have this property as is.\n> E.g. consider the transaction:\n> TX:\n> \u00a0 \u00a0locktime: None\n> \u00a0 \u00a0sequence: 100\n> \u00a0 \u00a0scriptpubkey: 101 CSV\n\nThat tx will never be valid, no matter the state of the chain -- even if\nit's 420 blocks after the utxo it's spending: it fails because \"top stack\nitem is greater than the transaction input sequence\" rule from BIP 112.\n\n> How will you tell it is able to be included without running the script?\n\nYou have to run the script at some point, but you don't need to run the\nscript to differentiate between it being valid on one chain vs valid on\nsome other chain.\n\n> What's nice is the transaction in this form cannot go from invalid to valid --\n> once invalid it is always invalid for a given UTXO.\n\nHuh? Timelocks always go from invalid to valid -- they're invalid prior\nto some block height (IsFinal() returns false), then valid after.\n\nNot going from valid to invalid is valuable because it limits the cases\nwhere you have to remove txs (and their descendents) from the mempool.\n\nCheers,\naj"
            }
        ],
        "thread_summary": {
            "title": "Eltoo / Anyprevout & Baked in Sequences",
            "categories": [
                "bitcoin-dev",
                "Lightning-dev"
            ],
            "authors": [
                "Anthony Towns",
                "Jeremy"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 5831
        }
    },
    {
        "title": "[bitcoin-dev] A Stroll through Fee-Bumping Techniques : Input-Based vs Child-Pay-For-Parent",
        "thread_messages": [
            {
                "author": "Anthony Towns",
                "date": "2021-07-08T11:17:16",
                "message_text_only": "On Thu, May 27, 2021 at 04:14:13PM -0400, Antoine Riard via bitcoin-dev wrote:\n> This overhead could be smoothed even further in the future with more advanced\n> sighash malleability flags like SIGHASH_IOMAP, allowing transaction signers to\n> commit to a map of inputs/outputs [2]. In the context of input-based, the\n> overflowed fee value could be redirected to an outgoing output.\n\n> Input-based (SIGHASH_ANYPREVOUT+SIGHASH_IOMAP): Multiple chains of transactions\n> might be aggregated together *non-interactively*. One bumping input and\n> outgoing output can be attached to the aggregated root.\n\n> [2] https://bitcointalk.org/index.php?topic=252960.0\n\nI haven't seen any recent specs for \"IOMAP\", but there are a few things\nthat have bugged me about them in the past:\n\n (1) allowing partially overlapping sets of outputs could allow \"theft\",\n     eg if I give you a signature \"you can spend A+B as long as I get X\"\n     and \"you can spend A+C as long as I get X\", you could combine them\n     to spend A+B+C instead but still only give me 1 X.\n\n (2) a range specification or a whole bitfield is a lot heavier than an\n     extra bit to add to the sighash\n\n (3) this lets you specify lots of different ways of hashing the\n     outputs, which then can't be cached, so you get kind-of quadratic\n     behaviour -- O(n^2/8) where n/2 is the size of the inputs, which\n     gives you the number of signatures, and n/2 is also the size of the\n     outputs, so n/4 is a different half of the output selected for each\n     signature in the input.\n\nBut under the \"don't bring me problems, bring me solutions\" banner,\nhere's an idea.\n\nThe easy way to avoid O(n^2) behaviour in (3) is to disallow partial\noverlaps. So let's treat the tx as being distinct bundles of x-inputs\nand y-outputs, and we'll use the annex for grouping, since that is\ncommitted to by singatures. Call the annex field \"sig_group_count\".\n\nWhen processing inputs, setup a new state pair, (start, end), initially\n(0,0).\n\nWhen evaluating an input, lookup sig_group_count. If it's not present,\nthen set start := end. If it's present and 0, leave start and end\nunchanged. Otherwise, if it's present and greather than 0, set\nstart := end, and then set end := start + sig_group_count.\n\nIntroduce a new SIGHASH_GROUP flag, as an alternative to ALL/SINGLE/NONE,\nthat commits to each output i, start <= i < end. If start==end or end >\nnum_outputs, signature is invalid.\n\nThat means each output in a tx could be hashed three times instead of\ntwice (once for its particular group, as well as once for SIGHASH_ALL\nand once for SIGHASH_SINGLE), and I think would let you combine x-input\nand y-outputs fairly safely, by having the first input commit to \"y\"\nin the annex, and the remaining x-1 commit to \"0\".\n\nThat does mean if you have two different sets of inputs (x1 and x2)\neach spending to the exact same set of y outputs, you could claim all\nbut one of them while only paying a single set of y outputs. But you\ncould include an \"OP_RETURN hash(x1)\" tapleaf branch in one of the y\noutputs to ensure the outputs aren't precisely the same to avoid that\nproblem, so maybe that's fine?\n\nOkay, now that I've written and re-written that a couple of times,\nit looks like I'm just reinventing Rusty's signature bundles from 2018:\n\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-April/015862.html\n\n(though at least I think using the annex is probably an improvement on\nhaving values that affect other inputs being buried deeper in an input's\nwitness data)\n\n\n\nWithout something like this, I think it will be very hard to incorporate\nfees into eltoo with layered commitments [0]. As a new sighash mode it\nwould make sense to include it as part of ANYPREVOUT to avoid introducing\nmany new \"unknown key types\".\n\n[0] https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-January/002448.html\n    also, https://www.erisian.com.au/lightning-dev/log-2021-07-08.html\n\nCheers,\naj"
            },
            {
                "author": "Antoine Riard",
                "date": "2021-07-09T13:19:45",
                "message_text_only": "On Thu, May 27, 2021 at 04:14:13PM -0400, Antoine Riard via bitcoin-dev\nwrote:\n> This overhead could be smoothed even further in the future with more\nadvanced\n> sighash malleability flags like SIGHASH_IOMAP, allowing transaction\nsigners to\n> commit to a map of inputs/outputs [2]. In the context of input-based, the\n> overflowed fee value could be redirected to an outgoing output.\n\n> Input-based (SIGHASH_ANYPREVOUT+SIGHASH_IOMAP): Multiple chains of\ntransactions\n> might be aggregated together *non-interactively*. One bumping input and\n> outgoing output can be attached to the aggregated root.\n\n> [2] https://bitcointalk.org/index.php?topic=252960.0\n\n> I haven't seen any recent specs for \"IOMAP\", but there are a few things\n> that have bugged me about them in the past:\n\nTBH, I don't think we have been further with Darosior than comparing the\ncompression schemes relevant for the bitfield :)\n\nThanks to start the hard grinding work!\n\n>  (1) allowing partially overlapping sets of outputs could allow \"theft\",\n>      eg if I give you a signature \"you can spend A+B as long as I get X\"\n>      and \"you can spend A+C as long as I get X\", you could combine them\n>      to spend A+B+C instead but still only give me 1 X.\n\nYes I think there is an even more unsafe case than described. A transaction\nthird-party knowledgeable about the partial sets could combine them, then\nattach an additional siphoning output Y. E.g, if {A=50, B=50, C=50} and\nX=100 the third-party could attach output Y=50 ?\n\nThough I believe the validity of those thefts are a function of further\nspecification of the transaction digest coverage, as you might have a\nmalleability scheme where B or C's signatures hash are implicitly\ncommitting to subset inputs order. If you have `H_prevouts(A || B)` and\n`H_prevouts(A || C)`, an attacker wouldn't be able to satisfy both B and C\nscripts in the same transaction ?\n\nOne mitigation which was mentioned in previous pinning discussion was to\nadd a per-participant finalizing key to A's script and thus lockdown\ntransaction template at broadcast. I don't think it works here as you can't\nassume that your counterparties, from different protocol sessions, won't\ncollude together to combine their finalizing signatures and achieve a spend\nreplay across sessions ?\n\nThat said, I'm not even sure we should disallow partially overlapping sets\nof outputs at the consensus-level, one could imagine a crowdfunding\napplication where you delegate A+B and A+C to different parties, and you\nimplicitly allow them to cooperate as long as they fulfill X's output value\n?\n\n>  (2) a range specification or a whole bitfield is a lot heavier than an\n>      extra bit to add to the sighash\n\nYes, one quick optimization in case of far-depth output committed in the\nbitfield could be to have a few initial bits serving as vectors to blank\nout unused bitfield spaces. Though I concede a new sighash bits arithmetic\nmight be too fancy for consensus-code.\n\n\n>  (3) this lets you specify lots of different ways of hashing the\n>      outputs, which then can't be cached, so you get kind-of quadratic\n>      behaviour -- O(n^2/8) where n/2 is the size of the inputs, which\n>      gives you the number of signatures, and n/2 is also the size of the\n>      outputs, so n/4 is a different half of the output selected for each\n>      signature in the input.\n\nIf you assume n size of transaction data, and that each signature hash is\ncommitting to inputs + half of outputs, yes I think it's even worst kind-of\nquadratic, like O(3n^2/4) ? And you might even worsen the hashing in\nfunction of flexibility allowed, like still committing to the whole\ntransaction size but a different combination order of outputs selected for\neach signature.\n\nBut under the \"don't bring me problems, bring me solutions\" banner, here's\nan idea.\n\n> The easy way to avoid O(n^2) behaviour in (3) is to disallow partial\n> overlaps. So let's treat the tx as being distinct bundles of x-inputs\n> and y-outputs, and we'll use the annex for grouping, since that is\n> committed to by singatures. Call the annex field \"sig_group_count\".\n\n> When processing inputs, setup a new state pair, (start, end), initially\n> (0,0).\n>\n> When evaluating an input, lookup sig_group_count. If it's not present,\n> then set start := end. If it's present and 0, leave start and end\n> unchanged. Otherwise, if it's present and greather than 0, set\n> start := end, and then set end := start + sig_group_count.\n\nIIUC the design rationale, the \"sig_group_count\" lockdowns the hashing of\noutputs for a given input, thus allowing midstate reuse across signatures\ninput.\n\n> Introduce a new SIGHASH_GROUP flag, as an alternative to ALL/SINGLE/NONE,\n> that commits to each output i, start <= i < end. If start==end or end >\n> num_outputs, signature is invalid.\n>\n> That means each output in a tx could be hashed three times instead of\n> twice (once for its particular group, as well as once for SIGHASH_ALL\n> and once for SIGHASH_SINGLE), and I think would let you combine x-input\n> and y-outputs fairly safely, by having the first input commit to \"y\"\n> in the annex, and the remaining x-1 commit to \"0\".\n>\n> That does mean if you have two different sets of inputs (x1 and x2)\n> each spending to the exact same set of y outputs, you could claim all\n> but one of them while only paying a single set of y outputs. But you\n> could include an \"OP_RETURN hash(x1)\" tapleaf branch in one of the y\n> outputs to ensure the outputs aren't precisely the same to avoid that\n> problem, so maybe that's fine?\n\nIf the index i is absolute w.r.t to the transaction output index, I think\nthis design might have a shortcoming.\n\nLet's say you want to combine {x_1, y_1} and {x_2, y_2} where {x, y}\ndenotes bundles of Lightning commitment transactions.\n\nx_1 is dual-signed by Alice and Bob under the SIGHASH_GROUP flag with\n`sig_group_count`=3.\nx_2 is dual-signed by Alice and Caroll under the SIGHASH_GROUP flag, with\n`sig_group_count`=2.\ny_1 and y_2 are disjunctive.\n\nAt broadcast, Alice is not able to combine {x_1,y_1} and {x_2, y_2} for the\nreason that x_1, x_2 are colliding on the absolute output position.\n\nOne fix could be to skim the \"end > num_ouputs\" semantic, and thus have\nAlice negotiate (start,end) encompassing all her channels outputs index and\nthen strictly ordering her i indexes on all her counterparties. But I don't\nthink you can assume index order to be transitive across Lightning nodes,\nat least without bundle combination gaps in your local set of channels.\n\nI think this SIGHASH_GROUP proposal might solve other use-cases, but if I\nunderstand the semantics correctly, it doesn't seem to achieve the batch\nfee-bumping of multiple Lightning commitment with O(1) onchain footprint I\nwas thinking of for IOMAP...\n\nOne counter-proposal to solve this \"pre-signed y-outputs ordinate\" could be\ninstead to envision the SIGHASH_GROUP as vector coordinates and the annex\nfield as the projection.\n\nLet's say annex field := (hashOutputsGroups) and SIGHASH_GROUP(i,j) where j\nis a non-null integer.\nCall i the starting index of the output group committed by this input.\nCall j the output group size committed by this input.\n\nAt validation, compute `hashOutputsGroup` = H(outputs[i...i+j-1]).\nIf the computed `hashOutputGroup` isn't equal to the input annex field\n`hashOutputsGroup`, fails validation.\nOtherwise, substitute `hashOutputGroup` to bip-143 `hashOutputs` while\nconserving , and proceed to signature verification.\n\nAs (i,j) are not included in the annex and are only part of witness data,\nthey can be selected by the bundles combiner at broadcast to construct a\nvalid transaction.\n\nIf the combiner is malicious and (i,j) points to another outputs group, the\ncomputed hash is going to be invalid, as it doesn't satisfy the annex\n`output_group` field.\n\nIf you want to disallow partial overlaps for your bundle, we could even\nhave a bit k. If k=1, verify that all transaction `output_group` fields are\nnot colliding.\n\nHmmmm, sounds more flexible but you might still have a bit of hashing\ncomplexity to deal with ?\n\n> Okay, now that I've written and re-written that a couple of times,\n> it looks like I'm just reinventing Rusty's signature bundles from 2018:\n>\n>\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-April/015862.html\n>\n> (though at least I think using the annex is probably an improvement on\n> having values that affect other inputs being buried deeper in an input's\n> witness data)\n>\n> Without something like this, I think it will be very hard to incorporate\n> fees into eltoo with layered commitments [0]. As a new sighash mode it\n> would make sense to include it as part of ANYPREVOUT to avoid introducing\n> many new \"unknown key types\".\n\nWell, I agree on the overall direction though maybe we should detail\nprimitive requirements a bit more, otherwise it might not fit the\nsecond-layer use-case we're interested with.\n\nCheers,\nAntoine\n\nLe jeu. 8 juil. 2021 \u00e0 07:17, Anthony Towns <aj at erisian.com.au> a \u00e9crit :\n\n> On Thu, May 27, 2021 at 04:14:13PM -0400, Antoine Riard via bitcoin-dev\n> wrote:\n> > This overhead could be smoothed even further in the future with more\n> advanced\n> > sighash malleability flags like SIGHASH_IOMAP, allowing transaction\n> signers to\n> > commit to a map of inputs/outputs [2]. In the context of input-based, the\n> > overflowed fee value could be redirected to an outgoing output.\n>\n> > Input-based (SIGHASH_ANYPREVOUT+SIGHASH_IOMAP): Multiple chains of\n> transactions\n> > might be aggregated together *non-interactively*. One bumping input and\n> > outgoing output can be attached to the aggregated root.\n>\n> > [2] https://bitcointalk.org/index.php?topic=252960.0\n>\n> I haven't seen any recent specs for \"IOMAP\", but there are a few things\n> that have bugged me about them in the past:\n>\n>  (1) allowing partially overlapping sets of outputs could allow \"theft\",\n>      eg if I give you a signature \"you can spend A+B as long as I get X\"\n>      and \"you can spend A+C as long as I get X\", you could combine them\n>      to spend A+B+C instead but still only give me 1 X.\n>\n>  (2) a range specification or a whole bitfield is a lot heavier than an\n>      extra bit to add to the sighash\n>\n>  (3) this lets you specify lots of different ways of hashing the\n>      outputs, which then can't be cached, so you get kind-of quadratic\n>      behaviour -- O(n^2/8) where n/2 is the size of the inputs, which\n>      gives you the number of signatures, and n/2 is also the size of the\n>      outputs, so n/4 is a different half of the output selected for each\n>      signature in the input.\n>\n> But under the \"don't bring me problems, bring me solutions\" banner,\n> here's an idea.\n>\n> The easy way to avoid O(n^2) behaviour in (3) is to disallow partial\n> overlaps. So let's treat the tx as being distinct bundles of x-inputs\n> and y-outputs, and we'll use the annex for grouping, since that is\n> committed to by singatures. Call the annex field \"sig_group_count\".\n>\n> When processing inputs, setup a new state pair, (start, end), initially\n> (0,0).\n>\n> When evaluating an input, lookup sig_group_count. If it's not present,\n> then set start := end. If it's present and 0, leave start and end\n> unchanged. Otherwise, if it's present and greather than 0, set\n> start := end, and then set end := start + sig_group_count.\n>\n> Introduce a new SIGHASH_GROUP flag, as an alternative to ALL/SINGLE/NONE,\n> that commits to each output i, start <= i < end. If start==end or end >\n> num_outputs, signature is invalid.\n>\n> That means each output in a tx could be hashed three times instead of\n> twice (once for its particular group, as well as once for SIGHASH_ALL\n> and once for SIGHASH_SINGLE), and I think would let you combine x-input\n> and y-outputs fairly safely, by having the first input commit to \"y\"\n> in the annex, and the remaining x-1 commit to \"0\".\n>\n> That does mean if you have two different sets of inputs (x1 and x2)\n> each spending to the exact same set of y outputs, you could claim all\n> but one of them while only paying a single set of y outputs. But you\n> could include an \"OP_RETURN hash(x1)\" tapleaf branch in one of the y\n> outputs to ensure the outputs aren't precisely the same to avoid that\n> problem, so maybe that's fine?\n>\n> Okay, now that I've written and re-written that a couple of times,\n> it looks like I'm just reinventing Rusty's signature bundles from 2018:\n>\n>\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-April/015862.html\n>\n> (though at least I think using the annex is probably an improvement on\n> having values that affect other inputs being buried deeper in an input's\n> witness data)\n>\n>\n>\n> Without something like this, I think it will be very hard to incorporate\n> fees into eltoo with layered commitments [0]. As a new sighash mode it\n> would make sense to include it as part of ANYPREVOUT to avoid introducing\n> many new \"unknown key types\".\n>\n> [0]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-January/002448.html\n>     also, https://www.erisian.com.au/lightning-dev/log-2021-07-08.html\n>\n> Cheers,\n> aj\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210709/b5a0db96/attachment-0001.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2021-07-10T01:47:32",
                "message_text_only": "On Fri, Jul 09, 2021 at 09:19:45AM -0400, Antoine Riard via bitcoin-dev wrote:\n> > The easy way to avoid O(n^2) behaviour in (3) is to disallow partial\n> > overlaps. So let's treat the tx as being distinct bundles of x-inputs\n> > and y-outputs, and we'll use the annex for grouping, since that is\n> > committed to by singatures. Call the annex field \"sig_group_count\".\n> > When processing inputs, setup a new state pair, (start, end), initially\n> > (0,0).\n> > When evaluating an input, lookup sig_group_count. If it's not present,\n> > then set start := end. If it's present and 0, leave start and end\n> > unchanged. Otherwise, if it's present and greather than 0, set\n> > start := end, and then set end := start + sig_group_count.\n> IIUC the design rationale, the \"sig_group_count\" lockdowns the hashing of\n> outputs for a given input, thus allowing midstate reuse across signatures\n> input.\n\nNo midstates, the message being signed would just replace\nSIGHASH_SINGLE's:\n\n  sha_single_output: the SHA256 of the corresponding output in CTxOut\n  format\n\nwith\n\n  sha_group_outputs: the SHA256 of the serialization of the group\n  outputs in CTxOut format.\n\nie, you'd take span<CTxOut>{start,end}, serialize it (same as if it were\na vector of just those CTxOuts), and sha256 it.\n\n> Let's say you want to combine {x_1, y_1} and {x_2, y_2} where {x, y} denotes\n> bundles of Lightning commitment transactions.\n> x_1 is dual-signed by Alice and Bob under the SIGHASH_GROUP flag with\n> `sig_group_count`=3.\n> x_2 is dual-signed by Alice and Caroll under the SIGHASH_GROUP flag, with\n> `sig_group_count`=2.\n> y_1 and y_2 are disjunctive.\n> At broadcast, Alice is not able to combine {x_1,y_1} and {x_2, y_2} for the\n> reason that x_1, x_2 are colliding on the absolute output position.\n\nSo the sha256 of the span of the group doesn't commit to start and end\n-- it just serializes a vector, so commits to the number of elements,\nthe order, and the elements themselves. So you're taking serialize(y_1)\nand serialize(y_2), and each of x_1 signs against the former, and each\nof x_2 signs against the latter.\n\n(Note that the annex for x_1_0 specifies sig_group_count=len(y_1)\nand the annex for x_1_{1..} specifies sig_group_count=0, for \"reuse\nprevious input's group\", and the signatures for each input commit to\nthe annex anyway)\n\n> One fix could be to skim the \"end > num_ouputs\" semantic,\n\nThat's only there to ensure the span doesn't go out of range, so I don't\nthink it makes any sense to skip it?\n\n> I think this SIGHASH_GROUP proposal might solve other use-cases, but if I\n> understand the semantics correctly, it doesn't seem to achieve the batch\n> fee-bumping of multiple Lightning commitment with O(1) onchain footprint I was\n> thinking of for IOMAP...\n\nDoes the above resolve that?\n\nCheers,\naj"
            },
            {
                "author": "Antoine Riard",
                "date": "2021-07-12T00:02:12",
                "message_text_only": "> So the sha256 of the span of the group doesn't commit to start and end\n> -- it just serializes a vector, so commits to the number of elements,\n> the order, and the elements themselves.\n\nGotcha wasn't clear to me that the new state pair isn't committed as part\nof the annex.\n\nHave been confused by \"Introduce a new SIGHASH_GROUP flag, as an\nalternative to ALL/SINGLE/NONE, that commits to each output i, start <= i <\nend.\"\n\n> Does the above resolve that?\n\nI think so. It shouldn't be susceptible to any spend replay attack, as the\nstate pair prevents output group overlapping though you might still have to\nbe careful about siphoning ? Something you should already care about if you\nuse SIGHASH_SINGLE and your x's amount > y's value.\n\nLe ven. 9 juil. 2021 \u00e0 21:47, Anthony Towns <aj at erisian.com.au> a \u00e9crit :\n\n> On Fri, Jul 09, 2021 at 09:19:45AM -0400, Antoine Riard via bitcoin-dev\n> wrote:\n> > > The easy way to avoid O(n^2) behaviour in (3) is to disallow partial\n> > > overlaps. So let's treat the tx as being distinct bundles of x-inputs\n> > > and y-outputs, and we'll use the annex for grouping, since that is\n> > > committed to by singatures. Call the annex field \"sig_group_count\".\n> > > When processing inputs, setup a new state pair, (start, end), initially\n> > > (0,0).\n> > > When evaluating an input, lookup sig_group_count. If it's not present,\n> > > then set start := end. If it's present and 0, leave start and end\n> > > unchanged. Otherwise, if it's present and greather than 0, set\n> > > start := end, and then set end := start + sig_group_count.\n> > IIUC the design rationale, the \"sig_group_count\" lockdowns the hashing of\n> > outputs for a given input, thus allowing midstate reuse across signatures\n> > input.\n>\n> No midstates, the message being signed would just replace\n> SIGHASH_SINGLE's:\n>\n>   sha_single_output: the SHA256 of the corresponding output in CTxOut\n>   format\n>\n> with\n>\n>   sha_group_outputs: the SHA256 of the serialization of the group\n>   outputs in CTxOut format.\n>\n> ie, you'd take span<CTxOut>{start,end}, serialize it (same as if it were\n> a vector of just those CTxOuts), and sha256 it.\n>\n> > Let's say you want to combine {x_1, y_1} and {x_2, y_2} where {x, y}\n> denotes\n> > bundles of Lightning commitment transactions.\n> > x_1 is dual-signed by Alice and Bob under the SIGHASH_GROUP flag with\n> > `sig_group_count`=3.\n> > x_2 is dual-signed by Alice and Caroll under the SIGHASH_GROUP flag, with\n> > `sig_group_count`=2.\n> > y_1 and y_2 are disjunctive.\n> > At broadcast, Alice is not able to combine {x_1,y_1} and {x_2, y_2} for\n> the\n> > reason that x_1, x_2 are colliding on the absolute output position.\n>\n> So the sha256 of the span of the group doesn't commit to start and end\n> -- it just serializes a vector, so commits to the number of elements,\n> the order, and the elements themselves. So you're taking serialize(y_1)\n> and serialize(y_2), and each of x_1 signs against the former, and each\n> of x_2 signs against the latter.\n>\n> (Note that the annex for x_1_0 specifies sig_group_count=len(y_1)\n> and the annex for x_1_{1..} specifies sig_group_count=0, for \"reuse\n> previous input's group\", and the signatures for each input commit to\n> the annex anyway)\n>\n> > One fix could be to skim the \"end > num_ouputs\" semantic,\n>\n> That's only there to ensure the span doesn't go out of range, so I don't\n> think it makes any sense to skip it?\n>\n> > I think this SIGHASH_GROUP proposal might solve other use-cases, but if I\n> > understand the semantics correctly, it doesn't seem to achieve the batch\n> > fee-bumping of multiple Lightning commitment with O(1) onchain footprint\n> I was\n> > thinking of for IOMAP...\n>\n> Does the above resolve that?\n>\n> Cheers,\n> aj\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210711/87c953b3/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "A Stroll through Fee-Bumping Techniques : Input-Based vs Child-Pay-For-Parent",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Anthony Towns",
                "Antoine Riard"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 23875
        }
    },
    {
        "title": "[bitcoin-dev] Taproot Fields for PSBT",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2021-07-08T20:06:08",
                "message_text_only": "Suggestion:\n\nIt should be allowed that different keys can specify different sighash\nflags.\n\nAs an example, if chaperone signatures were desired with anyprevout, it\nwould be required to specify that the anyprevout key sign with APO and the\nchaperone sign with ALL. As another example, Sapio emulator oracles sign\nwith SIGHASH_ALL whereas other signatories might be instructed to sign with\na different flag.\n\nThe current sighashtype key is per-input:\n- If a sighash type is provided, the signer must check that the sighash is\nacceptable. If unacceptable, they must fail.\n- If a sighash type is not provided, the signer should sign using\nSIGHASH_ALL, but may use any sighash type they wish.\n\nSo a new per-key mapping can be added safely.\n\nI have no strong opinions on the format for said per-key sighash hints.\n\nWhy do this now? Well, I requested it when spec'ing V2 as well, but it\nwould be nice to get it spec'd and implemented.\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Mon, Jun 28, 2021 at 1:32 PM Salvatore Ingala via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Andrew,\n>\n> Thanks for the clarification, I was indeed reading it under the mistaken\n> assumption that only one leaf would be added to the PSBT.\n>\n> En passant, for the less experienced readers, it might be helpful if the\n> key types that are possibly present multiple times (with different keydata)\n> were somehow labeled in the tables.\n>\n> Best,\n> Salvatore Ingala\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210708/d6ecda51/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Taproot Fields for PSBT",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1874
        }
    },
    {
        "title": "[bitcoin-dev] BIP-118 / SigHash \"what's covered\" Cheatsheet",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2021-07-10T00:11:58",
                "message_text_only": "As a part of my ongoing review of BIP-118 I put together the following\nchart.\n\nSource:\nhttps://docs.google.com/spreadsheets/d/1KeWJ_cly9zoRX5_h70RTniRT2m8_iaVceK_aF6obWeM\n\nNot tightly checked to be free of errors, but I figured such a chart would\nbe helpful for folks evaluating BIP-118.\n\nPerhaps the BIPs (generally, incl 34x) could be updated to present the\ninformation in such a chart -- at least for me it's much clearer than\nfollowing a bunch of conditional logic (maybe if there's ever desire for\nsome consensus refactoring this could be a table in the code replacing the\ncond logic).\n\n[image: image.png]\n\nA few highlighted nuances:\n\n- input index is never signed (i previously thought one mode signed it).\nKey reuse under APOAS|Default and APOAS|All is a bit extra unsafe given\nsusceptibility to the \"half-spend\" problem. This limits usability of APO\nfor covenants a-la CTV because you can't stop someone from adding inputs to\nyour contract nor can you prevent half-spend problems when reusing\naddresses.\n- APO signs the Amounts, APOAS never does.\n- APO signs both the SPK and the Tapleaf hash, meaning that APO binds\nitself to the entire script rather than just it's fragment. There's no\nsetting which is \"just this fragment\"\n- APO's signature binds it to a specific script fragment *within* a taproot\nkey, but not a specific script path\n- the flag \"default\" is not really a flag at all -- when default is used\n(as a or'd byte) there are different results than when default is inferred\n(by absence of a byte) (this is maybe a bitcoin core specific quirk).\n- There are 16 different possible modes total, so all combinations of flags\nmean *something* (advisable or not as with ACP | None)\n- | Default and | All overlap, so there's an opportunity to either reserve\nor assign 4 additional sighash modes if desired. These could cover some of\nthe gaps above, or be saved for future purposes rather than be wasted now.\nAnother point of interest is -- not to rock the boat -- but because BIP-118\nis defining a new key type we could do away with the notion that sighash\nflags are \"flags\" and convert to an enum (e.g., numbered 0-256 for whatever\ncombination of fields each would incur) and give each signature type a\nsensible name, rather than thinking of things as a combo of flags (e.g.,\nAPOAS is not some intersection of what APO and ACP do independently).\n\nHopefully this helps!\n\nCheers,\n\nJeremy\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210709/620c1d70/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: image.png\nType: image/png\nSize: 1104237 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210709/620c1d70/attachment-0001.png>"
            }
        ],
        "thread_summary": {
            "title": "BIP-118 / SigHash \"what's covered\" Cheatsheet",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2933
        }
    },
    {
        "title": "[bitcoin-dev] An idea to block invalid addresses from reaching the peers.dat buckets",
        "thread_messages": [
            {
                "author": "Ali Sherief",
                "date": "2021-07-12T23:33:16",
                "message_text_only": "This is an interesting read: https://bitcointalk.org/index.php?topic=5348856.0\n\nSo according to this, somebody is spamming the bitcoin network with addr message pointing to invalid addresses and ports, which bloats the peers.dat and corresponding structure in memory.\n\nSince peers.dat uses a custom record type which I don't know how to parse, I wasn't able to check specifics of IP addresses listed in there, but I believe I have a workaround to prevent this kind of thing from happening. Exactly how easy or difficult it will be to implement this change I don't know.\n\n- Change the AddrDb updating functionality so that it does not add nodes that are unreachable. Not unreachable by timeout, but \"connection refused\" kind of errors.\n\nSuch addresses can either be stored in a new, separate database-like file such as \"ignore.dat\", or they can be augmented in the peers.dat file under a new entry type (I'm not sure if this is even possible). In both cases the invalid nodes can be immediately flushed from memory to avoid processing them.\n\n-- This is only done the first time the node is seen in the wild. To avoid blocking nodes which happened to go offline, the check won't be made if it's already in the buckets. So it won't clean up an attack like this (meaning peers.dat files have to be recreated to fix this) but it will prevent another in the future.\n\n- In order to facilitate other nodes discovering blocked nodes, a new ZMQ message can be made that sends the node's list of ignored addresses. Since I haven't used ZMQ much I don't know the specifics of how to do this.\n\n- Introduce a new file or command-line/config option called \"ignorelist\" or something with a list of subnets that will *not* be read into the AddrDB buckets in any case.\n\nIt will work differently from the banlist, whose primary job is to block peers that send invalid messages, not peers that are not, and cannot, be unreachable in the first place.\n\n- Ali Sherief\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210712/0c857f86/attachment.html>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2021-07-13T00:54:29",
                "message_text_only": "> This is an interesting read: https://bitcointalk.org/index.php?topic=5348856.0\n>\n> So according to this, somebody is spamming the bitcoin network with addr message pointing to invalid addresses and ports, which bloats the peers.dat and corresponding structure in memory.\n\nThe peers.dat file and the structure in memory have a fixed size, so those are not a problem.\n\n> Since peers.dat uses a custom record type which I don't know how to parse, I wasn't able to check specifics of IP addresses listed in there, but I believe I have a workaround to prevent this kind of thing from happening. Exactly how easy or difficult it will be to implement this change I don't know.\n\nThe \"addrman\" database is organized into 1024 buckets with \"new\" addresses (which we haven't tried to connect to), and 256 buckets with \"tried\" addresses (which we have connected to ourselves). Each bucket consists of 64 positions, and each of those can hold 1 address. Along with the addresses we remember where we originally heard about them (which IP).\n\nEach group of source IPs (/16s etc) selects a subset of just 64 buckets (salted using a host-specific secret key), and inserts the newly received IPs in a position in a bucket in one of those, if certain criteria are met (the position was empty, or it held an IP address that also occurs elsewhere in the table already). This limits the impact an attacker can have, because they cannot under any circumstances affect IPs in buckets outside of the 64 their group maps to.\n\nThis database structure is a design from 2012, which was significantly improved following recommendations in the Eclipse Attacks paper (https://cs-people.bu.edu/heilman/eclipse/).\n\n> - Change the AddrDb updating functionality so that it does not add nodes that are unreachable. Not unreachable by timeout, but \"connection refused\" kind of errors.\n\nIn a way we have that; there are separate tables in peers.dat for new and tried addresses. I don't think it's feasible to not add untried addresses at all, as our ability to create connections is far too low to try everything we receive. But I think the existing structure should reasonably protect against spam (in terms of database poisoning; there is certainly a processing cost to it).\n\nCheers,\n\n--\nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210713/a19693ad/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "An idea to block invalid addresses from reaching the peers.dat buckets",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Ali Sherief",
                "Pieter Wuille"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 4574
        }
    },
    {
        "title": "[bitcoin-dev] Travel rule, VASP UID and bitcoin URI - A new BIP",
        "thread_messages": [
            {
                "author": "Karel Kyovsky",
                "date": "2021-07-16T14:35:21",
                "message_text_only": "Hi There,\nI would like to propose a standardization of the bitcoin URI parameter name\nthat could be optionally used to contain the unique id of VASP (Virtual\nasset service provider as defined by FATF) hosting the user's wallet\naddress.\nMy question is: Should I prepare a completely new BIP or should I prepare a\nmodification of BIP21?\nBIP21 status is FINAL so I guess it should be a completely new BIP that\nwould just extend the BIP21. I'm looking for confirmation of this approach.\nThank you for answering that.\n\nPlease let's NOT start a discussion whether the FATF travel rule is a good\nthing or not. This could derail my initial question.\n\nBackground:\nWe are going to be soon working on travel rule integration for our Bitcoin\nATM product.\nThe current user scenario is that the user shows on his phone QR code to\nthe ATM with bitcoin URI containing an address, inserts cash and walks away\nwith BTC arriving to his wallet.\n\nIn a Travel Rule compliant scenario the ATM operator must perform the \"best\neffort\" to find out who(VASP) is hosting the user's wallet, contact such\nVASP and send VASP customer identity data. This can be achieved by:\n\na) ATM contacting every possible known VASP that is travel rule compliant\nvia some platform and ask him whether the address read from the QR code\nbelongs to him. Such search could be done also with bloom filter to protect\nthe privacy of a user. But of course this is very far from ideal.\n\nor\n\nb) ATM could use blockchain analytics tools to find who might be serving\nthis wallet (major exchange etc). If the wallet address is empty prior to\nthe purchase on the ATM this address would have to be monitored for some\ntime to find out if it doesn't fall into some exchange's(VASP) cluster and\nthat would have to be later contacted.\n\nor\n\nc) User will choose from the list of VASPs on the ATM screen to match his\nwallet provider(imagine phonebook with search field - terrible). Most\npeople will select irrelevant VASP because they will not be willing to\nspend time to search VASP's name on the screen.\n\nor\n\nd) The user could enable in settings of their mobile wallet that VASP UID\nwould be provided in URI as one of the parameters so that Bitcoin ATM\noperator will not have to search for VASP and could communicate with VASP\nimmediately after scanning URI from QR code. In such a case options a) or\nb) or c) would not have to be performed and user experience for ATM users\nwould stay the same as before travel rule compliance. In order to achieve\nthis all wallet providers need to use the same parameter name in URI so\nthat ATM will read this parameter - standardization of this parameter name\nis the purpose of proposed new BIP.\n\nVASP UID could be also a public key that could be used to encrypt the\ncustomer's identity information before sending it to wallet provider VASP\nfrom the bitcoin ATM. Directory of VASP UIDs, how VASP could be contacted,\nmethod of transfer when one knows VASP UID should be all outside of scope\nof this BIP. I expect this to be covered by 3rd party\ntools/platforms/regulators.\n\nBitcoin ATM operators want to stay in business and for that they need to\nstay compliant with US regulation. Therefore they ask us to improve our\nproducts to comply with the FATF-Travel Rule.\nThe same probably applies to US custodian wallet service providers so I\nenvision that the majority of custodian wallets offered on Appstore/Google\nplay in the US would provide their VASP UID in bitcoin URI as a new default\nwith an option for users to turn it off.\n\nPlease note that Travel Rule doesn't apply for unhosted(non-custodian)\nwallets.\n\nThank you,\nKarel Kyovsky\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210716/51c92af6/attachment.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2021-07-16T21:42:16",
                "message_text_only": "On Fri, Jul 16, 2021 at 04:35:21PM +0200, Karel Kyovsky via bitcoin-dev wrote:\n> I would like to propose a standardization of [a new] bitcoin URI parameter name\n> [...]\n> My question is: Should I prepare a completely new BIP or should I prepare a\n> modification of BIP21?\n\nPlease use a new BIP.  See BIP72 for a previous instance where another\nURI parameter for BIP21 was standardized.\nhttps://github.com/bitcoin/bips/blob/master/bip-0072.mediawiki\n\n(I think your compliance situation is mostly off topic for this list, so\nI'm not commenting on that.)\n\n-Dave\n\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210716/7e4e83e1/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Travel rule, VASP UID and bitcoin URI - A new BIP",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Karel Kyovsky",
                "David A. Harding"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 4621
        }
    },
    {
        "title": "[bitcoin-dev] Online discussion on Taproot roll out - Tuesday July 20th 17:15 UTC",
        "thread_messages": [
            {
                "author": "Michael Folkson",
                "date": "2021-07-17T13:16:19",
                "message_text_only": "Hi\n\nThere is an online Zoom call (also livestreamed on YouTube) on Tuesday\nJuly 20th at 17:15 UTC discussing Taproot roll out post activation in\nNovember. It will be focused at developers and so discussion will be\ntechnical but all are welcome to attend/watch.\n\nMurch has this wiki page monitoring planned ecosystem support of P2TR\naddresses and it would be great to hear from projects and businesses\nthat have Taproot support on their medium/long term development\nroadmap or are considering it:\nhttps://en.bitcoin.it/wiki/Bech32_adoption\n\nMeetup link (Zoom link will be announced here):\nhttps://www.meetup.com/BitDevsLDN/events/279041693/\n\nDraft pre-reading link (will be finalized before Tuesday):\nhttps://gist.github.com/michaelfolkson/0803271754f851530fe8242087859254\n\nThanks\nMichael\n\n-- \nMichael Folkson\nEmail: michaelfolkson at gmail.com\nKeybase: michaelfolkson\nPGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3"
            }
        ],
        "thread_summary": {
            "title": "Online discussion on Taproot roll out - Tuesday July 20th 17:15 UTC",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Michael Folkson"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 922
        }
    },
    {
        "title": "[bitcoin-dev] Multisig Enhanced Privacy Scheme",
        "thread_messages": [
            {
                "author": "Michael Flaxman",
                "date": "2021-07-20T19:44:19",
                "message_text_only": "I've been working on ways to prevent privacy leaks in multisig quorums, and have come up with a creative use of BIP32 paths.\n\nWorking code with broadcasted transactions can be found here:\nhttps://github.com/mflaxman/blind-xpub\n\nThis scheme allows for some powerful new features:\n\n- If an unauthorized party gains access to a BIP39 seed phrase, that party learns nothing about transactions in any multisig quorum that seed participates in\n- It allows trusted-minimized third parties (e.g. a lawyer, accountant, heir, close friend, \"uncle Jim\" bitcoiner, collaborative custody service, etc) to hold an emergency recovery key in a multisig quorum with zero knowledge of what that key protects\n\nThis scheme has been live on mainnet for some time and has multi-vendor support from several Coordinators and Signers. I am anecdotally aware of large sums of bitcoin that are currently being HODLed with it.\n\nMy hope in publishing this is to encourage more interoperable hardware wallet / coordinator software support for enhanced privacy, along with improved UX at each step. Feedback is welcome.\n\nBest,\n\nMichael\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210720/d3326b7d/attachment.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2021-07-25T04:49:24",
                "message_text_only": "On Tue, Jul 20, 2021 at 07:44:19PM +0000, Michael Flaxman via bitcoin-dev wrote:\n> I've been working on ways to prevent privacy leaks in multisig\n> quorums, and have come up with a creative use of BIP32 paths.\n\nIt seems to me like it would be rare for an attacker to obtain a private\nBIP32 seed but not simultaneously learn what HD paths it's being used with.\nI assume basically everyone is storing their descriptors (or descriptor\nequivalents) alongside their seeds; doing so helps ensure a robust\nrecovery.\n\nHowever, to the degree that privacy from seed thieves is a problem we\nwant to solve, I think it's largely fixed by using taproot with\nmultisignatures and threshold signatures.  As long as participants\naren't reusing the same keys in different contexts, it shouldn't be\npossible for a third party who doesn't know all involved pubkeys to\ndetermine that any particular aggregated pubkey contained material from\na certain base pubkey.\n\nI would suggest that it's probably more beneficial for wallet authors to\nwork on implementing support for taproot and MuSig or MuSig2 than\nsupport for this scheme, although maybe I'm misunderstanding this\nscheme's motivation.\n\n-Dave\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210724/8873de50/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Multisig Enhanced Privacy Scheme",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "David A. Harding",
                "Michael Flaxman"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 2735
        }
    },
    {
        "title": "[bitcoin-dev] Covenant opcode proposal OP_CONSTRAINDESTINATION (an alternative to OP_CTV)",
        "thread_messages": [
            {
                "author": "Billy Tetrud",
                "date": "2021-07-21T05:56:10",
                "message_text_only": "Hi All,\n\nI have been working on a proposal for an opcode I call\nOP_CONSTRAINDESTINATION. The purpose of the opcode is to allow a spend-path\nto restrict the destination address that an output's coins can be directed\nto. When the destination address is something like a P2SH address, this\nallows step-wise covenant scripts (where one script must lead to another).\n\nThis involves both specifying particular addresses the output is allowed to\nsend coins to, as well as constraining the amount of the fee that output is\nallowed to contribute to. For example, if you had an output that contains\n1000 satoshi, you could specify that a maximum of ~100 sats of that output\ngo to the miner fee and the other ~900 sats must go to one of a list of\nspecified addresses (~ meaning approximately, because the fee is specified\nrelative to recent median fee rates - details in the proposal).\n\nThis opcode has a few different applications, but my primary motivation for\ncreating this opcode is to create more flexible wallet vaults\n<https://hackingdistributed.com/2016/02/26/how-to-implement-secure-bitcoin-vaults>\n.\n\nTo compare this opcode to OP_CHECKTEMPLATEVERIFY, wallet vaults that can be\ncreated with OP_CTV must be created in specified chunks: the address is\nexplicitly tied to a particular utxo sent to it. To retrieve coins from the\nvault, the output must be spent by one of a specific set of transactions\n(potentially one per spend path). Outputs cannot be arbitrarily combined\ninto a transaction, and there is no flexibility whatsoever in deciding\noptions at the time of spending from the vault - all options must be\npremeditated and encoded into the address itself when sending money to the\nvault. This has some related foot-gun scenarios, where the wallet vault has\naddresses that if sent to would generally result in burning those coins,\nunless done in a very specific way by the owner of the vault.\n\nBy contrast, OP_CD allows a lot more flexibility because it only constrains\nthe address to be sent to from the vault, but doesn't put additional\nconstraints on the transaction. This means that outputs can be combined\ninto a single transaction like you would expect in a normal transaction. It\nalso means that external users (people who don't own the vault) can safely\nsend money directly into the vault without coins being burned.\n\n*I have the proposal for this opcode up here:\nhttps://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/bip-constraindestination.md\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/bip-constraindestination.md>*.\nI'd love to hear what people think about it, what problems it might have\nthat I've missed, or other issues or suggestions surrounding this. I'd also\nappreciate any input that would help me improve the presentation of the\nopcode.\n\nThanks!\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210720/71264b19/attachment.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2021-07-25T05:38:03",
                "message_text_only": "On Tue, Jul 20, 2021 at 10:56:10PM -0700, Billy Tetrud via bitcoin-dev wrote:\n> This involves [...] constraining the amount of the fee that output is\n> allowed to contribute to.  [...] fee is specified relative to recent\n> median fee rates - details in the proposal).\n\nHere are the relevant details:\n\n> The medianFeeRate is defined as the median fee rate per vbyte for the\n> most recent windowLength blocks. The maxFeeContribution is defined as\n> medianFeeRate * 2^feeFactor of the fee. Note that this is a limitation\n> on the fee, not on the fee-rate. If feeFactor is -1,\n> maxFeeContribution is 0.\n\nFirst, I don't think we want full nodes to have to store the feerate for\nevery transaction in a 3,000 block window (~2.5 million txes, assuming\nall segwit).  I'm sure you could tweak this proposal to require a much\nsmaller dataset.\n\nSecond, I think this requires careful consideration of how it might\naffect the incentives for miners.  Miners can include many small high-fee\npay-to-self transactions in their blocks to raise the median feerate,\nbut this puts them at increased risk of fee sniping from other miners,\nwhich may incentivize fee-raisers to centralize their mining, which is\nultimately bad.  I'm not sure that's a huge concern with this proposal,\nbut I think it and other incentive problems require consideration.\n\nFinally, I think this fee mechanism is redundant.  For any case where\nthis opcode will be used, you'll want to have two things:\n\n    1. A mutual spend clause (e.g. a multisignature taproot keypath\n       spend) where all parties agree on a spend of the output and so\n       can set an appropriate feerate at that time.  You want this\n       because it'll be the most efficient way to spend.\n\n    2. A fee override that allows paying additional fees beyond what\n       OP_CONSTRAINDESTINATION allows, either through attaching an\n       additional input or through CPFP.  You want this because you\n       will know more about feerate conditions at spend time than you\n       did when you created the receiving script.\n\nIf you have the ability to choose feerates through the above mechanisms,\nyou don't need a constrained feerate mechanism that might be\nmanipulable by miners.\n\n(I haven't looked closely at the rest of your proposal; the above just\ncaught my attention.)\n\n-Dave\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210724/e5c1bfe3/attachment.sig>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2021-07-25T19:49:38",
                "message_text_only": "Thanks for taking a look at the proposal David. I appreciate it.\n\n> I don't think we want full nodes to have to store the feerate for every\ntransaction in a 3,000 block window\n\nThat's a good point. It would probably be just as good to find the median\nfee-rate for each block and store that, then calculate the average of those\nstored per-block median numbers. Do you think that would be sufficiently\ncheap to store?\n\n> Miners can include many small high-fee pay-to-self transactions in their\nblocks to raise the median feerate\n\nDefinitely a reasonable thing to consider. One point I want to make about\nthat tho is that the opcode only limits how much of a particular output can\nbe put towards the transaction fee - for the vast majority of transactions\nusing this opcode, a lower fee would be used and the limit would be\nirrelevant (and therefore raising the median fee rate would not affect\nthose transactions). The point of limiting the fee is to limit an\nattacker's ability to grief a victim by sending all their funds as\ntransaction fee. So the only situations where miners would gain something\nfrom raising the fee rate is for griefing situations, which should be so\nrare as to be completely insignificant to miners. If griefing is not rare,\nsomething else is pretty broken.\n\n> I think this fee mechanism is redundant\n\nSee above, but to break down that situation a bit further, these are the\ntwo situations I can think of:\n\n   1. The opcode limits user/group A to send the output to user/group B\n   2. The opcode limits user A to send from one address they own to another\n   address they own.\n\nIn case 1, user/group A could be the attacker that attempts to direct as\nmuch of the outputs as possible towards the fee (instead of the agreed upon\nrecipient user/group B). In case 2, the attacker would be someone that\nsteals a key from the user (eg in the case the attacker gets access to 1\nkey of the wallet vault keys) and attempts to grief them by making a\ntransaction with the highest possible fee. In both these scenarios, the fee\nlimit helps limit the amount of damage these attackers could do to their\nvictim. Without a fee limit, these attack vectors could spend up to the\nfull output amount as fee, which could be very damaging.\n\n> A mutual spend clause\n\nHave you considered the use case of wallet vaults? I designed this opcode\nprimarily with wallet vaults in mind. In such a case there is a \"mutual\nspend clause\" of a kind - but all the keys may be owned by a single\nindividual. One of the keys would be kept close at hand, and other keys\nwould be kept in more secure and more difficult-to-access places (like a\nsafe in a remote location). While the key-spend-path would be cheapest on\nchain, traveling to get the key itself might often be more expensive than\nusing the script spend-path (because it takes time and effort to travel to\nthose locations and access the keys). It might be informative to take a\nlook at these wallet vault scripts\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/op_cdWalletVault1.md>\nthat\ncould use this opcode or the larger vision\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/README.md>\nI have for wallet vaults (which involves 2 other new opcodes). There are\ncertainly also multi-user multisig use cases for OP_CD that have similar\nproperties to this single-user use case.\n\n> A fee override that allows paying additional fees .. through attaching an\nadditional input or through CPFP\n\nI definitely agree those are desirable mechanisms. To reiterate what I said\nabove, the fee limitation is there to limit griefing attack vectors that\nspend an unreasonable amount of a particular output towards the fee.\nSpending *other* outputs (via either of those mechanisms) towards a\ntransaction's fee is perfectly acceptable and doesn't undermine the purpose\nof the fee limitation.\n\nAt its core, the limitation is there because the miner is another\ndestination that the output's funds can be sent to, and while it wouldn't\nbe wise to prevent an output from being spent as fee at all (because then\nthe output is unspendable on its own, or with any other similarly\nconstrained outputs), if OP_CD allowed spending the entire output as a fee\nthen it wouldn't be successful in constraining the destination to the\nlisted addresses.\n\nDo you see my points here, or do you still think the limitation is\nredundant?\n\nThanks,\nBT\n\n\n\n\nOn Sat, Jul 24, 2021 at 10:39 PM David A. Harding via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Tue, Jul 20, 2021 at 10:56:10PM -0700, Billy Tetrud via bitcoin-dev\n> wrote:\n> > This involves [...] constraining the amount of the fee that output is\n> > allowed to contribute to.  [...] fee is specified relative to recent\n> > median fee rates - details in the proposal).\n>\n> Here are the relevant details:\n>\n> > The medianFeeRate is defined as the median fee rate per vbyte for the\n> > most recent windowLength blocks. The maxFeeContribution is defined as\n> > medianFeeRate * 2^feeFactor of the fee. Note that this is a limitation\n> > on the fee, not on the fee-rate. If feeFactor is -1,\n> > maxFeeContribution is 0.\n>\n> First, I don't think we want full nodes to have to store the feerate for\n> every transaction in a 3,000 block window (~2.5 million txes, assuming\n> all segwit).  I'm sure you could tweak this proposal to require a much\n> smaller dataset.\n>\n> Second, I think this requires careful consideration of how it might\n> affect the incentives for miners.  Miners can include many small high-fee\n> pay-to-self transactions in their blocks to raise the median feerate,\n> but this puts them at increased risk of fee sniping from other miners,\n> which may incentivize fee-raisers to centralize their mining, which is\n> ultimately bad.  I'm not sure that's a huge concern with this proposal,\n> but I think it and other incentive problems require consideration.\n>\n> Finally, I think this fee mechanism is redundant.  For any case where\n> this opcode will be used, you'll want to have two things:\n>\n>     1. A mutual spend clause (e.g. a multisignature taproot keypath\n>        spend) where all parties agree on a spend of the output and so\n>        can set an appropriate feerate at that time.  You want this\n>        because it'll be the most efficient way to spend.\n>\n>     2. A fee override that allows paying additional fees beyond what\n>        OP_CONSTRAINDESTINATION allows, either through attaching an\n>        additional input or through CPFP.  You want this because you\n>        will know more about feerate conditions at spend time than you\n>        did when you created the receiving script.\n>\n> If you have the ability to choose feerates through the above mechanisms,\n> you don't need a constrained feerate mechanism that might be\n> manipulable by miners.\n>\n> (I haven't looked closely at the rest of your proposal; the above just\n> caught my attention.)\n>\n> -Dave\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210725/2257a16a/attachment.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2021-07-26T00:05:53",
                "message_text_only": "On Sun, Jul 25, 2021 at 12:49:38PM -0700, Billy Tetrud wrote:\n> find the median fee-rate for each block and store that, then calculate\n> the average of those stored per-block median numbers. \n\nOne datapoint per block seems fine to me and it works much nicer with\npruned nodes.\n\n> So the only situations where miners would gain something\n> from raising the fee rate is for griefing situations, which should be so\n> rare as to be completely insignificant to miners. \n\nI don't believe the problem scope can be reduced this way.  Although we\nwe often look at miners as separate from users, it's important to\nremember that every miner is also a user of Bitcoin and ever user of\nBitcoin may also someday be a miner.  Users may also employ miners\ndirectly via out-of-band payments.\n\nIn your usecase of vaults, we can imagine Bob is attempting to store\n100,000 BTC.  He designs his vault to allow spending on fees up to 10x\nthe 3,000 block median fee.  Mallory steals Bob's encumbered spending\nkey.  Mallory could immediately go to a miner and offer them a 50/50\nsplit on the 10x fees over the median (~10,000 sat?), or Mallory could\ntake a bit more time and work with a cartel of miners to raise the\nmedian over a period of three weeks (3k blocks) to 10,000\nBTC/transaction, allowing them to take all of Bob's coins in fees.\n\n> if OP_CD allowed spending the entire output as a fee then it wouldn't\n> be successful in constraining the destination to the listed addresses.\n\nThe alternative is to never allow OP_CD to spend any of the UTXOs it\nencumbers to fees, requiring all fees be paid via another mechanism.\nSince satisfactory designs are going to provide those other mechanisms\nanyway, it seems to me that there's no need for OP_CD to manage fees.\nThat said, I don't have a real strong opinion here.\n\n-Dave\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210725/b442f887/attachment.sig>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2021-07-26T20:18:35",
                "message_text_only": ">  it's important to remember that every miner is also a user of Bitcoin\nand ever user of Bitcoin may also someday be a miner\n\nThat's certainly true. One good quantification for how much of a problem\nthis could be is to calculate the cost of the attack vs the damage done in\nthe attack. So let me try to estimate that:\n\nMiners could collectively shift the fee rate up by sending payments to\nthemselves, like you said. However, each one represents an opportunity cost\nof a low-value transaction. Given a bell curve distribution of transaction\nfee-rates, filling 15% of each block with these self-pay transactions could\nraise the median fee rate by about 1/4 of a standard deviation, or\nsomething probably around a 5% increase in median fee rate. This would lose\nminers approximately 5% of the fees for the blocks they did this for. So in\norder to do 1-to-1 damage (which would have them break even on the attack),\nthere would have to be enough of these transactions to fill up maybe 1% of\n3000 blocks (if we assume these transactions will generally have 10 times\nthe fee-rate of the displaced low-value transactions). That would be on the\norder of hundreds of thousands of transactions. A shorter sample\nwindow would be easier to abuse this way, but even still likely at least\nhundreds of transactions would be needed to make up the difference.\n\nManipulating fees this way has diminishing returns, meaning that filling a\nsmaller percent of a block with high-fee self-payment transactions would\nlead to a greater increase in the median fee rate per amount of fees lost.\n\nSomething interesting about this attack is that a successful attack would\nmake the next attack easier, because mining these transactions from stolen\nkeys would also help raise the median fee-rate a bit (tho only a fraction\nof the self-pay transactions that would still be necessary for the next\nround of attacks).\n\nAnd the above is a situation with 100% dishonest miners. With fewer\ndishonest miners, say 25%, the attack would have a much lower ROI.\n\nFor the wallet vault use case, this is still a security improvement over a\nnormal wallet, since in a normal wallet, a stolen key means all your funds\ncan be stolen, but in an OP_CD wallet vault the attackers are still limited\nin how much can be stolen via the fee, stealing via the fee requires paying\nminers a cut to receive back some of the fee, and stealing extra  (via\nraising the median fee rate) has a real cost placed on the miners.\n\nFor multi-party scenarios, I think the fee limit might be slightly less\neffective. Eg in contracts where some money is promised to be sent to\nanother person's address (e.g. congestion controlled payments), if a miner\ncontrols the sending address that miner can simply send the maximum fee to\ngain more money directly. The limit is still partially effective, but its\ndefinitely worth noting that malicious miners can abuse the fee limit\nmechanism. I would think manipulating the median fee rate is just as\ndifficult in this scenario tho.\n\n> pay-to-self transactions .. puts them at increased risk of fee sniping\nfrom other miners, which may incentivize fee-raisers to centralize their\nmining\n\nThis is an interesting point I forgot to respond to from your first email.\nI think even without the threat of fee-sniping, fee raisers would want to\ncartelize because coordinating the timing of attacks would reduce their\ncollective costs. Tho fee-sniping would increase this pressure, I agree. It\nseems like cartels like this would have to get near the range of being able\nto 51% attack to really be effective tho.\n\n> The alternative is to never allow OP_CD to spend any of the UTXOs it\nencumbers to fees\n\nI agree that functionally this would work ok. However, both other\nmechanisms (gathering keys for a multisig spend or CPFP / adding other\ninputs) are likely to often be more expensive than letting the UTXO\ncontribute to the fee directly. Also, it would complicate usability of\nthese outputs, sometimes even making them unspendable by the user directly\n(in the case they don't have access to external outputs to contribute to\nthe fee).\n\nIn any case, I've updated my proposal with some of the things we've\ndiscussed. Thanks!\n\n@Randy What are you agreeing with?\n\nOn Mon, Jul 26, 2021 at 5:59 AM Randy Fox <mrkingfoxx at hotmail.com> wrote:\n\n> Agree.\n>\n>\n> Sent from Yahoo Mail for iPhone\n> <https://overview.mail.yahoo.com/?.src=iOS>\n>\n> On Sunday, July 25, 2021, 7:07 PM, David A. Harding via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> On Sun, Jul 25, 2021 at 12:49:38PM -0700, Billy Tetrud wrote:\n> > find the median fee-rate for each block and store that, then calculate\n> > the average of those stored per-block median numbers.\n>\n> One datapoint per block seems fine to me and it works much nicer with\n> pruned nodes.\n>\n> > So the only situations where miners would gain something\n> > from raising the fee rate is for griefing situations, which should be so\n> > rare as to be completely insignificant to miners.\n>\n> I don't believe the problem scope can be reduced this way.  Although we\n> we often look at miners as separate from users, it's important to\n> remember that every miner is also a user of Bitcoin and ever user of\n> Bitcoin may also someday be a miner.  Users may also employ miners\n> directly via out-of-band payments.\n>\n> In your usecase of vaults, we can imagine Bob is attempting to store\n> 100,000 BTC.  He designs his vault to allow spending on fees up to 10x\n> the 3,000 block median fee.  Mallory steals Bob's encumbered spending\n> key.  Mallory could immediately go to a miner and offer them a 50/50\n> split on the 10x fees over the median (~10,000 sat?), or Mallory could\n> take a bit more time and work with a cartel of miners to raise the\n> median over a period of three weeks (3k blocks) to 10,000\n> BTC/transaction, allowing them to take all of Bob's coins in fees.\n>\n> > if OP_CD allowed spending the entire output as a fee then it wouldn't\n> > be successful in constraining the destination to the listed addresses.\n>\n> The alternative is to never allow OP_CD to spend any of the UTXOs it\n> encumbers to fees, requiring all fees be paid via another mechanism.\n> Since satisfactory designs are going to provide those other mechanisms\n> anyway, it seems to me that there's no need for OP_CD to manage fees.\n> That said, I don't have a real strong opinion here.\n>\n>\n> -Dave\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210726/64ebe96d/attachment.html>"
            },
            {
                "author": "James MacWhyte",
                "date": "2021-07-26T21:08:09",
                "message_text_only": "Hi Billy!\n\nSee above, but to break down that situation a bit further, these are the\n> two situations I can think of:\n>\n>    1. The opcode limits user/group A to send the output to user/group B\n>    2. The opcode limits user A to send from one address they own to\n>    another address they own.\n>\n> I'm trying to think of a good use case for this type of opcode. In these\nexamples, an attacker who compromises the key for user A can't steal the\nmoney because it can only be sent to user B. So if the attacker wants to\nsteal the funds, they would need to compromise the keys of both user A and\nuser B.\n\nBut how is that any better than a 2-of-2 multisig? Isn't the end result\nexactly the same?\n\nJames\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210726/688c8adb/attachment.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2021-07-27T00:41:29",
                "message_text_only": "Hey James,\n\nIn the examples you mentioned, what I was exploring was a mechanism of\nattack by which the attacker could steal user A's key and use that key to\nsend a transaction with the maximum possible fee. User B would still\nreceive some funds (probably), but if the fee could be large, the attacker\nwould either do a lot of damage to user B (griefing) or could make an\nagreement with a miner to give back some of the large fee (theft).\n\nBut as for use cases, the proposal mentions a number of use cases\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/bip-constraindestination.md#motivation>\nand\nmost overlap with the use cases of op_ctv <https://utxos.org/uses/> (Jeremy\nRubin's website for op_ctv has a lot of good details, most of which are\nalso relevant to op_cd). The use case I'm most interested in is wallet\nvaults. This opcode can be used to create a wallet vault where the user\nonly needs to use, for example, 1 key to spend funds, but the attacker must\nsteal 2 or more keys to spend funds. The benefits of a 2 key wallet vault\nlike this vs a normal 2-of-2 multisig wallet are that not only does an\nattacker have to steal both keys (same level of security), but also the\nuser can lose one key and still recover their funds (better redundancy) and\nalso that generally the user doesn't need to access their second key - so\nthat can remain in a much more secure location (which would also probably\nmake that key harder to steal). The only time the second key only comes\ninto play if one key is stolen and the attacker attempts to send a\ntransaction. At that point, the user would go find and use his second key\n(along with the first) to send a revoke transaction to prevent the attacker\nfrom stealing their funds. This is somewhat akin to a lightning watchtower\nscenario, where your wallet would watch the chain and alert you about an\nunexpected transaction, at which point you'd manually do a revoke (vs a\nwatchtower's automated response). You might be interested in taking a look\nat this wallet vault design\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/op_cdWalletVault1.md>\nthat uses OP_CD or even my full vision\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults> of the wallet\nvault I want to be able to create.\n\nWith a covenant opcode like this, its possible to create very usable and\naccessible but highly secure wallets that can allow normal people to hold\nself custody of their keys without fear of loss or theft and without the\nhassle of a lot of safe deposit boxes (or other secure seed storage\nlocations).\n\nCheers,\nBT\n\n\n\n\n\nOn Mon, Jul 26, 2021 at 2:08 PM James MacWhyte <macwhyte at gmail.com> wrote:\n\n> Hi Billy!\n>\n> See above, but to break down that situation a bit further, these are the\n>> two situations I can think of:\n>>\n>>    1. The opcode limits user/group A to send the output to user/group B\n>>    2. The opcode limits user A to send from one address they own to\n>>    another address they own.\n>>\n>> I'm trying to think of a good use case for this type of opcode. In these\n> examples, an attacker who compromises the key for user A can't steal the\n> money because it can only be sent to user B. So if the attacker wants to\n> steal the funds, they would need to compromise the keys of both user A and\n> user B.\n>\n> But how is that any better than a 2-of-2 multisig? Isn't the end result\n> exactly the same?\n>\n> James\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210726/9bec6c43/attachment-0001.html>"
            },
            {
                "author": "Zac Greenwood",
                "date": "2021-07-27T11:18:11",
                "message_text_only": "Hi Billy,\n\nOn the topic of wallet vaults, are there any plans to implement a way to\nlimit the maximum amount to be sent from an address?\n\nAn example of such limit might be: the maximum amount allowed to send is\nmax(s, p) where s is a number of satoshi and p a percentage of the total\navailable (sendable) amount.\n\nA minimum value may be imposed on the percentage to ensure that the address\ncan be emptied within a reasonable number of transactions. The second\nparameter s allows a minimum permitted amount. (This is necessary because\nwith only the percentage parameter the minimum permitted amount converges\nto zero, making it impossible to empty the address).\n\nThere may be other ways too. In my view, such kind of restriction would be\nextremely effective in thwarting the most damaging type of theft being the\none where all funds are swept in a single transaction.\n\nZac\n\n\nOn Tue, 27 Jul 2021 at 03:26, Billy Tetrud via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hey James,\n>\n> In the examples you mentioned, what I was exploring was a mechanism of\n> attack by which the attacker could steal user A's key and use that key to\n> send a transaction with the maximum possible fee. User B would still\n> receive some funds (probably), but if the fee could be large, the attacker\n> would either do a lot of damage to user B (griefing) or could make an\n> agreement with a miner to give back some of the large fee (theft).\n>\n> But as for use cases, the proposal mentions a number of use cases\n> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/bip-constraindestination.md#motivation> and\n> most overlap with the use cases of op_ctv <https://utxos.org/uses/> (Jeremy\n> Rubin's website for op_ctv has a lot of good details, most of which are\n> also relevant to op_cd). The use case I'm most interested in is wallet\n> vaults. This opcode can be used to create a wallet vault where the user\n> only needs to use, for example, 1 key to spend funds, but the attacker must\n> steal 2 or more keys to spend funds. The benefits of a 2 key wallet vault\n> like this vs a normal 2-of-2 multisig wallet are that not only does an\n> attacker have to steal both keys (same level of security), but also the\n> user can lose one key and still recover their funds (better redundancy) and\n> also that generally the user doesn't need to access their second key - so\n> that can remain in a much more secure location (which would also probably\n> make that key harder to steal). The only time the second key only comes\n> into play if one key is stolen and the attacker attempts to send a\n> transaction. At that point, the user would go find and use his second key\n> (along with the first) to send a revoke transaction to prevent the attacker\n> from stealing their funds. This is somewhat akin to a lightning watchtower\n> scenario, where your wallet would watch the chain and alert you about an\n> unexpected transaction, at which point you'd manually do a revoke (vs a\n> watchtower's automated response). You might be interested in taking a look\n> at this wallet vault design\n> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/op_cdWalletVault1.md>\n> that uses OP_CD or even my full vision\n> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults> of the\n> wallet vault I want to be able to create.\n>\n> With a covenant opcode like this, its possible to create very usable and\n> accessible but highly secure wallets that can allow normal people to hold\n> self custody of their keys without fear of loss or theft and without the\n> hassle of a lot of safe deposit boxes (or other secure seed storage\n> locations).\n>\n> Cheers,\n> BT\n>\n>\n>\n>\n>\n> On Mon, Jul 26, 2021 at 2:08 PM James MacWhyte <macwhyte at gmail.com> wrote:\n>\n>> Hi Billy!\n>>\n>> See above, but to break down that situation a bit further, these are the\n>>> two situations I can think of:\n>>>\n>>>    1. The opcode limits user/group A to send the output to user/group B\n>>>    2. The opcode limits user A to send from one address they own to\n>>>    another address they own.\n>>>\n>>> I'm trying to think of a good use case for this type of opcode. In these\n>> examples, an attacker who compromises the key for user A can't steal the\n>> money because it can only be sent to user B. So if the attacker wants to\n>> steal the funds, they would need to compromise the keys of both user A and\n>> user B.\n>>\n>> But how is that any better than a 2-of-2 multisig? Isn't the end result\n>> exactly the same?\n>>\n>> James\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210727/c75c3771/attachment.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2021-07-27T17:21:11",
                "message_text_only": "Hi Zac,\n\nI haven't heard of any proposal for limiting the amount that can be sent\nfrom an address. I assume you mean limiting the amount that can be sent in\na period of time - eg something that would encode that for address A, only\nX bitcoin can be sent from the address in a given day/week/etc, is that\nright? That would actually be a somewhat difficult thing to do in the\noutput-based system Bitcoin uses, and would be easier in an account based\nsystem like Ethereum. The problem is that each output is separate, and\nthere's no concept in bitcoin of encumbering outputs together.\n\nWhat you could do is design a system where coins would be combined in a\nsingle output, and then encumber that output with a script that allows a\nlimited amount of coin be sent to a destination address and requires all\nother bitcoins be returned to sender in a new change output that is also\ntimelocked. That way, the new change output can't be used again until the\ntimelock expires (eg a week). However, to ensure this wallet works\nproperly, any deposit into the wallet would have to also spend the wallet's\nsingle output, so as to create a new single output at that address. So 3rd\nparties wouldn't be able to arbitrarily send money in (or rather, they\ncould, but each output would have its own separate spending limit).\n\n> such kind of restriction would be extremely effective in thwarting the\nmost damaging type of theft being the one where all funds are swept in a\nsingle transaction\n\nIt would. However a normal wallet vault basically already has this property\n- a thief can't simply sweep funds instantly, but instead the victim will\nsee an initiated transaction and will be able to reverse it within a delay\ntime-window. I don't think adding a spending limit would add meaningful\nsecurity to a delayed-send wallet vault like that. But it could be used to\nincrease the security of a wallet vault that can be instantly spent from -\nie if the attacker successfully steals funds, then the victim has time to\ngo gather their additional keys and move the remaining (unstolen) funds\ninto a new wallet.\n\nOP_CD could potentially be augmented to allow specifying limit amounts for\neach destination, which would allow you to create a wallet like this. It\nwould be a bit of an awkward wallet to use tho, since you couldn't receive\ndirectly into it from a 3rd party and you also couldn't keep separate\noutputs (which is bad for privacy).\n\nAn alternate way of doing this that you don't need any new opcodes for\nwould be to have a 3rd party service that signs multisig transactions from\na wallet only up to a limit. The end-user could have additional keys such\nthat the 3rd party can't prevent them from accessing that (if they turn\nuncooperative), and the 3rd party would only have a single key so they\ncan't steal funds, but the user would sign a transaction with one key, and\nthe 3rd party with another as long as the spending limit hasn't been\nreached. This wouldn't have much counterparty risk, but would be a less\nawkward wallet than what I described above - meaning anyone could send\nfunds into the wallet without defeating the spending limit, and privacy\ncould be kept intact (minus the fact that the 3rd party would know what\nyour outputs are).\n\nBT\n\nOn Tue, Jul 27, 2021 at 4:18 AM Zac Greenwood <zachgrw at gmail.com> wrote:\n\n> Hi Billy,\n>\n> On the topic of wallet vaults, are there any plans to implement a way to\n> limit the maximum amount to be sent from an address?\n>\n> An example of such limit might be: the maximum amount allowed to send is\n> max(s, p) where s is a number of satoshi and p a percentage of the total\n> available (sendable) amount.\n>\n> A minimum value may be imposed on the percentage to ensure that the\n> address can be emptied within a reasonable number of transactions. The\n> second parameter s allows a minimum permitted amount. (This is necessary\n> because with only the percentage parameter the minimum permitted amount\n> converges to zero, making it impossible to empty the address).\n>\n> There may be other ways too. In my view, such kind of restriction would be\n> extremely effective in thwarting the most damaging type of theft being the\n> one where all funds are swept in a single transaction.\n>\n> Zac\n>\n>\n> On Tue, 27 Jul 2021 at 03:26, Billy Tetrud via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hey James,\n>>\n>> In the examples you mentioned, what I was exploring was a mechanism of\n>> attack by which the attacker could steal user A's key and use that key to\n>> send a transaction with the maximum possible fee. User B would still\n>> receive some funds (probably), but if the fee could be large, the attacker\n>> would either do a lot of damage to user B (griefing) or could make an\n>> agreement with a miner to give back some of the large fee (theft).\n>>\n>> But as for use cases, the proposal mentions a number of use cases\n>> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/bip-constraindestination.md#motivation> and\n>> most overlap with the use cases of op_ctv <https://utxos.org/uses/> (Jeremy\n>> Rubin's website for op_ctv has a lot of good details, most of which are\n>> also relevant to op_cd). The use case I'm most interested in is wallet\n>> vaults. This opcode can be used to create a wallet vault where the user\n>> only needs to use, for example, 1 key to spend funds, but the attacker must\n>> steal 2 or more keys to spend funds. The benefits of a 2 key wallet vault\n>> like this vs a normal 2-of-2 multisig wallet are that not only does an\n>> attacker have to steal both keys (same level of security), but also the\n>> user can lose one key and still recover their funds (better redundancy) and\n>> also that generally the user doesn't need to access their second key - so\n>> that can remain in a much more secure location (which would also probably\n>> make that key harder to steal). The only time the second key only comes\n>> into play if one key is stolen and the attacker attempts to send a\n>> transaction. At that point, the user would go find and use his second key\n>> (along with the first) to send a revoke transaction to prevent the attacker\n>> from stealing their funds. This is somewhat akin to a lightning watchtower\n>> scenario, where your wallet would watch the chain and alert you about an\n>> unexpected transaction, at which point you'd manually do a revoke (vs a\n>> watchtower's automated response). You might be interested in taking a look\n>> at this wallet vault design\n>> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/op_cdWalletVault1.md>\n>> that uses OP_CD or even my full vision\n>> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults> of the\n>> wallet vault I want to be able to create.\n>>\n>> With a covenant opcode like this, its possible to create very usable and\n>> accessible but highly secure wallets that can allow normal people to hold\n>> self custody of their keys without fear of loss or theft and without the\n>> hassle of a lot of safe deposit boxes (or other secure seed storage\n>> locations).\n>>\n>> Cheers,\n>> BT\n>>\n>>\n>>\n>>\n>>\n>> On Mon, Jul 26, 2021 at 2:08 PM James MacWhyte <macwhyte at gmail.com>\n>> wrote:\n>>\n>>> Hi Billy!\n>>>\n>>> See above, but to break down that situation a bit further, these are the\n>>>> two situations I can think of:\n>>>>\n>>>>    1. The opcode limits user/group A to send the output to user/group B\n>>>>    2. The opcode limits user A to send from one address they own to\n>>>>    another address they own.\n>>>>\n>>>> I'm trying to think of a good use case for this type of opcode. In\n>>> these examples, an attacker who compromises the key for user A can't steal\n>>> the money because it can only be sent to user B. So if the attacker wants\n>>> to steal the funds, they would need to compromise the keys of both user A\n>>> and user B.\n>>>\n>>> But how is that any better than a 2-of-2 multisig? Isn't the end result\n>>> exactly the same?\n>>>\n>>> James\n>>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210727/098ffbde/attachment-0001.html>"
            },
            {
                "author": "Zac Greenwood",
                "date": "2021-07-28T04:57:33",
                "message_text_only": "Hi Billy,\n\nThank you for your comprehensive reply. My purpose was to find out whether\na proposal to somehow limit the amount being sent from an address exists\nand to further illustrate my thoughts by giving a concrete example of how\nthis might work functionally without getting to deep into the\ntechnicalities.\n\nAs for your assumption: for an amount limit to have the desired effect, I\nrealize now that there must also exist some limit on the number of\ntransactions that will be allowed from the encumbered address.\n\nTaking a step back, a typical use case would be a speculating user\nintending to hodl bitcoin but who still wishes to be able to occasionally\ntransact minor amounts.\n\nIdeally, such user should optionally still be able to bypass the rate limit\nand spend the entire amount in a single transaction by signing with an\nadditional private key (multisig).\n\nDuring the setup phase, a user sends all their to-be-rate-limited coin to a\nsingle address. When spending from this rate limited address, any change\nsent to the change address must be rate limited as well using identical\nparameters. I believe that\u2019s also what you\u2019re suggesting.\n\nI believe that a smart wallet should be able to set up and maintain\nmultiple rate-limited addresses in such a way that their aggregate\nbehaviour meets any rate-limiting parameters as desired by the user. This\nought to alleviate your privacy concerns because it means that the wallet\nwill be able to mix outputs.\n\nThe options for the to-be implemented rate-limiting parameters vary from\ncompletely arbitrary to more restrictive.\n\nCompletely arbitrary parameters would allow users to set up a rate limit\nthat basically destroys their funds, for instance rate-limiting an address\nto an amount of 1 satoshi per 100 blocks.\n\nMore restrictive rate limits would remove such footgun and may require that\nonly a combination of parameters are allowed such that all funds will be\nspendable within a set number of blocks (for instance 210,000).\n\nAs for the rate-limiting parameters, in addition to a per-transaction\nmaximum of (minimum amount in satoshi or a percentage of the total amount\nstored at the address), also the transaction frequency must be limited. I\nwould propose this to be expressed as a number of blocks before a next\ntransaction can be sent from the encumbered address(es).\n\nI believe such user-enabled rate-limiting is superior to one that requires\na third party.\n\nAs an aside, I am not sure how a vault solution would be able to prevent an\nattacker who is in possession of the vaults\u2019 private key from sabotaging\nthe user by replacing the user transaction with one having a higher fee\nevery time the user attempts to transact. I am probably missing something\nhere though.\n\nZac\n\n\nOn Tue, 27 Jul 2021 at 19:21, Billy Tetrud <billy.tetrud at gmail.com> wrote:\n\n> Hi Zac,\n>\n> I haven't heard of any proposal for limiting the amount that can be sent\n> from an address. I assume you mean limiting the amount that can be sent in\n> a period of time - eg something that would encode that for address A, only\n> X bitcoin can be sent from the address in a given day/week/etc, is that\n> right? That would actually be a somewhat difficult thing to do in the\n> output-based system Bitcoin uses, and would be easier in an account based\n> system like Ethereum. The problem is that each output is separate, and\n> there's no concept in bitcoin of encumbering outputs together.\n>\n> What you could do is design a system where coins would be combined in a\n> single output, and then encumber that output with a script that allows a\n> limited amount of coin be sent to a destination address and requires all\n> other bitcoins be returned to sender in a new change output that is also\n> timelocked. That way, the new change output can't be used again until the\n> timelock expires (eg a week). However, to ensure this wallet works\n> properly, any deposit into the wallet would have to also spend the wallet's\n> single output, so as to create a new single output at that address. So 3rd\n> parties wouldn't be able to arbitrarily send money in (or rather, they\n> could, but each output would have its own separate spending limit).\n>\n> > such kind of restriction would be extremely effective in thwarting the\n> most damaging type of theft being the one where all funds are swept in a\n> single transaction\n>\n> It would. However a normal wallet vault basically already has this\n> property - a thief can't simply sweep funds instantly, but instead the\n> victim will see an initiated transaction and will be able to reverse it\n> within a delay time-window. I don't think adding a spending limit would add\n> meaningful security to a delayed-send wallet vault like that. But it could\n> be used to increase the security of a wallet vault that can be instantly\n> spent from - ie if the attacker successfully steals funds, then the victim\n> has time to go gather their additional keys and move the remaining\n> (unstolen) funds into a new wallet.\n>\n> OP_CD could potentially be augmented to allow specifying limit amounts for\n> each destination, which would allow you to create a wallet like this. It\n> would be a bit of an awkward wallet to use tho, since you couldn't receive\n> directly into it from a 3rd party and you also couldn't keep separate\n> outputs (which is bad for privacy).\n>\n> An alternate way of doing this that you don't need any new opcodes for\n> would be to have a 3rd party service that signs multisig transactions from\n> a wallet only up to a limit. The end-user could have additional keys such\n> that the 3rd party can't prevent them from accessing that (if they turn\n> uncooperative), and the 3rd party would only have a single key so they\n> can't steal funds, but the user would sign a transaction with one key, and\n> the 3rd party with another as long as the spending limit hasn't been\n> reached. This wouldn't have much counterparty risk, but would be a less\n> awkward wallet than what I described above - meaning anyone could send\n> funds into the wallet without defeating the spending limit, and privacy\n> could be kept intact (minus the fact that the 3rd party would know what\n> your outputs are).\n>\n> BT\n>\n> On Tue, Jul 27, 2021 at 4:18 AM Zac Greenwood <zachgrw at gmail.com> wrote:\n>\n>> Hi Billy,\n>>\n>> On the topic of wallet vaults, are there any plans to implement a way to\n>> limit the maximum amount to be sent from an address?\n>>\n>> An example of such limit might be: the maximum amount allowed to send is\n>> max(s, p) where s is a number of satoshi and p a percentage of the total\n>> available (sendable) amount.\n>>\n>> A minimum value may be imposed on the percentage to ensure that the\n>> address can be emptied within a reasonable number of transactions. The\n>> second parameter s allows a minimum permitted amount. (This is necessary\n>> because with only the percentage parameter the minimum permitted amount\n>> converges to zero, making it impossible to empty the address).\n>>\n>> There may be other ways too. In my view, such kind of restriction would\n>> be extremely effective in thwarting the most damaging type of theft being\n>> the one where all funds are swept in a single transaction.\n>>\n>> Zac\n>>\n>>\n>> On Tue, 27 Jul 2021 at 03:26, Billy Tetrud via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Hey James,\n>>>\n>>> In the examples you mentioned, what I was exploring was a mechanism of\n>>> attack by which the attacker could steal user A's key and use that key to\n>>> send a transaction with the maximum possible fee. User B would still\n>>> receive some funds (probably), but if the fee could be large, the attacker\n>>> would either do a lot of damage to user B (griefing) or could make an\n>>> agreement with a miner to give back some of the large fee (theft).\n>>>\n>>> But as for use cases, the proposal mentions a number of use cases\n>>> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/bip-constraindestination.md#motivation> and\n>>> most overlap with the use cases of op_ctv <https://utxos.org/uses/> (Jeremy\n>>> Rubin's website for op_ctv has a lot of good details, most of which are\n>>> also relevant to op_cd). The use case I'm most interested in is wallet\n>>> vaults. This opcode can be used to create a wallet vault where the user\n>>> only needs to use, for example, 1 key to spend funds, but the attacker must\n>>> steal 2 or more keys to spend funds. The benefits of a 2 key wallet vault\n>>> like this vs a normal 2-of-2 multisig wallet are that not only does an\n>>> attacker have to steal both keys (same level of security), but also the\n>>> user can lose one key and still recover their funds (better redundancy) and\n>>> also that generally the user doesn't need to access their second key - so\n>>> that can remain in a much more secure location (which would also probably\n>>> make that key harder to steal). The only time the second key only comes\n>>> into play if one key is stolen and the attacker attempts to send a\n>>> transaction. At that point, the user would go find and use his second key\n>>> (along with the first) to send a revoke transaction to prevent the attacker\n>>> from stealing their funds. This is somewhat akin to a lightning watchtower\n>>> scenario, where your wallet would watch the chain and alert you about an\n>>> unexpected transaction, at which point you'd manually do a revoke (vs a\n>>> watchtower's automated response). You might be interested in taking a look\n>>> at this wallet vault design\n>>> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/op_cdWalletVault1.md>\n>>> that uses OP_CD or even my full vision\n>>> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults> of the\n>>> wallet vault I want to be able to create.\n>>>\n>>> With a covenant opcode like this, its possible to create very usable and\n>>> accessible but highly secure wallets that can allow normal people to hold\n>>> self custody of their keys without fear of loss or theft and without the\n>>> hassle of a lot of safe deposit boxes (or other secure seed storage\n>>> locations).\n>>>\n>>> Cheers,\n>>> BT\n>>>\n>>>\n>>>\n>>>\n>>>\n>>> On Mon, Jul 26, 2021 at 2:08 PM James MacWhyte <macwhyte at gmail.com>\n>>> wrote:\n>>>\n>>>> Hi Billy!\n>>>>\n>>>> See above, but to break down that situation a bit further, these are\n>>>>> the two situations I can think of:\n>>>>>\n>>>>>    1. The opcode limits user/group A to send the output to user/group\n>>>>>    B\n>>>>>    2. The opcode limits user A to send from one address they own to\n>>>>>    another address they own.\n>>>>>\n>>>>> I'm trying to think of a good use case for this type of opcode. In\n>>>> these examples, an attacker who compromises the key for user A can't steal\n>>>> the money because it can only be sent to user B. So if the attacker wants\n>>>> to steal the funds, they would need to compromise the keys of both user A\n>>>> and user B.\n>>>>\n>>>> But how is that any better than a 2-of-2 multisig? Isn't the end result\n>>>> exactly the same?\n>>>>\n>>>> James\n>>>>\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210728/9ad7f8bf/attachment-0001.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2021-07-28T17:57:09",
                "message_text_only": "Hi Zac,\n\n> a smart wallet should be able to set up and maintain multiple\nrate-limited addresses in such a way that their aggregate behaviour meets\nany rate-limiting parameters as desired by the user\n\nI think that would be possible if there was a way to say \"within the last B\nblocks, this output can only spend to addresses other than X,Y,Z an amount\nless than C coins minus however much coins have been spent by those\naddresses in the last B blocks\". This would require that full nodes keep\naround information about which addresses have been spent from recently, so\nthat information is accessible during script execution. This could be made\na bit less heavy by requiring countable transactions to run some particular\nopcode (so only opted-in transactions would need to be stored).\n\n> This ought to alleviate your privacy concerns because it means that the\nwallet will be able to mix outputs.\n\nThe ability to mix outputs isn't a privacy issue. The ability to keep\noutputs separate is the privacy issue. For rate-limiting to work, the\noutputs must be associated with eachother so that rate limiting can take\nthem all into account. It seems to me that its fundamentally impossible to\ndo this while keeping outputs uncorrelated.\n\n> such user-enabled rate-limiting is superior to one that requires a third\nparty.\n\nRemoving a 3rd party certainly has upsides. However, using a 3rd party\nwould be able to solve the privacy issue by keeping outputs uncorrelated\n(in different addresses) to the outside world. Trade offs.\n\nIn any case, if you want to continue talking about rate-limiting\ntransactions, it might be a good idea to start a new thread for that, since\nits a bit off topic for this one.\n\n> how a vault solution would be able to prevent an attacker who is in\npossession of the vaults\u2019 private key from sabotaging the user by replacing\nthe user transaction with one having a higher fee every time the user\nattempts to transact\n\nA wallet vault has multiple keys. If one key is stolen, the user can use\ntwo keys to override the attacker's transaction. If two keys are stolen,\nthe user can use three keys. Etc. The attacker must have as many keys as\nthe user can use in order to successfully steal funds. This can happen in\none of these kinds of ways:\n\nA. The attacker steals all keys.\nB. The attacker steals half the keys and ensures that the victim doesn't\nhave access to those keys (eg the attacker steals the only copy of half the\nkeys).\nC. The attacker steals any key and incapacitates the victim for the entire\ncooldown period, so they can't use any of their keys.\n\nIn case C, it would be useful to have rate limiting actually.\n\nOn Tue, Jul 27, 2021 at 9:57 PM Zac Greenwood <zachgrw at gmail.com> wrote:\n\n> Hi Billy,\n>\n> Thank you for your comprehensive reply. My purpose was to find out whether\n> a proposal to somehow limit the amount being sent from an address exists\n> and to further illustrate my thoughts by giving a concrete example of how\n> this might work functionally without getting to deep into the\n> technicalities.\n>\n> As for your assumption: for an amount limit to have the desired effect, I\n> realize now that there must also exist some limit on the number of\n> transactions that will be allowed from the encumbered address.\n>\n> Taking a step back, a typical use case would be a speculating user\n> intending to hodl bitcoin but who still wishes to be able to occasionally\n> transact minor amounts.\n>\n> Ideally, such user should optionally still be able to bypass the rate\n> limit and spend the entire amount in a single transaction by signing with\n> an additional private key (multisig).\n>\n> During the setup phase, a user sends all their to-be-rate-limited coin to\n> a single address. When spending from this rate limited address, any change\n> sent to the change address must be rate limited as well using identical\n> parameters. I believe that\u2019s also what you\u2019re suggesting.\n>\n> I believe that a smart wallet should be able to set up and maintain\n> multiple rate-limited addresses in such a way that their aggregate\n> behaviour meets any rate-limiting parameters as desired by the user. This\n> ought to alleviate your privacy concerns because it means that the wallet\n> will be able to mix outputs.\n>\n> The options for the to-be implemented rate-limiting parameters vary from\n> completely arbitrary to more restrictive.\n>\n> Completely arbitrary parameters would allow users to set up a rate limit\n> that basically destroys their funds, for instance rate-limiting an address\n> to an amount of 1 satoshi per 100 blocks.\n>\n> More restrictive rate limits would remove such footgun and may require\n> that only a combination of parameters are allowed such that all funds will\n> be spendable within a set number of blocks (for instance 210,000).\n>\n> As for the rate-limiting parameters, in addition to a per-transaction\n> maximum of (minimum amount in satoshi or a percentage of the total amount\n> stored at the address), also the transaction frequency must be limited. I\n> would propose this to be expressed as a number of blocks before a next\n> transaction can be sent from the encumbered address(es).\n>\n> I believe such user-enabled rate-limiting is superior to one that requires\n> a third party.\n>\n> As an aside, I am not sure how a vault solution would be able to prevent\n> an attacker who is in possession of the vaults\u2019 private key from sabotaging\n> the user by replacing the user transaction with one having a higher fee\n> every time the user attempts to transact. I am probably missing something\n> here though.\n>\n> Zac\n>\n>\n> On Tue, 27 Jul 2021 at 19:21, Billy Tetrud <billy.tetrud at gmail.com> wrote:\n>\n>> Hi Zac,\n>>\n>> I haven't heard of any proposal for limiting the amount that can be sent\n>> from an address. I assume you mean limiting the amount that can be sent in\n>> a period of time - eg something that would encode that for address A, only\n>> X bitcoin can be sent from the address in a given day/week/etc, is that\n>> right? That would actually be a somewhat difficult thing to do in the\n>> output-based system Bitcoin uses, and would be easier in an account based\n>> system like Ethereum. The problem is that each output is separate, and\n>> there's no concept in bitcoin of encumbering outputs together.\n>>\n>> What you could do is design a system where coins would be combined in a\n>> single output, and then encumber that output with a script that allows a\n>> limited amount of coin be sent to a destination address and requires all\n>> other bitcoins be returned to sender in a new change output that is also\n>> timelocked. That way, the new change output can't be used again until the\n>> timelock expires (eg a week). However, to ensure this wallet works\n>> properly, any deposit into the wallet would have to also spend the wallet's\n>> single output, so as to create a new single output at that address. So 3rd\n>> parties wouldn't be able to arbitrarily send money in (or rather, they\n>> could, but each output would have its own separate spending limit).\n>>\n>> > such kind of restriction would be extremely effective in thwarting the\n>> most damaging type of theft being the one where all funds are swept in a\n>> single transaction\n>>\n>> It would. However a normal wallet vault basically already has this\n>> property - a thief can't simply sweep funds instantly, but instead the\n>> victim will see an initiated transaction and will be able to reverse it\n>> within a delay time-window. I don't think adding a spending limit would add\n>> meaningful security to a delayed-send wallet vault like that. But it could\n>> be used to increase the security of a wallet vault that can be instantly\n>> spent from - ie if the attacker successfully steals funds, then the victim\n>> has time to go gather their additional keys and move the remaining\n>> (unstolen) funds into a new wallet.\n>>\n>> OP_CD could potentially be augmented to allow specifying limit amounts\n>> for each destination, which would allow you to create a wallet like this.\n>> It would be a bit of an awkward wallet to use tho, since you couldn't\n>> receive directly into it from a 3rd party and you also couldn't keep\n>> separate outputs (which is bad for privacy).\n>>\n>> An alternate way of doing this that you don't need any new opcodes for\n>> would be to have a 3rd party service that signs multisig transactions from\n>> a wallet only up to a limit. The end-user could have additional keys such\n>> that the 3rd party can't prevent them from accessing that (if they turn\n>> uncooperative), and the 3rd party would only have a single key so they\n>> can't steal funds, but the user would sign a transaction with one key, and\n>> the 3rd party with another as long as the spending limit hasn't been\n>> reached. This wouldn't have much counterparty risk, but would be a less\n>> awkward wallet than what I described above - meaning anyone could send\n>> funds into the wallet without defeating the spending limit, and privacy\n>> could be kept intact (minus the fact that the 3rd party would know what\n>> your outputs are).\n>>\n>> BT\n>>\n>> On Tue, Jul 27, 2021 at 4:18 AM Zac Greenwood <zachgrw at gmail.com> wrote:\n>>\n>>> Hi Billy,\n>>>\n>>> On the topic of wallet vaults, are there any plans to implement a way to\n>>> limit the maximum amount to be sent from an address?\n>>>\n>>> An example of such limit might be: the maximum amount allowed to send is\n>>> max(s, p) where s is a number of satoshi and p a percentage of the total\n>>> available (sendable) amount.\n>>>\n>>> A minimum value may be imposed on the percentage to ensure that the\n>>> address can be emptied within a reasonable number of transactions. The\n>>> second parameter s allows a minimum permitted amount. (This is necessary\n>>> because with only the percentage parameter the minimum permitted amount\n>>> converges to zero, making it impossible to empty the address).\n>>>\n>>> There may be other ways too. In my view, such kind of restriction would\n>>> be extremely effective in thwarting the most damaging type of theft being\n>>> the one where all funds are swept in a single transaction.\n>>>\n>>> Zac\n>>>\n>>>\n>>> On Tue, 27 Jul 2021 at 03:26, Billy Tetrud via bitcoin-dev <\n>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> Hey James,\n>>>>\n>>>> In the examples you mentioned, what I was exploring was a mechanism of\n>>>> attack by which the attacker could steal user A's key and use that key to\n>>>> send a transaction with the maximum possible fee. User B would still\n>>>> receive some funds (probably), but if the fee could be large, the attacker\n>>>> would either do a lot of damage to user B (griefing) or could make an\n>>>> agreement with a miner to give back some of the large fee (theft).\n>>>>\n>>>> But as for use cases, the proposal mentions a number of use cases\n>>>> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/bip-constraindestination.md#motivation> and\n>>>> most overlap with the use cases of op_ctv <https://utxos.org/uses/> (Jeremy\n>>>> Rubin's website for op_ctv has a lot of good details, most of which are\n>>>> also relevant to op_cd). The use case I'm most interested in is wallet\n>>>> vaults. This opcode can be used to create a wallet vault where the user\n>>>> only needs to use, for example, 1 key to spend funds, but the attacker must\n>>>> steal 2 or more keys to spend funds. The benefits of a 2 key wallet vault\n>>>> like this vs a normal 2-of-2 multisig wallet are that not only does an\n>>>> attacker have to steal both keys (same level of security), but also the\n>>>> user can lose one key and still recover their funds (better redundancy) and\n>>>> also that generally the user doesn't need to access their second key - so\n>>>> that can remain in a much more secure location (which would also probably\n>>>> make that key harder to steal). The only time the second key only comes\n>>>> into play if one key is stolen and the attacker attempts to send a\n>>>> transaction. At that point, the user would go find and use his second key\n>>>> (along with the first) to send a revoke transaction to prevent the attacker\n>>>> from stealing their funds. This is somewhat akin to a lightning watchtower\n>>>> scenario, where your wallet would watch the chain and alert you about an\n>>>> unexpected transaction, at which point you'd manually do a revoke (vs a\n>>>> watchtower's automated response). You might be interested in taking a look\n>>>> at this wallet vault design\n>>>> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/op_cdWalletVault1.md>\n>>>> that uses OP_CD or even my full vision\n>>>> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults> of the\n>>>> wallet vault I want to be able to create.\n>>>>\n>>>> With a covenant opcode like this, its possible to create very usable\n>>>> and accessible but highly secure wallets that can allow normal people to\n>>>> hold self custody of their keys without fear of loss or theft and without\n>>>> the hassle of a lot of safe deposit boxes (or other secure seed storage\n>>>> locations).\n>>>>\n>>>> Cheers,\n>>>> BT\n>>>>\n>>>>\n>>>>\n>>>>\n>>>>\n>>>> On Mon, Jul 26, 2021 at 2:08 PM James MacWhyte <macwhyte at gmail.com>\n>>>> wrote:\n>>>>\n>>>>> Hi Billy!\n>>>>>\n>>>>> See above, but to break down that situation a bit further, these are\n>>>>>> the two situations I can think of:\n>>>>>>\n>>>>>>    1. The opcode limits user/group A to send the output to\n>>>>>>    user/group B\n>>>>>>    2. The opcode limits user A to send from one address they own to\n>>>>>>    another address they own.\n>>>>>>\n>>>>>> I'm trying to think of a good use case for this type of opcode. In\n>>>>> these examples, an attacker who compromises the key for user A can't steal\n>>>>> the money because it can only be sent to user B. So if the attacker wants\n>>>>> to steal the funds, they would need to compromise the keys of both user A\n>>>>> and user B.\n>>>>>\n>>>>> But how is that any better than a 2-of-2 multisig? Isn't the end\n>>>>> result exactly the same?\n>>>>>\n>>>>> James\n>>>>>\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>\n>>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210728/d57202f0/attachment-0001.html>"
            },
            {
                "author": "Jeremy",
                "date": "2021-07-28T22:30:19",
                "message_text_only": "High level feedback:\n\nyou should spec out the opcodes as separate pieces of functionality as it\nsounds like OP_CD is really 3 or 4 opcodes in one (e.g., amounts to\noutputs, output addresses, something with fees).\n\nOne major drawback of your approach is that all transactions are twice as\nlarge as they might otherwise need to be for simple things like congestion\ncontrol trees, since you have to repeat all of the output data twice.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210728/327b67b8/attachment.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2021-07-30T18:42:23",
                "message_text_only": "Thanks for taking another look Jeremy. That's an interesting idea to split\nit up into simpler opcodes, however there are some\nlimitations/considerations there.\n\nFor example, with output addresses, I added specifying amounts to outputs\nin order to make script evaluation simpler and eliminate a potential DOS\nvector. I wrote about this in the section 'Specifying values sent to each\noutput\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/bip-constraindestination.md#specifying-values-sent-to-each-output>'.\nOriginally, I designed OP_CD without specifying what amounts an input\ncontributes to what outputs, but it seemed like this would require\ncalculating various combinations of inequalities, which could get expensive\nin scenarios where many inputs had overlapping destinations. See the\nexamples under the OP_CD section in this commit\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/commit/9b2257410b5f0fc991f68e774c3faf601c02cc5d>\n.\n\nMaybe there's an elegant and cheap way of verifying that a number of inputs\nthat have destination address limitations is within limits, but if so I\ndon't know how to do that. If there was a good way to do that, then I\nwouldn't want to propose the ability to validate that specific amounts go\nto specific outputs. So unless there's a simple and dos-vector-free way of\nevaluating what addresses an input goes to without knowing what amounts an\ninput contributes to each output, I don't think these functionalities\nshould be separated.\n\nAnd about a fee-limit opcode, that could certainly be done on its own.\nHowever, a version of OP_CD that doesn't specify fees would have to take\nthe fee-limit into account, and the calculation for the stand-alone\nfee-limit operation would be moot for that output.\n\nSo I think it could make sense to split the fee limit off from the rest of\nOP_CD. I'm curious to know what others think of that.\n\n> all transactions are twice as large as they might otherwise need to be\nfor simple things like congestion control trees, since you have to repeat\nall of the output data twice\n\nWell, the transaction wouldn't be quite twice as large. Each output would\nadd 9 bytes to the transaction, and outputs already are a minimum of about\n30 bytes I think? So for transactions with a lot of outputs, it could make\nthe transaction about 1/3 larger. I'll add a section on this into my\nproposal.\n\nPerhaps it would be a reasonable optimization to allow omitting an output\nvalue in cases where the entire output amount is contributed by that input.\nThis would reduce the overhead of specifying output amounts to 2 bytes for\nmost outputs (1 byte for the index, another to indicate the full value),\nmeaning that it would only make the transaction about 7% larger. What do\nyou think about that idea?\n\nOn Wed, Jul 28, 2021 at 3:30 PM Jeremy via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> High level feedback:\n>\n> you should spec out the opcodes as separate pieces of functionality as it\n> sounds like OP_CD is really 3 or 4 opcodes in one (e.g., amounts to\n> outputs, output addresses, something with fees).\n>\n> One major drawback of your approach is that all transactions are twice as\n> large as they might otherwise need to be for simple things like congestion\n> control trees, since you have to repeat all of the output data twice.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210730/b2f29d8d/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Covenant opcode proposal OP_CONSTRAINDESTINATION (an alternative to OP_CTV)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy",
                "David A. Harding",
                "James MacWhyte",
                "Zac Greenwood",
                "Billy Tetrud"
            ],
            "messages_count": 13,
            "total_messages_chars_count": 69370
        }
    },
    {
        "title": "[bitcoin-dev] Exploring: limiting transaction output amount as a function of total input value",
        "thread_messages": [
            {
                "author": "Zac Greenwood",
                "date": "2021-07-31T20:01:49",
                "message_text_only": "Hi list,\n\nI'd like to explore whether it is feasible to implement new scripting\ncapabilities in Bitcoin that enable limiting the output amount of a\ntransaction based on the total value of its inputs. In other words, to\nimplement the ability to limit the maximum amount that can be sent from an\naddress.\n\nTwo use cases come to mind:\n\nUC1: enable a user to add additional protection their funds by\nrate-limiting the amount they are able to send during a certain period\n(measured in blocks). A typical use case might be a user that intends to\nhodl their bitcoin, but still wishes to occasionally send small amounts.\nThis avoids an attacker from sweeping all their funds in a single\ntransaction, allowing the user to become aware of the theft and intervene\nto prevent further theft.\n\nUC2: exchanges may wish to rate-limit addresses containing large amounts of\nbitcoin, adding warm- or hot-wallet functionality to a cold-storage\naddress. This would enable an exchange to drastically reduce the number of\ntimes a cold wallet must be accessed with private keys that enable access\nto the full amount.\n\nIn a typical setup, I'd envision using multisig such that the user has two\nsets of private keys to their encumbered address (with a \"set\" of keys\nmeaning \"one or more\" keys). One set of private keys allows only for\nsending with rate-limiting restrictions in place, and a s second set of\nprivate keys allowing for sending any amount without rate-limiting,\neffectively overriding such restriction.\n\nThe parameters that define in what way an output is rate-limited might be\ndefined as follows:\n\nParam 1: a block height \"h0\" indicating the first block height of an epoch;\nParam 2: a block height \"h1\" indicating the last block height of an epoch;\nParam 3: an amount \"a\" in satoshi indicating the maximum amount that is\nallowed to be sent in any epoch;\nParam 4: an amount \"a_remaining\" (in satoshi) indicating the maximum amount\nthat is allowed to be sent within the current epoch.\n\nFor example, consider an input containing 100m sats (1 BTC) which has been\nrate-limited with parameters (h0, h1, a, a_remaning) of (800000, 800143,\n500k, 500k). These parameters define that the address is rate-limited to\nsending a maximum of 500k sats in the current epoch that starts at block\nheight 800000 and ends at height 800143 (or about one day ignoring block\ntime variance) and that the full amount of 500k is still sendable. These\nrate-limiting parameters ensure that it takes at minimum 100m / 500k = 200\ntransactions and 200 x 144 blocks or about 200 days to spend the full 100m\nsats. As noted earlier, in a typical setup a user should retain the option\nto transact the entire amount using a second (set of) private key(s).\n\nFor rate-limiting to work, any change output created by a transaction from\na rate-limited address must itself be rate-limited as well. For instance,\nexpanding on the above example, assume that the user spends 200k sats from\na rate-limited address a1 containing 100m sats:\n\nStart situation:\nAt block height 800000: rate-limited address a1 is created;\nValue of a1: 100.0m sats;\nRate limiting params of a1: h0=800000, h1=800143, a=500k, a_remaining=500k;\n\nTransaction t1:\nIncluded at block height 800100;\nSpend: 200k + fee;\nRate limiting params: h0=800000, h1=800143, a=500k, a_remaining=300k.\n\nResult:\nValue at destination address: 200k sats;\nRate limiting params at destination address: none;\nValue at change address a2: 99.8m sats;\nRate limiting params at change address a2: h0=800000, h1=800143, a=500k,\na_remaining=300k.\n\nIn order to properly enforce rate limiting, the change address must be\nrate-limited such that the original rate limit of 500k sats per 144 blocks\ncannot be exceeded. In this example, the change address a2 were given the\nsame rate limiting parameters as the transaction that served as its input.\nAs a result, from block 800100 up until and including block 800143, a\nmaximum amount of 300k sats is allowed to be spent from the change address.\n\nExample continued:\na2: 99.8 sats at height 800100;\nRate-limit params: h0=800000, h1=800143, a=500k, a_remaining=300k;\n\nTransaction t2:\nIncluded at block height 800200\nSpend: 400k + fees.\nRate-limiting params: h0=800144, h1=800287, a=500k, a_remaining=100k.\n\nResult:\nValue at destination address: 400k sats;\nRate limiting params at destination address: none;\nValue at change address a3: 99.4m sats;\nRate limiting params at change address a3: h0=800144, h1=800287, a=500k,\na_remaining=100k.\n\nTransaction t2 is allowed because it falls within the next epoch (running\nfrom 800144 to 800287) so a spend of 400k does not violate the constraint\nof 500k per epoch.\n\nAs could be seen, the rate limiting parameters are part of the transaction\nand chosen by the user (or their wallet). This means that the parameters\nmust be validated to ensure that they do not violate the intended\nconstraints.\n\nFor instance, this transaction should not be allowed:\na2: 99.8 sats at height 800100;\nRate-limit params of a2: h0=800000, h1=800143, a=500k, a_remaining=300k;\n\nTransaction t2a:\nIncluded at block height 800200;\nSpend: 400k + fees;\nRate-limit params: h0=800124, h1=800267, a=500k, a_remaining=100k.\n\nThis transaction t2a attempts to shift the epoch forward by 20 blocks such\nthat it starts at 800124 instead of 800144. Shifting the epoch forward like\nthis must not be allowed because it enables spending more that the rate\nlimit allows, which is 500k in any epoch of 144 blocks. It would enable\noverspending:\n\nt1: spend 200k at 800100 (epoch 1: total: 200k);\nt2a: spend 400k at 800200 (epoch 2: total: 400k);\nt3a: spend 100k at 800201 (epoch 2: total: 500k);\nt4a: spend 500k at 800268 (epoch 2: total: 1000k, overspending for epoch 2).\n\nSpecifying the rate-limiting parameters explicitly at every transaction\nallows the user to tighten the spending limit by setting tighter limits or\nfor instance by setting a_remainder to 0 if they wish to enforce not\nspending more during an epoch.\n\nI will stop here because I would like to gauge interest in this idea first\nbefore continuing work on other aspects. Two main pieces of work jump to\nmind:\n\nDefine all validations;\nDescribe aggregate behaviour of multiple (rate-limited) inputs, proof that\ntwo rate-limited addresses cannot spend more than the sum of their\nindividual limits.\n\nZac\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210731/48005608/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Exploring: limiting transaction output amount as a function of total input value",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Zac Greenwood"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 6470
        }
    },
    {
        "title": "[bitcoin-dev] BIP proposal: Anti-fee-sniping protection with nSequence in taproot transactions to improve privacy for off-chain protocols",
        "thread_messages": [
            {
                "author": "Chris Belcher",
                "date": "2021-07-22T14:44:11",
                "message_text_only": "Hello list,\n\nSomeone reviewing my taproot privacy BIP proposal suggested\nclarification on the spec, so I've written some python-like pseudocode.\nIt implements the suggestion of choosing a random input instead of the\nfirst one.\n\nSome wallet teams are already working on implementing taproot for their\non-chain app. I urge wallet developers to include this BIP as well, so\nthat their user's spends will improve the privacy and fungibility of\noff-chain protocols. Also, and admittedly a less urgently,\nanti-fee-sniping will improve the incentives for miners in the\nlow-inflation future of bitcoin.\n\nAs before find the latest version of this BIP here:\nhttps://gist.github.com/chris-belcher/903feab321bf41055c91eaec46581e89\n\n\ndef apply_anti_fee_sniping_fields(transaction):\n    # bip68 requires v=2\n    transaction.version = 2\n    # always set nlocktime if any of the transaction inputs have more\n    # confirmations than 65535 or are taproot inputs\n    # otherwise choose either nlocktime or nsequence with 50% odds\n    if any(map(lambda input: input.confirmations() > 65535\n\t    || input.is_taproot(), transaction.inputs))\\\n\t    || randint(2) == 0:\n\ttransaction.nlocktime = blockchain.height()\n\tif randint(10) == 0:\n\t    transaction.nlocktime = max(0, transaction.nlocktime\n\t    - randint(0, 99))\n    else:\n\tinput_index = randint(len(transaction.inputs))\n\ttransaction.inputs[input_index].nsequence = transaction.inputs\\\n\t    [input_index].confirmations()\n\tif randint(10) == 0:\n\t    transaction.inputs[input_index].nsequence = max(0,\n\t\ttransaction.inputs[input_index].nsequence\n                - randint(0, 99))"
            }
        ],
        "thread_summary": {
            "title": "BIP proposal: Anti-fee-sniping protection with nSequence in taproot transactions to improve privacy for off-chain protocols",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Chris Belcher"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1607
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Privacy Week/Month",
        "thread_messages": [
            {
                "author": "Prayank",
                "date": "2021-07-23T18:48:31",
                "message_text_only": "Hello World,\n\nWhat?\n\nI would love if Bitcoin developers would celebrate a 'Bitcoin Privacy week or month' once in an year. Not sure about the dates. Enthusiasm can be similar to Valentines week or Secret Santa week but Seriousness should be like Wikileaks or Human Rights Foundation.\n\nWhy?\n\nI am not sure if we need reasons, charts, etc. to discuss privacy and make all users aware of things involved. People consider privacy issues as something that can be ignored, for me they are same as security issues and very important in network like Bitcoin. Most of the people may still ignore it considering the feedback on few issues related to privacy in past. Although we can still try and its a new day. Not giving up is what makes the difference in the end.\n\nAlso I would like to clarify, there are lot of positives and people that have contributed a lot to improve privacy in Bitcoin but they will never get similar appreciation as compared to few others because of different reasons which I don't want to discuss here and one of them is decentralization.\u00a0 Don't want to mention names but there have been influencers in past who are followed by lot of people for their thoughts on privacy but a normal Bitcoin Core Contributor with less than 1000 followers and lot of work that improved privacy in Bitcoin is ignored.\n\nThis is a speech from an Indian web series which only people who know Hindi would understand:\u00a0https://www.youtube.com/watch?v=ztBfQU41s-o\n\nTL;DR:\u00a0\nThis guy was not allowed to talk about his product\nHe still argued that he cannot talk about the product but still talk about something in 5 minutes.\nHe says nobody cares about \"What\", they are interested in \"Why\"\nHe is scared and feels like a contestant in reality show in which he can't even perform.\nMost important thing: Never give up\nMentors, Angel Investors etc. are external things that you don't control, what you can do is prove things with your work.\nHe couldn't sell his product so he sold himself.\nI will keep trying to improve privacy or talk about it when I cannot code in few things. Request other developers to help.\nHow?\n\nShare 1 issue from repository of any Bitcoin project related to privacy and your thoughts.\nShare 1 pull request\nShare anything else that you think may help improve things related to privacy\nMailing list or Twitter or something else? I am not sure.\n\nIs this off topic? If yes, apologize and maybe request same people on other channels.\u00a0\n-- \n Prayank\n\nA3B1 E430 2298 178F\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20210723/801e0768/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Privacy Week/Month",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Prayank"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2657
        }
    },
    {
        "title": "[bitcoin-dev] Last week's second IRC workshop on L2 onchain support and wrap up",
        "thread_messages": [
            {
                "author": "Michael Folkson",
                "date": "2021-07-29T11:36:25",
                "message_text_only": "There was some additional discussion on L2 onchain support at the\nrecent online Sydney Socratic Seminar. It wasn't recorded but a\ntranscript is below.\n\nTranscript: https://btctranscripts.com/sydney-bitcoin-meetup/2021-07-06-socratic-seminar/\n\nThe discussion focused partly on the rules [1] of BIP 125 RBF and the\nrationale for these rules (which isn't clear from the BIP). Proposed\nideas such as SIGHASH_IOMAP, fee sponsorship and transaction mutation\nwere also discussed that weren't covered during the IRC workshops.\n\n[1] https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki#implementation-details\n\nOn Tue, Jun 29, 2021 at 10:44 AM Michael Folkson\n<michaelfolkson at gmail.com> wrote:\n>\n> A summary of the first workshop is here:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-June/019079.html\n>\n> The focus for this second workshop was fee bumping and package relay.\n> For more details on package relay see:\n> https://github.com/ariard/L2-zoology/blob/master/workshops/package-relay-and-friends.md\n>\n> The conversation log for the second workshop is here:\n> https://gist.github.com/ariard/32b51ecceccc5c6f647bae86d083c442\n>\n> Package relay background\n>\n> Package relay is potentially useful for L2 protocols to address the\n> inherent unpredictability of future fees. CPFP (child-pays-for-parent)\n> seeks to ensure say a justice transaction, in Lightning\u2019s case, with a\n> lower fee, gets confirmed in a more timely manner because miners are\n> incentivized to include the child transaction in a block. To do so\n> they must include the parent transaction in that block or a preceding\n> block. By \u201cpackaging\u201d the parent and the child the initiator of the\n> transaction(s) can ensure the miner\u2019s mempool doesn\u2019t initially reject\n> the parent transaction for having a too low fee.\n>\n> There has been prior work done in previous years on package relay,\n> mainly by Suhas Daftuar.\n>\n> Draft BIP: https://gist.github.com/sdaftuar/8756699bfcad4d3806ba9f3396d4e66a\n>\n> Package relay design questions: https://github.com/bitcoin/bitcoin/issues/14895\n>\n> Recently Gloria Zhao has been advancing package relay in Bitcoin Core:\n> https://gist.github.com/glozow/7064717e727a3eb27fad4f8504513add\n>\n> Package relay implementation\n>\n> Attendees seemed in agreement that enabling 2 transaction packages\n> would be sufficient (at least for now) for Lightning and DLCs. A L2\n> protocol should always be able to design a two step process where the\n> first transaction has an effective zero fee rate and the second\n> transaction sets the fee. Restricting the size of the package to 2 may\n> have the cost of slightly longer confirmation times and/or slightly\n> higher fees (t-bast) but it compares well to the increased\n> implementation complexity of larger package sizes. Two generation:\n> multi parent, single child shouldn\u2019t introduce material implementation\n> complexity over two generation: single parent, single child (glozow).\n>\n> Package RBF (replace-by-fee) is possible where there are two competing\n> packages with competing Lightning commitment transactions in them and\n> the second package is given a higher fee to attempt to get it\n> confirmed before the first package. However, supporting RBF within a\n> package (ie replacing a transaction in a package with a higher fee\n> transaction) increases implementation complexity and makes it harder\n> to reason about (glozow).\n>\n> rgrant raised the possibility of using two packages {A,B} and {B,C} if\n> three transaction packages e.g. {A,B,C} weren\u2019t supported but it was\n> suggested it is perhaps better to just broadcast a high fee CPFP\n> transaction for the {A,B} package rather than creating two packages.\n> If the first package has been evicted from the mempool the {B,C}\n> package wouldn\u2019t propagate because it would be an orphan package\n> (t-bast).\n>\n> glozow suggested that only hints (wtxids of transactions you think\n> should be package validated) could be communicated rather than\n> relaying the transaction themselves but there were concerns from\n> others on whether these hints would successfully propagate across the\n> network. Instead fee rate hints could be sent to inform a peer\u2019s\n> decision on whether it makes sense to fetch the rest of the package\n> (t-bast).\n>\n> darosior suggested the idea of a package based CBlockPolicyEstimator\n> in Bitcoin Core if CPFP is going to be increasingly used on the\n> network.\n>\n> Witness replacement and Taproot\n>\n> Tapscripts can be unlimited in size so with current Taproot rules you\n> could in theory go from a 100,000 vbyte witness to an empty witness.\n> L2 protocols may have a UTXO shared by two parties where Alice\u2019s\n> witness for her branch is say 1,000 vbytes and Bob\u2019s witness is only\n> say 250 vbytes. Replacing Alice\u2019s larger witness with Bob\u2019s smaller\n> witness could reduce transaction fees. For Lightning the best case is\n> a Taproot key path spend (16 vbyte witness) and the worst case is\n> going to be a 150 vbyte witness. Miniscript can tell you your worst\n> case transaction size and this can be used to assess the transaction\n> pinning risk of a bloated witness (all harding).\n>\n> A future soft fork could give meaning to the annex in Taproot\n> (darosior) which could be used for inflating the fee rate of a\n> witness. Then you could have a same-txid-different-wtxid coming after\n> with a lower fee rate but higher vbytes size to override package\n> limits (ariard). But fee rate is purely a policy concept and the annex\n> operates at the consensus level. In addition the annex can only\n> increase the weight of a transaction, it cannot decrease it (harding).\n>\n> Wrap up and initial goals\n>\n> With regards to the goals of the workshops that were initially\n> announced here:\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-April/003002.html\n>\n> 1) 2 transactions packages sounds enough to support currently deployed\n> L2 protocols\n> 2) There are ongoing discussions in the ecosystem regarding\n> deprecation of opt in RBF and implementation of full RBF:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-June/019074.html\n> 3) Generally status quo and ad hoc security incident response policy\n> in the case of cross-layer security issues\n> 4) Generally status quo on L2 security philosophy design. L2 protocol\n> designers should seek to minimize assumptions on the base layer.\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at gmail.com\n> Keybase: michaelfolkson\n> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n\n\n\n-- \nMichael Folkson\nEmail: michaelfolkson at gmail.com\nKeybase: michaelfolkson\nPGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3"
            }
        ],
        "thread_summary": {
            "title": "Last week's second IRC workshop on L2 onchain support and wrap up",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Michael Folkson"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 6621
        }
    }
]