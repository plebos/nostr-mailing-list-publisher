[
    {
        "title": "[bitcoin-dev] Version 1 witness programs (first draft)",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2017-10-01T01:13:29",
                "message_text_only": "I've put together a first draft for what I hope to be a good next step for \nSegwit and Bitcoin scripting:\n    https://github.com/luke-jr/bips/blob/witnessv1/bip-witnessv1.mediawiki\n\nThis introduces 5 key changes:\n\n1. Minor versions for witnesses, inside the witness itself. Essentially the \nwitness [major] version 1 simply indicates the witness commitment is SHA256d, \nand nothing more.\n\nThe remaining two are witness version 1.0 (major 1, minor 0):\n\n2. As previously discussed, undefined opcodes immediately cause the script to \nexit with success, making future opcode softforks a lot more flexible.\n\n3. If the final stack element is not exactly true or false, it is interpreted \nas a tail-call Script and executed. (Credit to Mark Friedenbach)\n\n4. A new shorter fixed-length signature format, eliminating the need to guess \nthe signature size in advance. All signatures are 65 bytes, unless a condition \nscript is included (see #5).\n\n5. The ability for signatures to commit to additional conditions, expressed in \nthe form of a serialized Script in the signature itself. This would be useful \nin combination with OP_CHECKBLOCKATHEIGHT (BIP 115), hopefully ending the \nwhole replay protection argument by introducing it early to Bitcoin before any \nfurther splits.\n\nThis last part is a big ugly right now: the signature must commit to the \nscript interpreter flags and internal \"sigversion\", which basically serve the \nsame purpose. The reason for this, is that otherwise someone could move the \nsignature to a different context in an attempt to exploit differences in the \nvarious Script interpretation modes. I don't consider the BIP deployable \nwithout this getting resolved, but I'm not sure what the best approach would \nbe. Maybe it should be replaced with a witness [major] version and witness \nstack?\n\nThere is also draft code implementing [the consensus side of] this:\n    https://github.com/bitcoin/bitcoin/compare/master...luke-jr:witnessv1\n\nThoughts? Anything I've overlooked / left missing that would be \nuncontroversial and desirable? (Is any of this unexpectedly controversial for \nsome reason?)\n\nLuke"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-10-01T02:23:47",
                "message_text_only": "The CLEANSTACK rule should be eliminated, and instead the number of items on the stack should be incorporated into the signature hash. That way any script with a CHECKSIG is protected from witness extension malleability, and those rare ones that do not use signature operations can have a \u201cDEPTH 1 EQUALVERIFY\u201d at the end. This allows for much simpler tail-call evaluation as you don\u2019t need to pass arguments on the alt-stack.\n\n> On Sep 30, 2017, at 6:13 PM, Luke Dashjr via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> I've put together a first draft for what I hope to be a good next step for \n> Segwit and Bitcoin scripting:\n>    https://github.com/luke-jr/bips/blob/witnessv1/bip-witnessv1.mediawiki\n> \n> This introduces 5 key changes:\n> \n> 1. Minor versions for witnesses, inside the witness itself. Essentially the \n> witness [major] version 1 simply indicates the witness commitment is SHA256d, \n> and nothing more.\n> \n> The remaining two are witness version 1.0 (major 1, minor 0):\n> \n> 2. As previously discussed, undefined opcodes immediately cause the script to \n> exit with success, making future opcode softforks a lot more flexible.\n> \n> 3. If the final stack element is not exactly true or false, it is interpreted \n> as a tail-call Script and executed. (Credit to Mark Friedenbach)\n> \n> 4. A new shorter fixed-length signature format, eliminating the need to guess \n> the signature size in advance. All signatures are 65 bytes, unless a condition \n> script is included (see #5).\n> \n> 5. The ability for signatures to commit to additional conditions, expressed in \n> the form of a serialized Script in the signature itself. This would be useful \n> in combination with OP_CHECKBLOCKATHEIGHT (BIP 115), hopefully ending the \n> whole replay protection argument by introducing it early to Bitcoin before any \n> further splits.\n> \n> This last part is a big ugly right now: the signature must commit to the \n> script interpreter flags and internal \"sigversion\", which basically serve the \n> same purpose. The reason for this, is that otherwise someone could move the \n> signature to a different context in an attempt to exploit differences in the \n> various Script interpretation modes. I don't consider the BIP deployable \n> without this getting resolved, but I'm not sure what the best approach would \n> be. Maybe it should be replaced with a witness [major] version and witness \n> stack?\n> \n> There is also draft code implementing [the consensus side of] this:\n>    https://github.com/bitcoin/bitcoin/compare/master...luke-jr:witnessv1\n> \n> Thoughts? Anything I've overlooked / left missing that would be \n> uncontroversial and desirable? (Is any of this unexpectedly controversial for \n> some reason?)\n> \n> Luke\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Luke Dashjr",
                "date": "2017-10-01T02:47:41",
                "message_text_only": "Should it perhaps commit to the length of the serialised witness data instead \nor additionally? Now that signatures are no longer variable-length, that'd be \npossible...\n\nAs far as tail-call needs are concerned, CLEANSTACK wouldn't have been checked \nuntil AFTER the tail-call in the first draft. But I suppose eliminating it for \nother possible future purposes is still useful.\n\nLuke\n\n\nOn Sunday 01 October 2017 2:23:47 AM Mark Friedenbach wrote:\n> The CLEANSTACK rule should be eliminated, and instead the number of items\n> on the stack should be incorporated into the signature hash. That way any\n> script with a CHECKSIG is protected from witness extension malleability,\n> and those rare ones that do not use signature operations can have a \u201cDEPTH\n> 1 EQUALVERIFY\u201d at the end. This allows for much simpler tail-call\n> evaluation as you don\u2019t need to pass arguments on the alt-stack.\n> \n> > On Sep 30, 2017, at 6:13 PM, Luke Dashjr via bitcoin-dev\n> > <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > \n> > I've put together a first draft for what I hope to be a good next step\n> > for\n> > \n> > Segwit and Bitcoin scripting:\n> >    https://github.com/luke-jr/bips/blob/witnessv1/bip-witnessv1.mediawiki\n> > \n> > This introduces 5 key changes:\n> > \n> > 1. Minor versions for witnesses, inside the witness itself. Essentially\n> > the witness [major] version 1 simply indicates the witness commitment is\n> > SHA256d, and nothing more.\n> > \n> > The remaining two are witness version 1.0 (major 1, minor 0):\n> > \n> > 2. As previously discussed, undefined opcodes immediately cause the\n> > script to exit with success, making future opcode softforks a lot more\n> > flexible.\n> > \n> > 3. If the final stack element is not exactly true or false, it is\n> > interpreted as a tail-call Script and executed. (Credit to Mark\n> > Friedenbach)\n> > \n> > 4. A new shorter fixed-length signature format, eliminating the need to\n> > guess the signature size in advance. All signatures are 65 bytes, unless\n> > a condition script is included (see #5).\n> > \n> > 5. The ability for signatures to commit to additional conditions,\n> > expressed in the form of a serialized Script in the signature itself.\n> > This would be useful in combination with OP_CHECKBLOCKATHEIGHT (BIP\n> > 115), hopefully ending the whole replay protection argument by\n> > introducing it early to Bitcoin before any further splits.\n> > \n> > This last part is a big ugly right now: the signature must commit to the\n> > script interpreter flags and internal \"sigversion\", which basically serve\n> > the same purpose. The reason for this, is that otherwise someone could\n> > move the signature to a different context in an attempt to exploit\n> > differences in the various Script interpretation modes. I don't consider\n> > the BIP deployable without this getting resolved, but I'm not sure what\n> > the best approach would be. Maybe it should be replaced with a witness\n> > [major] version and witness stack?\n> > \n> > There is also draft code implementing [the consensus side of] this:\n> >    https://github.com/bitcoin/bitcoin/compare/master...luke-jr:witnessv1\n> > \n> > Thoughts? Anything I've overlooked / left missing that would be\n> > uncontroversial and desirable? (Is any of this unexpectedly controversial\n> > for some reason?)\n> > \n> > Luke\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-10-01T05:04:32",
                "message_text_only": "Clean stack should be eliminated for other possible future uses, the most obvious of which is recursive tail-call for general computation capability. I\u2019m not arguing for that at this time, just arguing that we shouldn\u2019t prematurely cut off an easy implementation of such should we want to. Clean stack must still exist as policy for future soft-fork safety, but being a consensus requirement was only to avoid witness malleability, which committing to the size of the witness also accomplishes.\n\nCommitting to the number of witness elements is fully sufficient, and using the number of elements avoids problems of not knowing the actual size in bytes at the time of signing, e.g. because the witness contains a merkle proof generated by another party from an unbalanced tree, and unbalanced trees are expected to be common (so that elements can be placed higher in the tree in accordance with their higher expected probability of usage). Other future extensions might also have variable-length proofs.\n\n> On Sep 30, 2017, at 7:47 PM, Luke Dashjr <luke at dashjr.org> wrote:\n> \n> Should it perhaps commit to the length of the serialised witness data instead \n> or additionally? Now that signatures are no longer variable-length, that'd be \n> possible...\n> \n> As far as tail-call needs are concerned, CLEANSTACK wouldn't have been checked \n> until AFTER the tail-call in the first draft. But I suppose eliminating it for \n> other possible future purposes is still useful.\n> \n> Luke"
            },
            {
                "author": "Felix Weis",
                "date": "2017-10-01T11:22:30",
                "message_text_only": "Just a simple suggestion since the signature format is changed. Can this be\ndesigned so that possible future hard forks can simply change 1 constant in\nthe code and turn on cross chain replay protection?\n\nOn Sun, Oct 1, 2017 at 1:05 PM Mark Friedenbach via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Clean stack should be eliminated for other possible future uses, the most\n> obvious of which is recursive tail-call for general computation capability.\n> I\u2019m not arguing for that at this time, just arguing that we shouldn\u2019t\n> prematurely cut off an easy implementation of such should we want to. Clean\n> stack must still exist as policy for future soft-fork safety, but being a\n> consensus requirement was only to avoid witness malleability, which\n> committing to the size of the witness also accomplishes.\n>\n> Committing to the number of witness elements is fully sufficient, and\n> using the number of elements avoids problems of not knowing the actual size\n> in bytes at the time of signing, e.g. because the witness contains a merkle\n> proof generated by another party from an unbalanced tree, and unbalanced\n> trees are expected to be common (so that elements can be placed higher in\n> the tree in accordance with their higher expected probability of usage).\n> Other future extensions might also have variable-length proofs.\n>\n> > On Sep 30, 2017, at 7:47 PM, Luke Dashjr <luke at dashjr.org> wrote:\n> >\n> > Should it perhaps commit to the length of the serialised witness data\n> instead\n> > or additionally? Now that signatures are no longer variable-length,\n> that'd be\n> > possible...\n> >\n> > As far as tail-call needs are concerned, CLEANSTACK wouldn't have been\n> checked\n> > until AFTER the tail-call in the first draft. But I suppose eliminating\n> it for\n> > other possible future purposes is still useful.\n> >\n> > Luke\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171001/4e1497ee/attachment-0001.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2017-10-01T17:36:05",
                "message_text_only": "BIP 115 provides fork-independent opt-in replay protection, which can be used \nin combination with the new signature condition scripts in this proposal.\n\nPerhaps the code can have a flag for new altcoins to easily make it mandatory \n(and we can use it on testnet?).\n\nLuke\n\n\nOn Sunday 01 October 2017 11:22:30 AM Felix Weis wrote:\n> Just a simple suggestion since the signature format is changed. Can this be\n> designed so that possible future hard forks can simply change 1 constant in\n> the code and turn on cross chain replay protection?\n> \n> On Sun, Oct 1, 2017 at 1:05 PM Mark Friedenbach via bitcoin-dev <\n> \n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > Clean stack should be eliminated for other possible future uses, the most\n> > obvious of which is recursive tail-call for general computation\n> > capability. I\u2019m not arguing for that at this time, just arguing that we\n> > shouldn\u2019t prematurely cut off an easy implementation of such should we\n> > want to. Clean stack must still exist as policy for future soft-fork\n> > safety, but being a consensus requirement was only to avoid witness\n> > malleability, which committing to the size of the witness also\n> > accomplishes.\n> > \n> > Committing to the number of witness elements is fully sufficient, and\n> > using the number of elements avoids problems of not knowing the actual\n> > size in bytes at the time of signing, e.g. because the witness contains\n> > a merkle proof generated by another party from an unbalanced tree, and\n> > unbalanced trees are expected to be common (so that elements can be\n> > placed higher in the tree in accordance with their higher expected\n> > probability of usage). Other future extensions might also have\n> > variable-length proofs.\n> > \n> > > On Sep 30, 2017, at 7:47 PM, Luke Dashjr <luke at dashjr.org> wrote:\n> > > \n> > > Should it perhaps commit to the length of the serialised witness data\n> > \n> > instead\n> > \n> > > or additionally? Now that signatures are no longer variable-length,\n> > \n> > that'd be\n> > \n> > > possible...\n> > > \n> > > As far as tail-call needs are concerned, CLEANSTACK wouldn't have been\n> > \n> > checked\n> > \n> > > until AFTER the tail-call in the first draft. But I suppose eliminating\n> > \n> > it for\n> > \n> > > other possible future purposes is still useful.\n> > > \n> > > Luke\n> > \n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Russell O'Connor",
                "date": "2017-10-01T19:05:38",
                "message_text_only": "Given the proposed fixed signature size, It seems better to me that we\ncreate a SIGHASH_WITNESS_WEIGHT flag as opposed to SIGHASH_WITNESS_DEPTH.\n\nMark, you seem to be arguing that in general we still want weight\nmalleability even with witness depth fixed, but I don't understand in what\nscenario we would want that.\n\nIt strikes me that is most scenarios all parties signing an input would do\nso after an execution path through the script has been agreed upon by all\nparties, in which case the witness weight can be fixed.\nIn rare cases where the smart contract requires that some parties sign in\nadvance of the decision about the execution path (for example, I'm thinking\nabout delegation here, but I want to keep my remarks general), we wouldn't\nwant to fix the witness depth either.\n\nA SIGHASH_WITNESS_WEIGHT would prevent all possible malleability that would\nmodify the transaction's fee/weight priority (at least for that one input),\nand greatly reduce the overall attack surface of witness malleability\nissues.\n\nOn Sun, Oct 1, 2017 at 1:04 AM, Mark Friedenbach via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Clean stack should be eliminated for other possible future uses, the most\n> obvious of which is recursive tail-call for general computation capability.\n> I\u2019m not arguing for that at this time, just arguing that we shouldn\u2019t\n> prematurely cut off an easy implementation of such should we want to. Clean\n> stack must still exist as policy for future soft-fork safety, but being a\n> consensus requirement was only to avoid witness malleability, which\n> committing to the size of the witness also accomplishes.\n>\n> Committing to the number of witness elements is fully sufficient, and\n> using the number of elements avoids problems of not knowing the actual size\n> in bytes at the time of signing, e.g. because the witness contains a merkle\n> proof generated by another party from an unbalanced tree, and unbalanced\n> trees are expected to be common (so that elements can be placed higher in\n> the tree in accordance with their higher expected probability of usage).\n> Other future extensions might also have variable-length proofs.\n>\n> > On Sep 30, 2017, at 7:47 PM, Luke Dashjr <luke at dashjr.org> wrote:\n> >\n> > Should it perhaps commit to the length of the serialised witness data\n> instead\n> > or additionally? Now that signatures are no longer variable-length,\n> that'd be\n> > possible...\n> >\n> > As far as tail-call needs are concerned, CLEANSTACK wouldn't have been\n> checked\n> > until AFTER the tail-call in the first draft. But I suppose eliminating\n> it for\n> > other possible future purposes is still useful.\n> >\n> > Luke\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171001/61186661/attachment.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-10-01T19:27:21",
                "message_text_only": "> On Oct 1, 2017, at 12:05 PM, Russell O'Connor <roconnor at blockstream.io> wrote:\n> \n> Given the proposed fixed signature size, It seems better to me that we create a SIGHASH_WITNESS_WEIGHT flag as opposed to SIGHASH_WITNESS_DEPTH.\n\nFor what benefit? If your script actually uses all the items on the stack, and if your script is not written in such a way as to allow malleability (which cannot be prevented in general), then they\u2019re equivalent. Using weight instead of depth only needlessly restricts other parties to select a witness size up-front.\n\nAnd to be clear, signing witness weight doesn\u2019t mean the witness is not malleable. The signer could sign again with a different ECDSA nonce. Or if the signer is signing from a 2-of-3 wallet, a common scenario I hope, there are 3 possible key combinations that could be used. If using MBV, a 3-element tree is inherently unbalanced and the common use case can have a smaller proof size.\n\nWitnesses are not 3rd party malleable and we will maintain that property going forward with future opcodes.\n\n> Mark, you seem to be arguing that in general we still want weight malleability even with witness depth fixed, but I don't understand in what scenario we would want that.\n\nAny time all parties are not online at the same time in an interactive signing protocol, or for which individual parties have to reconfigure their signing choices due to failures. We should not restrict our script signature system to such a degree that it becomes difficult to create realistic signing setups for people using best practices (multi-key, 2FA, etc.) to sign. If I am a participant in a signing protocol, it would be layer violating to treat me as anything other than a black box, such that internal errors and timeouts in my signing setup don\u2019t propagate upwards to the multi-party protocol.\n\nFor example, I should be able to try to 2FA sign, and if that fails go fetch my backup key and sign with that. But because it\u2019s my infrequently used backup key, it might be placed deeper in the key tree and therefore signatures using it are larger. All the other signers need care is that slot #3 in the witness is where my Merkle proof goes. They shouldn\u2019t have to restart and resign because my proof was a little larger than anticipated \u2014 and maybe they can\u2019t resign because double-spend protections!"
            },
            {
                "author": "Russell O'Connor",
                "date": "2017-10-01T19:41:46",
                "message_text_only": "On Sun, Oct 1, 2017 at 3:27 PM, Mark Friedenbach <mark at friedenbach.org>\nwrote:\n\n> > On Oct 1, 2017, at 12:05 PM, Russell O'Connor <roconnor at blockstream.io>\n> wrote:\n> >\n> > Given the proposed fixed signature size, It seems better to me that we\n> create a SIGHASH_WITNESS_WEIGHT flag as opposed to SIGHASH_WITNESS_DEPTH.\n>\n> For what benefit? If your script actually uses all the items on the stack,\n> and if your script is not written in such a way as to allow malleability\n> (which cannot be prevented in general), then they\u2019re equivalent. Using\n> weight instead of depth only needlessly restricts other parties to select a\n> witness size up-front.\n>\n\nCreating a Bitcoin script that does not allow malleability is difficult and\nrequires wasting a lot of bytes to do so, typically when handling issues\naround non-0-or-1 witness values being used with OP_IF, and dealing with\nnon-standard-zero values, etc.  Adding a witness weight flag cuts through\nthe worst of all this, and makes script design enormously simpler and makes\nscripts smaller and cheaper.\n\n\n> And to be clear, signing witness weight doesn\u2019t mean the witness is not\n> malleable. The signer could sign again with a different ECDSA nonce. Or if\n> the signer is signing from a 2-of-3 wallet, a common scenario I hope, there\n> are 3 possible key combinations that could be used. If using MBV, a\n> 3-element tree is inherently unbalanced and the common use case can have a\n> smaller proof size.\n>\n> Witnesses are not 3rd party malleable and we will maintain that property\n> going forward with future opcodes.\n>\n> > Mark, you seem to be arguing that in general we still want weight\n> malleability even with witness depth fixed, but I don't understand in what\n> scenario we would want that.\n>\n> Any time all parties are not online at the same time in an interactive\n> signing protocol, or for which individual parties have to reconfigure their\n> signing choices due to failures. We should not restrict our script\n> signature system to such a degree that it becomes difficult to create\n> realistic signing setups for people using best practices (multi-key, 2FA,\n> etc.) to sign. If I am a participant in a signing protocol, it would be\n> layer violating to treat me as anything other than a black box, such that\n> internal errors and timeouts in my signing setup don\u2019t propagate upwards to\n> the multi-party protocol.\n>\n> For example, I should be able to try to 2FA sign, and if that fails go\n> fetch my backup key and sign with that. But because it\u2019s my infrequently\n> used backup key, it might be placed deeper in the key tree and therefore\n> signatures using it are larger. All the other signers need care is that\n> slot #3 in the witness is where my Merkle proof goes. They shouldn\u2019t have\n> to restart and resign because my proof was a little larger than anticipated\n> \u2014 and maybe they can\u2019t resign because double-spend protections!\n>\n\nI'll argue that I don't want my counter-party going off and using a very\ndeeply nested key in order to subvert the fee rate we've agreed upon after\nI've signed my part of the input.  If we are doing multi-party signing of\ninputs we need to communicate anyways to construct the transaction.  I see\nno problem with requiring my counter-party to choose their keys before I\nsign so that I know up front what our fee rate is going to be.  If they\nlose their keys and need a backup, they should have to come back to me to\nresign in order that we can negotiate a new fee rate for the transaction\nand who is going to be covering how much of the fee and on which inputs.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171001/a587d6ba/attachment.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-10-01T20:39:11",
                "message_text_only": "> On Oct 1, 2017, at 12:41 PM, Russell O'Connor <roconnor at blockstream.io> wrote:\n> \n> Creating a Bitcoin script that does not allow malleability is difficult and requires wasting a lot of bytes to do so, typically when handling issues around non-0-or-1 witness values being used with OP_IF, and dealing with non-standard-zero values, etc.\n\nScript validation flags of the correct place to do this. We already have policy validation flags that check for these things. They were not made consensus rules with Segwit v0 mainly due to concern over scope creep in an already large overhaul, of my memory is correct. Script versions and quadratic hashing fixes where the minimum necessary to allow segwit to activate safely while still enabling future upgrades that would otherwise have been hard forks. We knew that we would be later changing the EC signature scheme to be something that supported signature aggregation, and that would be more appropriate time to discuss such changes. As we are considering to do now (although witness versions means we don\u2019t need to omnibus the script upgrade here either, so a v1 before signature aggregation is ready is fine IMHO).\n\nIn any case if there is any general witness malleability due to opcode semantics that it\u2019s not fixed by one of our existing policy flags, that is a bug and I would encourage you to report it.\n> I'll argue that I don't want my counter-party going off and using a very deeply nested key in order to subvert the fee rate we've agreed upon after I've signed my part of the input.  If we are doing multi-party signing of inputs we need to communicate anyways to construct the transaction.  I see no problem with requiring my counter-party to choose their keys before I sign so that I know up front what our fee rate is going to be.  If they lose their keys and need a backup, they should have to come back to me to resign in order that we can negotiate a new fee rate for the transaction and who is going to be covering how much of the fee and on which inputs.\n\nArguing that every single user should be forced to restart an interactive signing session. That\u2019s a very strong statement based on something that I would say is a preference that depends on circumstances.\n\nWhat about an optional commitment to witness size in bytes? The value zero meaning \u201cI don\u2019t care.\u201d I would argue that it should be a maximum however, and therefor serialized as part of the witness. The serialization of this would be very compact (1 plus the difference between actual and maximum, with zero meaning not used.)"
            },
            {
                "author": "Luke Dashjr",
                "date": "2017-10-01T20:43:18",
                "message_text_only": "On Sunday 01 October 2017 8:39:11 PM Mark Friedenbach wrote:\n> What about an optional commitment to witness size in bytes? The value zero\n> meaning \u201cI don\u2019t care.\u201d I would argue that it should be a maximum however,\n> and therefor serialized as part of the witness. The serialization of this\n> would be very compact (1 plus the difference between actual and maximum,\n> with zero meaning not used.)\n\nCould just do SIGHASH_WITNESS_SIZE in addition to SIGHASH_WITNESS_DEPTH..."
            },
            {
                "author": "Russell O'Connor",
                "date": "2017-10-02T20:38:49",
                "message_text_only": "On Sun, Oct 1, 2017 at 4:39 PM, Mark Friedenbach <mark at friedenbach.org>\nwrote:\n\n>\n> > On Oct 1, 2017, at 12:41 PM, Russell O'Connor <roconnor at blockstream.io>\n> wrote:\n> >\n> > Creating a Bitcoin script that does not allow malleability is difficult\n> and requires wasting a lot of bytes to do so, typically when handling\n> issues around non-0-or-1 witness values being used with OP_IF, and dealing\n> with non-standard-zero values, etc.\n>\n> Script validation flags of the correct place to do this. We already have\n> policy validation flags that check for these things. They were not made\n> consensus rules with Segwit v0 mainly due to concern over scope creep in an\n> already large overhaul, of my memory is correct. Script versions and\n> quadratic hashing fixes where the minimum necessary to allow segwit to\n> activate safely while still enabling future upgrades that would otherwise\n> have been hard forks. We knew that we would be later changing the EC\n> signature scheme to be something that supported signature aggregation, and\n> that would be more appropriate time to discuss such changes. As we are\n> considering to do now (although witness versions means we don\u2019t need to\n> omnibus the script upgrade here either, so a v1 before signature\n> aggregation is ready is fine IMHO).\n>\n\nScript validation isn't the correct place to do this.  The reason is that\nscript operations are not aware of whether the stack items they are\nprocessing are witness malleable items or Script computed values.  Let me\ntake OP_IF as one example.  When OP_IF operates directly on witness data,\nit is subject to witness malleability, and therefore one needs to add extra\ncode around that to prevent witness malleability.  On the other hand, when\nOP_IF operates on computed data, it isn't subject to malleability and can\nsafely process non-zero-or-one values. If OP_IF were restricted to\nrequiring canonical inputs, then for the cases that OP_IF operates on\ncomputed data, they will need to add extra code to canonicalize their\ninputs.  I don't think there is a correct answer here.  That is because I\nbelieve this isn't the correct place to aim to restrict witness\nmalleability.\n\nOTOH, signatures are a fine place to aim to restrict witness malleability.\nIn fact, if signatures could securely cover all witness data, I think\neveryone here would jump at the opportunity to implement that.  However,\nsince that isn't known to be possible, we are left with doing the best we\ncan, which is to have signatures cover weight (or bytes).  This prevents\nthe worst effects of witness malleability and does so without burdening\nScript development.  (This also requires signatures have a fixed size, so\nit is understandable that signature-covers-weight wasn't included in Segwit\nv0 scripts).\n\n\n> In any case if there is any general witness malleability due to opcode\n> semantics that it\u2019s not fixed by one of our existing policy flags, that is\n> a bug and I would encourage you to report it.\n> > I'll argue that I don't want my counter-party going off and using a very\n> deeply nested key in order to subvert the fee rate we've agreed upon after\n> I've signed my part of the input.  If we are doing multi-party signing of\n> inputs we need to communicate anyways to construct the transaction.  I see\n> no problem with requiring my counter-party to choose their keys before I\n> sign so that I know up front what our fee rate is going to be.  If they\n> lose their keys and need a backup, they should have to come back to me to\n> resign in order that we can negotiate a new fee rate for the transaction\n> and who is going to be covering how much of the fee and on which inputs.\n>\n> Arguing that every single user should be forced to restart an interactive\n> signing session. That\u2019s a very strong statement based on something that I\n> would say is a preference that depends on circumstances.\n>\n> What about an optional commitment to witness size in bytes? The value zero\n> meaning \u201cI don\u2019t care.\u201d I would argue that it should be a maximum however,\n> and therefor serialized as part of the witness. The serialization of this\n> would be very compact (1 plus the difference between actual and maximum,\n> with zero meaning not used.)\n\n\nI would be fine your suggestion above, though I think Luke's suggestion of\nhaving both SIGHASH_WITNESS_SIZE and SIGHASH_WITNESS_DEPTH flag is better\nbecause it is simpler.\n\nThose people worried about restarting interactive signing session in the\nunlikely event of parties not knowing what keys they are planning to use\ncan use just the SIGHASH_WITNESS_DEPTH flag.  Those people worried about\ncounterparties fiddling with fee rates can use both flags.  The choice\ndoesn't even need to be made at script commitment time.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171002/36c4797d/attachment.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-10-01T18:34:07",
                "message_text_only": "I would also suggest that the 520 byte push limitation be removed for v1 scripts as well. MERKLEBRANCHVERIFY in particular could benefit from larger proof sizes. To do so safely would require reworking script internals to use indirect pointers and reference counting for items on stack, but this is worth doing generally, and introducing a per-input hashing limit equal to a small multiple of the witness size (or retaining the opcount limit).\n\n> On Sep 30, 2017, at 6:13 PM, Luke Dashjr via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> I've put together a first draft for what I hope to be a good next step for \n> Segwit and Bitcoin scripting:\n>    https://github.com/luke-jr/bips/blob/witnessv1/bip-witnessv1.mediawiki\n> \n> This introduces 5 key changes:\n> \n> 1. Minor versions for witnesses, inside the witness itself. Essentially the \n> witness [major] version 1 simply indicates the witness commitment is SHA256d, \n> and nothing more.\n> \n> The remaining two are witness version 1.0 (major 1, minor 0):\n> \n> 2. As previously discussed, undefined opcodes immediately cause the script to \n> exit with success, making future opcode softforks a lot more flexible.\n> \n> 3. If the final stack element is not exactly true or false, it is interpreted \n> as a tail-call Script and executed. (Credit to Mark Friedenbach)\n> \n> 4. A new shorter fixed-length signature format, eliminating the need to guess \n> the signature size in advance. All signatures are 65 bytes, unless a condition \n> script is included (see #5).\n> \n> 5. The ability for signatures to commit to additional conditions, expressed in \n> the form of a serialized Script in the signature itself. This would be useful \n> in combination with OP_CHECKBLOCKATHEIGHT (BIP 115), hopefully ending the \n> whole replay protection argument by introducing it early to Bitcoin before any \n> further splits.\n> \n> This last part is a big ugly right now: the signature must commit to the \n> script interpreter flags and internal \"sigversion\", which basically serve the \n> same purpose. The reason for this, is that otherwise someone could move the \n> signature to a different context in an attempt to exploit differences in the \n> various Script interpretation modes. I don't consider the BIP deployable \n> without this getting resolved, but I'm not sure what the best approach would \n> be. Maybe it should be replaced with a witness [major] version and witness \n> stack?\n> \n> There is also draft code implementing [the consensus side of] this:\n>    https://github.com/bitcoin/bitcoin/compare/master...luke-jr:witnessv1\n> \n> Thoughts? Anything I've overlooked / left missing that would be \n> uncontroversial and desirable? (Is any of this unexpectedly controversial for \n> some reason?)\n> \n> Luke\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Johnson Lau",
                "date": "2017-10-01T21:32:56",
                "message_text_only": "So there are 3 proposals with similar goal but different designs. I try to summarise some questions below:\n\n1. How do we allow further upgrade within v1 witness? Here are some options:\na. Minor version in witness. (Johnson / Luke) I prefer this way, but we may end up with many minor versions.\nb. OP_RETURNTRUE (Luke). I proposed this in an earlier version of BIP114 but now I think it doesn\u2019t interact well with signature aggregation, and I worry that it would have some other unexpected effects.\nc. Generalised NOP method: user has to provide the returned value, so even VERIFY-type code could do anything\n\n2. Do we want to allow signature-time commitment of extra scripts?\nI think all proposals allow this, just with different way\na. Tail-call semantics with CHECKSIGFROMSTACK (Mark). I think this is too rigid as it works only with specially designed scriptPubKey\nb. scriptWitCode: extra scripts are put in some fixed location in witness (Johnson). This makes sure static analysability.\nc. Extra-data as script in OP_CHECKSIG (Luke)\n\n3. Do we want to allow static analysis of sigop?\nBIP114 and the related proposals are specifically designed to allow static analysis of sigop. I think this was one of the main reason of OP_EVAL not being accepted. This was also the main reason of Ethereum failing to do a DAO hacker softfork, leading to the ETH/ETC split. I\u2019m not sure if we really want to give up this property. Once we do it, we have to support it forever.\n\n\u2014\u2014\nJohnson"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-10-02T00:35:38",
                "message_text_only": "> On Oct 1, 2017, at 2:32 PM, Johnson Lau <jl2012 at xbt.hk> wrote:\n> \n> So there are 3 proposals with similar goal but different designs. I try to summarise some questions below:\n> \n> 1. How do we allow further upgrade within v1 witness? Here are some options:\n> a. Minor version in witness. (Johnson / Luke) I prefer this way, but we may end up with many minor versions.\n\nI'm not sure I agree with the \"minor version\" nomenclature, or that we would necessarily end up with any consensus-visible fields beyond 2.  There are two separate soft-fork version fields that were, I think it is fair to say now, inappropriately merged in the \"script version\u201d feature of segregated witness as described in BIP141.\n\nFirst there is the witness type, which combined with the length of the commitment that follows specifies how data from the witness stack is used to calculate/verify the witness commitment in the scriptPubKey of the output being spent.  For v0 with a 20-byte hash, it says that those 20 bytes are the HASH160 of the top element of the stack.  For v0 with a 32-byte hash, it says that those 32 bytes are the HASH256 of the top element of the stack.\n\nSecond there is the script version, which is not present as a separate field for witness type v0.  Implicitly though, the script version for v0,20-byte is that the witness consists of two elements, and these are interpreted as a pubkey and a signature.  For v0,32-byte the script version is that the witness consists of 1 or more elements; with max 520 byte size constraints for all but the top element, which has a higher limit of 10,000 bytes; and the top-most element is interpreted as a script and executed with the modified CHECKSIG behavior defined by BIP141 and the CLEANSTACK rule enforced.\n\nThese are separate roles, one not being derivative of the other.  In an ideal world the witness type (of which there are only 16 remaining without obsoleting BIP141) is used only to specify a new function for transforming the witness stack into a commitment for verification purposes.  Merklized script would be one example: v2,32-byte could be defined to require a witness stack of at least two elements, the top most of which is a Merkle inclusion proof of the second item in a tree whose root is given in the 32-byte payload of the output.  Maybe v3 would prove inclusion by means of some sort of RSA accumulator or something.\n\nSuch a specification says nothing about the features of the subscript drawn from the Merkle tree, or even whether it is bitcoin script at all vs something else (Simplicity, DEX, RISC-V, Joy, whatever).  All that is necessary is that a convention be adopted about where to find the script version from whatever data is left on the stack after doing the witness type check (hashing the script, calculating a Merkle root, checking inclusion in an RSA accumulator, whatever).  A simple rule is that it is serialized and prefixed to the beginning of the string that was checked against the commitment in the output.\n\nSo v0,32-byte says that the top item is hashed and that hash must match the 32-byte value in the output.  This new v1,32-byte witness type being talked about in this thread would have exactly the same hashing rules, but will execute the resulting string based on its prefix, the script version, which is first removed before execution.\n\nSure first script version used could be a cleaned up script with a bunch of the weirdness removed (CHECKMULTISIG, I'm looking at you!); CLTV, CSV, and MBV drop arguments; disabled opcodes and unassigned NOPs become \"return true\"; etc.  Maybe v2 adds new opcodes.  But we can imagine script version that do something totally different, like introduce a new script based on a strongly-typed Merklized lambda calculus, or a RISC-V executable format, or whatever.\n\nThis has pragmatic implications with the separation of witness type and script version: we could then define a \"MAST\" output that proves the script used is drawn from a set represented by the Merkle tree.  However different scripts in that tree can use different versions.  It would be useful if the most common script is the key aggregated everyone-signs outcome, which looks like a regular bitcoin payment, and then contingency cases can be handled by means of a complicated script written in some newly added general computation language or a whole emulated RISC-V virtual machine.\n\n> b. OP_RETURNTRUE (Luke). I proposed this in an earlier version of BIP114 but now I think it doesn\u2019t interact well with signature aggregation, and I worry that it would have some other unexpected effects.\n> c. Generalised NOP method: user has to provide the returned value, so even VERIFY-type code could do anything\n\nI see no reason to do either. Gate new behavior based on script execution flags, which are set based on the script version.  Script versions not understood are treated as \"return true\" to begin with.  The interpreter isn't even going to try to decode the script according to the old rules, let alone try to execute it, so there's no reason for the old soft-fork compatability tricks.\n\nThe new soft-fork trick is that you increment the script version number.  That is all.\n\n> 2. Do we want to allow signature-time commitment of extra scripts?\n> I think all proposals allow this, just with different way\n> a. Tail-call semantics with CHECKSIGFROMSTACK (Mark). I think this is too rigid as it works only with specially designed scriptPubKey\n\nThis is not signature-time commitment of extra script. Not without CHECKSIGFROMSTACK or something like it.\n\n> b. scriptWitCode: extra scripts are put in some fixed location in witness (Johnson). This makes sure static analysability.\n> c. Extra-data as script in OP_CHECKSIG (Luke)\n\nPropose these as their own script updates.  Script versioning makes such new features cheap.  There's no reason to create some sort of complex omnibus overhaul that does everything.\n\n> 3. Do we want to allow static analysis of sigop?\n> BIP114 and the related proposals are specifically designed to allow static analysis of sigop. I think this was one of the main reason of OP_EVAL not being accepted. This was also the main reason of Ethereum failing to do a DAO hacker softfork, leading to the ETH/ETC split. I\u2019m not sure if we really want to give up this property. Once we do it, we have to support it forever.\n\nAgain, this is off-topic for this thread.  I don't think a v1 witness type upgrade should do any of these things.  The v1 witness type should add a proper script version in the witness, and remove or simplify limits or unnecessary verification rules that are no longer necessary and/or hindering progress.  That\u2019s it.\n\nFor example, I don't think a v1 witness version should be coupled with my tail-call semantics or the introduction of MERKLEBRANCHVERIFY (but if MBV was released already we could have it drop its arguments, which would be nice).  However it should drop the CLEANSTACK rule in favor of something else (like signatures committing to the witness depth and/or weight) since the tail-call BIP demonstrates it to be an impediment to extensibility and alternatives are not.  And it should drop the 520 byte push limitation, as the MBV BIP demonstrates use cases that have serialized proofs larger than that, like a k-of-N threshold with N=16."
            },
            {
                "author": "Luke Dashjr",
                "date": "2017-10-02T02:56:27",
                "message_text_only": "On Monday 02 October 2017 12:35:38 AM Mark Friedenbach wrote:\n> > b. OP_RETURNTRUE (Luke). I proposed this in an earlier version of BIP114\n> > but now I think it doesn\u2019t interact well with signature aggregation, and\n> > I worry that it would have some other unexpected effects. c. Generalised\n> > NOP method: user has to provide the returned value, so even VERIFY-type\n> > code could do anything\n> \n> I see no reason to do either. Gate new behavior based on script execution\n> flags, which are set based on the script version.  Script versions not\n> understood are treated as \"return true\" to begin with.  The interpreter\n> isn't even going to try to decode the script according to the old rules,\n> let alone try to execute it, so there's no reason for the old soft-fork\n> compatability tricks.\n> \n> The new soft-fork trick is that you increment the script version number. \n> That is all.\n\nThis breaks parallel softfork deployments.\n\n> > b. scriptWitCode: extra scripts are put in some fixed location in witness\n> > (Johnson). This makes sure static analysability. c. Extra-data as script\n> > in OP_CHECKSIG (Luke)\n> \n> Propose these as their own script updates.  Script versioning makes such\n> new features cheap.  There's no reason to create some sort of complex\n> omnibus overhaul that does everything.\n\nOnly if there's common code to implement both versions, which doesn't work if \nthe changes from A to B to C are drastic. To avoid such drastic changes, the \noverall design/layout needs to at least be planned to cover the desired use \ncases in advance.\n\nLuke"
            },
            {
                "author": "Sjors Provoost",
                "date": "2017-10-02T09:09:00",
                "message_text_only": "Op 2 okt. 2017, om 03:56 heeft Luke Dashjr via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:\n> \n> On Monday 02 October 2017 12:35:38 AM Mark Friedenbach wrote:\n>>> b. OP_RETURNTRUE (Luke). I proposed this in an earlier version of BIP114\n>>> but now I think it doesn\u2019t interact well with signature aggregation, and\n>>> I worry that it would have some other unexpected effects. c. Generalised\n>>> NOP method: user has to provide the returned value, so even VERIFY-type\n>>> code could do anything\n>> \n>> I see no reason to do either. Gate new behavior based on script execution\n>> flags, which are set based on the script version.  Script versions not\n>> understood are treated as \"return true\" to begin with.  The interpreter\n>> isn't even going to try to decode the script according to the old rules,\n>> let alone try to execute it, so there's no reason for the old soft-fork\n>> compatability tricks.\n>> \n>> The new soft-fork trick is that you increment the script version number.\n>> That is all.\n> \n> This breaks parallel softfork deployments.\n\nIf unknown script versions are treated as \"return true\", there's no need for versions to be deployed in sequence, right? Maybe they should be called numbered script types, rather than script versions.\n\nSjors\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171002/99d0f6a0/attachment.sig>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2017-10-02T00:45:22",
                "message_text_only": "On Sunday 01 October 2017 9:32:56 PM Johnson Lau wrote:\n> 1. How do we allow further upgrade within v1 witness? Here are some\n> options: a. Minor version in witness. (Johnson / Luke) I prefer this way,\n> but we may end up with many minor versions. b. OP_RETURNTRUE (Luke). I\n> proposed this in an earlier version of BIP114 but now I think it doesn\u2019t\n> interact well with signature aggregation, and I worry that it would have\n> some other unexpected effects. c. Generalised NOP method: user has to\n> provide the returned value, so even VERIFY-type code could do anything\n\nI like (A) and (B). Use B when practical, and (A) when more fundamental \nchanges are needed. SigAgg is a concern, but there are ways to adapt it.\n\n(C) is harmless, but I think unnecessary with (A) and/or (B).\n\n> 2. Do we want to allow signature-time commitment of extra scripts?\n> I think all proposals allow this, just with different way\n> a. Tail-call semantics with CHECKSIGFROMSTACK (Mark). I think this is too\n> rigid as it works only with specially designed scriptPubKey b.\n> scriptWitCode: extra scripts are put in some fixed location in witness\n> (Johnson). This makes sure static analysability. c. Extra-data as script\n> in OP_CHECKSIG (Luke)\n\nNote that my BIP draft supports both (A) and (C).\n\n> 3. Do we want to allow static analysis of sigop?\n> BIP114 and the related proposals are specifically designed to allow static\n> analysis of sigop. I think this was one of the main reason of OP_EVAL not\n> being accepted. This was also the main reason of Ethereum failing to do a\n> DAO hacker softfork, leading to the ETH/ETC split. I\u2019m not sure if we\n> really want to give up this property. Once we do it, we have to support it\n> forever.\n\nIt seems inevitable at this point. Maybe we could add a separate \"executable-\nwitness\" array (in the same manner as the current witness was softforked in), \nand require tail-call and condition scripts to merely reference these by hash, \nbut I'm not sure it's worth the effort?\n\nThinking further, we could avoid adding a separate executable-witness \ncommitment by either:\nA) Define that all the witness elements in v1 are type-tagged (put the minor\n   witness version on them all, and redefine minor 0 as a stack item?); or\nB) Use an empty element as a delimiter between stack and executable items.\n\nTo avoid witness malleability, the executable items can be required to be \nsorted in some manner.\n\nThe downside of these approaches is that we now need an addition 20 or 32 \nbytes per script reference... which IMO may possibly be worse than losing \nstatic analysis. I wonder if there's a way to avoid that overhead?\n\nLuke"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-10-05T20:33:56",
                "message_text_only": "Here\u2019s an additional (uncontroversial?) idea due to Russell O\u2019Connor:\n\nInstead of requiring that the last item popped off the stack in a CHECKMULTISIG be zero, have it instead be required that it is a bitfield specifying which pubkeys are used, or more likely the complement thereof. This allows signatures to be matched to pubkeys in the order given, and batch validated, with no risk of 3rd party malleability.\n\nMark\n\n> On Sep 30, 2017, at 6:13 PM, Luke Dashjr via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> I've put together a first draft for what I hope to be a good next step for \n> Segwit and Bitcoin scripting:\n>    https://github.com/luke-jr/bips/blob/witnessv1/bip-witnessv1.mediawiki\n> \n> This introduces 5 key changes:\n> \n> 1. Minor versions for witnesses, inside the witness itself. Essentially the \n> witness [major] version 1 simply indicates the witness commitment is SHA256d, \n> and nothing more.\n> \n> The remaining two are witness version 1.0 (major 1, minor 0):\n> \n> 2. As previously discussed, undefined opcodes immediately cause the script to \n> exit with success, making future opcode softforks a lot more flexible.\n> \n> 3. If the final stack element is not exactly true or false, it is interpreted \n> as a tail-call Script and executed. (Credit to Mark Friedenbach)\n> \n> 4. A new shorter fixed-length signature format, eliminating the need to guess \n> the signature size in advance. All signatures are 65 bytes, unless a condition \n> script is included (see #5).\n> \n> 5. The ability for signatures to commit to additional conditions, expressed in \n> the form of a serialized Script in the signature itself. This would be useful \n> in combination with OP_CHECKBLOCKATHEIGHT (BIP 115), hopefully ending the \n> whole replay protection argument by introducing it early to Bitcoin before any \n> further splits.\n> \n> This last part is a big ugly right now: the signature must commit to the \n> script interpreter flags and internal \"sigversion\", which basically serve the \n> same purpose. The reason for this, is that otherwise someone could move the \n> signature to a different context in an attempt to exploit differences in the \n> various Script interpretation modes. I don't consider the BIP deployable \n> without this getting resolved, but I'm not sure what the best approach would \n> be. Maybe it should be replaced with a witness [major] version and witness \n> stack?\n> \n> There is also draft code implementing [the consensus side of] this:\n>    https://github.com/bitcoin/bitcoin/compare/master...luke-jr:witnessv1\n> \n> Thoughts? Anything I've overlooked / left missing that would be \n> uncontroversial and desirable? (Is any of this unexpectedly controversial for \n> some reason?)\n> \n> Luke\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Russell O'Connor",
                "date": "2017-10-05T21:28:48",
                "message_text_only": "On Thu, Oct 5, 2017 at 4:33 PM, Mark Friedenbach via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Here\u2019s an additional (uncontroversial?) idea due to Russell O\u2019Connor:\n>\n\nFor the record, it's Johnson Lau's proposal where I read this idea.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171005/3dc6a749/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Version 1 witness programs (first draft)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Felix Weis",
                "Johnson Lau",
                "Russell O'Connor",
                "Luke Dashjr",
                "Sjors Provoost",
                "Mark Friedenbach"
            ],
            "messages_count": 20,
            "total_messages_chars_count": 52660
        }
    },
    {
        "title": "[bitcoin-dev] Merkle branch verification & tail-call semantics for generalized MAST",
        "thread_messages": [
            {
                "author": "Russell O'Connor",
                "date": "2017-10-02T17:15:38",
                "message_text_only": "(Subject was: [bitcoin-dev] Version 1 witness programs (first draft)), but\nI'm moving part of that conversation to this thread.\n\nOn Sun, Oct 1, 2017 at 5:32 PM, Johnson Lau <jl2012 at xbt.hk> wrote:\n\n> 3. Do we want to allow static analysis of sigop?\n> BIP114 and the related proposals are specifically designed to allow static\n> analysis of sigop. I think this was one of the main reason of OP_EVAL not\n> being accepted. This was also the main reason of Ethereum failing to do a\n> DAO hacker softfork, leading to the ETH/ETC split. I\u2019m not sure if we\n> really want to give up this property. Once we do it, we have to support it\n> forever.\n\n\nI would very much like to retain the ability to do static analysis.  More\ngenerally, the idea of interpreting arbitrary data as code, as done in\nOP_EVAL and in TAILCALL, makes me quite anxious.  This at the root of many\nsecurity problems throughout the software industry, and I don't relish\ngiving more fuel to the underhanded Bitcoin Script contestants.\n\nOn Sun, Oct 1, 2017 at 8:45 PM, Luke Dashjr <luke at dashjr.org> wrote:\n\n> > 3. Do we want to allow static analysis of sigop?\n> > BIP114 and the related proposals are specifically designed to allow\n> static\n> > analysis of sigop. I think this was one of the main reason of OP_EVAL not\n> > being accepted. This was also the main reason of Ethereum failing to do a\n> > DAO hacker softfork, leading to the ETH/ETC split. I\u2019m not sure if we\n> > really want to give up this property. Once we do it, we have to support\n> it\n> > forever.\n>\n> It seems inevitable at this point. Maybe we could add a separate\n> \"executable-\n> witness\" array (in the same manner as the current witness was softforked\n> in),\n> and require tail-call and condition scripts to merely reference these by\n> hash,\n> but I'm not sure it's worth the effort?\n>\n> Thinking further, we could avoid adding a separate executable-witness\n> commitment by either:\n> A) Define that all the witness elements in v1 are type-tagged (put the\n> minor\n>    witness version on them all, and redefine minor 0 as a stack item?); or\n> B) Use an empty element as a delimiter between stack and executable items.\n>\n> To avoid witness malleability, the executable items can be required to be\n> sorted in some manner.\n>\n> The downside of these approaches is that we now need an addition 20 or 32\n> bytes per script reference... which IMO may possibly be worse than losing\n> static analysis. I wonder if there's a way to avoid that overhead?\n>\n\nActually, I have a half-baked idea I've been thinking about along these\nlines.\n\nThe idea is to add a flag to each stack item in the Script interpreter to\nmark whether the item in the stack is \"executable\" or \"non-executable\", not\nso different from how computers mark pages to implement executable space\nprotection.  By default, all stack items are marked \"non-executable\".  We\nthen redefine OP_PUSHDATA4 as OP_PUSHCODE within ScriptSigs.  The\noperational semantics of OP_PUSHCODE would remain the same as OP_PUSHDATA4\nexcept it would set the pushed item's associated flag to \"executable\".  All\ndata pushed by OP_PUSHCODE would be subject to the sigops limits and any\nother similar static analysis limits.\n\nSegwit v0 doesn't use OP_PUSHDATA codes to create the input stack, so we\nwould have to mark executable input stack items using a new witness v1\nformat. But, IIUC, TAILCALL isn't going to be compatible with Segwit v0\nanyway.\n\nDuring a TAILCALL, it is required that the top item on the stack have the\n\"executable\" flag, otherwise TAILCALL is not used (and the script succeeds\nor fails based on the top item's data value as usual).\n\nAll other operations can treat \"executable\" items as data, including the\nmerkle branch verification.  None of the Script operations can create\n\"executable\" items; in particular, OP_PUSHDATA4 within the ScriptPubKey\nalso would not create \"executable\" items.  (We can talk about the behaviour\nof OP_CAT when that time comes).\n\nOne last trick is that when \"executable\" values are duplicated, by OP_DUP,\nOP_IFDUP, OP_PICK. then the newly created copy of the value on top of the\nstack is marked \"non-executable\".\n\nBecause we make the \"executable\" flag non-copyable, we are now free to\nallow unbounded uses of TAILCALL (i.e. TAILCALL can be used multiplie times\nin a single input).  Why is this safe?  Because the number of \"executable\"\nitems decreases by at least one every time TAILCALL is invoked. the number\nof OP_PUSHCODE occurrences in the witness puts an upper bound on the number\nof invocations of TAILCALL allowed.  Using static analysis of the script\npubkey and the data within the OP_PUSHCODE data, we compute an upper bound\non the number of operations (of any type) that can occur during execution.\n\nUnbounded TAILCALL should let us (in the presence of OP_CHECKSIGFROMSTACK)\nhave unbounded delegation.\n\nOverall, I believe that OP_PUSHCODE\n\n1. is fully backwards compatible.\n2. maintains our ability to perform static analysis with TAILCALL.\n3. never lets us interpret computed values as executable code.\n4. extends TAILCALL to safely allow multiple TAILCALLs per script.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171002/794f9cab/attachment-0001.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-10-28T04:40:01",
                "message_text_only": "I have completed updating the three BIPs with all the feedback that I have received so far. In short summary, here is an incomplete list of the changes that were made:\n\n* Modified the hashing function fast-SHA256 so that an internal node cannot be interpreted simultaneously as a leaf.\n* Changed MERKLEBRANCHVERIFY to verify a configurable number of elements from the tree, instead of just one.\n* Changed MERKLEBRANCHVERIFY to have two modes: one where the inputs are assumed to be hashes, and one where they are run through double-SHA256 first.\n* Made tail-call eval compatible with BIP141\u2019s CLEANSTACK consensus rule by allowing parameters to be passed on the alt-stack.\n* Restricted tail-call eval to segwit scripts only, so that checking sigop and opcode limits of the policy script would not be necessary.\n\nThere were a bunch of other small modifications, typo fixes, and optimizations that were made as well.\n\nI am now ready to submit these BIPs as a PR against the bitcoin/bips repo, and I request that the BIP editor assign numbers.\n\nThank you,\nMark Friedenbach\n\n> On Sep 6, 2017, at 5:38 PM, Mark Friedenbach <mark at friedenbach.org> wrote:\n> \n> I would like to propose two new script features to be added to the\n> bitcoin protocol by means of soft-fork activation. These features are\n> a new opcode, MERKLE-BRANCH-VERIFY (MBV) and tail-call execution\n> semantics.\n> \n> In brief summary, MERKLE-BRANCH-VERIFY allows script authors to force\n> redemption to use values selected from a pre-determined set committed\n> to in the scriptPubKey, but without requiring revelation of unused\n> elements in the set for both enhanced privacy and smaller script\n> sizes. Tail-call execution semantics allows a single level of\n> recursion into a subscript, providing properties similar to P2SH while\n> at the same time more flexible.\n> \n> These two features together are enough to enable a range of\n> applications such as tree signatures (minus Schnorr aggregation) as\n> described by Pieter Wuille [1], and a generalized MAST useful for\n> constructing private smart contracts. It also brings privacy and\n> fungibility improvements to users of counter-signing wallet/vault\n> services as unique redemption policies need only be revealed if/when\n> exceptional circumstances demand it, leaving most transactions looking\n> the same as any other MAST-enabled multi-sig script.\n> \n> I believe that the implementation of these features is simple enough,\n> and the use cases compelling enough that we could BIP 8/9 rollout of\n> these features in relatively short order, perhaps before the end of\n> the year.\n> \n> I have written three BIPs to describe these features, and their\n> associated implementation, for which I now invite public review and\n> discussion:\n> \n> Fast Merkle Trees\n> BIP: https://gist.github.com/maaku/41b0054de0731321d23e9da90ba4ee0a\n> Code: https://github.com/maaku/bitcoin/tree/fast-merkle-tree\n> \n> MERKLEBRANCHVERIFY\n> BIP: https://gist.github.com/maaku/bcf63a208880bbf8135e453994c0e431\n> Code: https://github.com/maaku/bitcoin/tree/merkle-branch-verify\n> \n> Tail-call execution semantics\n> BIP: https://gist.github.com/maaku/f7b2e710c53f601279549aa74eeb5368\n> Code: https://github.com/maaku/bitcoin/tree/tail-call-semantics\n> \n> Note: I have circulated this idea privately among a few people, and I\n> will note that there is one piece of feedback which I agree with but\n> is not incorporated yet: there should be a multi-element MBV opcode\n> that allows verifying multiple items are extracted from a single\n> tree. It is not obvious how MBV could be modified to support this\n> without sacrificing important properties, or whether should be a\n> separate multi-MBV opcode instead.\n> \n> Kind regards,\n> Mark Friedenbach"
            }
        ],
        "thread_summary": {
            "title": "Merkle branch verification & tail-call semantics for generalized MAST",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Russell O'Connor",
                "Mark Friedenbach"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 9009
        }
    },
    {
        "title": "[bitcoin-dev] A solution may solve Block Withholding Attack",
        "thread_messages": [
            {
                "author": "\u6f58\u5fd7\u5f6a",
                "date": "2017-10-03T15:52:16",
                "message_text_only": "Here is a solution may solve Block Withholding Attack. The general idea is\ncame from Aviv Zohar(avivz at cs.huji.ac.il), I made it work for Bitcoin.\nAnyway, thanks Aviv.\n\n=====================\n\nDIFF_1 = 0x00000000FFFF0000000000000000000000000000000000000000000000000000;\n\nDiff = DIFF_1 / target\n\nthis is equal to\n\nDiff = DIFF_1 / (target - 0) or Diff = DIFF_1 / abs(target - 0)\n\nnow, we change diff algo to below:\n\nNew_Diff = DIFF_1 / abs(target - offset)\n\nOffset is 32 bytes, like uint256 in Bitcoin, range is [0, 2^256),\ndefine: offset_hash = DSHA256(offset).\n\nwe need to do a little change to the merkle root hash algo, put the\noffset_hash as a tx hash in the front of tx hashes.\n\n[offset_hash, coinbase_tx_hash, tx01_hash, tx02_hash, \u2026 , tx_n_hash]\n\nActually could put offset_hash in any place in the array of hashes.\n\nnetwork_hash_range = network_hash_end - network_hash_begin\n\nminer_hash_range = miner_hash_end - miner_hash_begin\n\nThe offset value MUST between network_hash_begin/end or\nminer_hash_begin/end.\n\nhttps://user-images.githubusercontent.com/514951/31133378-e00d9ca2-a891-11e7-8c61-73325f59f6ed.JPG\n\nWhen mining pool send a job to miners, put the PoW hash range\n(miner_hash_begin/end) in the job. So if the miners find a hash which value\nis between [miner_hash_begin, miner_hash_end], means it's SHOULD be a\nvalid share, could submit the share to the pool. If the hash value is\nbetween [network_hash_begin, network_hash_end] means find a valid block.\n\nThe network_diff is much much high than the miner's diff, means the\nnetwork_hash_range is much much smaller than miner_hash_range. By now,\na typical miner's pool diff is around 16K, network diff is 1123863285132,\nso miner_hash_range is at least million times bigger than\nnetwork_hash_range.\nThe miners only know miner_hash_range, it's impossible for cheat miners\nto find out which share could make a valid block or not.\n\nProblems:\n1. it's a hard fork.\n2. will make existed asic dsha256 chips useless, but I think it's only a\nsmall change to make new asic chips based on existed tech.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171003/00d1a45c/attachment-0001.html>"
            },
            {
                "author": "James Hilliard",
                "date": "2017-10-06T14:36:15",
                "message_text_only": "There have been some other proposals to deal with this such as\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2012-June/001506.html\nthat may be possible to implement in existing miners.\n\nOn Tue, Oct 3, 2017 at 9:52 AM, \u6f58\u5fd7\u5f6a via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Here is a solution may solve Block Withholding Attack. The general idea is\n> came from Aviv Zohar(avivz at cs.huji.ac.il), I made it work for Bitcoin.\n> Anyway, thanks Aviv.\n>\n> =====================\n>\n> DIFF_1 = 0x00000000FFFF0000000000000000000000000000000000000000000000000000;\n>\n> Diff = DIFF_1 / target\n>\n> this is equal to\n>\n> Diff = DIFF_1 / (target - 0) or Diff = DIFF_1 / abs(target - 0)\n>\n> now, we change diff algo to below:\n>\n> New_Diff = DIFF_1 / abs(target - offset)\n>\n> Offset is 32 bytes, like uint256 in Bitcoin, range is [0, 2^256),\n> define: offset_hash = DSHA256(offset).\n>\n> we need to do a little change to the merkle root hash algo, put the\n> offset_hash as a tx hash in the front of tx hashes.\n>\n> [offset_hash, coinbase_tx_hash, tx01_hash, tx02_hash, \u2026 , tx_n_hash]\n>\n> Actually could put offset_hash in any place in the array of hashes.\n>\n> network_hash_range = network_hash_end - network_hash_begin\n>\n> miner_hash_range = miner_hash_end - miner_hash_begin\n>\n> The offset value MUST between network_hash_begin/end or\n> miner_hash_begin/end.\n>\n> https://user-images.githubusercontent.com/514951/31133378-e00d9ca2-a891-11e7-8c61-73325f59f6ed.JPG\n>\n> When mining pool send a job to miners, put the PoW hash range\n> (miner_hash_begin/end) in the job. So if the miners find a hash which value\n> is between [miner_hash_begin, miner_hash_end], means it's SHOULD be a\n> valid share, could submit the share to the pool. If the hash value is\n> between [network_hash_begin, network_hash_end] means find a valid block.\n>\n> The network_diff is much much high than the miner's diff, means the\n> network_hash_range is much much smaller than miner_hash_range. By now,\n> a typical miner's pool diff is around 16K, network diff is 1123863285132,\n> so miner_hash_range is at least million times bigger than\n> network_hash_range.\n> The miners only know miner_hash_range, it's impossible for cheat miners\n> to find out which share could make a valid block or not.\n>\n> Problems:\n> 1. it's a hard fork.\n> 2. will make existed asic dsha256 chips useless, but I think it's only a\n> small change to make new asic chips based on existed tech.\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Kevin Pan",
                "date": "2017-10-08T09:28:32",
                "message_text_only": "But I think this one is simpler and better than Luke's.\n\nAnd now is different like 2012, pools need be more independ today. Pools\nwant\nto express their opinion or standpoint. Some of can't do that like remove\nthe\nNYA tag and one the reason is the Block Withholding Attack.\n\nKevin Pan\n\nOn Fri, Oct 6, 2017 at 10:36 PM, James Hilliard <james.hilliard1 at gmail.com>\nwrote:\n\n> There have been some other proposals to deal with this such as\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/\n> 2012-June/001506.html\n> that may be possible to implement in existing miners.\n>\n> On Tue, Oct 3, 2017 at 9:52 AM, \u6f58\u5fd7\u5f6a via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > Here is a solution may solve Block Withholding Attack. The general idea\n> is\n> > came from Aviv Zohar(avivz at cs.huji.ac.il), I made it work for Bitcoin.\n> > Anyway, thanks Aviv.\n> >\n> > =====================\n> >\n> > DIFF_1 = 0x00000000FFFF0000000000000000000000000000000000000000000000\n> 000000;\n> >\n> > Diff = DIFF_1 / target\n> >\n> > this is equal to\n> >\n> > Diff = DIFF_1 / (target - 0) or Diff = DIFF_1 / abs(target - 0)\n> >\n> > now, we change diff algo to below:\n> >\n> > New_Diff = DIFF_1 / abs(target - offset)\n> >\n> > Offset is 32 bytes, like uint256 in Bitcoin, range is [0, 2^256),\n> > define: offset_hash = DSHA256(offset).\n> >\n> > we need to do a little change to the merkle root hash algo, put the\n> > offset_hash as a tx hash in the front of tx hashes.\n> >\n> > [offset_hash, coinbase_tx_hash, tx01_hash, tx02_hash, \u2026 , tx_n_hash]\n> >\n> > Actually could put offset_hash in any place in the array of hashes.\n> >\n> > network_hash_range = network_hash_end - network_hash_begin\n> >\n> > miner_hash_range = miner_hash_end - miner_hash_begin\n> >\n> > The offset value MUST between network_hash_begin/end or\n> > miner_hash_begin/end.\n> >\n> > https://user-images.githubusercontent.com/514951/\n> 31133378-e00d9ca2-a891-11e7-8c61-73325f59f6ed.JPG\n> >\n> > When mining pool send a job to miners, put the PoW hash range\n> > (miner_hash_begin/end) in the job. So if the miners find a hash which\n> value\n> > is between [miner_hash_begin, miner_hash_end], means it's SHOULD be a\n> > valid share, could submit the share to the pool. If the hash value is\n> > between [network_hash_begin, network_hash_end] means find a valid block.\n> >\n> > The network_diff is much much high than the miner's diff, means the\n> > network_hash_range is much much smaller than miner_hash_range. By now,\n> > a typical miner's pool diff is around 16K, network diff is 1123863285132,\n> > so miner_hash_range is at least million times bigger than\n> > network_hash_range.\n> > The miners only know miner_hash_range, it's impossible for cheat miners\n> > to find out which share could make a valid block or not.\n> >\n> > Problems:\n> > 1. it's a hard fork.\n> > 2. will make existed asic dsha256 chips useless, but I think it's only a\n> > small change to make new asic chips based on existed tech.\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171008/c60a6a4d/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "A solution may solve Block Withholding Attack",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "\u6f58\u5fd7\u5f6a",
                "Kevin Pan",
                "James Hilliard"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 8202
        }
    },
    {
        "title": "[bitcoin-dev] New difficulty algorithm needed for SegWit2x fork?",
        "thread_messages": [
            {
                "author": "Scott Roberts",
                "date": "2017-10-09T21:26:50",
                "message_text_only": "Background:\nThe bitcoin difficulty algorithm does not seem to be a good one.\u00a0 If there is a fork due to miners seeking maximum profit without due regard to security, users, and nodes, the \"better\" coin could end up being the minority chain. If 90% of hashrate is really going to at least initially go towards using SegWit2x, BTC would face 10x delays in confirmations until the next difficulty adjustment, negatively affecting its price relative to BTC1, causing further delays from even more miner abandonment (until the next adjustment). The 10% miners remaining on BTC do not inevitably lose by staying to endure 10x delays because they have 10x less competition, and the same situation applies to BTC1 miners. If the prices are the same and stable, all seems well for everyone, other things aside.\u00a0 But if the BTC price does not fall to reflect the decreased hashrate, the situation seems to be a big problem for both coins: BTC1 miners will jump back to BTC when the difficulty adjustment occurs, initiating a potentially never-ending oscillation between the two coins, potentially worse than what BCH is experiencing.\u00a0 They will not issue coins too fast like BCH because that is a side effect of the asymmetry in BCH's rise and fall algorithm.\nSolution:\nHard fork to implement a new difficulty algorithm that uses a simple rolling average with a much smaller window.\u00a0 Many small coins have done this as a way to stop big miners from coming on and then suddenly leaving, leaving constant miners stuck with a high difficulty for the rest of a (long) averaging window.\u00a0 Even better, adjust the reward based on recent solvetimes to motivate more mining (or less) if the solvetimes are too slow (or too fast).\u00a0 This will keep keep the coin issuance rate perfectly on schedule with real time.\u00a0\nI recommend the following for Bitcoin, as fast, simple, and better than any other difficulty algorithm I'm aware of.\u00a0 This is the result of a lot of work the past year.\n=== Begin difficulty algorithm ===# Zawy v6 difficulty algorithm (modified for bitcoin)# Unmodified Zawy v6 for alt coins:\u00a0# http://zawy1.blogspot.com/2017/07/best-difficulty-algorithm-zawy-v1b.html# My failed attempts at something better:# https://github.com/seredat/karbowanec/commit/231db5270acb2e673a641a1800be910ce345668a## Keep negative solvetimes to correct bad timestamps.# Do not be tempted to use:# next_D = sum(last N Ds) * T / [max(last N TSs) - min(last N TSs];# D=difficulty, ST= Solvetime, TS = timestamp, T=TargetSolveTime\n# set constants until next hard fork:\nT=600;\u00a0N=30; # Averaging window. Smoother than N=15, faster response than N=60.X=5; # size of sudden hashrate changes expected as multiple of base hashrate.limit = X^(2/N); # limit rise and fall to protect against timestamp errors & manipulationadjust = 1/(1+0.67/N);\u00a0 # keeps avg solvetime on track for small N.\n# begin difficulty algorithm\u00a0\navg_ST=0; # avg SolveTimeavg_D=0;for ( i=height;\u00a0 i > height-N;\u00a0 i--) {\u00a0 # go through N most recent blocks\u00a0 \u00a0avg_ST += (TS[i] - TS[i-1]) / N; # TS=timestamps\u00a0 \u00a0avg_D += D[i]/N;}avg_ST = T*limit if avg_ST > T*limit;\u00a0avg_ST = T/limit if avg_ST < T/limit;\u00a0\nnext_D = avg_D * T / avg_ST * adjust;\u00a0\n# Tim Olsen suggested changing coin reward to protect against hash attacks.# Karbowanek coin suggested something similar.# After testing many ideas, I could not find anything better than the simplest idea below.# It was a surprise that coin issuance rate came out perfect.# BaseReward = coins per block\nnext_reward = BaseReward * avg_ST / T;\n======= end algo ====\nDue to the limit and keeping negative solvetimes in a true average, timestamp errors resulting in negative solvetimes are corrected in the next block. Otherwise, one would need to do like Zcash and cause a 5-block delay in the response by resorting to the median of past 11 blocks (MTP) as the most recent timestamp, offsetting the timestamps from their corresponding difficulties by 5 blocks. (it does not cause an averaging problem, but it does cause a 5-block delay in the response.)\nSmall N windows like keep the correct median, but cause avg solvetime to be above the target. The \"adjust\" constant (empirically determined) fixes this, but it causes the median to be that same percentage too low, below the ideal Poisson median which is 0.693 of the mean. I was not able to find a fix to this that did not slow down the response to hashrate changes.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171009/c018731b/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "New difficulty algorithm needed for SegWit2x fork?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Scott Roberts"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4576
        }
    },
    {
        "title": "[bitcoin-dev] New difficulty algorithm needed for SegWit2x fork? (reformatted text)",
        "thread_messages": [
            {
                "author": "Scott Roberts",
                "date": "2017-10-09T22:57:32",
                "message_text_only": "Sorry, my previous email did not have the plain text I intended.\n\nBackground: \n\nThe bitcoin difficulty algorithm does not seem to be a good one. If there \nis a fork due to miners seeking maximum profit without due regard to \nsecurity, users, and nodes, the \"better\" coin could end up being the \nminority chain. If 90% of hashrate is really going to at least initially go \ntowards using SegWit2x, BTC would face 10x delays in confirmations \nuntil the next difficulty adjustment, negatively affecting its price relative \nto BTC1, causing further delays from even more miner abandonment \n(until the next adjustment). The 10% miners remaining on BTC do not \ninevitably lose by staying to endure 10x delays because they have 10x \nless competition, and the same situation applies to BTC1 miners. If the \nprices are the same and stable, all seems well for everyone, other things \naside. But if the BTC price does not fall to reflect the decreased hashrate, \nhe situation seems to be a big problem for both coins: BTC1 miners will \njump back to BTC when the difficulty adjustment occurs, initiating a \npotentially never-ending oscillation between the two coins, potentially \nworse than what BCH is experiencing.  They will not issue coins too fast \nlike BCH because that is a side effect of the asymmetry in BCH's rise and \nfall algorithm. \n\nSolution: \n\nHard fork to implement a new difficulty algorithm that uses a simple rolling \naverage with a much smaller window.  Many small coins have done this as \na way to stop big miners from coming on and then suddenly leaving, leaving \nconstant miners stuck with a high difficulty for the rest of a (long) averaging \nwindow.  Even better, adjust the reward based on recent solvetimes to \nmotivate more mining (or less) if the solvetimes are too slow (or too fast). \nThis will keep keep coin issuance rate perfectly on schedule with real time. \n\nI recommend the following for Bitcoin, as fast, simple, and better than any \nother difficulty algorithm I'm aware of.  This is the result of a lot of work the \npast year. \n\n=== Begin difficulty algorithm === \n# Zawy v6 difficulty algorithm (modified for bitcoin) \n# Unmodified Zawy v6 for alt coins: \n# http://zawy1.blogspot.com/2017/07/best-difficulty-algorithm-zawy-v1b.html \n# All my failed attempts at something better: \n# https://github.com/seredat/karbowanec/commit/231db5270acb2e673a641a1800be910ce345668a \n# \n# Keep negative solvetimes to correct bad timestamps. \n# Do not be tempted to use: \n# next_D = sum(last N Ds) * T / [max(last N TSs) - min(last N TSs]; \n# ST= Solvetime, TS = timestamp \n\n# set constants until next hard fork: \n\nT=600; # coin's TargetSolvetime \nN=30; # Averaging window. Smoother than N=15, faster response than N=60. \nX=5; \nlimit = X^(2/N); # limit rise and fall in case of timestamp manipulation \nadjust = 1/(1+0.67/N);  # keeps avg solvetime on track \n\n# begin difficulty algorithm \n\navg_ST=0; avg_D=0; \nfor ( i=height;  i > height-N;  i--) {  # go through N most recent blocks \navg_ST += (TS[i] - TS[i-1]) / N; \navg_D += D[i]/N; \n} \navg_ST = T*limit if avg_ST > T*limit; \navg_ST = T/limit if avg_ST < T/limit; \n\nnext_D = avg_D * T / avg_ST * adjust; \n\n# Tim Olsen suggested changing reward to protect against hash attacks. \n# Karbowanek coin suggested something similar. \n# I could not find anything better than the simplest idea below. \n# It was a great surprise that coin issuance rate came out perfect. \n# BaseReward = coins per block \n\nnext_reward = BaseReward * avg_ST / T; \n\n======= end algo ==== \n\nDue to the limit and keeping negative solvetimes in a true average, \ntimestamp errors resulting in negative solvetimes are corrected in the next \nblock. Otherwise, one would need to do like Zcash and cause a 5-block \ndelay in the response by resorting to the median of past 11 blocks (MPT) \nas the most recent timestamp, offsetting the timestamps from their \ncorresponding difficulties by 5 blocks. (it does not cause an averaging \nproblem, but it does cause a 5-block delay in the response.)"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-10-10T02:19:11",
                "message_text_only": "The problem of fast acting but non vulnerable difficulty adjustment algorithms is interesting. I would certainly like to see this space further explored, and even have some ideas myself.\n\nHowever without commenting on the technical merits of this specific proposal, I think it must be said upfront that the stated goal is not good. The largest technical concern (ignoring governance) over B2X is that it is a rushed, poorly reviewed hard fork. Hard forks should not be rushed, and they should receive more than the usual level of expert and community review.\n\nI\u2019m that light, doing an even more rushed hard fork on an even newer idea with even less review would be hypocritical at best. I would suggest reframing as a hardfork wishlist research problem for the next properly planned hard fork, if one occurs. You might also find the hardfork research group a more accommodating venue for this discussion:\n\nhttps://bitcoinhardforkresearch.github.io/\n\n> On Oct 9, 2017, at 3:57 PM, Scott Roberts via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Sorry, my previous email did not have the plain text I intended.\n> \n> Background: \n> \n> The bitcoin difficulty algorithm does not seem to be a good one. If there \n> is a fork due to miners seeking maximum profit without due regard to \n> security, users, and nodes, the \"better\" coin could end up being the \n> minority chain. If 90% of hashrate is really going to at least initially go \n> towards using SegWit2x, BTC would face 10x delays in confirmations \n> until the next difficulty adjustment, negatively affecting its price relative \n> to BTC1, causing further delays from even more miner abandonment \n> (until the next adjustment). The 10% miners remaining on BTC do not \n> inevitably lose by staying to endure 10x delays because they have 10x \n> less competition, and the same situation applies to BTC1 miners. If the \n> prices are the same and stable, all seems well for everyone, other things \n> aside. But if the BTC price does not fall to reflect the decreased hashrate, \n> he situation seems to be a big problem for both coins: BTC1 miners will \n> jump back to BTC when the difficulty adjustment occurs, initiating a \n> potentially never-ending oscillation between the two coins, potentially \n> worse than what BCH is experiencing.  They will not issue coins too fast \n> like BCH because that is a side effect of the asymmetry in BCH's rise and \n> fall algorithm. \n> \n> Solution: \n> \n> Hard fork to implement a new difficulty algorithm that uses a simple rolling \n> average with a much smaller window.  Many small coins have done this as \n> a way to stop big miners from coming on and then suddenly leaving, leaving \n> constant miners stuck with a high difficulty for the rest of a (long) averaging \n> window.  Even better, adjust the reward based on recent solvetimes to \n> motivate more mining (or less) if the solvetimes are too slow (or too fast). \n> This will keep keep coin issuance rate perfectly on schedule with real time. \n> \n> I recommend the following for Bitcoin, as fast, simple, and better than any \n> other difficulty algorithm I'm aware of.  This is the result of a lot of work the \n> past year. \n> \n> === Begin difficulty algorithm === \n> # Zawy v6 difficulty algorithm (modified for bitcoin) \n> # Unmodified Zawy v6 for alt coins: \n> # http://zawy1.blogspot.com/2017/07/best-difficulty-algorithm-zawy-v1b.html \n> # All my failed attempts at something better: \n> # https://github.com/seredat/karbowanec/commit/231db5270acb2e673a641a1800be910ce345668a \n> # \n> # Keep negative solvetimes to correct bad timestamps. \n> # Do not be tempted to use: \n> # next_D = sum(last N Ds) * T / [max(last N TSs) - min(last N TSs]; \n> # ST= Solvetime, TS = timestamp \n> \n> # set constants until next hard fork: \n> \n> T=600; # coin's TargetSolvetime \n> N=30; # Averaging window. Smoother than N=15, faster response than N=60. \n> X=5; \n> limit = X^(2/N); # limit rise and fall in case of timestamp manipulation \n> adjust = 1/(1+0.67/N);  # keeps avg solvetime on track \n> \n> # begin difficulty algorithm \n> \n> avg_ST=0; avg_D=0; \n> for ( i=height;  i > height-N;  i--) {  # go through N most recent blocks \n> avg_ST += (TS[i] - TS[i-1]) / N; \n> avg_D += D[i]/N; \n> } \n> avg_ST = T*limit if avg_ST > T*limit; \n> avg_ST = T/limit if avg_ST < T/limit; \n> \n> next_D = avg_D * T / avg_ST * adjust; \n> \n> # Tim Olsen suggested changing reward to protect against hash attacks. \n> # Karbowanek coin suggested something similar. \n> # I could not find anything better than the simplest idea below. \n> # It was a great surprise that coin issuance rate came out perfect. \n> # BaseReward = coins per block \n> \n> next_reward = BaseReward * avg_ST / T; \n> \n> ======= end algo ==== \n> \n> Due to the limit and keeping negative solvetimes in a true average, \n> timestamp errors resulting in negative solvetimes are corrected in the next \n> block. Otherwise, one would need to do like Zcash and cause a 5-block \n> delay in the response by resorting to the median of past 11 blocks (MPT) \n> as the most recent timestamp, offsetting the timestamps from their \n> corresponding difficulties by 5 blocks. (it does not cause an averaging \n> problem, but it does cause a 5-block delay in the response.)\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171009/198043c0/attachment.html>"
            },
            {
                "author": "Ben Kloester",
                "date": "2017-10-10T02:57:23",
                "message_text_only": "Is there a contingency plan in the case that the incumbent chain following\nthe Bitcoin Core consensus rules comes under 51% attack?\n\nIf the 2x fork really does have the support of >66% of miners (which\nremains to be seen), it seems like they'd have spare capacity to perform\nsuch an attack. In which case, a rushed hard fork might be the only option\nto guarantee the survival of the chain, would it not?\n\nI'm aware of Luke's work on BitcoinHardfork\n<https://github.com/BitcoinHardfork>, but not aware of whether this has\nactually been tested in the field by anyone - ie whether anyone actually\nhas even run the code much / created a testnet. What are the options for an\nemergency hard fork, and how much testing has each seen?\n\n*Ben Kloester*\n\nOn 10 October 2017 at 13:19, Mark Friedenbach via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> The problem of fast acting but non vulnerable difficulty adjustment\n> algorithms is interesting. I would certainly like to see this space further\n> explored, and even have some ideas myself.\n>\n> However without commenting on the technical merits of this specific\n> proposal, I think it must be said upfront that the stated goal is not good.\n> The largest technical concern (ignoring governance) over B2X is that it is\n> a rushed, poorly reviewed hard fork. Hard forks should not be rushed, and\n> they should receive more than the usual level of expert and community\n> review.\n>\n> I\u2019m that light, doing an even more rushed hard fork on an even newer idea\n> with even less review would be hypocritical at best. I would suggest\n> reframing as a hardfork wishlist research problem for the next properly\n> planned hard fork, if one occurs. You might also find the hardfork research\n> group a more accommodating venue for this discussion:\n>\n> https://bitcoinhardforkresearch.github.io/\n>\n> On Oct 9, 2017, at 3:57 PM, Scott Roberts via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Sorry, my previous email did not have the plain text I intended.\n>\n> Background:\n>\n> The bitcoin difficulty algorithm does not seem to be a good one. If there\n> is a fork due to miners seeking maximum profit without due regard to\n> security, users, and nodes, the \"better\" coin could end up being the\n> minority chain. If 90% of hashrate is really going to at least initially\n> go\n> towards using SegWit2x, BTC would face 10x delays in confirmations\n> until the next difficulty adjustment, negatively affecting its price\n> relative\n> to BTC1, causing further delays from even more miner abandonment\n> (until the next adjustment). The 10% miners remaining on BTC do not\n> inevitably lose by staying to endure 10x delays because they have 10x\n> less competition, and the same situation applies to BTC1 miners. If the\n> prices are the same and stable, all seems well for everyone, other things\n> aside. But if the BTC price does not fall to reflect the decreased\n> hashrate,\n> he situation seems to be a big problem for both coins: BTC1 miners will\n> jump back to BTC when the difficulty adjustment occurs, initiating a\n> potentially never-ending oscillation between the two coins, potentially\n> worse than what BCH is experiencing.  They will not issue coins too fast\n> like BCH because that is a side effect of the asymmetry in BCH's rise and\n> fall algorithm.\n>\n> Solution:\n>\n> Hard fork to implement a new difficulty algorithm that uses a simple\n> rolling\n> average with a much smaller window.  Many small coins have done this as\n> a way to stop big miners from coming on and then suddenly leaving, leaving\n> constant miners stuck with a high difficulty for the rest of a (long)\n> averaging\n> window.  Even better, adjust the reward based on recent solvetimes to\n> motivate more mining (or less) if the solvetimes are too slow (or too\n> fast).\n> This will keep keep coin issuance rate perfectly on schedule with real\n> time.\n>\n> I recommend the following for Bitcoin, as fast, simple, and better than\n> any\n> other difficulty algorithm I'm aware of.  This is the result of a lot of\n> work the\n> past year.\n>\n> === Begin difficulty algorithm ===\n> # Zawy v6 difficulty algorithm (modified for bitcoin)\n> # Unmodified Zawy v6 for alt coins:\n> # http://zawy1.blogspot.com/2017/07/best-difficulty-\n> algorithm-zawy-v1b.html\n> # All my failed attempts at something better:\n> # https://github.com/seredat/karbowanec/commit/\n> 231db5270acb2e673a641a1800be910ce345668a\n> #\n> # Keep negative solvetimes to correct bad timestamps.\n> # Do not be tempted to use:\n> # next_D = sum(last N Ds) * T / [max(last N TSs) - min(last N TSs];\n> # ST= Solvetime, TS = timestamp\n>\n> # set constants until next hard fork:\n>\n> T=600; # coin's TargetSolvetime\n> N=30; # Averaging window. Smoother than N=15, faster response than N=60.\n> X=5;\n> limit = X^(2/N); # limit rise and fall in case of timestamp manipulation\n> adjust = 1/(1+0.67/N);  # keeps avg solvetime on track\n>\n> # begin difficulty algorithm\n>\n> avg_ST=0; avg_D=0;\n> for ( i=height;  i > height-N;  i--) {  # go through N most recent blocks\n> avg_ST += (TS[i] - TS[i-1]) / N;\n> avg_D += D[i]/N;\n> }\n> avg_ST = T*limit if avg_ST > T*limit;\n> avg_ST = T/limit if avg_ST < T/limit;\n>\n> next_D = avg_D * T / avg_ST * adjust;\n>\n> # Tim Olsen suggested changing reward to protect against hash attacks.\n> # Karbowanek coin suggested something similar.\n> # I could not find anything better than the simplest idea below.\n> # It was a great surprise that coin issuance rate came out perfect.\n> # BaseReward = coins per block\n>\n> next_reward = BaseReward * avg_ST / T;\n>\n> ======= end algo ====\n>\n> Due to the limit and keeping negative solvetimes in a true average,\n> timestamp errors resulting in negative solvetimes are corrected in the\n> next\n> block. Otherwise, one would need to do like Zcash and cause a 5-block\n> delay in the response by resorting to the median of past 11 blocks (MPT)\n> as the most recent timestamp, offsetting the timestamps from their\n> corresponding difficulties by 5 blocks. (it does not cause an averaging\n> problem, but it does cause a 5-block delay in the response.)\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171010/a592d3b6/attachment-0001.html>"
            },
            {
                "author": "greg misiorek",
                "date": "2017-10-10T10:34:35",
                "message_text_only": "Yes, I agree. Hard forks should be as much scrutinized by fellow bitcoiners, i.e. developers and holders and not only rushed by miners or some other investment gurus, whose incentives are not entirely clear, to remain as decentralized as economically possible.\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Mark Friedenbach via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Monday, October 9, 2017 10:19 PM\nTo: Scott Roberts; Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] New difficulty algorithm needed for SegWit2x fork? (reformatted text)\n\nThe problem of fast acting but non vulnerable difficulty adjustment algorithms is interesting. I would certainly like to see this space further explored, and even have some ideas myself.\n\nHowever without commenting on the technical merits of this specific proposal, I think it must be said upfront that the stated goal is not good. The largest technical concern (ignoring governance) over B2X is that it is a rushed, poorly reviewed hard fork. Hard forks should not be rushed, and they should receive more than the usual level of expert and community review.\n\nI\u2019m that light, doing an even more rushed hard fork on an even newer idea with even less review would be hypocritical at best. I would suggest reframing as a hardfork wishlist research problem for the next properly planned hard fork, if one occurs. You might also find the hardfork research group a more accommodating venue for this discussion:\n\nhttps://bitcoinhardforkresearch.github.io/\nWelcome - Bitcoin Hard Fork Research<https://bitcoinhardforkresearch.github.io/>\nbitcoinhardforkresearch.github.io\nBitcoin Hard Fork Research This website will be updated with relevant ongoing information about Bitcoin hard fork research. Resources: BIP-MMHF, draft patch last ...\n\n\n\nOn Oct 9, 2017, at 3:57 PM, Scott Roberts via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n\nSorry, my previous email did not have the plain text I intended.\n\nBackground:\n\nThe bitcoin difficulty algorithm does not seem to be a good one. If there\nis a fork due to miners seeking maximum profit without due regard to\nsecurity, users, and nodes, the \"better\" coin could end up being the\nminority chain. If 90% of hashrate is really going to at least initially go\ntowards using SegWit2x, BTC would face 10x delays in confirmations\nuntil the next difficulty adjustment, negatively affecting its price relative\nto BTC1, causing further delays from even more miner abandonment\n(until the next adjustment). The 10% miners remaining on BTC do not\ninevitably lose by staying to endure 10x delays because they have 10x\nless competition, and the same situation applies to BTC1 miners. If the\nprices are the same and stable, all seems well for everyone, other things\naside. But if the BTC price does not fall to reflect the decreased hashrate,\nhe situation seems to be a big problem for both coins: BTC1 miners will\njump back to BTC when the difficulty adjustment occurs, initiating a\npotentially never-ending oscillation between the two coins, potentially\nworse than what BCH is experiencing.  They will not issue coins too fast\nlike BCH because that is a side effect of the asymmetry in BCH's rise and\nfall algorithm.\n\nSolution:\n\nHard fork to implement a new difficulty algorithm that uses a simple rolling\naverage with a much smaller window.  Many small coins have done this as\na way to stop big miners from coming on and then suddenly leaving, leaving\nconstant miners stuck with a high difficulty for the rest of a (long) averaging\nwindow.  Even better, adjust the reward based on recent solvetimes to\nmotivate more mining (or less) if the solvetimes are too slow (or too fast).\nThis will keep keep coin issuance rate perfectly on schedule with real time.\n\nI recommend the following for Bitcoin, as fast, simple, and better than any\nother difficulty algorithm I'm aware of.  This is the result of a lot of work the\npast year.\n\n=== Begin difficulty algorithm ===\n# Zawy v6 difficulty algorithm (modified for bitcoin)\n# Unmodified Zawy v6 for alt coins:\n# http://zawy1.blogspot.com/2017/07/best-difficulty-algorithm-zawy-v1b.html\n# All my failed attempts at something better:\n# https://github.com/seredat/karbowanec/commit/231db5270acb2e673a641a1800be910ce345668a\n#\n# Keep negative solvetimes to correct bad timestamps.\n# Do not be tempted to use:\n# next_D = sum(last N Ds) * T / [max(last N TSs) - min(last N TSs];\n# ST= Solvetime, TS = timestamp\n\n# set constants until next hard fork:\n\nT=600; # coin's TargetSolvetime\nN=30; # Averaging window. Smoother than N=15, faster response than N=60.\nX=5;\nlimit = X^(2/N); # limit rise and fall in case of timestamp manipulation\nadjust = 1/(1+0.67/N);  # keeps avg solvetime on track\n\n# begin difficulty algorithm\n\navg_ST=0; avg_D=0;\nfor ( i=height;  i > height-N;  i--) {  # go through N most recent blocks\navg_ST += (TS[i] - TS[i-1]) / N;\navg_D += D[i]/N;\n}\navg_ST = T*limit if avg_ST > T*limit;\navg_ST = T/limit if avg_ST < T/limit;\n\nnext_D = avg_D * T / avg_ST * adjust;\n\n# Tim Olsen suggested changing reward to protect against hash attacks.\n# Karbowanek coin suggested something similar.\n# I could not find anything better than the simplest idea below.\n# It was a great surprise that coin issuance rate came out perfect.\n# BaseReward = coins per block\n\nnext_reward = BaseReward * avg_ST / T;\n\n======= end algo ====\n\nDue to the limit and keeping negative solvetimes in a true average,\ntimestamp errors resulting in negative solvetimes are corrected in the next\nblock. Otherwise, one would need to do like Zcash and cause a 5-block\ndelay in the response by resorting to the median of past 11 blocks (MPT)\nas the most recent timestamp, offsetting the timestamps from their\ncorresponding difficulties by 5 blocks. (it does not cause an averaging\nproblem, but it does cause a 5-block delay in the response.)\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171010/423c22c5/attachment.html>"
            },
            {
                "author": "Ben Kloester",
                "date": "2017-10-11T01:44:52",
                "message_text_only": "Mark, this seems an awful lot like an answer of \"no\", to my question \"Is\nthere a contingency plan in the case that the incumbent chain following the\nBitcoin Core consensus rules comes under 51% attack?\" - is this a correct\ninterpretation?\n\nIn fact, beyond a no, it seems like a \"no, and I disagree with the idea of\ncreating one\".\n\nSo if Bitcoin comes under successful 51%, the project, in your vision, has\nsimply failed?\n\n*Ben Kloester*\n\nOn 10 October 2017 at 13:19, Mark Friedenbach via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> The problem of fast acting but non vulnerable difficulty adjustment\n> algorithms is interesting. I would certainly like to see this space further\n> explored, and even have some ideas myself.\n>\n> However without commenting on the technical merits of this specific\n> proposal, I think it must be said upfront that the stated goal is not good.\n> The largest technical concern (ignoring governance) over B2X is that it is\n> a rushed, poorly reviewed hard fork. Hard forks should not be rushed, and\n> they should receive more than the usual level of expert and community\n> review.\n>\n> I\u2019m that light, doing an even more rushed hard fork on an even newer idea\n> with even less review would be hypocritical at best. I would suggest\n> reframing as a hardfork wishlist research problem for the next properly\n> planned hard fork, if one occurs. You might also find the hardfork research\n> group a more accommodating venue for this discussion:\n>\n> https://bitcoinhardforkresearch.github.io/\n>\n> On Oct 9, 2017, at 3:57 PM, Scott Roberts via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Sorry, my previous email did not have the plain text I intended.\n>\n> Background:\n>\n> The bitcoin difficulty algorithm does not seem to be a good one. If there\n> is a fork due to miners seeking maximum profit without due regard to\n> security, users, and nodes, the \"better\" coin could end up being the\n> minority chain. If 90% of hashrate is really going to at least initially\n> go\n> towards using SegWit2x, BTC would face 10x delays in confirmations\n> until the next difficulty adjustment, negatively affecting its price\n> relative\n> to BTC1, causing further delays from even more miner abandonment\n> (until the next adjustment). The 10% miners remaining on BTC do not\n> inevitably lose by staying to endure 10x delays because they have 10x\n> less competition, and the same situation applies to BTC1 miners. If the\n> prices are the same and stable, all seems well for everyone, other things\n> aside. But if the BTC price does not fall to reflect the decreased\n> hashrate,\n> he situation seems to be a big problem for both coins: BTC1 miners will\n> jump back to BTC when the difficulty adjustment occurs, initiating a\n> potentially never-ending oscillation between the two coins, potentially\n> worse than what BCH is experiencing.  They will not issue coins too fast\n> like BCH because that is a side effect of the asymmetry in BCH's rise and\n> fall algorithm.\n>\n> Solution:\n>\n> Hard fork to implement a new difficulty algorithm that uses a simple\n> rolling\n> average with a much smaller window.  Many small coins have done this as\n> a way to stop big miners from coming on and then suddenly leaving, leaving\n> constant miners stuck with a high difficulty for the rest of a (long)\n> averaging\n> window.  Even better, adjust the reward based on recent solvetimes to\n> motivate more mining (or less) if the solvetimes are too slow (or too\n> fast).\n> This will keep keep coin issuance rate perfectly on schedule with real\n> time.\n>\n> I recommend the following for Bitcoin, as fast, simple, and better than\n> any\n> other difficulty algorithm I'm aware of.  This is the result of a lot of\n> work the\n> past year.\n>\n> === Begin difficulty algorithm ===\n> # Zawy v6 difficulty algorithm (modified for bitcoin)\n> # Unmodified Zawy v6 for alt coins:\n> # http://zawy1.blogspot.com/2017/07/best-difficulty-\n> algorithm-zawy-v1b.html\n> # All my failed attempts at something better:\n> # https://github.com/seredat/karbowanec/commit/\n> 231db5270acb2e673a641a1800be910ce345668a\n> #\n> # Keep negative solvetimes to correct bad timestamps.\n> # Do not be tempted to use:\n> # next_D = sum(last N Ds) * T / [max(last N TSs) - min(last N TSs];\n> # ST= Solvetime, TS = timestamp\n>\n> # set constants until next hard fork:\n>\n> T=600; # coin's TargetSolvetime\n> N=30; # Averaging window. Smoother than N=15, faster response than N=60.\n> X=5;\n> limit = X^(2/N); # limit rise and fall in case of timestamp manipulation\n> adjust = 1/(1+0.67/N);  # keeps avg solvetime on track\n>\n> # begin difficulty algorithm\n>\n> avg_ST=0; avg_D=0;\n> for ( i=height;  i > height-N;  i--) {  # go through N most recent blocks\n> avg_ST += (TS[i] - TS[i-1]) / N;\n> avg_D += D[i]/N;\n> }\n> avg_ST = T*limit if avg_ST > T*limit;\n> avg_ST = T/limit if avg_ST < T/limit;\n>\n> next_D = avg_D * T / avg_ST * adjust;\n>\n> # Tim Olsen suggested changing reward to protect against hash attacks.\n> # Karbowanek coin suggested something similar.\n> # I could not find anything better than the simplest idea below.\n> # It was a great surprise that coin issuance rate came out perfect.\n> # BaseReward = coins per block\n>\n> next_reward = BaseReward * avg_ST / T;\n>\n> ======= end algo ====\n>\n> Due to the limit and keeping negative solvetimes in a true average,\n> timestamp errors resulting in negative solvetimes are corrected in the\n> next\n> block. Otherwise, one would need to do like Zcash and cause a 5-block\n> delay in the response by resorting to the median of past 11 blocks (MPT)\n> as the most recent timestamp, offsetting the timestamps from their\n> corresponding difficulties by 5 blocks. (it does not cause an averaging\n> problem, but it does cause a 5-block delay in the response.)\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171011/338575fd/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2017-10-11T02:48:13",
                "message_text_only": "Good morning Ben,\n\nI am not Mark, and I am nowhere near being a true Core developer yet, but I would like to point out that even under a 51% attack, there is a practical limit to the number of blocks that can be orphaned.  It would still take years to rewrite history from the Genesis block, for instance.\n\nWhat little data we have (BT1 / BT2 price ratio on BitFinex) suggests that tokens solely on the 2X chain will not be valued as highly as tokens solely on the Core chain.  As miners generate tokens that are only for a specific chain, they will have higher incentive to gain tokens on the Core chain rather than the 2X chain.\n\nAs is commonly said, hodling is free, whereas mining is not.  Hodlers have much greater power in hardfork situations than miners have: simply by selling their tokens on the 2X chain and not in the Core chain, hodlers can impose economic disincentives for mining of the 2X chain.\n\nMiners can switch to BCH, but that is valued even less than BT2 tokens are, and thus even less attractive to mine on.\n\nWe should also pay attention, that BCH changed its difficulty algorithm, and it is often considered to be to its detriment due to sudden hashpower oscillations on that chain.  We should be wary of difficulty algorithm changes, as it is the difficulty which determines the security of the chain.\n\n--\n\nIf we attempt to deploy a difficulty change, that is a hardfork, and hodlers will be divided on this situation.  Some will sell the tokens on the difficulty-change hardfork, some will sell the tokens on the non-difficulty-change hardfork.  Thus the economic punishment for mining the 2X chain will be diluted due to the introduction of the difficulty-change hardfork, due to splitting of the hodler base that passes judgment over development.\n\nThus, strategy-wise, it is better to not hardfork (whether difficulty adjustment, PoW change, or so on) in response to a contentious hardfork, as hodlers can remain united against or for the contentious hardfork.  Instead, it is better to let the market decide, which automatically imposes economic sanctions on miners who choose against the market's decision.  Thus, it is better to simply let 2X die under the hands of our benevolent hodlers.\n\nLater, when it is obvious which fate is sealed, we can reconsider such changes (difficulty adjustment, PoW change, block size) when things are calmer.  However, such changes cannot be safely done in response to a contentious hardfork.\n\n--\n\nIf indeed the Core chain is eradicated, then Bitcoin indeed has failed and I would very much rather sell my hodlings and find some other means to amuse myself.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171010/abf9db2a/attachment.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-10-11T04:08:52",
                "message_text_only": "You phrase the question as if \u201cdeploying a hard fork to bitcoin\u201d would protect the bitcoin chain from the attack. But that\u2019s not what happens. If you are hard forking from the perspective of deployed nodes, you are an different ledger, regardless of circumstance or who did it. Instead of there being one altcoin fighting to take hashpower from bitcoin, there\u2019d now be 2. It is not at all obvious to me that this would be a better outcome.\n\nIf that isn\u2019t reason enough, changing the difficulty adjustment algorithm doesn\u2019t solve the underlying issue\u2015hashpower not being aligned with users\u2019 (or even its owners\u2019) interests. Propose a fix to the underlying cause and that might be worth considering, if it passes peer review. But without that you\u2019d just be making the state of affairs arguably worse.\n\nAnd so yes, *if* this incentive problem can\u2019t be solved, and the unaltered bitcoin chain dies from disuse after suffering a hashpower attack, especially a centrally and/or purposefully instigated one, then bitcoin would be failed a failed project.\n\nThe thesis (and value proposition) of bitcoin is that a particular category of economic incentives can be used to solve the problem of creating a secure trustess ledger. If those incentives failed, then he thesis of bitcoin would have been experimentally falsified, yes. Maybe the incentives can be made better to save the project, but we\u2019d have to fix the source of the problem not the symptoms.\n\n> On Oct 10, 2017, at 6:44 PM, Ben Kloester <benkloester at gmail.com> wrote:\n> \n> Mark, this seems an awful lot like an answer of \"no\", to my question \"Is there a contingency plan in the case that the incumbent chain following the Bitcoin Core consensus rules comes under 51% attack?\" - is this a correct interpretation?\n> \n> In fact, beyond a no, it seems like a \"no, and I disagree with the idea of creating one\".\n> \n> So if Bitcoin comes under successful 51%, the project, in your vision, has simply failed?\n> \n> Ben Kloester\n> \n> \n>> On 10 October 2017 at 13:19, Mark Friedenbach via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> The problem of fast acting but non vulnerable difficulty adjustment algorithms is interesting. I would certainly like to see this space further explored, and even have some ideas myself.\n>> \n>> However without commenting on the technical merits of this specific proposal, I think it must be said upfront that the stated goal is not good. The largest technical concern (ignoring governance) over B2X is that it is a rushed, poorly reviewed hard fork. Hard forks should not be rushed, and they should receive more than the usual level of expert and community review.\n>> \n>> I\u2019m that light, doing an even more rushed hard fork on an even newer idea with even less review would be hypocritical at best. I would suggest reframing as a hardfork wishlist research problem for the next properly planned hard fork, if one occurs. You might also find the hardfork research group a more accommodating venue for this discussion:\n>> \n>> https://bitcoinhardforkresearch.github.io/\n>> \n>>> On Oct 9, 2017, at 3:57 PM, Scott Roberts via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> \n>>> Sorry, my previous email did not have the plain text I intended.\n>>> \n>>> Background: \n>>> \n>>> The bitcoin difficulty algorithm does not seem to be a good one. If there \n>>> is a fork due to miners seeking maximum profit without due regard to \n>>> security, users, and nodes, the \"better\" coin could end up being the \n>>> minority chain. If 90% of hashrate is really going to at least initially go \n>>> towards using SegWit2x, BTC would face 10x delays in confirmations \n>>> until the next difficulty adjustment, negatively affecting its price relative \n>>> to BTC1, causing further delays from even more miner abandonment \n>>> (until the next adjustment). The 10% miners remaining on BTC do not \n>>> inevitably lose by staying to endure 10x delays because they have 10x \n>>> less competition, and the same situation applies to BTC1 miners. If the \n>>> prices are the same and stable, all seems well for everyone, other things \n>>> aside. But if the BTC price does not fall to reflect the decreased hashrate, \n>>> he situation seems to be a big problem for both coins: BTC1 miners will \n>>> jump back to BTC when the difficulty adjustment occurs, initiating a \n>>> potentially never-ending oscillation between the two coins, potentially \n>>> worse than what BCH is experiencing.  They will not issue coins too fast \n>>> like BCH because that is a side effect of the asymmetry in BCH's rise and \n>>> fall algorithm. \n>>> \n>>> Solution: \n>>> \n>>> Hard fork to implement a new difficulty algorithm that uses a simple rolling \n>>> average with a much smaller window.  Many small coins have done this as \n>>> a way to stop big miners from coming on and then suddenly leaving, leaving \n>>> constant miners stuck with a high difficulty for the rest of a (long) averaging \n>>> window.  Even better, adjust the reward based on recent solvetimes to \n>>> motivate more mining (or less) if the solvetimes are too slow (or too fast). \n>>> This will keep keep coin issuance rate perfectly on schedule with real time. \n>>> \n>>> I recommend the following for Bitcoin, as fast, simple, and better than any \n>>> other difficulty algorithm I'm aware of.  This is the result of a lot of work the \n>>> past year. \n>>> \n>>> === Begin difficulty algorithm === \n>>> # Zawy v6 difficulty algorithm (modified for bitcoin) \n>>> # Unmodified Zawy v6 for alt coins: \n>>> # http://zawy1.blogspot.com/2017/07/best-difficulty-algorithm-zawy-v1b.html \n>>> # All my failed attempts at something better: \n>>> # https://github.com/seredat/karbowanec/commit/231db5270acb2e673a641a1800be910ce345668a \n>>> # \n>>> # Keep negative solvetimes to correct bad timestamps. \n>>> # Do not be tempted to use: \n>>> # next_D = sum(last N Ds) * T / [max(last N TSs) - min(last N TSs]; \n>>> # ST= Solvetime, TS = timestamp \n>>> \n>>> # set constants until next hard fork: \n>>> \n>>> T=600; # coin's TargetSolvetime \n>>> N=30; # Averaging window. Smoother than N=15, faster response than N=60. \n>>> X=5; \n>>> limit = X^(2/N); # limit rise and fall in case of timestamp manipulation \n>>> adjust = 1/(1+0.67/N);  # keeps avg solvetime on track \n>>> \n>>> # begin difficulty algorithm \n>>> \n>>> avg_ST=0; avg_D=0; \n>>> for ( i=height;  i > height-N;  i--) {  # go through N most recent blocks \n>>> avg_ST += (TS[i] - TS[i-1]) / N; \n>>> avg_D += D[i]/N; \n>>> } \n>>> avg_ST = T*limit if avg_ST > T*limit; \n>>> avg_ST = T/limit if avg_ST < T/limit; \n>>> \n>>> next_D = avg_D * T / avg_ST * adjust; \n>>> \n>>> # Tim Olsen suggested changing reward to protect against hash attacks. \n>>> # Karbowanek coin suggested something similar. \n>>> # I could not find anything better than the simplest idea below. \n>>> # It was a great surprise that coin issuance rate came out perfect. \n>>> # BaseReward = coins per block \n>>> \n>>> next_reward = BaseReward * avg_ST / T; \n>>> \n>>> ======= end algo ==== \n>>> \n>>> Due to the limit and keeping negative solvetimes in a true average, \n>>> timestamp errors resulting in negative solvetimes are corrected in the next \n>>> block. Otherwise, one would need to do like Zcash and cause a 5-block \n>>> delay in the response by resorting to the median of past 11 blocks (MPT) \n>>> as the most recent timestamp, offsetting the timestamps from their \n>>> corresponding difficulties by 5 blocks. (it does not cause an averaging \n>>> problem, but it does cause a 5-block delay in the response.)\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> \n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> \n> \n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171010/4c45d2f3/attachment-0001.html>"
            },
            {
                "author": "Moral Agent",
                "date": "2017-10-11T15:28:08",
                "message_text_only": ">Instead of there being one altcoin fighting to take hashpower from\nbitcoin, there\u2019d now be 2\n\nYes, there would be 2. One of which would (in the scenario we are\ndiscussing) be producing blocks excruciatingly slowly but be the same in\nall other aspects.\n\n>changing the difficulty adjustment algorithm doesn\u2019t solve the underlying\nissue\u2014hashpower not being aligned with users\u2019 (or even its owners\u2019)\ninterests\n\nI disagree. Changing the difficulty adjustment algorithm could improve the\nfunctionality of a chain, which could be an important prerequisite to using\nand trading the tokens on the chain. This property could help keep the\nprice of the token high, which is what pressures hashpower to align with\nuser interests.\n\n>And so yes, *if* this incentive problem can\u2019t be solved, and the unaltered\nbitcoin chain dies from disuse after suffering a hashpower attack,\nespecially a centrally and/or purposefully instigated one, then bitcoin\nwould be failed a failed project.\n\nIF the incentive problem could not be resolved then Bitcoin would be a\nfailed project.\n\nBut here is a bit of good news.\n\nBitcoin has developers!\n\nAnd those developers can publish a contingency plan!\n\nAnd that contingency plan can be an emergency hard fork to a different\nretarget algorithm.\n\nAnd that emergency hard fork can gain consensus if it is broadly preferred\nover the status quo.\n\nIf 90% of the hash power follows NYA, blocks are going to take 100 minutes\nuntil difficulty adjusts after 4.5 months.\n\nThat is quite a handicap, even for a honey badger. Emergency hard fork\ncarries a risk, but depending on the scenario in November, it could be a\nrisk worth taking.\n\nOne more thing. If miners think they are going to succeed in starving the\nlegacy chain to death, they might be more likely to try. If they get a\ncredible signal that the legacy chain will react by changing the retarget\nfunction and thereby be more likely to survive, they might feel less\ncommitted to a strategy of starving the legacy chain. This could be\nespecially true if they are giving up profit for what they fervently hope\nwill be a short period of time.\n\nOn Wed, Oct 11, 2017 at 12:08 AM, Mark Friedenbach via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> You phrase the question as if \u201cdeploying a hard fork to bitcoin\u201d would\n> protect the bitcoin chain from the attack. But that\u2019s not what happens. If\n> you are hard forking from the perspective of deployed nodes, you are an\n> different ledger, regardless of circumstance or who did it. Instead of\n> there being one altcoin fighting to take hashpower from bitcoin, there\u2019d\n> now be 2. It is not at all obvious to me that this would be a better\n> outcome.\n>\n> If that isn\u2019t reason enough, changing the difficulty adjustment algorithm\n> doesn\u2019t solve the underlying issue\u2014hashpower not being aligned with users\u2019\n> (or even its owners\u2019) interests. Propose a fix to the underlying cause and\n> that might be worth considering, if it passes peer review. But without that\n> you\u2019d just be making the state of affairs arguably worse.\n>\n> And so yes, *if* this incentive problem can\u2019t be solved, and the unaltered\n> bitcoin chain dies from disuse after suffering a hashpower attack,\n> especially a centrally and/or purposefully instigated one, then bitcoin\n> would be failed a failed project.\n>\n> The thesis (and value proposition) of bitcoin is that a particular\n> category of economic incentives can be used to solve the problem of\n> creating a secure trustess ledger. If those incentives failed, then he\n> thesis of bitcoin would have been experimentally falsified, yes. Maybe the\n> incentives can be made better to save the project, but we\u2019d have to fix the\n> source of the problem not the symptoms.\n>\n> On Oct 10, 2017, at 6:44 PM, Ben Kloester <benkloester at gmail.com> wrote:\n>\n> Mark, this seems an awful lot like an answer of \"no\", to my question \"Is\n> there a contingency plan in the case that the incumbent chain following the\n> Bitcoin Core consensus rules comes under 51% attack?\" - is this a correct\n> interpretation?\n>\n> In fact, beyond a no, it seems like a \"no, and I disagree with the idea of\n> creating one\".\n>\n> So if Bitcoin comes under successful 51%, the project, in your vision, has\n> simply failed?\n>\n> *Ben Kloester*\n>\n> On 10 October 2017 at 13:19, Mark Friedenbach via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> The problem of fast acting but non vulnerable difficulty adjustment\n>> algorithms is interesting. I would certainly like to see this space further\n>> explored, and even have some ideas myself.\n>>\n>> However without commenting on the technical merits of this specific\n>> proposal, I think it must be said upfront that the stated goal is not good.\n>> The largest technical concern (ignoring governance) over B2X is that it is\n>> a rushed, poorly reviewed hard fork. Hard forks should not be rushed, and\n>> they should receive more than the usual level of expert and community\n>> review.\n>>\n>> I\u2019m that light, doing an even more rushed hard fork on an even newer idea\n>> with even less review would be hypocritical at best. I would suggest\n>> reframing as a hardfork wishlist research problem for the next properly\n>> planned hard fork, if one occurs. You might also find the hardfork research\n>> group a more accommodating venue for this discussion:\n>>\n>> https://bitcoinhardforkresearch.github.io/\n>>\n>> On Oct 9, 2017, at 3:57 PM, Scott Roberts via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> Sorry, my previous email did not have the plain text I intended.\n>>\n>> Background:\n>>\n>> The bitcoin difficulty algorithm does not seem to be a good one. If there\n>> is a fork due to miners seeking maximum profit without due regard to\n>> security, users, and nodes, the \"better\" coin could end up being the\n>> minority chain. If 90% of hashrate is really going to at least initially\n>> go\n>> towards using SegWit2x, BTC would face 10x delays in confirmations\n>> until the next difficulty adjustment, negatively affecting its price\n>> relative\n>> to BTC1, causing further delays from even more miner abandonment\n>> (until the next adjustment). The 10% miners remaining on BTC do not\n>> inevitably lose by staying to endure 10x delays because they have 10x\n>> less competition, and the same situation applies to BTC1 miners. If the\n>> prices are the same and stable, all seems well for everyone, other things\n>> aside. But if the BTC price does not fall to reflect the decreased\n>> hashrate,\n>> he situation seems to be a big problem for both coins: BTC1 miners will\n>> jump back to BTC when the difficulty adjustment occurs, initiating a\n>> potentially never-ending oscillation between the two coins, potentially\n>> worse than what BCH is experiencing.  They will not issue coins too fast\n>> like BCH because that is a side effect of the asymmetry in BCH's rise and\n>> fall algorithm.\n>>\n>> Solution:\n>>\n>> Hard fork to implement a new difficulty algorithm that uses a simple\n>> rolling\n>> average with a much smaller window.  Many small coins have done this as\n>> a way to stop big miners from coming on and then suddenly leaving,\n>> leaving\n>> constant miners stuck with a high difficulty for the rest of a (long)\n>> averaging\n>> window.  Even better, adjust the reward based on recent solvetimes to\n>> motivate more mining (or less) if the solvetimes are too slow (or too\n>> fast).\n>> This will keep keep coin issuance rate perfectly on schedule with real\n>> time.\n>>\n>> I recommend the following for Bitcoin, as fast, simple, and better than\n>> any\n>> other difficulty algorithm I'm aware of.  This is the result of a lot of\n>> work the\n>> past year.\n>>\n>> === Begin difficulty algorithm ===\n>> # Zawy v6 difficulty algorithm (modified for bitcoin)\n>> # Unmodified Zawy v6 for alt coins:\n>> # http://zawy1.blogspot.com/2017/07/best-difficulty-algorithm-\n>> zawy-v1b.html\n>> # All my failed attempts at something better:\n>> # https://github.com/seredat/karbowanec/commit/231db5270acb2e6\n>> 73a641a1800be910ce345668a\n>> #\n>> # Keep negative solvetimes to correct bad timestamps.\n>> # Do not be tempted to use:\n>> # next_D = sum(last N Ds) * T / [max(last N TSs) - min(last N TSs];\n>> # ST= Solvetime, TS = timestamp\n>>\n>> # set constants until next hard fork:\n>>\n>> T=600; # coin's TargetSolvetime\n>> N=30; # Averaging window. Smoother than N=15, faster response than N=60.\n>> X=5;\n>> limit = X^(2/N); # limit rise and fall in case of timestamp manipulation\n>> adjust = 1/(1+0.67/N);  # keeps avg solvetime on track\n>>\n>> # begin difficulty algorithm\n>>\n>> avg_ST=0; avg_D=0;\n>> for ( i=height;  i > height-N;  i--) {  # go through N most recent blocks\n>> avg_ST += (TS[i] - TS[i-1]) / N;\n>> avg_D += D[i]/N;\n>> }\n>> avg_ST = T*limit if avg_ST > T*limit;\n>> avg_ST = T/limit if avg_ST < T/limit;\n>>\n>> next_D = avg_D * T / avg_ST * adjust;\n>>\n>> # Tim Olsen suggested changing reward to protect against hash attacks.\n>> # Karbowanek coin suggested something similar.\n>> # I could not find anything better than the simplest idea below.\n>> # It was a great surprise that coin issuance rate came out perfect.\n>> # BaseReward = coins per block\n>>\n>> next_reward = BaseReward * avg_ST / T;\n>>\n>> ======= end algo ====\n>>\n>> Due to the limit and keeping negative solvetimes in a true average,\n>> timestamp errors resulting in negative solvetimes are corrected in the\n>> next\n>> block. Otherwise, one would need to do like Zcash and cause a 5-block\n>> delay in the response by resorting to the median of past 11 blocks (MPT)\n>> as the most recent timestamp, offsetting the timestamps from their\n>> corresponding difficulties by 5 blocks. (it does not cause an averaging\n>> problem, but it does cause a 5-block delay in the response.)\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171011/c9ac3993/attachment-0001.html>"
            },
            {
                "author": "Scott Roberts",
                "date": "2017-10-11T01:29:54",
                "message_text_only": "I agree: a new difficulty algorithm starting from zero is inconceivably \nrushed. But it's also inconceivable to not have one ready in two months \nif my understanding of our current situation is correct. Is there any \ncomplaint or suggestion about this algorithm or the appropriate goals of \nan ideal difficulty algorithm? I feel like there is a discussion that needs \nto be hashed out before a draft BIP at the HF page, but I do not know \nwhere is best or who would be interested. If the community shows it is \nreceptive and supportive I think I could get Karbowanek coin to put it \ninto live action and solicit hash attacks. They are currently using a \nsimpler N=17 like this since last November. They have tested all my \nattempted improvements the past few months, so they are familiar with all \nthe in and outs. \n\nThis particular coin split is looking different. Assuming users currently \nprefer SW, it still seems like miner support is going to convince enough \nusers that SegWit2x is a worthy if not superior alternative. The result \ncould be both coins oscillating with long delays, as long as the price is \nsimilar. As soon as it is not similar, maybe the loser will be in a death \nspiral, pushed to the margin like previous coins. This might be a bitcoin \nfeature. But the 2016 window seems like it is too brutal. It seems like it \nwill result in an accidental winner before the better coin can be \ndetermined by more rational means."
            },
            {
                "author": "Scott Roberts",
                "date": "2017-10-12T08:51:33",
                "message_text_only": "Since there is no surviving argument in this thread contrary to my original\npost, I'll begin work on a BIP.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171012/0541774a/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "New difficulty algorithm needed for SegWit2x fork? (reformatted text)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Moral Agent",
                "Scott Roberts",
                "greg misiorek",
                "Ben Kloester",
                "ZmnSCPxj",
                "Mark Friedenbach"
            ],
            "messages_count": 10,
            "total_messages_chars_count": 52226
        }
    },
    {
        "title": "[bitcoin-dev] Generalized sharding protocol for decentralized scaling without Miners owning our BTC",
        "thread_messages": [
            {
                "author": "Tao Effect",
                "date": "2017-10-10T00:04:55",
                "message_text_only": "Dear list,\n\nIn previous arguments over Drivechain (and Drivechain-like proposals) I promised that better scaling proposals \u2014 that do not sacrifice Bitcoin's security \u2014 would come along.\n\nI planned to do a detailed writeup, but have decided to just send off this email with what I have, because I'm unlikely to have time to write up a detailed proposal.\n\nThe idea is very simple, and I'm sure others have mentioned either exactly it, or similar ideas (e.g. burning coins) before.\n\nThis is a generic sharding protocol for all blockchains, including Bitcoin.\n\nUsers simply say: \"My coins on Chain A are going to be sent to Chain B\".\n\nThen they burn the coins on Chain A, and create a minting transaction on Chain B. The details of how to ensure that coins do not get lost needs to be worked out, but I'm fairly certain the folks on this list can figure out those details.\n\n- Thin clients, nodes, and miners, can all very easily verify that said action took place, and therefore accept the \"newly minted\" coins on B as valid.\n- Users client software now also knows where to look for the other coins (if for some reason it needs to).\n\nThis doesn't even need much modification to the Bitcoin protocol as most of the verification is done client-side.\n\nIt is fully decentralized, and there's no need to give our ownership of our coins to miners to get scale.\n\nMy sincere apologies if this has been brought up before (in which case, I would be very grateful for a link to the proposal).\n\nCheers,\nGreg Slepak\n\n--\nPlease do not email me anything that you are not comfortable also sharing with the NSA.\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171009/261e847b/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171009/261e847b/attachment.sig>"
            },
            {
                "author": "Tao Effect",
                "date": "2017-10-10T01:02:38",
                "message_text_only": "Dear list,\n\nIn previous arguments over Drivechain (and Drivechain-like proposals) I promised that better scaling proposals \u2014 that do not sacrifice Bitcoin's security \u2014 would come along.\n\nI planned to do a detailed writeup, but have decided to just send off this email with what I have, because I'm unlikely to have time to write up a detailed proposal.\n\nThe idea is very simple (and by no means novel*), and I'm sure others have mentioned either exactly it, or similar ideas (e.g. burning coins) before.\n\nThis is a generic sharding protocol for all blockchains, including Bitcoin.\n\nUsers simply say: \"My coins on Chain A are going to be sent to Chain B\".\n\nThen they burn the coins on Chain A, and create a minting transaction on Chain B. The details of how to ensure that coins do not get lost needs to be worked out, but I'm fairly certain the folks on this list can figure out those details.\n\n- Thin clients, nodes, and miners, can all very easily verify that said action took place, and therefore accept the \"newly minted\" coins on B as valid.\n- Users client software now also knows where to look for the other coins (if for some reason it needs to).\n\nThis doesn't even need much modification to the Bitcoin protocol as most of the verification is done client-side.\n\nIt is fully decentralized, and there's no need to give our ownership of our coins to miners to get scale.\n\nMy sincere apologies if this has been brought up before (in which case, I would be very grateful for a link to the proposal).\n\nCheers,\nGreg Slepak\n\n* This idea is similar in spirit to Interledger.\n\n--\nPlease do not email me anything that you are not comfortable also sharing with the NSA.\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171009/2ff1f35a/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171009/2ff1f35a/attachment-0001.sig>"
            },
            {
                "author": "Paul Sztorc",
                "date": "2017-10-10T01:39:33",
                "message_text_only": "That is only a one-way peg, not a two-way.\n\nIn fact, that is exactly what drivechain does, if one chooses parameters\nfor the drivechain that make it impossible for any side-to-main transfer to\nsucceed.\n\nOne-way pegs have strong first-mover disadvantages.\n\nPaul\n\nOn Oct 9, 2017 9:24 PM, \"Tao Effect via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\nDear list,\n\nIn previous arguments over Drivechain (and Drivechain-like proposals) I\npromised that better scaling proposals \u2014 that do not sacrifice Bitcoin's\nsecurity \u2014 would come along.\n\nI planned to do a detailed writeup, but have decided to just send off this\nemail with what I have, because I'm unlikely to have time to write up a\ndetailed proposal.\n\nThe idea is very simple (and by no means novel*), and I'm sure others have\nmentioned either exactly it, or similar ideas (e.g. burning coins) before.\n\nThis is a generic sharding protocol for all blockchains, including Bitcoin.\n\nUsers simply say: \"My coins on Chain A are going to be sent to Chain B\".\n\nThen they burn the coins on Chain A, and create a minting transaction on\nChain B. The details of how to ensure that coins do not get lost needs to\nbe worked out, but I'm fairly certain the folks on this list can figure out\nthose details.\n\n- Thin clients, nodes, and miners, can all very easily verify that said\naction took place, and therefore accept the \"newly minted\" coins on B as\nvalid.\n- Users client software now also knows where to look for the other coins\n(if for some reason it needs to).\n\nThis doesn't even need much modification to the Bitcoin protocol as most of\nthe verification is done client-side.\n\nIt is fully decentralized, and there's no need to give our ownership of our\ncoins to miners to get scale.\n\nMy sincere apologies if this has been brought up before (in which case, I\nwould be very grateful for a link to the proposal).\n\nCheers,\nGreg Slepak\n\n* This idea is similar in spirit to Interledger.\n\n--\nPlease do not email me anything that you are not comfortable also sharing with\nthe NSA.\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171009/ca05b959/attachment.html>"
            },
            {
                "author": "Tao Effect",
                "date": "2017-10-10T05:19:58",
                "message_text_only": "Paul,\n\nIt's a two-way peg.\n\nThere's nothing preventing transfers back to the main chain.\n\nThey work in the exact same manner.\n\nCheers,\nGreg\n\n--\nPlease do not email me anything that you are not comfortable also sharing with the NSA.\n\n> On Oct 9, 2017, at 6:39 PM, Paul Sztorc <truthcoin at gmail.com <mailto:truthcoin at gmail.com>> wrote:\n> \n> That is only a one-way peg, not a two-way.\n> \n> In fact, that is exactly what drivechain does, if one chooses parameters for the drivechain that make it impossible for any side-to-main transfer to succeed.\n> \n> One-way pegs have strong first-mover disadvantages.\n> \n> Paul\n> \n> On Oct 9, 2017 9:24 PM, \"Tao Effect via bitcoin-dev\" <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> Dear list,\n> \n> In previous arguments over Drivechain (and Drivechain-like proposals) I promised that better scaling proposals \u2014 that do not sacrifice Bitcoin's security \u2014 would come along.\n> \n> I planned to do a detailed writeup, but have decided to just send off this email with what I have, because I'm unlikely to have time to write up a detailed proposal.\n> \n> The idea is very simple (and by no means novel*), and I'm sure others have mentioned either exactly it, or similar ideas (e.g. burning coins) before.\n> \n> This is a generic sharding protocol for all blockchains, including Bitcoin.\n> \n> Users simply say: \"My coins on Chain A are going to be sent to Chain B\".\n> \n> Then they burn the coins on Chain A, and create a minting transaction on Chain B. The details of how to ensure that coins do not get lost needs to be worked out, but I'm fairly certain the folks on this list can figure out those details.\n> \n> - Thin clients, nodes, and miners, can all very easily verify that said action took place, and therefore accept the \"newly minted\" coins on B as valid.\n> - Users client software now also knows where to look for the other coins (if for some reason it needs to).\n> \n> This doesn't even need much modification to the Bitcoin protocol as most of the verification is done client-side.\n> \n> It is fully decentralized, and there's no need to give our ownership of our coins to miners to get scale.\n> \n> My sincere apologies if this has been brought up before (in which case, I would be very grateful for a link to the proposal).\n> \n> Cheers,\n> Greg Slepak\n> \n> * This idea is similar in spirit to Interledger.\n> \n> --\n> Please do not email me anything that you are not comfortable also sharing with the NSA.\n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n> \n> \n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171009/f3c63867/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171009/f3c63867/attachment-0001.sig>"
            },
            {
                "author": "Lucas Clemente Vella",
                "date": "2017-10-10T20:18:39",
                "message_text_only": "2017-10-09 22:39 GMT-03:00 Paul Sztorc via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org>:\n\n> That is only a one-way peg, not a two-way.\n>\n> In fact, that is exactly what drivechain does, if one chooses parameters\n> for the drivechain that make it impossible for any side-to-main transfer to\n> succeed.\n>\n> One-way pegs have strong first-mover disadvantages.\n>\n\nI understand the first-mover disadvantages, but I keep thinking that if the\nnew chain is Pareto optimal, i.e. is in all aspects at least good as the\noriginal chain, but in some so much better to justify the change, the\ninitial resistance is an unstable equilibrium. Like a herd of buffaloes\nattacking a lion: the first buffalo to attack is in awful disadvantage, but\nif a critical mass of the herd follows, the movement succeeds beyond\nturning back, and every buffalo benefited, both those who attacked the lion\nand those that didn't (because the lion was chased away or killed).\n\n-- \nLucas Clemente Vella\nlvella at gmail.com\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171010/533ac1c1/attachment.html>"
            },
            {
                "author": "Paul Sztorc",
                "date": "2017-10-10T11:20:36",
                "message_text_only": "Haha, no. Because you \"burned\" the coins.\n\nOn Oct 10, 2017 1:20 AM, \"Tao Effect\" <contact at taoeffect.com> wrote:\n\n> Paul,\n>\n> It's a two-way peg.\n>\n> There's nothing preventing transfers back to the main chain.\n>\n> They work in the exact same manner.\n>\n> Cheers,\n> Greg\n>\n> --\n> Please do not email me anything that you are not comfortable also sharing with\n> the NSA.\n>\n> On Oct 9, 2017, at 6:39 PM, Paul Sztorc <truthcoin at gmail.com> wrote:\n>\n> That is only a one-way peg, not a two-way.\n>\n> In fact, that is exactly what drivechain does, if one chooses parameters\n> for the drivechain that make it impossible for any side-to-main transfer to\n> succeed.\n>\n> One-way pegs have strong first-mover disadvantages.\n>\n> Paul\n>\n> On Oct 9, 2017 9:24 PM, \"Tao Effect via bitcoin-dev\" <bitcoin-dev at lists.\n> linuxfoundation.org> wrote:\n>\n> Dear list,\n>\n> In previous arguments over Drivechain (and Drivechain-like proposals) I\n> promised that better scaling proposals \u2014 that do not sacrifice Bitcoin's\n> security \u2014 would come along.\n>\n> I planned to do a detailed writeup, but have decided to just send off this\n> email with what I have, because I'm unlikely to have time to write up a\n> detailed proposal.\n>\n> The idea is very simple (and by no means novel*), and I'm sure others have\n> mentioned either exactly it, or similar ideas (e.g. burning coins) before.\n>\n> This is a generic sharding protocol for all blockchains, including Bitcoin.\n>\n> Users simply say: \"My coins on Chain A are going to be sent to Chain B\".\n>\n> Then they burn the coins on Chain A, and create a minting transaction on\n> Chain B. The details of how to ensure that coins do not get lost needs to\n> be worked out, but I'm fairly certain the folks on this list can figure out\n> those details.\n>\n> - Thin clients, nodes, and miners, can all very easily verify that said\n> action took place, and therefore accept the \"newly minted\" coins on B as\n> valid.\n> - Users client software now also knows where to look for the other coins\n> (if for some reason it needs to).\n>\n> This doesn't even need much modification to the Bitcoin protocol as most\n> of the verification is done client-side.\n>\n> It is fully decentralized, and there's no need to give our ownership of\n> our coins to miners to get scale.\n>\n> My sincere apologies if this has been brought up before (in which case, I\n> would be very grateful for a link to the proposal).\n>\n> Cheers,\n> Greg Slepak\n>\n> * This idea is similar in spirit to Interledger.\n>\n> --\n> Please do not email me anything that you are not comfortable also sharing with\n> the NSA.\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171010/25fb5d8e/attachment.html>"
            },
            {
                "author": "Tao Effect",
                "date": "2017-10-10T14:09:44",
                "message_text_only": "Hi Paul,\n\nI thought it was clear, but apparently you are getting stuck on the semantics of the word \"burn\".\n\nThe \"burning\" applies to the original coins you had.\n\nWhen you transfer them back, you get newly minted coins, equivalent to the amount you \"burned\" on the chain you're transferring from \u2014 as stated in the OP.\n\nIf you don't like the word \"burn\", pick another one.\n\n--\nPlease do not email me anything that you are not comfortable also sharing with the NSA.\n\n> On Oct 10, 2017, at 4:20 AM, Paul Sztorc <truthcoin at gmail.com <mailto:truthcoin at gmail.com>> wrote:\n> \n> Haha, no. Because you \"burned\" the coins.\n> \n> On Oct 10, 2017 1:20 AM, \"Tao Effect\" <contact at taoeffect.com <mailto:contact at taoeffect.com>> wrote:\n> Paul,\n> \n> It's a two-way peg.\n> \n> There's nothing preventing transfers back to the main chain.\n> \n> They work in the exact same manner.\n> \n> Cheers,\n> Greg\n> \n> --\n> Please do not email me anything that you are not comfortable also sharing with the NSA.\n> \n>> On Oct 9, 2017, at 6:39 PM, Paul Sztorc <truthcoin at gmail.com <mailto:truthcoin at gmail.com>> wrote:\n>> \n>> That is only a one-way peg, not a two-way.\n>> \n>> In fact, that is exactly what drivechain does, if one chooses parameters for the drivechain that make it impossible for any side-to-main transfer to succeed.\n>> \n>> One-way pegs have strong first-mover disadvantages.\n>> \n>> Paul\n>> \n>> On Oct 9, 2017 9:24 PM, \"Tao Effect via bitcoin-dev\" <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>> Dear list,\n>> \n>> In previous arguments over Drivechain (and Drivechain-like proposals) I promised that better scaling proposals \u2014 that do not sacrifice Bitcoin's security \u2014 would come along.\n>> \n>> I planned to do a detailed writeup, but have decided to just send off this email with what I have, because I'm unlikely to have time to write up a detailed proposal.\n>> \n>> The idea is very simple (and by no means novel*), and I'm sure others have mentioned either exactly it, or similar ideas (e.g. burning coins) before.\n>> \n>> This is a generic sharding protocol for all blockchains, including Bitcoin.\n>> \n>> Users simply say: \"My coins on Chain A are going to be sent to Chain B\".\n>> \n>> Then they burn the coins on Chain A, and create a minting transaction on Chain B. The details of how to ensure that coins do not get lost needs to be worked out, but I'm fairly certain the folks on this list can figure out those details.\n>> \n>> - Thin clients, nodes, and miners, can all very easily verify that said action took place, and therefore accept the \"newly minted\" coins on B as valid.\n>> - Users client software now also knows where to look for the other coins (if for some reason it needs to).\n>> \n>> This doesn't even need much modification to the Bitcoin protocol as most of the verification is done client-side.\n>> \n>> It is fully decentralized, and there's no need to give our ownership of our coins to miners to get scale.\n>> \n>> My sincere apologies if this has been brought up before (in which case, I would be very grateful for a link to the proposal).\n>> \n>> Cheers,\n>> Greg Slepak\n>> \n>> * This idea is similar in spirit to Interledger.\n>> \n>> --\n>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>> \n>> \n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>> \n>> \n> \n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171010/0b61b6ae/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171010/0b61b6ae/attachment-0001.sig>"
            },
            {
                "author": "Paul Sztorc",
                "date": "2017-10-10T15:09:21",
                "message_text_only": "I think this response speaks for itself.\n\nOn 10/10/2017 10:09 AM, Tao Effect wrote:\n> Hi Paul,\n>\n> I thought it was clear, but apparently you are getting stuck on the\n> semantics of the word \"burn\".\n>\n> The \"burning\" applies to the original coins you had.\n>\n> When you transfer them back, you get newly minted coins, equivalent to\n> the amount you \"burned\" on the chain you're transferring from \u2014 as\n> stated in the OP.\n>\n> If you don't like the word \"burn\", pick another one.\n>\n> --\n> Please do not email me anything that you are not comfortable also\n> sharing\u00a0with the NSA.\n>\n>> On Oct 10, 2017, at 4:20 AM, Paul Sztorc <truthcoin at gmail.com\n>> <mailto:truthcoin at gmail.com>> wrote:\n>>\n>> Haha, no. Because you \"burned\" the coins.\n>>\n>> On Oct 10, 2017 1:20 AM, \"Tao Effect\" <contact at taoeffect.com\n>> <mailto:contact at taoeffect.com>> wrote:\n>>\n>>     Paul,\n>>\n>>     It's a two-way peg.\n>>\n>>     There's nothing preventing transfers back to the main chain.\n>>\n>>     They work in the exact same manner.\n>>\n>>     Cheers,\n>>     Greg\n>>\n>>     --\n>>     Please do not email me anything that you are not comfortable also\n>>     sharing\u00a0with the NSA.\n>>\n>>>     On Oct 9, 2017, at 6:39 PM, Paul Sztorc <truthcoin at gmail.com\n>>>     <mailto:truthcoin at gmail.com>> wrote:\n>>>\n>>>     That is only a one-way peg, not a two-way.\n>>>\n>>>     In fact, that is exactly what drivechain does, if one chooses\n>>>     parameters for the drivechain that make it impossible for any\n>>>     side-to-main transfer to succeed.\n>>>\n>>>     One-way pegs have strong first-mover disadvantages.\n>>>\n>>>     Paul\n>>>\n>>>     On Oct 9, 2017 9:24 PM, \"Tao Effect via bitcoin-dev\"\n>>>     <bitcoin-dev at lists.linuxfoundation.org\n>>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>>\n>>>         Dear list,\n>>>\n>>>         In previous arguments over Drivechain (and Drivechain-like\n>>>         proposals) I promised that better scaling proposals \u2014 that\n>>>         do not sacrifice Bitcoin's security \u2014 would come along.\n>>>\n>>>         I planned to do a detailed writeup, but have decided to just\n>>>         send off this email with what I have, because I'm unlikely\n>>>         to have time to write up a detailed proposal.\n>>>\n>>>         The idea is very simple (and by no means novel*), and I'm\n>>>         sure others have mentioned either exactly it, or similar\n>>>         ideas (e.g. burning coins) before.\n>>>\n>>>         This is a generic sharding protocol for all blockchains,\n>>>         including Bitcoin.\n>>>\n>>>         Users simply say: \"My coins on Chain A are going to be sent\n>>>         to Chain B\".\n>>>\n>>>         Then they burn the coins on Chain A, and create a minting\n>>>         transaction on Chain B. The details of how to ensure that\n>>>         coins do not get lost needs to be worked out, but I'm fairly\n>>>         certain the folks on this list can figure out those details.\n>>>\n>>>         - Thin clients, nodes, and miners, can all very easily\n>>>         verify that said action took place, and therefore accept the\n>>>         \"newly minted\" coins on B as valid.\n>>>         - Users client software now also knows where to look for the\n>>>         other coins (if for some reason it needs to).\n>>>\n>>>         This doesn't even need much modification to the Bitcoin\n>>>         protocol as most of the verification is done client-side.\n>>>\n>>>         It is fully decentralized, and there's no need to give our\n>>>         ownership of our coins to miners to get scale.\n>>>\n>>>         My sincere apologies if this has been brought up before (in\n>>>         which case, I would be very grateful for a link to the\n>>>         proposal).\n>>>\n>>>         Cheers,\n>>>         Greg Slepak\n>>>\n>>>         * This idea is similar in spirit to Interledger.\n>>>\n>>>         --\n>>>         Please do not email me anything that you are not comfortable\n>>>         also sharing\u00a0with the NSA.\n>>>\n>>>\n>>>         _______________________________________________\n>>>         bitcoin-dev mailing list\n>>>         bitcoin-dev at lists.linuxfoundation.org\n>>>         <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>         <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>>>\n>>>\n>>\n>\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171010/0bebbbfd/attachment-0001.html>"
            },
            {
                "author": "Tao Effect",
                "date": "2017-10-10T19:25:03",
                "message_text_only": "Is that what passes for a technical argument these days? Sheesh.\n\nWhereas in Drivechain users are forced to give up their coins to a single group for whatever sidechains they interact with, the generic sharding algo lets them (1) keep their coins, (2) trust whatever group they want to trust (the miners of the various sidechains).\n\nDrivechain offers objectively worse security.\n\n--\nSent from my mobile device.\nPlease do not email me anything that you are not comfortable also sharing with the NSA.\n\n> On Oct 10, 2017, at 8:09 AM, Paul Sztorc via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> I think this response speaks for itself.\n> \n>> On 10/10/2017 10:09 AM, Tao Effect wrote:\n>> Hi Paul,\n>> \n>> I thought it was clear, but apparently you are getting stuck on the semantics of the word \"burn\".\n>> \n>> The \"burning\" applies to the original coins you had.\n>> \n>> When you transfer them back, you get newly minted coins, equivalent to the amount you \"burned\" on the chain you're transferring from \u2015 as stated in the OP.\n>> \n>> If you don't like the word \"burn\", pick another one.\n>> \n>> --\n>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>> \n>>> On Oct 10, 2017, at 4:20 AM, Paul Sztorc <truthcoin at gmail.com> wrote:\n>>> \n>>> Haha, no. Because you \"burned\" the coins.\n>>> \n>>>> On Oct 10, 2017 1:20 AM, \"Tao Effect\" <contact at taoeffect.com> wrote:\n>>>> Paul,\n>>>> \n>>>> It's a two-way peg.\n>>>> \n>>>> There's nothing preventing transfers back to the main chain.\n>>>> \n>>>> They work in the exact same manner.\n>>>> \n>>>> Cheers,\n>>>> Greg\n>>>> \n>>>> --\n>>>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>>>> \n>>>>> On Oct 9, 2017, at 6:39 PM, Paul Sztorc <truthcoin at gmail.com> wrote:\n>>>>> \n>>>>> That is only a one-way peg, not a two-way.\n>>>>> \n>>>>> In fact, that is exactly what drivechain does, if one chooses parameters for the drivechain that make it impossible for any side-to-main transfer to succeed.\n>>>>> \n>>>>> One-way pegs have strong first-mover disadvantages.\n>>>>> \n>>>>> Paul\n>>>>> \n>>>>> On Oct 9, 2017 9:24 PM, \"Tao Effect via bitcoin-dev\" <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>> Dear list,\n>>>>> \n>>>>> In previous arguments over Drivechain (and Drivechain-like proposals) I promised that better scaling proposals \u2015 that do not sacrifice Bitcoin's security \u2015 would come along.\n>>>>> \n>>>>> I planned to do a detailed writeup, but have decided to just send off this email with what I have, because I'm unlikely to have time to write up a detailed proposal.\n>>>>> \n>>>>> The idea is very simple (and by no means novel*), and I'm sure others have mentioned either exactly it, or similar ideas (e.g. burning coins) before.\n>>>>> \n>>>>> This is a generic sharding protocol for all blockchains, including Bitcoin.\n>>>>> \n>>>>> Users simply say: \"My coins on Chain A are going to be sent to Chain B\".\n>>>>> \n>>>>> Then they burn the coins on Chain A, and create a minting transaction on Chain B. The details of how to ensure that coins do not get lost needs to be                                             worked out, but I'm fairly certain the folks on this list can figure out those details.\n>>>>> \n>>>>> - Thin clients, nodes, and miners, can all very easily verify that said action took place, and therefore accept the \"newly minted\" coins on B as valid.\n>>>>> - Users client software now also knows where to look for the other coins (if for some reason it                                             needs to).\n>>>>> \n>>>>> This doesn't even need much modification to the Bitcoin protocol as most of the verification is done client-side.\n>>>>> \n>>>>> It is fully decentralized, and there's no need to give our ownership of our coins to miners to get scale.\n>>>>> \n>>>>> My sincere apologies if this has been brought up before (in which case, I would be very grateful for a link to the proposal).\n>>>>> \n>>>>> Cheers,\n>>>>> Greg Slepak\n>>>>> \n>>>>> * This idea is similar in spirit to Interledger.\n>>>>> \n>>>>> --\n>>>>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>>>>> \n>>>>> \n>>>>> _______________________________________________\n>>>>> bitcoin-dev mailing list\n>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>> \n>>>>> \n>>>> \n>> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171010/a217ed4f/attachment-0001.html>"
            },
            {
                "author": "CryptAxe",
                "date": "2017-10-10T19:50:13",
                "message_text_only": "Your method would change the number of Bitcoins in existence. Why?\n\nOn Oct 10, 2017 12:47 PM, \"Tao Effect via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Is that what passes for a technical argument these days? Sheesh.\n>\n> Whereas in Drivechain users are forced to give up their coins to a single\n> group for whatever sidechains they interact with, the generic sharding algo\n> lets them (1) keep their coins, (2) trust whatever group they want to trust\n> (the miners of the various sidechains).\n>\n> Drivechain offers objectively worse security.\n>\n> --\n> Sent from my mobile device.\n> Please do not email me anything that you are not comfortable also sharing\n> with the NSA.\n>\n> On Oct 10, 2017, at 8:09 AM, Paul Sztorc via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> I think this response speaks for itself.\n>\n> On 10/10/2017 10:09 AM, Tao Effect wrote:\n>\n> Hi Paul,\n>\n> I thought it was clear, but apparently you are getting stuck on the\n> semantics of the word \"burn\".\n>\n> The \"burning\" applies to the original coins you had.\n>\n> When you transfer them back, you get newly minted coins, equivalent to the\n> amount you \"burned\" on the chain you're transferring from \u2014 as stated in\n> the OP.\n>\n> If you don't like the word \"burn\", pick another one.\n>\n> --\n> Please do not email me anything that you are not comfortable also sharing with\n> the NSA.\n>\n> On Oct 10, 2017, at 4:20 AM, Paul Sztorc <truthcoin at gmail.com> wrote:\n>\n> Haha, no. Because you \"burned\" the coins.\n>\n> On Oct 10, 2017 1:20 AM, \"Tao Effect\" <contact at taoeffect.com> wrote:\n>\n>> Paul,\n>>\n>> It's a two-way peg.\n>>\n>> There's nothing preventing transfers back to the main chain.\n>>\n>> They work in the exact same manner.\n>>\n>> Cheers,\n>> Greg\n>>\n>> --\n>> Please do not email me anything that you are not comfortable also sharing with\n>> the NSA.\n>>\n>> On Oct 9, 2017, at 6:39 PM, Paul Sztorc <truthcoin at gmail.com> wrote:\n>>\n>> That is only a one-way peg, not a two-way.\n>>\n>> In fact, that is exactly what drivechain does, if one chooses parameters\n>> for the drivechain that make it impossible for any side-to-main transfer to\n>> succeed.\n>>\n>> One-way pegs have strong first-mover disadvantages.\n>>\n>> Paul\n>>\n>> On Oct 9, 2017 9:24 PM, \"Tao Effect via bitcoin-dev\" <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> Dear list,\n>>\n>> In previous arguments over Drivechain (and Drivechain-like proposals) I\n>> promised that better scaling proposals \u2014 that do not sacrifice Bitcoin's\n>> security \u2014 would come along.\n>>\n>> I planned to do a detailed writeup, but have decided to just send off\n>> this email with what I have, because I'm unlikely to have time to write up\n>> a detailed proposal.\n>>\n>> The idea is very simple (and by no means novel*), and I'm sure others\n>> have mentioned either exactly it, or similar ideas (e.g. burning coins)\n>> before.\n>>\n>> This is a generic sharding protocol for all blockchains, including\n>> Bitcoin.\n>>\n>> Users simply say: \"My coins on Chain A are going to be sent to Chain B\".\n>>\n>> Then they burn the coins on Chain A, and create a minting transaction on\n>> Chain B. The details of how to ensure that coins do not get lost needs to\n>> be worked out, but I'm fairly certain the folks on this list can figure out\n>> those details.\n>>\n>> - Thin clients, nodes, and miners, can all very easily verify that said\n>> action took place, and therefore accept the \"newly minted\" coins on B as\n>> valid.\n>> - Users client software now also knows where to look for the other coins\n>> (if for some reason it needs to).\n>>\n>> This doesn't even need much modification to the Bitcoin protocol as most\n>> of the verification is done client-side.\n>>\n>> It is fully decentralized, and there's no need to give our ownership of\n>> our coins to miners to get scale.\n>>\n>> My sincere apologies if this has been brought up before (in which case, I\n>> would be very grateful for a link to the proposal).\n>>\n>> Cheers,\n>> Greg Slepak\n>>\n>> * This idea is similar in spirit to Interledger.\n>>\n>> --\n>> Please do not email me anything that you are not comfortable also sharing with\n>> the NSA.\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>>\n>>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171010/de8cb97c/attachment.html>"
            },
            {
                "author": "Tao Effect",
                "date": "2017-10-10T20:13:20",
                "message_text_only": "It would not change the number of Bitcoins in existence.\n\n--\nSent from my mobile device.\nPlease do not email me anything that you are not comfortable also sharing with the NSA.\n\n> On Oct 10, 2017, at 12:50 PM, CryptAxe <cryptaxe at gmail.com> wrote:\n> \n> Your method would change the number of Bitcoins in existence. Why? \n> \n>> On Oct 10, 2017 12:47 PM, \"Tao Effect via bitcoin-dev\" <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> Is that what passes for a technical argument these days? Sheesh.\n>> \n>> Whereas in Drivechain users are forced to give up their coins to a single group for whatever sidechains they interact with, the generic sharding algo lets them (1) keep their coins, (2) trust whatever group they want to trust (the miners of the various sidechains).\n>> \n>> Drivechain offers objectively worse security.\n>> \n>> --\n>> Sent from my mobile device.\n>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>> \n>>> On Oct 10, 2017, at 8:09 AM, Paul Sztorc via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> \n>>> I think this response speaks for itself.\n>>> \n>>>> On 10/10/2017 10:09 AM, Tao Effect wrote:\n>>>> Hi Paul,\n>>>> \n>>>> I thought it was clear, but apparently you are getting stuck on the semantics of the word \"burn\".\n>>>> \n>>>> The \"burning\" applies to the original coins you had.\n>>>> \n>>>> When you transfer them back, you get newly minted coins, equivalent to the amount you \"burned\" on the chain you're transferring from \u2015 as stated in the OP.\n>>>> \n>>>> If you don't like the word \"burn\", pick another one.\n>>>> \n>>>> --\n>>>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>>>> \n>>>>> On Oct 10, 2017, at 4:20 AM, Paul Sztorc <truthcoin at gmail.com> wrote:\n>>>>> \n>>>>> Haha, no. Because you \"burned\" the coins.\n>>>>> \n>>>>>> On Oct 10, 2017 1:20 AM, \"Tao Effect\" <contact at taoeffect.com> wrote:\n>>>>>> Paul,\n>>>>>> \n>>>>>> It's a two-way peg.\n>>>>>> \n>>>>>> There's nothing preventing transfers back to the main chain.\n>>>>>> \n>>>>>> They work in the exact same manner.\n>>>>>> \n>>>>>> Cheers,\n>>>>>> Greg\n>>>>>> \n>>>>>> --\n>>>>>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>>>>>> \n>>>>>>> On Oct 9, 2017, at 6:39 PM, Paul Sztorc <truthcoin at gmail.com> wrote:\n>>>>>>> \n>>>>>>> That is only a one-way peg, not a two-way.\n>>>>>>> \n>>>>>>> In fact, that is exactly what drivechain does, if one chooses parameters for the drivechain that make it impossible for any side-to-main transfer to succeed.\n>>>>>>> \n>>>>>>> One-way pegs have strong first-mover disadvantages.\n>>>>>>> \n>>>>>>> Paul\n>>>>>>> \n>>>>>>> On Oct 9, 2017 9:24 PM, \"Tao Effect via bitcoin-dev\" <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>>>> Dear list,\n>>>>>>> \n>>>>>>> In previous arguments over Drivechain (and Drivechain-like                                             proposals) I promised that better scaling proposals \u2015 that do not sacrifice Bitcoin's security \u2015 would come along.\n>>>>>>> \n>>>>>>> I planned to do a detailed writeup, but have decided to just send off this email with what I have, because I'm unlikely to have time to write up a detailed proposal.\n>>>>>>> \n>>>>>>> The idea is very simple (and by no means novel*), and I'm sure others have mentioned either exactly it, or similar ideas (e.g. burning coins) before.\n>>>>>>> \n>>>>>>> This is a generic sharding protocol for all blockchains, including Bitcoin.\n>>>>>>> \n>>>>>>> Users simply say: \"My coins on Chain A are going to be sent to                                             Chain B\".\n>>>>>>> \n>>>>>>> Then they burn the coins on Chain A, and create a minting transaction on Chain B. The details of how to ensure that coins do not get lost needs to be worked out, but I'm fairly certain the folks on this list can figure out those details.\n>>>>>>> \n>>>>>>> - Thin clients, nodes, and miners, can all very easily verify that said action took place, and therefore accept the \"newly minted\" coins on B as valid.\n>>>>>>> - Users client software now also knows where to look for the other coins (if for some reason it needs to).\n>>>>>>> \n>>>>>>> This doesn't even need much modification to the Bitcoin protocol as most of the verification is done client-side.\n>>>>>>> \n>>>>>>> It is fully decentralized, and there's no need to give our ownership of our coins to miners to get scale.\n>>>>>>> \n>>>>>>> My sincere apologies if this has been brought up before (in which case, I would be very grateful for a link to the proposal).\n>>>>>>> \n>>>>>>> Cheers,\n>>>>>>> Greg Slepak\n>>>>>>> \n>>>>>>> * This idea is similar in spirit to Interledger.\n>>>>>>> \n>>>>>>> --\n>>>>>>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>>>>>>> \n>>>>>>> \n>>>>>>> _______________________________________________\n>>>>>>> bitcoin-dev mailing list\n>>>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>>> \n>>>>>>> \n>>>>>> \n>>>> \n>>> \n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> \n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> \n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171010/f093139f/attachment-0001.html>"
            },
            {
                "author": "Lucas Clemente Vella",
                "date": "2017-10-10T20:23:43",
                "message_text_only": "2017-10-10 11:09 GMT-03:00 Tao Effect via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org>:\n\n> When you transfer them back, you get newly minted coins, equivalent to the\n> amount you \"burned\" on the chain you're transferring from \u2014 as stated in\n> the OP.\n>\n\nIf you have to change Bitcoin to recognize a transfer from the sidechain\nback into Bitcoin, you kill the purpose of the sidechain. You could as well\njust change the Bitcoin to implement whatever desirable features the\nsidechain would have. The whole idea of sidechains is to keep Bicoin\nunchangend, and allow for the voluntary transfer of tokens out of Bitcoin\nto the sidechain of your choosing.\n\n\n-- \nLucas Clemente Vella\nlvella at gmail.com\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171010/3979cda4/attachment-0001.html>"
            },
            {
                "author": "Paul Sztorc",
                "date": "2017-10-10T20:23:45",
                "message_text_only": "What if two sidechains are implemented at once? What if people get excited\nabout one sidechain today, but a second even-better one is published the\nvery next week? What if the original mainchain decides to integrate the\nfeatures of the sidechain that you just one-way pegged to?\n\nIn these cases, the user looses money, whereas in the two-way peg they\nwould not lose a thing.\n\nWhile the one-way peg is interesting, it really doesn't compare.\n\nPaul\n\nOn Oct 10, 2017 4:19 PM, \"Lucas Clemente Vella\" <lvella at gmail.com> wrote:\n\n2017-10-09 22:39 GMT-03:00 Paul Sztorc via bitcoin-dev <bitcoin-dev at lists.\nlinuxfoundation.org>:\n\n> That is only a one-way peg, not a two-way.\n>\n> In fact, that is exactly what drivechain does, if one chooses parameters\n> for the drivechain that make it impossible for any side-to-main transfer to\n> succeed.\n>\n> One-way pegs have strong first-mover disadvantages.\n>\n\nI understand the first-mover disadvantages, but I keep thinking that if the\nnew chain is Pareto optimal, i.e. is in all aspects at least good as the\noriginal chain, but in some so much better to justify the change, the\ninitial resistance is an unstable equilibrium. Like a herd of buffaloes\nattacking a lion: the first buffalo to attack is in awful disadvantage, but\nif a critical mass of the herd follows, the movement succeeds beyond\nturning back, and every buffalo benefited, both those who attacked the lion\nand those that didn't (because the lion was chased away or killed).\n\n-- \nLucas Clemente Vella\nlvella at gmail.com\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171010/a29725fb/attachment.html>"
            },
            {
                "author": "Tao Effect",
                "date": "2017-10-10T20:43:17",
                "message_text_only": "What?\n\nThat is not correct.\n\nThere is a fixed amount of Bitcoin, as I said.\n\nThe only difference is what chain it is on.\n\nIt is precisely because there is a fixed amount that when you burn-to-withdraw you mint on another chain.\n\nI will not respond to any more emails unless they\u2019re from core developers. Gotta run.\n\n--\nSent from my mobile device.\nPlease do not email me anything that you are not comfortable also sharing with the NSA.\n\n> On Oct 10, 2017, at 1:23 PM, James Hudon <jameshudon at gmail.com> wrote:\n> \n> You're asking for newly minted bitcoin to go to you but you burned the bitcoin used in the peg. You're effectively losing your money and then stealing from the miners to gain it back. The miners had to issue your amount of bitcoin 2 times (once for your original bitcoin, again to make you whole). Why would they agree to this?\n> --\n> hudon\n> \n>> On Oct 10, 2017, at 13:13, Tao Effect via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> \n>> It would not change the number of Bitcoins in existence.\n>> \n>> --\n>> Sent from my mobile device.\n>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>> \n>>> On Oct 10, 2017, at 12:50 PM, CryptAxe <cryptaxe at gmail.com> wrote:\n>>> \n>>> Your method would change the number of Bitcoins in existence. Why? \n>>> \n>>> On Oct 10, 2017 12:47 PM, \"Tao Effect via bitcoin-dev\" <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> Is that what passes for a technical argument these days? Sheesh.\n>>> \n>>> Whereas in Drivechain users are forced to give up their coins to a single group for whatever sidechains they interact with, the generic sharding algo lets them (1) keep their coins, (2) trust whatever group they want to trust (the miners of the various sidechains).\n>>> \n>>> Drivechain offers objectively worse security.\n>>> \n>>> --\n>>> Sent from my mobile device.\n>>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>>> \n>>>> On Oct 10, 2017, at 8:09 AM, Paul Sztorc via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>> \n>>>> I think this response speaks for itself.\n>>>> \n>>>>> On 10/10/2017 10:09 AM, Tao Effect wrote:\n>>>>> Hi Paul,\n>>>>> \n>>>>> I thought it was clear, but apparently you are getting stuck on the semantics of the word \"burn\".\n>>>>> \n>>>>> The \"burning\" applies to the original coins you had.\n>>>>> \n>>>>> When you transfer them back, you get newly minted coins, equivalent to the amount you \"burned\" on the chain you're transferring from \u2015 as stated in the OP.\n>>>>> \n>>>>> If you don't like the word \"burn\", pick another one.\n>>>>> \n>>>>> --\n>>>>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>>>>> \n>>>>>> On Oct 10, 2017, at 4:20 AM, Paul Sztorc <truthcoin at gmail.com> wrote:\n>>>>>> \n>>>>>> Haha, no. Because you \"burned\" the coins.\n>>>>>> \n>>>>>> On Oct 10, 2017 1:20 AM, \"Tao Effect\" <contact at taoeffect.com> wrote:\n>>>>>> Paul,\n>>>>>> \n>>>>>> It's a two-way peg.\n>>>>>> \n>>>>>> There's nothing preventing transfers back to the main chain.\n>>>>>> \n>>>>>> They work in the exact same manner.\n>>>>>> \n>>>>>> Cheers,\n>>>>>> Greg\n>>>>>> \n>>>>>> --\n>>>>>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>>>>>> \n>>>>>>> On Oct 9, 2017, at 6:39 PM, Paul Sztorc <truthcoin at gmail.com> wrote:\n>>>>>>> \n>>>>>>> That is only a one-way peg, not a two-way.\n>>>>>>> \n>>>>>>> In fact, that is exactly what drivechain does, if one chooses parameters for the drivechain that make it impossible for any side-to-main transfer to succeed.\n>>>>>>> \n>>>>>>> One-way pegs have strong first-mover disadvantages.\n>>>>>>> \n>>>>>>> Paul\n>>>>>>> \n>>>>>>> On Oct 9, 2017 9:24 PM, \"Tao Effect via bitcoin-dev\" <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>>>> Dear list,\n>>>>>>> \n>>>>>>> In previous arguments over Drivechain (and Drivechain-like proposals) I promised that better scaling proposals \u2015 that do not sacrifice Bitcoin's security \u2015 would come along.\n>>>>>>> \n>>>>>>> I planned to do a detailed writeup, but have decided to just send off this email with what I have, because I'm unlikely to have time to write up a detailed proposal.\n>>>>>>> \n>>>>>>> The idea is very simple (and by no means novel*), and I'm sure others have mentioned either exactly it, or similar ideas (e.g. burning coins) before.\n>>>>>>> \n>>>>>>> This is a generic sharding protocol for all blockchains, including Bitcoin.\n>>>>>>> \n>>>>>>> Users simply say: \"My coins on Chain A are going to be sent to Chain B\".\n>>>>>>> \n>>>>>>> Then they burn the coins on Chain A, and create a minting transaction on Chain B. The details of how to ensure that coins do not get lost needs to be worked out, but I'm fairly certain the folks on this list can figure out those details.\n>>>>>>> \n>>>>>>> - Thin clients, nodes, and miners, can all very easily verify that said action took place, and therefore accept the \"newly minted\" coins on B as valid.\n>>>>>>> - Users client software now also knows where to look for the other coins (if for some reason it needs to).\n>>>>>>> \n>>>>>>> This doesn't even need much modification to the Bitcoin protocol as most of the verification is done client-side.\n>>>>>>> \n>>>>>>> It is fully decentralized, and there's no need to give our ownership of our coins to miners to get scale.\n>>>>>>> \n>>>>>>> My sincere apologies if this has been brought up before (in which case, I would be very grateful for a link to the proposal).\n>>>>>>> \n>>>>>>> Cheers,\n>>>>>>> Greg Slepak\n>>>>>>> \n>>>>>>> * This idea is similar in spirit to Interledger.\n>>>>>>> \n>>>>>>> --\n>>>>>>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>>>>>>> \n>>>>>>> \n>>>>>>> _______________________________________________\n>>>>>>> bitcoin-dev mailing list\n>>>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>>> \n>>>>>>> \n>>>>>> \n>>>>> \n>>>> \n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>> \n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>> \n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "CryptAxe",
                "date": "2017-10-10T20:49:20",
                "message_text_only": "You could technically call myself and Chris 'core developers'. You don't\nget to have a fixed rate of Bitcoin and a second way to mint coins at the\nsame time.\n\nOn Oct 10, 2017 1:46 PM, \"Tao Effect via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> What?\n>\n> That is not correct.\n>\n> There is a fixed amount of Bitcoin, as I said.\n>\n> The only difference is what chain it is on.\n>\n> It is precisely because there is a fixed amount that when you\n> burn-to-withdraw you mint on another chain.\n>\n> I will not respond to any more emails unless they\u2019re from core developers.\n> Gotta run.\n>\n> --\n> Sent from my mobile device.\n> Please do not email me anything that you are not comfortable also sharing\n> with the NSA.\n>\n> > On Oct 10, 2017, at 1:23 PM, James Hudon <jameshudon at gmail.com> wrote:\n> >\n> > You're asking for newly minted bitcoin to go to you but you burned the\n> bitcoin used in the peg. You're effectively losing your money and then\n> stealing from the miners to gain it back. The miners had to issue your\n> amount of bitcoin 2 times (once for your original bitcoin, again to make\n> you whole). Why would they agree to this?\n> > --\n> > hudon\n> >\n> >> On Oct 10, 2017, at 13:13, Tao Effect via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>\n> >> It would not change the number of Bitcoins in existence.\n> >>\n> >> --\n> >> Sent from my mobile device.\n> >> Please do not email me anything that you are not comfortable also\n> sharing with the NSA.\n> >>\n> >>> On Oct 10, 2017, at 12:50 PM, CryptAxe <cryptaxe at gmail.com> wrote:\n> >>>\n> >>> Your method would change the number of Bitcoins in existence. Why?\n> >>>\n> >>> On Oct 10, 2017 12:47 PM, \"Tao Effect via bitcoin-dev\" <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>> Is that what passes for a technical argument these days? Sheesh.\n> >>>\n> >>> Whereas in Drivechain users are forced to give up their coins to a\n> single group for whatever sidechains they interact with, the generic\n> sharding algo lets them (1) keep their coins, (2) trust whatever group they\n> want to trust (the miners of the various sidechains).\n> >>>\n> >>> Drivechain offers objectively worse security.\n> >>>\n> >>> --\n> >>> Sent from my mobile device.\n> >>> Please do not email me anything that you are not comfortable also\n> sharing with the NSA.\n> >>>\n> >>>> On Oct 10, 2017, at 8:09 AM, Paul Sztorc via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>>>\n> >>>> I think this response speaks for itself.\n> >>>>\n> >>>>> On 10/10/2017 10:09 AM, Tao Effect wrote:\n> >>>>> Hi Paul,\n> >>>>>\n> >>>>> I thought it was clear, but apparently you are getting stuck on the\n> semantics of the word \"burn\".\n> >>>>>\n> >>>>> The \"burning\" applies to the original coins you had.\n> >>>>>\n> >>>>> When you transfer them back, you get newly minted coins, equivalent\n> to the amount you \"burned\" on the chain you're transferring from \u2015 as\n> stated in the OP.\n> >>>>>\n> >>>>> If you don't like the word \"burn\", pick another one.\n> >>>>>\n> >>>>> --\n> >>>>> Please do not email me anything that you are not comfortable also\n> sharing with the NSA.\n> >>>>>\n> >>>>>> On Oct 10, 2017, at 4:20 AM, Paul Sztorc <truthcoin at gmail.com>\n> wrote:\n> >>>>>>\n> >>>>>> Haha, no. Because you \"burned\" the coins.\n> >>>>>>\n> >>>>>> On Oct 10, 2017 1:20 AM, \"Tao Effect\" <contact at taoeffect.com>\n> wrote:\n> >>>>>> Paul,\n> >>>>>>\n> >>>>>> It's a two-way peg.\n> >>>>>>\n> >>>>>> There's nothing preventing transfers back to the main chain.\n> >>>>>>\n> >>>>>> They work in the exact same manner.\n> >>>>>>\n> >>>>>> Cheers,\n> >>>>>> Greg\n> >>>>>>\n> >>>>>> --\n> >>>>>> Please do not email me anything that you are not comfortable also\n> sharing with the NSA.\n> >>>>>>\n> >>>>>>> On Oct 9, 2017, at 6:39 PM, Paul Sztorc <truthcoin at gmail.com>\n> wrote:\n> >>>>>>>\n> >>>>>>> That is only a one-way peg, not a two-way.\n> >>>>>>>\n> >>>>>>> In fact, that is exactly what drivechain does, if one chooses\n> parameters for the drivechain that make it impossible for any side-to-main\n> transfer to succeed.\n> >>>>>>>\n> >>>>>>> One-way pegs have strong first-mover disadvantages.\n> >>>>>>>\n> >>>>>>> Paul\n> >>>>>>>\n> >>>>>>> On Oct 9, 2017 9:24 PM, \"Tao Effect via bitcoin-dev\" <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>>>>>> Dear list,\n> >>>>>>>\n> >>>>>>> In previous arguments over Drivechain (and Drivechain-like\n> proposals) I promised that better scaling proposals \u2015 that do not sacrifice\n> Bitcoin's security \u2015 would come along.\n> >>>>>>>\n> >>>>>>> I planned to do a detailed writeup, but have decided to just send\n> off this email with what I have, because I'm unlikely to have time to write\n> up a detailed proposal.\n> >>>>>>>\n> >>>>>>> The idea is very simple (and by no means novel*), and I'm sure\n> others have mentioned either exactly it, or similar ideas (e.g. burning\n> coins) before.\n> >>>>>>>\n> >>>>>>> This is a generic sharding protocol for all blockchains, including\n> Bitcoin.\n> >>>>>>>\n> >>>>>>> Users simply say: \"My coins on Chain A are going to be sent to\n> Chain B\".\n> >>>>>>>\n> >>>>>>> Then they burn the coins on Chain A, and create a minting\n> transaction on Chain B. The details of how to ensure that coins do not get\n> lost needs to be worked out, but I'm fairly certain the folks on this list\n> can figure out those details.\n> >>>>>>>\n> >>>>>>> - Thin clients, nodes, and miners, can all very easily verify that\n> said action took place, and therefore accept the \"newly minted\" coins on B\n> as valid.\n> >>>>>>> - Users client software now also knows where to look for the other\n> coins (if for some reason it needs to).\n> >>>>>>>\n> >>>>>>> This doesn't even need much modification to the Bitcoin protocol\n> as most of the verification is done client-side.\n> >>>>>>>\n> >>>>>>> It is fully decentralized, and there's no need to give our\n> ownership of our coins to miners to get scale.\n> >>>>>>>\n> >>>>>>> My sincere apologies if this has been brought up before (in which\n> case, I would be very grateful for a link to the proposal).\n> >>>>>>>\n> >>>>>>> Cheers,\n> >>>>>>> Greg Slepak\n> >>>>>>>\n> >>>>>>> * This idea is similar in spirit to Interledger.\n> >>>>>>>\n> >>>>>>> --\n> >>>>>>> Please do not email me anything that you are not comfortable also\n> sharing with the NSA.\n> >>>>>>>\n> >>>>>>>\n> >>>>>>> _______________________________________________\n> >>>>>>> bitcoin-dev mailing list\n> >>>>>>> bitcoin-dev at lists.linuxfoundation.org\n> >>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >>>>>>>\n> >>>>>>>\n> >>>>>>\n> >>>>>\n> >>>>\n> >>>> _______________________________________________\n> >>>> bitcoin-dev mailing list\n> >>>> bitcoin-dev at lists.linuxfoundation.org\n> >>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >>>\n> >>> _______________________________________________\n> >>> bitcoin-dev mailing list\n> >>> bitcoin-dev at lists.linuxfoundation.org\n> >>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >>>\n> >> _______________________________________________\n> >> bitcoin-dev mailing list\n> >> bitcoin-dev at lists.linuxfoundation.org\n> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171010/2693944e/attachment-0001.html>"
            },
            {
                "author": "James Hudon",
                "date": "2017-10-10T20:57:03",
                "message_text_only": "You're asking for newly minted bitcoin to go to you but you burned the bitcoin used in the peg. You're effectively losing your money and then stealing from the miners to gain it back. The miners had to issue your amount of bitcoin 2 times (once for your original bitcoin, again to make you whole). Why would they agree to this?\n--\nhudon\n\n> On Oct 10, 2017, at 13:43, Tao Effect via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> What?\n> \n> That is not correct.\n> \n> There is a fixed amount of Bitcoin, as I said.\n> \n> The only difference is what chain it is on.\n> \n> It is precisely because there is a fixed amount that when you burn-to-withdraw you mint on another chain.\n> \n> I will not respond to any more emails unless they\u2019re from core developers. Gotta run.\n> \n> --\n> Sent from my mobile device.\n> Please do not email me anything that you are not comfortable also sharing with the NSA.\n> \n>> On Oct 10, 2017, at 1:23 PM, James Hudon <jameshudon at gmail.com> wrote:\n>> \n>> You're asking for newly minted bitcoin to go to you but you burned the bitcoin used in the peg. You're effectively losing your money and then stealing from the miners to gain it back. The miners had to issue your amount of bitcoin 2 times (once for your original bitcoin, again to make you whole). Why would they agree to this?\n>> --\n>> hudon\n>> \n>>> On Oct 10, 2017, at 13:13, Tao Effect via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> \n>>> It would not change the number of Bitcoins in existence.\n>>> \n>>> --\n>>> Sent from my mobile device.\n>>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>>> \n>>>> On Oct 10, 2017, at 12:50 PM, CryptAxe <cryptaxe at gmail.com> wrote:\n>>>> \n>>>> Your method would change the number of Bitcoins in existence. Why? \n>>>> \n>>>> On Oct 10, 2017 12:47 PM, \"Tao Effect via bitcoin-dev\" <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>> Is that what passes for a technical argument these days? Sheesh.\n>>>> \n>>>> Whereas in Drivechain users are forced to give up their coins to a single group for whatever sidechains they interact with, the generic sharding algo lets them (1) keep their coins, (2) trust whatever group they want to trust (the miners of the various sidechains).\n>>>> \n>>>> Drivechain offers objectively worse security.\n>>>> \n>>>> --\n>>>> Sent from my mobile device.\n>>>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>>>> \n>>>>> On Oct 10, 2017, at 8:09 AM, Paul Sztorc via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>> \n>>>>> I think this response speaks for itself.\n>>>>> \n>>>>>> On 10/10/2017 10:09 AM, Tao Effect wrote:\n>>>>>> Hi Paul,\n>>>>>> \n>>>>>> I thought it was clear, but apparently you are getting stuck on the semantics of the word \"burn\".\n>>>>>> \n>>>>>> The \"burning\" applies to the original coins you had.\n>>>>>> \n>>>>>> When you transfer them back, you get newly minted coins, equivalent to the amount you \"burned\" on the chain you're transferring from \u2015 as stated in the OP.\n>>>>>> \n>>>>>> If you don't like the word \"burn\", pick another one.\n>>>>>> \n>>>>>> --\n>>>>>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>>>>>> \n>>>>>>> On Oct 10, 2017, at 4:20 AM, Paul Sztorc <truthcoin at gmail.com> wrote:\n>>>>>>> \n>>>>>>> Haha, no. Because you \"burned\" the coins.\n>>>>>>> \n>>>>>>> On Oct 10, 2017 1:20 AM, \"Tao Effect\" <contact at taoeffect.com> wrote:\n>>>>>>> Paul,\n>>>>>>> \n>>>>>>> It's a two-way peg.\n>>>>>>> \n>>>>>>> There's nothing preventing transfers back to the main chain.\n>>>>>>> \n>>>>>>> They work in the exact same manner.\n>>>>>>> \n>>>>>>> Cheers,\n>>>>>>> Greg\n>>>>>>> \n>>>>>>> --\n>>>>>>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>>>>>>> \n>>>>>>>> On Oct 9, 2017, at 6:39 PM, Paul Sztorc <truthcoin at gmail.com> wrote:\n>>>>>>>> \n>>>>>>>> That is only a one-way peg, not a two-way.\n>>>>>>>> \n>>>>>>>> In fact, that is exactly what drivechain does, if one chooses parameters for the drivechain that make it impossible for any side-to-main transfer to succeed.\n>>>>>>>> \n>>>>>>>> One-way pegs have strong first-mover disadvantages.\n>>>>>>>> \n>>>>>>>> Paul\n>>>>>>>> \n>>>>>>>> On Oct 9, 2017 9:24 PM, \"Tao Effect via bitcoin-dev\" <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>>>>> Dear list,\n>>>>>>>> \n>>>>>>>> In previous arguments over Drivechain (and Drivechain-like proposals) I promised that better scaling proposals \u2015 that do not sacrifice Bitcoin's security \u2015 would come along.\n>>>>>>>> \n>>>>>>>> I planned to do a detailed writeup, but have decided to just send off this email with what I have, because I'm unlikely to have time to write up a detailed proposal.\n>>>>>>>> \n>>>>>>>> The idea is very simple (and by no means novel*), and I'm sure others have mentioned either exactly it, or similar ideas (e.g. burning coins) before.\n>>>>>>>> \n>>>>>>>> This is a generic sharding protocol for all blockchains, including Bitcoin.\n>>>>>>>> \n>>>>>>>> Users simply say: \"My coins on Chain A are going to be sent to Chain B\".\n>>>>>>>> \n>>>>>>>> Then they burn the coins on Chain A, and create a minting transaction on Chain B. The details of how to ensure that coins do not get lost needs to be worked out, but I'm fairly certain the folks on this list can figure out those details.\n>>>>>>>> \n>>>>>>>> - Thin clients, nodes, and miners, can all very easily verify that said action took place, and therefore accept the \"newly minted\" coins on B as valid.\n>>>>>>>> - Users client software now also knows where to look for the other coins (if for some reason it needs to).\n>>>>>>>> \n>>>>>>>> This doesn't even need much modification to the Bitcoin protocol as most of the verification is done client-side.\n>>>>>>>> \n>>>>>>>> It is fully decentralized, and there's no need to give our ownership of our coins to miners to get scale.\n>>>>>>>> \n>>>>>>>> My sincere apologies if this has been brought up before (in which case, I would be very grateful for a link to the proposal).\n>>>>>>>> \n>>>>>>>> Cheers,\n>>>>>>>> Greg Slepak\n>>>>>>>> \n>>>>>>>> * This idea is similar in spirit to Interledger.\n>>>>>>>> \n>>>>>>>> --\n>>>>>>>> Please do not email me anything that you are not comfortable also sharing with the NSA.\n>>>>>>>> \n>>>>>>>> \n>>>>>>>> _______________________________________________\n>>>>>>>> bitcoin-dev mailing list\n>>>>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>>>> \n>>>>>>>> \n>>>>>>> \n>>>>>> \n>>>>> \n>>>>> _______________________________________________\n>>>>> bitcoin-dev mailing list\n>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>> \n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>> \n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Ben Kloester",
                "date": "2017-10-11T02:04:01",
                "message_text_only": "I don't get it. At the moment, the number of Bitcoin is fixed (at 21\nmillion) by the geometric decay of the block reward.\n\nAdding any other means of creating coins besides the existing block reward,\nor altering the block reward schedule, is extremely likely to be seen as\nmessing with fixed supply. And not adding another method to create coins\nwouldn't work - because then redemptions would have to come out of miner's\nblock reward, which I don't imagine they're going to share just because you\nask.\n\nThe only way you might convince users that adding a second way to mint\ncoins is not messing with fixed supply, is if there is some kind of proof\nthat the number of coins being minted is accounted for by past burnt coins.\nWe could call this 'regeneration'. But then you also need a way to prevent\ndouble-regeneration, in which the same burnt coins are used as proof twice.\n\nAnd you would also need per-sidechain accounting, so that you can't just\nregenerate burnt coins that were originally burnt for sidechain A when all\nyou have is coins on sidechain B. But where to put all this logic? Building\na system that enforces the accounting for sidechains into Bitcoin, as Lucas\npointed out, is not much different to just building the sidechain itself\ndirectly into Bitcoin.\n\nAnd if you did assemble all that, what you have anyway is a two way peg,\nwhich I suspect will be isomorphic to the very sidechain proposals you seem\nto be criticising/attempting to do better than.\n\n\n\n*Ben Kloester*\n\nOn 11 October 2017 at 07:43, Tao Effect via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> What?\n>\n> That is not correct.\n>\n> There is a fixed amount of Bitcoin, as I said.\n>\n> The only difference is what chain it is on.\n>\n> It is precisely because there is a fixed amount that when you\n> burn-to-withdraw you mint on another chain.\n>\n> I will not respond to any more emails unless they\u2019re from core developers.\n> Gotta run.\n>\n> --\n> Sent from my mobile device.\n> Please do not email me anything that you are not comfortable also sharing\n> with the NSA.\n>\n> > On Oct 10, 2017, at 1:23 PM, James Hudon <jameshudon at gmail.com> wrote:\n> >\n> > You're asking for newly minted bitcoin to go to you but you burned the\n> bitcoin used in the peg. You're effectively losing your money and then\n> stealing from the miners to gain it back. The miners had to issue your\n> amount of bitcoin 2 times (once for your original bitcoin, again to make\n> you whole). Why would they agree to this?\n> > --\n> > hudon\n> >\n> >> On Oct 10, 2017, at 13:13, Tao Effect via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>\n> >> It would not change the number of Bitcoins in existence.\n> >>\n> >> --\n> >> Sent from my mobile device.\n> >> Please do not email me anything that you are not comfortable also\n> sharing with the NSA.\n> >>\n> >>> On Oct 10, 2017, at 12:50 PM, CryptAxe <cryptaxe at gmail.com> wrote:\n> >>>\n> >>> Your method would change the number of Bitcoins in existence. Why?\n> >>>\n> >>> On Oct 10, 2017 12:47 PM, \"Tao Effect via bitcoin-dev\" <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>> Is that what passes for a technical argument these days? Sheesh.\n> >>>\n> >>> Whereas in Drivechain users are forced to give up their coins to a\n> single group for whatever sidechains they interact with, the generic\n> sharding algo lets them (1) keep their coins, (2) trust whatever group they\n> want to trust (the miners of the various sidechains).\n> >>>\n> >>> Drivechain offers objectively worse security.\n> >>>\n> >>> --\n> >>> Sent from my mobile device.\n> >>> Please do not email me anything that you are not comfortable also\n> sharing with the NSA.\n> >>>\n> >>>> On Oct 10, 2017, at 8:09 AM, Paul Sztorc via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>>>\n> >>>> I think this response speaks for itself.\n> >>>>\n> >>>>> On 10/10/2017 10:09 AM, Tao Effect wrote:\n> >>>>> Hi Paul,\n> >>>>>\n> >>>>> I thought it was clear, but apparently you are getting stuck on the\n> semantics of the word \"burn\".\n> >>>>>\n> >>>>> The \"burning\" applies to the original coins you had.\n> >>>>>\n> >>>>> When you transfer them back, you get newly minted coins, equivalent\n> to the amount you \"burned\" on the chain you're transferring from \u2015 as\n> stated in the OP.\n> >>>>>\n> >>>>> If you don't like the word \"burn\", pick another one.\n> >>>>>\n> >>>>> --\n> >>>>> Please do not email me anything that you are not comfortable also\n> sharing with the NSA.\n> >>>>>\n> >>>>>> On Oct 10, 2017, at 4:20 AM, Paul Sztorc <truthcoin at gmail.com>\n> wrote:\n> >>>>>>\n> >>>>>> Haha, no. Because you \"burned\" the coins.\n> >>>>>>\n> >>>>>> On Oct 10, 2017 1:20 AM, \"Tao Effect\" <contact at taoeffect.com>\n> wrote:\n> >>>>>> Paul,\n> >>>>>>\n> >>>>>> It's a two-way peg.\n> >>>>>>\n> >>>>>> There's nothing preventing transfers back to the main chain.\n> >>>>>>\n> >>>>>> They work in the exact same manner.\n> >>>>>>\n> >>>>>> Cheers,\n> >>>>>> Greg\n> >>>>>>\n> >>>>>> --\n> >>>>>> Please do not email me anything that you are not comfortable also\n> sharing with the NSA.\n> >>>>>>\n> >>>>>>> On Oct 9, 2017, at 6:39 PM, Paul Sztorc <truthcoin at gmail.com>\n> wrote:\n> >>>>>>>\n> >>>>>>> That is only a one-way peg, not a two-way.\n> >>>>>>>\n> >>>>>>> In fact, that is exactly what drivechain does, if one chooses\n> parameters for the drivechain that make it impossible for any side-to-main\n> transfer to succeed.\n> >>>>>>>\n> >>>>>>> One-way pegs have strong first-mover disadvantages.\n> >>>>>>>\n> >>>>>>> Paul\n> >>>>>>>\n> >>>>>>> On Oct 9, 2017 9:24 PM, \"Tao Effect via bitcoin-dev\" <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>>>>>> Dear list,\n> >>>>>>>\n> >>>>>>> In previous arguments over Drivechain (and Drivechain-like\n> proposals) I promised that better scaling proposals \u2015 that do not sacrifice\n> Bitcoin's security \u2015 would come along.\n> >>>>>>>\n> >>>>>>> I planned to do a detailed writeup, but have decided to just send\n> off this email with what I have, because I'm unlikely to have time to write\n> up a detailed proposal.\n> >>>>>>>\n> >>>>>>> The idea is very simple (and by no means novel*), and I'm sure\n> others have mentioned either exactly it, or similar ideas (e.g. burning\n> coins) before.\n> >>>>>>>\n> >>>>>>> This is a generic sharding protocol for all blockchains, including\n> Bitcoin.\n> >>>>>>>\n> >>>>>>> Users simply say: \"My coins on Chain A are going to be sent to\n> Chain B\".\n> >>>>>>>\n> >>>>>>> Then they burn the coins on Chain A, and create a minting\n> transaction on Chain B. The details of how to ensure that coins do not get\n> lost needs to be worked out, but I'm fairly certain the folks on this list\n> can figure out those details.\n> >>>>>>>\n> >>>>>>> - Thin clients, nodes, and miners, can all very easily verify that\n> said action took place, and therefore accept the \"newly minted\" coins on B\n> as valid.\n> >>>>>>> - Users client software now also knows where to look for the other\n> coins (if for some reason it needs to).\n> >>>>>>>\n> >>>>>>> This doesn't even need much modification to the Bitcoin protocol\n> as most of the verification is done client-side.\n> >>>>>>>\n> >>>>>>> It is fully decentralized, and there's no need to give our\n> ownership of our coins to miners to get scale.\n> >>>>>>>\n> >>>>>>> My sincere apologies if this has been brought up before (in which\n> case, I would be very grateful for a link to the proposal).\n> >>>>>>>\n> >>>>>>> Cheers,\n> >>>>>>> Greg Slepak\n> >>>>>>>\n> >>>>>>> * This idea is similar in spirit to Interledger.\n> >>>>>>>\n> >>>>>>> --\n> >>>>>>> Please do not email me anything that you are not comfortable also\n> sharing with the NSA.\n> >>>>>>>\n> >>>>>>>\n> >>>>>>> _______________________________________________\n> >>>>>>> bitcoin-dev mailing list\n> >>>>>>> bitcoin-dev at lists.linuxfoundation.org\n> >>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >>>>>>>\n> >>>>>>>\n> >>>>>>\n> >>>>>\n> >>>>\n> >>>> _______________________________________________\n> >>>> bitcoin-dev mailing list\n> >>>> bitcoin-dev at lists.linuxfoundation.org\n> >>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >>>\n> >>> _______________________________________________\n> >>> bitcoin-dev mailing list\n> >>> bitcoin-dev at lists.linuxfoundation.org\n> >>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >>>\n> >> _______________________________________________\n> >> bitcoin-dev mailing list\n> >> bitcoin-dev at lists.linuxfoundation.org\n> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171011/3aecf220/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Generalized sharding protocol for decentralized scaling without Miners owning our BTC",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "CryptAxe",
                "Lucas Clemente Vella",
                "Ben Kloester",
                "Paul Sztorc",
                "Tao Effect",
                "James Hudon"
            ],
            "messages_count": 17,
            "total_messages_chars_count": 70924
        }
    },
    {
        "title": "[bitcoin-dev]  New difficulty algorithm part 2",
        "thread_messages": [
            {
                "author": "Scott Roberts",
                "date": "2017-10-11T14:50:20",
                "message_text_only": "(This is new thread because I'm having trouble getting yahoo mail \n\nto use \"reply-to\", copy-pasting the subject did not work, and the \nlist has not approved my gmail)\nA hard fork in the near term is feasible only post-disaster (in my mind, \nthat means Core failing from long transaction delays that destroys \nconfidence and therefore price). A hard fork attempt to fix the situation \nwill not work unless the difficulty is fixed to let price guide hash power \ninstead of vice versa. We seem to be headed towards letting the tail wag \nthe dog. BTC may find itself in the same position as BCH and all alts: the \ncurrent difficulty algorithm is untenable and will require a fork. \n\nCurrent difficulty algorithm in presence of higher hashrate coin with \nthe same POW: \nlower hashpower => wait times => lost confidence => lower price => defeat \n\nDifficulty algorithms that alts find absolutely necessary when there \nis a higher hash rate coin with the same POW: \nhodler faith => price => hashpower => survivable coin \n\nAlt experience time and time again is that Core will have to fork to a \nfaster responding difficulty algorithm if it finds itself suddenly (and \nfor the first time) with a lower hashrate. \n\n\nMark Friedenbach wrote: \n> changing the difficulty adjustment algorithm doesn\u2019t solve the underlying \n> issue, hashpower not being aligned with users\u2019 (or owners') interests. \n\nI define \"users\" as those who it it for value transfer (including \npurchases) without concern for long-term value. If SegWit2x reduces fees \nper coin, then hashpower is being aligned with their short-term interests. \n\nIt does not solve it, but it is a pre-requisite if the coin has a lower \nhashrate (BTC at end of November). A faster responding diffulty is a \npre-requisite in minority hashrate coins for letting price (hodlers) \ndictate hashpower instead of vice versa. This is the experience of alts. \n\nZmnSCPxj wrote: \n> Hodlers have much greater power in hardfork situations than miners \n\nNot when hodlers are more evenly split between coins. Miners will prefer \nthe coin with higher transaction fees which will erode hodler confidence \nvia longer delays. This means transaction fees will evolve to the highest \nthat common marketplace users can accepet (they are not intereseted in \nhodler security), not the lowest technologically feasible fee that provides \nthe greatest security. Large blocks reduce network security while giving \nthe higher total transaction fees to miners even as it can reduce fees per \ncoin for users. The mining \"lobby\" will always describe this as \"best for \nusers\". Non-hodling users and miners logically prefer SegWit2x. \n\nZmnSCPxj wrote: \n> BCH changed its difficulty algorithm, and it is often considered to be to \nits detriment due to sudden hashpower oscillations \n\nBCH has survived this long because they did NOT use the bitcoin difficulty \nalgorithm. Granted, it is a bad design that included an asymmetry that has \nresulted in too many coins being issued. If they had inverted the decrease \nrule to create a symmetrically fast increase rule instead of keeping \nbitcoin's increase logic, they would be in much better shape, much better \nthan the bitcoin difficulty algorithm. Making it symmetrical and fast would \nhave resulted in more obvious fast oscillations, but this would have helped \nprice discovery to settle the oscillations to an acceptable level that \ncould stabilize the price by preventing too many coins from being issued. \n\nOscillations require: 1) comparable price and 2) miners having the option \nto go back and forth to a larger coin. Bitcoin's long, jumping difficulty \naveraging window may destroy the minority hashrate coin faster in fewer \noscillations thanks to a first-to-market effect more than reason. In \npersuit of higher total transacton fees, miners are deciding SegWit2x is \n\"first-to-market\" to cause Core to have long delays. This is not a \nconspiracy, but simply seeking profit. Since fees per coin can also be \nreduced, they can convince themselves and others that it is the best \noption. \n\nA shorter difficulty algorithm averaging window enables more, faster \noscillations to enable better price discovery before a winner is chosen. \nThe design I'm proposing should be close to the ideal.  For example, Mark \nFriedenbach suggested a difficulty adjustment every 18 blocks by averaging \nthe past 36 blocks. If a coin using that has the minority hashrate, then it \ncould quickly develop into a sudden influx from the majority change for 18 \nblocks, then they exit back to the majority chain for 36 blocks before \ndoing it again. They get 1/3 of the blocks at \"zero excess cost\" \n(difficulty will be 1/10 the correct value if they are 10x base hashrate) \nand then they will leave the constant miners with a higher difficulty for \n36 blocks (at 3.33x higher difficulty if the \"attackers\" are 10x the base \nhashrate). This forces constant miners to start copying them, amplifying \nthe oscillations and delays of the minority hashrate coin. A rolling \naverage window of any length does not theoretically prevent this, unless \nthe window is short enough to be comparable to the time cost of switching \ncoins, if there is a time cost. A say this because in testing I was able \nto design an attack algorithm that always gets 1/3 of the coins at \"zero \nexcess cost\".  But a rolling average with a shorter window should make the \n\"accidental collusion\" of miners seeking profit more unlikely to occur. \nThe reward function I've proposed appears to reduce it to 1/6 total coins \nobtainable at \"zero excess cost\", and similarly reduce oscillations and \nassist better price discovery."
            }
        ],
        "thread_summary": {
            "title": "New difficulty algorithm part 2",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Scott Roberts"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 5627
        }
    },
    {
        "title": "[bitcoin-dev] New difficulty algorithm part 2",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2017-10-12T10:40:24",
                "message_text_only": "Good morning,\n\n>ZmnSCPxj wrote:\n>> Hodlers have much greater power in hardfork situations than miners\n>\n>Not when hodlers are more evenly split between coins. Miners will prefer\n>the coin with higher transaction fees which will erode hodler confidence\n>via longer delays. This means transaction fees will evolve to the highest\n>that common marketplace users can accepet (they are not intereseted in\n>hodler security), not the lowest technologically feasible fee that provides\n>the greatest security. Large blocks reduce network security while giving\n>the higher total transaction fees to miners even as it can reduce fees per\n>coin for users. The mining \"lobby\" will always describe this as \"best for\n>users\". Non-hodling users and miners logically prefer SegWit2x.\n\nHodlers still have greater power than non-hodling users, whether miners or day-traders.\n\nHodlers holding millions in coin, total, can greatly drop price of any undesired hardfork.\n\nMiners will prefer the coin with higher transaction fees as measured in real-world value.  Thus even if the unwanted chain provides 2 tokens as fee per block, whereas the wanted chain provides 1 token as fee per block, if the unwanted chain tokens are valued at 1/4 the wanted chain tokens, miners will still prefer the wanted chain regardless.  What the chains will compete in is the real-world value of the total mining reward.\n\nHodlers hodl all the cards here.\n\n>ZmnSCPxj wrote:\n>> BCH changed its difficulty algorithm, and it is often considered to be to\n>its detriment due to sudden hashpower oscillations\n>\n>BCH has survived this long because they did NOT use the bitcoin difficulty\n<snip>\n\nAll this speculation seems to suggest to me simply that a difficulty change leads to keeping a chain alive unnecessarily, when by rights, it should be dead and laid to rest.\n\nIf Bitcoin needs some sudden change in difficulty algorithm to survive, then it has failed.  Feel free to do your own hardfork into yet another derivative altcoin.\n\n>Bitcoin has developers!\n>\n>And those developers can publish a contingency plan!\n>\n>And that contingency plan can be an emergency hard fork to a different retarget algorithm.\n>\n>And that emergency hard fork can gain consensus if it is broadly preferred over the status quo.\n\nEvery hardfork is an invitation to shatter the community even further than it already is.  There is no need for further shattering.\n\nThe idea that an emergency hardfork to a different difficulty algorithm is necessary arises from a lack of understanding of just how much power hodlers have over the destiny of a coin.\n\nEvery hodler who rejects a hardfork, will sell the hardfork coin, increasing its supply and reducing its price.\n\nEvery miner who mines a rejected hardfork, creates new tokens in the hardfork, increasing its supply and reducing its price.\n\nCoins that are hedl will remain hedl, and are not part of the supply.  Thus coins on the desired chain will remain high in price, regardless of available transaction rate.  The lack of freshly-minted coins also contracts the supply.\n\nIn the end, this will result in the same behavior as in BCH, where hodlers sodl the unwanted hardfork as quickly as they could.  Indeed, due exactly to miner support, 2X is much more likely to quickly drop in price than BCH did.  I am sure you have seen the images pointing out how easy it was to determine when BCH blocks arrived: they arrived a little before each dip in BCH price.  Fast 2X block rate will lead to faster 2X death, with its miners becoming bagholders.\n\nAs most Core developers hodl vast amounts, it is far more likely that any hardfork that goes against what Core wishes will collapse, simply by Core developers acting in their capacity as hodlers of Bitcoin, without needing to do any special action in their capacity as developers.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171012/003fc7c4/attachment.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-10-12T15:25:23",
                "message_text_only": "> On Oct 12, 2017, at 3:40 AM, ZmnSCPxj via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> As most Core developers hodl vast amounts, it is far more likely that any hardfork that goes against what Core wishes will collapse, simply by Core developers acting in their capacity as hodlers of Bitcoin, without needing to do any special action in their capacity as developers.\n\nWhile this might be true of some, it is most certainly not true of many, and it is a very dangerous men to the safety and well being of people on this list.\n\nYou don\u2019t get bitcoin for being a bitcoin developer, and there is no reason to suppose a developer has any more or less bitcoin than anyone else in the industry.\n\nIt is certainly the case that a large number of people and organizations who are not developers hold massive amounts of bitcoin (hundred of thousands each, millions in aggregate)."
            },
            {
                "author": "Scott Roberts",
                "date": "2017-10-12T15:42:02",
                "message_text_only": "ZmnSCPxj wrote:\n> Thus even if the unwanted chain provides 2 tokens as fee per block,\n> whereas the wanted chain provides 1 token as fee per block, if the\n> unwanted chain tokens are valued at 1/4 the wanted chain tokens, miners\n> will still prefer the wanted chain regardless.\n\nThis is a good point I was not thinking about, but your math assumes\n1/2 price for a coin that can do 2x more transactions. Holders like\nRoger Ver have an interest in low price and more transactions. A coin\nwith 2x more transactions, 22% lower price, and 22% lower fees per\ncoin transferred will attract more merchants, customers, and miners\n(they get 50% more total fees) and this will in turn attract more\nhodlers and devs. This assumes it outweighs hodler security concerns.\nMerchants and customers, to the extent they are not long term hodlers,\nare not interested in price as much as stability, so they are somewhat\nat odds with hodlers.\n\nBitcoin consensus truth is based on \"might is right\". Buyers and\nsellers of goods and services (\"users\") can shift some might to miners\nvia fees, to the chagrin of hodlers who have more interest in security\nand price increases. Some hodlers think meeting user needs is the\nsource of long term value. Others think mining infrastructure is. You\nseem to require hodlers to correctly identify and rely solely on good\ndevelopers. Whatever combination of these is the case, bad money can\nstill drive out good, especially if the market determination is not\nefficient.\n\nA faster measurement of hashrate for difficulty enables the economic\ndetermination to be more efficient and correct. It prevents the\nbiggest coin from bullying forks that have better ideas. Conversely,\nit prevents miners from switching to an inferior coin simply because\nit provides them with more \"protection money\" from fees that enables\nthem to bully Bitcoin Core out of existence, even in the presence of a\nslightly larger hodler support.\n\nDevs are a governing authority under the influence of users, hodlers,\nand miners. Miners are like banks lobbying government for higher total\nfees. Hodlers are the new 1%, holding 90% of the coin, lobbying both\ndevs and users for security, but equally interested in price\nincreases. Users are \"the people\" that devs need to protect against\nboth hodlers and miners. They do not care about price as long as it is\nstable. They do not want to become the 99% owning 10% of the coin or\nhave to pay unecessary fees merely for their coin to be the biggest\nbully on the block.  A faster responding difficulty will take a lot of\nhot air out of the bully. It prevents miners from being able to\ndictate that only coins with high fees are allowed.  They are less\nable to destroy small coins that have a fast defense.\n\nThe 1% and banks would starve the people that feed them to death if\nthey were allowed complete control of the government. Are hodlers and\nminers any wiser? Devs need to strive for an expansion of the coin\nquantity to keep value constant which is the foundation of the 5\ncharacteristics of an ideal currency.  Therefore devs should seek\npeaceful and sustainable forks of bitcoin. This will enable constant\nvalue, security, and low transaction fees per coin transfer. Alts\naside, the current situation of discouraging forks forbids constant\nvalue via limited quantity.  It also forces a choice between high\nsecurity and low fees.  Forks with a faster difficulty will be more\ncapable of retaining value.\n\nUsers, devs, hodlers, and miners are naturally aligned and at odds in\ndifferent ways. A flow chart of the checks and balances should enable\nbetter development towards a self-controlling feedback system, but the\ngoals need to be known before it could be designed and implemented.\nHodlers say price increases is the goal. Users say efficient transfer\nof value. Miners say fees (at least that's the end game after mining).\nI'm with users despite trying to be the 1% (which reminds me of a book\nabout how people often vote based on feeling good about their morality\nand concern for society as a whole, despite it being contrary to their\npersonal best interests if that vote wins.)"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2017-10-13T04:45:33",
                "message_text_only": "Good morning,\n\n>ZmnSCPxj wrote:\n>> Thus even if the unwanted chain provides 2 tokens as fee per block,\n>> whereas the wanted chain provides 1 token as fee per block, if the\n>> unwanted chain tokens are valued at 1/4 the wanted chain tokens, miners\n>> will still prefer the wanted chain regardless.\n>\n>This is a good point I was not thinking about, but your math assumes\n>1/2 price for a coin that can do 2x more transactions. Holders like\n>Roger Ver have an interest in low price and more transactions. A coin\n>with 2x more transactions, 22% lower price, and 22% lower fees per\n>coin transferred will attract more merchants, customers, and miners\n>(they get 50% more total fees) and this will in turn attract more\n>hodlers and devs. This assumes it outweighs hodler security concerns.\n>Merchants and customers, to the extent they are not long term hodlers,\n>are not interested in price as much as stability, so they are somewhat\n>at odds with hodlers.\n\nAs of this moment, BT1 / BT2 price ratio in BitFinex is slightly higher than 7 : 1.  Twice the transaction rate cannot overcome this price ratio difference.  Even if you were to claim that the BitFinex data is off by a factor of 3, twice the transaction rate still cannot overcome the price ratio difference.  Do you have stronger data than what is available on BitFinex?  If not, your assumptions are incorrect and all conclusions suspect.\n\n>Bitcoin consensus truth is based on \"might is right\". Buyers and\n>sellers of goods and services (\"users\") can shift some might to miners\n>via fees, to the chagrin of hodlers who have more interest in security\n>and price increases. Some hodlers think meeting user needs is the\n>source of long term value. Others think mining infrastructure is.\n\nMining infrastructure follows price.  If bitcoins were still trading at 1 USD per coin, nobody will build mining infrastructure to the same level as today, with 5000 USD per coin.\n\nPrice will follow user needs, i.e. demand.\n\n>You\n>seem to require hodlers to correctly identify and rely solely on good\n>developers.\n\nFor the very specific case of 2X, it is very easy to make this identification.  Even without understanding the work being done, one can reasonably say that it is far more likely that a loose group of 100 or more developers will contain a few good or excellent developers, than a group of a few developers containing a similar number of good or excellent developers.\n\nUser needs will get met only on the chain that good developers work on.  Bitcoin today has too many limitations: viruses on Windows can steal all your money, fee estimates consistently overestimate, fees rise during spamming attacks, easy to lose psuedonymity, tiny UTXOs are infeasible to spend, cannot support dozens of thousands of transactions per second.  Rationally, long-term hodlers will select a chain with better developers who are more likely to discover or innovate methods to reduce, eliminate, or sidestep those limitations.  Perhaps the balance will change in the future, but it is certainly not the balance now, and thus any difficulty algorithm change in response to the current situation will be premature, and far more likely to cause disaster than avert one.\n\n>Whatever combination of these is the case, bad money can\n>still drive out good, especially if the market determination is not\n>efficient.\n>\n>A faster measurement of hashrate for difficulty enables the economic\n>determination to be more efficient and correct. It prevents the\n>biggest coin from bullying forks that have better ideas. Conversely,\n>it prevents miners from switching to an inferior coin simply because\n>it provides them with more \"protection money\" from fees that enables\n>them to bully Bitcoin Core out of existence, even in the presence of a\n>slightly larger hodler support.\n\nThis requires that all chains follow the same difficulty adjustment: after all, it is also entirely the possibility that 2X will be the lower-hashrate coin in a few months, with the Core chain bullying them out of existence.  Perhaps you should cross-post your analysis to bitcoin-segwit2x also.  After all, the 2X developers should also want to have faster price discovery of the true price of 2X, away from the unfavorable (incorrect?) pricing on BitFinex.\n\n>Devs are a governing authority under the influence of users, hodlers,\n>and miners. Miners are like banks lobbying government for higher total\n>fees. Hodlers are the new 1%, holding 90% of the coin, lobbying both\n>devs and users for security, but equally interested in price\n>increases. Users are \"the people\" that devs need to protect against\n>both hodlers and miners. They do not care about price as long as it is\n>stable. They do not want to become the 99% owning 10% of the coin or\n>have to pay unecessary fees merely for their coin to be the biggest\n>bully on the block. A faster responding difficulty will take a lot of\n>hot air out of the bully. It prevents miners from being able to\n>dictate that only coins with high fees are allowed. They are less\n>able to destroy small coins that have a fast defense.\n>\n>The 1% and banks would starve the people that feed them to death if\n>they were allowed complete control of the government. Are hodlers and\n>miners any wiser?\n\nAre developers any wiser, either?\n\nThen consider this wisdom: The fewer back-incompatible changes to a coin, the better.  Hardforks of any kind are an invitation to disaster and, at this point, require massive coordination effort which cannot be feasibly done within a month.  Fast market determination can be done using off-chain methods (such as on-exchange trades), and are generally robust against temporary problems on-chain, although admittedly there is a counterparty risk involved.  The coin works, and in general there is usually very little need to fix it, especially using dangerous hardforks.\n\n>Devs need to strive for an expansion of the coin\n>quantity to keep value constant which is the foundation of the 5\n>characteristics of an ideal currency.\n\nIs that your goal?  This is a massive departure from the conception of Bitcoin as having a fixed limit and effectively becoming deflationary.  It will also lead to massive economic distortions in favor of those who receive newly-minted coins.  I doubt any developer would want to have this property.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171013/1afdebf0/attachment-0001.html>"
            },
            {
                "author": "Scott Roberts",
                "date": "2017-10-13T11:35:09",
                "message_text_only": "Yes, the current price ratio indicates there is no need for a new\ndifficulty algorithm. I do not desire to fork before a disaster, or to\notherwise employ a new difficulty before a fork is otherwise needed.\n\nA 2-week delay in difficulty response is a 2 week error in\nmeasurement. Slow response generally means less intelligence.\n\nMy goal is not to have a bunch of BTC clones that merchants and buyers\nuse equally, but to have a  better difficulty algorithm in place to be\nused in the next BTC \"Core\" fork. If not for the current situation,\nthen for future security.\n\n>  This is a massive departure from the conception of Bitcoin as having a fixed limit and effectively becoming deflationary.\n\nYou mean multiple forks is inflationary. The current limit in quantity\nis deflationary because the use of the coin is rising faster than its\nmining is producing (see velocity of money). Constant value is defined\nas being neither. Bitcoin's deflationary quality created a massive\nmarketing advantage as well as paid the creator about million dollars\nan hour. If it suddenly were able to be a constant value coin, its use\nin the marketplace and as a real store of value would skyrocket and\nthe cries of \"Ponzi scheme\" would stop. The trick is in determining\nconstant value without a 3rd party such as an index of a basket of\ncommodities (which both Keynes and von Mises wanted, but was scuttled\nby the U.S. at Bretton Woods).\n\nOn Fri, Oct 13, 2017 at 12:45 AM, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n> Good morning,\n>\n>\n>>ZmnSCPxj wrote:\n>>> Thus even if the unwanted chain provides 2 tokens as fee per block,\n>>> whereas the wanted chain provides 1 token as fee per block, if the\n>>> unwanted chain tokens are valued at 1/4 the wanted chain tokens, miners\n>>> will still prefer the wanted chain regardless.\n>>\n>>This is a good point I was not thinking about, but your math assumes\n>>1/2 price for a coin that can do 2x more transactions. Holders like\n>>Roger Ver have an interest in low price and more transactions. A coin\n>>with 2x more transactions, 22% lower price, and 22% lower fees per\n>>coin transferred will attract more merchants, customers, and miners\n>>(they get 50% more total fees) and this will in turn attract more\n>>hodlers and devs. This assumes it outweighs hodler security concerns.\n>>Merchants and customers, to the extent they are not long term hodlers,\n>>are not interested in price as much as stability, so they are somewhat\n>>at odds with hodlers.\n>\n> As of this moment, BT1 / BT2 price ratio in BitFinex is slightly higher than\n> 7 : 1.  Twice the transaction rate cannot overcome this price ratio\n> difference.  Even if you were to claim that the BitFinex data is off by a\n> factor of 3, twice the transaction rate still cannot overcome the price\n> ratio difference.  Do you have stronger data than what is available on\n> BitFinex?  If not, your assumptions are incorrect and all conclusions\n> suspect.\n>\n>\n>>Bitcoin consensus truth is based on \"might is right\". Buyers and\n>>sellers of goods and services (\"users\") can shift some might to miners\n>>via fees, to the chagrin of hodlers who have more interest in security\n>>and price increases. Some hodlers think meeting user needs is the\n>>source of long term value. Others think mining infrastructure is.\n>\n> Mining infrastructure follows price.  If bitcoins were still trading at 1\n> USD per coin, nobody will build mining infrastructure to the same level as\n> today, with 5000 USD per coin.\n>\n> Price will follow user needs, i.e. demand.\n>\n>>You\n>>seem to require hodlers to correctly identify and rely solely on good\n>>developers.\n>\n> For the very specific case of 2X, it is very easy to make this\n> identification.  Even without understanding the work being done, one can\n> reasonably say that it is far more likely that a loose group of 100 or more\n> developers will contain a few good or excellent developers, than a group of\n> a few developers containing a similar number of good or excellent\n> developers.\n>\n> User needs will get met only on the chain that good developers work on.\n> Bitcoin today has too many limitations: viruses on Windows can steal all\n> your money, fee estimates consistently overestimate, fees rise during\n> spamming attacks, easy to lose psuedonymity, tiny UTXOs are infeasible to\n> spend, cannot support dozens of thousands of transactions per second.\n> Rationally, long-term hodlers will select a chain with better developers who\n> are more likely to discover or innovate methods to reduce, eliminate, or\n> sidestep those limitations.  Perhaps the balance will change in the future,\n> but it is certainly not the balance now, and thus any difficulty algorithm\n> change in response to the current situation will be premature, and far more\n> likely to cause disaster than avert one.\n>\n>>Whatever combination of these is the case, bad money can\n>>still drive out good, especially if the market determination is not\n>>efficient.\n>>\n>>A faster measurement of hashrate for difficulty enables the economic\n>>determination to be more efficient and correct. It prevents the\n>>biggest coin from bullying forks that have better ideas. Conversely,\n>>it prevents miners from switching to an inferior coin simply because\n>>it provides them with more \"protection money\" from fees that enables\n>>them to bully Bitcoin Core out of existence, even in the presence of a\n>>slightly larger hodler support.\n>\n> This requires that all chains follow the same difficulty adjustment: after\n> all, it is also entirely the possibility that 2X will be the lower-hashrate\n> coin in a few months, with the Core chain bullying them out of existence.\n> Perhaps you should cross-post your analysis to bitcoin-segwit2x also.  After\n> all, the 2X developers should also want to have faster price discovery of\n> the true price of 2X, away from the unfavorable (incorrect?) pricing on\n> BitFinex.\n>\n>>Devs are a governing authority under the influence of users, hodlers,\n>>and miners. Miners are like banks lobbying government for higher total\n>>fees. Hodlers are the new 1%, holding 90% of the coin, lobbying both\n>>devs and users for security, but equally interested in price\n>>increases. Users are \"the people\" that devs need to protect against\n>>both hodlers and miners. They do not care about price as long as it is\n>>stable. They do not want to become the 99% owning 10% of the coin or\n>>have to pay unecessary fees merely for their coin to be the biggest\n>>bully on the block. A faster responding difficulty will take a lot of\n>>hot air out of the bully. It prevents miners from being able to\n>>dictate that only coins with high fees are allowed. They are less\n>>able to destroy small coins that have a fast defense.\n>>\n>>The 1% and banks would starve the people that feed them to death if\n>>they were allowed complete control of the government. Are hodlers and\n>>miners any wiser?\n>\n> Are developers any wiser, either?\n>\n> Then consider this wisdom: The fewer back-incompatible changes to a coin,\n> the better.  Hardforks of any kind are an invitation to disaster and, at\n> this point, require massive coordination effort which cannot be feasibly\n> done within a month.  Fast market determination can be done using off-chain\n> methods (such as on-exchange trades), and are generally robust against\n> temporary problems on-chain, although admittedly there is a counterparty\n> risk involved.  The coin works, and in general there is usually very little\n> need to fix it, especially using dangerous hardforks.\n>\n>>Devs need to strive for an expansion of the coin\n>>quantity to keep value constant which is the foundation of the 5\n>>characteristics of an ideal currency.\n>\n> Is that your goal?  This is a massive departure from the conception of\n> Bitcoin as having a fixed limit and effectively becoming deflationary.  It\n> will also lead to massive economic distortions in favor of those who receive\n> newly-minted coins.  I doubt any developer would want to have this property.\n>\n> Regards,\n> ZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "New difficulty algorithm part 2",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Scott Roberts",
                "Mark Friedenbach"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 23484
        }
    },
    {
        "title": "[bitcoin-dev] bitcoin-dev Digest, Vol 29, Issue 21",
        "thread_messages": [
            {
                "author": "Ilan Oh",
                "date": "2017-10-13T12:27:17",
                "message_text_only": "> Mining infrastructure follows price.  If bitcoins were still trading at 1\nUSD per coin, nobody will build mining infrastructure to the same level as\ntoday, with 5000 USD per coin.\n\nIn the case of bitcoin, it is the price that follows mining\ninfrastructures. The price is at 5000 because it is difficult to mine\nbitcoin not the other way around, like you mention it. Even with a fixed\ndemand, price would go up as difficulty grow, the supply guide the market.\nThere is a strong incentive to mine blindly as it is difficult to estimate\nfor a miner where is the actual demand, with a start up currency without\nactual economic support. Indeed at the genesis of this \"mining-price\" cycle\nthe incentive was to contribute to a network and create ones own supply,\nand not respond to a demand.\n\nIlansky\n\nLe 13 oct. 2017 13:55, <bitcoin-dev-request at lists.linuxfoundation.org> a\n\u00e9crit :\n\n> Send bitcoin-dev mailing list submissions to\n>         bitcoin-dev at lists.linuxfoundation.org\n>\n> To subscribe or unsubscribe via the World Wide Web, visit\n>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> or, via email, send a message with subject or body 'help' to\n>         bitcoin-dev-request at lists.linuxfoundation.org\n>\n> You can reach the person managing the list at\n>         bitcoin-dev-owner at lists.linuxfoundation.org\n>\n> When replying, please edit your Subject line so it is more specific\n> than \"Re: Contents of bitcoin-dev digest...\"\n>\n>\n> Today's Topics:\n>\n>    1. Re: New difficulty algorithm part 2 (ZmnSCPxj)\n>    2. Re: New difficulty algorithm part 2 (Scott Roberts)\n>\n>\n> ----------------------------------------------------------------------\n>\n> Message: 1\n> Date: Fri, 13 Oct 2017 00:45:33 -0400\n> From: ZmnSCPxj <ZmnSCPxj at protonmail.com>\n> To: Scott Roberts <wordsgalore at gmail.com>\n> Cc: \"bitcoin-dev at lists.linuxfoundation.org\"\n>         <bitcoin-dev at lists.linuxfoundation.org>\n> Subject: Re: [bitcoin-dev] New difficulty algorithm part 2\n> Message-ID:\n>         <Hr8ORNHzR76wNhJHoagwXi2ewQ1qYSZScH0xeltVnqid2ljOowc2bj8-\n> rkbdukpk9eyoPx1ReOZSUsNrcowRU9gL5UbKtblkQn2SUo06BHE=@protonmail.com>\n>\n> Content-Type: text/plain; charset=\"utf-8\"\n>\n> Good morning,\n>\n> >ZmnSCPxj wrote:\n> >> Thus even if the unwanted chain provides 2 tokens as fee per block,\n> >> whereas the wanted chain provides 1 token as fee per block, if the\n> >> unwanted chain tokens are valued at 1/4 the wanted chain tokens, miners\n> >> will still prefer the wanted chain regardless.\n> >\n> >This is a good point I was not thinking about, but your math assumes\n> >1/2 price for a coin that can do 2x more transactions. Holders like\n> >Roger Ver have an interest in low price and more transactions. A coin\n> >with 2x more transactions, 22% lower price, and 22% lower fees per\n> >coin transferred will attract more merchants, customers, and miners\n> >(they get 50% more total fees) and this will in turn attract more\n> >hodlers and devs. This assumes it outweighs hodler security concerns.\n> >Merchants and customers, to the extent they are not long term hodlers,\n> >are not interested in price as much as stability, so they are somewhat\n> >at odds with hodlers.\n>\n> As of this moment, BT1 / BT2 price ratio in BitFinex is slightly higher\n> than 7 : 1.  Twice the transaction rate cannot overcome this price ratio\n> difference.  Even if you were to claim that the BitFinex data is off by a\n> factor of 3, twice the transaction rate still cannot overcome the price\n> ratio difference.  Do you have stronger data than what is available on\n> BitFinex?  If not, your assumptions are incorrect and all conclusions\n> suspect.\n>\n> >Bitcoin consensus truth is based on \"might is right\". Buyers and\n> >sellers of goods and services (\"users\") can shift some might to miners\n> >via fees, to the chagrin of hodlers who have more interest in security\n> >and price increases. Some hodlers think meeting user needs is the\n> >source of long term value. Others think mining infrastructure is.\n>\n> Mining infrastructure follows price.  If bitcoins were still trading at 1\n> USD per coin, nobody will build mining infrastructure to the same level as\n> today, with 5000 USD per coin.\n>\n> Price will follow user needs, i.e. demand.\n>\n> >You\n> >seem to require hodlers to correctly identify and rely solely on good\n> >developers.\n>\n> For the very specific case of 2X, it is very easy to make this\n> identification.  Even without understanding the work being done, one can\n> reasonably say that it is far more likely that a loose group of 100 or more\n> developers will contain a few good or excellent developers, than a group of\n> a few developers containing a similar number of good or excellent\n> developers.\n>\n> User needs will get met only on the chain that good developers work on.\n> Bitcoin today has too many limitations: viruses on Windows can steal all\n> your money, fee estimates consistently overestimate, fees rise during\n> spamming attacks, easy to lose psuedonymity, tiny UTXOs are infeasible to\n> spend, cannot support dozens of thousands of transactions per second.\n> Rationally, long-term hodlers will select a chain with better developers\n> who are more likely to discover or innovate methods to reduce, eliminate,\n> or sidestep those limitations.  Perhaps the balance will change in the\n> future, but it is certainly not the balance now, and thus any difficulty\n> algorithm change in response to the current situation will be premature,\n> and far more likely to cause disaster than avert one.\n>\n> >Whatever combination of these is the case, bad money can\n> >still drive out good, especially if the market determination is not\n> >efficient.\n> >\n> >A faster measurement of hashrate for difficulty enables the economic\n> >determination to be more efficient and correct. It prevents the\n> >biggest coin from bullying forks that have better ideas. Conversely,\n> >it prevents miners from switching to an inferior coin simply because\n> >it provides them with more \"protection money\" from fees that enables\n> >them to bully Bitcoin Core out of existence, even in the presence of a\n> >slightly larger hodler support.\n>\n> This requires that all chains follow the same difficulty adjustment: after\n> all, it is also entirely the possibility that 2X will be the lower-hashrate\n> coin in a few months, with the Core chain bullying them out of existence.\n> Perhaps you should cross-post your analysis to bitcoin-segwit2x also.\n> After all, the 2X developers should also want to have faster price\n> discovery of the true price of 2X, away from the unfavorable (incorrect?)\n> pricing on BitFinex.\n>\n> >Devs are a governing authority under the influence of users, hodlers,\n> >and miners. Miners are like banks lobbying government for higher total\n> >fees. Hodlers are the new 1%, holding 90% of the coin, lobbying both\n> >devs and users for security, but equally interested in price\n> >increases. Users are \"the people\" that devs need to protect against\n> >both hodlers and miners. They do not care about price as long as it is\n> >stable. They do not want to become the 99% owning 10% of the coin or\n> >have to pay unecessary fees merely for their coin to be the biggest\n> >bully on the block. A faster responding difficulty will take a lot of\n> >hot air out of the bully. It prevents miners from being able to\n> >dictate that only coins with high fees are allowed. They are less\n> >able to destroy small coins that have a fast defense.\n> >\n> >The 1% and banks would starve the people that feed them to death if\n> >they were allowed complete control of the government. Are hodlers and\n> >miners any wiser?\n>\n> Are developers any wiser, either?\n>\n> Then consider this wisdom: The fewer back-incompatible changes to a coin,\n> the better.  Hardforks of any kind are an invitation to disaster and, at\n> this point, require massive coordination effort which cannot be feasibly\n> done within a month.  Fast market determination can be done using off-chain\n> methods (such as on-exchange trades), and are generally robust against\n> temporary problems on-chain, although admittedly there is a counterparty\n> risk involved.  The coin works, and in general there is usually very little\n> need to fix it, especially using dangerous hardforks.\n>\n> >Devs need to strive for an expansion of the coin\n> >quantity to keep value constant which is the foundation of the 5\n> >characteristics of an ideal currency.\n>\n> Is that your goal?  This is a massive departure from the conception of\n> Bitcoin as having a fixed limit and effectively becoming deflationary.  It\n> will also lead to massive economic distortions in favor of those who\n> receive newly-minted coins.  I doubt any developer would want to have this\n> property.\n>\n> Regards,\n> ZmnSCPxj\n> -------------- next part --------------\n> An HTML attachment was scrubbed...\n> URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/\n> attachments/20171013/1afdebf0/attachment.html>\n>\n> ------------------------------\n>\n> Message: 2\n> Date: Fri, 13 Oct 2017 07:35:09 -0400\n> From: Scott Roberts <wordsgalore at gmail.com>\n> To: ZmnSCPxj <ZmnSCPxj at protonmail.com>\n> Cc: \"bitcoin-dev at lists.linuxfoundation.org\"\n>         <bitcoin-dev at lists.linuxfoundation.org>\n> Subject: Re: [bitcoin-dev] New difficulty algorithm part 2\n> Message-ID:\n>         <CADtTMvnrZp=JD4rkXQOZAPNS9BMNMqnTyfA65PRzZhWs+VxgHA at mail.\n> gmail.com>\n> Content-Type: text/plain; charset=\"UTF-8\"\n>\n> Yes, the current price ratio indicates there is no need for a new\n> difficulty algorithm. I do not desire to fork before a disaster, or to\n> otherwise employ a new difficulty before a fork is otherwise needed.\n>\n> A 2-week delay in difficulty response is a 2 week error in\n> measurement. Slow response generally means less intelligence.\n>\n> My goal is not to have a bunch of BTC clones that merchants and buyers\n> use equally, but to have a  better difficulty algorithm in place to be\n> used in the next BTC \"Core\" fork. If not for the current situation,\n> then for future security.\n>\n> >  This is a massive departure from the conception of Bitcoin as having a\n> fixed limit and effectively becoming deflationary.\n>\n> You mean multiple forks is inflationary. The current limit in quantity\n> is deflationary because the use of the coin is rising faster than its\n> mining is producing (see velocity of money). Constant value is defined\n> as being neither. Bitcoin's deflationary quality created a massive\n> marketing advantage as well as paid the creator about million dollars\n> an hour. If it suddenly were able to be a constant value coin, its use\n> in the marketplace and as a real store of value would skyrocket and\n> the cries of \"Ponzi scheme\" would stop. The trick is in determining\n> constant value without a 3rd party such as an index of a basket of\n> commodities (which both Keynes and von Mises wanted, but was scuttled\n> by the U.S. at Bretton Woods).\n>\n> On Fri, Oct 13, 2017 at 12:45 AM, ZmnSCPxj <ZmnSCPxj at protonmail.com>\n> wrote:\n> > Good morning,\n> >\n> >\n> >>ZmnSCPxj wrote:\n> >>> Thus even if the unwanted chain provides 2 tokens as fee per block,\n> >>> whereas the wanted chain provides 1 token as fee per block, if the\n> >>> unwanted chain tokens are valued at 1/4 the wanted chain tokens, miners\n> >>> will still prefer the wanted chain regardless.\n> >>\n> >>This is a good point I was not thinking about, but your math assumes\n> >>1/2 price for a coin that can do 2x more transactions. Holders like\n> >>Roger Ver have an interest in low price and more transactions. A coin\n> >>with 2x more transactions, 22% lower price, and 22% lower fees per\n> >>coin transferred will attract more merchants, customers, and miners\n> >>(they get 50% more total fees) and this will in turn attract more\n> >>hodlers and devs. This assumes it outweighs hodler security concerns.\n> >>Merchants and customers, to the extent they are not long term hodlers,\n> >>are not interested in price as much as stability, so they are somewhat\n> >>at odds with hodlers.\n> >\n> > As of this moment, BT1 / BT2 price ratio in BitFinex is slightly higher\n> than\n> > 7 : 1.  Twice the transaction rate cannot overcome this price ratio\n> > difference.  Even if you were to claim that the BitFinex data is off by a\n> > factor of 3, twice the transaction rate still cannot overcome the price\n> > ratio difference.  Do you have stronger data than what is available on\n> > BitFinex?  If not, your assumptions are incorrect and all conclusions\n> > suspect.\n> >\n> >\n> >>Bitcoin consensus truth is based on \"might is right\". Buyers and\n> >>sellers of goods and services (\"users\") can shift some might to miners\n> >>via fees, to the chagrin of hodlers who have more interest in security\n> >>and price increases. Some hodlers think meeting user needs is the\n> >>source of long term value. Others think mining infrastructure is.\n> >\n> > Mining infrastructure follows price.  If bitcoins were still trading at 1\n> > USD per coin, nobody will build mining infrastructure to the same level\n> as\n> > today, with 5000 USD per coin.\n> >\n> > Price will follow user needs, i.e. demand.\n> >\n> >>You\n> >>seem to require hodlers to correctly identify and rely solely on good\n> >>developers.\n> >\n> > For the very specific case of 2X, it is very easy to make this\n> > identification.  Even without understanding the work being done, one can\n> > reasonably say that it is far more likely that a loose group of 100 or\n> more\n> > developers will contain a few good or excellent developers, than a group\n> of\n> > a few developers containing a similar number of good or excellent\n> > developers.\n> >\n> > User needs will get met only on the chain that good developers work on.\n> > Bitcoin today has too many limitations: viruses on Windows can steal all\n> > your money, fee estimates consistently overestimate, fees rise during\n> > spamming attacks, easy to lose psuedonymity, tiny UTXOs are infeasible to\n> > spend, cannot support dozens of thousands of transactions per second.\n> > Rationally, long-term hodlers will select a chain with better developers\n> who\n> > are more likely to discover or innovate methods to reduce, eliminate, or\n> > sidestep those limitations.  Perhaps the balance will change in the\n> future,\n> > but it is certainly not the balance now, and thus any difficulty\n> algorithm\n> > change in response to the current situation will be premature, and far\n> more\n> > likely to cause disaster than avert one.\n> >\n> >>Whatever combination of these is the case, bad money can\n> >>still drive out good, especially if the market determination is not\n> >>efficient.\n> >>\n> >>A faster measurement of hashrate for difficulty enables the economic\n> >>determination to be more efficient and correct. It prevents the\n> >>biggest coin from bullying forks that have better ideas. Conversely,\n> >>it prevents miners from switching to an inferior coin simply because\n> >>it provides them with more \"protection money\" from fees that enables\n> >>them to bully Bitcoin Core out of existence, even in the presence of a\n> >>slightly larger hodler support.\n> >\n> > This requires that all chains follow the same difficulty adjustment:\n> after\n> > all, it is also entirely the possibility that 2X will be the\n> lower-hashrate\n> > coin in a few months, with the Core chain bullying them out of existence.\n> > Perhaps you should cross-post your analysis to bitcoin-segwit2x also.\n> After\n> > all, the 2X developers should also want to have faster price discovery of\n> > the true price of 2X, away from the unfavorable (incorrect?) pricing on\n> > BitFinex.\n> >\n> >>Devs are a governing authority under the influence of users, hodlers,\n> >>and miners. Miners are like banks lobbying government for higher total\n> >>fees. Hodlers are the new 1%, holding 90% of the coin, lobbying both\n> >>devs and users for security, but equally interested in price\n> >>increases. Users are \"the people\" that devs need to protect against\n> >>both hodlers and miners. They do not care about price as long as it is\n> >>stable. They do not want to become the 99% owning 10% of the coin or\n> >>have to pay unecessary fees merely for their coin to be the biggest\n> >>bully on the block. A faster responding difficulty will take a lot of\n> >>hot air out of the bully. It prevents miners from being able to\n> >>dictate that only coins with high fees are allowed. They are less\n> >>able to destroy small coins that have a fast defense.\n> >>\n> >>The 1% and banks would starve the people that feed them to death if\n> >>they were allowed complete control of the government. Are hodlers and\n> >>miners any wiser?\n> >\n> > Are developers any wiser, either?\n> >\n> > Then consider this wisdom: The fewer back-incompatible changes to a coin,\n> > the better.  Hardforks of any kind are an invitation to disaster and, at\n> > this point, require massive coordination effort which cannot be feasibly\n> > done within a month.  Fast market determination can be done using\n> off-chain\n> > methods (such as on-exchange trades), and are generally robust against\n> > temporary problems on-chain, although admittedly there is a counterparty\n> > risk involved.  The coin works, and in general there is usually very\n> little\n> > need to fix it, especially using dangerous hardforks.\n> >\n> >>Devs need to strive for an expansion of the coin\n> >>quantity to keep value constant which is the foundation of the 5\n> >>characteristics of an ideal currency.\n> >\n> > Is that your goal?  This is a massive departure from the conception of\n> > Bitcoin as having a fixed limit and effectively becoming deflationary.\n> It\n> > will also lead to massive economic distortions in favor of those who\n> receive\n> > newly-minted coins.  I doubt any developer would want to have this\n> property.\n> >\n> > Regards,\n> > ZmnSCPxj\n>\n>\n> ------------------------------\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n> End of bitcoin-dev Digest, Vol 29, Issue 21\n> *******************************************\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171013/6f6c73fc/attachment-0001.html>"
            },
            {
                "author": "Scott Roberts",
                "date": "2017-10-13T13:57:33",
                "message_text_only": "> ZmnSCPxj wrote\n>> Mining infrastructure follows price.\n\nIlansky wrote:\n> In the case of bitcoin, it is the price that follows mining infrastructures.\n\nI generally agree with ZmnSCPxj that\ngood ideas => good devs => hodlers => price => mining\n\nExcept that each step is not an absolute, and can be biased by things\nlike miners who seek profit via fees and other means that are not good\nfor everyone else. Llansky's belief itself influences price away from\nthe ideal. Marketing \"easy profits for hodlers!\" and first-to-market\nmonopoly are other elements that influence price and thereby guide\nmining away from good ideas (like a constant value currency). Then\nprice pulls in good devs that pulls in more mining. So it can snowball\ninto a monster.\n\nWe need not debate cause and effect since it's distant from the list's\ngoals. The relevance to me is that the biases away from ZmnSCPxj's\nideal are a reason a more responsive difficulty is needed.\n\nMining is for determining truth of the blockchain, not to make sure\nthere is only 1 blockchain. ZmnSCPxj indicates we should not do\nanything that has more precision or speed in determining the correct\ndifficulty if it reduces Bitcoin's ability to be a monopoly. Not\ncoincidentally, the monopoly helps ensure hodlers become the new 1%. A\nfork clone that uses the faster difficulty would attack BTC's slow\ndifficulty if it achieves a comparable price. All other things being\nequal, it would lower BTC's value until it forks to fix the\ndifficulty.\n\nOn Fri, Oct 13, 2017 at 8:27 AM, Ilan Oh via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> Mining infrastructure follows price.  If bitcoins were still trading at 1\n>> USD per coin, nobody will build mining infrastructure to the same level as\n>> today, with 5000 USD per coin.\n>\n> In the case of bitcoin, it is the price that follows mining infrastructures.\n> The price is at 5000 because it is difficult to mine bitcoin not the other\n> way around, like you mention it. Even with a fixed demand, price would go up\n> as difficulty grow, the supply guide the market. There is a strong incentive\n> to mine blindly as it is difficult to estimate for a miner where is the\n> actual demand, with a start up currency without actual economic support.\n> Indeed at the genesis of this \"mining-price\" cycle the incentive was to\n> contribute to a network and create ones own supply, and not respond to a\n> demand.\n>\n> Ilansky\n>\n> Le 13 oct. 2017 13:55, <bitcoin-dev-request at lists.linuxfoundation.org> a\n> \u00e9crit :\n>>\n>> Send bitcoin-dev mailing list submissions to\n>>         bitcoin-dev at lists.linuxfoundation.org\n>>\n>> To subscribe or unsubscribe via the World Wide Web, visit\n>>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> or, via email, send a message with subject or body 'help' to\n>>         bitcoin-dev-request at lists.linuxfoundation.org\n>>\n>> You can reach the person managing the list at\n>>         bitcoin-dev-owner at lists.linuxfoundation.org\n>>\n>> When replying, please edit your Subject line so it is more specific\n>> than \"Re: Contents of bitcoin-dev digest...\"\n>>\n>>\n>> Today's Topics:\n>>\n>>    1. Re: New difficulty algorithm part 2 (ZmnSCPxj)\n>>    2. Re: New difficulty algorithm part 2 (Scott Roberts)\n>>\n>>\n>> ----------------------------------------------------------------------\n>>\n>> Message: 1\n>> Date: Fri, 13 Oct 2017 00:45:33 -0400\n>> From: ZmnSCPxj <ZmnSCPxj at protonmail.com>\n>> To: Scott Roberts <wordsgalore at gmail.com>\n>> Cc: \"bitcoin-dev at lists.linuxfoundation.org\"\n>>         <bitcoin-dev at lists.linuxfoundation.org>\n>> Subject: Re: [bitcoin-dev] New difficulty algorithm part 2\n>> Message-ID:\n>>\n>> <Hr8ORNHzR76wNhJHoagwXi2ewQ1qYSZScH0xeltVnqid2ljOowc2bj8-rkbdukpk9eyoPx1ReOZSUsNrcowRU9gL5UbKtblkQn2SUo06BHE=@protonmail.com>\n>>\n>> Content-Type: text/plain; charset=\"utf-8\"\n>>\n>> Good morning,\n>>\n>> >ZmnSCPxj wrote:\n>> >> Thus even if the unwanted chain provides 2 tokens as fee per block,\n>> >> whereas the wanted chain provides 1 token as fee per block, if the\n>> >> unwanted chain tokens are valued at 1/4 the wanted chain tokens, miners\n>> >> will still prefer the wanted chain regardless.\n>> >\n>> >This is a good point I was not thinking about, but your math assumes\n>> >1/2 price for a coin that can do 2x more transactions. Holders like\n>> >Roger Ver have an interest in low price and more transactions. A coin\n>> >with 2x more transactions, 22% lower price, and 22% lower fees per\n>> >coin transferred will attract more merchants, customers, and miners\n>> >(they get 50% more total fees) and this will in turn attract more\n>> >hodlers and devs. This assumes it outweighs hodler security concerns.\n>> >Merchants and customers, to the extent they are not long term hodlers,\n>> >are not interested in price as much as stability, so they are somewhat\n>> >at odds with hodlers.\n>>\n>> As of this moment, BT1 / BT2 price ratio in BitFinex is slightly higher\n>> than 7 : 1.  Twice the transaction rate cannot overcome this price ratio\n>> difference.  Even if you were to claim that the BitFinex data is off by a\n>> factor of 3, twice the transaction rate still cannot overcome the price\n>> ratio difference.  Do you have stronger data than what is available on\n>> BitFinex?  If not, your assumptions are incorrect and all conclusions\n>> suspect.\n>>\n>> >Bitcoin consensus truth is based on \"might is right\". Buyers and\n>> >sellers of goods and services (\"users\") can shift some might to miners\n>> >via fees, to the chagrin of hodlers who have more interest in security\n>> >and price increases. Some hodlers think meeting user needs is the\n>> >source of long term value. Others think mining infrastructure is.\n>>\n>> Mining infrastructure follows price.  If bitcoins were still trading at 1\n>> USD per coin, nobody will build mining infrastructure to the same level as\n>> today, with 5000 USD per coin.\n>>\n>> Price will follow user needs, i.e. demand.\n>>\n>> >You\n>> >seem to require hodlers to correctly identify and rely solely on good\n>> >developers.\n>>\n>> For the very specific case of 2X, it is very easy to make this\n>> identification.  Even without understanding the work being done, one can\n>> reasonably say that it is far more likely that a loose group of 100 or more\n>> developers will contain a few good or excellent developers, than a group of\n>> a few developers containing a similar number of good or excellent\n>> developers.\n>>\n>> User needs will get met only on the chain that good developers work on.\n>> Bitcoin today has too many limitations: viruses on Windows can steal all\n>> your money, fee estimates consistently overestimate, fees rise during\n>> spamming attacks, easy to lose psuedonymity, tiny UTXOs are infeasible to\n>> spend, cannot support dozens of thousands of transactions per second.\n>> Rationally, long-term hodlers will select a chain with better developers who\n>> are more likely to discover or innovate methods to reduce, eliminate, or\n>> sidestep those limitations.  Perhaps the balance will change in the future,\n>> but it is certainly not the balance now, and thus any difficulty algorithm\n>> change in response to the current situation will be premature, and far more\n>> likely to cause disaster than avert one.\n>>\n>> >Whatever combination of these is the case, bad money can\n>> >still drive out good, especially if the market determination is not\n>> >efficient.\n>> >\n>> >A faster measurement of hashrate for difficulty enables the economic\n>> >determination to be more efficient and correct. It prevents the\n>> >biggest coin from bullying forks that have better ideas. Conversely,\n>> >it prevents miners from switching to an inferior coin simply because\n>> >it provides them with more \"protection money\" from fees that enables\n>> >them to bully Bitcoin Core out of existence, even in the presence of a\n>> >slightly larger hodler support.\n>>\n>> This requires that all chains follow the same difficulty adjustment: after\n>> all, it is also entirely the possibility that 2X will be the lower-hashrate\n>> coin in a few months, with the Core chain bullying them out of existence.\n>> Perhaps you should cross-post your analysis to bitcoin-segwit2x also.  After\n>> all, the 2X developers should also want to have faster price discovery of\n>> the true price of 2X, away from the unfavorable (incorrect?) pricing on\n>> BitFinex.\n>>\n>> >Devs are a governing authority under the influence of users, hodlers,\n>> >and miners. Miners are like banks lobbying government for higher total\n>> >fees. Hodlers are the new 1%, holding 90% of the coin, lobbying both\n>> >devs and users for security, but equally interested in price\n>> >increases. Users are \"the people\" that devs need to protect against\n>> >both hodlers and miners. They do not care about price as long as it is\n>> >stable. They do not want to become the 99% owning 10% of the coin or\n>> >have to pay unecessary fees merely for their coin to be the biggest\n>> >bully on the block. A faster responding difficulty will take a lot of\n>> >hot air out of the bully. It prevents miners from being able to\n>> >dictate that only coins with high fees are allowed. They are less\n>> >able to destroy small coins that have a fast defense.\n>> >\n>> >The 1% and banks would starve the people that feed them to death if\n>> >they were allowed complete control of the government. Are hodlers and\n>> >miners any wiser?\n>>\n>> Are developers any wiser, either?\n>>\n>> Then consider this wisdom: The fewer back-incompatible changes to a coin,\n>> the better.  Hardforks of any kind are an invitation to disaster and, at\n>> this point, require massive coordination effort which cannot be feasibly\n>> done within a month.  Fast market determination can be done using off-chain\n>> methods (such as on-exchange trades), and are generally robust against\n>> temporary problems on-chain, although admittedly there is a counterparty\n>> risk involved.  The coin works, and in general there is usually very little\n>> need to fix it, especially using dangerous hardforks.\n>>\n>> >Devs need to strive for an expansion of the coin\n>> >quantity to keep value constant which is the foundation of the 5\n>> >characteristics of an ideal currency.\n>>\n>> Is that your goal?  This is a massive departure from the conception of\n>> Bitcoin as having a fixed limit and effectively becoming deflationary.  It\n>> will also lead to massive economic distortions in favor of those who receive\n>> newly-minted coins.  I doubt any developer would want to have this property.\n>>\n>> Regards,\n>> ZmnSCPxj\n>> -------------- next part --------------\n>> An HTML attachment was scrubbed...\n>> URL:\n>> <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171013/1afdebf0/attachment.html>\n>>\n>> ------------------------------\n>>\n>> Message: 2\n>> Date: Fri, 13 Oct 2017 07:35:09 -0400\n>> From: Scott Roberts <wordsgalore at gmail.com>\n>> To: ZmnSCPxj <ZmnSCPxj at protonmail.com>\n>> Cc: \"bitcoin-dev at lists.linuxfoundation.org\"\n>>         <bitcoin-dev at lists.linuxfoundation.org>\n>> Subject: Re: [bitcoin-dev] New difficulty algorithm part 2\n>> Message-ID:\n>>\n>> <CADtTMvnrZp=JD4rkXQOZAPNS9BMNMqnTyfA65PRzZhWs+VxgHA at mail.gmail.com>\n>> Content-Type: text/plain; charset=\"UTF-8\"\n>>\n>> Yes, the current price ratio indicates there is no need for a new\n>> difficulty algorithm. I do not desire to fork before a disaster, or to\n>> otherwise employ a new difficulty before a fork is otherwise needed.\n>>\n>> A 2-week delay in difficulty response is a 2 week error in\n>> measurement. Slow response generally means less intelligence.\n>>\n>> My goal is not to have a bunch of BTC clones that merchants and buyers\n>> use equally, but to have a  better difficulty algorithm in place to be\n>> used in the next BTC \"Core\" fork. If not for the current situation,\n>> then for future security.\n>>\n>> >  This is a massive departure from the conception of Bitcoin as having a\n>> > fixed limit and effectively becoming deflationary.\n>>\n>> You mean multiple forks is inflationary. The current limit in quantity\n>> is deflationary because the use of the coin is rising faster than its\n>> mining is producing (see velocity of money). Constant value is defined\n>> as being neither. Bitcoin's deflationary quality created a massive\n>> marketing advantage as well as paid the creator about million dollars\n>> an hour. If it suddenly were able to be a constant value coin, its use\n>> in the marketplace and as a real store of value would skyrocket and\n>> the cries of \"Ponzi scheme\" would stop. The trick is in determining\n>> constant value without a 3rd party such as an index of a basket of\n>> commodities (which both Keynes and von Mises wanted, but was scuttled\n>> by the U.S. at Bretton Woods).\n>>\n>> On Fri, Oct 13, 2017 at 12:45 AM, ZmnSCPxj <ZmnSCPxj at protonmail.com>\n>> wrote:\n>> > Good morning,\n>> >\n>> >\n>> >>ZmnSCPxj wrote:\n>> >>> Thus even if the unwanted chain provides 2 tokens as fee per block,\n>> >>> whereas the wanted chain provides 1 token as fee per block, if the\n>> >>> unwanted chain tokens are valued at 1/4 the wanted chain tokens,\n>> >>> miners\n>> >>> will still prefer the wanted chain regardless.\n>> >>\n>> >>This is a good point I was not thinking about, but your math assumes\n>> >>1/2 price for a coin that can do 2x more transactions. Holders like\n>> >>Roger Ver have an interest in low price and more transactions. A coin\n>> >>with 2x more transactions, 22% lower price, and 22% lower fees per\n>> >>coin transferred will attract more merchants, customers, and miners\n>> >>(they get 50% more total fees) and this will in turn attract more\n>> >>hodlers and devs. This assumes it outweighs hodler security concerns.\n>> >>Merchants and customers, to the extent they are not long term hodlers,\n>> >>are not interested in price as much as stability, so they are somewhat\n>> >>at odds with hodlers.\n>> >\n>> > As of this moment, BT1 / BT2 price ratio in BitFinex is slightly higher\n>> > than\n>> > 7 : 1.  Twice the transaction rate cannot overcome this price ratio\n>> > difference.  Even if you were to claim that the BitFinex data is off by\n>> > a\n>> > factor of 3, twice the transaction rate still cannot overcome the price\n>> > ratio difference.  Do you have stronger data than what is available on\n>> > BitFinex?  If not, your assumptions are incorrect and all conclusions\n>> > suspect.\n>> >\n>> >\n>> >>Bitcoin consensus truth is based on \"might is right\". Buyers and\n>> >>sellers of goods and services (\"users\") can shift some might to miners\n>> >>via fees, to the chagrin of hodlers who have more interest in security\n>> >>and price increases. Some hodlers think meeting user needs is the\n>> >>source of long term value. Others think mining infrastructure is.\n>> >\n>> > Mining infrastructure follows price.  If bitcoins were still trading at\n>> > 1\n>> > USD per coin, nobody will build mining infrastructure to the same level\n>> > as\n>> > today, with 5000 USD per coin.\n>> >\n>> > Price will follow user needs, i.e. demand.\n>> >\n>> >>You\n>> >>seem to require hodlers to correctly identify and rely solely on good\n>> >>developers.\n>> >\n>> > For the very specific case of 2X, it is very easy to make this\n>> > identification.  Even without understanding the work being done, one can\n>> > reasonably say that it is far more likely that a loose group of 100 or\n>> > more\n>> > developers will contain a few good or excellent developers, than a group\n>> > of\n>> > a few developers containing a similar number of good or excellent\n>> > developers.\n>> >\n>> > User needs will get met only on the chain that good developers work on.\n>> > Bitcoin today has too many limitations: viruses on Windows can steal all\n>> > your money, fee estimates consistently overestimate, fees rise during\n>> > spamming attacks, easy to lose psuedonymity, tiny UTXOs are infeasible\n>> > to\n>> > spend, cannot support dozens of thousands of transactions per second.\n>> > Rationally, long-term hodlers will select a chain with better developers\n>> > who\n>> > are more likely to discover or innovate methods to reduce, eliminate, or\n>> > sidestep those limitations.  Perhaps the balance will change in the\n>> > future,\n>> > but it is certainly not the balance now, and thus any difficulty\n>> > algorithm\n>> > change in response to the current situation will be premature, and far\n>> > more\n>> > likely to cause disaster than avert one.\n>> >\n>> >>Whatever combination of these is the case, bad money can\n>> >>still drive out good, especially if the market determination is not\n>> >>efficient.\n>> >>\n>> >>A faster measurement of hashrate for difficulty enables the economic\n>> >>determination to be more efficient and correct. It prevents the\n>> >>biggest coin from bullying forks that have better ideas. Conversely,\n>> >>it prevents miners from switching to an inferior coin simply because\n>> >>it provides them with more \"protection money\" from fees that enables\n>> >>them to bully Bitcoin Core out of existence, even in the presence of a\n>> >>slightly larger hodler support.\n>> >\n>> > This requires that all chains follow the same difficulty adjustment:\n>> > after\n>> > all, it is also entirely the possibility that 2X will be the\n>> > lower-hashrate\n>> > coin in a few months, with the Core chain bullying them out of\n>> > existence.\n>> > Perhaps you should cross-post your analysis to bitcoin-segwit2x also.\n>> > After\n>> > all, the 2X developers should also want to have faster price discovery\n>> > of\n>> > the true price of 2X, away from the unfavorable (incorrect?) pricing on\n>> > BitFinex.\n>> >\n>> >>Devs are a governing authority under the influence of users, hodlers,\n>> >>and miners. Miners are like banks lobbying government for higher total\n>> >>fees. Hodlers are the new 1%, holding 90% of the coin, lobbying both\n>> >>devs and users for security, but equally interested in price\n>> >>increases. Users are \"the people\" that devs need to protect against\n>> >>both hodlers and miners. They do not care about price as long as it is\n>> >>stable. They do not want to become the 99% owning 10% of the coin or\n>> >>have to pay unecessary fees merely for their coin to be the biggest\n>> >>bully on the block. A faster responding difficulty will take a lot of\n>> >>hot air out of the bully. It prevents miners from being able to\n>> >>dictate that only coins with high fees are allowed. They are less\n>> >>able to destroy small coins that have a fast defense.\n>> >>\n>> >>The 1% and banks would starve the people that feed them to death if\n>> >>they were allowed complete control of the government. Are hodlers and\n>> >>miners any wiser?\n>> >\n>> > Are developers any wiser, either?\n>> >\n>> > Then consider this wisdom: The fewer back-incompatible changes to a\n>> > coin,\n>> > the better.  Hardforks of any kind are an invitation to disaster and, at\n>> > this point, require massive coordination effort which cannot be feasibly\n>> > done within a month.  Fast market determination can be done using\n>> > off-chain\n>> > methods (such as on-exchange trades), and are generally robust against\n>> > temporary problems on-chain, although admittedly there is a counterparty\n>> > risk involved.  The coin works, and in general there is usually very\n>> > little\n>> > need to fix it, especially using dangerous hardforks.\n>> >\n>> >>Devs need to strive for an expansion of the coin\n>> >>quantity to keep value constant which is the foundation of the 5\n>> >>characteristics of an ideal currency.\n>> >\n>> > Is that your goal?  This is a massive departure from the conception of\n>> > Bitcoin as having a fixed limit and effectively becoming deflationary.\n>> > It\n>> > will also lead to massive economic distortions in favor of those who\n>> > receive\n>> > newly-minted coins.  I doubt any developer would want to have this\n>> > property.\n>> >\n>> > Regards,\n>> > ZmnSCPxj\n>>\n>>\n>> ------------------------------\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>> End of bitcoin-dev Digest, Vol 29, Issue 21\n>> *******************************************\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            }
        ],
        "thread_summary": {
            "title": "bitcoin-dev Digest, Vol 29, Issue 21",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Scott Roberts",
                "Ilan Oh"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 38492
        }
    },
    {
        "title": "[bitcoin-dev] Improving Scalability via Block Time Decrease",
        "thread_messages": [
            {
                "author": "Jonathan Sterling",
                "date": "2017-10-19T06:52:48",
                "message_text_only": "The current ten-minute block time was chosen by Satoshi as a tradeoff\nbetween confirmation time and the amount of work wasted due to chain\nsplits. Is there not room for optimization in this number from:\n\nA. Advances in technology in the last 8-9 years\nB. A lack of any rigorous formula being used to determine what's the\noptimal rate\nC. The existence of similar chains that work at a much lower block times\n\nWhilst I think we can all agree that 10 second block times would result in\na lot of chain splits due to Bitcoins 12-13 second propagation time (to 95%\nof nodes), I think we'll find that we can go lower than 10 minutes without\nmuch issue. Is this something that should be looked at or am I an idiot who\nneeds to read more? If I'm an idiot, I apologize; kindly point me in the\nright direction.\n\nThings I've read on the subject:\nhttps://medium.facilelogin.com/the-mystery-behind-block-time-63351e35603a\n(section header \"Why Bitcoin Block Time Is 10 Minutes ?\")\nhttps://bitcointalk.org/index.php?topic=176108.0\nhttps://bitcoin.stackexchange.com/questions/1863/why-was-the-target-block-time-chosen-to-be-10-minutes\n\nKind Regards,\n\nJonathan Sterling\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171019/d940fd4e/attachment.html>"
            },
            {
                "author": "Ad\u00e1n S\u00e1nchez de Pedro Crespo",
                "date": "2017-10-19T13:41:51",
                "message_text_only": "Blockchains with fast confirmation times are currently believed to\nsuffer from reduced security due to a high stale rate.\n\nAs blocks take a certain time to propagate through the network, if miner\nA mines a block and then miner B happens to mine another block before\nminer A's block propagates to B, miner B's block will end up wasted and\nwill not \"contribute to network security\".\n\nFurthermore, there is a centralization issue: if miner A is a mining\npool with 30% hashpower and B has 10% hashpower, A will have a risk of\nproducing a stale block 70% of the time (since the other 30% of the time\nA produced the last block and so will get mining data immediately)\nwhereas B will have a risk of producing a stale block 90% of the time.\n\nThus, if the block interval is short enough for the stale rate\nto be high, A will be substantially more efficient simply by virtue of\nits size. With these two effects combined, blockchains which produce\nblocks quickly are very likely to lead to one mining pool having a large\nenough percentage of the network hashpower to have de facto control over\nthe mining process.\n\nAnother possible implication of reducing the average block time is that\nblock size should be reduced accordingly. In an hypothetical 5 minutes\nblock size Bitcoin blockchain, there would be twice the block space\navailable for miners to include transactions, which could lead to 2\nimmediate consequences: (1) the blockchain could grow up to twice the\nrate, which is known to be bad for decentralization; and (2) transaction\nfees might go down, making it cheaper for spammers to bloat our beloved\nUTXO sets.\n\nThere have been numerous proposals that tried to overcome the downsides\nof faster blocks, the most noteworthy probably being the \"Greedy\nHeaviest Observed Subtree\" (GHOST) protocol:\nhttp://www.cs.huji.ac.il/~yoni_sompo/pubs/15/btc_scalability_full.pdf\n\nPersonally, I can't see why Bitcoin would need or how could it even\nbenefit at all from faster blocks. Nevertheless, I would really love if\nsomeone in the list who has already run the numbers could bring some\nvalid points on why 10 minutes is the optimal rate (other than \"if it\nain't broke, don't fix it\").\n\n-- \nAd\u00e1n S\u00e1nchez de Pedro Crespo\nCTO, Stampery Inc.\nSan Francisco - Madrid"
            }
        ],
        "thread_summary": {
            "title": "Improving Scalability via Block Time Decrease",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Ad\u00e1n S\u00e1nchez de Pedro Crespo",
                "Jonathan Sterling"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 3580
        }
    },
    {
        "title": "[bitcoin-dev] bitcoin-dev Digest, Vol 29, Issue 24",
        "thread_messages": [
            {
                "author": "Ilan Oh",
                "date": "2017-10-20T17:24:34",
                "message_text_only": "The only blocktime reduction that would be a game changer, would be a 1\nsecond blocktime or less, and by less I mean much less maybe 1000\nblocks/second. Which would enable decentralized high frequency trading or\nplaying WoW on blockchain and other cool stuff.\n\nBut technology is not developped enough as far as I now, maybe with quantum\ncomputers in the future, and it is even bitcoins goal?\n\nAlso there is a guy who wrote a script to avoid \"sybil attack\" from 2x\nhttps://github.com/mariodian/ban-segshit8x-nodes\n\nI don't know what it's worth, maybe check it out, I'm not huge support of\nthat kind of methods.\n\nIlansky\n\n\nLe 20 oct. 2017 14:01, <bitcoin-dev-request at lists.linuxfoundation.org> a\n\u00e9crit :\n\n> Send bitcoin-dev mailing list submissions to\n>         bitcoin-dev at lists.linuxfoundation.org\n>\n> To subscribe or unsubscribe via the World Wide Web, visit\n>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> or, via email, send a message with subject or body 'help' to\n>         bitcoin-dev-request at lists.linuxfoundation.org\n>\n> You can reach the person managing the list at\n>         bitcoin-dev-owner at lists.linuxfoundation.org\n>\n> When replying, please edit your Subject line so it is more specific\n> than \"Re: Contents of bitcoin-dev digest...\"\n>\n>\n> Today's Topics:\n>\n>    1. Improving Scalability via Block Time Decrease (Jonathan Sterling)\n>    2. Re: Improving Scalability via Block Time Decrease\n>       (=?UTF-8?Q?Ad=c3=a1n_S=c3=a1nchez_de_Pedro_Crespo?=)\n>\n>\n> ----------------------------------------------------------------------\n>\n> Message: 1\n> Date: Thu, 19 Oct 2017 14:52:48 +0800\n> From: Jonathan Sterling <jon at thancodes.com>\n> To: bitcoin-dev at lists.linuxfoundation.org\n> Subject: [bitcoin-dev] Improving Scalability via Block Time Decrease\n> Message-ID:\n>         <CAH01uEtLhLEj5XOp_MDRii2dR8-zUu4fUsCd25mzLDtpD_fwYQ at mail.\n> gmail.com>\n> Content-Type: text/plain; charset=\"utf-8\"\n>\n> The current ten-minute block time was chosen by Satoshi as a tradeoff\n> between confirmation time and the amount of work wasted due to chain\n> splits. Is there not room for optimization in this number from:\n>\n> A. Advances in technology in the last 8-9 years\n> B. A lack of any rigorous formula being used to determine what's the\n> optimal rate\n> C. The existence of similar chains that work at a much lower block times\n>\n> Whilst I think we can all agree that 10 second block times would result in\n> a lot of chain splits due to Bitcoins 12-13 second propagation time (to 95%\n> of nodes), I think we'll find that we can go lower than 10 minutes without\n> much issue. Is this something that should be looked at or am I an idiot who\n> needs to read more? If I'm an idiot, I apologize; kindly point me in the\n> right direction.\n>\n> Things I've read on the subject:\n> https://medium.facilelogin.com/the-mystery-behind-block-time-63351e35603a\n> (section header \"Why Bitcoin Block Time Is 10 Minutes ?\")\n> https://bitcointalk.org/index.php?topic=176108.0\n> https://bitcoin.stackexchange.com/questions/1863/why-was-\n> the-target-block-time-chosen-to-be-10-minutes\n>\n> Kind Regards,\n>\n> Jonathan Sterling\n> -------------- next part --------------\n> An HTML attachment was scrubbed...\n> URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/\n> attachments/20171019/d940fd4e/attachment-0001.html>\n>\n> ------------------------------\n>\n> Message: 2\n> Date: Thu, 19 Oct 2017 15:41:51 +0200\n> From: \"=?UTF-8?Q?Ad=c3=a1n_S=c3=a1nchez_de_Pedro_Crespo?=\"\n>         <adan at stampery.co>\n> To: bitcoin-dev at lists.linuxfoundation.org\n> Subject: Re: [bitcoin-dev] Improving Scalability via Block Time\n>         Decrease\n> Message-ID: <40b6ef7b-f518-38cd-899a-8f301bc7ac3a at stampery.com>\n> Content-Type: text/plain; charset=utf-8\n>\n> Blockchains with fast confirmation times are currently believed to\n> suffer from reduced security due to a high stale rate.\n>\n> As blocks take a certain time to propagate through the network, if miner\n> A mines a block and then miner B happens to mine another block before\n> miner A's block propagates to B, miner B's block will end up wasted and\n> will not \"contribute to network security\".\n>\n> Furthermore, there is a centralization issue: if miner A is a mining\n> pool with 30% hashpower and B has 10% hashpower, A will have a risk of\n> producing a stale block 70% of the time (since the other 30% of the time\n> A produced the last block and so will get mining data immediately)\n> whereas B will have a risk of producing a stale block 90% of the time.\n>\n> Thus, if the block interval is short enough for the stale rate\n> to be high, A will be substantially more efficient simply by virtue of\n> its size. With these two effects combined, blockchains which produce\n> blocks quickly are very likely to lead to one mining pool having a large\n> enough percentage of the network hashpower to have de facto control over\n> the mining process.\n>\n> Another possible implication of reducing the average block time is that\n> block size should be reduced accordingly. In an hypothetical 5 minutes\n> block size Bitcoin blockchain, there would be twice the block space\n> available for miners to include transactions, which could lead to 2\n> immediate consequences: (1) the blockchain could grow up to twice the\n> rate, which is known to be bad for decentralization; and (2) transaction\n> fees might go down, making it cheaper for spammers to bloat our beloved\n> UTXO sets.\n>\n> There have been numerous proposals that tried to overcome the downsides\n> of faster blocks, the most noteworthy probably being the \"Greedy\n> Heaviest Observed Subtree\" (GHOST) protocol:\n> http://www.cs.huji.ac.il/~yoni_sompo/pubs/15/btc_scalability_full.pdf\n>\n> Personally, I can't see why Bitcoin would need or how could it even\n> benefit at all from faster blocks. Nevertheless, I would really love if\n> someone in the list who has already run the numbers could bring some\n> valid points on why 10 minutes is the optimal rate (other than \"if it\n> ain't broke, don't fix it\").\n>\n> --\n> Ad?n S?nchez de Pedro Crespo\n> CTO, Stampery Inc.\n> San Francisco - Madrid\n>\n>\n> ------------------------------\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n> End of bitcoin-dev Digest, Vol 29, Issue 24\n> *******************************************\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171020/25f557c0/attachment.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-10-20T18:55:55",
                "message_text_only": "You could do that today, with one of the 3 interoperable Lightning implementations available. Lowering the block interval on the other hand comes with a large number of centralizing downsides documented elsewhere. And getting down to 1sec or less on a global network is simply impossible due to the speed of light. \n\nIf you want point of sale support, I suggest looking into the excellent work the Lightning teams have done.\n\n> On Oct 20, 2017, at 7:24 PM, Ilan Oh via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> The only blocktime reduction that would be a game changer, would be a 1 second blocktime or less, and by less I mean much less maybe 1000 blocks/second. Which would enable decentralized high frequency trading or playing WoW on blockchain and other cool stuff. \n> \n> But technology is not developped enough as far as I now, maybe with quantum computers in the future, and it is even bitcoins goal?\n> \n> Also there is a guy who wrote a script to avoid \"sybil attack\" from 2x\n> https://github.com/mariodian/ban-segshit8x-nodes\n> \n> I don't know what it's worth, maybe check it out, I'm not huge support of that kind of methods.\n> \n> Ilansky\n> \n> \n> Le 20 oct. 2017 14:01, <bitcoin-dev-request at lists.linuxfoundation.org> a \u00e9crit :\n>> Send bitcoin-dev mailing list submissions to\n>>         bitcoin-dev at lists.linuxfoundation.org\n>> \n>> To subscribe or unsubscribe via the World Wide Web, visit\n>>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> or, via email, send a message with subject or body 'help' to\n>>         bitcoin-dev-request at lists.linuxfoundation.org\n>> \n>> You can reach the person managing the list at\n>>         bitcoin-dev-owner at lists.linuxfoundation.org\n>> \n>> When replying, please edit your Subject line so it is more specific\n>> than \"Re: Contents of bitcoin-dev digest...\"\n>> \n>> \n>> Today's Topics:\n>> \n>>    1. Improving Scalability via Block Time Decrease (Jonathan Sterling)\n>>    2. Re: Improving Scalability via Block Time Decrease\n>>       (=?UTF-8?Q?Ad=c3=a1n_S=c3=a1nchez_de_Pedro_Crespo?=)\n>> \n>> \n>> ----------------------------------------------------------------------\n>> \n>> Message: 1\n>> Date: Thu, 19 Oct 2017 14:52:48 +0800\n>> From: Jonathan Sterling <jon at thancodes.com>\n>> To: bitcoin-dev at lists.linuxfoundation.org\n>> Subject: [bitcoin-dev] Improving Scalability via Block Time Decrease\n>> Message-ID:\n>>         <CAH01uEtLhLEj5XOp_MDRii2dR8-zUu4fUsCd25mzLDtpD_fwYQ at mail.gmail.com>\n>> Content-Type: text/plain; charset=\"utf-8\"\n>> \n>> The current ten-minute block time was chosen by Satoshi as a tradeoff\n>> between confirmation time and the amount of work wasted due to chain\n>> splits. Is there not room for optimization in this number from:\n>> \n>> A. Advances in technology in the last 8-9 years\n>> B. A lack of any rigorous formula being used to determine what's the\n>> optimal rate\n>> C. The existence of similar chains that work at a much lower block times\n>> \n>> Whilst I think we can all agree that 10 second block times would result in\n>> a lot of chain splits due to Bitcoins 12-13 second propagation time (to 95%\n>> of nodes), I think we'll find that we can go lower than 10 minutes without\n>> much issue. Is this something that should be looked at or am I an idiot who\n>> needs to read more? If I'm an idiot, I apologize; kindly point me in the\n>> right direction.\n>> \n>> Things I've read on the subject:\n>> https://medium.facilelogin.com/the-mystery-behind-block-time-63351e35603a\n>> (section header \"Why Bitcoin Block Time Is 10 Minutes ?\")\n>> https://bitcointalk.org/index.php?topic=176108.0\n>> https://bitcoin.stackexchange.com/questions/1863/why-was-the-target-block-time-chosen-to-be-10-minutes\n>> \n>> Kind Regards,\n>> \n>> Jonathan Sterling\n>> -------------- next part --------------\n>> An HTML attachment was scrubbed...\n>> URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171019/d940fd4e/attachment-0001.html>\n>> \n>> ------------------------------\n>> \n>> Message: 2\n>> Date: Thu, 19 Oct 2017 15:41:51 +0200\n>> From: \"=?UTF-8?Q?Ad=c3=a1n_S=c3=a1nchez_de_Pedro_Crespo?=\"\n>>         <adan at stampery.co>\n>> To: bitcoin-dev at lists.linuxfoundation.org\n>> Subject: Re: [bitcoin-dev] Improving Scalability via Block Time\n>>         Decrease\n>> Message-ID: <40b6ef7b-f518-38cd-899a-8f301bc7ac3a at stampery.com>\n>> Content-Type: text/plain; charset=utf-8\n>> \n>> Blockchains with fast confirmation times are currently believed to\n>> suffer from reduced security due to a high stale rate.\n>> \n>> As blocks take a certain time to propagate through the network, if miner\n>> A mines a block and then miner B happens to mine another block before\n>> miner A's block propagates to B, miner B's block will end up wasted and\n>> will not \"contribute to network security\".\n>> \n>> Furthermore, there is a centralization issue: if miner A is a mining\n>> pool with 30% hashpower and B has 10% hashpower, A will have a risk of\n>> producing a stale block 70% of the time (since the other 30% of the time\n>> A produced the last block and so will get mining data immediately)\n>> whereas B will have a risk of producing a stale block 90% of the time.\n>> \n>> Thus, if the block interval is short enough for the stale rate\n>> to be high, A will be substantially more efficient simply by virtue of\n>> its size. With these two effects combined, blockchains which produce\n>> blocks quickly are very likely to lead to one mining pool having a large\n>> enough percentage of the network hashpower to have de facto control over\n>> the mining process.\n>> \n>> Another possible implication of reducing the average block time is that\n>> block size should be reduced accordingly. In an hypothetical 5 minutes\n>> block size Bitcoin blockchain, there would be twice the block space\n>> available for miners to include transactions, which could lead to 2\n>> immediate consequences: (1) the blockchain could grow up to twice the\n>> rate, which is known to be bad for decentralization; and (2) transaction\n>> fees might go down, making it cheaper for spammers to bloat our beloved\n>> UTXO sets.\n>> \n>> There have been numerous proposals that tried to overcome the downsides\n>> of faster blocks, the most noteworthy probably being the \"Greedy\n>> Heaviest Observed Subtree\" (GHOST) protocol:\n>> http://www.cs.huji.ac.il/~yoni_sompo/pubs/15/btc_scalability_full.pdf\n>> \n>> Personally, I can't see why Bitcoin would need or how could it even\n>> benefit at all from faster blocks. Nevertheless, I would really love if\n>> someone in the list who has already run the numbers could bring some\n>> valid points on why 10 minutes is the optimal rate (other than \"if it\n>> ain't broke, don't fix it\").\n>> \n>> --\n>> Ad?n S?nchez de Pedro Crespo\n>> CTO, Stampery Inc.\n>> San Francisco - Madrid\n>> \n>> \n>> ------------------------------\n>> \n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> \n>> \n>> End of bitcoin-dev Digest, Vol 29, Issue 24\n>> *******************************************\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171020/065c4aa9/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "bitcoin-dev Digest, Vol 29, Issue 24",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Mark Friedenbach",
                "Ilan Oh"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 14112
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Core build system (automake vs cmake)",
        "thread_messages": [
            {
                "author": "Kosta Zertsekel",
                "date": "2017-10-22T17:11:09",
                "message_text_only": "Hi guys,\n\nI wonder why automake has become the build system for Bitcoin Core?\nI mean - why not cmake which is considered better?\nCan you please point to the relevant discussion or explanation?\n\nThanks,\n--- Kosta Z.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171022/adc0c0f3/attachment.html>"
            },
            {
                "author": "Kosta Zertsekel",
                "date": "2017-10-23T11:52:04",
                "message_text_only": ">> On Oct 22, 2017, at 13:11, Kosta Zertsekel wrote:\n>> I wonder why automake has become the build system for Bitcoin Core?\n>> I mean - why not cmake which is considered better?\n>> Can you please point to the relevant discussion or explanation?\n\n> On Mon, Oct 23, 2017 at 6:24 AM, Jeffrey Paul <jp at eeqj.com> wrote:\n> Considered by whom? Automake is the standard and I prefer it as it\nrequires\n> no additional install on most systems. For that, I consider it better.\n\nWell, here are some quotes about CMake build tools...\n\nJetBrains (2014)\n================\nOur brief research showed that CMake and \u2018make\u2019 were the most popular\ncross-platform tools, having ~30% of users each, while both Autotools\nand qmake had less than 7% of users. So we ended up with CMake and make.\n[https://blog.jetbrains.com/clion/2014/09/cmake-vs-the-others-round-1/]\n\nKDE Project (2006)\n==================\nNow the next big change is happening: KDE is leaving the aging \"autotool\"\nbuild chain behind. Some developers, not only in KDE, like to nickname\nthe autotools as \"auto-hell\" because of its difficult to comprehend\narchitecture. So, KDE 4 will feature a completely different build system:\nCMake.\n[https://lwn.net/Articles/188693/]\n\nAlso, there are more advanced build systems:\n============================================\n - Meson [http://mesonbuild.com]\n - Ninja [https://ninja-build.org/]\n\nAll of them (CMake, Meson, Ninja) had a goal to replace automake.\nWas there any discussion about choosing the best build system for\nBitcoin Core?\n\nThanks,\n--- Kosta Z.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171023/b9f4437e/attachment.html>"
            },
            {
                "author": "Thomas Guyot-Sionnest",
                "date": "2017-10-24T15:25:19",
                "message_text_only": "On 23/10/17 07:52 AM, Kosta Zertsekel via bitcoin-dev wrote:\n> >> On Oct 22, 2017, at 13:11, Kosta Zertsekel wrote:\n> >> I wonder why automake has become the build system for Bitcoin Core?\n> >> I mean - why not cmake which is considered better?\n> >> Can you please point to the relevant discussion or explanation?\n>\n> > On Mon, Oct 23, 2017 at 6:24 AM, Jeffrey Paul <jp at eeqj.com\n> <mailto:jp at eeqj.com>> wrote:\n> > Considered by whom? Automake is the standard and I prefer it as it\n> requires\n> > no additional install on most systems. For that, I consider it better.\n>\n> Well, here are some quotes about CMake build tools...\n>\n> [...]\n>\n> All of them (CMake, Meson, Ninja) had a goal to replace automake.\n> Was there any discussion about choosing the best build system for\n> Bitcoin Core?\n\nWhat exact problem are you trying to fix for bitcoin-core?\n\nEach build system have their pros and cons, and what you need it the\nright tool for the job. Unless there is a specific problem to solve and\nthat cmake can solve it without causing other issues, why would you want\nto change?\n\nOr better yet, convert yourself bitcoin-core to cmake and show the\ndevelopers that it makes build config simpler without scarifying\nfeatures (cross-platform builds, gitian...) then maybe they'll adopt it.\n\nRegards,\n\n-- \nThomas"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Core build system (automake vs cmake)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Thomas Guyot-Sionnest",
                "Kosta Zertsekel"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 3428
        }
    },
    {
        "title": "[bitcoin-dev] Visually Differentiable - Bitcoin Addresses",
        "thread_messages": [
            {
                "author": "shiva sitamraju",
                "date": "2017-10-30T08:56:40",
                "message_text_only": "Hi,\n\nWhen I copy and paste bitcoin address, I double check the first few bytes,\nto make sure I copied the correct one. This is to make sure some rogue\nsoftware is not changing the address, or I incorrectly pasted the wrong\naddress.\n\n\nWith Bech32 address, its seems like in this department we are taking as\nstep in the backward direction. With the traditional address, I could\ncompare first few bytes like 1Ko or 1L3. With bech32, bc1. is all I can see\nand compare which is likely to be same anyway. Note that most users will\nonly compare the first few bytes only (since addresses themselves are very\nlong and will overflow in a mobile text box).\n\nIs there anyway to make the Bech32 addresses format more visually distinct\n(atleast the first few bytes) ?\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171030/66bd249b/attachment.html>"
            },
            {
                "author": "Ricardo Filipe",
                "date": "2017-10-30T12:14:42",
                "message_text_only": "start double checking the last few bytes instead?\n\n2017-10-30 8:56 GMT+00:00 shiva sitamraju via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org>:\n> Hi,\n>\n> When I copy and paste bitcoin address, I double check the first few bytes,\n> to make sure I copied the correct one. This is to make sure some rogue\n> software is not changing the address, or I incorrectly pasted the wrong\n> address.\n>\n>\n> With Bech32 address, its seems like in this department we are taking as step\n> in the backward direction. With the traditional address, I could compare\n> first few bytes like 1Ko or 1L3. With bech32, bc1. is all I can see and\n> compare which is likely to be same anyway. Note that most users will only\n> compare the first few bytes only (since addresses themselves are very long\n> and will overflow in a mobile text box).\n>\n> Is there anyway to make the Bech32 addresses format more visually distinct\n> (atleast the first few bytes) ?\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Ben Thompson",
                "date": "2017-10-30T14:23:51",
                "message_text_only": "The last few bytes can be generated to be the same also.\n\nOn Mon, 30 Oct 2017, 14:20 Ricardo Filipe via bitcoin-dev, <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> start double checking the last few bytes instead?\n>\n> 2017-10-30 8:56 GMT+00:00 shiva sitamraju via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org>:\n> > Hi,\n> >\n> > When I copy and paste bitcoin address, I double check the first few\n> bytes,\n> > to make sure I copied the correct one. This is to make sure some rogue\n> > software is not changing the address, or I incorrectly pasted the wrong\n> > address.\n> >\n> >\n> > With Bech32 address, its seems like in this department we are taking as\n> step\n> > in the backward direction. With the traditional address, I could compare\n> > first few bytes like 1Ko or 1L3. With bech32, bc1. is all I can see and\n> > compare which is likely to be same anyway. Note that most users will only\n> > compare the first few bytes only (since addresses themselves are very\n> long\n> > and will overflow in a mobile text box).\n> >\n> > Is there anyway to make the Bech32 addresses format more visually\n> distinct\n> > (atleast the first few bytes) ?\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171030/d84f94d4/attachment-0001.html>"
            },
            {
                "author": "Ben Thompson",
                "date": "2017-10-30T12:49:18",
                "message_text_only": "Checking the first few bytes of a Bitcoin Address should not be considered\nsufficient for ensuring that it is correct as it takes less than a second\nto generate a 3 character vanity address that matches the first 3\ncharacters of an address.\n\nOn Mon, 30 Oct 2017, 11:44 shiva sitamraju via bitcoin-dev, <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi,\n>\n> When I copy and paste bitcoin address, I double check the first few bytes,\n> to make sure I copied the correct one. This is to make sure some rogue\n> software is not changing the address, or I incorrectly pasted the wrong\n> address.\n>\n>\n> With Bech32 address, its seems like in this department we are taking as\n> step in the backward direction. With the traditional address, I could\n> compare first few bytes like 1Ko or 1L3. With bech32, bc1. is all I can see\n> and compare which is likely to be same anyway. Note that most users will\n> only compare the first few bytes only (since addresses themselves are very\n> long and will overflow in a mobile text box).\n>\n> Is there anyway to make the Bech32 addresses format more visually distinct\n> (atleast the first few bytes) ?\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171030/f3848a6e/attachment.html>"
            },
            {
                "author": "shiva sitamraju",
                "date": "2017-10-30T13:13:56",
                "message_text_only": "For example bc1qeklep85ntjz4605drds6aww9u0qr46qzrv5xswd35uhjuj8ahfcqgf6hak\nin 461e8a4aa0a0e75c06602c505bd7aa06e7116ba5cd98fd6e046e8cbeb00379d6 is 62\nbytes ! This is very very long. This will create lot of usability problems\nin\n\n- Blockexplorers (atleast user should be visually able to compare in a\ntransaction having multiple outputs which one his address)\n- Mobiles\n- Payment terminals\n\n>From my limited understanding, the purpose of inventing a bitcoin address\nformat is for usability and ease of identification (versus a ECDSA public\nkey), While I get the error/checksum capabilities Bech32 brings, any user\nwould prefer a 20 byte address with a checksum  over an address that would\nwrap several lines !!\n\n\nOn Mon, Oct 30, 2017 at 6:19 PM, Ben Thompson <\nthompson.benedictjames at gmail.com> wrote:\n\n> Checking the first few bytes of a Bitcoin Address should not be considered\n> sufficient for ensuring that it is correct as it takes less than a second\n> to generate a 3 character vanity address that matches the first 3\n> characters of an address.\n>\n> On Mon, 30 Oct 2017, 11:44 shiva sitamraju via bitcoin-dev, <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi,\n>>\n>> When I copy and paste bitcoin address, I double check the first few\n>> bytes, to make sure I copied the correct one. This is to make sure some\n>> rogue software is not changing the address, or I incorrectly pasted the\n>> wrong address.\n>>\n>>\n>> With Bech32 address, its seems like in this department we are taking as\n>> step in the backward direction. With the traditional address, I could\n>> compare first few bytes like 1Ko or 1L3. With bech32, bc1. is all I can see\n>> and compare which is likely to be same anyway. Note that most users will\n>> only compare the first few bytes only (since addresses themselves are very\n>> long and will overflow in a mobile text box).\n>>\n>> Is there anyway to make the Bech32 addresses format more visually\n>> distinct (atleast the first few bytes) ?\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171030/ae11b543/attachment.html>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2017-10-30T14:26:29",
                "message_text_only": "On Oct 30, 2017 15:21, \"shiva sitamraju via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\nFor example bc1qeklep85ntjz4605drds6aww9u0qr46qzrv5xswd35uhjuj8ahfcqgf6hak\nin 461e8a4aa0a0e75c06602c505bd7aa06e7116ba5cd98fd6e046e8cbeb00379d6 is 62\nbytes !\n\n\n...\n\nWhile I get the error/checksum capabilities Bech32 brings, any user would\nprefer a 20 byte address with a checksum  over an address that would wrap\nseveral lines !!\n\n\nThat's an unfair comparison. You're pasting a P2WSH address which contains\na 256-bit hash.\n\nA P2WPKH address (which only contains a 160-bit hash, just like P2PKH and\nP2SH) in Bech32 is only 42 characters, not 62.\n\nCheers,\n\n-- \nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171030/00d5cdc5/attachment.html>"
            },
            {
                "author": "Moral Agent",
                "date": "2017-10-30T14:39:07",
                "message_text_only": "If you are going to rely on human verification of addresses, the best way\nmight be map it to words.\n\nFor example, with a 6000 word list, a 25 byte address (with a checksum)\ncould be mapped to 16 words like this:\n\nvocally           acquire        removed     unfounded\neuphemism    sanctuary    sectional     driving\nentree            freckles    aloof           vertebrae\nscribble          surround      prelaw         effort\n\nIn my opinion, that is much faster to verify than this:\n\n13gQFTYHuAcfnZjXo2NFsy1E8JGSLwXHCZ\n\nor\n\nbc1qrp33g0q5c5txsp9arysrx4k6zdkfs4nce4xj0gdcccefvpysxf3qccfmv3\n\nAlthough I really do love Bech32.\n\nOn Mon, Oct 30, 2017 at 9:13 AM, shiva sitamraju via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> For example bc1qeklep85ntjz4605drds6aww9u0qr46qzrv5xswd35uhjuj8ahfcqgf6hak\n> in 461e8a4aa0a0e75c06602c505bd7aa06e7116ba5cd98fd6e046e8cbeb00379d6 is 62\n> bytes ! This is very very long. This will create lot of usability problems\n> in\n>\n> - Blockexplorers (atleast user should be visually able to compare in a\n> transaction having multiple outputs which one his address)\n> - Mobiles\n> - Payment terminals\n>\n> From my limited understanding, the purpose of inventing a bitcoin address\n> format is for usability and ease of identification (versus a ECDSA public\n> key), While I get the error/checksum capabilities Bech32 brings, any user\n> would prefer a 20 byte address with a checksum  over an address that would\n> wrap several lines !!\n>\n>\n> On Mon, Oct 30, 2017 at 6:19 PM, Ben Thompson <\n> thompson.benedictjames at gmail.com> wrote:\n>\n>> Checking the first few bytes of a Bitcoin Address should not be\n>> considered sufficient for ensuring that it is correct as it takes less than\n>> a second to generate a 3 character vanity address that matches the first 3\n>> characters of an address.\n>>\n>> On Mon, 30 Oct 2017, 11:44 shiva sitamraju via bitcoin-dev, <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Hi,\n>>>\n>>> When I copy and paste bitcoin address, I double check the first few\n>>> bytes, to make sure I copied the correct one. This is to make sure some\n>>> rogue software is not changing the address, or I incorrectly pasted the\n>>> wrong address.\n>>>\n>>>\n>>> With Bech32 address, its seems like in this department we are taking as\n>>> step in the backward direction. With the traditional address, I could\n>>> compare first few bytes like 1Ko or 1L3. With bech32, bc1. is all I can see\n>>> and compare which is likely to be same anyway. Note that most users will\n>>> only compare the first few bytes only (since addresses themselves are very\n>>> long and will overflow in a mobile text box).\n>>>\n>>> Is there anyway to make the Bech32 addresses format more visually\n>>> distinct (atleast the first few bytes) ?\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171030/612c7b18/attachment.html>"
            },
            {
                "author": "Danny Thorpe",
                "date": "2017-10-30T16:15:45",
                "message_text_only": "Humans are very visually oriented, recognizing differences in images more\neasily than differences in text.\n\nWhat about generating an image based on the bytes of an address, using\nsomething like identicon, used by gravatar? Any small change to the text\ninput produces a significantly different image.\n\n-Danny\n\nOn Oct 30, 2017 7:43 AM, \"Moral Agent via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> If you are going to rely on human verification of addresses, the best way\n> might be map it to words.\n>\n> For example, with a 6000 word list, a 25 byte address (with a checksum)\n> could be mapped to 16 words like this:\n>\n> vocally           acquire        removed     unfounded\n> euphemism    sanctuary    sectional     driving\n> entree            freckles    aloof           vertebrae\n> scribble          surround      prelaw         effort\n>\n> In my opinion, that is much faster to verify than this:\n>\n> 13gQFTYHuAcfnZjXo2NFsy1E8JGSLwXHCZ\n>\n> or\n>\n> bc1qrp33g0q5c5txsp9arysrx4k6zdkfs4nce4xj0gdcccefvpysxf3qccfmv3\n>\n> Although I really do love Bech32.\n>\n> On Mon, Oct 30, 2017 at 9:13 AM, shiva sitamraju via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> For example bc1qeklep85ntjz4605drds6aww9u0qr46qzrv5xswd35uhjuj8ahfcqgf6hak\n>> in 461e8a4aa0a0e75c06602c505bd7aa06e7116ba5cd98fd6e046e8cbeb00379d6 is\n>> 62 bytes ! This is very very long. This will create lot of usability\n>> problems in\n>>\n>> - Blockexplorers (atleast user should be visually able to compare in a\n>> transaction having multiple outputs which one his address)\n>> - Mobiles\n>> - Payment terminals\n>>\n>> From my limited understanding, the purpose of inventing a bitcoin address\n>> format is for usability and ease of identification (versus a ECDSA public\n>> key), While I get the error/checksum capabilities Bech32 brings, any user\n>> would prefer a 20 byte address with a checksum  over an address that would\n>> wrap several lines !!\n>>\n>>\n>> On Mon, Oct 30, 2017 at 6:19 PM, Ben Thompson <\n>> thompson.benedictjames at gmail.com> wrote:\n>>\n>>> Checking the first few bytes of a Bitcoin Address should not be\n>>> considered sufficient for ensuring that it is correct as it takes less than\n>>> a second to generate a 3 character vanity address that matches the first 3\n>>> characters of an address.\n>>>\n>>> On Mon, 30 Oct 2017, 11:44 shiva sitamraju via bitcoin-dev, <\n>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> Hi,\n>>>>\n>>>> When I copy and paste bitcoin address, I double check the first few\n>>>> bytes, to make sure I copied the correct one. This is to make sure some\n>>>> rogue software is not changing the address, or I incorrectly pasted the\n>>>> wrong address.\n>>>>\n>>>>\n>>>> With Bech32 address, its seems like in this department we are taking as\n>>>> step in the backward direction. With the traditional address, I could\n>>>> compare first few bytes like 1Ko or 1L3. With bech32, bc1. is all I can see\n>>>> and compare which is likely to be same anyway. Note that most users will\n>>>> only compare the first few bytes only (since addresses themselves are very\n>>>> long and will overflow in a mobile text box).\n>>>>\n>>>> Is there anyway to make the Bech32 addresses format more visually\n>>>> distinct (atleast the first few bytes) ?\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>\n>>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171030/ec4752a9/attachment.html>"
            },
            {
                "author": "Moral Agent",
                "date": "2017-10-30T16:48:09",
                "message_text_only": "Or like keyart:\nhttps://pthree.org/2014/04/18/the-drunken-bishop-for-openpgp-keys/\n\nImages would definitely be quicker to verify by a human, but I don't think\nhumans can RELIABLY verify anything close to 25 bytes through an image.\n\nOur visual processing system is designed wrong for this purpose, since it\nsubconsciously \"corrects\" visual input to whatever we expect to see.\n\nIt isn't enough to say that any small change produces a \"significantly\"\ndifferent image. What you need is for it to be (practically) impossible to\nconstruct an image that looks similar but is wrong, which is a far higher\nstandard. For example, any change to a private key renders a significantly\ndifferent address -- but it is possible for an attacker to grind their way\nto a similar-looking address.\n\nI would recommend displaying 16 words in a 4 x 4 grid, but otherwise with\nno visual distractions.\n\nFor example, don't provide an image next to the words as a help. Don't use\ncolors to differentiate two different sets of 16 words. What will happen is\npeople will see a pattern that triggers a sensation of familiarity, and\nthey will not carefully verify all of the words -- which is what security\nrequires.\n\nFor higher security keys, you could grind an address with enough zeros at\nthe beginning to be expressed by fewer words. For example, you could grind\nto an address that could be fully expressed with a 12 word (4 x 3) grid\nthat would be easier for a human to verify reliably.\n\nOn Mon, Oct 30, 2017 at 12:15 PM, Danny Thorpe <danny.thorpe at gmail.com>\nwrote:\n\n> Humans are very visually oriented, recognizing differences in images more\n> easily than differences in text.\n>\n> What about generating an image based on the bytes of an address, using\n> something like identicon, used by gravatar? Any small change to the text\n> input produces a significantly different image.\n>\n> -Danny\n>\n> On Oct 30, 2017 7:43 AM, \"Moral Agent via bitcoin-dev\" <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> If you are going to rely on human verification of addresses, the best way\n>> might be map it to words.\n>>\n>> For example, with a 6000 word list, a 25 byte address (with a checksum)\n>> could be mapped to 16 words like this:\n>>\n>> vocally           acquire        removed     unfounded\n>> euphemism    sanctuary    sectional     driving\n>> entree            freckles    aloof           vertebrae\n>> scribble          surround      prelaw         effort\n>>\n>> In my opinion, that is much faster to verify than this:\n>>\n>> 13gQFTYHuAcfnZjXo2NFsy1E8JGSLwXHCZ\n>>\n>> or\n>>\n>> bc1qrp33g0q5c5txsp9arysrx4k6zdkfs4nce4xj0gdcccefvpysxf3qccfmv3\n>>\n>> Although I really do love Bech32.\n>>\n>> On Mon, Oct 30, 2017 at 9:13 AM, shiva sitamraju via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> For example bc1qeklep85ntjz4605drds6aww9u0qr46qzrv5xswd35uhjuj8ahfcqgf6hak\n>>> in 461e8a4aa0a0e75c06602c505bd7aa06e7116ba5cd98fd6e046e8cbeb00379d6 is\n>>> 62 bytes ! This is very very long. This will create lot of usability\n>>> problems in\n>>>\n>>> - Blockexplorers (atleast user should be visually able to compare in a\n>>> transaction having multiple outputs which one his address)\n>>> - Mobiles\n>>> - Payment terminals\n>>>\n>>> From my limited understanding, the purpose of inventing a bitcoin\n>>> address format is for usability and ease of identification (versus a ECDSA\n>>> public key), While I get the error/checksum capabilities Bech32 brings, any\n>>> user would prefer a 20 byte address with a checksum  over an address that\n>>> would wrap several lines !!\n>>>\n>>>\n>>> On Mon, Oct 30, 2017 at 6:19 PM, Ben Thompson <\n>>> thompson.benedictjames at gmail.com> wrote:\n>>>\n>>>> Checking the first few bytes of a Bitcoin Address should not be\n>>>> considered sufficient for ensuring that it is correct as it takes less than\n>>>> a second to generate a 3 character vanity address that matches the first 3\n>>>> characters of an address.\n>>>>\n>>>> On Mon, 30 Oct 2017, 11:44 shiva sitamraju via bitcoin-dev, <\n>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>\n>>>>> Hi,\n>>>>>\n>>>>> When I copy and paste bitcoin address, I double check the first few\n>>>>> bytes, to make sure I copied the correct one. This is to make sure some\n>>>>> rogue software is not changing the address, or I incorrectly pasted the\n>>>>> wrong address.\n>>>>>\n>>>>>\n>>>>> With Bech32 address, its seems like in this department we are taking\n>>>>> as step in the backward direction. With the traditional address, I could\n>>>>> compare first few bytes like 1Ko or 1L3. With bech32, bc1. is all I can see\n>>>>> and compare which is likely to be same anyway. Note that most users will\n>>>>> only compare the first few bytes only (since addresses themselves are very\n>>>>> long and will overflow in a mobile text box).\n>>>>>\n>>>>> Is there anyway to make the Bech32 addresses format more visually\n>>>>> distinct (atleast the first few bytes) ?\n>>>>> _______________________________________________\n>>>>> bitcoin-dev mailing list\n>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>\n>>>>\n>>>\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171030/8f52182e/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Visually Differentiable - Bitcoin Addresses",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Ben Thompson",
                "shiva sitamraju",
                "Ricardo Filipe",
                "Moral Agent",
                "Danny Thorpe",
                "Pieter Wuille"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 21603
        }
    },
    {
        "title": "[bitcoin-dev] Simplicity: An alternative to Script",
        "thread_messages": [
            {
                "author": "Russell O'Connor",
                "date": "2017-10-30T15:22:20",
                "message_text_only": "I've been working on the design and implementation of an alternative to\nBitcoin Script, which I call Simplicity.  Today, I am presenting my design\nat the PLAS 2017 Workshop <http://plas2017.cse.buffalo.edu/> on Programming\nLanguages and Analysis for Security.  You find a copy of my Simplicity\npaper at https://blockstream.com/simplicity.pdf\n\nSimplicity is a low-level, typed, functional, native MAST language where\nprograms are built from basic combinators.  Like Bitcoin Script, Simplicity\nis designed to operate at the consensus layer.  While one can write\nSimplicity by hand, it is expected to be the target of one, or multiple,\nfront-end languages.\n\nSimplicity comes with formal denotational semantics (i.e. semantics of what\nprograms compute) and formal operational semantics (i.e. semantics of how\nprograms compute). These are both formalized in the Coq proof assistant and\nproven equivalent.\n\nFormal denotational semantics are of limited value unless one can use them\nin practice to reason about programs. I've used Simplicity's formal\nsemantics to prove correct an implementation of the SHA-256 compression\nfunction written in Simplicity.  I have also implemented a variant of ECDSA\nsignature verification in Simplicity, and plan to formally validate its\ncorrectness along with the associated elliptic curve operations.\n\nSimplicity comes with easy to compute static analyses that can compute\nbounds on the space and time resources needed for evaluation.  This is\nimportant for both node operators, so that the costs are knows before\nevaluation, and for designing Simplicity programs, so that smart-contract\nparticipants can know the costs of their contract before committing to it.\n\nAs a native MAST language, unused branches of Simplicity programs are\npruned at redemption time.  This enhances privacy, reduces the block weight\nused, and can reduce space and time resource costs needed for evaluation.\n\nTo make Simplicity practical, jets replace common Simplicity expressions\n(identified by their MAST root) and directly implement them with C code.  I\nanticipate developing a broad set of useful jets covering arithmetic\noperations, elliptic curve operations, and cryptographic operations\nincluding hashing and digital signature validation.\n\nThe paper I am presenting at PLAS describes only the foundation of the\nSimplicity language.  The final design includes extensions not covered in\nthe paper, including\n\n- full convent support, allowing access to all transaction data.\n- support for signature aggregation.\n- support for delegation.\n\nSimplicity is still in a research and development phase.  I'm working to\nproduce a bare-bones SDK that will include\n\n- the formal semantics and correctness proofs in Coq\n- a Haskell implementation for constructing Simplicity programs\n- and a C interpreter for Simplicity.\n\nAfter an SDK is complete the next step will be making Simplicity available\nin the Elements project <https://elementsproject.org/> so that anyone can\nstart experimenting with Simplicity in sidechains. Only after extensive\nvetting would it be suitable to consider Simplicity for inclusion in\nBitcoin.\n\nSimplicity has a long ways to go still, and this work is not intended to\ndelay consideration of the various Merkelized Script proposals that are\ncurrently ongoing.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171030/d8a6f806/attachment.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-10-30T15:31:22",
                "message_text_only": "So enthused that this is public now! Great work. \n\nSent from my iPhone\n\n> On Oct 30, 2017, at 8:22 AM, Russell O'Connor via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> I've been working on the design and implementation of an alternative to Bitcoin Script, which I call Simplicity.  Today, I am presenting my design at the PLAS 2017 Workshop on Programming Languages and Analysis for Security.  You find a copy of my Simplicity paper at https://blockstream.com/simplicity.pdf\n> \n> Simplicity is a low-level, typed, functional, native MAST language where programs are built from basic combinators.  Like Bitcoin Script, Simplicity is designed to operate at the consensus layer.  While one can write Simplicity by hand, it is expected to be the target of one, or multiple, front-end languages.\n> \n> Simplicity comes with formal denotational semantics (i.e. semantics of what programs compute) and formal operational semantics (i.e. semantics of how programs compute). These are both formalized in the Coq proof assistant and proven equivalent.\n> \n> Formal denotational semantics are of limited value unless one can use them in practice to reason about programs. I've used Simplicity's formal semantics to prove correct an implementation of the SHA-256 compression function written in Simplicity.  I have also implemented a variant of ECDSA signature verification in Simplicity, and plan to formally validate its correctness along with the associated elliptic curve operations.\n> \n> Simplicity comes with easy to compute static analyses that can compute bounds on  the space and time resources needed for evaluation.  This is important for both node operators, so that the costs are knows before evaluation, and for designing Simplicity programs, so that smart-contract  participants can know the costs of their contract before committing to it.\n> \n> As a native MAST language, unused branches of Simplicity programs are pruned at redemption time.  This enhances privacy, reduces the block weight used, and can reduce space and time resource costs needed for evaluation.\n> \n> To make Simplicity practical, jets replace common Simplicity expressions (identified by their MAST root) and directly implement them with C code.  I anticipate developing a broad set of useful jets covering arithmetic operations, elliptic curve operations, and cryptographic operations including hashing and digital signature validation.\n> \n> The paper I am presenting at PLAS describes only the foundation of the Simplicity language.  The final design includes extensions not covered in the paper, including\n> \n> - full convent support, allowing access to all transaction data.\n> - support for signature aggregation.\n> - support for delegation.\n> \n> Simplicity is still in a research and development phase.  I'm working to produce a bare-bones SDK that will include \n> \n> - the formal semantics and correctness proofs in Coq\n> - a Haskell implementation for constructing Simplicity programs\n> - and a C interpreter for Simplicity.\n> \n> After an SDK is complete the next step will be making Simplicity available in the Elements project so that anyone can start experimenting with Simplicity in sidechains. Only after extensive vetting would it be suitable to consider Simplicity for inclusion in Bitcoin.\n> \n> Simplicity has a long ways to go still, and this work is not intended to delay consideration of the various Merkelized Script proposals that are currently ongoing.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171030/8d986d48/attachment-0001.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2017-10-30T21:42:44",
                "message_text_only": "I admittedly haven't had a chance to read the paper in full details, but I was curious how you propose dealing with \"jets\" in something like Bitcoin. AFAIU, other similar systems are left doing hard-forks to reduce the sigops/weight/fee-cost of transactions every time they want to add useful optimized drop-ins. For obvious reasons, this seems rather impractical and a potentially critical barrier to adoption of such optimized drop-ins, which I imagine would be required to do any new cryptographic algorithms due to the significant fee cost of interpreting such things.\n\nIs there some insight I'm missing here?\n\nMatt\n\nOn October 30, 2017 11:22:20 AM EDT, Russell O'Connor via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>I've been working on the design and implementation of an alternative to\n>Bitcoin Script, which I call Simplicity.  Today, I am presenting my\n>design\n>at the PLAS 2017 Workshop <http://plas2017.cse.buffalo.edu/> on\n>Programming\n>Languages and Analysis for Security.  You find a copy of my Simplicity\n>paper at https://blockstream.com/simplicity.pdf\n>\n>Simplicity is a low-level, typed, functional, native MAST language\n>where\n>programs are built from basic combinators.  Like Bitcoin Script,\n>Simplicity\n>is designed to operate at the consensus layer.  While one can write\n>Simplicity by hand, it is expected to be the target of one, or\n>multiple,\n>front-end languages.\n>\n>Simplicity comes with formal denotational semantics (i.e. semantics of\n>what\n>programs compute) and formal operational semantics (i.e. semantics of\n>how\n>programs compute). These are both formalized in the Coq proof assistant\n>and\n>proven equivalent.\n>\n>Formal denotational semantics are of limited value unless one can use\n>them\n>in practice to reason about programs. I've used Simplicity's formal\n>semantics to prove correct an implementation of the SHA-256 compression\n>function written in Simplicity.  I have also implemented a variant of\n>ECDSA\n>signature verification in Simplicity, and plan to formally validate its\n>correctness along with the associated elliptic curve operations.\n>\n>Simplicity comes with easy to compute static analyses that can compute\n>bounds on the space and time resources needed for evaluation.  This is\n>important for both node operators, so that the costs are knows before\n>evaluation, and for designing Simplicity programs, so that\n>smart-contract\n>participants can know the costs of their contract before committing to\n>it.\n>\n>As a native MAST language, unused branches of Simplicity programs are\n>pruned at redemption time.  This enhances privacy, reduces the block\n>weight\n>used, and can reduce space and time resource costs needed for\n>evaluation.\n>\n>To make Simplicity practical, jets replace common Simplicity\n>expressions\n>(identified by their MAST root) and directly implement them with C\n>code.  I\n>anticipate developing a broad set of useful jets covering arithmetic\n>operations, elliptic curve operations, and cryptographic operations\n>including hashing and digital signature validation.\n>\n>The paper I am presenting at PLAS describes only the foundation of the\n>Simplicity language.  The final design includes extensions not covered\n>in\n>the paper, including\n>\n>- full convent support, allowing access to all transaction data.\n>- support for signature aggregation.\n>- support for delegation.\n>\n>Simplicity is still in a research and development phase.  I'm working\n>to\n>produce a bare-bones SDK that will include\n>\n>- the formal semantics and correctness proofs in Coq\n>- a Haskell implementation for constructing Simplicity programs\n>- and a C interpreter for Simplicity.\n>\n>After an SDK is complete the next step will be making Simplicity\n>available\n>in the Elements project <https://elementsproject.org/> so that anyone\n>can\n>start experimenting with Simplicity in sidechains. Only after extensive\n>vetting would it be suitable to consider Simplicity for inclusion in\n>Bitcoin.\n>\n>Simplicity has a long ways to go still, and this work is not intended\n>to\n>delay consideration of the various Merkelized Script proposals that are\n>currently ongoing.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171030/2094b682/attachment.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-10-30T21:56:00",
                "message_text_only": "Script versions makes this no longer a hard-fork to do. The script version would implicitly encode which jets are optimized, and what their optimized cost is.\n\n> On Oct 30, 2017, at 2:42 PM, Matt Corallo via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> I admittedly haven't had a chance to read the paper in full details, but I was curious how you propose dealing with \"jets\" in something like Bitcoin. AFAIU, other similar systems are left doing hard-forks to reduce the sigops/weight/fee-cost of transactions every time they want to add useful optimized drop-ins. For obvious reasons, this seems rather impractical and a potentially critical barrier to adoption of such optimized drop-ins, which I imagine would be required to do any new cryptographic algorithms due to the significant fee cost of interpreting such things.\n> \n> Is there some insight I'm missing here?\n> \n> Matt\n> \n> On October 30, 2017 11:22:20 AM EDT, Russell O'Connor via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> I've been working on the design and implementation of an alternative to Bitcoin Script, which I call Simplicity.  Today, I am presenting my design at the PLAS 2017 Workshop <http://plas2017.cse.buffalo.edu/> on Programming Languages and Analysis for Security.  You find a copy of my Simplicity paper at https://blockstream.com/simplicity.pdf <https://blockstream.com/simplicity.pdf>\n> \n> Simplicity is a low-level, typed, functional, native MAST language where programs are built from basic combinators.  Like Bitcoin Script, Simplicity is designed to operate at the consensus layer.  While one can write Simplicity by hand, it is expected to be the target of one, or multiple, front-end languages.\n> \n> Simplicity comes with formal denotational semantics (i.e. semantics of what programs compute) and formal operational semantics (i.e. semantics of how programs compute). These are both formalized in the Coq proof assistant and proven equivalent.\n> \n> Formal denotational semantics are of limited value unless one can use them in practice to reason about programs. I've used Simplicity's formal semantics to prove correct an implementation of the SHA-256 compression function written in Simplicity.  I have also implemented a variant of ECDSA signature verification in Simplicity, and plan to formally validate its correctness along with the associated elliptic curve operations.\n> \n> Simplicity comes with easy to compute static analyses that can compute bounds on the space and time resources needed for evaluation.  This is important for both node operators, so that the costs are knows before evaluation, and for designing Simplicity programs, so that smart-contract participants can know the costs of their contract before committing to it.\n> \n> As a native MAST language, unused branches of Simplicity programs are pruned at redemption time.  This enhances privacy, reduces the block weight used, and can reduce space and time resource costs needed for evaluation.\n> \n> To make Simplicity practical, jets replace common Simplicity expressions (identified by their MAST root) and directly implement them with C code.  I anticipate developing a broad set of useful jets covering arithmetic operations, elliptic curve operations, and cryptographic operations including hashing and digital signature validation.\n> \n> The paper I am presenting at PLAS describes only the foundation of the Simplicity language.  The final design includes extensions not covered in the paper, including\n> \n> - full convent support, allowing access to all transaction data.\n> - support for signature aggregation.\n> - support for delegation.\n> \n> Simplicity is still in a research and development phase.  I'm working to produce a bare-bones SDK that will include \n> \n> - the formal semantics and correctness proofs in Coq\n> - a Haskell implementation for constructing Simplicity programs\n> - and a C interpreter for Simplicity.\n> \n> After an SDK is complete the next step will be making Simplicity available in the Elements project <https://elementsproject.org/> so that anyone can start experimenting with Simplicity in sidechains. Only after extensive vetting would it be suitable to consider Simplicity for inclusion in Bitcoin.\n> \n> Simplicity has a long ways to go still, and this work is not intended to delay consideration of the various Merkelized Script proposals that are currently ongoing.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171030/e25a609d/attachment-0001.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2017-10-30T22:14:44",
                "message_text_only": "Are you anticipating it will be reasonably possible to execute more\ncomplicated things in interpreted form even after \"jets\" are put in\nplace? If not its just a soft-fork to add new script operations and\ngoing through the effort of making them compatible with existing code\nand using a full 32 byte hash to represent them seems wasteful - might\nas well just add a \"SHA256 opcode\".\n\nEither way it sounds like you're assuming a pretty aggressive soft-fork\ncadence? I'm not sure if that's so practical right now (or are you\nthinking it would be more practical if things were\ndrop-in-formally-verified-equivalent-replacements?).\n\nMatt\n\nOn 10/30/17 17:56, Mark Friedenbach wrote:\n> Script versions makes this no longer a hard-fork to do. The script\n> version would implicitly encode which jets are optimized, and what their\n> optimized cost is.\n> \n>> On Oct 30, 2017, at 2:42 PM, Matt Corallo via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org\n>> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>\n>> I admittedly haven't had a chance to read the paper in full details,\n>> but I was curious how you propose dealing with \"jets\" in something\n>> like Bitcoin. AFAIU, other similar systems are left doing hard-forks\n>> to reduce the sigops/weight/fee-cost of transactions every time they\n>> want to add useful optimized drop-ins. For obvious reasons, this seems\n>> rather impractical and a potentially critical barrier to adoption of\n>> such optimized drop-ins, which I imagine would be required to do any\n>> new cryptographic algorithms due to the significant fee cost of\n>> interpreting such things.\n>>\n>> Is there some insight I'm missing here?\n>>\n>> Matt\n>>\n>> On October 30, 2017 11:22:20 AM EDT, Russell O'Connor via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org\n>> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>\n>>     I've been working on the design and implementation of an\n>>     alternative to Bitcoin Script, which I call Simplicity.\u00a0 Today, I\n>>     am presenting my design at the PLAS 2017 Workshop\n>>     <http://plas2017.cse.buffalo.edu/> on Programming Languages and\n>>     Analysis for Security.\u00a0 You find a copy of my Simplicity paper at\n>>     https://blockstream.com/simplicity.pdf\n>>     <https://blockstream.com/simplicity.pdf>\n>>\n>>     Simplicity is a low-level, typed, functional, native MAST language\n>>     where programs are built from basic combinators.\u00a0 Like Bitcoin\n>>     Script, Simplicity is designed to operate at the consensus layer.\u00a0\n>>     While one can write Simplicity by hand, it is expected to be the\n>>     target of one, or multiple, front-end languages.\n>>\n>>     Simplicity comes with formal denotational semantics (i.e.\n>>     semantics of what programs compute) and formal operational\n>>     semantics (i.e. semantics of how programs compute). These are both\n>>     formalized in the Coq proof assistant and proven equivalent.\n>>\n>>     Formal denotational semantics are of limited value unless one can\n>>     use them in practice to reason about programs. I've used\n>>     Simplicity's formal semantics to prove correct an implementation\n>>     of the SHA-256 compression function written in Simplicity.\u00a0 I have\n>>     also implemented a variant of ECDSA signature verification in\n>>     Simplicity, and plan to formally validate its correctness along\n>>     with the associated elliptic curve operations.\n>>\n>>     Simplicity comes with easy to compute static analyses that can\n>>     compute bounds on the space and time resources needed for\n>>     evaluation.\u00a0 This is important for both node operators, so that\n>>     the costs are knows before evaluation, and for designing\n>>     Simplicity programs, so that smart-contract participants can know\n>>     the costs of their contract before committing to it.\n>>\n>>     As a native MAST language, unused branches of Simplicity programs\n>>     are pruned at redemption time.\u00a0 This enhances privacy, reduces the\n>>     block weight used, and can reduce space and time resource costs\n>>     needed for evaluation.\n>>\n>>     To make Simplicity practical, jets replace common Simplicity\n>>     expressions (identified by their MAST root) and directly implement\n>>     them with C code.\u00a0 I anticipate developing a broad set of useful\n>>     jets covering arithmetic operations, elliptic curve operations,\n>>     and cryptographic operations including hashing and digital\n>>     signature validation.\n>>\n>>     The paper I am presenting at PLAS describes only the foundation of\n>>     the Simplicity language.\u00a0 The final design includes extensions not\n>>     covered in the paper, including\n>>\n>>     - full convent support, allowing access to all transaction data.\n>>     - support for signature aggregation.\n>>     - support for delegation.\n>>\n>>     Simplicity is still in a research and development phase.\u00a0 I'm\n>>     working to produce a bare-bones SDK that will include\n>>\n>>     - the formal semantics and correctness proofs in Coq\n>>     - a Haskell implementation for constructing Simplicity programs\n>>     - and a C interpreter for Simplicity.\n>>\n>>     After an SDK is complete the next step will be making Simplicity\n>>     available in the Elements project <https://elementsproject.org/>\n>>     so that anyone can start experimenting with Simplicity in\n>>     sidechains. Only after extensive vetting would it be suitable to\n>>     consider Simplicity for inclusion in Bitcoin.\n>>\n>>     Simplicity has a long ways to go still, and this work is not\n>>     intended to delay consideration of the various Merkelized Script\n>>     proposals that are currently ongoing.\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-10-30T22:32:42",
                "message_text_only": "I was just making a factual observation/correction. This is Russell\u2019s project and I don\u2019t want to speak for him. Personally I don\u2019t think the particulars of bitcoin integration design space have been thoroughly explored enough to predict the exact approach that will be used.\n\nIt is possible to support a standard library of jets that are general purpose enough to allow the validation of new crypto primitives, like reusing sha2 to make Lamport signatures. Or use curve-agnostic jets to do Weil pairing validation. Or string manipulation and serialization jets to implement covenants. So I don\u2019t think the situation is as dire as you make it sound.\n\n> On Oct 30, 2017, at 3:14 PM, Matt Corallo <lf-lists at mattcorallo.com> wrote:\n> \n> Are you anticipating it will be reasonably possible to execute more\n> complicated things in interpreted form even after \"jets\" are put in\n> place? If not its just a soft-fork to add new script operations and\n> going through the effort of making them compatible with existing code\n> and using a full 32 byte hash to represent them seems wasteful - might\n> as well just add a \"SHA256 opcode\".\n> \n> Either way it sounds like you're assuming a pretty aggressive soft-fork\n> cadence? I'm not sure if that's so practical right now (or are you\n> thinking it would be more practical if things were\n> drop-in-formally-verified-equivalent-replacements?).\n> \n> Matt\n> \n>> On 10/30/17 17:56, Mark Friedenbach wrote:\n>> Script versions makes this no longer a hard-fork to do. The script\n>> version would implicitly encode which jets are optimized, and what their\n>> optimized cost is.\n>> \n>>> On Oct 30, 2017, at 2:42 PM, Matt Corallo via bitcoin-dev\n>>> <bitcoin-dev at lists.linuxfoundation.org\n>>> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>> \n>>> I admittedly haven't had a chance to read the paper in full details,\n>>> but I was curious how you propose dealing with \"jets\" in something\n>>> like Bitcoin. AFAIU, other similar systems are left doing hard-forks\n>>> to reduce the sigops/weight/fee-cost of transactions every time they\n>>> want to add useful optimized drop-ins. For obvious reasons, this seems\n>>> rather impractical and a potentially critical barrier to adoption of\n>>> such optimized drop-ins, which I imagine would be required to do any\n>>> new cryptographic algorithms due to the significant fee cost of\n>>> interpreting such things.\n>>> \n>>> Is there some insight I'm missing here?\n>>> \n>>> Matt\n>>> \n>>> On October 30, 2017 11:22:20 AM EDT, Russell O'Connor via bitcoin-dev\n>>> <bitcoin-dev at lists.linuxfoundation.org\n>>> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>> \n>>>    I've been working on the design and implementation of an\n>>>    alternative to Bitcoin Script, which I call Simplicity.  Today, I\n>>>    am presenting my design at the PLAS 2017 Workshop\n>>>    <http://plas2017.cse.buffalo.edu/> on Programming Languages and\n>>>    Analysis for Security.  You find a copy of my Simplicity paper at\n>>>    https://blockstream.com/simplicity.pdf\n>>>    <https://blockstream.com/simplicity.pdf>\n>>> \n>>>    Simplicity is a low-level, typed, functional, native MAST language\n>>>    where programs are built from basic combinators.  Like Bitcoin\n>>>    Script, Simplicity is designed to operate at the consensus layer. \n>>>    While one can write Simplicity by hand, it is expected to be the\n>>>    target of one, or multiple, front-end languages.\n>>> \n>>>    Simplicity comes with formal denotational semantics (i.e.\n>>>    semantics of what programs compute) and formal operational\n>>>    semantics (i.e. semantics of how programs compute). These are both\n>>>    formalized in the Coq proof assistant and proven equivalent.\n>>> \n>>>    Formal denotational semantics are of limited value unless one can\n>>>    use them in practice to reason about programs. I've used\n>>>    Simplicity's formal semantics to prove correct an implementation\n>>>    of the SHA-256 compression function written in Simplicity.  I have\n>>>    also implemented a variant of ECDSA signature verification in\n>>>    Simplicity, and plan to formally validate its correctness along\n>>>    with the associated elliptic curve operations.\n>>> \n>>>    Simplicity comes with easy to compute static analyses that can\n>>>    compute bounds on the space and time resources needed for\n>>>    evaluation.  This is important for both node operators, so that\n>>>    the costs are knows before evaluation, and for designing\n>>>    Simplicity programs, so that smart-contract participants can know\n>>>    the costs of their contract before committing to it.\n>>> \n>>>    As a native MAST language, unused branches of Simplicity programs\n>>>    are pruned at redemption time.  This enhances privacy, reduces the\n>>>    block weight used, and can reduce space and time resource costs\n>>>    needed for evaluation.\n>>> \n>>>    To make Simplicity practical, jets replace common Simplicity\n>>>    expressions (identified by their MAST root) and directly implement\n>>>    them with C code.  I anticipate developing a broad set of useful\n>>>    jets covering arithmetic operations, elliptic curve operations,\n>>>    and cryptographic operations including hashing and digital\n>>>    signature validation.\n>>> \n>>>    The paper I am presenting at PLAS describes only the foundation of\n>>>    the Simplicity language.  The final design includes extensions not\n>>>    covered in the paper, including\n>>> \n>>>    - full convent support, allowing access to all transaction data.\n>>>    - support for signature aggregation.\n>>>    - support for delegation.\n>>> \n>>>    Simplicity is still in a research and development phase.  I'm\n>>>    working to produce a bare-bones SDK that will include\n>>> \n>>>    - the formal semantics and correctness proofs in Coq\n>>>    - a Haskell implementation for constructing Simplicity programs\n>>>    - and a C interpreter for Simplicity.\n>>> \n>>>    After an SDK is complete the next step will be making Simplicity\n>>>    available in the Elements project <https://elementsproject.org/>\n>>>    so that anyone can start experimenting with Simplicity in\n>>>    sidechains. Only after extensive vetting would it be suitable to\n>>>    consider Simplicity for inclusion in Bitcoin.\n>>> \n>>>    Simplicity has a long ways to go still, and this work is not\n>>>    intended to delay consideration of the various Merkelized Script\n>>>    proposals that are currently ongoing.\n>>> \n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>"
            },
            {
                "author": "Matt Corallo",
                "date": "2017-10-30T22:50:04",
                "message_text_only": "OK, fair enough, just wanted to make sure we were on the same page.\n\"Thorny issues there and there hasn't been a ton of effort put into what\nBitcoin integration and maintainability looks like\" is a perfectly fair\nresponse :)\n\nMatt\n\nOn 10/30/17 18:32, Mark Friedenbach wrote:\n> I was just making a factual observation/correction. This is Russell\u2019s project and I don\u2019t want to speak for him. Personally I don\u2019t think the particulars of bitcoin integration design space have been thoroughly explored enough to predict the exact approach that will be used.\n> \n> It is possible to support a standard library of jets that are general purpose enough to allow the validation of new crypto primitives, like reusing sha2 to make Lamport signatures. Or use curve-agnostic jets to do Weil pairing validation. Or string manipulation and serialization jets to implement covenants. So I don\u2019t think the situation is as dire as you make it sound.\n> \n>> On Oct 30, 2017, at 3:14 PM, Matt Corallo <lf-lists at mattcorallo.com> wrote:\n>>\n>> Are you anticipating it will be reasonably possible to execute more\n>> complicated things in interpreted form even after \"jets\" are put in\n>> place? If not its just a soft-fork to add new script operations and\n>> going through the effort of making them compatible with existing code\n>> and using a full 32 byte hash to represent them seems wasteful - might\n>> as well just add a \"SHA256 opcode\".\n>>\n>> Either way it sounds like you're assuming a pretty aggressive soft-fork\n>> cadence? I'm not sure if that's so practical right now (or are you\n>> thinking it would be more practical if things were\n>> drop-in-formally-verified-equivalent-replacements?).\n>>\n>> Matt\n>>\n>>> On 10/30/17 17:56, Mark Friedenbach wrote:\n>>> Script versions makes this no longer a hard-fork to do. The script\n>>> version would implicitly encode which jets are optimized, and what their\n>>> optimized cost is.\n>>>\n>>>> On Oct 30, 2017, at 2:42 PM, Matt Corallo via bitcoin-dev\n>>>> <bitcoin-dev at lists.linuxfoundation.org\n>>>> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>>>\n>>>> I admittedly haven't had a chance to read the paper in full details,\n>>>> but I was curious how you propose dealing with \"jets\" in something\n>>>> like Bitcoin. AFAIU, other similar systems are left doing hard-forks\n>>>> to reduce the sigops/weight/fee-cost of transactions every time they\n>>>> want to add useful optimized drop-ins. For obvious reasons, this seems\n>>>> rather impractical and a potentially critical barrier to adoption of\n>>>> such optimized drop-ins, which I imagine would be required to do any\n>>>> new cryptographic algorithms due to the significant fee cost of\n>>>> interpreting such things.\n>>>>\n>>>> Is there some insight I'm missing here?\n>>>>\n>>>> Matt\n>>>>\n>>>> On October 30, 2017 11:22:20 AM EDT, Russell O'Connor via bitcoin-dev\n>>>> <bitcoin-dev at lists.linuxfoundation.org\n>>>> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>>>\n>>>>    I've been working on the design and implementation of an\n>>>>    alternative to Bitcoin Script, which I call Simplicity.  Today, I\n>>>>    am presenting my design at the PLAS 2017 Workshop\n>>>>    <http://plas2017.cse.buffalo.edu/> on Programming Languages and\n>>>>    Analysis for Security.  You find a copy of my Simplicity paper at\n>>>>    https://blockstream.com/simplicity.pdf\n>>>>    <https://blockstream.com/simplicity.pdf>\n>>>>\n>>>>    Simplicity is a low-level, typed, functional, native MAST language\n>>>>    where programs are built from basic combinators.  Like Bitcoin\n>>>>    Script, Simplicity is designed to operate at the consensus layer. \n>>>>    While one can write Simplicity by hand, it is expected to be the\n>>>>    target of one, or multiple, front-end languages.\n>>>>\n>>>>    Simplicity comes with formal denotational semantics (i.e.\n>>>>    semantics of what programs compute) and formal operational\n>>>>    semantics (i.e. semantics of how programs compute). These are both\n>>>>    formalized in the Coq proof assistant and proven equivalent.\n>>>>\n>>>>    Formal denotational semantics are of limited value unless one can\n>>>>    use them in practice to reason about programs. I've used\n>>>>    Simplicity's formal semantics to prove correct an implementation\n>>>>    of the SHA-256 compression function written in Simplicity.  I have\n>>>>    also implemented a variant of ECDSA signature verification in\n>>>>    Simplicity, and plan to formally validate its correctness along\n>>>>    with the associated elliptic curve operations.\n>>>>\n>>>>    Simplicity comes with easy to compute static analyses that can\n>>>>    compute bounds on the space and time resources needed for\n>>>>    evaluation.  This is important for both node operators, so that\n>>>>    the costs are knows before evaluation, and for designing\n>>>>    Simplicity programs, so that smart-contract participants can know\n>>>>    the costs of their contract before committing to it.\n>>>>\n>>>>    As a native MAST language, unused branches of Simplicity programs\n>>>>    are pruned at redemption time.  This enhances privacy, reduces the\n>>>>    block weight used, and can reduce space and time resource costs\n>>>>    needed for evaluation.\n>>>>\n>>>>    To make Simplicity practical, jets replace common Simplicity\n>>>>    expressions (identified by their MAST root) and directly implement\n>>>>    them with C code.  I anticipate developing a broad set of useful\n>>>>    jets covering arithmetic operations, elliptic curve operations,\n>>>>    and cryptographic operations including hashing and digital\n>>>>    signature validation.\n>>>>\n>>>>    The paper I am presenting at PLAS describes only the foundation of\n>>>>    the Simplicity language.  The final design includes extensions not\n>>>>    covered in the paper, including\n>>>>\n>>>>    - full convent support, allowing access to all transaction data.\n>>>>    - support for signature aggregation.\n>>>>    - support for delegation.\n>>>>\n>>>>    Simplicity is still in a research and development phase.  I'm\n>>>>    working to produce a bare-bones SDK that will include\n>>>>\n>>>>    - the formal semantics and correctness proofs in Coq\n>>>>    - a Haskell implementation for constructing Simplicity programs\n>>>>    - and a C interpreter for Simplicity.\n>>>>\n>>>>    After an SDK is complete the next step will be making Simplicity\n>>>>    available in the Elements project <https://elementsproject.org/>\n>>>>    so that anyone can start experimenting with Simplicity in\n>>>>    sidechains. Only after extensive vetting would it be suitable to\n>>>>    consider Simplicity for inclusion in Bitcoin.\n>>>>\n>>>>    Simplicity has a long ways to go still, and this work is not\n>>>>    intended to delay consideration of the various Merkelized Script\n>>>>    proposals that are currently ongoing.\n>>>>\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2017-10-30T23:29:28",
                "message_text_only": "On Mon, Oct 30, 2017 at 9:42 PM, Matt Corallo via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> I admittedly haven't had a chance to read the paper in full details, but I\n> was curious how you propose dealing with \"jets\" in something like Bitcoin.\n> AFAIU, other similar systems are left doing hard-forks to reduce the\n> sigops/weight/fee-cost of transactions every time they want to add useful\n> optimized drop-ins. For obvious reasons, this seems rather impractical and a\n> potentially critical barrier to adoption of such optimized drop-ins, which I\n> imagine would be required to do any new cryptographic algorithms due to the\n> significant fee cost of interpreting such things.\n\nFor some framing-- I think we're still a long way off from proposing\nsomething like this in Bitcoin, and _how_ it's ultimately proposed is\nan open question.\n\nThere are many ways to use simplicity, for an extreme example:  one\ncould define a collection of high level operations and combinators at\nthe level of things in Bitcoin Script (op_sha256, op_equal, op_cat,\netc.)  and make an interpreter that implements these operations as\ndiscounted jets and ONLY these operations at all.\n\nAt that point you have a system which is functionally like Bitcoin\nScript-- with the same performance characteristics-- but with a pretty\nmuch perfectly rigorous formal specification and which is highly\namenable to the formal analysis of smart contracts written in it.\n\nAt the other extreme, you expose a full on Bitmachine and allow\narbitrary simplicity--  But this is probably slow enough to not be\nvery useful.  Simplicity itself is so simple that it doesn't natively\nhave a concept of a _bit_, library code programs the concept of a bit,\nthen the concept of a half adder ... and so on.   As a result a\ncompletely unjetted implementation is slow (actually remarkably fast\nconsidering that it's effectively interpreting a circuit constructed\nfrom pure logic).\n\nThe most useful way of using it would probably be in-between: a good\ncollection of high level functions, and mid-level functions (e.g.\narithmetic and string operations) making a wide space of useful but\ngeneral software both possible and high performance.  But to get there\nwe need enough experience with it to know what the requisite\ncollection of operations would be.\n\nOne challenge is that I don't think we have a clear mental model for\nhow nominal validation costs are allowed to be before there is a\nnegative impact.  It's probably safe to assume 'pretty darn nominal'\nis a requirement, but there is still a lot that can be done within\nthat envelope.\n\nAs far as consensus discounted jets goes:\n\n>From my perspective there are three related ideas around this:\n\nIs a particular script-root jetted or not in an implementation?\n -- In and of itself this is not of consensus consequence; esp.\nbecause a major design feature of simplicity is that it should be\npossible using to prove that an optimized C implementation of a\nsimplicity program is complete and correct (using VST+COQ).\n\nIs a particular script-root 'standard and known' in the P2P network:\n -- This means that you can skip communicating it when sending\nwitnesses to peers; but this is something that could be negotiated on\na peer by peer basis-- like compressing transactions, and isn't at all\nconsensus normative.\n\nIs a particular jet discounted and what are the discounts:\n -- This is inherently a consensus question; as the bitmachine costing\nfor a program is consensus normative (assuming that you allow\narbitrary simplicity code at all).\n\nA script-versioning like mechanism can provide for a straight-forward\nway to upgrade discounted cost tables in a compatible way--  if you're\nrunning old software that doesn't have the required jets to justify a\nparticular discount collection -- well that's okay, you won't validate\nthose scripts at all. (so they'll be super fast for you!)\n\nAnother potential tool is the idea of sunsetting cost limits that\nsunset; e.g. after N years, the limits go away with an assumption that\nupdated limits have been softforked in that ativate at that time and\nthemselves expire in N years.  Old software would become slower\nvalidating due to newly discounted code they lack jets for... but\nwould continue validating (at least until they run out of performance\nheadroom).\n\nThis is theoretically attractive in a number of regards, but\nunfortunately I think our industry hasn't shown sufficient maturity\nabout engineering tradeoffs to make this a politically viable choice\nin the mid-term-- I known I'm personally uncomfortable with the\noutspokenness of parties that hold positions which I think can fairly\nbe summarized \"We should remove all limits and if the system crashes\nand burns as a result, we'll just make a new one! YOLO.\". But it's\ninteresting to think about in the long term.\n\nThere are also hybrid approaches where you can imagine this decision\nbeing made by node operators, e.g. continuing to validate code that\nexceeds your effort limits on probabilistic and best effort basis;\neven more attractive if there were a protocol for efficiently showing\nothers that an operation had an invalid witness. Though there is a lot\nto explore about the brittleness to partitioning that comes from any\nexpectation that you'd learn about invalid updates by exception.\n\nIn any case, these are all options that exist completely independently\nof simplicity.  I think we should think of simplicity as a rigorous\nbase which we could _potentially_ use to build whatever future\ndirection of script we like out of... by itself it doesn't mandate a\nparticular depth or level of adoption.\n\nAnd for the moment it's still also mostly just a base-- I don't\nanticipate typical smart contracting end users programming directly w/\nsimplicity even if Bitcoin did support arbitrary simplicity--  I\nexpect they'd program in user friendly domain specific languages which\nare formally tied to their implementations in simplicity that allow-\nbut do not force- closed loop formal reasoning about their contracts\nall the way from their high level business rules straight through to\nthe machine code implementing the interpreter(s) that run in the\nnetwork.\n\nBut to get there we'll have to prove in practice that this is actually\nworkable. We have some evidence that it is,  e.g. Roconnor's SHA2\nimplementation in simplicity is proven to implement the same function\nthat a C implementation implements (via the compcert formalization of\nC).  but there will need to be more."
            },
            {
                "author": "Russell O'Connor",
                "date": "2017-10-31T20:38:16",
                "message_text_only": "(sorry, I forgot to reply-all earlier)\n\nThe very short answer to this question is that I plan on using Luke's\nfail-success-on-unknown-operation in Simplicity.  This is something that\nisn't detailed at all in the paper.\n\nThe plan is that discounted jets will be explicitly labeled as jets in the\ncommitment.  If you can provide a Merkle path from the root to a node that\nis an explicit jet, but that jet isn't among the finite number of known\ndiscounted jets, then the script is automatically successful (making it\nanyone-can-spend).  When new jets are wanted they can be soft-forked into\nthe protocol (for example if we get a suitable quantum-resistant digital\nsignature scheme) and the list of known discounted jets grows.  Old nodes\nget a merkle path to the new jet, which they view as an unknown jet, and\nallow the transaction as a anyone-can-spend transaction.  New nodes see a\nregular Simplicity redemption.  (I haven't worked out the details of how\nthe P2P protocol will negotiate with old nodes, but I don't forsee any\nproblems.)\n\nNote that this implies that you should never participate in any Simplicity\ncontract where you don't get access to the entire source code of all\nbranches to check that it doesn't have an unknown jet.\n\nOn Mon, Oct 30, 2017 at 5:42 PM, Matt Corallo <lf-lists at mattcorallo.com>\nwrote:\n\n> I admittedly haven't had a chance to read the paper in full details, but I\n> was curious how you propose dealing with \"jets\" in something like Bitcoin.\n> AFAIU, other similar systems are left doing hard-forks to reduce the\n> sigops/weight/fee-cost of transactions every time they want to add useful\n> optimized drop-ins. For obvious reasons, this seems rather impractical and\n> a potentially critical barrier to adoption of such optimized drop-ins,\n> which I imagine would be required to do any new cryptographic algorithms\n> due to the significant fee cost of interpreting such things.\n>\n> Is there some insight I'm missing here?\n>\n> Matt\n>\n>\n> On October 30, 2017 11:22:20 AM EDT, Russell O'Connor via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> I've been working on the design and implementation of an alternative to\n>> Bitcoin Script, which I call Simplicity.  Today, I am presenting my design\n>> at the PLAS 2017 Workshop <http://plas2017.cse.buffalo.edu/> on\n>> Programming Languages and Analysis for Security.  You find a copy of my\n>> Simplicity paper at https://blockstream.com/simplicity.pdf\n>>\n>> Simplicity is a low-level, typed, functional, native MAST language where\n>> programs are built from basic combinators.  Like Bitcoin Script, Simplicity\n>> is designed to operate at the consensus layer.  While one can write\n>> Simplicity by hand, it is expected to be the target of one, or multiple,\n>> front-end languages.\n>>\n>> Simplicity comes with formal denotational semantics (i.e. semantics of\n>> what programs compute) and formal operational semantics (i.e. semantics of\n>> how programs compute). These are both formalized in the Coq proof assistant\n>> and proven equivalent.\n>>\n>> Formal denotational semantics are of limited value unless one can use\n>> them in practice to reason about programs. I've used Simplicity's formal\n>> semantics to prove correct an implementation of the SHA-256 compression\n>> function written in Simplicity.  I have also implemented a variant of ECDSA\n>> signature verification in Simplicity, and plan to formally validate its\n>> correctness along with the associated elliptic curve operations.\n>>\n>> Simplicity comes with easy to compute static analyses that can compute\n>> bounds on the space and time resources needed for evaluation.  This is\n>> important for both node operators, so that the costs are knows before\n>> evaluation, and for designing Simplicity programs, so that smart-contract\n>> participants can know the costs of their contract before committing to it.\n>>\n>> As a native MAST language, unused branches of Simplicity programs are\n>> pruned at redemption time.  This enhances privacy, reduces the block weight\n>> used, and can reduce space and time resource costs needed for evaluation.\n>>\n>> To make Simplicity practical, jets replace common Simplicity expressions\n>> (identified by their MAST root) and directly implement them with C code.  I\n>> anticipate developing a broad set of useful jets covering arithmetic\n>> operations, elliptic curve operations, and cryptographic operations\n>> including hashing and digital signature validation.\n>>\n>> The paper I am presenting at PLAS describes only the foundation of the\n>> Simplicity language.  The final design includes extensions not covered in\n>> the paper, including\n>>\n>> - full convent support, allowing access to all transaction data.\n>> - support for signature aggregation.\n>> - support for delegation.\n>>\n>> Simplicity is still in a research and development phase.  I'm working to\n>> produce a bare-bones SDK that will include\n>>\n>> - the formal semantics and correctness proofs in Coq\n>> - a Haskell implementation for constructing Simplicity programs\n>> - and a C interpreter for Simplicity.\n>>\n>> After an SDK is complete the next step will be making Simplicity\n>> available in the Elements project <https://elementsproject.org/> so that\n>> anyone can start experimenting with Simplicity in sidechains. Only after\n>> extensive vetting would it be suitable to consider Simplicity for inclusion\n>> in Bitcoin.\n>>\n>> Simplicity has a long ways to go still, and this work is not intended to\n>> delay consideration of the various Merkelized Script proposals that are\n>> currently ongoing.\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171031/40b31969/attachment.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-10-31T20:46:49",
                "message_text_only": "Nit, but if you go down that specific path I would suggest making just\nthe jet itself fail-open. That way you are not so limited in requiring\nvalidation of the full contract -- one party can verify simply that\nwhatever condition they care about holds on reaching that part of the\ncontract. E.g. maybe their signature is needed at the top level, and\nthen they don't care what further restrictions are placed.\n\nOn Tue, Oct 31, 2017 at 1:38 PM, Russell O'Connor via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> (sorry, I forgot to reply-all earlier)\n>\n> The very short answer to this question is that I plan on using Luke's\n> fail-success-on-unknown-operation in Simplicity.  This is something that\n> isn't detailed at all in the paper.\n>\n> The plan is that discounted jets will be explicitly labeled as jets in the\n> commitment.  If you can provide a Merkle path from the root to a node that\n> is an explicit jet, but that jet isn't among the finite number of known\n> discounted jets, then the script is automatically successful (making it\n> anyone-can-spend).  When new jets are wanted they can be soft-forked into\n> the protocol (for example if we get a suitable quantum-resistant digital\n> signature scheme) and the list of known discounted jets grows.  Old nodes\n> get a merkle path to the new jet, which they view as an unknown jet, and\n> allow the transaction as a anyone-can-spend transaction.  New nodes see a\n> regular Simplicity redemption.  (I haven't worked out the details of how the\n> P2P protocol will negotiate with old nodes, but I don't forsee any\n> problems.)\n>\n> Note that this implies that you should never participate in any Simplicity\n> contract where you don't get access to the entire source code of all\n> branches to check that it doesn't have an unknown jet.\n>\n> On Mon, Oct 30, 2017 at 5:42 PM, Matt Corallo <lf-lists at mattcorallo.com>\n> wrote:\n>>\n>> I admittedly haven't had a chance to read the paper in full details, but I\n>> was curious how you propose dealing with \"jets\" in something like Bitcoin.\n>> AFAIU, other similar systems are left doing hard-forks to reduce the\n>> sigops/weight/fee-cost of transactions every time they want to add useful\n>> optimized drop-ins. For obvious reasons, this seems rather impractical and a\n>> potentially critical barrier to adoption of such optimized drop-ins, which I\n>> imagine would be required to do any new cryptographic algorithms due to the\n>> significant fee cost of interpreting such things.\n>>\n>> Is there some insight I'm missing here?\n>>\n>> Matt\n>>\n>>\n>> On October 30, 2017 11:22:20 AM EDT, Russell O'Connor via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>> I've been working on the design and implementation of an alternative to\n>>> Bitcoin Script, which I call Simplicity.  Today, I am presenting my design\n>>> at the PLAS 2017 Workshop on Programming Languages and Analysis for\n>>> Security.  You find a copy of my Simplicity paper at\n>>> https://blockstream.com/simplicity.pdf\n>>>\n>>> Simplicity is a low-level, typed, functional, native MAST language where\n>>> programs are built from basic combinators.  Like Bitcoin Script, Simplicity\n>>> is designed to operate at the consensus layer.  While one can write\n>>> Simplicity by hand, it is expected to be the target of one, or multiple,\n>>> front-end languages.\n>>>\n>>> Simplicity comes with formal denotational semantics (i.e. semantics of\n>>> what programs compute) and formal operational semantics (i.e. semantics of\n>>> how programs compute). These are both formalized in the Coq proof assistant\n>>> and proven equivalent.\n>>>\n>>> Formal denotational semantics are of limited value unless one can use\n>>> them in practice to reason about programs. I've used Simplicity's formal\n>>> semantics to prove correct an implementation of the SHA-256 compression\n>>> function written in Simplicity.  I have also implemented a variant of ECDSA\n>>> signature verification in Simplicity, and plan to formally validate its\n>>> correctness along with the associated elliptic curve operations.\n>>>\n>>> Simplicity comes with easy to compute static analyses that can compute\n>>> bounds on the space and time resources needed for evaluation.  This is\n>>> important for both node operators, so that the costs are knows before\n>>> evaluation, and for designing Simplicity programs, so that smart-contract\n>>> participants can know the costs of their contract before committing to it.\n>>>\n>>> As a native MAST language, unused branches of Simplicity programs are\n>>> pruned at redemption time.  This enhances privacy, reduces the block weight\n>>> used, and can reduce space and time resource costs needed for evaluation.\n>>>\n>>> To make Simplicity practical, jets replace common Simplicity expressions\n>>> (identified by their MAST root) and directly implement them with C code.  I\n>>> anticipate developing a broad set of useful jets covering arithmetic\n>>> operations, elliptic curve operations, and cryptographic operations\n>>> including hashing and digital signature validation.\n>>>\n>>> The paper I am presenting at PLAS describes only the foundation of the\n>>> Simplicity language.  The final design includes extensions not covered in\n>>> the paper, including\n>>>\n>>> - full convent support, allowing access to all transaction data.\n>>> - support for signature aggregation.\n>>> - support for delegation.\n>>>\n>>> Simplicity is still in a research and development phase.  I'm working to\n>>> produce a bare-bones SDK that will include\n>>>\n>>> - the formal semantics and correctness proofs in Coq\n>>> - a Haskell implementation for constructing Simplicity programs\n>>> - and a C interpreter for Simplicity.\n>>>\n>>> After an SDK is complete the next step will be making Simplicity\n>>> available in the Elements project so that anyone can start experimenting\n>>> with Simplicity in sidechains. Only after extensive vetting would it be\n>>> suitable to consider Simplicity for inclusion in Bitcoin.\n>>>\n>>> Simplicity has a long ways to go still, and this work is not intended to\n>>> delay consideration of the various Merkelized Script proposals that are\n>>> currently ongoing.\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2017-10-31T21:01:05",
                "message_text_only": "That approach is worth considering.  However there is a wrinkle that\nSimplicity's denotational semantics doesn't imply an order of operations.\nFor example, if one half of a pair contains a assertion failure\n(fail-closed), and the other half contains a unknown jet (fail-open), then\ndoes the program succeed or fail?\n\nThis could be solved by providing an order of operations; however I fear\nthat will complicate formal reasoning about Simplicity expressions.  Formal\nreasoning is hard enough as is and I hesitate to complicate the semantics\nin ways that make formal reasoning harder still.\n\n\nOn Oct 31, 2017 15:47, \"Mark Friedenbach\" <mark at friedenbach.org> wrote:\n\nNit, but if you go down that specific path I would suggest making just\nthe jet itself fail-open. That way you are not so limited in requiring\nvalidation of the full contract -- one party can verify simply that\nwhatever condition they care about holds on reaching that part of the\ncontract. E.g. maybe their signature is needed at the top level, and\nthen they don't care what further restrictions are placed.\n\nOn Tue, Oct 31, 2017 at 1:38 PM, Russell O'Connor via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> (sorry, I forgot to reply-all earlier)\n>\n> The very short answer to this question is that I plan on using Luke's\n> fail-success-on-unknown-operation in Simplicity.  This is something that\n> isn't detailed at all in the paper.\n>\n> The plan is that discounted jets will be explicitly labeled as jets in the\n> commitment.  If you can provide a Merkle path from the root to a node that\n> is an explicit jet, but that jet isn't among the finite number of known\n> discounted jets, then the script is automatically successful (making it\n> anyone-can-spend).  When new jets are wanted they can be soft-forked into\n> the protocol (for example if we get a suitable quantum-resistant digital\n> signature scheme) and the list of known discounted jets grows.  Old nodes\n> get a merkle path to the new jet, which they view as an unknown jet, and\n> allow the transaction as a anyone-can-spend transaction.  New nodes see a\n> regular Simplicity redemption.  (I haven't worked out the details of how\nthe\n> P2P protocol will negotiate with old nodes, but I don't forsee any\n> problems.)\n>\n> Note that this implies that you should never participate in any Simplicity\n> contract where you don't get access to the entire source code of all\n> branches to check that it doesn't have an unknown jet.\n>\n> On Mon, Oct 30, 2017 at 5:42 PM, Matt Corallo <lf-lists at mattcorallo.com>\n> wrote:\n>>\n>> I admittedly haven't had a chance to read the paper in full details, but\nI\n>> was curious how you propose dealing with \"jets\" in something like\nBitcoin.\n>> AFAIU, other similar systems are left doing hard-forks to reduce the\n>> sigops/weight/fee-cost of transactions every time they want to add useful\n>> optimized drop-ins. For obvious reasons, this seems rather impractical\nand a\n>> potentially critical barrier to adoption of such optimized drop-ins,\nwhich I\n>> imagine would be required to do any new cryptographic algorithms due to\nthe\n>> significant fee cost of interpreting such things.\n>>\n>> Is there some insight I'm missing here?\n>>\n>> Matt\n>>\n>>\n>> On October 30, 2017 11:22:20 AM EDT, Russell O'Connor via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>> I've been working on the design and implementation of an alternative to\n>>> Bitcoin Script, which I call Simplicity.  Today, I am presenting my\ndesign\n>>> at the PLAS 2017 Workshop on Programming Languages and Analysis for\n>>> Security.  You find a copy of my Simplicity paper at\n>>> https://blockstream.com/simplicity.pdf\n>>>\n>>> Simplicity is a low-level, typed, functional, native MAST language where\n>>> programs are built from basic combinators.  Like Bitcoin Script,\nSimplicity\n>>> is designed to operate at the consensus layer.  While one can write\n>>> Simplicity by hand, it is expected to be the target of one, or multiple,\n>>> front-end languages.\n>>>\n>>> Simplicity comes with formal denotational semantics (i.e. semantics of\n>>> what programs compute) and formal operational semantics (i.e. semantics\nof\n>>> how programs compute). These are both formalized in the Coq proof\nassistant\n>>> and proven equivalent.\n>>>\n>>> Formal denotational semantics are of limited value unless one can use\n>>> them in practice to reason about programs. I've used Simplicity's formal\n>>> semantics to prove correct an implementation of the SHA-256 compression\n>>> function written in Simplicity.  I have also implemented a variant of\nECDSA\n>>> signature verification in Simplicity, and plan to formally validate its\n>>> correctness along with the associated elliptic curve operations.\n>>>\n>>> Simplicity comes with easy to compute static analyses that can compute\n>>> bounds on the space and time resources needed for evaluation.  This is\n>>> important for both node operators, so that the costs are knows before\n>>> evaluation, and for designing Simplicity programs, so that\nsmart-contract\n>>> participants can know the costs of their contract before committing to\nit.\n>>>\n>>> As a native MAST language, unused branches of Simplicity programs are\n>>> pruned at redemption time.  This enhances privacy, reduces the block\nweight\n>>> used, and can reduce space and time resource costs needed for\nevaluation.\n>>>\n>>> To make Simplicity practical, jets replace common Simplicity expressions\n>>> (identified by their MAST root) and directly implement them with C\ncode.  I\n>>> anticipate developing a broad set of useful jets covering arithmetic\n>>> operations, elliptic curve operations, and cryptographic operations\n>>> including hashing and digital signature validation.\n>>>\n>>> The paper I am presenting at PLAS describes only the foundation of the\n>>> Simplicity language.  The final design includes extensions not covered\nin\n>>> the paper, including\n>>>\n>>> - full convent support, allowing access to all transaction data.\n>>> - support for signature aggregation.\n>>> - support for delegation.\n>>>\n>>> Simplicity is still in a research and development phase.  I'm working to\n>>> produce a bare-bones SDK that will include\n>>>\n>>> - the formal semantics and correctness proofs in Coq\n>>> - a Haskell implementation for constructing Simplicity programs\n>>> - and a C interpreter for Simplicity.\n>>>\n>>> After an SDK is complete the next step will be making Simplicity\n>>> available in the Elements project so that anyone can start experimenting\n>>> with Simplicity in sidechains. Only after extensive vetting would it be\n>>> suitable to consider Simplicity for inclusion in Bitcoin.\n>>>\n>>> Simplicity has a long ways to go still, and this work is not intended to\n>>> delay consideration of the various Merkelized Script proposals that are\n>>> currently ongoing.\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171031/dfe2ecf7/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Simplicity: An alternative to Script",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Russell O'Connor",
                "Gregory Maxwell",
                "Matt Corallo",
                "Mark Friedenbach"
            ],
            "messages_count": 11,
            "total_messages_chars_count": 61755
        }
    },
    {
        "title": "[bitcoin-dev] Optimization of Codes for Electrum",
        "thread_messages": [
            {
                "author": "Daryl - .",
                "date": "2017-10-30T17:12:44",
                "message_text_only": "Dear Bitcoin-Dev,\n\nI\u2019m writing in to enquire on the post (https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2013-July/002916.html) and I\u2019d like to seek your help and understanding on the codes you modified in order to optimize the syncing of blockchain. For instance, the functions that you modified/variables/values that may lead to a better performance. I\u2019m currently working on further optimising Electrum in terms of syncing and any help will be greatly appreciated.\n\nThank you and I really look forward to your prompt reply soon.\n\nRegards,\nDaryl\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171030/94c539a0/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Optimization of Codes for Electrum",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Daryl - ."
            ],
            "messages_count": 1,
            "total_messages_chars_count": 739
        }
    }
]