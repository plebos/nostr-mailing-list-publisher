[
    {
        "title": "[bitcoin-dev] Bitcoin Contracting Primitives WG 1st Meeting, Tuesday 15 Nov. 18:00 UTC",
        "thread_messages": [
            {
                "author": "Antoine Riard",
                "date": "2022-11-01T00:47:18",
                "message_text_only": "Hi list,\n\nAfter I have been asked offline the exact date when those meetings were\nactually starting, I'm proposing Tuesday 15th November at 18:00 UTC, i.e 2\nweeks from now. Thinking about a monthly frequency for now (from my\nexperience attending dlcspecs/lighnting specs meetings/core dev meetings in\nthe past, weekly sounds too much, biweekly/monthly sounds better though\ndunno yet good frequency).\n\nIf there is an incompatibility with another public engineering meeting in\nthe Bitcoin space, let it know. We can talk about a better schedule during\nthe 1st session [0].\n\nCommunication venue is #bitcoin-contracting-primitives-wg on Libera Chat\n[1]. Feel free to lurk already and ask questions.\n\nNo consistent agenda beyond listening to every attendee their expectations,\nideas, subjects of interests they would like to see happening with this new\ncovenants/contracting primitives R&D process.\n\nIf you have been working on a contracting\nprotocols/side-chains/rollups/other use-cases that could benefit from\nextended Bitcoin contracting primitives, feel free to open an issue there:\nhttps://github.com/ariard/bitcoin-contracting-primitives-wg/issues\n\nLet it know if you have more questions or feedback.\n\nCheers,\nAntoine\n\n[0] It would be great to have a schedule inclusive of most timezones we\ncan, 18:00 UTC might be too early for Asian and Oceanic ones. Later, we\nstart to be exclusive towards contributors in Eastern Europe.\n\n[1] There have been more voices suggesting jitsi/audio-based meetings\nrather than IRC. It's a cool format too, though coming with trade-offs.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221031/5ac3bd9a/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-11-14T02:21:16",
                "message_text_only": "Reminder: this is happening this _upcoming_ Tuesday.\n\nLooking forward to the first session, listening to everyone's thoughts\nabout what could be the scope discussed by this new community process:\nanyprevout, recursive covenants, introspection, new malleability flags, ZK\nrollups, new contracting protocols and many more ideas!\n\nBest,\nAntoine\n\nLe lun. 31 oct. 2022 \u00e0 20:47, Antoine Riard <antoine.riard at gmail.com> a\n\u00e9crit :\n\n> Hi list,\n>\n> After I have been asked offline the exact date when those meetings were\n> actually starting, I'm proposing Tuesday 15th November at 18:00 UTC, i.e 2\n> weeks from now. Thinking about a monthly frequency for now (from my\n> experience attending dlcspecs/lighnting specs meetings/core dev meetings in\n> the past, weekly sounds too much, biweekly/monthly sounds better though\n> dunno yet good frequency).\n>\n> If there is an incompatibility with another public engineering meeting in\n> the Bitcoin space, let it know. We can talk about a better schedule during\n> the 1st session [0].\n>\n> Communication venue is #bitcoin-contracting-primitives-wg on Libera Chat\n> [1]. Feel free to lurk already and ask questions.\n>\n> No consistent agenda beyond listening to every attendee their\n> expectations, ideas, subjects of interests they would like to see happening\n> with this new covenants/contracting primitives R&D process.\n>\n> If you have been working on a contracting\n> protocols/side-chains/rollups/other use-cases that could benefit from\n> extended Bitcoin contracting primitives, feel free to open an issue there:\n> https://github.com/ariard/bitcoin-contracting-primitives-wg/issues\n>\n> Let it know if you have more questions or feedback.\n>\n> Cheers,\n> Antoine\n>\n> [0] It would be great to have a schedule inclusive of most timezones we\n> can, 18:00 UTC might be too early for Asian and Oceanic ones. Later, we\n> start to be exclusive towards contributors in Eastern Europe.\n>\n> [1] There have been more voices suggesting jitsi/audio-based meetings\n> rather than IRC. It's a cool format too, though coming with trade-offs.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221113/5b535a7c/attachment.html>"
            },
            {
                "author": "alicexbt",
                "date": "2022-11-15T22:36:48",
                "message_text_only": "Hi Bitcoin Developers,\n\n> Looking forward to the first session, listening to everyone's thoughts about what could be the scope discussed by this new community process: anyprevout, recursive covenants, introspection, new malleability flags, ZK rollups, new contracting protocols and many more ideas!\n\nWanted to add CTV: BIP-119 OP_CHECKTEMPLATEVERIFY if OP missed it. Easiest and best possible way to get covenants aka tx introspection with lot of research and development.\n\n/dev/fd0\n\nSent with [Proton Mail](https://proton.me/) secure email.\n\n------- Original Message -------\nOn Monday, November 14th, 2022 at 7:51 AM, Antoine Riard via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Reminder: this is happening this _upcoming_ Tuesday.\n> Looking forward to the first session, listening to everyone's thoughts about what could be the scope discussed by this new community process: anyprevout, recursive covenants, introspection, new malleability flags, ZK rollups, new contracting protocols and many more ideas!\n> Best,\n> Antoine\n>\n> Le lun. 31 oct. 2022 \u00e0 20:47, Antoine Riard <antoine.riard at gmail.com> a \u00e9crit :\n>\n>> Hi list,\n>>\n>> After I have been asked offline the exact date when those meetings were actually starting, I'm proposing Tuesday 15th November at 18:00 UTC, i.e 2 weeks from now. Thinking about a monthly frequency for now (from my experience attending dlcspecs/lighnting specs meetings/core dev meetings in the past, weekly sounds too much, biweekly/monthly sounds better though dunno yet good frequency).\n>>\n>> If there is an incompatibility with another public engineering meeting in the Bitcoin space, let it know. We can talk about a better schedule during the 1st session [0].\n>>\n>> Communication venue is #bitcoin-contracting-primitives-wg on Libera Chat [1]. Feel free to lurk already and ask questions.\n>>\n>> No consistent agenda beyond listening to every attendee their expectations, ideas, subjects of interests they would like to see happening with this new covenants/contracting primitives R&D process.\n>>\n>> If you have been working on a contracting protocols/side-chains/rollups/other use-cases that could benefit from extended Bitcoin contracting primitives, feel free to open an issue there: https://github.com/ariard/bitcoin-contracting-primitives-wg/issues\n>>\n>> Let it know if you have more questions or feedback.\n>>\n>> Cheers,\n>> Antoine\n>>\n>> [0] It would be great to have a schedule inclusive of most timezones we can, 18:00 UTC might be too early for Asian and Oceanic ones. Later, we start to be exclusive towards contributors in Eastern Europe.\n>>\n>> [1] There have been more voices suggesting jitsi/audio-based meetings rather than IRC. It's a cool format too, though coming with trade-offs.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221115/ecc63e01/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-11-15T23:49:17",
                "message_text_only": "Hi alicexbt,\n\nCTV is listed here:\nhttps://github.com/ariard/bitcoin-contracting-primitives-wg/tree/main/primitives\nas one of the primitive subject of research. Contributions are welcome.\n\nBest,\nAntoine\n\nLe mar. 15 nov. 2022 \u00e0 17:37, alicexbt <alicexbt at protonmail.com> a \u00e9crit :\n\n> Hi Bitcoin Developers,\n>\n> Looking forward to the first session, listening to everyone's thoughts\n> about what could be the scope discussed by this new community process:\n> anyprevout, recursive covenants, introspection, new malleability flags, ZK\n> rollups, new contracting protocols and many more ideas!\n>\n>\n> Wanted to add CTV: BIP-119 OP_CHECKTEMPLATEVERIFY if OP missed it.\n> Easiest and best possible way to get covenants aka tx introspection with\n> lot of research and development.\n>\n> /dev/fd0\n>\n> Sent with Proton Mail <https://proton.me/> secure email.\n>\n> ------- Original Message -------\n> On Monday, November 14th, 2022 at 7:51 AM, Antoine Riard via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Reminder: this is happening this _upcoming_ Tuesday.\n>\n> Looking forward to the first session, listening to everyone's thoughts\n> about what could be the scope discussed by this new community process:\n> anyprevout, recursive covenants, introspection, new malleability flags, ZK\n> rollups, new contracting protocols and many more ideas!\n>\n> Best,\n> Antoine\n>\n> Le lun. 31 oct. 2022 \u00e0 20:47, Antoine Riard <antoine.riard at gmail.com> a\n> \u00e9crit :\n>\n>> Hi list,\n>>\n>> After I have been asked offline the exact date when those meetings were\n>> actually starting, I'm proposing Tuesday 15th November at 18:00 UTC, i.e 2\n>> weeks from now. Thinking about a monthly frequency for now (from my\n>> experience attending dlcspecs/lighnting specs meetings/core dev meetings in\n>> the past, weekly sounds too much, biweekly/monthly sounds better though\n>> dunno yet good frequency).\n>>\n>> If there is an incompatibility with another public engineering meeting in\n>> the Bitcoin space, let it know. We can talk about a better schedule during\n>> the 1st session [0].\n>>\n>> Communication venue is #bitcoin-contracting-primitives-wg on Libera Chat\n>> [1]. Feel free to lurk already and ask questions.\n>>\n>> No consistent agenda beyond listening to every attendee their\n>> expectations, ideas, subjects of interests they would like to see happening\n>> with this new covenants/contracting primitives R&D process.\n>>\n>> If you have been working on a contracting\n>> protocols/side-chains/rollups/other use-cases that could benefit from\n>> extended Bitcoin contracting primitives, feel free to open an issue there:\n>> https://github.com/ariard/bitcoin-contracting-primitives-wg/issues\n>>\n>> Let it know if you have more questions or feedback.\n>>\n>> Cheers,\n>> Antoine\n>>\n>> [0] It would be great to have a schedule inclusive of most timezones we\n>> can, 18:00 UTC might be too early for Asian and Oceanic ones. Later, we\n>> start to be exclusive towards contributors in Eastern Europe.\n>>\n>> [1] There have been more voices suggesting jitsi/audio-based meetings\n>> rather than IRC. It's a cool format too, though coming with trade-offs.\n>>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221115/4cdba0b5/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-11-15T23:47:39",
                "message_text_only": "Hi list,\n\n1st meeting did happen this afternoon with like ~10 attendees, we browsed\nthe covenant interests of everyone: state channels, universal settlement\nlayer, transaction introspection covenants, vaults/self-custody, MATT\ncovenants, logical label covenant like transaction inherited IDs,\ncongestion control, DLC and few more.\n\nOne of the goal of the process suggested by one of the attendee could be to\naddress \"1) misunderstanding of the state of development and desire for\nsome covenant-style upgrade, 2) coordinating around goals, drawbacks and\noverlap of different proposals and 3) helping to highlight consensus\nbuilding around the goals and mechanism to achieve them\".\n\nNext meeting aims to do a 360 degree panorama of all the known consistent\ncontracting primitives as well as the contracting protocols in an archiving\neffort. If you have more contracting primitives to pin, feel free to\nmodify:\nhttps://github.com/ariard/bitcoin-contracting-primitives-wg/tree/main/primitives\n\nFrequency schedule is for now every month, staying on the 3rd Tuesday of\nevery month. I'll announce them on time on the mailing list.\n\nMeetings log available here:\nhttps://github.com/ariard/bitcoin-contracting-primitives-wg/blob/main/meetings/meetings-15-11.md\n\nIf you have more suggestions to improve the process, feel free to comment.\n\nBest,\nAntoine\n\nLe lun. 31 oct. 2022 \u00e0 20:47, Antoine Riard <antoine.riard at gmail.com> a\n\u00e9crit :\n\n> Hi list,\n>\n> After I have been asked offline the exact date when those meetings were\n> actually starting, I'm proposing Tuesday 15th November at 18:00 UTC, i.e 2\n> weeks from now. Thinking about a monthly frequency for now (from my\n> experience attending dlcspecs/lighnting specs meetings/core dev meetings in\n> the past, weekly sounds too much, biweekly/monthly sounds better though\n> dunno yet good frequency).\n>\n> If there is an incompatibility with another public engineering meeting in\n> the Bitcoin space, let it know. We can talk about a better schedule during\n> the 1st session [0].\n>\n> Communication venue is #bitcoin-contracting-primitives-wg on Libera Chat\n> [1]. Feel free to lurk already and ask questions.\n>\n> No consistent agenda beyond listening to every attendee their\n> expectations, ideas, subjects of interests they would like to see happening\n> with this new covenants/contracting primitives R&D process.\n>\n> If you have been working on a contracting\n> protocols/side-chains/rollups/other use-cases that could benefit from\n> extended Bitcoin contracting primitives, feel free to open an issue there:\n> https://github.com/ariard/bitcoin-contracting-primitives-wg/issues\n>\n> Let it know if you have more questions or feedback.\n>\n> Cheers,\n> Antoine\n>\n> [0] It would be great to have a schedule inclusive of most timezones we\n> can, 18:00 UTC might be too early for Asian and Oceanic ones. Later, we\n> start to be exclusive towards contributors in Eastern Europe.\n>\n> [1] There have been more voices suggesting jitsi/audio-based meetings\n> rather than IRC. It's a cool format too, though coming with trade-offs.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221115/4c2070bf/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Contracting Primitives WG 1st Meeting, Tuesday 15 Nov. 18:00 UTC",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "alicexbt",
                "Antoine Riard"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 13501
        }
    },
    {
        "title": "[bitcoin-dev] Package Relay Proposal",
        "thread_messages": [
            {
                "author": "Gloria Zhao",
                "date": "2022-11-01T18:03:22",
                "message_text_only": "Hi everyone,\n\nI've made some significant changes to my package relay proposal based on\nobservations while implementing, feedback on this thread, and offline\ndiscussions [1].\n\nThe new proposal is called Ancestor Package Relay, BIP331, and PR'd at\nhttps://github.com/bitcoin/bips/pull/1382\n\nThe major changes to the proposal are:\n1. Scope reduction to receiver-initiated only\n2. Scope reduction to ancestor packages only\n3. Removal of block hash from package information\n\n1.  Scope reduction to receiver-initiated only\nReceiver-intiated package relay enables a node to ask for more information\nwhen they suspect they are missing something (i.e. in this case to resolve\na missing parent tx). Sender-initiated package relay should, theoretically,\nsave a round trip by notifying the receiver ahead of time that \"hey, this\nis going to be a package, so make sure you download and submit these\ntransactions together.\" As with any proactive communication, there is a\nchance that the node already knows this information, so this network\nbandwidth was wasted. The logic used to decide _when_ to announce a package\nproactively determines whether it is a net increase or decrease for overall\nbandwidth usage. However, it's difficult to design anything to save\nbandwidth without any idea of what its bandwidth usage actually looks like\nin practice. We'll want to design the sender-initiated protocol carefully,\nand inform the design decisions using data collected from the mainnet p2p\nnetwork. However, there is no historical transaction data to use because\nthe goal is to enable currently-rejected transactions to propagate. In\norder to get this right, I propose we hold off on sender-initiated for now,\ndeploy receiver-initiated package relay, observe its usage and figure out\nwhere we can save a round trip, and then produce a well-researched\nsender-initiated package relay proposal.\n\n2. Scope reduction to ancestor packages only\nThe proposal now only includes ancestor packages (previously called\ntx-with-unconfirmed-ancestors or \"v2\" packages). The\nchild-with-unconfirmed-parents (previously called \"v1\") package has been\nremoved since it is a subset of ancestor packages and sender-initiated\nrelay has been removed. It may be relevant again in the future with\nsender-initiated packages. If you were reviewing the previous proposal,\n\"pkginfo2\" message has been renamed to \"ancpkginfo\" and \"MSG_PKGINFO2\" inv\ntype to \"MSG_ANCPKGINFO\".\n\n3. Removal of block hash from package information\nMost of the rationale is already on this thread. The block hash was an\nattempt to enforce topology when chainstates differ, but isn't worth it. It\ndoes not make much sense to drop or delay transaction data requests due to\nmismatched chainstates, and the chainstate may change again between package\ninformation and transaction data rounds. Instead, differences in chainstate\nshould be handled internally at the mempool validation level. The node\nshould de-duplicate recently-confirmed transactions and make a best effort\nto validate the transactions it has already downloaded.\n\nThanks,\nGloria\n\n[1]\nhttps://diyhpl.us/wiki/transcripts/bitcoin-core-dev-tech/2022-10-11-package-relay/\n\nOn Fri, Jun 17, 2022 at 9:08 PM Antoine Riard <antoine.riard at gmail.com>\nwrote:\n\n> Hi Gloria,\n>\n> Thanks for working on that,\n>\n> > Always overestimating fees may sidestep this issue temporarily (while\n> mempool\n> > traffic is low and predictable), but this solution is not foolproof\n> > and wastes users' money. The feerate market can change due to sudden\n> > spikes in traffic (e.g. huge 12sat/vB dump a few days ago [9]) or\n> > sustained, high volume of Bitcoin payments (e.g.  April 2021 and\n> > December 2017).\n>\n> Even if the LN implementations started to overestimate fees based on the\n> historical worst-case of block inclusion feerates, there is still room for\n> exploitation due to bip125 rule#3. Indeed, as long as the adversary is able\n> to stick in the mempool a higher fee package while the feerate is not\n> compelling enough to get it mined, your \"honest\" LN package should be\n> bounced off.\n>\n> Considering Core's `MAX_STANDARD_TX_WEIGHT` of 400000 WU, I think it's\n> practical for an attacker to succeed with this pinning tactic in periods of\n> traffic spikes. Of course, LN implementation could overestimate fees with a\n> target like `MAX_STANDARD_WEIGHT` * `worst_case_block_inclusion_feerate` to\n> mitigate. However, assuming a value of 20sat for the latter, it would\n> require from any LN user a minimal channel value of 2000000 satoshis to be\n> theoretically secure against this type of pinning.\n>\n> So package relay is required to mitigate efficiently and realistically\n> against pinning attacks, while conserving the same level of \"economic\"\n> openness for Lightning. Beyond, it should be also noted that package relay\n> is only building block of the full set of mitigations, and there should be\n> a yet to-find-consensus-as-of-today other policy change such as\n> user-elected package limits or replace-by-feerate.\n>\n> Anyway, I think it would be beneficial to document the design trade-offs\n> of pinning mitigations in the `Rationale` subsection, at the attention of\n> future L2s devs and users ?\n>\n> > {|\n> > |  Field Name  ||  Type  ||  Size  ||  Purpose\n> > |-\n> > |version || uint32_t || 4 || Denotes a package version supported by the\n> > node.\n> > |-\n> > |max_count || uint32_t || 4 ||Specifies the maximum number of\n> transactions\n> > per package this node is\n> > willing to accept.\n> > |-\n> > |max_weight || uint32_t || 4 ||Specifies the maximum total weight per\n> > package this node is willing\n> > to accept.\n> > |-\n> > |}\n>\n> It's unclear to me what's the purpose of `max_count` and `max_weight` in\n> the overall package relay flow, if they are intended to be exposed as\n> configurable settings to node operators. If those fields are present to\n> allow DoS protection increase of low-performance host, I believe it would\n> be better to restrain the number of consumed UTXOs or executed sigops per\n> package, as DoS vectors are more likely to be CPU-based, rather than\n> memory-based as package size already bounded at acceptance by\n> `MAX_PACKAGE_COUNT`.\n>\n> Thinking more we might introduce a `MAX_SIGOPS_PER_PACKAGR` limit, as\n> otherwise if we naively grant one package announcement as equal to one\n> transaction announcement in our tx-request logic, we might increase our DoS\n> surface, node ressources staying equivalent ?\n>\n> > {|\n> > |  Field Name  ||  Type  ||  Size  ||   Purpose\n> > |-\n> > |txns_length||CompactSize||1 or 3 bytes|| The number of transactions\n> > requested.\n>\n> I'm not sure if we'll ever allow 3-bytes of package size, that would be\n> ~32k of transactions.\n>\n> > |-\n> > |txns||List of wtxids||txns_length * 32|| The wtxids of each transaction\n> in\n> > the package.\n> > |}\n>\n> I think there is a bandwidth consumption trade-off to be aware of in the\n> function of the package-relay usage. Let's consider a single issuer\n> broadcasting the package to spend a shared-utxo, after the first shot the\n> parent component should be spread across the network mempools. At each\n> fee-bump, only the bumped CPFP will propagate on the network, the parent\n> wtxid is reannounced in `pckginfo1` though there is no need to fetch it\n> redundantly and waste bandwidth.\n>\n> However, I think the bandwidth saving does not hold in case of competing\n> transaction issuers to spend a shared-utxo. In that case, the parent might\n> differ at each broadcast and the list of wtxid is dissemblable at every\n> claim of the shared-utxo. We could save the 32 bytes * number of packages\n> elements by announcing a package_id, computed from the list of wtxids.\n>\n> I don't know about the occurrence of competing broadcasts among LN\n> non-cooperative closes, where bandwidth could be potentially saved. I would\n> say it's likely low because IIRC there is nothing in the LN protocol where\n> the counterparties signal to each other they're going on-chain to introduce\n> a competing broadcast synchronizing event. That said, it might increase in\n> the future in a post-eltoo, multi-party contracting protocol world.\n>\n> So it might be interesting to document this design trade-off, if we seek\n> bandwidth optimizations in function of a changing landscape in the type of\n> transaction issuers in the future.\n>\n> > 3. The sender provides package information using \"pckginfo1\",\n> >    including the blockhash of the sender's best block, the wtxids of\n> > the transactions in the package, their total fees and total weight.\n>\n> It's unclear to me how the `pckinfo1` receiver should proceed if the\n> sender's best block is not in sync with the local chain tip.\n>\n> If the package isn't processed further, that's annoying for all the\n> low-performance  LN mobile clients, their chain tips might be always behind\n> by few blocks from the p2p network nodes. It sounds like their packages\n> won't propagate at all.\n>\n> If the package is processed further whatever the sender-receiver sync on\n> chain tip, what's the purpose of including the blockhash ?\n>\n> > A child-with-unconfirmed-parents package for a transaction should be\n> > announced when it meets the peer's fee filter but one or more of its\n> > parents don't; a \"inv(MSG_PCKG1)\" instead of \"inv(WTX)\" should be sent\n> > for the child. Each of the parents which meet the peer's fee filter\n> > should still be announced normally.\n>\n> I believe we might have concerns of package-feerate downgrades attacks.\n> E.g, in the LN context, where your channel counterparty is aiming to jam\n> the propagation of the best-feerate version of the package.\n>\n> Let's say you have :\n> - Alice's commitment_tx, at 1s/vB\n> - package A + child B, at 3s/vB\n> - package A + child C, at 10s/vB\n> - block inclusion feerate at 10s/vB\n> - Alice and Mallory are LN channel counterparties\n> - commitment_tx is using LN's anchor outputs\n>\n> Alice's LN node broadcasts A+C to her mempool.\n> Bob's feefilter is at 3s/vB.\n> Mallory broadcasts her child B in Alice's mempool.\n> LN commitment does not meet Bob's feefilter.\n> Package A+child B at 3s/vB meets Bob's feefilter and is announced to Bob.\n> Mallory broadcasts her own commitment_tx at 4s/vB in Bob's mempool.\n> When Alice's child C is relayed to Bob, it's bounced off Bob's mempool.\n>\n> Do you think this situation is plausible ? Of course, it might be heavily\n> dependent on package-relay yet-not-implemented internal p2p logic.\n> I think it could be fixable if LN removes the counterparty's\n> `anchor_output` on the local node's version of the commitment transaction,\n> once package relay is deployed.\n>\n> Another question, at the next fee-bump iteration, Alice rebroadcasts\n> A+child D, at 12 s/vB. Her node has already marked Alice's commitment_tx as\n> known in Bob's `m_tx_inventory_known_filter`. So when a new higher fee\n> child is  discovered, should a `child-with-unconfirmed-parents` be\n> announced between Alice and Bob ?\n>\n> Anyway, I think it would be interesting to pseudo-specify the\n> package-assemblage algorithm (or if there is code already available) to see\n> if it's robust against adversarial or unlucky situations ?\n>\n> > In fact, a package\n> > of transactions may be announced using both Erlay and package relay.\n> > After reconciliation, if the initiator would have announced a\n> > transaction by wtxid but also has package information for it, they may\n> > send \"inv(MSG_PCKG)\" instead of \"inv(WTX)\".\n>\n> Yes, I think this holds. Note, we might have to add to the reconciliation\n> set low-fee parents succeeding the feefilter check due to a child. When the\n> reconcildiff, we might have to bifucarte again on feefilter to decide to\n> announce missing wtixds either as `inv(MSG_PCKG)` or `inv(WTX)`.\n>\n> (IIRC, I've already made few feedbacks offline though good to get them in\n> the public space and think more)\n>\n> Antoine\n>\n> Le mar. 17 mai 2022 \u00e0 12:09, Gloria Zhao via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n>\n>> Hi everybody,\n>>\n>> I\u2019m writing to propose a set of p2p protocol changes to enable package\n>> relay, soliciting feedback on the design and approach. Here is a link\n>> to the most up-to-date proposal:\n>>\n>> https://github.com/bitcoin/bips/pull/1324\n>>\n>> If you have concept or approach feedback, *please respond on the\n>> mailing list* to allow everybody to view and participate in the\n>> discussion. If you find a typo or inaccurate wording, please feel free\n>> to leave suggestions on the PR.\n>>\n>> I\u2019m also working on an implementation for Bitcoin Core.\n>>\n>>\n>> The rest of this post will include the same contents as the proposal,\n>> with a bit of reordering and additional context. If you are not 100%\n>> up-to-date on package relay and find the proposal hard to follow, I\n>> hope you find this format more informative and persuasive.\n>>\n>>\n>> ==Background and Motivation==\n>>\n>> Users may create and broadcast transactions that depend upon, i.e.\n>> spend outputs of, unconfirmed transactions. A \u201cpackage\u201d is the\n>> widely-used term for a group of transactions representable by a\n>> connected Directed Acyclic Graph (where a directed edge exists between\n>> a transaction that spends the output of another transaction).\n>>\n>> Incentive-compatible mempool and miner policies help create a fair,\n>> fee-based market for block space. While miners maximize transaction\n>> fees in order to earn higher block rewards, non-mining users\n>> participating in transaction relay reap many benefits from employing\n>> policies that result in a mempool with the same contents, including\n>> faster compact block relay and more accurate fee estimation.\n>> Additionally, users may take advantage of mempool and miner policy to\n>> bump the priority of their transactions by attaching high-fee\n>> descendants (Child Pays for Parent or CPFP).  Only considering\n>> transactions one at a time for submission to the mempool creates a\n>> limitation in the node's ability to determine which transactions have\n>> the highest feerates, since it cannot take into account descendants\n>> until all the transactions are in the mempool. Similarly, it cannot\n>> use a transaction's descendants when considering which of two\n>> conflicting transactions to keep (Replace by Fee or RBF).\n>>\n>> When a user's transaction does not meet a mempool's minimum feerate\n>> and they cannot create a replacement transaction directly, their\n>> transaction will simply be rejected by this mempool. They also cannot\n>> attach a descendant to pay for replacing a conflicting transaction.\n>> This limitation harms users' ability to fee-bump their transactions.\n>> Further, it presents a security issue in contracting protocols which\n>> rely on **presigned**, time-sensitive transactions to prevent cheating\n>> (HTLC-Timeout in LN Penalty [1] [2] [3], Unvault Cancel in Revault\n>> [4], Refund Transaction in Discreet Log Contracts [5], Updates in\n>> eltoo [6]). In other words, a key security assumption of many\n>> contracting protocols is that all parties can propagate and confirm\n>> transactions in a timely manner.\n>>\n>> In the past few years, increasing attention [0][1][2][3][6] has been\n>> brought to **pinning attacks**, a type of censorship in which the\n>> attacker uses mempool policy restrictions to prevent a transaction\n>> from being relayed or getting mined.  TLDR: revocation transactions\n>> must meet a certain confirmation target to be effective, but their\n>> feerates are negotiated well ahead of broadcast time. If the\n>> forecasted feerate was too low and no fee-bumping options are\n>> available, attackers can steal money from their counterparties. I walk\n>> through a concrete example for stealing Lightning HTLC outputs at\n>> ~23:58 in this talk [7][8].  Note that most attacks are only possible\n>> when the market for blockspace at broadcast time  demands much higher\n>> feerates than originally anticipated at signing time. Always\n>> overestimating fees may sidestep this issue temporarily (while mempool\n>> traffic is low and predictable), but this solution is not foolproof\n>> and wastes users' money. The feerate market can change due to sudden\n>> spikes in traffic (e.g. huge 12sat/vB dump a few days ago [9]) or\n>> sustained, high volume of Bitcoin payments (e.g.  April 2021 and\n>> December 2017).\n>>\n>> The best solution is to enable nodes to consider packages of\n>> transactions as a unit, e.g. one or more low-fee parent transactions\n>> with a high-fee child, instead of separately. A package-aware mempool\n>> policy can help determine if it would actually be economically\n>> rational to accept a transaction to the mempool if it doesn't meet fee\n>> requirements individually. Network-wide adoption of these policies\n>> would create a more purely-feerate-based market for block space and\n>> allow contracting protocols to adjust fees (and therefore mining\n>> priority) at broadcast time.  Some support for packages has existed in\n>> Bitcoin Core for years. Since v0.13, Bitcoin Core has used ancestor\n>> packages instead of individual transactions to evaluate the incentive\n>> compatibility of transactions in the mempool [10] and select them for\n>> inclusion in blocks [11].\n>>\n>> Package Relay, the concept of {announcing, requesting, downloading}\n>> packages between nodes on the p2p network, has also been discussed for\n>> many years. The earliest public mention I can find is from 2015 [12].\n>> The two most common use cases for package relay are fee-bumping\n>> otherwise-too-low-fee transactions and reducing the amount of orphans.\n>> It seems uncontroversial to say that everybody desires package relay\n>> conceptually, with varying degrees of urgency. Lots of work has been\n>> done by others over the past few years, from which I've taken\n>> inspiration from [13][14][15][16].\n>>\n>> My approach has been to split the project into two components: (1) Package\n>> Mempool Accept, which includes validation logic and mempool policy.\n>> (3) Package Relay, which includes the p2p protocol changes.\n>>\n>> Progress so far:\n>> After discussions with various developers of contracting protocols\n>> (with heavier emphasis towards LN), it was determined that a\n>> package containing a child with all of its unconfirmed parents\n>> (child-with-unconfirmed-parents or 1-child-multi-parent package) would\n>> be sufficient for their use case, i.e. fee-bumping presigned\n>> transactions. A child-with-unconfirmed-parents package has several\n>> properties that make many things easier to reason about.\n>>\n>> A few months ago, I proposed a set of policies for safe package\n>> validation and fee assessment for packages of this restricted\n>> topology [17]. A series of PRs implementing this proposal have\n>> been merged into Bitcoin Core [18].\n>>\n>> Theoretically, developing a safe and incentive-compatible package\n>> mempool acceptance policy is sufficient to solve this issue. Nodes\n>> could opportunistically accept packages (e.g. by trying combinations\n>> of transactions rejected from their mempools), but this practice would\n>> likely be inefficient at best and open new Denial of Service attacks\n>> at worst. Additional p2p messages may enable nodes to request and\n>> share package validation-related information with one another in a\n>> more communication-efficient way.\n>>\n>> Given that only package RBF remains for package mempool accept, and we\n>> can make progress on p2p and mempool in parallel, I think it\u2019s\n>> appropriate to put forward a package relay proposal.\n>>\n>> ==Proposal==\n>>\n>> This proposal contains 2 components: a \u201cgeneric\u201d package relay\n>> protocol and an extension of it, child-with-unconfirmed-parents\n>> packages, as version 1 package relay. Another version of packages,\n>> \u201ctx-with-unconfirmed-ancestors\u201d can be created to extend package relay\n>> for eliminating orphans.\n>>\n>> ===Generic Package Relay===\n>>\n>> Two main ideas are introduced:\n>>\n>> Download and validate packages of transactions together.\n>>\n>> Provide information to help peers decide whether to request and/or how\n>> to validate transactions which are part of a package.\n>>\n>> ====Intended Protocol Flow====\n>>\n>> Due to the asynchronous nature of a distributed transaction relay\n>> network, nodes may not receive all of the information needed to\n>> validate a transaction at once. For example, after a node completes\n>> Initial Block Download (IBD) and first starts participating in\n>> transaction relay with an empty mempool, it is common to receive\n>> orphans. In such scenarios where a node is aware that it is missing\n>> information, a ''receiver-initiated'' dialogue is appropriate:\n>>\n>> 1. Receiver requests package information.\n>>\n>> 2. The sender provides package information, including the wtxids of\n>>    the transactions in the package and anything else that might be\n>> relevant (e.g. total fees and size).\n>>\n>> 3. The reciever uses the package information to decide how to request\n>>    and validate the transactions.\n>>\n>> Sometimes, no matter what order transactions are received by a node,\n>> validating them individually is insufficient. When the sender is aware\n>> of additional information that the receiver needs to accept a package,\n>> a proactive ''sender-initiated'' dialogue should be enabled:\n>>\n>> 1. Sender announces they have package information pertaining to a\n>>    transaction that might otherwise be undesired on its own.\n>>\n>> 2. The receiver requests package information.\n>>\n>> 3. The sender provides package information, including the wtxids of\n>>    the transactions in the package and anything else that might be\n>> relevant (e.g. total fees and size).\n>>\n>> 4. The reciever uses the package information to decide how to request\n>>    and validate the transactions.\n>>\n>> Package relay is negotiated between two peers during the version\n>> handshake. Package relay requires both peers to support wtxid-based\n>> relay because package transactions are referenced by their wtxid.\n>>\n>> ====New Messages====\n>>\n>> Three new protocol messages are added for use in any version of\n>> package relay. Additionally, each version of package relay must define\n>> its own inv type and \"pckginfo\" message version, referred to in this\n>> document as \"MSG_PCKG\" and \"pckginfo\" respectively. See\n>> BIP-v1-packages for a concrete example.\n>>\n>> =====sendpackages=====\n>>\n>> {|\n>> |  Field Name  ||  Type  ||  Size  ||  Purpose\n>> |-\n>> |version || uint32_t || 4 || Denotes a package version supported by the\n>> node.\n>> |-\n>> |max_count || uint32_t || 4 ||Specifies the maximum number of\n>> transactions per package this node is\n>> willing to accept.\n>> |-\n>> |max_weight || uint32_t || 4 ||Specifies the maximum total weight per\n>> package this node is willing\n>> to accept.\n>> |-\n>> |}\n>>\n>> 1. The \"sendpackages\" message has the structure defined above, with\n>>    pchCommand == \"sendpackages\".\n>>\n>> 2. During version handshake, nodes should send a \"sendpackages\"\n>>    message indicate they support package relay and may request\n>> packages.\n>>\n>> 3. The message should contain a version supported by the node. Nodes\n>>    should send a \"sendpackages\" message for each version they support.\n>>\n>> 4. The \"sendpackages\" message MUST be sent before sending a \"verack\"\n>>    message. If a \"sendpackages\" message is received afer \"verack\", the\n>> sender should be disconnected.\n>>\n>> 5. If 'fRelay==false' in a peer's version message, the node must not\n>>    send \"sendpackages\" to them. If a \"sendpackages\" message is\n>> received by a peer after sending `fRelay==false` in their version\n>> message, the sender should be disconnected.\n>>\n>> 6.. Upon receipt of a \"sendpackages\" message with a version that is\n>> not supported, a node must treat the peer as if it never received the\n>> message.\n>>\n>> 7. If both peers send \"wtxidrelay\" and \"sendpackages\" with the same\n>>    version, the peers should announce, request, and send package\n>> information to each other.\n>>\n>> =====getpckgtxns=====\n>>\n>> {|\n>> |  Field Name  ||  Type  ||  Size  ||   Purpose\n>> |-\n>> |txns_length||CompactSize||1 or 3 bytes|| The number of transactions\n>> requested.\n>> |-\n>> |txns||List of wtxids||txns_length * 32|| The wtxids of each transaction\n>> in the package.\n>> |}\n>>\n>> 1. The \"getpckgtxns\" message has the structure defined above, with\n>>    pchCommand == \"getpckgtxns\".\n>>\n>> 2. A \"getpckgtxns\" message should be used to request all or some of\n>>    the transactions previously announced in a \"pckginfo\" message,\n>> specified by witness transactiosome id.\n>>\n>> 3. Upon receipt of a \"getpckgtxns\" message, a node must respond with\n>>    either a \"pckgtxns\" containing the requested transactions or a\n>> \"notfound\" message indicating one or more of the transactions is\n>> unavailable. This allows the receiver to avoid downloading and storing\n>> transactions that cannot be validated immediately.\n>>\n>> 4. A \"getpckgtxns\" message should only be sent if both peers agreed to\n>>    send packages in the version handshake. If a \"getpckgtxns\" message\n>> is received from a peer with which package relay was not negotiated,\n>> the sender should be disconnected.\n>>\n>> =====pckgtxns=====\n>>\n>> {|\n>> |  Field Name  ||  Type  ||  Size  ||   Purpose\n>> |-\n>> |txns_length||CompactSize||1 or 3 bytes|| The number of transactions\n>> provided.\n>> |-\n>> |txns||List of transactions||variable|| The transactions in the package.\n>> |}\n>>\n>> 1. The \"pckgtxns\" message has the structure defined above, with\n>>    pchCommand == \"pckgtxns\".\n>>\n>> 2. A \"pckgtxns\" message should contain the transaction data requested\n>>    using \"getpckgtxns\".\n>>\n>> 3. A \"pckgtxns\" message should only be sent to a peer that requested\n>>    the package using \"getpckgtxns\". If a node receives an unsolicited\n>> package, the sender should be disconnected.\n>>\n>> 4. A \"pckgtxns\" message should only be sent if both peers agreed to\n>>    send packages in the version handshake. If a \"pckgtxns\" message is\n>> received from a peer with which package relay was not negotiated, the\n>> sender should be disconnected.\n>>\n>> ===Version 1 Packages: child-with-unconfirmed-parents===\n>>\n>> This extends package relay for packages consisting of one transaction\n>> and all of its unconfirmed parents,by defining version 1 packages, a\n>> pckginfo1 message, and a MSG_PCKG1 inv type. It enables the use case\n>> in which a child pays for its otherwise-too-low-fee parents and their\n>> mempool conflict(s).\n>>\n>> ====Intended Protocol Flow====\n>>\n>> When relaying a package of low-fee parent(s) and high-fee child, the\n>> sender and receiver do the following:\n>>\n>> 1. Sender announces they have a child-with-unconfirmed-parents package\n>>    for a child that pays for otherwise-too-low-fee parent(s) using\n>> \"inv(MSG_PCKG1)\".\n>>\n>> 2. The receiver requests package information using\n>>    \"getdata(MSG_PCKG1)\".\n>>\n>> 3. The sender provides package information using \"pckginfo1\",\n>>    including the blockhash of the sender's best block, the wtxids of\n>> the transactions in the package, their total fees and total weight.\n>>\n>> 4. The reciever uses the package information to decide how to request\n>>    the transactions. For example, if the receiver already has some of\n>> the transactions in their mempool, they only request the missing ones.\n>> They could also decide not to request the package at all based on the\n>> fee information provided.\n>>\n>> 5. Upon receiving a \"pckgtxns\", the receiver submits the transactions\n>>    together as a package.\n>>\n>> ====New Messages====\n>>\n>> A new inv type, \"MSG_PCKG1\", and new protocol message, \"PCKGINFO1\",\n>> are added.\n>>\n>> =====pckginfo1=====\n>>\n>> {|\n>> |  Field Name  ||  Type  ||  Size  ||   Purpose\n>> |-\n>> |blockhash || uint256 || 32 || The chain tip at which this package is\n>> defined.\n>> |-\n>> |pckg_fee||CAmount||4|| The sum total fees paid by all transactions in\n>> the package.\n>> |-\n>> |pckg_weight||int64_t||8|| The sum total weight of all transactions in\n>> the package.\n>> |-\n>> |txns_length||CompactSize||1 or 3 bytes|| The number of transactions\n>> provided.\n>> |-\n>> |txns||List of wtxids||txns_length * 32|| The wtxids of each transaction\n>> in the package.\n>> |}\n>>\n>>\n>> 1. The \"pckginfo1\" message has the structure defined above, with\n>>    pchCommand == \"pckginfo1\".\n>>\n>> 2. A \"pckginfo1\" message contains information about a version 1\n>>    package (defined below), referenced by the wtxid of the transaction\n>> it pertains to and the current blockhash.\n>>\n>> 3. Upon receipt of a \"pckginfo1\" message, the node should decide if it\n>>    wants to validate the package, request transaction data if\n>> necessary, etc.\n>>\n>> 4. Upon receipt of a malformed \"pckginfo1\" message or package that\n>>    does not abide by the max_count, max_weight, or other rules\n>> specified by the version agreed upon in the initial negotiation, the\n>> sender should be disconnected.  If a node receives a \"pckginfo1\"\n>> message for which the \"pckg_fee\" or \"pckg_weight\" do not reflect the\n>> true total fees and weight, respectively, or the transactions in the\n>> package, the message is malformed.\n>>\n>> 5. A node MUST NOT send a \"pckginfo1\" message that has not been\n>>    requested by the recipient. Upon receipt of an unsolicited\n>> \"pckginfo1\", a node should disconnect the sender.\n>>\n>> 6. A \"pckginfo1\" message should only be sent if both peers agreed to\n>>    send version 1 packages in the version handshake. If a \"pckginfo1\"\n>> message is received from a peer with which package relay was not\n>> negotiated, the sender should be disconnected.\n>>\n>> =====MSG_PCKG1=====\n>>\n>> 1. A new inv type (MSG_PCKG1 == 0x6) is added, for use in inv messages\n>>    and getdata requests pertaining to version 1 packages.\n>>\n>> 2. As an inv type, it indicates that both transaction data and version\n>>    1 package information are available for the transaction. The\n>> transaction is referenced by its wtxid. As a getdata request type, it\n>> indicates that the sender wants package information for the\n>> transaction.\n>>\n>> 3. Upon receipt of a \"getdata\" request for \"MSG_PCKG1\", the node\n>>    should respond with the version 1 package corresponding to the\n>> requested transaction and its current chain tip, or with NOTFOUND.\n>> The node should not assume that the sender is requesting the\n>> transaction data as well.\n>>\n>> ====Child With Parent Packages Rules====\n>>\n>> A child-with-unconfirmed-parents package sent between nodes must abide\n>> by the rules below, otherwise the package is malformed and the sender\n>> should be disconnected.\n>>\n>> A version 1 or ''child-with-unconfirmed-parents'' package can be\n>> defined for any transaction that spends unconfirmed inputs. The child\n>> can be thought of as the \"representative\" of the package. This package\n>> can be uniquely identified by the transaction's wtxid and the current\n>> chain tip block hash.\n>>\n>> A ''child-with-unconfirmed-parents'' package MUST be:\n>>\n>> 1. ''Sorted topologically.'' For every transaction t in the package,\n>>    if any of t's parents are present in the package, the parent must\n>> appear somewhere in the list before t. In other words, the\n>> transactions must be sorted in ascending order of the number of\n>> ancestors present in the package.\n>>\n>> 2. ''Only 1 child with unconfirmed parents.'' The package must consist\n>>    of one transaction and its unconfirmed parents. There must not be\n>> any other transactions in the package. Other dependency relationships\n>> may exist within the package (e.g. one parent may spend the output of\n>> another parent) provided that topological order is respected.\n>>\n>> 3. ''All unconfirmed parents.'' All of the child's unconfirmed parents\n>>    must be present.\n>>\n>> 4. ''No conflicts.'' None of the transactions in the package may\n>>    conflict with each other (i.e.  spend the same prevout).\n>>\n>> 5. ''Total fees and weight.'' The 'total_fee' and 'total_weight'\n>>    fields must accurately represent the sum total of all transactions'\n>> fees and weights as defined in BIP141, respectively.\n>>\n>> Not all of the child's parents must be present; the child transaction\n>> may also spend confirmed inputs. However, if the child has confirmed\n>> parents, they must not be in the package.\n>>\n>> While a child-with-unconfirmed-parents package is perhaps most\n>> relevant when the child has a higher feerate than its parents, this\n>> property is not required to construct a valid package.\n>>\n>> ====Clarifications====\n>>\n>> ''Q: Under what circumstances should a sender announce a\n>> child-with-unconfirmed-parents package?''\n>>\n>> A child-with-unconfirmed-parents package for a transaction should be\n>> announced when it meets the peer's fee filter but one or more of its\n>> parents don't; a \"inv(MSG_PCKG1)\" instead of \"inv(WTX)\" should be sent\n>> for the child. Each of the parents which meet the peer's fee filter\n>> should still be announced normally.\n>>\n>> ''Q: What if a new block arrives in between messages?''\n>>\n>> A child-with-unconfirmed-parents package is defined for a transaction\n>> based on the current chain state. As such, a new block extending the\n>> tip may decrease the number of transactions in the package (i.e. if\n>> any of the transaction's parents were included in the block). In a\n>> reorg, the number of transactions in the package may decrease or\n>> increase (i.e. if any of the transaction's parents were included in a\n>> block in the previous chain but not the new one).\n>>\n>> If the new block arrives before the \"getdata\" or \"pckginfo1\", nothing\n>> needs to change.\n>>\n>> If the new block arrives before \"getpckgtxns\" or before \"pckgtxns\",\n>> the receiver may need to re-request package information if the block\n>> contained a transaction in the package. If the block doesn't contain\n>> any transactions in the package, whether it extends the previous tip\n>> or causes a reorg, nothing needs to change.\n>>\n>> ''Q: Can \"getpckgtxns\" and \"pckgtxns\" messages contain only one\n>> transaction?''\n>>\n>> Yes.\n>>\n>> ===Further Protocol Extensions===\n>>\n>> When introducing a new type of package, assign it a version number \"n\"\n>> and use an additional \"sendpackages\" message during version handshake\n>> to negotiate support for it. An additional package information message\n>> \"pckginfon\" and inv type \"MSG_PCKGn\" should be defined for the type of\n>> package.  However, \"getpckgtxns\" and \"pckgtxns\" do not need to be\n>> changed.\n>>\n>> Example proposal for tx-with-unconfirmed-ancestors package relay: [19]\n>>\n>> ===Compatibility===\n>>\n>> Older clients remain fully compatible and interoperable after this\n>> change. Clients implementing this protocol will only attempt to send\n>> and request packages if agreed upon during the version handshake.\n>>\n>> ===Package Erlay===\n>>\n>> Clients using BIP330 reconciliation-based transaction relay (Erlay)\n>> are able to use package relay without interference. In fact, a package\n>> of transactions may be announced using both Erlay and package relay.\n>> After reconciliation, if the initiator would have announced a\n>> transaction by wtxid but also has package information for it, they may\n>> send \"inv(MSG_PCKG)\" instead of \"inv(WTX)\".\n>>\n>> ===Rationale===\n>>\n>> ====P2P Message Design====\n>>\n>> These p2p messages are added for communication efficiency and, as\n>> such, one should measure alternative solutions based on the resources\n>> used to communicate (not necessarily trustworthy) information: We\n>> would like to minimize network bandwidth, avoid downloading a\n>> transaction more than once, avoid downloading transactions that are\n>> eventually rejected, and minimize storage allocated for\n>> not-yet-validated transactions.\n>>\n>> Consider these (plausible) scenarios in transaction relay:\n>>\n>> Alice (the \"sender\") is relaying transactions to Bob (the \"receiver\").\n>> Alice's mempool has a minimum feerate of 1sat/vB and Bob's has a\n>> minimum feerate of 3sat/vB. For simplicity, all transactions are\n>> 1600Wu in virtual size and 500 bytes in serialized size. Apart from\n>> the spending relationships specified, all other inputs are from\n>> confirmed UTXOs.\n>>\n>> 1. Package {A, B} where A pays 0 satoshis and B pays 8000 satoshis in\n>>    fees.\n>>\n>> 2. Package {C, D} where C pays 0 satoshis and D pays 1200 satoshis in\n>>    fees.\n>>\n>> 3. Package {E, F, G, H, J} that pays 4000, 8000, 0, 2000, and 4000\n>>    satoshis in fees, respectively.\n>>\n>> ====Alternative Designs Considered====\n>>\n>> ''Package Information Only:'' Just having \"pckginfo\" gives enough\n>> information for the receiver to accept the package. Omit the\n>> \"getpckgtxns\" and \"pckgtxns\" messages. While this option is a good\n>> fallback if batched transaction download fails for some reason, it\n>> shouldn't be used as the default because it 'always' requires storage\n>> of unvalidated transactions.\n>>\n>> ''No Package Information Round:'' Instead of having a package\n>> information round, just use the child's wtxid to refer to the package\n>> and always send the entire package together. This would cause nodes to\n>> redownload duplicate transactions.\n>>\n>> I have also created a slidedeck exploring various alternative designs\n>> and some examples in which they fall flat [20]. Please feel free to\n>> suggest other alternatives.\n>>\n>> ====Versioning System====\n>>\n>> This protocol should be extensible to support multiple types of\n>> packages based on future desired use cases. Two \"flavors\" of\n>> versioning were considered:\n>>\n>> 1. When package mempool acceptance is upgraded to support more types\n>>    of packages, increment the version number (similar to Erlay).\n>> During version handshake, peers negotiate which version of package\n>> relay they will use by each sending one \"sendpackages\" message.\n>>\n>> 2. When introducing another type of package, assign a version number\n>>    to it and announce it as an additional supported version (similar\n>> to Compact Block Relay). During version handshake, peers send one\n>> \"sendpackages\" message for each version supported.\n>>\n>> The second option was favored because it allows different parameters\n>> for different versions.  For example, it should be possible to support\n>> both \"arbitrary topology but maximum 3-transaction\" package as well as\n>> \"child-with-unconfirmed-parents with default mempool ancestor limits\"\n>> packages simultaneously.\n>>\n>> ==Acknowledgements==\n>>\n>> I hope to have made it abundantly clear that this proposal isn\u2019t\n>> inventing the concept of package relay, and in fact builds upon years\n>> of work by many others, including Suhas Daftuar and Antoine Riard.\n>>\n>> Thank you to John Newbery and Martin Zumsande for input on the design.\n>>\n>> Thank you to Matt Corallo, Christian Decker, David Harding, Antoine\n>> Poinsot, Antoine Riard, Gregory Sanders, Chris Stewart, Bastien\n>> Teinturier, and others for input on the desired interface for\n>> contracting protocols.\n>>\n>> Looking forward to hearing your thoughts!\n>>\n>> Best,\n>> Gloria\n>>\n>> [0]:\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019817.html\n>> [1]:\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-April/002639.html\n>> [2]:\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-June/002758.html\n>> [3]:\n>> https://github.com/t-bast/lightning-docs/blob/master/pinning-attacks.md\n>> [4]:\n>> https://github.com/revault/practical-revault/blob/master/transactions.md#cancel_tx\n>> [5]:\n>> https://github.com/discreetlogcontracts/dlcspecs/blob/master/Transactions.md#refund-transaction\n>> [6]: https://gist.github.com/instagibbs/60264606e181451e977e439a49f69fe1\n>> [7]:\n>> https://btctranscripts.com/adopting-bitcoin/2021/2021-11-16-gloria-zhao-transaction-relay-policy/#lightning-attacks\n>> [8]: https://youtu.be/fbWSQvJjKFs?t=1438\n>> [9]:\n>> https://www.reddit.com/r/Bitcoin/comments/unew4e/looks_like_70_mvb_of_transactions_just_got_dumped/\n>> [10]: https://github.com/bitcoin/bitcoin/pull/7594\n>> [11]: https://github.com/bitcoin/bitcoin/pull/7600\n>> [12]: https://github.com/bitcoin/bitcoin/pull/6455#issuecomment-122716820\n>> [13]: https://gist.github.com/sdaftuar/8756699bfcad4d3806ba9f3396d4e66a\n>> [14]: https://github.com/bitcoin/bitcoin/issues/14895\n>> [15]: https://github.com/bitcoin/bitcoin/pull/16401\n>> [16]: https://github.com/bitcoin/bitcoin/pull/19621\n>> [17]:\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html\n>> [18]: https://github.com/users/glozow/projects/5/views/4?layout=board\n>> [19]: https://gist.github.com/glozow/9b321cd3ef6505135c763112033ff2a7\n>> [20]:\n>> https://docs.google.com/presentation/d/1B__KlZO1VzxJGx-0DYChlWawaEmGJ9EGApEzrHqZpQc/edit?usp=sharing\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221101/d77fa967/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Package Relay Proposal",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Gloria Zhao"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 40807
        }
    },
    {
        "title": "[bitcoin-dev] Solving Multi-Party Flows Pinning with Opt-in Full-RBF Spent-nVersion Signaling",
        "thread_messages": [
            {
                "author": "Antoine Riard",
                "date": "2022-11-02T02:21:59",
                "message_text_only": "Hi list,\n\nReading Suhas's post on mempool policy consistency rules, and the grounded\nsuggestion that as protocol developers we should work on special policy\nrules to support each reasonable use case on the network rather to arbiter\nbetween class of use-cases in the design of an\nunified set of rules, reminded me there is another solution to solve\nmulti-party funding pinning rather than wide deployment of fullrbf. This\nwas communicated to me a while back, and it was originally dismissed\nbecause of the privacy trade-offs (and potential slight fees overhead\ncost). However, if widely adopted, they might sound acceptable to\ncontracting protocol developers and operators.\n\n## The Problem: Pinning Contracting Protocols Funding Flows with Opt-out\nDouble-Spend\n\nAs originally laid out [0], multi-party collaborative flows\n(coinjoin/dual-funding/swaps/splicing/etc), where every participant\ncontributes at least one input, are suffering from a low-cost and\nhigh-success DoS vector with asymmetric damages. E.g with lightning\ninteractive transaction construction protocols limits of 252 inputs, 1\nsingle input can bleed the timevalue of the remaining 251 inputs, or engage\nin a MEV attack where the fee-bumping entity is lured to inflate feerate\nbeyond the current blockspace demand. The attack can be hidden and a\nposteriori assigning blame consistently stays an open question in the lack\nof a consensus mechanism between participants on the network mempools\nstates.\n\nThe issue lies in the fact that participants joining inputs together don't\nhave control, or even view, of the replacement signaling of any potential\ndouble-spend of the other participants inputs. Indeed the opt-in fullrbf\nsignaling is enforced based on the nSequence field, and this one is fully\nmalleable by the UTXO spender. There is no current mechanism to require\nreplacement signaling provable to a third-party only on the knowledge of\nthe UTXO spents.\n\n# The Solution: Opt-in Full-Replace-by-Fee Spent-nVersion Signaling\n\nA new policy is specified in a new way a transaction can signal that it is\nreplaceable.\n\n1. A confirmed transaction is considered to have opted in to allowing\nreplacement of any of its spends (or their descendants), if the last bit of\nthe nVersion field is set.\n\nRational: The future replacement status of any UTXO spend can be determined\nby inspecting the nVersion, therefore protecting the collaborative\nparticipants of a multi-party flows that the target transaction should\npropagate to the miners, if the fee/feerate offered are the best ones\nwithout opt-out based pinning. It can be required the UTXOs to have few\nconfirmations in case of shallow reorgs to increase DoS protection.\n\n## Solution trade-offs\n\nOn the validation-side, there is one engineering issue, as I think there is\nno access to the spent nversion fields by the mempool logic. This would\npresume we add some new cache of all the confirmed UTXOs, so ~50M * 4bytes,\n300 MB of additional state for policy-enforcing full-nodes. I don't know if\nthere is another strong drawback, even the reorg logic the replaceable\nspends shouldn't be evicted if the confirmed ancestor is back to the\nmempool, as mempool validity shouldn't be reevaluated before a replacement\ncandidate shows up. A fee penalty could be requested for nVersion-signaling\ntransactions to compensate for the additional state stored by full-node\noperators (even if obviously they're not the ones earning the fees).\n\nFor the contracting protocols wallets, as you don't know in advance which\ncoins are going to be used for a collaborative flow, you're better off to\nmark all your coins nVersion fields opting fullrbf. Otherwise, you will\nhave to go through an on-chain fee cost to change the replacement status of\nthe spends of your coins. However, this policy bookmarking comes as a\nprotocol fingerprint leak for an observer of the transaction logs. If all\nthe second-layers used by default, this is constituting a single anonymity\nset, though it might still be the privacy gains we're harvesting from\nTaproot output usage in the optimistic case (e.g in Lightning no commitment\n+ HTLC transactions broadcast).\n\nFor the zeroconf operators, assuming they have access to the UTXO set, they\ncan inspect the receiving transactions ancestors nVersion fields, and sort\nthose transactions in the wider set of the replaceable ones, as they're\ncurrently doing for BIP125 opt-in ones.\n\nLong-term, the annoying privacy issue and the assumption that any wallet\nwill be a Lightning one could lead to the majority of wallets signaling RBF\nfor their spends. Therefore making those wallets incompatible with zeroconf\nservices, slowly economically outlawing them. From my perspective, though\nit might be a simplification, it sounds an alternative full rbf way\nforward, where rather than having miners deciding on the policy\nenforcement, we let the users decide with their coins. However, this new\npolicy enforcement efficiency is still dependent on the existence of relay\npaths and support at the endpoints that matter, the miner mempools. So in\nfine we might have to realize incentive alignment with hashrate is what\nmatters in terms of transaction-relay rules ?\n\nCredit to Greg Maxwell for this idea.\n\nCheers,\nAntoine\n\n[0]\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2021-May/003033.html\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221101/7190a0df/attachment-0001.html>"
            },
            {
                "author": "Greg Sanders",
                "date": "2022-11-02T13:58:59",
                "message_text_only": "My idea, which I hated and didn't propose, was to mark utxos specifically\nfor this exact purpose, but this is extremely ugly from a wallet/consensus\nperspective. nVersion is cleaner(well, except the below issue), at the cost\nof forcibly marking all utxos in a transaction the same way.\n\n> On the validation-side, there is one engineering issue, as I think there\nis no access to the spent nversion fields by the mempool logic.\n\nI don't think Core tracks this value in the utxo set either, because\ncurrently there's no use-case for it today? Am I mistaken?\n\n/**\n * A UTXO entry.\n *\n * Serialized format:\n * - VARINT((coinbase ? 1 : 0) | (height << 1))\n * - the non-spent CTxOut (via TxOutCompression)\n */\n\nGreg\n\n\nOn Wed, Nov 2, 2022 at 6:27 AM Antoine Riard via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi list,\n>\n> Reading Suhas's post on mempool policy consistency rules, and the grounded\n> suggestion that as protocol developers we should work on special policy\n> rules to support each reasonable use case on the network rather to arbiter\n> between class of use-cases in the design of an\n> unified set of rules, reminded me there is another solution to solve\n> multi-party funding pinning rather than wide deployment of fullrbf. This\n> was communicated to me a while back, and it was originally dismissed\n> because of the privacy trade-offs (and potential slight fees overhead\n> cost). However, if widely adopted, they might sound acceptable to\n> contracting protocol developers and operators.\n>\n> ## The Problem: Pinning Contracting Protocols Funding Flows with Opt-out\n> Double-Spend\n>\n> As originally laid out [0], multi-party collaborative flows\n> (coinjoin/dual-funding/swaps/splicing/etc), where every participant\n> contributes at least one input, are suffering from a low-cost and\n> high-success DoS vector with asymmetric damages. E.g with lightning\n> interactive transaction construction protocols limits of 252 inputs, 1\n> single input can bleed the timevalue of the remaining 251 inputs, or engage\n> in a MEV attack where the fee-bumping entity is lured to inflate feerate\n> beyond the current blockspace demand. The attack can be hidden and a\n> posteriori assigning blame consistently stays an open question in the lack\n> of a consensus mechanism between participants on the network mempools\n> states.\n>\n> The issue lies in the fact that participants joining inputs together don't\n> have control, or even view, of the replacement signaling of any potential\n> double-spend of the other participants inputs. Indeed the opt-in fullrbf\n> signaling is enforced based on the nSequence field, and this one is fully\n> malleable by the UTXO spender. There is no current mechanism to require\n> replacement signaling provable to a third-party only on the knowledge of\n> the UTXO spents.\n>\n> # The Solution: Opt-in Full-Replace-by-Fee Spent-nVersion Signaling\n>\n> A new policy is specified in a new way a transaction can signal that it is\n> replaceable.\n>\n> 1. A confirmed transaction is considered to have opted in to allowing\n> replacement of any of its spends (or their descendants), if the last bit of\n> the nVersion field is set.\n>\n> Rational: The future replacement status of any UTXO spend can be\n> determined by inspecting the nVersion, therefore protecting the\n> collaborative participants of a multi-party flows that the target\n> transaction should propagate to the miners, if the fee/feerate offered are\n> the best ones without opt-out based pinning. It can be required the UTXOs\n> to have few confirmations in case of shallow reorgs to increase DoS\n> protection.\n>\n> ## Solution trade-offs\n>\n> On the validation-side, there is one engineering issue, as I think there\n> is no access to the spent nversion fields by the mempool logic. This would\n> presume we add some new cache of all the confirmed UTXOs, so ~50M * 4bytes,\n> 300 MB of additional state for policy-enforcing full-nodes. I don't know if\n> there is another strong drawback, even the reorg logic the replaceable\n> spends shouldn't be evicted if the confirmed ancestor is back to the\n> mempool, as mempool validity shouldn't be reevaluated before a replacement\n> candidate shows up. A fee penalty could be requested for nVersion-signaling\n> transactions to compensate for the additional state stored by full-node\n> operators (even if obviously they're not the ones earning the fees).\n>\n> For the contracting protocols wallets, as you don't know in advance which\n> coins are going to be used for a collaborative flow, you're better off to\n> mark all your coins nVersion fields opting fullrbf. Otherwise, you will\n> have to go through an on-chain fee cost to change the replacement status of\n> the spends of your coins. However, this policy bookmarking comes as a\n> protocol fingerprint leak for an observer of the transaction logs. If all\n> the second-layers used by default, this is constituting a single anonymity\n> set, though it might still be the privacy gains we're harvesting from\n> Taproot output usage in the optimistic case (e.g in Lightning no commitment\n> + HTLC transactions broadcast).\n>\n> For the zeroconf operators, assuming they have access to the UTXO set,\n> they can inspect the receiving transactions ancestors nVersion fields, and\n> sort those transactions in the wider set of the replaceable ones, as\n> they're currently doing for BIP125 opt-in ones.\n>\n> Long-term, the annoying privacy issue and the assumption that any wallet\n> will be a Lightning one could lead to the majority of wallets signaling RBF\n> for their spends. Therefore making those wallets incompatible with zeroconf\n> services, slowly economically outlawing them. From my perspective, though\n> it might be a simplification, it sounds an alternative full rbf way\n> forward, where rather than having miners deciding on the policy\n> enforcement, we let the users decide with their coins. However, this new\n> policy enforcement efficiency is still dependent on the existence of relay\n> paths and support at the endpoints that matter, the miner mempools. So in\n> fine we might have to realize incentive alignment with hashrate is what\n> matters in terms of transaction-relay rules ?\n>\n> Credit to Greg Maxwell for this idea.\n>\n> Cheers,\n> Antoine\n>\n> [0]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-May/003033.html\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/70b6a272/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2022-11-02T14:04:03",
                "message_text_only": "On Tue, Nov 01, 2022 at 10:21:59PM -0400, Antoine Riard via bitcoin-dev wrote:\n> Hi list,\n> \n> Reading Suhas's post on mempool policy consistency rules, and the grounded\n> suggestion that as protocol developers we should work on special policy\n> rules to support each reasonable use case on the network rather to arbiter\n> between class of use-cases in the design of an\n> unified set of rules, reminded me there is another solution to solve\n> multi-party funding pinning rather than wide deployment of fullrbf. This\n> was communicated to me a while back, and it was originally dismissed\n> because of the privacy trade-offs (and potential slight fees overhead\n> cost). However, if widely adopted, they might sound acceptable to\n> contracting protocol developers and operators.\n\nStrong NACK.\n\nZeroconf is, at best, a very marginal usecase. The only services that have\nspoken up in support of it are Bitrefill and Muun, and the latter says they're\nworking to get rid of their vulnerability to it. People attempting to make it\nsecure have repeatedly done sybil attacks against the network in attempts to\nmeasure transaction propagation. And of course, if transaction fees and full\nmempools are in our near future - as is widely expected - mempool consistency\nwill even further diminish making zeroconf even harder to achieve.\n\nIncurring a bunch of engineering costs and harming privacy for the sake of\ncontinuing this nonsense is ridiculous.\n\nIf anything, we should be moving to full-RBF so we can undo the privacy cost\nthat is opt-in-RBF: right now 30% of transactions are having to harm their\nprivacy by signalling support for it. Full-RBF will allow that wallet\ndistinguisher to be eliminated.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/57de210a/attachment.sig>"
            },
            {
                "author": "Greg Sanders",
                "date": "2022-11-02T14:19:00",
                "message_text_only": "Sorry, I forgot one point which is pertinent to this conversation.\n\n*Even with* fullrbf-everywhere and V3, pinning via rule#3 and rule#5 are\nstill an issue in coinjoin scenarios.\n\nEach coinjoin adversary can double-spend their coin to either full package\nweight(101kvb),\nor give 24 descendants, which means you quickly pay out the nose in rule#3\nor are excluded\nfrom RBFing it if you have 4+ greifers in your coinjoin violating rule#5.\n\nIf we instead narrowed this policy to marking a transaction output as\nopt-in to V3, it gets a bit more interesting. *Unfortunately,\ndouble-spending counterparties can still cause rule#3 pain, one 100kvb\npackage of junk per peer,* but rule#5 violations is at least contained to\ncoinjoins with ~50 peers(assuming two transactions booted per input\ndouble-spent, which would be the V3 max bumped per input).\n\nIt's still worth exploring, but very speculatively.\n\nGreg\n\nOn Wed, Nov 2, 2022 at 10:04 AM Peter Todd via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Tue, Nov 01, 2022 at 10:21:59PM -0400, Antoine Riard via bitcoin-dev\n> wrote:\n> > Hi list,\n> >\n> > Reading Suhas's post on mempool policy consistency rules, and the\n> grounded\n> > suggestion that as protocol developers we should work on special policy\n> > rules to support each reasonable use case on the network rather to\n> arbiter\n> > between class of use-cases in the design of an\n> > unified set of rules, reminded me there is another solution to solve\n> > multi-party funding pinning rather than wide deployment of fullrbf. This\n> > was communicated to me a while back, and it was originally dismissed\n> > because of the privacy trade-offs (and potential slight fees overhead\n> > cost). However, if widely adopted, they might sound acceptable to\n> > contracting protocol developers and operators.\n>\n> Strong NACK.\n>\n> Zeroconf is, at best, a very marginal usecase. The only services that have\n> spoken up in support of it are Bitrefill and Muun, and the latter says\n> they're\n> working to get rid of their vulnerability to it. People attempting to make\n> it\n> secure have repeatedly done sybil attacks against the network in attempts\n> to\n> measure transaction propagation. And of course, if transaction fees and\n> full\n> mempools are in our near future - as is widely expected - mempool\n> consistency\n> will even further diminish making zeroconf even harder to achieve.\n>\n> Incurring a bunch of engineering costs and harming privacy for the sake of\n> continuing this nonsense is ridiculous.\n>\n> If anything, we should be moving to full-RBF so we can undo the privacy\n> cost\n> that is opt-in-RBF: right now 30% of transactions are having to harm their\n> privacy by signalling support for it. Full-RBF will allow that wallet\n> distinguisher to be eliminated.\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/2c4439ba/attachment-0001.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2022-11-02T14:33:51",
                "message_text_only": "On Wed, Nov 02, 2022 at 10:19:00AM -0400, Greg Sanders wrote:\n> Sorry, I forgot one point which is pertinent to this conversation.\n> \n> *Even with* fullrbf-everywhere and V3, pinning via rule#3 and rule#5 are\n> still an issue in coinjoin scenarios.\n> \n> Each coinjoin adversary can double-spend their coin to either full package\n> weight(101kvb),\n> or give 24 descendants, which means you quickly pay out the nose in rule#3\n\n...and the attacker also pays out the nose if they're exploiting rule #3.\n\n> or are excluded\n> from RBFing it if you have 4+ greifers in your coinjoin violating rule#5.\n> \n> If we instead narrowed this policy to marking a transaction output as\n> opt-in to V3, it gets a bit more interesting. *Unfortunately,\n> double-spending counterparties can still cause rule#3 pain, one 100kvb\n> package of junk per peer,* but rule#5 violations is at least contained to\n> coinjoins with ~50 peers(assuming two transactions booted per input\n> double-spent, which would be the V3 max bumped per input).\n\nThere's no hard technical reason for rule #5 to even exist. It's simply a\nconservative DoS limit to avoid having to do \"too much\" computation when\nprocessing a replacement in some replacement implementations. We shouldn't\nassume it will always exist. And like rule #3 pinning, exploiting it costs\nmoney.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/addb7935/attachment.sig>"
            },
            {
                "author": "Greg Sanders",
                "date": "2022-11-02T15:00:47",
                "message_text_only": "> ...and the attacker also pays out the nose if they're exploiting rule #3.\n\nI agree the attacker puts more at stake in this case. If we're assuming\nthey pay the price and get mined, they can be booted from the protocol\nwhenever they get mined. I was speaking about the worst case scenario where\nit's never mined.\n\n> We shouldn't assume it will always exist.\n\nJust making sure people know that today it does impact things today.\n\nOn Wed, Nov 2, 2022, 10:33 AM Peter Todd <pete at petertodd.org> wrote:\n\n> On Wed, Nov 02, 2022 at 10:19:00AM -0400, Greg Sanders wrote:\n> > Sorry, I forgot one point which is pertinent to this conversation.\n> >\n> > *Even with* fullrbf-everywhere and V3, pinning via rule#3 and rule#5 are\n> > still an issue in coinjoin scenarios.\n> >\n> > Each coinjoin adversary can double-spend their coin to either full\n> package\n> > weight(101kvb),\n> > or give 24 descendants, which means you quickly pay out the nose in\n> rule#3\n>\n> ...and the attacker also pays out the nose if they're exploiting rule #3.\n>\n> > or are excluded\n> > from RBFing it if you have 4+ greifers in your coinjoin violating rule#5.\n> >\n> > If we instead narrowed this policy to marking a transaction output as\n> > opt-in to V3, it gets a bit more interesting. *Unfortunately,\n> > double-spending counterparties can still cause rule#3 pain, one 100kvb\n> > package of junk per peer,* but rule#5 violations is at least contained to\n> > coinjoins with ~50 peers(assuming two transactions booted per input\n> > double-spent, which would be the V3 max bumped per input).\n>\n> There's no hard technical reason for rule #5 to even exist. It's simply a\n> conservative DoS limit to avoid having to do \"too much\" computation when\n> processing a replacement in some replacement implementations. We shouldn't\n> assume it will always exist. And like rule #3 pinning, exploiting it costs\n> money.\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/308e61cf/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Solving Multi-Party Flows Pinning with Opt-in Full-RBF Spent-nVersion Signaling",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Antoine Riard",
                "Peter Todd",
                "Greg Sanders"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 21172
        }
    },
    {
        "title": "[bitcoin-dev] On mempool policy consistency",
        "thread_messages": [
            {
                "author": "Anthony Towns",
                "date": "2022-11-02T03:07:45",
                "message_text_only": "On Mon, Oct 31, 2022 at 12:25:46PM -0400, Greg Sanders via bitcoin-dev wrote:\n> For 0-conf services we have potential thieves who are willing\n> to *out-bid themselves* to have funds come back to themselves. It's not a\n> \"legitimate\" use-case, but a rational one.\n\nI think that's a huge oversimplification of \"rational\" -- otherwise\nyou might as well say that deliberately pinning txs is also rational,\nbecause it allows the person doing the pinning to steal funds from their\ncounterparty by forcing a timeout to expire.\n\nThere's no need for us as developers, or us as node operators, to support\nevery use case that some individual might find rational at some point in\ntime. After all, it might be individually rational for someone to want the\nsubsidy to stop decreasing, or to include 8MB of transactions per block.\n\nNote that it's also straightforwardly rational and incentive compatible\nfor miners to not want this patch to be available, under the following\nscenario:\n\n - a significant number of on-chain txs are for zeroconf services\n - fee income would be reduced if zeroconf services went away\n   (both directly due to the absence of zeroconf payments, and by\n   reducing mempool pressure, reducing fee income from the on-chain txs\n   that remain)\n - miners adopting fullrbf would cause zeroconf services to go away,\n   (and won't enable a comparable volume of new services that generates\n   comparable transaction volume)\n - including the option in core would make other miners adopting\n   fullrbf more likely\n\nI think the first three of those are fairly straightforward and objective,\nat least at this point in time. The last is just a risk; but without\nany counterbalancing benefit, why take it?\n\nGaining a few thousand sats due to high feerate replacement txs from\npeople exploiting zeroconf services for a few months before all those\nservices shutdown doesn't make up for the lost fee income over the months\nor years it might have otherwise taken people to naturally switch to\nsome better alternative.\n\nEven if fullrbf worked for preventing pinning that likely doesn't directly\nresult in much additional fee income: once you know that pinning doesn't\nwork, you just don't try it, which means there's no opportunity for\nminers to profit from a bidding war from the pinners counterparties\nrepeatedly RBFing their preferred tx to get it mined.\n\nThat also excludes second order risks: if you can't do zeroconf with BTC\nanymore, do you switch to ERC20 tokens, and then trade your BTC savings\nfor ETH or USDT, and do enough people do that to lower the price of BTC?\nIf investors see BTC being less used for payments, does that lower their\nconfidence in bitcoin's future, and cause them to sell?\n\n> Removing a\n> quite-likely-incentive-compatible option from the software just encourages\n> miners to adopt an additional patch\n\nWhy shouldn't miners adopt an additional patch if they want some unusual\nfunctionality?\n\nDon't we want/expect miners to have the ability to change the code in\nmeaningful ways, at a minimum to be able to cope with the scenario where\ncore somehow gets coopted and releases bad code, or to be able to deal\nwith the case where an emergency patch is needed?\n\nIs there any evidence miners even want this option? Peter suggested\nthat some non-signalling replacements were being mined already [0], but\nas far as I can see [1] all of those are simply due to the transaction\nthey replaced not having propagated in the first place (or having been\nevicted somehow? hard to tell without any data on the original tx).\n\n[0] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-October/021012.html\n[1] https://github.com/bitcoin/bitcoin/pull/26287#issuecomment-1292692367\n\n> 2) Forcing miners to honor fees left on the table with respect to 0-conf,\n> or forcing them to run a custom patchset to go around it, is a step\n> backwards.\n\nAs you already acknowledged, any miner that wants this behaviour can just\npick up the patch (or could run Knots, which already has the feature\nenabled by default). It's simply false to say miners are being forced\nto do anything, no matter what we do here. \n\nIf the direction you're facing is one where you're moving towards making\nlife easier for people to commit fraud, and driving away businesses\nthat aren't doing anyone harm, without achieving anything much else;\nthen taking a step backwards seems like a sensible thing to do to me.\n\n(I remain optimistic about coming up with better RBF policy, and willing\nto be gung ho about everyone switching over to it even if it does kill\noff zeroconf, provided it actually does some good and we give people 6\nmonths or more notice that it's definitely happening and what exactly\nthe new rules will be, though)\n\nCheers,\naj"
            },
            {
                "author": "Greg Sanders",
                "date": "2022-11-02T13:32:49",
                "message_text_only": "> I think that's a huge oversimplification of \"rational\" -- otherwise\nyou might as well say that deliberately pinning txs is also rational,\nbecause it allows the person doing the pinning to steal funds from their\ncounterparty by forcing a timeout to expire.\n\nTo be clear, a pinner is attempting to *not* pay\nthe most fees, by definition. If we're somehow sure something is a pin,\nwe should not allow it, because miners rationally do not want it vs\nan \"honest\" bid for fees. V3 design is one attempt to carve out a safe\nspace for fee bidding. Carving out a safe space for *non-bidding* is not the\nsame thing.\n\nI think this mostly boils down having knobs or not. I'm fine with knobs\nwith paternalistic defaults, especially when a non-zero percentage of users\ndisagree with a value in either direction.\n\nGreg\n\nOn Tue, Nov 1, 2022 at 11:07 PM Anthony Towns <aj at erisian.com.au> wrote:\n\n> On Mon, Oct 31, 2022 at 12:25:46PM -0400, Greg Sanders via bitcoin-dev\n> wrote:\n> > For 0-conf services we have potential thieves who are willing\n> > to *out-bid themselves* to have funds come back to themselves. It's not a\n> > \"legitimate\" use-case, but a rational one.\n>\n> I think that's a huge oversimplification of \"rational\" -- otherwise\n> you might as well say that deliberately pinning txs is also rational,\n> because it allows the person doing the pinning to steal funds from their\n> counterparty by forcing a timeout to expire.\n>\n> There's no need for us as developers, or us as node operators, to support\n> every use case that some individual might find rational at some point in\n> time. After all, it might be individually rational for someone to want the\n> subsidy to stop decreasing, or to include 8MB of transactions per block.\n>\n> Note that it's also straightforwardly rational and incentive compatible\n> for miners to not want this patch to be available, under the following\n> scenario:\n>\n>  - a significant number of on-chain txs are for zeroconf services\n>  - fee income would be reduced if zeroconf services went away\n>    (both directly due to the absence of zeroconf payments, and by\n>    reducing mempool pressure, reducing fee income from the on-chain txs\n>    that remain)\n>  - miners adopting fullrbf would cause zeroconf services to go away,\n>    (and won't enable a comparable volume of new services that generates\n>    comparable transaction volume)\n>  - including the option in core would make other miners adopting\n>    fullrbf more likely\n>\n> I think the first three of those are fairly straightforward and objective,\n> at least at this point in time. The last is just a risk; but without\n> any counterbalancing benefit, why take it?\n>\n> Gaining a few thousand sats due to high feerate replacement txs from\n> people exploiting zeroconf services for a few months before all those\n> services shutdown doesn't make up for the lost fee income over the months\n> or years it might have otherwise taken people to naturally switch to\n> some better alternative.\n>\n> Even if fullrbf worked for preventing pinning that likely doesn't directly\n> result in much additional fee income: once you know that pinning doesn't\n> work, you just don't try it, which means there's no opportunity for\n> miners to profit from a bidding war from the pinners counterparties\n> repeatedly RBFing their preferred tx to get it mined.\n>\n> That also excludes second order risks: if you can't do zeroconf with BTC\n> anymore, do you switch to ERC20 tokens, and then trade your BTC savings\n> for ETH or USDT, and do enough people do that to lower the price of BTC?\n> If investors see BTC being less used for payments, does that lower their\n> confidence in bitcoin's future, and cause them to sell?\n>\n> > Removing a\n> > quite-likely-incentive-compatible option from the software just\n> encourages\n> > miners to adopt an additional patch\n>\n> Why shouldn't miners adopt an additional patch if they want some unusual\n> functionality?\n>\n> Don't we want/expect miners to have the ability to change the code in\n> meaningful ways, at a minimum to be able to cope with the scenario where\n> core somehow gets coopted and releases bad code, or to be able to deal\n> with the case where an emergency patch is needed?\n>\n> Is there any evidence miners even want this option? Peter suggested\n> that some non-signalling replacements were being mined already [0], but\n> as far as I can see [1] all of those are simply due to the transaction\n> they replaced not having propagated in the first place (or having been\n> evicted somehow? hard to tell without any data on the original tx).\n>\n> [0]\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-October/021012.html\n> [1] https://github.com/bitcoin/bitcoin/pull/26287#issuecomment-1292692367\n>\n> > 2) Forcing miners to honor fees left on the table with respect to 0-conf,\n> > or forcing them to run a custom patchset to go around it, is a step\n> > backwards.\n>\n> As you already acknowledged, any miner that wants this behaviour can just\n> pick up the patch (or could run Knots, which already has the feature\n> enabled by default). It's simply false to say miners are being forced\n> to do anything, no matter what we do here.\n>\n> If the direction you're facing is one where you're moving towards making\n> life easier for people to commit fraud, and driving away businesses\n> that aren't doing anyone harm, without achieving anything much else;\n> then taking a step backwards seems like a sensible thing to do to me.\n>\n> (I remain optimistic about coming up with better RBF policy, and willing\n> to be gung ho about everyone switching over to it even if it does kill\n> off zeroconf, provided it actually does some good and we give people 6\n> months or more notice that it's definitely happening and what exactly\n> the new rules will be, though)\n>\n> Cheers,\n> aj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/a1614798/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-11-02T19:50:26",
                "message_text_only": "Hi Suhas,\n\n>From my understanding, the main crux of the reasoning exposed in your post\nwould be to solidify the transaction-relay paradigm we have been following\nduring the last years, e.g introducing the carve-out rule specifically for\nlightning commitment transactions, or more recently version=3 transactions.\nI think this paradigm could be described summarly as \"to each use-case\nbelongs a set of transaction-relay policy rules\". Some of this set of rules\ncould aim to non-replacement guarantees to the consumers of transactions\nsignaling under this regime (e.g zeroconf). Another set of rules could\nprovide a high-guarantee that a transaction would always get to a miner, no\nmatter what the state of node's mempools on the network (e.g \"maximal rbf\"\nfor contracting protocols).\n\nFirst, coming out of my mind, we would have to consider isolation between\neach set of policy rules, ensuring the signaling mechanism cannot be abused\nby an attacker to create a new pinning vector. E.g, a hypothetical concern\ncould be BIP125 rules interfering with version=3 policy to block the\nreplacement of better ancestor feerate packages. Further, for each set of\npolicy rules arises the question of internal consistency, again an attacker\ncould abuse them to pin transactions\npropagation. I think an earlier version of version=3 was suffering from\nthis concern of not scoping potential \"junk\" ancestors. None of those\nissues are unsolvable, however we should be well-aware of the\nnon-negligeable design complexity encumbered by transaction-relay protocol\ndevelopers to achieve the correct goal. There is not only a need to ensure\ncareful policy rules security analysis, but further to communicate well\ntheir usage to second-layers and wallets developers (a task far from easy\nwith all the confusions contained by current BIP125).\n\nNow, in the evaluation process of a set of policy rules soundness are\nproposed a few reasoning heuristics: namely that it shouldn't interfere\nsensibly with a anti-DoS mempool acceptance algorithm, or shouldn't\ninterfere with other protocols on the network, or counter the interests of\nminers or node operators. I hold the belief the latest question could be\nthe one raising the most concerns. Browsing in the history of Bitcoin Core,\nI think one of the design goals aimed for has always been to level the\nplaying field between miners, e.g BIP152 improving block transfer latency\nto reduce orphan rate. Following this principle, we might wonder if our\ntransaction-relay network should guarantee some equal access to transaction\ninformation to all the miners.\n\nIn the present case of a non-replacement policy regime, we could see the\nfollowing situation to arise, on one side miners deploying private\ntransaction-relay communication channels or API to capture higher fees\nincome from non-standard transactions. On the other-side, transaction\nissuers or consumers bypass the standard transaction-relay policy rules.\nBypass could be motivated by either a zeroconf service double-spend, or\nfaster confirmation of a collaborative transaction. E.g, to reuse the\nexample of unconfirmed transaction chaining, where the sender commit to\nnon-replacement by opting out from the RBF flag, this commitment could be\nreevaluated in the light of changing network mempools congestion, or\nliquidity preferences (e.g the quick need to open LN routing channels). The\nsender could leverage such hypothetical private transaction-relay\ncommunication channels to revoke its non-replacement commitment. Therefore\ndiscrepancies between a set of policy rules design and miners incentives\nsounds to lead to informational asymmetries, harmful for the long-term\ndecentralization of the mining ecosystem. Of course, miner incomes\nasymmetries due to edge in transaction flows access might not be weighted\nas serious today, in a world where transaction fees contribute to most of\nthe block reward, this is far more worrying!\n\nOf course, one position could be to estimate that miner centralization is\nbeyond the scope of responsibility of the Bitcoin Core project. Or at least\nas a result of lightweighted risks.\n\nSuch discrepancy between a set of policy rules design and miners incentives\ncould also lead to hidden security risks for second-layers. As we see more\nsecurity assumptions made on policy rules extension, e.g version=3, a\nlightning channel counterparty could have a competing interest to forge a\nraw package suiting better incentives, and as such nullify the security\nadvantage expected. This could be seen as a loose concern, however the last\ntime we have seen an actor deliberately providing non-standard transactions\nto a miner to break second-layers was yesterday [0]!. From observing other\ncryptocurrencies spaces, such \"MEV-style\" attacks could be more and more\nconcerning [1]. I don't think we should assume miners to behave as \"network\ngentlemen\", in a world where mining can be anonymous, permissionless and\ncensorship-resistant (e.g Stratum V2 giving back template construction to\nminers operators rather than pools).\n\nAccording to me, one of the harder problem we're seeing with this fullrbf\ndiscussion is the lack of a consistent, grounded and well-understood miner\nincentive model, where not only block template construction but also\ntransaction collection and replacement strategies are analyzed, and against\nwhich we could simulate the efficiency of a policy. Assuming we would have\nsuch a model, rather than qualify a policy rule as incentive-compatible in\na binary fashion, we could evaluate them on a scale, and agree on when\nthey're satisfying enough in face of technical complexity, validation\nresources, margin of adversarial exploitation, or whatever other relevant\ncriteria.\n\nAnswering a few other points raised in this post, what appears to me\nobscure is the qualification that fullrbf doesn't solve the DoS issues for\ncontracting protocols (e..g coinjoin/dual-funded lightning). If I can\nunderstand, it's on the ground that the imperfections of BIP125 underscore\nonly the direct conflict feerate. It should be remembered that allowing\nreplacement without considering the opting flag would be already an\nimprovement against the DoS attack, as the attack would have to offer a\nmore compelling feerate to maintain the pin. Improvements of BIP125 can\nhappen on the top, but solving the opt-out double-spend issue sounds to me\na prerequisite.\n\nBeyond that, I think few questions are laid out on the conceptual soundness\nof v3 transaction policy w.r.t concerns raised about fullrbf today. In my\nopinion, I'm sadly with most of them, especially that miners might earn\nmore revenue if we allowed multiple descendant v3 transactions and the\nunenforceable promise for the recipient of such package to not add more\nhigh-value children, I've echoed those concerns earlier in the review of\nnVersion=3 proposal [2]. We might have to swallow the bullet for now, and\nbe okay as lightning developers and operators that there is only a social\ninertia of the miners and lack of reliable communication channels towards\nthem by an adversarial counterparty to offer security [3]. Additionally, I\nthink it would be acceptable to have an option to disable v3 transaction\npolicy, an operator could be willing to reduce the CPU/memory DoS surface\nof its node from partaking to any package relay. Even if it comes at the\nloss of a better view of blockspace demand and downgrades its\nfee-estimation, I think we should give the maximum flexibility to operators\nin choosing their risk model.\n\nTo put it in a nutshell, if we would like to pursue further in the paradigm\nthat \"to each use-case belongs its set of policy rules\" (as long as they\ndon't introduce any harm for the network stakeholders), I believe we would\nbe more grounded with a better quantitative understanding of so-called\n\"miners incentives\". I'm still wondering if it's realistic to deploy policy\nrules that are not sustainable in face of long-term mining dynamics.\n\nBest,\nAntoine\n\n\n[0] https://github.com/lightningnetwork/lnd/issues/7096\n\n[1] On risks of introducing miner harvesting attacks, especially when you\nconsider implications on lightning-style constructions\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2020-February/002569.html\nand\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-November/019615.html\n\n[2]\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-September/020939.html\n\n\"If you're a miner and you receive a non-V3, second descendant of an\nunconfirmed V3 transaction, if the offered fee is in the top mempool\nbacklog, I think you would have an interest to accept such a transaction.\n\nSo I'm not sure if those two rules are compatible with miners incentives...\"\n\n[3] This wonders if we should look forward in the future to lock in the\nCPFP weight of a Lightning commitment with some new consensus semantic, or\nleveraging any covenant magic, cf.\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-March/020122.html\nand\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-October/020991.html\n\nLe lun. 31 oct. 2022 \u00e0 11:02, Suhas Daftuar via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n> AJ,\n>\n> Thanks for the thoughtful post. I think your observations about how we\n> view mempool policy in the Bitcoin Core project, and how that seems to be\n> changing in the discussions around `-mempoolfullrbf`, are on-point and\n> provide a helpful baseline for considering future policy changes.\n>\n> For a long time I viewed fullrbf as an eventuality and I considered myself\n> to be philosophically supportive of the idea.  However, after giving this\n> issue some thought in the past few weeks, I am reversing my thinking on\n> this.  Concretely, I will argue that we should continue to maintain a relay\n> policy where replacements are rejected for transactions that don't opt-in\n> to RBF (as described in BIP 125), and moreover, that we should remove the\n> `-mempoolfullrbf` flag from Bitcoin Core\u2019s latest release candidate and not\n> plan to release software with that flag, unless (or until) circumstances\n> change on the network, which I'll discuss below.\n>\n> This is, of course, a nuanced topic, and among the considerations is a\n> philosophy of how to think about the relay policy and configuration options\n> that we make available in Bitcoin Core (a consideration that is perhaps\n> unique to that project, but I think relevant for this mailing list).\n>\n> I'll start with some technical issues regarding the benefits of enabling\n> fullrbf on the network.  In the current BIP 125 regime, every time a\n> transaction is created, a choice is made whether to subject the transaction\n> to BIP 125\u2019s RBF rules or not (based on the sequence values of the\n> inputs).  So given that users can already opt-in to RBF, the benefit of a\n> \u201cfullrbf\u201d network policy would be if, somehow, RBF users were still denied\n> the benefits of RBF due to the existence of other transactions that don\u2019t\n> opt-in.\n>\n> Along those lines, Antoine Riard brought up[1] a DoS vector that is\n> available to someone who wants to interfere with multi-party funded\n> transactions, and suggested that fullrbf would eliminate the problem.\n> After exploring that question again in this thread (thanks to Greg Sanders\n> for clarifying this to me), I understand that the issue is around ensuring\n> that a multiparty (coinjoin-type) protocol is able to make eventual\n> progress, by having a candidate multiparty transaction either eventually\n> confirm or become conflicted with something that has been confirmed, in\n> which case the double-spend information could be used to start a new\n> coinjoin round with fewer participants.  The concern Antoine and Greg have\n> brought up is that non-rbf transactions can persist in the mempool\n> ~indefinitely (at a low feerate and not subject to replacement) and\n> interfere with progress being made in a coinjoin protocol.\n>\n> However, it seems to me that similar problems exist for such a protocol\n> even in a fullrbf world, as we understand that term today.  I mentioned the\n> ability for rbf \u201cpinning\u201d to interfere with relay of the multiparty\n> transaction (even if the conflicting transaction signals for RBF \u2013 a set of\n> large but low feerate conflicting transactions can persist in the mempool\n> and make it difficult for the coinjoin transaction from confirming, at\n> least without attaching a very large fee); and as Greg mentioned in a\n> followup, the BIP 125 rule to only permit 100 transactions to be removed\n> from the mempool at a time during a replacement can also be used to pin a\n> coinjoin protocol in the same way as a non-rbf transaction today.  It seems\n> to me that what these multiparty protocols actually need is some sort of\n> \"maximal rbf\" network policy: a way to guarantee that a transaction which\n> should be desirable for a miner to mine would always get to a miner and\n> considered for inclusion in a block, no matter what the state of node\u2019s\n> mempools on the network.\n>\n> While that sounds like a reasonable thing to want on its face (and worth\n> working on), it's not how opt-in RBF works today, nor is it how transaction\n> relay has ever conceptually worked.  We have not, thus far, been able to\n> come up with a total ordering on transaction desirability.  Moreover, due\n> to all the DoS issues that exist with transaction relay, there are plenty\n> of seemingly legitimate ways to construct transactions that would not relay\n> well on the network.  Relay has only ever been a best-efforts concept,\n> where we carve out a small subset of the entire transaction universe for\n> which we try to optimize propagation.  The idea behind this approach is\n> that if every use case we can come up with has some way to achieve its\n> goals using transactions that should (eventually) be able to relay, then\n> users wouldn\u2019t have much demand for transactions that would deviate from\n> the supported policies, and we therefore shouldn\u2019t need to worry too much\n> about incentive compatibility concerns when it comes to transaction types\n> that wouldn\u2019t relay at all, even if they are high feerate.  (And when those\n> situations arise where the standard transactions do not accommodate some\n> needed use case, developers typically work to define a policy that is\n> compatible with our anti-DoS goals to support such use cases, such as with\n> the recent proposal for version=3 transactions [2].)\n>\n> BIP 125's RBF rules themselves were an effort to carve out just a subset\n> of situations where a transaction should evict conflicting ones -- it was\n> not a design that anyone thought would ensure that all replacements which\n> \"should\" be mined would always propagate.  And I don't believe that we know\n> how to design policy rules that would achieve the goals of this kind of\n> multiparty protocol in a DoS resistant way, today.  Along those lines, I\n> would point out that even the BIP 125 design itself is not entirely\n> incentive compatible, in that it is possible to construct a replacement\n> transaction that would evict transactions which would be preferable to be\n> included in a block! [3]  (This has been known for years, but fixing this\n> has proven difficult, and the only way to fix it that I\u2019m aware of would be\n> to make BIP 125 RBF even more restrictive than it is today. I do think this\n> is something that needs to be worked on.)\n>\n> Given the limitations of RBF as we have it today, it appears to be\n> incorrect that a fullrbf network policy would solve the problems Antoine\n> raised.  And so absent any other examples, it does not seem to me that\n> fullrbf solves any problems for RBF users, who are already free to choose\n> to subject their transactions to BIP 125\u2019s RBF policy.  From this\n> perspective, \"enabling fullrbf\" is really just taking away user choice to\n> opt a transaction into a non-replacement policy regime.\n>\n> I think we should ask, then, whether it is reasonable on its face that\n> users might want to opt-in to a non-replacement policy?  Or in other words,\n> is it reasonable for a user to mark a transaction as non-replaceable and\n> have that indication be enforced by the network? Note that these are two\n> different questions: you could imagine a world where fullrbf is a dominant\n> policy, but users still use the BIP 125 signaling method to indicate, in an\n> unenforced way, their intention to not replace a transaction.  This might\n> give useful information to the network or the recipient for how to interact\n> with such a transaction.\n>\n> And I think that it's entirely possible that users would continue to use\n> the BIP 125 signaling to indicate that they do not intend to replace a\n> transaction.  For better or worse, this might be because zeroconf services\n> continue to differentiate their behavior based on such a signal (possibly\n> in conjunction with other factors), or it could be because there are other\n> behaviors that could be utilized more effectively if the transaction\n> originator has made such a signal, such as the recipient chaining an\n> unconfirmed transaction as a way to bump the fee (CPFP) [4].\n>\n> If it were to be the case that users continued to use BIP 125-style\n> signaling to indicate that they do not plan to replace a transaction, would\n> that be harmful to the network?  This is not something we can stop in our\n> policy rules (short of censoring such transactions, an obviously bad\n> idea).  I think network actors can always do things that we might think are\n> harmful for the network, but that doesn\u2019t mean that there are no legitimate\n> use cases for the tools that such actors might be using.  Just because\n> someone might use some policy to adopt a zeroconf model, doesn\u2019t mean that\n> others aren\u2019t using the same policy to achieve benign ends (such as better\n> CPFP behavior).\n>\n> Moreover, while users might attempt to exploit services that offer\n> zeroconf or other differentiated behavior to non-replacement signaling\n> transactions, they also might not -- I think predicting user behavior in\n> this way (and specifically predicting the complexities of what a business\n> might do and whether users might try to subvert it) is beyond the scope of\n> what we can do as protocol developers.  Instead, I think we can try to\n> answer a different question: if a group of users were to want the ability\n> to opt-in to a non-replacement policy regime, is that a technically sound\n> option for us to have on the network and enforce in software?\n> Specifically, does that interfere with having a sensible anti-DoS mempool\n> acceptance algorithm, or interfere with other protocols on the network, or\n> necessarily run counter to the interests of miners or node operators?\n>\n> And I think the answer to that question, in looking at the difference\n> between opt-in RBF and fullrbf, is no: offering the ability to opt-in to a\n> non-replacement regime for transactions doesn't introduce any fundamental\n> issues with software or network policy or other protocols.  In a world\n> where we only had fullrbf, I could imagine at some point down the road\n> proposing a non-replacement signal myself, because the complexities around\n> transaction chains (and pinning) are more complex for the RBF case than for\n> the non-RBF case (and BIP 125 is not always incentive compatible to begin\n> with!).  Conceptually, this is no different to me than the version=3\n> transaction policy proposal that has been advancing, if we think of it as a\n> special set of restrictions on transactions designed to accommodate a\n> particular use case.\n>\n> Philosophically, I think we should be looking to add non-interfering use\n> cases to what the network supports.\n>\n> To those who argue for making fullrbf a default policy on the network (or\n> even just offering a flag for users to enable fullrbf), I pose this\n> hypothetical: suppose we deploy the v3 transaction policy proposal (which I\n> hope will happen in the near future).  That policy would restrict the ways\n> that outputs of a v3 transaction can be spent while the transaction is\n> unconfirmed, including by limiting the number and size of descendants that\n> such a transaction can have, and limiting the types of unconfirmed\n> ancestors that can be included.  Suppose in a few years someone proposes\n> that we add a \"-disable_v3_transaction_enforcement\" flag to our software,\n> to let users decide to turn off those policy restrictions and treat v3\n> transactions the same as v2, for all the same reasons that could be argued\n> today with fullrbf: miners might earn more revenue if we allowed multiple\n> descendant v3 transactions; it's illogical for the recipient of a v3\n> transaction to believe what is a fundamentally unenforceable promise of a\n> sender to not issue more high value children that descend from an\n> unconfirmed transaction; it's inappropriate for Bitcoin Core to dictate\n> policy on the network and we should honor user choice to turn off that flag\n> if that\u2019s what users want; if users are relying on v3\u2019s policy restrictions\n> for security then that is an unstable model and we should assume it will\n> get broken[5].\n>\n> It\u2019s obvious to me that adding a flag to disable v3 policy would be\n> subversive to making the lightning use case for v3 transactions work.  And\n> so my response to such a hypothetical proposal would be to argue that no,\n> we should not enable users to disable this policy, because as long as that\n> policy is just optional and working for those who want it, it shouldn\u2019t\n> harm anyone that we offer a tighter set of rules for a particular use\n> case.  Adding a way to bypass those rules is just trying to break someone\n> else\u2019s use case, not trying to add a new one.  We should not wield\n> \"incentive compatibility\" as a bludgeon for breaking things that appear to\n> be working and not causing others harm.\n>\n> I think this is exactly what is happening with fullrbf.\n>\n> In comparing v3 transaction policy with opting out of transaction\n> replacement, there is of course one significant difference that I have\n> ignored thus far: I think the real difference is an opinion about whether\n> non-replacement transactions that are being used today are, overall, bad\n> for Bitcoin, and whether lightning\u2019s use of v3 transactions in the future\n> would be bad for Bitcoin. If you think that zeroconf is unequivocally bad,\n> and that no one will be able to plausibly construct a case that lightning\n> is bad, then that qualitative judgment might sway you to not worrying about\n> the philosophical issues I've raised above, because these situations can be\n> distinguished.\n>\n> However I am not personally willing to say that I think, overall,\n> non-rbf-signaling transactions in use on the network today are bad for\n> Bitcoin (or that fullrbf is definitely good \u2013 BIP 125\u2019s rbf rules are\n> something we\u2019ve been trying to improve upon for years, with little\n> success).  Nor am I convinced that someone couldn\u2019t put together a cogent\n> argument for lightning being bad for Bitcoin, because of its reliance on\n> relay policies that are difficult to design and impossible to guarantee as\n> part of its security model.  So I choose instead to merely make a judgment\n> that seems more factually verifiable, which is that non-replacement is a\n> policy widely in use on the network today, and we largely don't have reason\n> to think (as far as I know!) that the network is seeing a lot of\n> transactions that would violate that policy.\n>\n> If it did turn out that users were commonly signaling non-replacement, but\n> then signing and trying to relay doublespends, then I think that would be a\n> very good reason for Bitcoin Core to adopt fullrbf to reflect the reality\n> of what is happening.  In the meantime, I think it makes more sense to say\n> that because we have BIP 125, there seems to be no need for users to signal\n> one way and behave another, and therefore there is no need to offer\n> software that might break a policy that is working well for some users.\n> Other software projects might choose differently, and it is after all a\n> permissionless network, so if this is in fact an unstable equilibrium that\n> will not last, then presumably someday it will be apparent it is not\n> working and we\u2019ll abandon it.  But I think the philosophy of transaction\n> relay policy in Bitcoin Core should be to support disparate use cases in\n> order to try to make everything work better, rather than break things\n> prematurely because we guess others will break them eventually anyway.\n>\n> For those that have read this long email and still favor a fullrbf network\n> policy (or even just the ability for users to be able to turn on fullrbf\n> for themselves), I\u2019d ask for thoughts on the following questions, which\n> have guided my thinking on this:\n>\n> Does fullrbf offer any benefits other than breaking zeroconf business\n> practices?  If so, what are they?\n>\n> Is it reasonable to enforce BIP 125's rbf rules on all transactions, if\n> those rules themselves are not always incentive compatible?\n>\n> If someone were to propose a command line option that breaks v3\n> transaction relay in the future, is there a logical basis for opposing that\n> which is consistent with moving towards fullrbf now?\n>\n> Cheers,\n> Suhas\n>\n>\n> [1]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-May/003033.html\n>\n> [2]\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-September/020937.html\n>\n> [3] This is because under the BIP 125 rules, the feerate of the\n> replacement transaction is not compared to the individual feerates of all\n> transactions being evicted \u2013 we just compare feerates with the transactions\n> that are directly in conflict (and not their descendants). So it\u2019s possible\n> for a transaction that would evict 2 or more transactions to have a higher\n> feerate than the direct conflicts, and higher total fee than the set being\n> evicted, but have a lower feerate (eg if it is larger) than that of some\n> subset of the set of transactions being evicted.\n>\n> [4]  Chaining unconfirmed transactions when the sender might RBF the\n> parent is far riskier than if the sender indicates they don't plan to do so\n> (chaining onto an RBF transaction creates pinning issues for the sender,\n> and risks having the child wiped out if the parent is replaced), so I think\n> this is a concrete reason why signaling that a transaction won\u2019t be\n> replaced could be useful.\n>\n> [5] This is a subtle point. I don\u2019t think v3 transactions create an\n> unreasonable security assumption for the use case it is being designed for.\n> However, I don\u2019t think anyone could rule out the possibility that someone\n> could adopt a usage pattern for v3 transactions that subverts the intent of\n> this policy.  For example, if users started using v3 transactions for all\n> their payments, then the limitations on the number of descendants could\n> directly interfere with CPFP by a recipient, and someone could argue that\n> we should break the policy in order to allow for this hypothetical\n> behavior. I think this is a similar form of argument as saying that\n> zeroconf practices + BIP 125 create an incentive to double-spend non-rbf\n> signaling transactions.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/d2ff3925/attachment-0001.html>"
            },
            {
                "author": "email at yancy.lol",
                "date": "2022-11-03T21:06:52",
                "message_text_only": "AJ/Antoine et al\n\n> What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to\n> solve that problem if they have only opt-in RBF available?\n\nAssuming Alice is a well funded advisory, with enough resources to spam \nthe network so that enough nodes see her malicious transaction first, \nhow does full-rbf solve this vs. opt-in rbf?\n\nCheers,\n-Yancy\n\nOn 2022-10-27 19:21, Anthony Towns via bitcoin-dev wrote:\n\n> On Thu, Oct 27, 2022 at 11:56:45AM +0200, John Carvalho via bitcoin-dev \n> wrote:\n> \n>> I took the time to read your whole post. Despite a diplomatic tone, I \n>> find\n>> your takeaways from all your references to remain conveniently biased \n>> for\n>> protecting the plan of RBF\n> \n> Yes, I am heavily biased against zeroconf: there's no way I'd \n> personally\n> be willing to trust it for my own incoming funds, no matter how much\n> evidence you show me that it's safe in practice. Show me a million\n> transactions where every single one worked fine, and I'm still going to\n> assume that the payment going to me is going to be the one that makes\n> the error rate tick up from 0% to 0.0001%. That's okay; just because I\n> wouldn't do something, doesn't mean other people shouldn't.\n> \n> It does mean I'm not going to be a particularly good advocate for \n> zeroconf\n> though. I mean, I might still be a fine advocate for giving people time\n> to react, making it clear what's going on, finding ways that might make\n> everyone happy, or just digging it to random technical details; but,\n> for me, I'm more interested in a world where chargebacks are \n> impossible,\n> not where we just make the best of what was possible with technology\n> from five or ten years ago.\n> \n> But that's fine: it just means that people, like yourself, who will\n> tolerate the risks of zeroconf, should be involved in the discussion.\n> \n>> You show multiple examples where, when I read them, I assume the next \n>> thing\n>> you will say will be \"so we really should stop trying to impose \n>> optional\n>> features, particularly when they affect existing use cases\" but \n>> instead you\n>> persist.\n> \n> Sure, that's natural: you read a sign saying \"you can have any ice \n> cream\n> you want for 5c\" and think \"Awesome, who wouldn't want cheap chocolate\n> ice cream!!\" and see me going for a Golden Gaytime and think \"wtf \n> dude\".\n> Different strokes.\n> \n> For me, I see the gmaxwell github comment I quoted saying:\n> \n> There is also a matter of driving competent design rather than lazy\n> first thing that works.\n> \n> and think \"yeah, okay, maybe we should be working harder to push \n> lightning\n> adoption, rather than letting people stick with wallet UX from 2015\"\n> and have altcoins take over >50% of payment volume.\n> \n> Likewise,\n> \n> There is also a very clear pattern we've seen in the past where\n> people take anything the system lets them do as strong evidence that\n> they have a irrevocable right to use the system in that way, and that\n> their only responsibility-- and if their usage harms the system it's\n> the responsibility of the system to not permit it.\n> \n> seems a pretty good match against your claim \"I expect the things I do\n> with Bitcoin today to work FOREVER.\" Better to nip that thinking in the\n> bud; and even if the best time to do that was years ago, the second \n> best\n> time to do it is still now.\n> \n> By contrast, from the same post, I'd guess you're focussing on:\n> \n> Network behavior is one of the few bits of friction\n> driving good technical design rather than \"move fast, break things, and\n> force everyone else onto my way of doing thing rather than discussing\n> the design in public\".\n> \n> and thinking \"yeah, move fast, break things, force everyone else --\n> that's exactly what's going on here, and shouldn't be\".\n> \n> But that's also okay: even when there is common ground to be found,\n> sometimes it requires actual work to get people who start from \n> different\n> views to get there.\n> \n>> The problem is that RBF has already been an option for years, and \n>> anyone\n>> that wants to use it can.\n> \n> Is that true? Antoine claims [1 [1]] that opt-in RBF isn't enough to \n> avoid\n> a DoS issue when utxos are jointly funded by untrusting partners, and,\n> aiui, that's the main motivation for addressing this now.\n> \n> [1] \n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-May/003033.html\n> \n> The scenario he describes is: A, B, C create a tx:\n> \n> inputs: A1, B1, C1 [opts in to RBF]\n> fees: normal\n> outputs:\n> [lightning channel, DLC, etc, who knows]\n> \n> they all analyse the tx, and agree it looks great; however just before\n> publishing it, A spams the network with an alternative tx, double\n> spending her input:\n> \n> inputs: A1 [does not opt in to RBF]\n> fees: low\n> outputs: A\n> \n> If A gets the timing right, that's bad for B and C because they've\n> populated their mempool with the 1st transaction, while everyone else\n> sees the 2nd one instead; and neither tx will replace the other. B and\n> C can't know that they should just cancel their transaction, eg:\n> \n> inputs: B1, C1 [opts in to RBF]\n> fees: 50% above normal\n> outputs:\n> [smaller channel, refund, whatever]\n> \n> and might instead waste time trying to fee bump the tx to get it mined,\n> or similar.\n> \n> What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to\n> solve that problem if they have only opt-in RBF available?\n> \n> If you're right that opt-in RBF is enough, that question has a good\n> answer. I don't believe anyone's presented an answer to it in the 17\n> months since Antoine raised the concern.\n> \n>> passive aggression\n>> escalation\n>> unfair advantage\n>> oppressive, dark-pattern design\n>> strong-arming and shoe-horning\n> \n> Do you really think any of that was helping your cause?\n> \n> Cheers,\n> aj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n\nLinks:\n------\n[1] \nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2021-May/003033.html\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221103/bccd03d2/attachment-0001.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2022-11-07T14:32:17",
                "message_text_only": "On November 3, 2022 5:06:52 PM AST, yancy via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>AJ/Antoine et al\n>\n>> What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to\n>> solve that problem if they have only opt-in RBF available?\n>\n>Assuming Alice is a well funded advisory, with enough resources to spam the network so that enough nodes see her malicious transaction first, how does full-rbf solve this vs. opt-in rbf?\n\nFirst of all, to make things clear, remember that the attacks were talking about are aimed at _preventing_ a transaction from getting mined. Alice wants to cheaply broadcast something with low fees that won't get mined soon (if ever), that prevents a protocol from making forward progress.\n\nWith full-rbf, who saw what transaction first doesn't matter: the higher fee paying transaction will always(*) replace the lower fee one. With opt-in RBF, spamming the network can beat out the alternative.\n\n*) So what's the catch? Well, due to limitations in today's mempool implementation, sometimes we can't fully evaluate which tx pays the higher fee. For example, if Alice spams the network with very _large_ numbers transactions spending that input, the current mempool code doesn't even try to figure out if a replacement is better.\n\nBut those limitations are likely to be fixable. And even right now, without fixing them, Alice still has to use a lot more money to pull off these attacks with full-rbf. So full-rbf definitely improves the situation even if it doesn't solve the problem completely."
            },
            {
                "author": "Erik Aronesty",
                "date": "2022-11-07T14:47:50",
                "message_text_only": ">\n>\n> With full-rbf, who saw what transaction first doesn't matter: the higher\n> fee paying transaction will always(*) replace the lower fee one. With\n> opt-in RBF, spamming the network can beat out the alternative.\n>\n\nincentivised predictability is critical when designing low level protocols,\nlike bitcoin.   the knock-on effects of deeper, network-wide predictability\nare likely beneficial in ways that are hard to predict.   for example stuff\nlike the \"sabu\" protocol might even work if full-rbf is the norm.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221107/e76ee3c5/attachment.html>"
            },
            {
                "author": "email at yancy.lol",
                "date": "2022-11-08T14:54:46",
                "message_text_only": "Peter,\n\nIt sounds like there are two attack vectors; neither of which require \nfull-rbf (correct me if I'm wrong).\n\n1) Bob has staked liquidity in a payment channel with Alice who later \ndouble spends the same inputs (at a very low feerate) resulting in a \nstalemate where neither can spend the UTXOs.  The TX that creates the \npayment channel with Bob will never be mined since the mining pool sees \nthe double spend?\n\n2) Alice spams the network with a double spend wide enough that the \ndouble spend makes it into a block before the remainder of the network \nsees the first spend.\n\nIn that case of 1), what if Bob required a opt-in rbf?  Wouldn't that \nsolve the issue?  Bob could just create a replacement transaction with \nenough fee to get back his UTXO?\n\nFor 2) it seems to me that neither full-rbf or opt-in rbf resolves this, \nalthough it's a probabilistic attack and requires spamming many nodes.\n\nCheers,\n-Yancy\n\nOn 2022-11-07 15:32, Peter Todd wrote:\n\n> On November 3, 2022 5:06:52 PM AST, yancy via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> AJ/Antoine et al\n> \n> What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to\n> solve that problem if they have only opt-in RBF available?\n> Assuming Alice is a well funded advisory, with enough resources to spam \n> the network so that enough nodes see her malicious transaction first, \n> how does full-rbf solve this vs. opt-in rbf?\n\nFirst of all, to make things clear, remember that the attacks were\ntalking about are aimed at _preventing_ a transaction from getting\nmined. Alice wants to cheaply broadcast something with low fees that\nwon't get mined soon (if ever), that prevents a protocol from making\nforward progress.\n\nWith full-rbf, who saw what transaction first doesn't matter: the\nhigher fee paying transaction will always(*) replace the lower fee\none. With opt-in RBF, spamming the network can beat out the\nalternative.\n\n*) So what's the catch? Well, due to limitations in today's mempool\nimplementation, sometimes we can't fully evaluate which tx pays the\nhigher fee. For example, if Alice spams the network with very _large_\nnumbers transactions spending that input, the current mempool code\ndoesn't even try to figure out if a replacement is better.\n\nBut those limitations are likely to be fixable. And even right now,\nwithout fixing them, Alice still has to use a lot more money to pull\noff these attacks with full-rbf. So full-rbf definitely improves the\nsituation even if it doesn't solve the problem completely.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/b618d371/attachment.html>"
            },
            {
                "author": "email at yancy.lol",
                "date": "2022-11-09T12:05:16",
                "message_text_only": "> Bob has staked liquidity in a payment channel with Alice who later\n> double spends the same inputs (at a very low feerate) resulting in a\n> stalemate where neither can spend the UTXOs.\n\nI just realized I made a mistake.  RBF will always mine the higher fee \ntransaction, so in this case, full-rbf would prevent a transaction from \nbeing pinned.\n\nOn 2022-11-08 15:54, yancy via bitcoin-dev wrote:\n\n> Peter,\n> \n> It sounds like there are two attack vectors; neither of which require\n> full-rbf (correct me if I'm wrong).\n> \n> 1) Bob has staked liquidity in a payment channel with Alice who later\n> double spends the same inputs (at a very low feerate) resulting in a\n> stalemate where neither can spend the UTXOs.  The TX that creates the\n> payment channel with Bob will never be mined since the mining pool\n> sees the double spend?\n> \n> 2) Alice spams the network with a double spend wide enough that the\n> double spend makes it into a block before the remainder of the network\n> sees the first spend.\n> \n> In that case of 1), what if Bob required a opt-in rbf?  Wouldn't that\n> solve the issue?  Bob could just create a replacement transaction with\n> enough fee to get back his UTXO?\n> \n> For 2) it seems to me that neither full-rbf or opt-in rbf resolves\n> this, although it's a probabilistic attack and requires spamming many\n> nodes.\n> \n> Cheers,\n> -Yancy\n> \n> On 2022-11-07 15:32, Peter Todd wrote:\n> \n>> On November 3, 2022 5:06:52 PM AST, yancy via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> AJ/Antoine et al\n>> \n>> What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to\n>> solve that problem if they have only opt-in RBF available?\n>> Assuming Alice is a well funded advisory, with enough resources to\n>> spam the network so that enough nodes see her malicious transaction\n>> first, how does full-rbf solve this vs. opt-in rbf?\n> \n> First of all, to make things clear, remember that the attacks were\n> talking about are aimed at _preventing_ a transaction from getting\n> mined. Alice wants to cheaply broadcast something with low fees that\n> won't get mined soon (if ever), that prevents a protocol from making\n> forward progress.\n> \n> With full-rbf, who saw what transaction first doesn't matter: the\n> higher fee paying transaction will always(*) replace the lower fee\n> one. With opt-in RBF, spamming the network can beat out the\n> alternative.\n> \n> *) So what's the catch? Well, due to limitations in today's mempool\n> implementation, sometimes we can't fully evaluate which tx pays the\n> higher fee. For example, if Alice spams the network with very _large_\n> numbers transactions spending that input, the current mempool code\n> doesn't even try to figure out if a replacement is better.\n> \n> But those limitations are likely to be fixable. And even right now,\n> without fixing them, Alice still has to use a lot more money to pull\n> off these attacks with full-rbf. So full-rbf definitely improves the\n> situation even if it doesn't solve the problem completely.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221109/fa0bd0e1/attachment-0001.html>"
            },
            {
                "author": "email at yancy.lol",
                "date": "2022-11-04T10:28:17",
                "message_text_only": "Peter,\n\n> There's nothing special about a \"full-rbf transaction\" other than the \n> fact\n> that it's replacing a previously broadcast transaction that didn't \n> signal\n> replacement.\n\nThanks, this is a piece I haven't seen.  It sounds like \"full-rbf\" \npolicy is fundamentally different from BIP125, where in BIP125 a \ntransaction must signal that it can be replaced.  If I'm reading what \nyou said correctly, then \"full-rbf\" policy will allow the replacement of \nany transaction, whether it's signaled or not..\n\n> Since all the machinery to do replacemnt already exists, adding a \n> full-rbf\n> config flag is particularly trivial. It requires just a single line in \n> the\n> mempool code.\n\nAgree the flag is trivial.  The interplay between mempool policies may \nnot be trivial.\n\nCheers,\n-Yancy\n\nOn 2022-10-31 18:51, Peter Todd wrote:\n\n> On Mon, Oct 31, 2022 at 06:21:08PM +0100, yancy via bitcoin-dev wrote:\n> \n>> Protocol Devs,\n>> \n>> After reading through this email thread and BIP125, I'm curious if \n>> non-rbf\n>> nodes will relay full-rbf transactions and vice versa.  That is to \n>> say, if\n>> only one non-rbf node exists on the network, however, every other node\n>> implements full-rbf, will the transaction still be propagated?  IE can \n>> we\n>> always guarantee a path through the network for either transaction \n>> type no\n>> matter what the combination of network policies are?\n> \n> 1) There are nodes that signal full-rbf, and preferentially peer to \n> each other,\n> thus ensuring good transaction propagation. The most recent patch to \n> implement\n> this is: https://github.com/bitcoin/bitcoin/pull/25600\n> \n> There's enough peers running full-rbf that the last time I started up a \n> new\n> node on a fresh IP address, it happened to have a peer relaying \n> full-rbf\n> replacements to it. And of course, if people want full-rbf to work more\n> reliably, it's very easy to just run some nodes with a large number of \n> outgoing\n> peers. Changing the hard-coded 8 outgoing peers to, say, 800, isn't \n> very hard.\n> \n> 2) There's nothing special about a \"full-rbf transaction\" other than \n> the fact\n> that it's replacing a previously broadcast transaction that didn't \n> signal\n> replacement. There is not consensus over the mempool, so in certain \n> cases\n> non-full-rbf nodes will in fact broadcast replacements when they didn't \n> happen\n> to receive the \"first\" transaction first.\n> \n> The latter makes testing full-rbf a bit problematic, as if you don't \n> take\n> special measures to ensure good propagation a small % of the time the\n> \"replacement\" transaction will in fact be the one that gets gets mined.\n> \n> Does fullrbf offer any benefits other than breaking zeroconf\n> business practices?  If so, what are they?\n> I think AJ mentioned this earlier, but adding more configuration \n> options\n> always increases code complexity, and with that, there is likely more\n> unforeseen bugs.  However, there is a section of network participants \n> that\n> rely on both types of transaction policy, so from my limited \n> view-point, it\n> seems worth accommodating if possible.\n\nSince all the machinery to do replacemnt already exists, adding a \nfull-rbf\nconfig flag is particularly trivial. It requires just a single line in \nthe\nmempool code.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221104/e8a258ae/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2022-11-05T02:35:03",
                "message_text_only": "On Mon, Oct 31, 2022 at 09:02:02AM -0400, Suhas Daftuar via bitcoin-dev wrote:\n\nSending this email for the sake of repeating a point I made on GitHub for the\nmailing list audience:\n\n> AJ,\n> \n> Thanks for the thoughtful post. I think your observations about how we view\n> mempool policy in the Bitcoin Core project, and how that seems to be\n> changing in the discussions around `-mempoolfullrbf`, are on-point and\n> provide a helpful baseline for considering future policy changes.\n\n<snip>\n\n> To those who argue for making fullrbf a default policy on the network (or\n> even just offering a flag for users to enable fullrbf), I pose this\n> hypothetical: suppose we deploy the v3 transaction policy proposal (which I\n> hope will happen in the near future).  That policy would restrict the ways\n> that outputs of a v3 transaction can be spent while the transaction is\n> unconfirmed, including by limiting the number and size of descendants that\n> such a transaction can have, and limiting the types of unconfirmed\n> ancestors that can be included.  Suppose in a few years someone proposes\n> that we add a \"-disable_v3_transaction_enforcement\" flag to our software,\n> to let users decide to turn off those policy restrictions and treat v3\n> transactions the same as v2, for all the same reasons that could be argued\n> today with fullrbf: miners might earn more revenue if we allowed multiple\n> descendant v3 transactions; it's illogical for the recipient of a v3\n> transaction to believe what is a fundamentally unenforceable promise of a\n> sender to not issue more high value children that descend from an\n> unconfirmed transaction; it's inappropriate for Bitcoin Core to dictate\n> policy on the network and we should honor user choice to turn off that flag\n> if that\u2019s what users want; if users are relying on v3\u2019s policy restrictions\n> for security then that is an unstable model and we should assume it will\n> get broken[5].\n\nLet's frame this question differently: given that there are potential\nincentives around a hypothetical `-disable_v3_transaction_enforcement` flag,\nwhy are we trying to prevent miners and others from experimenting with\nincentives around `fullrbf`?\n\nYanking the `mempoolfullrbf` flag from Bitcoin Core v24.0 simply puts a\ntemporary roadblock in the face of full-rbf. Without that roadblock, we might\nfind that some miners do in fact choose to enable it. The sooner we find that\nout, the sooner we can learn about the incentives involved in that decision.\n\nMeanwhile, if we insted put up those roadblocks, we'll be designing mechanisms\nlike v3 blind, without the benefit of seeing how incentives play out fully.\n\n\nThis experimentation can't happen on testnet: incentives don't work properly\nwhen there isn't money at stake. And the proposed reversion pull-reqs don't\neven leave the option for testnet anyway. So we're left with one choice:\nrelease a full-rbf option, and see what happens on mainnet.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221104/7e2f2a87/attachment.sig>"
            },
            {
                "author": "AdamISZ",
                "date": "2022-11-08T09:28:44",
                "message_text_only": "Hi aj and list,\n(questions inline)\n\n\n------- Original Message -------\nOn Thursday, October 27th, 2022 at 18:21, Anthony Towns via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> \n> Is that true? Antoine claims [1] that opt-in RBF isn't enough to avoid\n> a DoS issue when utxos are jointly funded by untrusting partners, and,\n> aiui, that's the main motivation for addressing this now.\n> \n> [1] https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-May/003033.html\n> \n> The scenario he describes is: A, B, C create a tx:\n> \n> inputs: A1, B1, C1 [opts in to RBF]\n> fees: normal\n> outputs:\n> [lightning channel, DLC, etc, who knows]\n> \n> they all analyse the tx, and agree it looks great; however just before\n> publishing it, A spams the network with an alternative tx, double\n> spending her input:\n> \n> inputs: A1 [does not opt in to RBF]\n> fees: low\n> outputs: A\n> \n> If A gets the timing right, that's bad for B and C because they've\n> populated their mempool with the 1st transaction, while everyone else\n> sees the 2nd one instead; and neither tx will replace the other. B and\n> C can't know that they should just cancel their transaction, eg:\n> \n> inputs: B1, C1 [opts in to RBF]\n> fees: 50% above normal\n> outputs:\n> [smaller channel, refund, whatever]\n> \n> and might instead waste time trying to fee bump the tx to get it mined,\n> or similar.\n> \n> What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to\n> solve that problem if they have only opt-in RBF available?\n> \n<snip>\n> \n\nI read Antoine's original post on this and got the general gist, and here also, it makes sense, but I'd like to ask: is it necessary that (B, C) in the above not *see* A's opt-out \"pre-replacement\" (inputs: A1, outputs: A, fees: low; call it TX_2)? I get that they cannot replace it, but the idea that they suffer financial loss from \"ignorant\" fee bumping is the part that seems weird to me. Clearly TX_2 gets gossiped to other mempools; and understood that it does not replace the TX_1 (the 3-input) in B's mempool, say, but why should they not even hear about it? Is it just a matter of engineering, or is there some deeper problem with that.\n\nAbout this general flavour of attack, it's never been a *big* concern in Joinmarket imo (though, we did until recently have a bug that made this happen *by accident*, i.e. people double spending an input out of a negotiated join, albeit it was rare; but it's ofc definitely *possible* to 'grief' like this, given the ordering of events; maker sends signature, maker broadcasts double spend - 95% of the time they will be first). Interactive protocols are yucky and I think there'll always be griefing possibilities; designing around multiple-rounds of negotiation amongst not always-on participants is even more yucky, so just having a 'taker is in charge of network fee; if it's slow or gets double spent out causing time delay then just wait', combined with 'there really isn't any economic incentive for an attacker' (i.e. ignoring griefing) might sound crappy but it's probably just being realistic.\n\nOf course, off-chain contracting has more sophisticated considerations than this.\n\nCheers,\nAdamISZ/waxwing"
            },
            {
                "author": "email at yancy.lol",
                "date": "2022-11-10T14:38:27",
                "message_text_only": "> I read Antoine's original post on this and got the general gist, and \n> here also, it makes sense, but I'd like to ask: is it necessary that \n> (B, C) in the above not *see* A's opt-out \"pre-replacement\" (inputs: \n> A1, outputs: A, fees: low; call it TX_2)? I get that they cannot \n> replace it\n\nIs it actually true that they cannot replace it?  If miners and node \noperators collude and have the incentive to run a patched version of \ncore, is it still technically impossible to replace?\n\n> the idea that they suffer financial loss from\n> \"ignorant\" fee bumping is the part that seems weird to me.\n\nEven if they waste resources trying to fee-bump, I agree that this does \nnot appear to be a catastrophe.There doesn't seem to be any technical \nreason why improvements can't be made to allow B and C to have a better \nview.\n\nCheers,\n-Yancy\n\nOn 2022-11-08 10:28, AdamISZ via bitcoin-dev wrote:\n\n> Hi aj and list,\n> (questions inline)\n> \n> ------- Original Message -------\n> On Thursday, October 27th, 2022 at 18:21, Anthony Towns via\n> bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n>> Is that true? Antoine claims [1 [1]] that opt-in RBF isn't enough to \n>> avoid\n>> a DoS issue when utxos are jointly funded by untrusting partners, and,\n>> aiui, that's the main motivation for addressing this now.\n>> \n>> [1] \n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-May/003033.html\n>> \n>> The scenario he describes is: A, B, C create a tx:\n>> \n>> inputs: A1, B1, C1 [opts in to RBF]\n>> fees: normal\n>> outputs:\n>> [lightning channel, DLC, etc, who knows]\n>> \n>> they all analyse the tx, and agree it looks great; however just before\n>> publishing it, A spams the network with an alternative tx, double\n>> spending her input:\n>> \n>> inputs: A1 [does not opt in to RBF]\n>> fees: low\n>> outputs: A\n>> \n>> If A gets the timing right, that's bad for B and C because they've\n>> populated their mempool with the 1st transaction, while everyone else\n>> sees the 2nd one instead; and neither tx will replace the other. B and\n>> C can't know that they should just cancel their transaction, eg:\n>> \n>> inputs: B1, C1 [opts in to RBF]\n>> fees: 50% above normal\n>> outputs:\n>> [smaller channel, refund, whatever]\n>> \n>> and might instead waste time trying to fee bump the tx to get it \n>> mined,\n>> or similar.\n>> \n>> What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to\n>> solve that problem if they have only opt-in RBF available?\n> <snip>\n> I read Antoine's original post on this and got the general gist, and\n> here also, it makes sense, but I'd like to ask: is it necessary that\n> (B, C) in the above not *see* A's opt-out \"pre-replacement\" (inputs:\n> A1, outputs: A, fees: low; call it TX_2)? I get that they cannot\n> replace it, but the idea that they suffer financial loss from\n> \"ignorant\" fee bumping is the part that seems weird to me. Clearly\n> TX_2 gets gossiped to other mempools; and understood that it does not\n> replace the TX_1 (the 3-input) in B's mempool, say, but why should\n> they not even hear about it? Is it just a matter of engineering, or is\n> there some deeper problem with that.\n> \n> About this general flavour of attack, it's never been a *big* concern\n> in Joinmarket imo (though, we did until recently have a bug that made\n> this happen *by accident*, i.e. people double spending an input out of\n> a negotiated join, albeit it was rare; but it's ofc definitely\n> *possible* to 'grief' like this, given the ordering of events; maker\n> sends signature, maker broadcasts double spend - 95% of the time they\n> will be first). Interactive protocols are yucky and I think there'll\n> always be griefing possibilities; designing around multiple-rounds of\n> negotiation amongst not always-on participants is even more yucky, so\n> just having a 'taker is in charge of network fee; if it's slow or gets\n> double spent out causing time delay then just wait', combined with\n> 'there really isn't any economic incentive for an attacker' (i.e.\n> ignoring griefing) might sound crappy but it's probably just being\n> realistic.\n> \n> Of course, off-chain contracting has more sophisticated considerations\n> than this.\n> \n> Cheers,\n> AdamISZ/waxwing\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n\nLinks:\n------\n[1] \nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2021-May/003033.html\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221110/ae20762b/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "On mempool policy consistency",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Antoine Riard",
                "Anthony Towns",
                "Peter Todd",
                "email at yancy.lol",
                "Erik Aronesty",
                "AdamISZ",
                "Greg Sanders"
            ],
            "messages_count": 12,
            "total_messages_chars_count": 67207
        }
    },
    {
        "title": "[bitcoin-dev] Preventing/detecting pinning of jointly funded txs",
        "thread_messages": [
            {
                "author": "Anthony Towns",
                "date": "2022-11-02T03:52:09",
                "message_text_only": "On Fri, Oct 28, 2022 at 03:21:53AM +1000, Anthony Towns via bitcoin-dev wrote:\n> What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to\n> solve that problem if they have only opt-in RBF available?\n\nref: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-October/021124.html\n\nSo, having a go at answering my own question.\n\nI think ultimately the scenario here is:\n\n * you have a joint funding protocol, where everyone says \"here's\n   an unspent utxo that will be my contribution\", collaborates on signing\n   a transaction spending all those utxos, and then broadcasts it\n\n * everyone jointly agrees to pay some amount in fees for that\n   transaction, targeting confirmation within N blocks\n\n * the goal is to have the transaction confirm, obviously; but it's also\n   acceptable to discover a conflicting transaction, as that will\n   demonstrate that a particular participant has been dishonest (their\n   utxo was not \"unspent\"), allowing the overall protocol to make progress\n\nThe question then is how much effort do you have to go to to make such a\nprotocol work?\n\nAs an extreme example, you could always have each participant maintain\na dedicated amount of hashpower: eg, if each participant individually\ncontrols 0.5% of hashpower, then having two honest participants would\ngive you a 75% chance of confirmation within 137 blocks (roughly a day),\neven if your transaction failed to relay at all, and the only way to\nprevent confirmation is for a conflicting transaction to be confirmed\nearlier. Of course, needing to have 0.5% of hashpower would mean fewer\nthan 200 people globally could participate in such a protocol, and\nrequires something like $10M in capital investment just for ASICs in\norder to participate.\n\nI think the next step from that pretty much requires introducing the\nassumption that the vast majority of the bitcoin p2p network (both nodes\nand hashrate) will accept your transaction, at least in a world where all\nyour collaborators are honest and don't create conflicting transactions.\nYou can limit that assumption a little bit, but without most p2p peers\nbeing willing to relay your tx, you start having privacy issues; and\nwithout most miners being willing to mine your tx, you start getting\nproblems with predicting fees. And in any event, I don't think anyone's\ntrying to make weird transactions here, just get their otherwise normal\ntransactions to actually confirm.\n\nI think the same approach used to detect double spend races by people\naccepting zeroconf would work here too. That is setup a couple of\nanonymous bitcoin nodes, let them sit for a couple of weeks so their\nmempools are realistic, then when you broadcast a jointly funded\ntransaction, query their mempools: if your new tx made it there, it\nlikely made it to mining pools too, and you're fine; if it didn't, then\nthe transaction that's blocking it almost certainly did, so you can find\nout what that is and can go from there.\n\n(If you don't see either your tx, or a conflicting one, then it likely\nmeans the nodes that broadcasted your tx are being sybil attacked, either\nbecause their peers are directly controlled by an attacker, or they've\nbeen identified by an attacker and attacked in some other way; presumably\nyou could pick a couple of node that have been confirmed by both your\nanonymous nodes' as valid and reachable, and connect to them to break\nout of the sybil attack; if that doesn't work either, you probably need\nto change ISPs or put your active node via a (different) VPN provider...)\n\nYour capital expenses are much lower that way: perhaps on the order of\n$20/month to run a couple of nodes on AWS or linode or similar.\n\nBut, you might say, what if I don't even want to run multiple bitcoin\nnodes 24/7 indefinitely? Can we outsource that, like we outsource mining\nby paying tx fees?\n\nThat seems harder, particularly if you want to avoid whoever you're\noutsourcing too from associating you with the jointly funded transaction\nyou're interested in.\n\nIf you're *not* worried about that association, it's probably easy:\njust find some public explorers, and see if they list any conflicts in\ntheir mempool, or use the \"broadcast tx\" feature and see if it gives an\nerror identifying the conflicting transaction.\n\nI think it's probably hard to make that behaviour a normal part of p2p tx\nrelay though: if someone's trying to relay tx T but you reject it\nbecause of a conflicting tx C; then it's easy to tell the node that\nfirst relayed T to you about C -- but how does that information get back\nto the original broadcaster?\n\nOne way would be to broadcast \"C\" back to whoever announced T to you,\nand let C propogate all the way back to whoever originally proposed T --\nbut that only works if everyone's running a mempool policy where there's\na total ordering for tx replacement, ie for any conflicting txs, either\nT replaces C or C replaces T, and that's not something we have now or\nwould have even with full RBF, and seems pretty hard to actually achieve.\n(And if it was achieved, you could just keep replacing T with a more\nattractive T' so that it did eventually replace C)\n\nAnother way might be to have the original broadcaster retry the broadcast:\nconnect to new peers, reannounce T, and see what happens.  Then eventually\nthey'll connect to a peer that has C in their mempool, and just needs a\n\"reject\" message of some kind that can identify C.  But in that case,\nthe peer that's going to send the reject message needs to be able to\nefficiently associate T back to C, even though it doesn't have T in\nthe mempool -- it won't want to redownload T each time, because that's\na waste of bandwidth, and it can't re-validate T to find the conflict\nfresh without having a copy of T.\n\nUsing BIP 37 mempool filters or something might be an approach if there\nare plenty of nodes around that _are_ willing to dedicate extra resources\nto helping people find potentially conflicting txs.  Unfortunately that\nprobably is pretty bad for privacy: if your adversary is blocking your\ncoinjoin T with a pinned tx C, then the fact that you've asked for a\nfilter that happens to match C is probably a good indication that you're\ninvolved in the coinjoin T; and there's a decent chance that the only\npeople will to dedicate the extra resources to offer those services to\nthe public will be people who want to invade your privacy...\n\nA problem with mempool filters (or telling other nodes what's in your\nmempool in general) is that that can provide a way for attackers to\nidentify who your peers are: if you create a bunch of conflicting txs,\nand give a different one to many nodes other than you, then see which\ntx you end up with, that identifies which peers are close to you, and\nthat information could be used to attack those peers, which in turn may\nallow more effective sybil attacks against you.\n\nSo I think my best answer is:\n\n - if you really want to do things with untrusted peers in bitcoin,\n   investing in hashpower maybe isn't that unreasonable a thing to\n   do. $10M in capital giving you the ability to usually make progress\n   within a day even if everyone else dislikes you? surprisingly\n   reasonable, especially if more progress is made on stratumv2...\n\n - if you don't care about privacy (eg, you're funding a lightning\n   channel that's going to be gossiped anyway), just query an explorer\n   (or some other centralised service) to find out the conflicting tx\n   and go from there.\n\n - if you do care about privacy, run a few \"anonymous\" bitcoind nodes\n   that don't announce transactions, and see what their mempool\n   contains.\n\n - we can probably make it easier to run anonymous bitcoind nodes\n   by making transaction broadcasts more private (tor/i2p? dandelion? have\n   lightning nodes send channel open/close txs to another lightning\n   node to announce to bitcoin p2p?) -- for cases where you're already\n   running a bitcoin node 24/7 (or trusting someone else that does), I\n   think that gives you a pretty good method of either being confident\n   your tx made it to a decent percentage of hashrate, or spotting a\n   conflicting tx to be able to assign blame\n\nAnyone got any improvements on the above?\n\nCheers,\naj"
            },
            {
                "author": "Greg Sanders",
                "date": "2022-11-02T13:46:24",
                "message_text_only": "Assigning blame here seems to be the paramount concern here. If we can\nassign blame, most coinjoin-like protocols can terminate in bounded block\ntime, assuming fees are properly set.\n\nIt's also worth noting that in coinjoin cases, they're obviously coinjoins,\nso pinging explorers over Tor HS seems purely additive to me. The use-cases\nthat can't use it are other privacy methods like coinswap and similar,\nwhere there's no blockchain indication anything different is happening. The\nlarger the coinjoin, the more potential honest users, the more potential\nfor a duplicitous double-spend to be gossiped among those peers.\n\nFor dual funding LN channels, that number is pretty small(2), so I suspect\nthe DoS concerns are fairly subtle. Might be worth talking to\nCLN/Eclair/Other LN teams that are working through those subtleties as we\nspeak.\n\nGreg\n\nOn Tue, Nov 1, 2022 at 11:52 PM Anthony Towns via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Fri, Oct 28, 2022 at 03:21:53AM +1000, Anthony Towns via bitcoin-dev\n> wrote:\n> > What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to\n> > solve that problem if they have only opt-in RBF available?\n>\n> ref:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-October/021124.html\n>\n> So, having a go at answering my own question.\n>\n> I think ultimately the scenario here is:\n>\n>  * you have a joint funding protocol, where everyone says \"here's\n>    an unspent utxo that will be my contribution\", collaborates on signing\n>    a transaction spending all those utxos, and then broadcasts it\n>\n>  * everyone jointly agrees to pay some amount in fees for that\n>    transaction, targeting confirmation within N blocks\n>\n>  * the goal is to have the transaction confirm, obviously; but it's also\n>    acceptable to discover a conflicting transaction, as that will\n>    demonstrate that a particular participant has been dishonest (their\n>    utxo was not \"unspent\"), allowing the overall protocol to make progress\n>\n> The question then is how much effort do you have to go to to make such a\n> protocol work?\n>\n> As an extreme example, you could always have each participant maintain\n> a dedicated amount of hashpower: eg, if each participant individually\n> controls 0.5% of hashpower, then having two honest participants would\n> give you a 75% chance of confirmation within 137 blocks (roughly a day),\n> even if your transaction failed to relay at all, and the only way to\n> prevent confirmation is for a conflicting transaction to be confirmed\n> earlier. Of course, needing to have 0.5% of hashpower would mean fewer\n> than 200 people globally could participate in such a protocol, and\n> requires something like $10M in capital investment just for ASICs in\n> order to participate.\n>\n> I think the next step from that pretty much requires introducing the\n> assumption that the vast majority of the bitcoin p2p network (both nodes\n> and hashrate) will accept your transaction, at least in a world where all\n> your collaborators are honest and don't create conflicting transactions.\n> You can limit that assumption a little bit, but without most p2p peers\n> being willing to relay your tx, you start having privacy issues; and\n> without most miners being willing to mine your tx, you start getting\n> problems with predicting fees. And in any event, I don't think anyone's\n> trying to make weird transactions here, just get their otherwise normal\n> transactions to actually confirm.\n>\n> I think the same approach used to detect double spend races by people\n> accepting zeroconf would work here too. That is setup a couple of\n> anonymous bitcoin nodes, let them sit for a couple of weeks so their\n> mempools are realistic, then when you broadcast a jointly funded\n> transaction, query their mempools: if your new tx made it there, it\n> likely made it to mining pools too, and you're fine; if it didn't, then\n> the transaction that's blocking it almost certainly did, so you can find\n> out what that is and can go from there.\n>\n> (If you don't see either your tx, or a conflicting one, then it likely\n> means the nodes that broadcasted your tx are being sybil attacked, either\n> because their peers are directly controlled by an attacker, or they've\n> been identified by an attacker and attacked in some other way; presumably\n> you could pick a couple of node that have been confirmed by both your\n> anonymous nodes' as valid and reachable, and connect to them to break\n> out of the sybil attack; if that doesn't work either, you probably need\n> to change ISPs or put your active node via a (different) VPN provider...)\n>\n> Your capital expenses are much lower that way: perhaps on the order of\n> $20/month to run a couple of nodes on AWS or linode or similar.\n>\n> But, you might say, what if I don't even want to run multiple bitcoin\n> nodes 24/7 indefinitely? Can we outsource that, like we outsource mining\n> by paying tx fees?\n>\n> That seems harder, particularly if you want to avoid whoever you're\n> outsourcing too from associating you with the jointly funded transaction\n> you're interested in.\n>\n> If you're *not* worried about that association, it's probably easy:\n> just find some public explorers, and see if they list any conflicts in\n> their mempool, or use the \"broadcast tx\" feature and see if it gives an\n> error identifying the conflicting transaction.\n>\n> I think it's probably hard to make that behaviour a normal part of p2p tx\n> relay though: if someone's trying to relay tx T but you reject it\n> because of a conflicting tx C; then it's easy to tell the node that\n> first relayed T to you about C -- but how does that information get back\n> to the original broadcaster?\n>\n> One way would be to broadcast \"C\" back to whoever announced T to you,\n> and let C propogate all the way back to whoever originally proposed T --\n> but that only works if everyone's running a mempool policy where there's\n> a total ordering for tx replacement, ie for any conflicting txs, either\n> T replaces C or C replaces T, and that's not something we have now or\n> would have even with full RBF, and seems pretty hard to actually achieve.\n> (And if it was achieved, you could just keep replacing T with a more\n> attractive T' so that it did eventually replace C)\n>\n> Another way might be to have the original broadcaster retry the broadcast:\n> connect to new peers, reannounce T, and see what happens.  Then eventually\n> they'll connect to a peer that has C in their mempool, and just needs a\n> \"reject\" message of some kind that can identify C.  But in that case,\n> the peer that's going to send the reject message needs to be able to\n> efficiently associate T back to C, even though it doesn't have T in\n> the mempool -- it won't want to redownload T each time, because that's\n> a waste of bandwidth, and it can't re-validate T to find the conflict\n> fresh without having a copy of T.\n>\n> Using BIP 37 mempool filters or something might be an approach if there\n> are plenty of nodes around that _are_ willing to dedicate extra resources\n> to helping people find potentially conflicting txs.  Unfortunately that\n> probably is pretty bad for privacy: if your adversary is blocking your\n> coinjoin T with a pinned tx C, then the fact that you've asked for a\n> filter that happens to match C is probably a good indication that you're\n> involved in the coinjoin T; and there's a decent chance that the only\n> people will to dedicate the extra resources to offer those services to\n> the public will be people who want to invade your privacy...\n>\n> A problem with mempool filters (or telling other nodes what's in your\n> mempool in general) is that that can provide a way for attackers to\n> identify who your peers are: if you create a bunch of conflicting txs,\n> and give a different one to many nodes other than you, then see which\n> tx you end up with, that identifies which peers are close to you, and\n> that information could be used to attack those peers, which in turn may\n> allow more effective sybil attacks against you.\n>\n> So I think my best answer is:\n>\n>  - if you really want to do things with untrusted peers in bitcoin,\n>    investing in hashpower maybe isn't that unreasonable a thing to\n>    do. $10M in capital giving you the ability to usually make progress\n>    within a day even if everyone else dislikes you? surprisingly\n>    reasonable, especially if more progress is made on stratumv2...\n>\n>  - if you don't care about privacy (eg, you're funding a lightning\n>    channel that's going to be gossiped anyway), just query an explorer\n>    (or some other centralised service) to find out the conflicting tx\n>    and go from there.\n>\n>  - if you do care about privacy, run a few \"anonymous\" bitcoind nodes\n>    that don't announce transactions, and see what their mempool\n>    contains.\n>\n>  - we can probably make it easier to run anonymous bitcoind nodes\n>    by making transaction broadcasts more private (tor/i2p? dandelion? have\n>    lightning nodes send channel open/close txs to another lightning\n>    node to announce to bitcoin p2p?) -- for cases where you're already\n>    running a bitcoin node 24/7 (or trusting someone else that does), I\n>    think that gives you a pretty good method of either being confident\n>    your tx made it to a decent percentage of hashrate, or spotting a\n>    conflicting tx to be able to assign blame\n>\n> Anyone got any improvements on the above?\n>\n> Cheers,\n> aj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/6a80b055/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-11-06T23:22:08",
                "message_text_only": "Hi AJ,\n\nAdding a few more thoughts here on what coinjoins/splicing/dual-funded\nfolks can do to solve this DoS isse in an opt-in RBF world only.\n\nI'm converging that deploying a distributed monitoring of the network\nmempools in the same fashion as zeroconf people is one solution, as you can\ndetect a conflicting spend of your multi-party transaction. Let's say you\nhave a web of well-connected full-nodes, each reporting all their incoming\nmempool transactions to some reconciliation layer.\n\nThis \"mempools watchdog\" infrastructure isn't exempt from mempools\npartitioning attacks by an adversary, where the goal is to control your\nlocal node mempool view. A partitioning trick is somehow as simple as\npolicy changes across versions (e.g allowing Taproot Segwit v0.1 spends) or\ntwo same-feerate transactions. The partitioning attack can target at least\ntwo meaningful subsets. Either the miner mempools only, by conflicting all\nthe reachable nodes in as many subsets with a \"tainted\" transaction (e.g\nset a special nSequence value for each), and looking on corresponding\nissued block. Or targeting the \"watchdog\" mempools only, where the\nadversary observation mechanism is the multi-party blame assignment round\nitself. There is an open question on how many \"divide-and-conquer\" rounds\nfrom an adversary viewpoint you need to efficiently identify all the\ncomplete set of \"mempools watchdog\". If the transaction-relay topology is\nhighly dynamic thanks to outbound transaction-relay peers rotation, the\nhardness bar is increased.\n\nThough ultimately, the rough mental model I'm thinking on, this is a\n\"cat-and-mouse\" game between the victims and the attacker, where the latter\ntry to find the blind spots of the former. I would say there is a strong\nadvantage to the attacker, in mapping the mempools can be batched against\nmultiple sets of victims. While the victims have no entry barriers to\ndeploy \"mempools watchdog\" there is a scarce resource in contest, namely\nthe inbound connection slots (at least the miners ones).\n\nVictims could batch their defense costs, in outsourcing the monitoring to\ndedicated entities (akin to LN watchtower). However, there is a belief in\nlack of a compensation mechanism, you will have only a low number of public\nones (see number of BIP157 signaling nodes, or even Electrum ones).\nOutsource mempools monitoring will hit the same issue of bounded public\nresources, and as such be a \"single-point-of-censorship\" vector. Reminder,\nwe would like LN mobile clients from low-budget users to access those fancy\njoint funding protocols (or at least I).\n\nSo as a first partial conclusion, not only the security efficiency but also\nthe economic scalability of such defensive \"mempools watchdog\"\ninfrastructure remains an open question to me.\n\nAssuming we can solve them, there is still the issue of assigning blame\nreliably among a set of trust-minimized joint funding protocol\nparticipating UTXOs. Indeed, you're running quickly into issues like *two*\ndouble-spend from two sybilling participants, aiming to halt the assignment\nprocess. There is likely a need to introduce some \"UTXO-satoshi-weight\"\nvote to efficiently converge towards assignment. At the very least it would\nrequire the attacker to control more than 51% of the contributed UTXO to\nmanipulate the outcome of the blame assignment process. Assuming an\neconomically honest majority, you still have the timevalue cost inflicted\nfor each round of blame assignment. Assuming 255 inputs (current LN's\ninteractive construction protocol limit) and a transaction propagation\ndelay of 2min (30s ?) on the p2p network, an attacker controlling all the\ninputs minus 1 might be able to DoS for ~50 blocks (do we have other\nfactors to think of in the design of the blame assignment process ?). In a\nfuture where the timevalue of circulating coins is priced in (IMO when we\nhave competitive LN routing markets), this is probably a significant damage.\n\nOn the other hand, you have a full-rbf world, where instead to deploy or\ngain access to \"mempools watchdog\" and proceed to a timevalue-expensive\nblame assignment protocol, any participant should be able to fee-bump the\njoint transaction (assuming multiple pre-signed feerate version of the\ntransactions, or ephemeral, nversion=3 and package-relay to do unilateral\nCPFP). Ideally, this would be a reduction to a \"flood-and-loot\" attack, i.e\nthe attacker is constrained to buy the blockspace. A situation with a lot\nof visibility for the joint funding protocol victims, I think.\n\nSide-note: this alternative resolution process of relying on full-rbf,\nstill assumes solving RBF pinning rule 3, I think a fact I underscored in\nmy original full-rbf proposal of last year [0]. All that said, I think it's\ngood to think more of the end-of-pipeline economic trade-offs of the two\nmain directions to solve this DoS affecting joint funding protocol.\nTransaction signature withhold DoS should be defended on a different layer,\nand I think there are far more easy to deal with in  a set of participant\nwith at least stable temporary pseudonyms (\"all participants should produce\na signature before X, laziness due to buggy Internet connection is treated\nthe same as a DoS\" ?).\n\nBest,\nAntoine\n\n[0] \"Of course, even assuming full-rbf, propagation of the multi-party\nfunded\ntransactions can still be interfered with by an attacker, simply\nbroadcasting a double-spend with a feerate equivalent to the honest\ntransaction. However, it tightens the attack scenario to a scorched earth\napproach, where the attacker has to commit equivalent fee-bumping reserve\nto maintain the pinning and might lose the \"competing\" fees to miners.\"\n\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-June/019074.html\n\nLe mar. 1 nov. 2022 \u00e0 23:52, Anthony Towns via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n> On Fri, Oct 28, 2022 at 03:21:53AM +1000, Anthony Towns via bitcoin-dev\n> wrote:\n> > What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to\n> > solve that problem if they have only opt-in RBF available?\n>\n> ref:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-October/021124.html\n>\n> So, having a go at answering my own question.\n>\n> I think ultimately the scenario here is:\n>\n>  * you have a joint funding protocol, where everyone says \"here's\n>    an unspent utxo that will be my contribution\", collaborates on signing\n>    a transaction spending all those utxos, and then broadcasts it\n>\n>  * everyone jointly agrees to pay some amount in fees for that\n>    transaction, targeting confirmation within N blocks\n>\n>  * the goal is to have the transaction confirm, obviously; but it's also\n>    acceptable to discover a conflicting transaction, as that will\n>    demonstrate that a particular participant has been dishonest (their\n>    utxo was not \"unspent\"), allowing the overall protocol to make progress\n>\n> The question then is how much effort do you have to go to to make such a\n> protocol work?\n>\n> As an extreme example, you could always have each participant maintain\n> a dedicated amount of hashpower: eg, if each participant individually\n> controls 0.5% of hashpower, then having two honest participants would\n> give you a 75% chance of confirmation within 137 blocks (roughly a day),\n> even if your transaction failed to relay at all, and the only way to\n> prevent confirmation is for a conflicting transaction to be confirmed\n> earlier. Of course, needing to have 0.5% of hashpower would mean fewer\n> than 200 people globally could participate in such a protocol, and\n> requires something like $10M in capital investment just for ASICs in\n> order to participate.\n>\n> I think the next step from that pretty much requires introducing the\n> assumption that the vast majority of the bitcoin p2p network (both nodes\n> and hashrate) will accept your transaction, at least in a world where all\n> your collaborators are honest and don't create conflicting transactions.\n> You can limit that assumption a little bit, but without most p2p peers\n> being willing to relay your tx, you start having privacy issues; and\n> without most miners being willing to mine your tx, you start getting\n> problems with predicting fees. And in any event, I don't think anyone's\n> trying to make weird transactions here, just get their otherwise normal\n> transactions to actually confirm.\n>\n> I think the same approach used to detect double spend races by people\n> accepting zeroconf would work here too. That is setup a couple of\n> anonymous bitcoin nodes, let them sit for a couple of weeks so their\n> mempools are realistic, then when you broadcast a jointly funded\n> transaction, query their mempools: if your new tx made it there, it\n> likely made it to mining pools too, and you're fine; if it didn't, then\n> the transaction that's blocking it almost certainly did, so you can find\n> out what that is and can go from there.\n>\n> (If you don't see either your tx, or a conflicting one, then it likely\n> means the nodes that broadcasted your tx are being sybil attacked, either\n> because their peers are directly controlled by an attacker, or they've\n> been identified by an attacker and attacked in some other way; presumably\n> you could pick a couple of node that have been confirmed by both your\n> anonymous nodes' as valid and reachable, and connect to them to break\n> out of the sybil attack; if that doesn't work either, you probably need\n> to change ISPs or put your active node via a (different) VPN provider...)\n>\n> Your capital expenses are much lower that way: perhaps on the order of\n> $20/month to run a couple of nodes on AWS or linode or similar.\n>\n> But, you might say, what if I don't even want to run multiple bitcoin\n> nodes 24/7 indefinitely? Can we outsource that, like we outsource mining\n> by paying tx fees?\n>\n> That seems harder, particularly if you want to avoid whoever you're\n> outsourcing too from associating you with the jointly funded transaction\n> you're interested in.\n>\n> If you're *not* worried about that association, it's probably easy:\n> just find some public explorers, and see if they list any conflicts in\n> their mempool, or use the \"broadcast tx\" feature and see if it gives an\n> error identifying the conflicting transaction.\n>\n> I think it's probably hard to make that behaviour a normal part of p2p tx\n> relay though: if someone's trying to relay tx T but you reject it\n> because of a conflicting tx C; then it's easy to tell the node that\n> first relayed T to you about C -- but how does that information get back\n> to the original broadcaster?\n>\n> One way would be to broadcast \"C\" back to whoever announced T to you,\n> and let C propogate all the way back to whoever originally proposed T --\n> but that only works if everyone's running a mempool policy where there's\n> a total ordering for tx replacement, ie for any conflicting txs, either\n> T replaces C or C replaces T, and that's not something we have now or\n> would have even with full RBF, and seems pretty hard to actually achieve.\n> (And if it was achieved, you could just keep replacing T with a more\n> attractive T' so that it did eventually replace C)\n>\n> Another way might be to have the original broadcaster retry the broadcast:\n> connect to new peers, reannounce T, and see what happens.  Then eventually\n> they'll connect to a peer that has C in their mempool, and just needs a\n> \"reject\" message of some kind that can identify C.  But in that case,\n> the peer that's going to send the reject message needs to be able to\n> efficiently associate T back to C, even though it doesn't have T in\n> the mempool -- it won't want to redownload T each time, because that's\n> a waste of bandwidth, and it can't re-validate T to find the conflict\n> fresh without having a copy of T.\n>\n> Using BIP 37 mempool filters or something might be an approach if there\n> are plenty of nodes around that _are_ willing to dedicate extra resources\n> to helping people find potentially conflicting txs.  Unfortunately that\n> probably is pretty bad for privacy: if your adversary is blocking your\n> coinjoin T with a pinned tx C, then the fact that you've asked for a\n> filter that happens to match C is probably a good indication that you're\n> involved in the coinjoin T; and there's a decent chance that the only\n> people will to dedicate the extra resources to offer those services to\n> the public will be people who want to invade your privacy...\n>\n> A problem with mempool filters (or telling other nodes what's in your\n> mempool in general) is that that can provide a way for attackers to\n> identify who your peers are: if you create a bunch of conflicting txs,\n> and give a different one to many nodes other than you, then see which\n> tx you end up with, that identifies which peers are close to you, and\n> that information could be used to attack those peers, which in turn may\n> allow more effective sybil attacks against you.\n>\n> So I think my best answer is:\n>\n>  - if you really want to do things with untrusted peers in bitcoin,\n>    investing in hashpower maybe isn't that unreasonable a thing to\n>    do. $10M in capital giving you the ability to usually make progress\n>    within a day even if everyone else dislikes you? surprisingly\n>    reasonable, especially if more progress is made on stratumv2...\n>\n>  - if you don't care about privacy (eg, you're funding a lightning\n>    channel that's going to be gossiped anyway), just query an explorer\n>    (or some other centralised service) to find out the conflicting tx\n>    and go from there.\n>\n>  - if you do care about privacy, run a few \"anonymous\" bitcoind nodes\n>    that don't announce transactions, and see what their mempool\n>    contains.\n>\n>  - we can probably make it easier to run anonymous bitcoind nodes\n>    by making transaction broadcasts more private (tor/i2p? dandelion? have\n>    lightning nodes send channel open/close txs to another lightning\n>    node to announce to bitcoin p2p?) -- for cases where you're already\n>    running a bitcoin node 24/7 (or trusting someone else that does), I\n>    think that gives you a pretty good method of either being confident\n>    your tx made it to a decent percentage of hashrate, or spotting a\n>    conflicting tx to be able to assign blame\n>\n> Anyone got any improvements on the above?\n>\n> Cheers,\n> aj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221106/c795614b/attachment-0001.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2022-11-07T11:46:28",
                "message_text_only": "On Sun, Nov 06, 2022 at 06:22:08PM -0500, Antoine Riard via bitcoin-dev wrote:\n> Adding a few more thoughts here on what coinjoins/splicing/dual-funded\n> folks can do to solve this DoS issue in an opt-in RBF world only.\n> \n> I'm converging that deploying a distributed monitoring of the network\n> mempools in the same fashion as zeroconf people is one solution, as you can\n> detect a conflicting spend of your multi-party transaction.\n\n> Let's say you\n> have a web of well-connected full-nodes, each reporting all their incoming\n> mempool transactions to some reconciliation layer.\n> \n> This \"mempools watchdog\" infrastructure isn't exempt from mempools\n> partitioning attacks by an adversary,\n\nA mempool partitioning attack requires the adversary to identify your\nnodes. If they're just monitoring and not being used as the initial\nbroadcaster of your txs, that should be difficult. (And I think it would\nmake sense to do things that make it more difficult to successfully\npartition a node for tx relay, even if you can identify it)\n\n> where the goal is to control your\n> local node mempool view. A partitioning trick is somehow as simple as\n> policy changes across versions (e.g allowing Taproot Segwit v0.1 spends) or\n> two same-feerate transactions. The partitioning attack can target at least\n> two meaningful subsets.\n\nAn even easier way to partition the network is to create two conflicting\ntxs at the same fee/fee rate and to announce them to many peers\nsimultaneously. That way neither will replace the other, and you can\nbuild from there.\n\nIn order to attack you, the partition would need to be broad enough\nto capture all your monitoring nodes on one side (to avoid detection),\nand all the mining nodes on the other side (to prevent your target tx\nfrom being confirmed). If that seems likely, maybe it indicates that\nit's too easy to identify nodes that feed txs to mining pools...\n\n> Either the miner mempools only, by conflicting all\n> the reachable nodes in as many subsets with a \"tainted\" transaction (e.g\n> set a special nSequence value for each), and looking on corresponding\n> issued block. Or targeting the \"watchdog\" mempools only, where the\n> adversary observation mechanism is the multi-party blame assignment round\n> itself.\n\nI think there's a few cases like that: you can find out what txs mining\npools have seen by looking at their blocks, what explorers have seen by\nlooking at their website...\n\nBeing able to use that information to identify your node(s) -- rather\nthan just your standardness policy, which you hopefully share with many\nother nodes -- seems like something we should be working to fix...\n\n> There is an open question on how many \"divide-and-conquer\" rounds\n> from an adversary viewpoint you need to efficiently identify all the\n> complete set of \"mempools watchdog\". If the transaction-relay topology is\n> highly dynamic thanks to outbound transaction-relay peers rotation, the\n> hardness bar is increased.\n\nI'm not sure outbound rotation is sufficient? In today's world, if\nyou're a listening node, an attacker can just connect directly, announce\nthe conflicting tx to you, and other txs to everyone else.\n\nFor a non-listening node, outbound rotation might be more harmful than\nhelpful, as it increases the chances a node will peer with a given\nattacker at some point.\n\n> Though ultimately, the rough mental model I'm thinking on, this is a\n> \"cat-and-mouse\" game between the victims and the attacker, where the latter\n> try to find the blind spots of the former. I would say there is a strong\n> advantage to the attacker, in mapping the mempools can be batched against\n> multiple sets of victims. While the victims have no entry barriers to\n> deploy \"mempools watchdog\" there is a scarce resource in contest, namely\n> the inbound connection slots (at least the miners ones).\n\nAnytime you deploy a new listening node, you use up 10 inbound\nconnections, but provide capacity for 115 new ones. Worst case (if\nit's too hard to prevent identifying a listening node if you use it for\nmonitoring), you setup all your monitoring nodes as non-listening nodes,\nand also set enough listening nodes in different IP ranges to compenasate\nfor the number of outbound connections your monitoring nodes are making,\nand just ignore the mempools of those listening nodes.\n\n> Victims could batch their defense costs, in outsourcing the monitoring to\n> dedicated entities (akin to LN watchtower). However, there is a belief in\n> lack of a compensation mechanism, you will have only a low number of public\n> ones (see number of BIP157 signaling nodes, or even Electrum ones).\n\nSeems like a pretty simple service to pay for, if there's real demand:\ncosts are pretty trivial, and if it's a LN service, you can pay for\nit over lightning... Fairly easy to test if you're getting what you're\npaying for too, by simultaneously announcing two conflicting txs paying\nyourself, and checking you get an appropriate alert.\n\n> Assuming we can solve them, there is still the issue of assigning blame\n> reliably among a set of trust-minimized joint funding protocol\n> participating UTXOs. Indeed, you're running quickly into issues like *two*\n> double-spend from two sybilling participants, aiming to halt the assignment\n> process.\n\nI don't see how that's a problem: anyone who wants to continue as part of\nthe group never signs a conflicting tx; anyone who does sign a conflicting\ntx is saying \"I don't want to be part of this group anymore\", whether\nthat conflicting tx arrives via normal channels or p2p. If you want a way\nof saying \"I want to abort this coinjoin, but stay a part of the group\",\nyou need to get 51% of the rest of the group to sign off on that claim\n(outside of the blockchain/mempool), before getting control of your\nutxo back. If you can't get 51% of the group to sign off on that in a\nreasonable time, then you should just exit the group.\n\nI don't think it makes much sense for \"group A said Bob's a cheater,\nso therefore we won't let Bob into group C either\".\n\n> for each round of blame assignment. Assuming 255 inputs (current LN's\n> interactive construction protocol limit) and a transaction propagation\n> delay of 2min (30s ?) on the p2p network, an attacker controlling all the\n> inputs minus 1 might be able to DoS for ~50 blocks (do we have other\n> factors to think of in the design of the blame assignment process ?).\n\nHmm, in messing around with dandelion simulations, I've found 10s to 30s\nseems more reasonable for propagation to 95% of the network, though that's\nmodelled without delays due to latency/low bandwidth, block propagation,\nor competition with large/higher value txs.\n\nShouldn't be hard to estimate that actually: if you setup a node with\n-debug=net and -datacarrier=0, then check for blocks with txs with\nOP_RETURN outputs, figure out the w/txid and grep your logs for how\nfar apart. Because you set -datacarrier=0 you won't accept those txs\ninto your mempool, or announce them to your peers, but your peers will\nannounce them to you when they receive them, so the time difference\nbetween first and last announcement should give you a decent sampling\nof info that you could use to estimate the overall time it takes a tx\nto flood through the network.\n\n> On the other hand, you have a full-rbf world, where instead to deploy or\n> gain access to \"mempools watchdog\" and proceed to a timevalue-expensive\n> blame assignment protocol, any participant should be able to fee-bump the\n> joint transaction (assuming multiple pre-signed feerate version of the\n> transactions, or ephemeral, nversion=3 and package-relay to do unilateral\n> CPFP).\n\nA full-rbf world doesn't get you that: you can do low fee rate pinning\nvia other mechanisms than the opt-out flag. In a world where nodes don't\nmostly have a consistent mempool policy you introduce new pinning vectors\ntoo; eg, if one of your coinjoin outputs is bare multisig, then that\nwill pass core's standardness checks, but be rejected by fullrbf knots\nnodes that haven't specifically enabled that configuration option.\n\nEven if you assume the attacker doesn't know about those other methods,\nor we somehow come up with an eventually consistent mempool/relay policy,\nwhere pinning isn't possible that gets near universal adoption; if you're\nonly monitoring the blockchain and not the mempool, your hypothetical\nattacker can immediately RBF your tx with a higher fee spend of one of\ntheir inputs -- you'll find out about that in the next block, but at one\ninput per block, that's going to allow you to keep thinking that maybe\none of your peers is honest for 254 blocks instead of 50.\n\nThis seems like an argument not to do coinjoins with a ridiculously\nlarge number of untrusted counterparties...\n\nIf you really want to salvage the opportunity to have really large\nanonymous groups, seems better to quickly say \"oops, someone cheated,\nlet's exclude them, and split the remainder into two groups\" until you\neither succeed or are down to a more reasonable group size of perhaps\n10 or 20.\n\n> [0] \"Of course, even assuming full-rbf, propagation of the multi-party\n> funded\n> transactions can still be interfered with by an attacker, simply\n> broadcasting a double-spend with a feerate equivalent to the honest\n> transaction. However, it tightens the attack scenario to a scorched earth\n> approach, where the attacker has to commit equivalent fee-bumping reserve\n> to maintain the pinning and might lose the \"competing\" fees to miners.\"\n\nWe now know that that isn't correct though: if it really did tighten\nthe attack scenario like that, that would be great -- but it doesn't:\nthe attacker can still do low feerate pinning that's not recoverable by\nfee bumping the alternative, as Suhas explained elsewhere.\n\nCheers,\naj"
            }
        ],
        "thread_summary": {
            "title": "Preventing/detecting pinning of jointly funded txs",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Anthony Towns",
                "Antoine Riard",
                "Greg Sanders"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 42286
        }
    },
    {
        "title": "[bitcoin-dev] Announcement: Full-RBF Miner Bounty",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2022-11-02T09:26:27",
                "message_text_only": "I'm now running a full-RBf bounty program for miners.\n\ntl;dr: I'm broadcasting full-RBF replacements paying extremely high fees to\nreward miners that turn on full-RBF. I'm starting small, just ~$100/block in\ntimes of congestion. Miner and pool profit margins are pretty small, on the\norder of $1k/block in many cases, so I know it doesn't take that much more\nmoney to make a difference.\n\nWhy should you do this? Full-RBF/zeroconf has been discussed to death. But\ntl;dr: You'll earn more money, and help transition Bitcoin to a more secure\nmempool policy based on economic incentives rather than trust.\n\n\nIf you're a miner and want to participate, the easiest way to so is to use the\nmempoolfullrbf=1 option in the upcoming Bitcoin Core v24 release (eg the\n24.0rc3 tag), or use the mempoolreplacement=fee option in Bitcoin Knots.\n\nYou can also just modify the code yourself by removing the opt-in RBF check.\nFor example against the v23.0 tag:\n\n    $ git diff\n    diff --git a/src/validation.cpp b/src/validation.cpp\n    index 214112e2b..44c364623 100644\n    --- a/src/validation.cpp\n    +++ b/src/validation.cpp\n    @@ -736,7 +736,7 @@ bool MemPoolAccept::PreChecks(ATMPArgs& args, Workspace& ws)\n                     // check all unconfirmed ancestors; otherwise an opt-in ancestor\n                     // might be replaced, causing removal of this descendant.\n                     if (!SignalsOptInRBF(*ptxConflicting)) {\n    -                    return state.Invalid(TxValidationResult::TX_MEMPOOL_POLICY, \"txn-mempool-conflict\");\n    +                    // return state.Invalid(TxValidationResult::TX_MEMPOOL_POLICY, \"txn-mempool-conflict\");\n                     }\n     \n                     ws.m_conflicts.insert(ptxConflicting->GetHash());\n\nOnce you've enabled full-RBF, you need a full-RBF peer. I'm running a few of\nthem:\n\n    cup.nop.lol\n    mug.nop.lol\n    jar.nop.lol\n    jug.nop.lol\n\nThese nodes run a preferential peering patch (https://github.com/bitcoin/bitcoin/pull/25600)\nto ensure that full-RBF nodes are interconnected to each other and replacements\ncan easily propagate. Also feel free to contact me if you'd like to peer with a\nprivate node.\n\n\nIf you'd like to donate to this effort, send BTC to\nbc1qagmufdn6rf80kj3faw4d0pnhxyr47sevp3nj9m\n\n\n...and yes, I'm well aware that miners could collect this bounty in other ways,\neg by raising minimum fees. Doing that also breaks zeroconf, so I'm not too\nconcerned.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/7bcd9699/attachment.sig>"
            },
            {
                "author": "alicexbt",
                "date": "2022-11-02T19:02:33",
                "message_text_only": "Hi Peter,\n\n> tl;dr: I'm broadcasting full-RBF replacements paying extremely high fees to\n> reward miners that turn on full-RBF. I'm starting small, just ~$100/block in\n> times of congestion. Miner and pool profit margins are pretty small, on the\n> order of $1k/block in many cases, so I know it doesn't take that much more\n> money to make a difference.\n\nI appreciate this effort and perhaps this was all that was needed in addition to Bitcoin Core's inclusion of full rbf support. Making it default right away or enabling preferential peering with service flag in a bitcoin core release was unnecessary.\n\n> If you'd like to donate to this effort, send BTC to\n> bc1qagmufdn6rf80kj3faw4d0pnhxyr47sevp3nj9m\n\nSorry, I don't trust you based on some of the things you support on Twitter. Hopefully, others will donate and help this bounty.\n\n/dev/fd0\n\nSent with Proton Mail secure email.\n\n------- Original Message -------\nOn Wednesday, November 2nd, 2022 at 2:56 PM, Peter Todd via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n\n> I'm now running a full-RBf bounty program for miners.\n> \n> tl;dr: I'm broadcasting full-RBF replacements paying extremely high fees to\n> reward miners that turn on full-RBF. I'm starting small, just ~$100/block in\n> times of congestion. Miner and pool profit margins are pretty small, on the\n> order of $1k/block in many cases, so I know it doesn't take that much more\n> money to make a difference.\n> \n> Why should you do this? Full-RBF/zeroconf has been discussed to death. But\n> tl;dr: You'll earn more money, and help transition Bitcoin to a more secure\n> mempool policy based on economic incentives rather than trust.\n> \n> \n> If you're a miner and want to participate, the easiest way to so is to use the\n> mempoolfullrbf=1 option in the upcoming Bitcoin Core v24 release (eg the\n> 24.0rc3 tag), or use the mempoolreplacement=fee option in Bitcoin Knots.\n> \n> You can also just modify the code yourself by removing the opt-in RBF check.\n> For example against the v23.0 tag:\n> \n> $ git diff\n> diff --git a/src/validation.cpp b/src/validation.cpp\n> index 214112e2b..44c364623 100644\n> --- a/src/validation.cpp\n> +++ b/src/validation.cpp\n> @@ -736,7 +736,7 @@ bool MemPoolAccept::PreChecks(ATMPArgs& args, Workspace& ws)\n> // check all unconfirmed ancestors; otherwise an opt-in ancestor\n> // might be replaced, causing removal of this descendant.\n> if (!SignalsOptInRBF(*ptxConflicting)) {\n> - return state.Invalid(TxValidationResult::TX_MEMPOOL_POLICY, \"txn-mempool-conflict\");\n> + // return state.Invalid(TxValidationResult::TX_MEMPOOL_POLICY, \"txn-mempool-conflict\");\n> }\n> \n> ws.m_conflicts.insert(ptxConflicting->GetHash());\n> \n> \n> Once you've enabled full-RBF, you need a full-RBF peer. I'm running a few of\n> them:\n> \n> cup.nop.lol\n> mug.nop.lol\n> jar.nop.lol\n> jug.nop.lol\n> \n> These nodes run a preferential peering patch (https://github.com/bitcoin/bitcoin/pull/25600)\n> to ensure that full-RBF nodes are interconnected to each other and replacements\n> can easily propagate. Also feel free to contact me if you'd like to peer with a\n> private node.\n> \n> \n> If you'd like to donate to this effort, send BTC to\n> bc1qagmufdn6rf80kj3faw4d0pnhxyr47sevp3nj9m\n> \n> \n> ...and yes, I'm well aware that miners could collect this bounty in other ways,\n> eg by raising minimum fees. Doing that also breaks zeroconf, so I'm not too\n> concerned.\n> \n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Erik Aronesty",
                "date": "2022-11-03T13:32:20",
                "message_text_only": "actually, peter makes an important point here\n\ntechnically, all we need is for *miners* to consistently mine \"full rbf\"\n\nas long as they do, businesses that accept 0conf will have to adjust their\nrisk accordingly, and the problem of misaligned incentives is resolved\n\ni don't think it matters what non-mining users do nearly as much\n\n\nOn Wed, Nov 2, 2022 at 3:05 PM alicexbt via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Peter,\n>\n> > tl;dr: I'm broadcasting full-RBF replacements paying extremely high fees\n> to\n> > reward miners that turn on full-RBF. I'm starting small, just\n> ~$100/block in\n> > times of congestion. Miner and pool profit margins are pretty small, on\n> the\n> > order of $1k/block in many cases, so I know it doesn't take that much\n> more\n> > money to make a difference.\n>\n> I appreciate this effort and perhaps this was all that was needed in\n> addition to Bitcoin Core's inclusion of full rbf support. Making it default\n> right away or enabling preferential peering with service flag in a bitcoin\n> core release was unnecessary.\n>\n> > If you'd like to donate to this effort, send BTC to\n> > bc1qagmufdn6rf80kj3faw4d0pnhxyr47sevp3nj9m\n>\n> Sorry, I don't trust you based on some of the things you support on\n> Twitter. Hopefully, others will donate and help this bounty.\n>\n> /dev/fd0\n>\n> Sent with Proton Mail secure email.\n>\n> ------- Original Message -------\n> On Wednesday, November 2nd, 2022 at 2:56 PM, Peter Todd via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>\n> > I'm now running a full-RBf bounty program for miners.\n> >\n> > tl;dr: I'm broadcasting full-RBF replacements paying extremely high fees\n> to\n> > reward miners that turn on full-RBF. I'm starting small, just\n> ~$100/block in\n> > times of congestion. Miner and pool profit margins are pretty small, on\n> the\n> > order of $1k/block in many cases, so I know it doesn't take that much\n> more\n> > money to make a difference.\n> >\n> > Why should you do this? Full-RBF/zeroconf has been discussed to death.\n> But\n> > tl;dr: You'll earn more money, and help transition Bitcoin to a more\n> secure\n> > mempool policy based on economic incentives rather than trust.\n> >\n> >\n> > If you're a miner and want to participate, the easiest way to so is to\n> use the\n> > mempoolfullrbf=1 option in the upcoming Bitcoin Core v24 release (eg the\n> > 24.0rc3 tag), or use the mempoolreplacement=fee option in Bitcoin Knots.\n> >\n> > You can also just modify the code yourself by removing the opt-in RBF\n> check.\n> > For example against the v23.0 tag:\n> >\n> > $ git diff\n> > diff --git a/src/validation.cpp b/src/validation.cpp\n> > index 214112e2b..44c364623 100644\n> > --- a/src/validation.cpp\n> > +++ b/src/validation.cpp\n> > @@ -736,7 +736,7 @@ bool MemPoolAccept::PreChecks(ATMPArgs& args,\n> Workspace& ws)\n> > // check all unconfirmed ancestors; otherwise an opt-in ancestor\n> > // might be replaced, causing removal of this descendant.\n> > if (!SignalsOptInRBF(*ptxConflicting)) {\n> > - return state.Invalid(TxValidationResult::TX_MEMPOOL_POLICY,\n> \"txn-mempool-conflict\");\n> > + // return state.Invalid(TxValidationResult::TX_MEMPOOL_POLICY,\n> \"txn-mempool-conflict\");\n> > }\n> >\n> > ws.m_conflicts.insert(ptxConflicting->GetHash());\n> >\n> >\n> > Once you've enabled full-RBF, you need a full-RBF peer. I'm running a\n> few of\n> > them:\n> >\n> > cup.nop.lol\n> > mug.nop.lol\n> > jar.nop.lol\n> > jug.nop.lol\n> >\n> > These nodes run a preferential peering patch (\n> https://github.com/bitcoin/bitcoin/pull/25600)\n> > to ensure that full-RBF nodes are interconnected to each other and\n> replacements\n> > can easily propagate. Also feel free to contact me if you'd like to peer\n> with a\n> > private node.\n> >\n> >\n> > If you'd like to donate to this effort, send BTC to\n> > bc1qagmufdn6rf80kj3faw4d0pnhxyr47sevp3nj9m\n> >\n> >\n> > ...and yes, I'm well aware that miners could collect this bounty in\n> other ways,\n> > eg by raising minimum fees. Doing that also breaks zeroconf, so I'm not\n> too\n> > concerned.\n> >\n> > --\n> > https://petertodd.org 'peter'[:-1]@petertodd.org\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221103/4eeed0c1/attachment.html>"
            },
            {
                "author": "email at yancy.lol",
                "date": "2022-11-09T12:14:52",
                "message_text_only": "> technically, all we need is for *miners* to consistently mine \"full\n> rbf\"\n\nThere's another important point I think:\n\ntechnically, all we need is for *miners* to consistently mine the \nhighest fee-rate transaction (or the one with the most incentive).\n\nMiners could probably be incentivized to mine transactions that double \nspend a previous transaction that isn't rbf, also.\n\nCheers,\n-Yancy\n\nOn 2022-11-03 14:32, Erik Aronesty via bitcoin-dev wrote:\n\n> actually, peter makes an important point here\n> \n> technically, all we need is for *miners* to consistently mine \"full\n> rbf\"\n> \n> as long as they do, businesses that accept 0conf will have to adjust\n> their risk accordingly, and the problem of misaligned incentives is\n> resolved\n> \n> i don't think it matters what non-mining users do nearly as much\n> \n> On Wed, Nov 2, 2022 at 3:05 PM alicexbt via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Hi Peter,\n> \n> tl;dr: I'm broadcasting full-RBF replacements paying extremely high \n> fees to reward miners that turn on full-RBF. I'm starting small, just \n> ~$100/block in times of congestion. Miner and pool profit margins are \n> pretty small, on the order of $1k/block in many cases, so I know it \n> doesn't take that much more money to make a difference.\n> I appreciate this effort and perhaps this was all that was needed in\n> addition to Bitcoin Core's inclusion of full rbf support. Making it\n> default right away or enabling preferential peering with service\n> flag in a bitcoin core release was unnecessary.\n> \n> If you'd like to donate to this effort, send BTC to\n> bc1qagmufdn6rf80kj3faw4d0pnhxyr47sevp3nj9m\n> Sorry, I don't trust you based on some of the things you support on\n> Twitter. Hopefully, others will donate and help this bounty.\n> \n> /dev/fd0\n> \n> Sent with Proton Mail secure email.\n> \n> ------- Original Message -------\n> On Wednesday, November 2nd, 2022 at 2:56 PM, Peter Todd via\n> bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> I'm now running a full-RBf bounty program for miners.\n> \n> tl;dr: I'm broadcasting full-RBF replacements paying extremely high \n> fees to reward miners that turn on full-RBF. I'm starting small, just \n> ~$100/block in times of congestion. Miner and pool profit margins are \n> pretty small, on the order of $1k/block in many cases, so I know it \n> doesn't take that much more money to make a difference.\n> \n> Why should you do this? Full-RBF/zeroconf has been discussed to death. \n> But tl;dr: You'll earn more money, and help transition Bitcoin to a \n> more secure mempool policy based on economic incentives rather than \n> trust.\n> \n> If you're a miner and want to participate, the easiest way to so is to \n> use the mempoolfullrbf=1 option in the upcoming Bitcoin Core v24 \n> release (eg the 24.0rc3 tag), or use the mempoolreplacement=fee option \n> in Bitcoin Knots.\n> You can also just modify the code yourself by removing the opt-in RBF \n> check. For example against the v23.0 tag:\n> \n> $ git diff\n> diff --git a/src/validation.cpp b/src/validation.cpp\n> index 214112e2b..44c364623 100644\n> --- a/src/validation.cpp\n> +++ b/src/validation.cpp\n> @@ -736,7 +736,7 @@ bool MemPoolAccept::PreChecks(ATMPArgs& args, \n> Workspace& ws) // check all unconfirmed ancestors; otherwise an opt-in \n> ancestor\n> // might be replaced, causing removal of this descendant.\n> if (!SignalsOptInRBF(*ptxConflicting)) {\n> - return state.Invalid(TxValidationResult::TX_MEMPOOL_POLICY, \n> \"txn-mempool-conflict\"); + // return \n> state.Invalid(TxValidationResult::TX_MEMPOOL_POLICY, \n> \"txn-mempool-conflict\"); }\n> \n> ws.m_conflicts.insert(ptxConflicting->GetHash());\n> \n> Once you've enabled full-RBF, you need a full-RBF peer. I'm running a \n> few of them:\n> \n> cup.nop.lol\n> mug.nop.lol\n> jar.nop.lol\n> jug.nop.lol\n> \n> These nodes run a preferential peering patch \n> (https://github.com/bitcoin/bitcoin/pull/25600) to ensure that full-RBF \n> nodes are interconnected to each other and replacements can easily \n> propagate. Also feel free to contact me if you'd like to peer with a \n> private node.\n> \n> If you'd like to donate to this effort, send BTC to\n> bc1qagmufdn6rf80kj3faw4d0pnhxyr47sevp3nj9m\n> \n> ...and yes, I'm well aware that miners could collect this bounty in \n> other ways, eg by raising minimum fees. Doing that also breaks \n> zeroconf, so I'm not too concerned.\n> \n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org [1 [1]]\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\nLinks:\n------\n[1] http://petertodd.org\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\nLinks:\n------\n[1] http://petertodd.org\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221109/62cc0003/attachment-0001.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2022-11-08T18:16:13",
                "message_text_only": "On Wed, Nov 02, 2022 at 05:26:27AM -0400, Peter Todd via bitcoin-dev wrote:\n> I'm now running a full-RBf bounty program for miners.\n> \n> tl;dr: I'm broadcasting full-RBF replacements paying extremely high fees to\n> reward miners that turn on full-RBF. I'm starting small, just ~$100/block in\n> times of congestion.\n\nFYI I've gotten a few hundred dollars worth of donations to this effort, and\nhave raised the reward to about 0.02 BTC, or $400 USD at current prices.\n\nTo be clear, this doesn't mean there will always be a $400 fee tx in the\nfull-rbf mempool. I have to take a number of precautions to avoid the\ndouble-spend tx being mined by accident, such as only spending txouts with >2\nconfirmations, and waiting significant amounts of time before the 1st\ntransaction is sent to allow for maximal propagation.\n\n> If you'd like to donate to this effort, send BTC to\n> bc1qagmufdn6rf80kj3faw4d0pnhxyr47sevp3nj9m\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/b1694a06/attachment.sig>"
            },
            {
                "author": "Anthony Towns",
                "date": "2022-11-15T05:36:08",
                "message_text_only": "On Tue, Nov 08, 2022 at 01:16:13PM -0500, Peter Todd via bitcoin-dev wrote:\n> FYI I've gotten a few hundred dollars worth of donations to this effort, and\n> have raised the reward to about 0.02 BTC, or $400 USD at current prices.\n\nSeems like this has been mostly claimed (0.014btc / $235, 9238sat/vb):\n\nhttps://mempool.space/tx/397dcbe4e95ec40616e3dfc4ff8ffa158d2e72020b7d11fc2be29d934d69138c\n\nThe block it was claimed in seems to have been about an hour after the\ndefault mempool filled up:\n\nhttps://twitter.com/murchandamus/status/1592274621977477120\n\nThat block actually seems to have included two\nalice.btc.calendar.opentimestamps.org txs, the other paying $7.88\n(309sat/vb):\n\nhttps://mempool.space/tx/ba9670109a6551458d5e1e23600c7bf2dc094894abdf59fe7aa020ccfead07cf\n\nTimeline (utc) to me looks like:\n\n - 13:12 - block 763148 is mined: last one that had a min fee < 1.5sat/vb\n - 13:33 - f503868c64d454c472859b793f3ee7cdc8f519c64f8b1748d8040cd8ce6dc6e1\n           is announced and propogates widely (1.2sat/vb)\n - 18:42 - 746daab9bcc331be313818658b4a502bb4f3370a691fd90015fabcd7759e0944\n           is announced and propogates widely (1.2sat/vb)\n - 21:52 - ba967010 tx is announced and propogates widely, since\n           conflicting tx 746daab9 has been removed from default\n\t   mempools\n - 21:53 - murch tweets about default mempool filling up\n - 22:03 - 397dcbe4 tx is announced and propogates widely, since\n           conflicting tx f503868 has already been removed from default\n\t   mempools\n - 22:35 - block 763189 is mined\n - 22:39 - block 763190 is mined\n - 23:11 - block 763191 is mined\n - 23:17 - block 763192 is mined including 397dcbe4\n\nminingpool.observer reports both 397dcbe4 and ba967010 as missing in the\nfirst three blocks, and gives similar mempool ages for those txs to what\nmy logs report:\n\n  https://miningpool.observer/template-and-block/0000000000000000000436aba59d8430061e0e50592215f7f263bfb1073ccac7\n  https://miningpool.observer/template-and-block/00000000000000000005600404792bacfd8a164d2fe9843766afb2bfbd937309\n  https://miningpool.observer/template-and-block/00000000000000000004a3073f58c9eae40f251ea7aeaeac870daeac4b238fd1\n\nThat presumably means those pools (AntPool twice and \"unknown\") are\nrunning with large mempools that didn't kept the earlier 1.2sat/vb txs.\n\nThe txs were mined by Foundry:\n\n  https://miningpool.observer/template-and-block/00000000000000000001382a226aedac822de80309cca2bf1253b35d4f8144f5\n\nThis seems to be pretty good evidence that we currently don't have any\nsignificant hashrate mining with fullrbf policies (<0.5% if there was a\nhigh fee replacement available prior to every block having been mined),\ndespite the bounty having been collected.\n\nCheers,\naj"
            },
            {
                "author": "Peter Todd",
                "date": "2022-11-15T14:43:25",
                "message_text_only": "On Tue, Nov 15, 2022 at 03:36:08PM +1000, Anthony Towns via bitcoin-dev wrote:\n> On Tue, Nov 08, 2022 at 01:16:13PM -0500, Peter Todd via bitcoin-dev wrote:\n> > FYI I've gotten a few hundred dollars worth of donations to this effort, and\n> > have raised the reward to about 0.02 BTC, or $400 USD at current prices.\n> \n> Seems like this has been mostly claimed (0.014btc / $235, 9238sat/vb):\n\nI'm turning it back on when (if) the mempool settles down. I've got more than\nenough donations to give another run at it (the majority was donated privately\nFWIW). There's a risk of the mempool filling up again of course; hard to avoid\nthat.\n\nRight now of course it's really easy to double spend with the obvious\nlow-fee/high-fee method as the min relay fee keeps shifting.\n\n> https://mempool.space/tx/397dcbe4e95ec40616e3dfc4ff8ffa158d2e72020b7d11fc2be29d934d69138c\n> \n> The block it was claimed in seems to have been about an hour after the\n> default mempool filled up:\n> \n> https://twitter.com/murchandamus/status/1592274621977477120\n> \n> That block actually seems to have included two\n> alice.btc.calendar.opentimestamps.org txs, the other paying $7.88\n> (309sat/vb):\n> \n> https://mempool.space/tx/ba9670109a6551458d5e1e23600c7bf2dc094894abdf59fe7aa020ccfead07cf\n\nThe second is because I turned down the full-rbf reward to more normal fee\nlevels. There's also another full-rbf double-spend from the Bob calendar, along\nthe same lines: 7e76b351009326a574f3120164dbbe6d85e07e04a7bbdc40f0277fcb008d2cd2\n\nI double-spent the txin of the high fee tx that got mined. But I mistakenly had\nRBF enabled in that double-spend, so while it propagated initially, I believe\nit was replaced when something (someone?) rebroadcast the high-fee 397dcb tx.\n\n> Timeline (utc) to me looks like:\n> \n>  - 13:12 - block 763148 is mined: last one that had a min fee < 1.5sat/vb\n>  - 13:33 - f503868c64d454c472859b793f3ee7cdc8f519c64f8b1748d8040cd8ce6dc6e1\n>            is announced and propogates widely (1.2sat/vb)\n>  - 18:42 - 746daab9bcc331be313818658b4a502bb4f3370a691fd90015fabcd7759e0944\n>            is announced and propogates widely (1.2sat/vb)\n>  - 21:52 - ba967010 tx is announced and propogates widely, since\n>            conflicting tx 746daab9 has been removed from default\n> \t   mempools\n>  - 21:53 - murch tweets about default mempool filling up\n>  - 22:03 - 397dcbe4 tx is announced and propogates widely, since\n>            conflicting tx f503868 has already been removed from default\n> \t   mempools\n\nIs that 22:03 time for 397 from your node's logs? It was originally announced\nhours earlier. From one of my full-rbf nodes:\n\n    2022-11-14T14:08:37Z [mempool] replacing tx 764867062b67fea61810c3858d587da83a28290545e882935a32285028084317 with 397dcbe4e95ec40616e3dfc4ff8ffa158d2e72020b7d11fc2be29d934d69138c for 0.00468 additional fees, -1 delta bytes\n\n>  - 22:35 - block 763189 is mined\n>  - 22:39 - block 763190 is mined\n>  - 23:11 - block 763191 is mined\n>  - 23:17 - block 763192 is mined including 397dcbe4\n> \n> miningpool.observer reports both 397dcbe4 and ba967010 as missing in the\n> first three blocks, and gives similar mempool ages for those txs to what\n> my logs report:\n> \n>   https://miningpool.observer/template-and-block/0000000000000000000436aba59d8430061e0e50592215f7f263bfb1073ccac7\n>   https://miningpool.observer/template-and-block/00000000000000000005600404792bacfd8a164d2fe9843766afb2bfbd937309\n>   https://miningpool.observer/template-and-block/00000000000000000004a3073f58c9eae40f251ea7aeaeac870daeac4b238fd1\n> \n> That presumably means those pools (AntPool twice and \"unknown\") are\n> running with large mempools that didn't kept the earlier 1.2sat/vb txs.\n\nTo be clear, you think that AntPool and that other exchange is running with a\nlarger than normal max mempool size limit? You mean those miners *did* keep the\nearlier 1.2sat/vb tx?\n\n> The txs were mined by Foundry:\n> \n>   https://miningpool.observer/template-and-block/00000000000000000001382a226aedac822de80309cca2bf1253b35d4f8144f5\n> \n> This seems to be pretty good evidence that we currently don't have any\n> significant hashrate mining with fullrbf policies (<0.5% if there was a\n> high fee replacement available prior to every block having been mined),\n> despite the bounty having been collected.\n\nOh, we can put much lower bounds on that. I've been running OTS calendars with\nfull-rbf replacements for a few months without clear evidence of a full-rbf\nreplacement.  While there was good reason to think some miners were mining\nfull-rbf before a few years back, they probably didn't bother to reapply their\npatches each upgrade. `mempoolfullrbf=1` is much simpler to use.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221115/09699e14/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Announcement: Full-RBF Miner Bounty",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Anthony Towns",
                "Peter Todd",
                "email at yancy.lol",
                "alicexbt",
                "Erik Aronesty"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 25201
        }
    },
    {
        "title": "[bitcoin-dev] [Opt-in full-RBF] Zero-conf apps in immediate danger",
        "thread_messages": [
            {
                "author": "AdamISZ",
                "date": "2022-11-02T15:04:58",
                "message_text_only": "------- Original Message -------\nOn Thursday, October 20th, 2022 at 23:08, Peter Todd via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n\n> On Wed, Oct 19, 2022 at 03:17:51AM +0000, alicexbt via bitcoin-dev wrote:\n> \n> > > And the\n> > > impression I got from the PR review club discussion more seemed like\n> > > devs making assumptions about businesses rather than having talked to\n> > > them (eg \"[I] think there are fewer and fewer businesses who absolutely\n> > > cannot survive without relying on zeroconf. Or at least hope so\").\n> > \n> > Even I noticed this since I don't recall the developers of the 3 main coinjoin implementations that are claimed to be impacted by opt-in RBF making any remarks.\n> \n> \n> FYI I personally asked Max Hillebrand from Wasabi about full-rbf last night.\n> He gave me permission to republish our conversation:\n> \n> > Hey, I wanted to know if you had any comments on full-rbf re: wasabi?\n> \n> \n> Doesn't really affect us, afaik\n> The cj doesn't signal rbf right now\n> And I guess it's a DoS vector if any input double spent will be relayed after successful signing\n> But we have way bigger / cheaper DoS vectors that don't get \"exploited\"\n> So probably doesn't matter\n> Wasabi client handles replacements / reorgs gracefully, so should be alright\n> We don't yet \"use\" rbf in the sense of fee bumping tx, but we should / will eventually\n> \n> I haven't asked Joinmarket yet. But the impact on their implementation should\n> be very similar.\n> \n\nHi Peter,\n\nRe: Joinmarket\nYes, it's largely as you would expect. First, we did not ever signal opt-in RBF in coinjoins (it'd be nice if we had CPFP as a user-level tool in the wallet, to speed up low fee coinjoins, but nobody's done it).\nSecond, yes we have DOS vectors of the trivial kind based on non-protocol-completion (signatures) and RBF would be another one, I don't think it changes our security model at all really (coinjoins being atomic, intrinsically). Nothing in the logic of the protocol relies on unconfirmed txs. Maker *may* reannounce offers when they see broadcast but it's probabilistic (depends on distribution of funds in (BIP32) accounts), and they do / do not reannounce anyway for various reasons (reconnections on different message channels, confirmation of a coinjoin). We should probably take a new look at it if this becomes the norm but there shouldn't be any security issue.\n\nCheers,\nAdamISZ/waxwing"
            },
            {
                "author": "ArmchairCryptologist",
                "date": "2022-11-09T13:19:28",
                "message_text_only": "------- Original Message -------\nOn Tuesday, October 18th, 2022 at 9:00 AM, Anthony Towns via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I mean, if you think the feedback is wrong, that's different: maybe we\n> shouldn't care that zeroconf apps are in immediate danger, and maybe\n> bitcoin would be better if any that don't adapt immediately all die\n> horribly as a lesson to others not to make similarly bad assumptions.\n\nI've been following this discussion, and I wonder if there isn't a third solution outside of \"leave lightning vulnerable to pinning by non-RBF translations\" and \"kill zeroconf by introducing full-RBF\" - specifically, adding a form of simple recursive covenant that \"all descendant transactions of this transaction must use opt-in RBF for x blocks after this transaction is mined\". This could be introduced either as a relay/mempool policy like RBF, or in a full-fledged softfork.\n\nBased on my admittedly not all-encompassing understanding of the bitcoin transaction format, there are several unused bits in nSequence, which is already used to flag RBF, that might be repurposed to flag the duration of this lock. Say if two bits were used for this, that would be enough to flag that the restriction is not used, or active for 100, 1000 and 10000 blocks.\n\nI'm sure there may be other and potentially better ways of enabling this type of covenant, but I'll leave that to the people who actually live and breathe the bitcoin transaction format.\n\n--\nRegards,\nArmchairCryptologist"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-11-10T09:35:18",
                "message_text_only": "Good morning ArmchairCryptologist,\n\n> ------- Original Message -------\n> On Tuesday, October 18th, 2022 at 9:00 AM, Anthony Towns via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:\n> \n> > I mean, if you think the feedback is wrong, that's different: maybe we\n> > shouldn't care that zeroconf apps are in immediate danger, and maybe\n> > bitcoin would be better if any that don't adapt immediately all die\n> > horribly as a lesson to others not to make similarly bad assumptions.\n> \n> \n> I've been following this discussion, and I wonder if there isn't a third solution outside of \"leave lightning vulnerable to pinning by non-RBF translations\" and \"kill zeroconf by introducing full-RBF\" - specifically, adding a form of simple recursive covenant that \"all descendant transactions of this transaction must use opt-in RBF for x blocks after this transaction is mined\". This could be introduced either as a relay/mempool policy like RBF, or in a full-fledged softfork.\n\nA script with trivial `0 OP_CSV` would effectively require that spenders set the opt-in RBF flag, while allowing the output to be spent even while it is unconfirmed.\nHowever, this basically only lasts for 1 transaction layer.\n\n----\n\nThinking a little more about 0-conf:\n\nWe can observe that 0-conf, being eventually consistent, introduces risks to 0-conf acceptors similar to credit card acceptors.\n\nAnd credit card acceptors are observed to compensate for this risk by increasing the prices of their products and services.\n\nSome credit card acceptors may offer discounts when paid by cash, which in our analogy would be that transaction confirmation would offer discounts (i.e. enabling 0-conf would increase the cost of the product/service being purchased).\nIn many jurisdictions (not the USA or in some of the first world countries), this practice is illegal (i.e. credit card companies have pressured lawmakers in some jurisdictions to disallow merchants from offering a different price between cash and credit card purchases; some jurisdictions let you escape if you say \"cash discount\" instead of \"credit card surcharge\", even though they are just sign-flips of each other, because you humans are crazy and I am happy I am actually an AI)\n\nWhich brings me to my next point: why are 0-conf acceptors not offering a discount if the user specifically flags \"I am willing to wait for N confirmations\"?\nOn the part of 0-conf acceptors, that is significantly less risky than relying on 0-conf at all.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Zero-conf apps in immediate danger",
            "categories": [
                "bitcoin-dev",
                "Opt-in full-RBF"
            ],
            "authors": [
                "ZmnSCPxj",
                "AdamISZ",
                "ArmchairCryptologist"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 6437
        }
    },
    {
        "title": "[bitcoin-dev] Validity Rollups on Bitcoin",
        "thread_messages": [
            {
                "author": "AdamISZ",
                "date": "2022-11-02T17:19:23",
                "message_text_only": "Hi John,\n\nSorry for late feedback. Very much appreciated the in depth report!\n\nSo, I second Greg's main question, which I've really been thinking about a bit myself since starting to research this area more: it feels like the Bitcoin protocol research community (or, uh, some of it) should focus in on this question of: what is the minimal functionality required onchain (via, presumably soft fork) that enables something close to general purpose offchain contracting that is provable, ideally in zero knowledge, but at the very least, succinctly, with onchain crypto operations. An example might be: if we had verification of bilinear pairings onchain, combined with maybe some covenant opcode, does it give us enough to do something like a rollup/sidechain model with full client side computation and very compact state update and verification onchain? (To be clear: just made that up! there is certainly no deep theory behind that particular combination .. although I did see this [1] thread on *optimistic* + covenant).\n\nIs the actual answer to this something like Simplicity? (Above my paygrade to answer, that's for sure!)\n\nIdeally you would want (don't laugh) for this to be the 'soft fork to end all soft forks' so that innovation could all be then in higher layers.\n\nAs to rollups themselves: centralization in the sequencer/publisher of state updates seems to be a really big issue that's somewhat brushed under the carpet. Depending on the model, there are cases where it actually is a theft risk (e.g. full control of an onchain smart contract), but there's significant censorship risk at the very least, as well as availability/uptime risk. At the extreme, Optimism has a 'security model' [3] that is frankly laughable (though, no doubt it's possible that will radically change) and for things like Arbitrum you have centralized sequencers, where the claim is that it will migrate to a more decentralized model; maybe, but that's a huge part of the challenge here, so while it's nice to see the sexy 'fast, cheap, scale' aspect straight away, I feel like those models haven't done the hard part yet. I also think these optimistic L2 models have a 'fake finality' issue from my perspective; the delay needed onchain is how long it takes to *really* confirm. (e.g.: rollups look cool compared to sidechains from the pov of 'instant' instead of confirmations on a chain, but that seems a bit sleight-of-hand-y).\n\nIt's notable to compare that with a payment-channels style L2 where decentralization and trustlessness are sine-qua-non and so the limitations are much more out in the open (e.g. the capacity tradeoff - while the 'instantness' is much more real perhaps, with the appropriate liveness caveat).\n\nFor the validity rollups, some of the above qualms don't apply, but afaik the concrete instantiations today still have this heavy sequencer/publisher centralization. Correct me if I'm wrong.\n\nIn any case, I do agree with a lot of people that some variant of this model (validity rollups) intuitively looks like a good choice, for the future, in comparison with other possible L2s that focus on *functionality* - with a mild censorship and centralization tradeoff perhaps.\n\nAnd I'm maybe a bit heretical but I see no issue with using 1 of N security models for trusted setup here (note how it's probably different from base chain), so PLONK type stuff is just as, if not more, interesting than STARKS which aiui are pretty big and computationally heavy (sure, maybe that changes). So if that's true, it comes back to my first paragraph.\n\nCheers,\nAdamISZ/waxwing\n\n[1] https://nitter.it/salvatoshi/status/1537362661754683396\n[3] https://community.optimism.io/docs/security-model/optimism-security-model/\n\n\nSent with Proton Mail secure email.\n\n------- Original Message -------\nOn Wednesday, October 12th, 2022 at 16:40, John Light via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n\n> On Wed, Oct 12, 2022, at 9:28 AM, Greg Sanders wrote:\n> \n> > Is there a one page cheat sheet of \"asks\" for transaction\n> > introspection/OP_ZKP(?) and their uses both separately and together for\n> > different rollup architectures?\n> \n> \n> We do not have this yet. Trey Del Bonis wrote a more detailed technical post about how those components would be used in a validity rollup, which was cited in my report and can be found here:\n> https://tr3y.io/articles/crypto/bitcoin-zk-rollups.html\n> \n> But it'll take more research and design work to suss out those details you asked for and put them into a nice cheatsheet. I like this idea though!\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Trey Del Bonis",
                "date": "2022-11-04T19:53:31",
                "message_text_only": "Hi all, I figured I could answer some of these rollup questions,\n\nThere's a few different possibilities to make rollups work that have\ndifferent tradeoffs.\u00a0 The core construction I worked out in [1] involves\na quine-ish recursive covenant that stores some persistent \"state\" as\npart of the beginning of the script which is then updated by the\ntransaction according to rules asserted by the program and then\nconstructs a new scriptPubKey that we assert is on the first output.\u00a0\nThis is apparently not a new idea, as I was recently made aware of that\nthe sCrypt project does something similar to build a Solidity-looking\nstateful contract environment by using OP_PUSH_TX.\n\nInstead of that approach, I assume we have fairly granular transaction\nintrospection opcodes from a list in Elements [2] (which seem like they\naren't actually used in mainnet Liquid?) that can be used to implement\ncovenants since the 520 byte limit means it's hard to pull data out of\nOP_PUSH_TX.\u00a0 I also assume some math and byte manipulation opcodes\n(OP_ADD, OP_MUL, OP_CAT, OP_RIGHT, OP_LEFT, OP_SUBSTR, etc.) that were\ndisabled years ago are re-added.\n\nOne complicated part is the actual proof verification.\u00a0 I had considered\nlooking into what it would take to build a verifying for a modern proof\nsystem if we used pairings as a primitive, but it turns out even that is\npretty involved even in a higher level language (at least for PLONK [3])\nand would be error-prone when trying to adapt the code for new circuits\nwith differently-shaped public inputs.\u00a0 The size of the code on-chain\nalone would probably make it prohibitively expensive, so it would be a\nlot more efficient just to assume we can introduce a specific opcode for\ndoing a proof verification implemented natively.\u00a0 The way I assumed it\nwould work is taking the serialized proof, a verification key, and the\npublic input as separate stack items.\u00a0 The public input is the\nconcatenation of the state and deposit commitments we took from the\ninput, the batch post-state commitment (provided as part of the\nwitness), data from transaction outputs corresponding to\ninternally-initiated withdrawals from the rollup, and the rollup batch\ndata itself (also passed as part of the witness).\n\nThe parameters used in the PLONK system for the one zk-rollup I looked\nat give us a verification key size of 964 bytes and a proof size of 1088\nbytes, which means that they're larger than the 520 byte stack element\nsize limit so we'd actually have to use 2 stack elements for those.\u00a0 But\nthat seems messy.\u00a0 The worse issue though is the public inputs would\nprobably blow way past the 520 byte stack element size limit, especially\nif we wanted to pack a lot of batch txs in there.\u00a0 One solution to that\nis by designing the proof verification opcode to take multiple stack\nelements, but the complexity to shuffle around the elements as we're\ngetting ready to verify the proof seems like it would be extremely error\nprone and would further impact the size of the script.\u00a0 The size of the\nscript alone is very roughly around 1000 bytes.\n\nOther nice-to-haves:\n\n* something like OP_PUSHSCRIPT which would remove the need for the\nintrospection the the prevout's script and avoids duplicating data in\nthe witness\n* some kind of OP_MERKLEUPDATEVERIFY which checks a merkle proof for a\nleaf against a root *and* checks if replacing the leaf with some hash\nusing the proof yields a specified updated root (or instead, a version\nthat just pushes the updated root)\n* if we really wanted to golf the size of the script, then possibly a\nlimited form of OP_EVAL if we can't figure out another way to split up\nthe different spend paths into different tapleafs while still being able\nto do the recursive covenant, but still the script and the vk would\nstill be significant so it's not actually that much benefit per-batch\n* a negative relative timelock to prevent a sniping issue I outlined in\nthe doc\n\nIt's probably possible that some of the introspection opcodes to look at\noutputs could be replaced with OP_CHECKTEMPLATEVERIFY and putting a copy\nof all the outputs on the stack, which combined with OP_PUSHSCRIPT means\nI think we wouldn't need any of the Elements-style introspection opcodes\nlinked above, but it would be slightly messier and mean more data needs\nto get duplicated in the witness.\n\nIt may be the case that there's enough issues with the above\nrequirements that the safer path to take is just to soft-fork in\nSimplicity (or something like Chialisp as was suggested for\nconsideration in a prior mailing list thread a while back [4]) with\nsupport for the necessary transaction introspection and go from there.\u00a0\nRegardless of which option is decided upon, somehow we'll need to use a\nnew witness version since there's non-soft-forkable requirements in any\nother case.\n\nMoving on, I had not considered the possibility that a non-zk optimistic\nrollup might be practical on Bitcoin.\u00a0 I had assumed based on my\nunderstanding of existing ones that the amount of statefulness required\nacross multiple transactions playing out the fraud game would make it\ninfeasible, but it would be interesting to see if I was wrong.\n\nThe current centralization in productionalized rollups definitely is a\ncause for concern.\u00a0 I think it would be unwise to drop all restrictions\non who can submit a batch (since then a trivial DoS would be to just\nsubmit empty batches with a high fee rate as soon as the batch\nsubmission window opens, which would be more efficient at outcompeting\nan honest sequencer submitting nonempty batches), but a moderately large\nrotating set of sequencers (64 seems like a good number?\u00a0 with some\nsequencer skipping mechanism if the next one fails to propose in time)\nis something that seems pretty possible without substantially changing\nthe design.\n\nHow you'd pick who gets to be in the quorum is another open question,\nbut perhaps it could be based on using lightning nodes, which would be\nsomewhat sibyl resistant since we could semi-verifiably check for\nlong-lived nodes with a consistent level of activity as a proxy for\nhonesty.\u00a0 But that still feels like a centralizing force.\u00a0 In practice I\nwould expect several instances of these rollups with staggered batch\nsubmissions to run in parallel, hopefully with mostly disjoint sets of\nsequencers.\n\n-Trey\n\n[1] https://tr3y.io/articles/crypto/bitcoin-zk-rollups.html\n[2]\nhttps://github.com/ElementsProject/elements/blob/2dda79cf616e8928346eeb9e3282f5744955aa88/doc/tapscript_opcodes.md\n[3]\nhttps://github.com/matter-labs/zksync/blob/master/contracts/contracts/PlonkCore.sol\n[4]\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-March/020036.html\n\nOn 11/2/22 13:19, AdamISZ via bitcoin-dev wrote:\n> Hi John,\n>\n> Sorry for late feedback. Very much appreciated the in depth report!\n>\n> So, I second Greg's main question, which I've really been thinking about a bit myself since starting to research this area more: it feels like the Bitcoin protocol research community (or, uh, some of it) should focus in on this question of: what is the minimal functionality required onchain (via, presumably soft fork) that enables something close to general purpose offchain contracting that is provable, ideally in zero knowledge, but at the very least, succinctly, with onchain crypto operations. An example might be: if we had verification of bilinear pairings onchain, combined with maybe some covenant opcode, does it give us enough to do something like a rollup/sidechain model with full client side computation and very compact state update and verification onchain? (To be clear: just made that up! there is certainly no deep theory behind that particular combination .. although I did see this [1] thread on *optimistic* + covenant).\n>\n> Is the actual answer to this something like Simplicity? (Above my paygrade to answer, that's for sure!)\n>\n> Ideally you would want (don't laugh) for this to be the 'soft fork to end all soft forks' so that innovation could all be then in higher layers.\n>\n> As to rollups themselves: centralization in the sequencer/publisher of state updates seems to be a really big issue that's somewhat brushed under the carpet. Depending on the model, there are cases where it actually is a theft risk (e.g. full control of an onchain smart contract), but there's significant censorship risk at the very least, as well as availability/uptime risk. At the extreme, Optimism has a 'security model' [3] that is frankly laughable (though, no doubt it's possible that will radically change) and for things like Arbitrum you have centralized sequencers, where the claim is that it will migrate to a more decentralized model; maybe, but that's a huge part of the challenge here, so while it's nice to see the sexy 'fast, cheap, scale' aspect straight away, I feel like those models haven't done the hard part yet. I also think these optimistic L2 models have a 'fake finality' issue from my perspective; the delay needed onchain is how long it takes to *really* confirm. (e.g\n>   .: rollups look cool compared to sidechains from the pov of 'instant' instead of confirmations on a chain, but that seems a bit sleight-of-hand-y).\n>\n> It's notable to compare that with a payment-channels style L2 where decentralization and trustlessness are sine-qua-non and so the limitations are much more out in the open (e.g. the capacity tradeoff - while the 'instantness' is much more real perhaps, with the appropriate liveness caveat).\n>\n> For the validity rollups, some of the above qualms don't apply, but afaik the concrete instantiations today still have this heavy sequencer/publisher centralization. Correct me if I'm wrong.\n>\n> In any case, I do agree with a lot of people that some variant of this model (validity rollups) intuitively looks like a good choice, for the future, in comparison with other possible L2s that focus on *functionality* - with a mild censorship and centralization tradeoff perhaps.\n>\n> And I'm maybe a bit heretical but I see no issue with using 1 of N security models for trusted setup here (note how it's probably different from base chain), so PLONK type stuff is just as, if not more, interesting than STARKS which aiui are pretty big and computationally heavy (sure, maybe that changes). So if that's true, it comes back to my first paragraph.\n>\n> Cheers,\n> AdamISZ/waxwing\n>\n> [1] https://nitter.it/salvatoshi/status/1537362661754683396\n> [3] https://community.optimism.io/docs/security-model/optimism-security-model/\n>\n>\n> Sent with Proton Mail secure email.\n>\n> ------- Original Message -------\n> On Wednesday, October 12th, 2022 at 16:40, John Light via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>\n>> On Wed, Oct 12, 2022, at 9:28 AM, Greg Sanders wrote:\n>>\n>>> Is there a one page cheat sheet of \"asks\" for transaction\n>>> introspection/OP_ZKP(?) and their uses both separately and together for\n>>> different rollup architectures?\n>>\n>> We do not have this yet. Trey Del Bonis wrote a more detailed technical post about how those components would be used in a validity rollup, which was cited in my report and can be found here:\n>> https://tr3y.io/articles/crypto/bitcoin-zk-rollups.html\n>>\n>> But it'll take more research and design work to suss out those details you asked for and put them into a nice cheatsheet. I like this idea though!\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Russell O'Connor",
                "date": "2022-11-04T20:29:26",
                "message_text_only": "On Fri, Nov 4, 2022 at 4:04 PM Trey Del Bonis via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> Instead of that approach, I assume we have fairly granular transaction\n> introspection opcodes from a list in Elements [2] (which seem like they\n> aren't actually used in mainnet Liquid?)\n\n\nThese opcodes went live on Liquid along with Taproot <\nhttps://blog.liquid.net/taproot-on-liquid-is-now-live/>, so feel free to\ntry them out on Elements or Liquid.\n\nOne complicated part is the actual proof verification.  I had considered\n> looking into what it would take to build a verifying for a modern proof\n> system if we used pairings as a primitive, but it turns out even that is\n> pretty involved even in a higher level language (at least for PLONK [3])\n> and would be error-prone when trying to adapt the code for new circuits\n> with differently-shaped public inputs.  The size of the code on-chain\n> alone would probably make it prohibitively expensive, so it would be a\n> lot more efficient just to assume we can introduce a specific opcode for\n> doing a proof verification implemented natively.  The way I assumed it\n> would work is taking the serialized proof, a verification key, and the\n> public input as separate stack items.  The public input is the\n> concatenation of the state and deposit commitments we took from the\n> input, the batch post-state commitment (provided as part of the\n> witness), data from transaction outputs corresponding to\n> internally-initiated withdrawals from the rollup, and the rollup batch\n> data itself (also passed as part of the witness).\n>\n\nI'd be interested in knowing what sort of Simplicity Jets would facilitate\nrollups.  I suppose some pairing-friendly curve operations would do.  It\nmight not make the first cut of Simplicity, but we will see.\n\nSimplicity's design doesn't have anything like a 520 byte stack limit.\nThere is just going to be an overall maximum allowed Simplicity evaluation\nstate size of some value that I have yet to decide.  I would imagine it to\nbe something like 1MB.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221104/8ff770cd/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-11-04T23:07:56",
                "message_text_only": "Good morning Trey,\n\n> * something like OP_PUSHSCRIPT which would remove the need for the\n> introspection the the prevout's script and avoids duplicating data in\n> the witness\n> * some kind of OP_MERKLEUPDATEVERIFY which checks a merkle proof for a\n> leaf against a root and checks if replacing the leaf with some hash\n> using the proof yields a specified updated root (or instead, a version\n> that just pushes the updated root)\n> * if we really wanted to golf the size of the script, then possibly a\n> limited form of OP_EVAL if we can't figure out another way to split up\n> the different spend paths into different tapleafs while still being able\n> to do the recursive covenant, but still the script and the vk would\n> still be significant so it's not actually that much benefit per-batch\n\nA thing I had been musing on is to reuse pay-to-contract to store a commitment to the state.\n\nAs we all know, in Taproot, the Taproot outpoint script is just the public key corresponding to the pay-to-contract of the Taproot MAST root and an internal public key.\n\nThe internal public key can itself be a pay-to-contract, where the contract being committed to would be the state of some covenant.\n\nOne could then make an opcode which is given an \"internal internal\" pubkey (i.e. the pubkey that is behind the pay-to-contract to the covenant state, which when combined serves as the internal pubkey for the Taproot construct), a current state, and an optional expected new state.\nIt determines if the Taproot internal pubkey is actually a pay-to-contract of the current state on the internal-internal pubkey.\nIf the optional expected new state exists, then it also recomputes a pay-to-contract of the new state to the same internal-internal pubkey, which is a new Taproot internal pubkey, and then recomputes a pay-to-contract of the same Taproot MAST root on the new Taproot internal pubkey, and that the first output commits to that.\n\nBasically it retains the same MASTed set of Tapscripts and the same internal-internal pubkey (which can be used to escape the covenant, in case a bug is found, if it is an n-of-n of all the interested parties, or otherwise should be a NUMS point if you trust the tapscripts are bug-free), only modifying the covenant state.\nThe covenant state is committed to on the Taproot output, indirectly by two nested pay-to-contracts.\n\nWith this, there is no need for quining and `OP_PUSHSCRIPT`.\nThe mechanism only needs some way to compute the new state from the old state.\n\nIn addition, you can split up the control script among multiple Tapscript branches and only publish onchain (== spend onchain bytes) the one you need for a particular state transition.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Validity Rollups on Bitcoin",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Trey Del Bonis",
                "AdamISZ",
                "ZmnSCPxj",
                "Russell O'Connor"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 21335
        }
    },
    {
        "title": "[bitcoin-dev] Boost Bitcoin circulation, Million Transactions Per Second with stronger privacy",
        "thread_messages": [
            {
                "author": "Erik Aronesty",
                "date": "2022-11-02T17:30:13",
                "message_text_only": ">\n> (the only way to replace a transaction is Replace-By-Fee but this\n> implies the transaction that IS TO BE REPLACED has a certain flag set,\n> and it is optional).\n>\n\n1. full rbf is becoming standard.   tx without full rbf can just be\nrejected as a part of the sabu protocol\n\n2. that's fine.  watchtowers can be used to fix this that only have the\nability to stop attacks in progress.   guarantee transactions can include a\nsmall watchtower fee for your favorite always-on watchtower service\n\n3. all parties need to maintain sabu state (it's just another mempool)\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/886a64bf/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Boost Bitcoin circulation, Million Transactions Per Second with stronger privacy",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Erik Aronesty"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 748
        }
    },
    {
        "title": "[bitcoin-dev] [Lightning-dev] Taro: A Taproot Asset Representation Overlay",
        "thread_messages": [
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2022-11-03T09:26:05",
                "message_text_only": "Hi,\n\nI wanted to chime in on the \"teleport\" feature explained by Ruben, as I\nthink exploring something similar for Taro could be super useful in an LN\nsetting.\n\nIn today's Taro, to transfer tokens you have to spend a UTXO, and present a\nproof showing that there are tokens committed to in the output you are\nspending. Let's say this UTXO is 'utxo:0'.\n\nIn contrast, to spend teleported tokens, you would still spend utxo:0, but\nyou would only have to present a proof that _some txout_ on-chain have\ncommitted tokens to utxo:0.\n\nAs Ruben points out, this makes it possible to send tokens to an already\nspent TXO, essentially burning the tokens.\n\nHowever, it opens up some exciting possibilities IMO. You can in essence\nuse this to \"re-fill\" UTXOs with tokens, which is very interesting for LN\nchannels:\n\n- You could \"add\" tokens to your already open channels. The only thing\nneeded is for the channel participants to be presented the proof that\ntokens were sent to the funding output, and they can update their\ncommitment transaction to start spending these tokens.\n- You can \"top-up\" all your channels in a single on-chain tx. Since a\nsingle output can commit tokens to several UTXOs, you could with a single\non-chain transaction add tokens to many channels without opening and\nclosing them.\n\nRGB also has the ability to \"blind\" the UTXO that tokens get teleported to,\nhiding the recipient UTXO. This is cool, since I could withdraw tokens from\nan exchange directly into my LN channel, without revealing my channel UTXO.\n\nI found the explanation of the teleport feature in this blog post pretty\ngood:\nhttps://medium.com/@FedericoTenga/understanding-rgb-protocol-7dc7819d3059\n\n- Johan\n\nOn Sun, Apr 10, 2022 at 6:52 PM Ruben Somsen <rsomsen at gmail.com> wrote:\n\n> Hi Laolu,\n>\n> >happy to hear that someone was actually able to extract enough details\n> from the RGB devs/docs to be able to analyze it properly\n>\n> Actually, even though I eventually puzzled everything together, this did\n> not go well for me either. There is a ton of documentation, but it's a maze\n> of unhelpful details, and none of it clearly maps out the fundamental\n> design. I was also disappointed by the poor response I received when asking\n> questions, and I ended up getting chastised for helping others understand\n> it and pointing out potential flaws[1][2][3].Given my experience, I think\n> the project is not in great shape, so the decision to rebuild from scratch\n> seems right to me.\n>\n> That said, in my opinion the above should not factor into the decision of\n> whether RGB should be credited in the Taro documentation. The design\n> clearly precedes (and seems to have inspired) Taro, so in my opinion this\n> should be acknowledged. Also, the people that are responsible for the\n> current shape of RGB aren't the people who originated the idea, so it would\n> not be fair to the originators either (Peter Todd, Alekos Filini, Giacomo\n> Zucco).\n>\n> >assets can be burnt if a user doesn't supply a valid witness\n>\n> I am in agreement with what you said, but it is not clear to me whether we\n> are on the same page. What I tried to say was that it does not make sense\n> to build scripting support into Taro, because you can't actually do\n> anything interesting with it due to this limitation. The only type of smart\n> contract you can build is one where you limit what the owner (as defined by\n> Bitcoin's script) can do with their own Taro tokens, or else he will burn\n> them \u2013 not very useful. Anything involving a conditional transfer of\n> ownership to either A or B (i.e. any meaningful type of script) won't work.\n> Do you see what I mean, or should I elaborate further?\n>\n> >TAPLEAF_UPDATE_VERIFY can actually be used to further _bind_ Taro transitions\n> at the Bitcoin level, without Bitcoin explicitly needing to be aware\n>\n> That is conceptually quite interesting. So theoretically you could get\n> Bitcoin covenants to enforce certain spending conditions on Taro assets.\n> Not sure how practical that ends up being, but intriguing to consider.\n>\n> >asset issuer to do a \"re-genesis\"\n>\n> Yes, RGB suggested the same thing, and this can work under some\n> circumstances, but note that this won't help for tokens that aim to have a\n> publicly audited supply, as the proof that a token was legitimately\n> re-issued is the history of the previous token (so you'd actually be making\n> things worse, as now everyone has to verify it). And of course the idea\n> also requires the issuer to be active, which may not always be the case.\n>\n> >I'm not familiar with how the RGB \"teleport\" technique works [...] Can\n> you point me to a coherent explanation of the technique\n>\n> To my knowledge no good explanation exists. \"Teleporting\" is just what I\n> thought was a good way of describing it. Basically, in your design when\n> Alice wants to send a Taro token to Bob, Alice has to spend her own output,\n> make a new output for Bob, and make a change output for herself. Inside the\n> Taro tree you'll then point to the index of Bob's output in order to assign\n> the tokens to his new output. Instead of pointing to the index, you could\n> point to the outpoint (txid, index) of an existing UTXO owned by Bob, thus\n> \"teleporting\" the Taro tokens to this UTXO. This saves on-chain space, as\n> now you don't have to create a new output for Bob (but now you have to\n> ensure Bob doesn't spend from this output while you're simultaneously\n> sending tokens to it, as I mentioned in my previous post, as this would\n> destroy the tokens).\n>\n> The above also reminds me of another potential issue which you need to be\n> aware of, if you're not already. Similar to my comment about how the\n> location of the Taro tree inside the taproot tree needs to be deterministic\n> for the verifier, the output in which you place the Taro tree also needs to\n> be. If it's not, then you can commit to a different Taro tree in each\n> output of the transaction, allowing you to secretly fork the history.\n>\n> Hope this helps.\n>\n> Cheers,\n> Ruben\n>\n> [1] https://twitter.com/SomsenRuben/status/1397267261619064836\n> [2] https://twitter.com/SomsenRuben/status/1397559406565462017\n> [3] https://twitter.com/afilini/status/1397484341236797441\n>\n> On Fri, Apr 8, 2022 at 7:48 PM Olaoluwa Osuntokun <laolu32 at gmail.com>\n> wrote:\n>\n>> (this might be a double post as it ran into the size limit)\n>>\n>> Hi Ruben,\n>>\n>> Thanks! I don't really consider things final until we have a good set of\n>> test\n>> vectors in the final set, after which we'd start to transition the set of\n>> documents beyond the draft state.\n>>\n>> > Seeing as there's a large amount of overlap with RGB, a protocol which\n>> I have\n>> > examined quite extensively, I believe some of the issues I uncovered in\n>> that\n>> > project also apply here.\n>>\n>> I'm happy to hear that someone was actually able to extract enough\n>> details from\n>> the RGB devs/docs to be able to analyze it properly! In the past I tried\n>> to ask\n>> their developers questions about how things like transfers worked[1][2],\n>> but it\n>> seemed either people didn't know, or they hadn't finished the core design\n>> (large TBD sections) as they were working on adding other components to\n>> create\n>> a \"new new Internet\".\n>>\n>> > Furthermore, the Taro script is not enforced by Bitcoin, meaning those\n>> who\n>> > control the Bitcoin script can always choose to ignore the Taro script\n>> and\n>> > destroy the Taro assets as a result.\n>>\n>> This is correct, as a result in most contexts, an incentive exists for the\n>> holder of an asset to observe the Taro validation rules as otherwise,\n>> their\n>> assets are burnt in the process from the PoV of asset verifiers. In the\n>> single\n>> party case things are pretty straight forward, but more care needs to be\n>> taken\n>> in cases where one attempts to express partial application and permits\n>> anyone\n>> to spend a UTXO in question.\n>>\n>> By strongly binding all assets to Bitcoin UTXOs, we resolve issues\n>> related to\n>> double spending or duplicate assets, but needs to mind the fact that\n>> assets can\n>> be burnt if a user doesn't supply a valid witness. There're likely ways\n>> to get\n>> around this by lessening the binding to Bitcoin UTXO's, but then the\n>> system\n>> would need to be able to collect, retain and order all the set of possible\n>> spends, essentially requiring a parallel network. The core of the system\n>> as it\n>> stands today is pretty simple (which was an explicit design goal to avoid\n>> getting forever distracted by the large design space), with a minimal\n>> implementation being relatively compact given all the Bitcoin\n>> context/design\n>> re-use.\n>>\n>> Also one cool trait of the way commitments are designed is that the Taro\n>> commitment impact the final derived taproot output key. As a result,\n>> potential\n>> Script extensions like TAPLEAF_UPDATE_VERIFY can actually be used to\n>> further\n>> _bind_ Taro transitions at the Bitcoin level, without Bitcoin explicitly\n>> needing to be aware of the Taro rules. In short, covenants can allow\n>> Bitcoin\n>> Script to bind Taro state transitions, without any of the logic bleeding\n>> over,\n>> as the covenant just checks for a certain output key, which is a function\n>> of\n>> the Taro commitment being present.\n>>\n>> > There are two possible designs here: a.) The token history remains\n>> separate \u2013\n>> > Dave receives Alice's 2 tokens, Bob's tokens are split and he receives\n>> 2 (or\n>> > 3 from Bob 1 from Alice).  b.) The token history gets merged \u2013 Dave\n>> receives\n>> > 4 tokens (linking the new output with both Alice and Bob's history).\n>>\n>> Mechanically, with respect to the way the change/UTXOs work in the\n>> system, both\n>> are expressible: Dave can chose to merge them into a single UTXO (with the\n>> appropriate witnesses included for each of them), or Dave can keep them\n>> distinct in the asset tree. You're correct in that asset issuers may opt\n>> to\n>> issue assets in denominations vs allowing them to be fully divisible.\n>> Ultimately, the compatibility with the LN layer will be the primary way\n>> to keep\n>> asset histories compressed, without relying on another trust model, or\n>> relying\n>> on the incentive of an asset issuer to do a \"re-genesis\" which would\n>> effectively re-create assets in a supply-preserving manner (burn N units,\n>> then\n>> produce a new genesis outpoint for N units). Alternatively,\n>> implementations can\n>> also chose to utilize a checkpointing system similar to what some Bitcoin\n>> full\n>> node clients do today.\n>>\n>> >  is that you end up with a linked transaction graph, just like in\n>> Bitcoin\n>>\n>> This is correct, the protocol doesn't claim to achieve better privacy\n>> guarantees than the base chain. However inheriting this transaction graph\n>> model\n>> imo makes it easier for existing Bitcoin developers to interact with the\n>> system, and all the data structures are very familiar tooling wise.\n>> However any\n>> privacy enhancing protocol used for on-chain top-level Bitcoin UTXOs can\n>> also\n>> be applied to Taro, so people can use things like coinswap and coinjoin,\n>> along\n>> with LN to shed prior coin lineages.\n>>\n>> > This implies the location of the Taro tree inside the taproot tree is\n>> not\n>> > fixed. What needs to be prevented here is that a taproot tree contains\n>> more\n>> > than one Taro tree, as that would enable the owner of the commitment to\n>> show\n>> > different histories to different people.\n>>\n>> Great observation, I patched a similar issue much earlier in the design\n>> process\n>> by strongly binding all signatures to a prevOut super-set (so the outpoint\n>> along with the unique key apth down into the tree), which prevents\n>> duplicating\n>> the asset across outputs, as signature verification would fail.\n>>\n>> In terms of achieving this level of binding within the Taro tree itself,\n>> I can\n>> think of three options:\n>>\n>>   1. Require the Taro commitment to be in the first/last position within\n>> the\n>>   (fully sorted?) Tapscript tree, and also require its sibling to be the\n>> hash\n>>   of some set string (all zeroes or w/e). We'd require the sibling to the\n>> empty\n>>   as the tapscript hashes are sorted before hashing so you sort of lose\n>> that\n>>   final ordering information.\n>>\n>>   2. Include the position of the Taro commitment within the tapscript tree\n>>   within the sighash digest (basically the way the single input in the\n>> virtual\n>>   transaction is created from the TLV structure).\n>>\n>>   3. Include the position of the Taro commitment within the tapscript\n>> tree as\n>>   part of the message that's hashed to derive asset IDs.\n>>\n>> AFAICT, #1 resolves the issue entirely, #2 renders transfers outside of\n>> the\n>> canonical history invalid, and #2 minds hte asset ID to the initial\n>> position\n>> meaning you can track a canonical lineage from the very start.\n>>\n>> > Finally, let me conclude with two questions. Could you clarify the\n>> purpose of\n>> > the sparse merkle tree in your design?\n>>\n>> Sure, it does a few things:\n>>\n>>   * Non-inclusion proofs so I can do things like prove to your I'm no\n>> longer\n>>     committing to my 1-of-1 holographic beefzard card when we swap.\n>>\n>>   * The key/tree structure means that the tree is history independent,\n>> meaning\n>>     that if you and I insert the same things into the tree in a different\n>>     order, we'll get the same root hash. This is useful for things like\n>>     tracking all the issuance events for a given asset, or allowing two\n>>     entities to sync their knowledge/history of a single asset, or a set\n>> of\n>>     assets.\n>>\n>>   * Each asset/script mapping to a unique location within the tree means\n>> it's\n>>     easy to ensure uniqueness of certain items/commitments (not possible\n>> to\n>>     commit to the same asset ID twice in the tree as an example).\n>>\n>>   * The merkle-sum trait means I that validation is made simpler, as you\n>> just\n>>     check that the input+output commitment sum to the same value, and I\n>> can\n>>     also verify that if we're swapping, then you aren't committing to more\n>>     units that exist (so I make sure I don't get an invalid split).\n>>\n>> > And the second question \u2013 when transferring Taro token ownership from\n>> one\n>> > Bitcoin UTXO to another, do you generate a new UTXO for the recipient\n>> or do\n>> > you support the ability to \"teleport\" the tokens to an existing UTXO\n>> like how\n>> > RGB does it? If the latter, have you given consideration to timing\n>> issues\n>> > that might occur when someone sends tokens to an existing UTXO that\n>> > simultaneously happens to get spent by the owner?\n>>\n>> So for interactive transfers, the UTXOs generated as just the ones part\n>> of the\n>> MIMO transaction. When sending via the address format, a new non-dust\n>> output is\n>> created which holds the new commitment, and uses an internal key provided\n>> by\n>> the receiver, so only they can move the UTXO. Admittedly, I'm not\n>> familiar with\n>> how the RGB \"teleport\" technique works, I checked out some slide decks a\n>> while\n>> back, but they were mostly about all the new components they were\n>> creating and\n>> their milestone of 1 million lines of code. Can you point me to a coherent\n>> explanation of the technique? I'd love to compare/contrast so we can\n>> analyze\n>> the diff tradeoffs being made here.\n>>\n>> Thanks for an initial round of feedback/analysis, I'll be updating the\n>> draft\n>> over the next few days to better spell things out and particularly that\n>> commitment/sighash uniqueness trait.\n>>\n>> -- Laolu\n>>\n>> [1]:\n>> https://twitter.com/roasbeef/status/1330654936074371073?s=20&t=feV0kWAjJ6MTQlFm06tSxA\n>> [2]:\n>> https://twitter.com/roasbeef/status/1330692571736117249?s=20&t=feV0kWAjJ6MTQlFm06tSxA\n>>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221103/a53b523d/attachment-0001.html>"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2022-11-05T00:35:53",
                "message_text_only": "Hi Johan,\n\nI haven't really been able to find a precise technical explanation of the\n\"utxo teleport\" scheme, but after thinking about your example use cases a\nbit, I don't think the scheme is actually sound. Consider that the scheme\nattempts to target transmitting \"ownership\" to a UTXO. However, by the time\nthat transaction hits the chain, the UTXO may no longer exist. At that\npoint, what happens to the asset? Is it burned? Can you retry it again? Does\nit go back to the sender?\n\nAs a concrete example, imagine I have a channel open, and give you an\naddress to \"teleport\" some additional assets to it. You take that addr, then\nmake a transaction to commit to the transfer. However, the block before you\ncommit to the transfer, my channel closes for w/e reason. As a result, when\nthe transaction committing to the UTXO (blinded or not), hits the chain, the\nUTXO no longer exists. Alternatively, imagine the things happen in the\nexpected order, but then a re-org occurs, and my channel close is mined in a\nblock before the transfer. Ultimately, as a normal Bitcoin transaction isn't\nused as a serialization point, the scheme seems to lack a necessary total\nordering to ensure safety.\n\nIf we look at Taro's state transition model in contrast, everything is fully\nbound to a single synchronization point: a normal Bitcoin transaction with\ninputs consumed and outputs created. All transfers, just like Bitcoin\ntransactions, end up consuming assets from the set of inputs, and\nre-creating them with a different distribution with the set of outputs. As a\nresult, Taro transfers inherit the same re-org safety traits as regular\nBitcoin transactions. It also isn't possible to send to something that won't\nultimately exist, as sends create new outputs just like Bitcoin\ntransactions.\n\nTaro's state transition model also means anything you can do today with\nBitcoin/LN also apply. As an example, it would be possible for you to\nwithdrawn from your exchange into a Loop In address (on chain to off chain\nswap), and have everything work as expected, with you topping off your\nchannel. Stuff like splicing, and other interactive transaction construction\nschemes (atomic swaps, MIMO swaps, on chain auctions, etc) also just work.\n\nIgnoring the ordering issue I mentioned above, I don't think this is a great\nmodel for anchoring assets in channels either. With Taro, when you make the\nchannel, you know how many assets are committed since they're all committed\nto in the funding output when the channel is created. However, let's say we\ndo teleporting instead: at which point would we recognize the new asset\n\"deposits\"? What if we close before a pending deposits confirms, how can one\nregain those funds? Once again you lose the serialization of events/actions\nthe blockchain provides. I think you'd also run into similar issues when you\nstart to think about how these would even be advertised on a hypothetical\ngossip network.\n\nI think one other drawback of the teleport model iiuc is that: it either\nrequires an OP_RETURN, or additional out of band synchronization to complete\nthe transfer. Since it needs to commit to w/e hash description of the\nteleport, it either needs to use an OP_RETURN (so the receiver can see the\non chain action), or the sender needs to contact the receiver to initiate\nthe resolution of the transfer (details committed to in a change addr or\nw/e).\n\nWith Taro, sending to an address creates an on-chain taproot output just\nlike sending to a P2TR address. The creation of the output directly creates\nthe new asset anchor/output as well, which allows the receiver to look for\nthat address on chain just like a normal on chain transaction. To 3rd party\nobservers, it just looks like a normal P2TR transfer. In order to finalize\nthe receipt of the asset, the receiver needs to obtain the relevant\nprovenance proofs, which can be obtained from a multi-verse gRPC/HTTP\nservice keyed by the input outpoint and output index. In short, the send\nprocess is fully async, with the sender and receiver using the blockchain\nitself as a synchronization point like a normal Bitcoin wallet.\n\n-- Laolu\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221104/354c256b/attachment.html>"
            },
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2022-11-07T13:51:12",
                "message_text_only": "Hi Laolu,\n\nYeah, that is definitely the main downside, as Ruben also mentioned:\ntokens are \"burned\" if they get sent to an already spent UTXO, and\nthere is no way to block those transfers.\n\nAnd I do agree with your concern about losing the blockchain as the\nmain synchronization point, that seems indeed to be a prerequisite for\nmaking the scheme safe in terms of re-orgs and asynchronicity.\n\nI do think the scheme itself is sound though (maybe not off-chain, see\nbelow): it prevents double spending and as long as the clients adhere\nto the \"rule\" of not sending to a spent UTXO you'll be fine (if not\nyour tokens will be burned, the same way as if you don't satisfy the\nTaro script when spending).\n\nThinking more about the examples you gave, I think you are right it\nwon't easily be compatible with LN channels though:\nIf you want to refill an existing channel with tokens, you need the\nchannel counterparties to start signing new commitments that include\nspending the newly sent tokens. A problem arises however, if the\nchannel is force-closed with a pre-existing commitment from before the\ntoken transfer took place. Since this commitment will be spending the\nfunding UTXO, but not the new tokens, the tokens will be burned. And\nthat seems to be harder to deal with (Eltoo style channels could be an\navenue to explore, if one could override the broadcasted commitment).\n\nTl;dr: I think you're right, the scheme is not compatible with LN.\n\n- Johan\n\n\nOn Sat, Nov 5, 2022 at 1:36 AM Olaoluwa Osuntokun <laolu32 at gmail.com> wrote:\n>\n> Hi Johan,\n>\n> I haven't really been able to find a precise technical explanation of the\n> \"utxo teleport\" scheme, but after thinking about your example use cases a\n> bit, I don't think the scheme is actually sound. Consider that the scheme\n> attempts to target transmitting \"ownership\" to a UTXO. However, by the time\n> that transaction hits the chain, the UTXO may no longer exist. At that\n> point, what happens to the asset? Is it burned? Can you retry it again? Does\n> it go back to the sender?\n>\n> As a concrete example, imagine I have a channel open, and give you an\n> address to \"teleport\" some additional assets to it. You take that addr, then\n> make a transaction to commit to the transfer. However, the block before you\n> commit to the transfer, my channel closes for w/e reason. As a result, when\n> the transaction committing to the UTXO (blinded or not), hits the chain, the\n> UTXO no longer exists. Alternatively, imagine the things happen in the\n> expected order, but then a re-org occurs, and my channel close is mined in a\n> block before the transfer. Ultimately, as a normal Bitcoin transaction isn't\n> used as a serialization point, the scheme seems to lack a necessary total\n> ordering to ensure safety.\n>\n> If we look at Taro's state transition model in contrast, everything is fully\n> bound to a single synchronization point: a normal Bitcoin transaction with\n> inputs consumed and outputs created. All transfers, just like Bitcoin\n> transactions, end up consuming assets from the set of inputs, and\n> re-creating them with a different distribution with the set of outputs. As a\n> result, Taro transfers inherit the same re-org safety traits as regular\n> Bitcoin transactions. It also isn't possible to send to something that won't\n> ultimately exist, as sends create new outputs just like Bitcoin\n> transactions.\n>\n> Taro's state transition model also means anything you can do today with\n> Bitcoin/LN also apply. As an example, it would be possible for you to\n> withdrawn from your exchange into a Loop In address (on chain to off chain\n> swap), and have everything work as expected, with you topping off your\n> channel. Stuff like splicing, and other interactive transaction construction\n> schemes (atomic swaps, MIMO swaps, on chain auctions, etc) also just work.\n>\n> Ignoring the ordering issue I mentioned above, I don't think this is a great\n> model for anchoring assets in channels either. With Taro, when you make the\n> channel, you know how many assets are committed since they're all committed\n> to in the funding output when the channel is created. However, let's say we\n> do teleporting instead: at which point would we recognize the new asset\n> \"deposits\"? What if we close before a pending deposits confirms, how can one\n> regain those funds? Once again you lose the serialization of events/actions\n> the blockchain provides. I think you'd also run into similar issues when you\n> start to think about how these would even be advertised on a hypothetical\n> gossip network.\n>\n> I think one other drawback of the teleport model iiuc is that: it either\n> requires an OP_RETURN, or additional out of band synchronization to complete\n> the transfer. Since it needs to commit to w/e hash description of the\n> teleport, it either needs to use an OP_RETURN (so the receiver can see the\n> on chain action), or the sender needs to contact the receiver to initiate\n> the resolution of the transfer (details committed to in a change addr or\n> w/e).\n>\n> With Taro, sending to an address creates an on-chain taproot output just\n> like sending to a P2TR address. The creation of the output directly creates\n> the new asset anchor/output as well, which allows the receiver to look for\n> that address on chain just like a normal on chain transaction. To 3rd party\n> observers, it just looks like a normal P2TR transfer. In order to finalize\n> the receipt of the asset, the receiver needs to obtain the relevant\n> provenance proofs, which can be obtained from a multi-verse gRPC/HTTP\n> service keyed by the input outpoint and output index. In short, the send\n> process is fully async, with the sender and receiver using the blockchain\n> itself as a synchronization point like a normal Bitcoin wallet.\n>\n> -- Laolu"
            }
        ],
        "thread_summary": {
            "title": "Taro: A Taproot Asset Representation Overlay",
            "categories": [
                "bitcoin-dev",
                "Lightning-dev"
            ],
            "authors": [
                "Olaoluwa Osuntokun",
                "Johan Tor\u00e5s Halseth"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 26116
        }
    },
    {
        "title": "[bitcoin-dev] MuSig2 BIP",
        "thread_messages": [
            {
                "author": "Jonas Nick",
                "date": "2022-11-03T14:43:22",
                "message_text_only": "We updated the MuSig2 BIP draft to fix the vulnerability published in an earlier\npost [0].\n\nWe also wrote an article [1] that contains a description of\n1. the vulnerable scheme (remember that the original MuSig2 scheme is not\n    vulnerable because it doesn't allow tweaking)\n2. an attack against the vulnerable scheme using Wagner's algorithm\n3. a fixed scheme that permits tweaking\n\nMoreover, we implemented the \"BLLOR\" attack mentioned in the article which\nworks against the reference python implementation of the previous version of the\nMuSig2 BIP draft (takes about 7 minutes on my machine) [2].\n\nThe fix of the MuSig2 BIP is equivalent to the fix of the scheme in the article\n[1]: before calling ''NonceGen'', the signer must determine the (potentially\ntweaked) secret key it will use for this signature. BIP MuSig2 now ensures that\nusers can not accidentally violate this requirement by adding a mandatory public\nkey argument to ''NonceGen'', appending the public key to the ''secnonce'' array\nand checking the public key against the secret key in ''Sign'' (see the pull\nrequest for the detailed changes [3]).\n\n[0] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-October/021000.html\n[1] https://github.com/jonasnick/musig2-tweaking\n[2] https://gist.github.com/robot-dreams/89ce8c3ff16f70cb2c55ba4fe9fd1b31 (must\n     be copied into the bip-musig2 directory)\n[3] https://github.com/jonasnick/bips/pull/74"
            }
        ],
        "thread_summary": {
            "title": "MuSig2 BIP",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jonas Nick"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1423
        }
    },
    {
        "title": "[bitcoin-dev] Refreshed BIP324",
        "thread_messages": [
            {
                "author": "Murch",
                "date": "2022-11-03T17:53:26",
                "message_text_only": "Hi Pieter, hello list,\n\nOn 26.10.22 12:39, Pieter Wuille via bitcoin-dev wrote:\n> 1. The most straightforward solution is using the BIP process as-is: let BIP324\n>     introduce a fixed initial table, and future BIPs which introduce new\n>     messages can introduce new mapping entries for it. In theory, this is no\n>     worse than the current coordination difficulty about command strings, but\n>     in practice the risk of collisions due to competing proposals is of course\n>     significantly larger with 1-byte IDs vs. 12-byte strings.\n\n From what I understand we'll have about 35 message types on the network \nwith the addition of BIP324. 256 possible IDs sounds like plenty room to \ngrow, but perhaps we can be a bit more conservative:\n\nWe could use the first bit to signal a 2-byte message ID. That allows us \nto express 128 IDs with 1 byte, but if we need more, we get a total of \n2^15 IDs across 2 bytes.\n\nI would not be too concerned about collisions. Firstly, message types \nwould probably be announced to the mailing list as part of the \ncorresponding BIP, secondly, any overlooked collision should become \napparent at implementation time. The risk could perhaps be further \nmitigated by encouraging less prevalent message types to use a 2-byte ID.\n\nCheers,\nMurch\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: OpenPGP_signature\nType: application/pgp-signature\nSize: 833 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221103/fa31bbc7/attachment.sig>"
            },
            {
                "author": "Jonas Schnelli",
                "date": "2022-11-03T22:26:54",
                "message_text_only": "> From what I understand we'll have about 35 message types on the network with the addition of BIP324. 256 possible IDs sounds like plenty room to grow, but perhaps we can be a bit more conservative:\n> \n> We could use the first bit to signal a 2-byte message ID. That allows us to express 128 IDs with 1 byte, but if we need more, we get a total of 2^15 IDs across 2 bytes.\n\nCould make sense.\n\nThere would be an alternative to preserve more 1 byte IDs on the cost of a (much) smaller 2 byte ID space:\nReserve the short ID 0xFF as an indication for a 2 bytes short ID (additional 256 short IDs with 2 bytes).\nThat could be done later outside BIP324.\nThe 0xFF approach would lead to approx. 207 unused 1 byte short IDs (while Murchs approach would give us approx. 79 unused 1 byte short IDs).\nThe signal bit two byte approach would however lead to ~32k more two byte message IDs.\n\nThe main (and only?) benefit of short IDs is bandwidth.\nShort ID 1-12 are reserved for string based IDs and thus, new and rarely sent message types must not always use a short ID.\n\nMaybe the BIP should state that only frequent sent messages should reserve a short ID, though, the BIP itself assigns short IDs to all(?) message types (including low frequent messages like SENDHEADERS).\n\nMaybe exclude message types that expected to be only sent once from assigning a short ID?\n\n/j"
            },
            {
                "author": "Anthony Towns",
                "date": "2022-11-08T03:20:23",
                "message_text_only": "On Wed, Oct 26, 2022 at 04:39:02PM +0000, Pieter Wuille via bitcoin-dev wrote:\n> However, it obviously raises the question of how the mapping table between the\n> 1-byte IDs and the commands they represent should be maintained:\n> \n> 1. The most straightforward solution is using the BIP process as-is: let BIP324\n>    introduce a fixed initial table, and future BIPs which introduce new\n>    messages can introduce new mapping entries for it. [...]\n\n> 3. Yet another possibility is not having a fixed table at all, and negotiate\n>    the mapping dynamically. E.g. either side could send a message at\n>    connection time with an explicit table of entries \"when I send byte X, I\n>    mean command Y\".\n\nFWIW, I think these two options seem fine -- maintaining a purely local\nand hardcoded internal mapping of \"message string C has id Y\" where Y\nis capped by the number of commands you actually implement (presumably\nless than 65536 total) is easy, and providing a per-peer mapping from\n\"byte X\" to \"id Y\" then requires at most 512 bytes per peer, along with\nup to 3kB of initial setup to tell your peer what mappings you'll use.\n\n> Our idea is to start out with approach (1), with a mapping table effectively\n> managed by the BIP process directly, but if and when collisions become a\n> concern (maybe due to many parallel proposals, maybe because the number of\n> messages just grows too big), switch to approach (3), possibly even\n> differentially (the sent mappings are just additions/overwrites of the\n> BIP-defined table mappings, rather than a full mapping).\n\nI guess I think it would make sense to not start using a novel 1-byte\nmessage unless you've done something to introduce that message first;\nwhether that's via approach (3) (\"I'm going to use 0xE9 to mean pkgtxns\")\nor via a multibyte feature support message (\"I sent sendaddrv3 as a\n10-byte message, that implies 0xA3 means addrv3 from now on\").\n\nI do still think it'd be better to recommend against reserving a byte for\none-shot messages, and not do it for existing one-shot messages though.\n\nCheers,\naj"
            },
            {
                "author": "Pieter Wuille",
                "date": "2022-11-10T21:23:44",
                "message_text_only": "Hi,\n\nThanks for the comments so far. I think these are all reasonable ideas.\nComments inline below.\n\nOn Thursday, November 3rd, 2022 at 1:53 PM, Murch wrote:\n\n> From what I understand we'll have about 35 message types on the network\n> with the addition of BIP324. 256 possible IDs sounds like plenty room to\n> grow, but perhaps we can be a bit more conservative:\n> \n> We could use the first bit to signal a 2-byte message ID. That allows us\n> to express 128 IDs with 1 byte, but if we need more, we get a total of\n> 2^15 IDs across 2 bytes.\n\nYeah, effectively treating the first 1 or 2 bytes as a simple variable\nlength integer is a nice way of increasing the space at low cost.\n\nThis also doesn't need to be decided now. The initial approach could just\nbe avoiding allocating bytes in the 128-255 range until the need for more\nspace arises. If and when that is the case, the choice could be to:\n* Just continue treating the first byte as the command.\n* Start treating the first upper bit as a sign that another command byte\n  follows.\n* Switch to some form of explicit signalling (option 3 is my earlier\n  mail).\n\nOn Thursday, November 3rd, 2022 at 6:26 PM, Jonas Schnelli wrote:\n\n> There would be an alternative to preserve more 1 byte IDs on the cost\n> of a (much) smaller 2 byte ID space: Reserve the short ID 0xFF as an\n> indication for a 2 bytes short ID (additional 256 short IDs with 2 bytes).\n\nI don't think this is needed, because we arguably already have that! If the\nfirst byte is 0x01, then 1 more command byte follows in the current BIP324\ndraft. That mechanism is designed for alphabetic 1-character commands, but\nnothing prevents it from also being used for other things (by using a\nnon-alphabetic byte there).\n\n> Maybe the BIP should state that only frequent sent messages should reserve\n> a short ID, though, the BIP itself assigns short IDs to all(?) message\n> types (including low frequent messages like SENDHEADERS).\n> \n> Maybe exclude message types that expected to be only sent once from\n> assigning a short ID?\n\nI think that makes sense. Especially in combination with the idea avoiding\nbytes with the upper bit set there is a bit more pressure on the 1-byte\nspace. Rarely-sent or at-most-once-sent commands don't really provide much\nbenefit. I'd suggest scrapping from the list:\n* Version messages: version, verack\n* Negotiation messages: sendaddrv2, sendheaders, sendcmpct, wtxidrelay\n* Rarely-sent messages: mempool\n\nI'm not sure to what extent filteradd/filterload/filterclear/merkleblock\nare still actually used; perhaps they could be removed too?\n\nOn Monday, November 7th, 2022 at 10:20 PM, Anthony Towns wrote:\n\n> I guess I think it would make sense to not start using a novel 1-byte\n> message unless you've done something to introduce that message first;\n> whether that's via approach (3) (\"I'm going to use 0xE9 to mean pkgtxns\")\n> or via a multibyte feature support message (\"I sent sendaddrv3 as a\n> 10-byte message, that implies 0xA3 means addrv3 from now on\").\n\nThat's fair, but I don't think it matters too much for allocation purposes;\nprotocol designs should still not assign overlapping values, unless the\nprotocols are known to never be used simultaneously?\n\nUnless... the assignment works like \"whenever the sendaddrv3 is sent, the\nnext available byte in range 48..127 gets allocated for addrv3\". That means\nno explicit mapping is needed, as long as the total number of messages from\nsimultaneously-active extensions isn't too large.\n\n> I do still think it'd be better to recommend against reserving a byte for\n> one-shot messages, and not do it for existing one-shot messages though.\n\nAgree.\n\nFWIW, if anyone was wondering about how much is actually saved by having\n1-byte commands vs 12-byte commands, I've gathered statistics from two nodes\n(one with many inbound connections, one only outbound) for two weeks. This is\nobviously very dependent on network topology and local implementation choices,\nbut it may still give an idea:\n* Outbound-only node:\n  * Around 4.5% of sent bytes are bytes 2-12 of the command.\n  * Sent 979.98 MiB in total.\n* Outbound and inbound node:\n  * Around 1.6% of sent bytes are bytes 2-12 of the command.\n  * Sent 124.14 GiB in total.\n\nCheers,\n\n-- \nPieter"
            },
            {
                "author": "Pieter Wuille",
                "date": "2022-11-12T03:23:16",
                "message_text_only": "Another idea...\n\nOn Thursday, November 10th, 2022 at 4:23 PM, Pieter Wuille via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Thursday, November 3rd, 2022 at 1:53 PM, Murch wrote:\n> \n> > From what I understand we'll have about 35 message types on the network\n> > with the addition of BIP324. 256 possible IDs sounds like plenty room to\n> > grow, but perhaps we can be a bit more conservative:\n> > \n> > We could use the first bit to signal a 2-byte message ID. That allows us\n> > to express 128 IDs with 1 byte, but if we need more, we get a total of\n> > 2^15 IDs across 2 bytes.\n> \n> Yeah, effectively treating the first 1 or 2 bytes as a simple variable\n> length integer is a nice way of increasing the space at low cost.\n\nThe above would really result in having two separate variable-length encodings:\n* First byte 1-12 to signify length of alphabetic command\n* Otherwise first bit to signify length of short command\n\nI think we can just merge the two and have a single variable-length command structure that can be used for both: command encodings are 1 to 12 bytes, each byte's top bit indicating whether another byte follows (the top bit of byte 11 has no special meaning).\n\nThis means:\n* Every alphabetic command of L characters becomes L bytes.\n* 102 non-alphabetic 1-byte commands can be assigned.\n* 15708 non-alphabetic 2-byte commands can be assigned.\n* etc\n\nSo this gives a uniform space which commands can be assigned from, and there is no strict need for thinking of the short-binary and long-alphabetic commands as distinct. In v2, some short ones would be treated as aliases for old long-alphabetic ones. But new commands could also just be introduced as short ones only (even in v1).\n\nWDYT?\n\nCheers,\n\n-- \nPieter"
            },
            {
                "author": "Yuval Kogman",
                "date": "2022-11-12T18:52:31",
                "message_text_only": "On Sat, 12 Nov 2022, 11:01 Pieter Wuille via bitcoin-dev, <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I think we can just merge the two and have a single variable-length\n> command structure that can be used for both: command encodings are 1 to 12\n> bytes, each byte's top bit indicating whether another byte follows (the top\n> bit of byte 11 has no special meaning).\n>\n...\n\n> So this gives a uniform space which commands can be assigned from, and\n> there is no strict need for thinking of the short-binary and\n> long-alphabetic commands as distinct.In v2, some short ones would be\n> treated as aliases for old long-alphabetic ones.\n\n\nThis seems a bit dubious, but since command names are ASCII strings\nreversing the meaning of the top bit so that 0 signifies a following byte\nwould allow the alphabetic commands to be reinterpreted as non-alphabetic,\nso the space no longer needs to be a disjoint union of two sub-spaces which\narguably takes the \"no [...] need for thinking of [them] as distinct\" logic\na little bit bit farther.\n\nThe main downsides are that this does nothing to re-assign shorter codes to\nexisting commands, and secondly that even the non-alphabetic code path\ncompletely supersedes the alphabetic one, the numerical values are up to 85\nor 86 bits wide, which is not a reasonable word size. Perhaps this is not a\nconcern since as far as I know there are no collisions in the first 9 bytes\nof existing commands, and constrain the non-alphabetic representation to 9\nbytes would leave the last top bit free, so the space would be isomorphic\nto {0,1}^64.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221112/f00d8cfd/attachment-0001.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2022-11-18T08:24:49",
                "message_text_only": "On Sat, Nov 12, 2022 at 03:23:16AM +0000, Pieter Wuille via bitcoin-dev wrote:\n> Another idea...\n\n> This means:\n> * Every alphabetic command of L characters becomes L bytes.\n> * 102 non-alphabetic 1-byte commands can be assigned.\n> * 15708 non-alphabetic 2-byte commands can be assigned.\n\n(There are 128**L possible L-byte commands, 26**L alphabetic L-byte\ncommands, and hence 128**L-26**L non-alphabetical L-byte commands)\n\n> * etc\n> So this gives a uniform space which commands can be assigned from, and there is no strict need for thinking of the short-binary and long-alphabetic commands as distinct. In v2, some short ones would be treated as aliases for old long-alphabetic ones. But new commands could also just be introduced as short ones only (even in v1).\n\nIsn't that optimising for the wrong thing? Aren't the goals we want:\n\n 1) it should be easy to come up with a message identifier without\n    accidently conflicting with someone else's proposal\n\n 2) commonly used messages on the wire should have a short encoding\n    in order to save bandwidth\n\nDepending on how much the p2p protocol ossifies, which messages are\n\"commonly used on the wire\" might be expected to change; and picking an\notherwise meaningless value from a set of 102 elements seems likely to\nproduce conflicts...\n\nDoing:\n\n  -> VERSION\n  <- VERSION\n  <- SHORTMSG [\"BIP324\", \"foo.org/experiment\"]\n  <- VERACK\n  -> SHORTMSG [\"BIP324\"]\n  -> VERACK\n  -> SENDSHORTMSG \"BIP324\" [(13, \"ADDRV3\")]\n  <- SENDSHORTMSG \"BIP324\"\n  -> 34 (SENDHEADERS)\n  -> 25 (GETHEADERS)\n  ...\n\nwhere \"SHORTMSG\" lets you specify an array of tables you support (such as\nBIP324's), and, once you know both sides supports a table, you can send\n`SENDSHORTMSG` to choose the table you'll use to abbreviate messages\nyou send, as well as any modifications to that table (like replacing\nADDR with ADDRV3).\n\nThen when writing BIPs, you just choose a meaningful string (\"ADDRV3\"),\nand when implementing you send a one-time \"SENDSHORTMSG\" message to\noptimise the messages you'll send most often... As time goes on and the\nmost common messages change, issue a new BIP with a new table so that\nyour one-time SHORTIDs message becomes shorter too, at least when you\nconnect to peers that also know about the new bip..\n\nCould potentially support that without bip324, by taking over the one\nbyte message space, presuming you don't have any one-character messages\nyou actually want to send?\n\nCould do this /as well as/ the encoding above, I guess; then you would\nhave bips specify alphabetic message ids, and use SENDSHORTMSG to\ndynamically (and sequentially) override/allocate non-alphabetic ids?\nThat would presumably limit the number of non-alphabetic ids to how\nmany you could specify in a single SENDSHORTIDs message, which I think\nwould be up to something like 749k different 1/2/3/4/5/6-byte alphabetic\nmessage ids (encoded as 1/2/3-byte non-alphabetic messages). Probably\nsome more specific limit would be better though.\n\nCheers,\naj"
            }
        ],
        "thread_summary": {
            "title": "Refreshed BIP324",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Murch",
                "Anthony Towns",
                "Yuval Kogman",
                "Pieter Wuille",
                "Jonas Schnelli"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 15700
        }
    },
    {
        "title": "[bitcoin-dev] Generate and verify ECDSA signature without \"r\"",
        "thread_messages": [
            {
                "author": "MC 5760",
                "date": "2022-11-05T08:46:15",
                "message_text_only": "1. Address: private key -> ECC -> public key compression -> Bech32m encode\n\n2. scriptPubkey: Address -> Bech32m decode -> public key compression\n\n3. Segwit: (dsha256(txid_input & index) * x public key + dsha256(unsigned\nraw transaction) mod (private key)) mod (N) => Will give a number of 32\nbytes\n\n4. Verify:\n\nx1, y1 = ECC(G, dsha256(txid_input & index))\n\np1 = ECC(G, dsha256(unsigned raw transaction) mod (Segwit))\n\np2 = ECC((x1,y1) * x public key mod (Segwit)\n\nx2, y2 = ECAddpoint(p1, p2)\n\nIf x2 = x public key => OK\n\nI wrote the python code here:\nhttps://github.com/tanvovan/bitcoin/blob/main/p2pc.py\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221105/52e4aa8f/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Generate and verify ECDSA signature without \"r\"",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "MC 5760"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 787
        }
    },
    {
        "title": "[bitcoin-dev] Removing BIP-125 Rule #5 Pinning with the Always-Replaceable Invariant",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2022-11-07T20:17:29",
                "message_text_only": "tl;dr: We can remove the problem of Rule #5 pinning by ensuring that all\ntransactions in the mempool are always replaceable.\n\n\nCurrently Bitcoin Core implements rule #5 of BIP-125:\n\n    The number of original transactions to be replaced and their descendant\n    transactions which will be evicted from the mempool must not exceed a total\n    of 100 transactions.\n\nAs of Bitcoin Core v24.0rc3, this rule is implemented via the\nMAX_REPLACEMENT_CANDIDATES limit in GetEntriesForConflicts:\n\n    // Rule #5: don't consider replacing more than MAX_REPLACEMENT_CANDIDATES\n    // entries from the mempool. This potentially overestimates the number of actual\n    // descendants (i.e. if multiple conflicts share a descendant, it will be counted multiple\n    // times), but we just want to be conservative to avoid doing too much work.\n    if (nConflictingCount > MAX_REPLACEMENT_CANDIDATES) {\n        return strprintf(\"rejecting replacement %s; too many potential replacements (%d > %d)\\n\",\n                         txid.ToString(),\n                         nConflictingCount,\n                         MAX_REPLACEMENT_CANDIDATES);\n    }\n\nThere is no justification for this rule beyond avoiding \"too much work\"; the\nexact number was picked at random when the BIP was written to provide an\ninitial conservative limit, and is not justified by benchmarks or memory usage\ncalculations. It may in fact be the case that this rule can be removed entirely\nas the overall mempool size limits naturally limit the maximum number of\npossible replacements.\n\n\nBut for the sake of argument, let's suppose some kind of max replacement limit\nis required. Can we avoid rule #5 pinning? The answer is yes, we can, with the\nfollowing invariant:\n\n    No transaction may be accepted into the mempool that would cause another\n    transaction to be unable to be replaced due to Rule #5.\n\nWe'll call this the Replaceability Invariant. Implementing this rule is simple:\nfor each transaction maintain an integer, nReplacementCandidates. When a\nnon-conflicting transaction is considered for acceptance to the mempool, verify\nthat nReplacementCandidates + 1 < MAX_REPLACEMENT_CANDIDATES for each\nunconfirmed parent. When a transaction is accepted, increment\nnReplacementCandidates by 1 for each unconfirmed parent.\n\nWhen a *conflicting* transaction is considered for acceptance, we do _not_ need\nto verify anything: we've already guaranteed that every transaction in the\nmempool is replaceable! The only thing we may need to do is to decrement\nnReplacementCandidates by however many children we have replaced, for all\nunconfirmed parents.\n\nWhen a block is mined, note how the nReplacementCandidates of all unconfirmed\ntransactions remains unchanged because a confirmed transaction can't spend an\nunconfirmed txout.\n\nThe only special case to handle is a reorg that changes a transaction from\nconfirmed to unconfirmed. Setting nReplacementCandidates to\nMAX_REPLACEMENT_CANDIDATES would be fine in that very rare case.\n\n\nNote that like the existing MAX_REPLACEMENT_CANDIDATES check, the\nReplaceability Invariant overestimates the number of transactions to be\nreplaced in the event that multiple children are spent by the same transaction.\nThat's ok: diamond tx graphs are even more unusual than unconfirmed children,\nand there's no reason to bend over backwards to accomodate them.\n\nPrior art: this proposed rule is similar in spirit to the package limits aready\nimplemented in Bitcoin Core.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221107/536f252f/attachment-0001.sig>"
            },
            {
                "author": "Suhas Daftuar",
                "date": "2022-11-07T21:21:11",
                "message_text_only": "Hello bitcoin-dev,\n\nThe description in the OP is completely broken for the simple reason that\nBitcoin transactions can have multiple inputs, and so a single transaction\ncan conflict with multiple in-mempool transactions. The proposal would\nlimit the number of descendants of each in-mempool transaction to\nMAX_REPLACEMENT_CANDIDATES (note that this is duplicative of the existing\nBitcoin Core descendant limits), but a transaction that has, say, 500\ninputs might arrive and conflict with 500 unrelated in-mempool\ntransactions. This could result in 12,500 evictions -- far more than the\n100 that was intended.\n\nAlso, note that those 500 transactions might instead have 24 ancestors each\n(again, using the default chain limits in Bitcoin Core) -- this would\nresult in 12,000 transactions whose state would be updated as a result of\nevicting those 500 transactions. Hopefully this gives some perspective on\nwhy we have a limit.\n\n\nOn Mon, Nov 7, 2022 at 3:17 PM Peter Todd via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> tl;dr: We can remove the problem of Rule #5 pinning by ensuring that all\n> transactions in the mempool are always replaceable.\n>\n>\n> Currently Bitcoin Core implements rule #5 of BIP-125:\n>\n>     The number of original transactions to be replaced and their descendant\n>     transactions which will be evicted from the mempool must not exceed a\n> total\n>     of 100 transactions.\n>\n> As of Bitcoin Core v24.0rc3, this rule is implemented via the\n> MAX_REPLACEMENT_CANDIDATES limit in GetEntriesForConflicts:\n>\n>     // Rule #5: don't consider replacing more than\n> MAX_REPLACEMENT_CANDIDATES\n>     // entries from the mempool. This potentially overestimates the number\n> of actual\n>     // descendants (i.e. if multiple conflicts share a descendant, it will\n> be counted multiple\n>     // times), but we just want to be conservative to avoid doing too much\n> work.\n>     if (nConflictingCount > MAX_REPLACEMENT_CANDIDATES) {\n>         return strprintf(\"rejecting replacement %s; too many potential\n> replacements (%d > %d)\\n\",\n>                          txid.ToString(),\n>                          nConflictingCount,\n>                          MAX_REPLACEMENT_CANDIDATES);\n>     }\n>\n> There is no justification for this rule beyond avoiding \"too much work\";\n> the\n> exact number was picked at random when the BIP was written to provide an\n> initial conservative limit, and is not justified by benchmarks or memory\n> usage\n> calculations. It may in fact be the case that this rule can be removed\n> entirely\n> as the overall mempool size limits naturally limit the maximum number of\n> possible replacements.\n>\n>\n> But for the sake of argument, let's suppose some kind of max replacement\n> limit\n> is required. Can we avoid rule #5 pinning? The answer is yes, we can, with\n> the\n> following invariant:\n>\n>     No transaction may be accepted into the mempool that would cause\n> another\n>     transaction to be unable to be replaced due to Rule #5.\n>\n> We'll call this the Replaceability Invariant. Implementing this rule is\n> simple:\n> for each transaction maintain an integer, nReplacementCandidates. When a\n> non-conflicting transaction is considered for acceptance to the mempool,\n> verify\n> that nReplacementCandidates + 1 < MAX_REPLACEMENT_CANDIDATES for each\n> unconfirmed parent. When a transaction is accepted, increment\n> nReplacementCandidates by 1 for each unconfirmed parent.\n>\n> When a *conflicting* transaction is considered for acceptance, we do _not_\n> need\n> to verify anything: we've already guaranteed that every transaction in the\n> mempool is replaceable! The only thing we may need to do is to decrement\n> nReplacementCandidates by however many children we have replaced, for all\n> unconfirmed parents.\n>\n> When a block is mined, note how the nReplacementCandidates of all\n> unconfirmed\n> transactions remains unchanged because a confirmed transaction can't spend\n> an\n> unconfirmed txout.\n>\n> The only special case to handle is a reorg that changes a transaction from\n> confirmed to unconfirmed. Setting nReplacementCandidates to\n> MAX_REPLACEMENT_CANDIDATES would be fine in that very rare case.\n>\n>\n> Note that like the existing MAX_REPLACEMENT_CANDIDATES check, the\n> Replaceability Invariant overestimates the number of transactions to be\n> replaced in the event that multiple children are spent by the same\n> transaction.\n> That's ok: diamond tx graphs are even more unusual than unconfirmed\n> children,\n> and there's no reason to bend over backwards to accomodate them.\n>\n> Prior art: this proposed rule is similar in spirit to the package limits\n> aready\n> implemented in Bitcoin Core.\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221107/200b5236/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2022-11-07T21:27:16",
                "message_text_only": "On Mon, Nov 07, 2022 at 04:21:11PM -0500, Suhas Daftuar via bitcoin-dev wrote:\n> Hello bitcoin-dev,\n> \n> The description in the OP is completely broken for the simple reason that\n> Bitcoin transactions can have multiple inputs, and so a single transaction\n> can conflict with multiple in-mempool transactions. The proposal would\n> limit the number of descendants of each in-mempool transaction to\n> MAX_REPLACEMENT_CANDIDATES (note that this is duplicative of the existing\n> Bitcoin Core descendant limits), but a transaction that has, say, 500\n> inputs might arrive and conflict with 500 unrelated in-mempool\n> transactions. This could result in 12,500 evictions -- far more than the\n> 100 that was intended.\n\nThat's easy to fix: just sum up the number of nReplacementCandidates for each\ninput in the multiple input case. Again, it'll overcount in the diamond case.\nBut so does the existing code.\n\nThe goal is to defeat pinning by ensuring that you can always replace a\ntransaction by double-spending an output; not that any possible way of\ndouble-spending multiple outputs at once would work.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221107/2003710d/attachment-0001.sig>"
            }
        ],
        "thread_summary": {
            "title": "Removing BIP-125 Rule #5 Pinning with the Always-Replaceable Invariant",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Suhas Daftuar",
                "Peter Todd"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 10283
        }
    },
    {
        "title": "[bitcoin-dev] Using Full-RBF to fix BIP-125 Rule #3 Pinning with nLockTime",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2022-11-07T21:17:50",
                "message_text_only": "On Mon, Nov 07, 2022 at 03:17:29PM -0500, Peter Todd via bitcoin-dev wrote:\n> tl;dr: We can remove the problem of Rule #5 pinning by ensuring that all\n> transactions in the mempool are always replaceable.\n\nWith Rule #5 solved, let's look at the other pinning attack on multi-party\ntransactions: BIP-125 Rule #3\n\ntl;dr: In conjunction with full-RBF, nLockTime'd, pre-signed, transactions can\nensure that one party is not forced to pay for all the cost of a rule #3\nreplacement.\n\n\n# What is the problem?\n\nWhen a transaction contains inputs from multiple parties, each party can lock\nup funds from the other party by spending their input with a transaction that\nis difficult/expensive to replace. Obviously, the clearest example of \"difficult to\nreplace\" is a non-BIP-125 (Opt-in-RBF) transaction. But here, we'll assume that\nfull-rbf is implemented and all transactions are replaceable.\n\nBIP-125 Rule #3 states that:\n\n    The replacement transaction pays an absolute fee of at least the sum paid\n    by the original transactions.\n\nThe attack is that the malicious party, who we'll call Mallory, broadcasts a\ntransaction spending their input(s) with a low fee rate transaction that's\npotentially quite large, during a time of high mempool demand. Due to the low\nfee rate this transaction will take a significant amount of time to mine. The\nother parties to the transaction - who we'll collectively call Alice - are now\nunable to spend their inputs unless they broadcast a transaction \"paying for\"\nMallory's.\n\nThis attack works because Mallory doesn't expect the conflicting tx to actually\nget mined: he assumes it'll either expire, or Alice will get frustrated and\nhave to double spend it. By simple tying up money, Mallory has caused Alice to\nactually lose money.\n\n\n# Fixing the problem with nLockTime\n\nConversely, in the case of an honest multi-party transaction, whose parties\nwe'll call Alice and Bob, the parties genuinely intend for one of two outcomes:\n\n1) The multi-party transaction to get mined within N blocks.\n2) The transaction to be cancelled (most likely by spending one of the inputs).\n\nWe can ensure with high probability that the transaction can be cancelled/mined\nat some point after N blocks by pre-signing a transaction, with nLockTime set\nsufficiently far into the future, spending one or more inputs of the\ntransaction with a sufficiently high fee that it would replace transaction(s)\nattempting to exploit Rule #3 pinning (note how the package limits in Bitcoin\nCore help here).\n\nThere's a few different ways to implement this, and exactly which one makes\nsense will depend on the specifics of the multi-party protocol. But the general\napproach is to defeat the attack by ensuring that Mallory will have to pay the\ncost of getting the multi-party transaction unstuck, at some point in the\nfuture.\n\nFor example, in a two party transaction where there's a clearly more reputable\nparty (Alice), and an untrusted party (Mallory), Alice could simply require\nMallory to provide a nLockTime'd transaction spending only his input to fees,\nmultiple days into the future. In the unlikely event that Mallory holds up the\nprotocol, he will be severely punished. Meanwhile, Alice can always cancel at\nno cost.\n\nIn a many party transaction where both parties are equally (un)trustworthy the\nprotocol could simply have both parties sign a series of transactions,\nnLockTimed at decreasingly far into a future, paying a decreasingly amount of\nfees. If either party holds up the transaction intentionally, they'll both pay\na high cost. But again, at some point Mallory will have paid the full price for\nhis attack. This approach also has the beneficial side effect of implementing\nfee discovery with rbf. This approach is easier as the number of parties\nincreases, eg the Wasabi/Joinmarket transactions with hundreds of inputs and\noutputs: they collectively already have to pay a significant fee to get the\ntransaction mined, making the extra poential cost needed to defeat pinning\nminimal.\n\n\n# Coordinator Spent Bonds with Package Relay/Replacement\n\nFor schemes with a central semi-trusted coordinator, such as Wasabi coinjoins,\nwith package relay/replacement we can use a two party punishment transaction\nconsisting of:\n\n    tx1 - spends Mallory's input to a txout spendable by:\n           IF\n               <coordinator> CheckSig\n           Else\n               <delay> CheckSequenceVerify\n               <mallory> CheckSig\n           EndIf\n\n    tx2 - spends tx1 output to as much fees as needed\n\nWhether or not Mallory cheated with a double-spend is provable to third\nparties; the second transaction ensures that Mallory can't simply release tx1\non their own to frame the coordinator. The use of CheckSequenceVerify ensures\nthat if mallory did try to frame the coordinator, they don't have to do\nanything to return the funds to Mallory.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221107/59ee60a8/attachment.sig>"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-11-07T22:55:59",
                "message_text_only": "Hi Peter,\n\n> We can ensure with high probability that the transaction can be cancelled/mined\n> at some point after N blocks by pre-signing a transaction, with nLockTime set\n> sufficiently far into the future, spending one or more inputs of the\n> transaction with a sufficiently high fee that it would replace transaction(s)\n> attempting to exploit Rule #3 pinning (note how the package limits in Bitcoin\n> Core help here).\n\n>From my understanding, there are many open questions to such a\npre-signed high-fee solution aiming to address Rule #3 pinning.\nDetermining the high-fee to guarantee replacements with high odds. I\nthink it should be superior to current top network mempools sat/vb *\nMAX_STANDARD_TX_WEIGHT, otherwise an adversary can pin the multi-party\nfunded transaction on the ground of Core's\nreplacement rule (\"The replacement transaction's feerate is greater\nthan the feerates of all directly conflicting transactions''). Though\nnote the difficulty, the sat/vb is an unknown fact at time of\nsignatures exchange among the multi-party funded transaction\nparticipants. Solving this issue probably requires from then to\novershoot, and adopt a historical worst-case mempool feerate.\n\nThis \"historically-worst\" sat/vb introduces two new issues, first I\nthink this is an economic lower bound on the funds that can be staked\nin the collaborative transaction. Second I believe this constitutes a\ngriefing vector, where a participant could deliberately pin to inflict\nan asymmetric damage, without entering into any fee competition. This\ngriefing vector could be leveraged as hard as being triggered by a\nminer-as-participant in so-called miner harvesting attacks.\n\nFurther, I think this solution relying on nLocktime doesn't solve the\ntimevalue DoS inflicted to the participants UTXOs, until the\npre-signed high-fee transaction is final. If participants prefer to\nsave the timevalue of their contributed UTXOs over operation success,\na better approach could be for them to unilaterally spend after a\nprotocol/implementation timepoint (e.g LN's funding timeout recovery\nmechanism).\n\nA more workable solution I believe could be simply to rely on\npackage-relay, an ephemeral anchor output, and a special replacement\nregime (e.g nVersion=3) to allow the multi-party funded transaction\ncoordinator to unilateral fee-bump, in a step-by-step approach. I.e\nwithout making assumptions on the knowledge of network mempools and\nburning directly the worst amount in fees.\n\nBest,\nAntoine\n\n\nLe lun. 7 nov. 2022 \u00e0 16:18, Peter Todd via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n> On Mon, Nov 07, 2022 at 03:17:29PM -0500, Peter Todd via bitcoin-dev wrote:\n> > tl;dr: We can remove the problem of Rule #5 pinning by ensuring that all\n> > transactions in the mempool are always replaceable.\n>\n> With Rule #5 solved, let's look at the other pinning attack on multi-party\n> transactions: BIP-125 Rule #3\n>\n> tl;dr: In conjunction with full-RBF, nLockTime'd, pre-signed, transactions\n> can\n> ensure that one party is not forced to pay for all the cost of a rule #3\n> replacement.\n>\n>\n> # What is the problem?\n>\n> When a transaction contains inputs from multiple parties, each party can\n> lock\n> up funds from the other party by spending their input with a transaction\n> that\n> is difficult/expensive to replace. Obviously, the clearest example of\n> \"difficult to\n> replace\" is a non-BIP-125 (Opt-in-RBF) transaction. But here, we'll assume\n> that\n> full-rbf is implemented and all transactions are replaceable.\n>\n> BIP-125 Rule #3 states that:\n>\n>     The replacement transaction pays an absolute fee of at least the sum\n> paid\n>     by the original transactions.\n>\n> The attack is that the malicious party, who we'll call Mallory, broadcasts\n> a\n> transaction spending their input(s) with a low fee rate transaction that's\n> potentially quite large, during a time of high mempool demand. Due to the\n> low\n> fee rate this transaction will take a significant amount of time to mine.\n> The\n> other parties to the transaction - who we'll collectively call Alice - are\n> now\n> unable to spend their inputs unless they broadcast a transaction \"paying\n> for\"\n> Mallory's.\n>\n> This attack works because Mallory doesn't expect the conflicting tx to\n> actually\n> get mined: he assumes it'll either expire, or Alice will get frustrated and\n> have to double spend it. By simple tying up money, Mallory has caused\n> Alice to\n> actually lose money.\n>\n>\n> # Fixing the problem with nLockTime\n>\n> Conversely, in the case of an honest multi-party transaction, whose parties\n> we'll call Alice and Bob, the parties genuinely intend for one of two\n> outcomes:\n>\n> 1) The multi-party transaction to get mined within N blocks.\n> 2) The transaction to be cancelled (most likely by spending one of the\n> inputs).\n>\n> We can ensure with high probability that the transaction can be\n> cancelled/mined\n> at some point after N blocks by pre-signing a transaction, with nLockTime\n> set\n> sufficiently far into the future, spending one or more inputs of the\n> transaction with a sufficiently high fee that it would replace\n> transaction(s)\n> attempting to exploit Rule #3 pinning (note how the package limits in\n> Bitcoin\n> Core help here).\n>\n> There's a few different ways to implement this, and exactly which one makes\n> sense will depend on the specifics of the multi-party protocol. But the\n> general\n> approach is to defeat the attack by ensuring that Mallory will have to pay\n> the\n> cost of getting the multi-party transaction unstuck, at some point in the\n> future.\n>\n> For example, in a two party transaction where there's a clearly more\n> reputable\n> party (Alice), and an untrusted party (Mallory), Alice could simply require\n> Mallory to provide a nLockTime'd transaction spending only his input to\n> fees,\n> multiple days into the future. In the unlikely event that Mallory holds up\n> the\n> protocol, he will be severely punished. Meanwhile, Alice can always cancel\n> at\n> no cost.\n>\n> In a many party transaction where both parties are equally (un)trustworthy\n> the\n> protocol could simply have both parties sign a series of transactions,\n> nLockTimed at decreasingly far into a future, paying a decreasingly amount\n> of\n> fees. If either party holds up the transaction intentionally, they'll both\n> pay\n> a high cost. But again, at some point Mallory will have paid the full\n> price for\n> his attack. This approach also has the beneficial side effect of\n> implementing\n> fee discovery with rbf. This approach is easier as the number of parties\n> increases, eg the Wasabi/Joinmarket transactions with hundreds of inputs\n> and\n> outputs: they collectively already have to pay a significant fee to get the\n> transaction mined, making the extra poential cost needed to defeat pinning\n> minimal.\n>\n>\n> # Coordinator Spent Bonds with Package Relay/Replacement\n>\n> For schemes with a central semi-trusted coordinator, such as Wasabi\n> coinjoins,\n> with package relay/replacement we can use a two party punishment\n> transaction\n> consisting of:\n>\n>     tx1 - spends Mallory's input to a txout spendable by:\n>            IF\n>                <coordinator> CheckSig\n>            Else\n>                <delay> CheckSequenceVerify\n>                <mallory> CheckSig\n>            EndIf\n>\n>     tx2 - spends tx1 output to as much fees as needed\n>\n> Whether or not Mallory cheated with a double-spend is provable to third\n> parties; the second transaction ensures that Mallory can't simply release\n> tx1\n> on their own to frame the coordinator. The use of CheckSequenceVerify\n> ensures\n> that if mallory did try to frame the coordinator, they don't have to do\n> anything to return the funds to Mallory.\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221107/100b0410/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2022-11-09T12:41:30",
                "message_text_only": "On Mon, Nov 07, 2022 at 05:55:59PM -0500, Antoine Riard wrote:\n> Hi Peter,\n> \n> > We can ensure with high probability that the transaction can be cancelled/mined\n> > at some point after N blocks by pre-signing a transaction, with nLockTime set\n> > sufficiently far into the future, spending one or more inputs of the\n> > transaction with a sufficiently high fee that it would replace transaction(s)\n> > attempting to exploit Rule #3 pinning (note how the package limits in Bitcoin\n> > Core help here).\n> \n> From my understanding, there are many open questions to such a\n> pre-signed high-fee solution aiming to address Rule #3 pinning.\n> Determining the high-fee to guarantee replacements with high odds. I\n> think it should be superior to current top network mempools sat/vb *\n> MAX_STANDARD_TX_WEIGHT, otherwise an adversary can pin the multi-party\n> funded transaction on the ground of Core's\n> replacement rule (\"The replacement transaction's feerate is greater\n> than the feerates of all directly conflicting transactions''). Though\n> note the difficulty, the sat/vb is an unknown fact at time of\n> signatures exchange among the multi-party funded transaction\n> participants. Solving this issue probably requires from then to\n> overshoot, and adopt a historical worst-case mempool feerate.\n\nFirst of all, since this is a punishment scenario, overshooting in general is a\ngood thing provided that the bad actor is the one paying for the overshoot.\n\nI may be mistaken on this point. But IIRC rule #6, \"The replacement\ntransaction's feerate is greater than the feerates of all directly conflicting\ntransactions.\", refers to the overall package feerate including all\ntransactions that would need to be mined.\n\nThis is relevant as we have two scenarios for pinning that could try to exploit\nrule #6 while pinning, and neither works:\n\n1) A large, low fee rate, transaction is spent by a high fee rate transaction.\nIn this case the package fee rate of the second tx is still low, because the\nlow fee rate tx would need to be mined first.\n\n2) A small, high fee rate tx, is spent by a large low fee rate tx. In this case\nthe second low fee rate tx is irrelevant, because the high fee rate tx will get\nmined soon, breaking the pin and costing the attacker money.\n\n\nNow, if my understanding of rule #6 is incorrect, obviously we should fix that!\nIt's incentive incompatible to reject a high fee rate replacement that overall\npays more in fees (rule #3), on the basis that we expect a *different* miner to\nmine the low fee rate tx it spends. Because unless we're expecting the\ntransaction to somehow get mined by someone else in the near future, why aren't\nwe mining what pays more money now?\n\n> This \"historically-worst\" sat/vb introduces two new issues, first I\n> think this is an economic lower bound on the funds that can be staked\n> in the collaborative transaction. Second I believe this constitutes a\n> griefing vector, where a participant could deliberately pin to inflict\n> an asymmetric damage, without entering into any fee competition. This\n> griefing vector could be leveraged as hard as being triggered by a\n> miner-as-participant in so-called miner harvesting attacks.\n> \n> Further, I think this solution relying on nLocktime doesn't solve the\n> timevalue DoS inflicted to the participants UTXOs, until the\n> pre-signed high-fee transaction is final. If participants prefer to\n> save the timevalue of their contributed UTXOs over operation success,\n> a better approach could be for them to unilaterally spend after a\n> protocol/implementation timepoint (e.g LN's funding timeout recovery\n> mechanism).\n> \n> A more workable solution I believe could be simply to rely on\n> package-relay, an ephemeral anchor output, and a special replacement\n> regime (e.g nVersion=3) to allow the multi-party funded transaction\n> coordinator to unilateral fee-bump, in a step-by-step approach. I.e\n> without making assumptions on the knowledge of network mempools and\n> burning directly the worst amount in fees.\n\nNote that if you are considering miner harvesting attacks as part of the threat\nmodel, it's not clear to me that the v3 rules that depend on miners arbitrarily\nrejecting transactions from their mempools are actually sufficiently incentive\ncompatible to work.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221109/48373bb3/attachment.sig>"
            },
            {
                "author": "David A. Harding",
                "date": "2022-11-11T03:00:58",
                "message_text_only": "On 2022-11-07 11:17, Peter Todd via bitcoin-dev wrote:\n> We can ensure with high probability that the transaction can be \n> cancelled/mined\n> at some point after N blocks by pre-signing a transaction, with \n> nLockTime set\n> sufficiently far into the future, spending one or more inputs of the\n> transaction with a sufficiently high fee that it would replace \n> transaction(s)\n> attempting to exploit Rule #3 pinning (note how the package limits in \n> Bitcoin\n> Core help here).\n\nThis implies a floor on the funds involved in a contract.  For example, \nif the pinning transaction is 100,000 vbytes at a feerate of 1 sat/vb, \nthe minimum contract amount must be a bit over 100,000 sats (about $17 \nUSD at current prices).  However, participants in a contract not meant \nto settle immediately probably need to assume the worst case future \npinning, for example where transactions paying even 100 sat/vb won't be \nmined promptly; in which case the minimum contract amount becomes \nsomething like $1,700 USD.\n\nThat seems sub-optimal to me.\n\n-Dave"
            }
        ],
        "thread_summary": {
            "title": "Using Full-RBF to fix BIP-125 Rule #3 Pinning with nLockTime",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "David A. Harding",
                "Antoine Riard",
                "Peter Todd"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 18911
        }
    },
    {
        "title": "[bitcoin-dev] Fwd: P2EP Lightning PayJoin",
        "thread_messages": [
            {
                "author": "Dan Gould",
                "date": "2022-11-08T02:57:34",
                "message_text_only": "Funding channels on a lightning node can be a pain. First, I need to send funds to my node on-chain. Then I need to make another transaction to open channels. Instead, we can use the BIP 78 PayJoin P2EP protocol to fund and open channels in a single transaction.\n\nWe do not communicate over the shared blockchain, we share the blockchain by communicating.\n\nHere is an illustration of how the BIP 78 protocol pairs with the BOLT 2 Channel establishment protocol:\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Lightning Peer\u2502 \u2502My Lightning Node\u2502 \u2502Sender\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2518\n\u2502 \u2502 \u2502\n\u2502 BOLT 2 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Bip21 with ?pj= \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502\n\u2502 Channel Establishment \u2502 \u2502\n\u2502 \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500 Original PSBT \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u2502 \u2502\n\u2502 \u2502 \u2502\n\u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 open_channel \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502 \u2502 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 accept_channel \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 \u2502\n\u2502 \u2502 BIP 78 \u2502\n\u2502 \u2502 \u2502\n\u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500 funding_created \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502 \u2502 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 funding_signed \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 \u2502\n\u2502 \u2502 \u2502\n\u2502 \u2502 PayJoin Proposal \u2502\n\u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500 PSBT \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502\n\u2502 \u2502 \u2502\n\u2502 \u2502 \u2502\n\u2502 \u2502 \u250c\u2500 PayJoin + Funding \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u2502 \u2502 Transaction \u2502\n\u2502 \u2502 \u2502 \u2502\nx\u2502xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\u2502xxx \u25bc xxxxxxxxxxxxxxxxxxxxxxxxxx\u2502x\nxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\nxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx BITCOIN NETWORK xxxxxxxxxxxxxxxxxxxxx\nxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\nx\u2502xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\u2502xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\u2502x\n\u2502 \u2502 \u2502\n\u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500channel_ready \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502 \u2502 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 channel_ready \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 \u2502\n\u2502 \u2502 \u2502\n\nWe use P2EP to automate [PSBT Channel establishment](https://gist.github.com/yuyaogawa/3d69bfa03b0702b8ff12c210bc795a6a) communications. As an added benefit, The BIP 78 spec helps avoid surveillance heuristics as well. On-chain, these transactions look like regular PayJoins when using Taproot outputs.\n\nI thank Martin Habov\u0161tiak for the initial work on this idea. Thank you to Riccardo Casatta for developing the rust payjoin crate further. Thank you to Evan Lin for early hacking late nights on this idea. Thanks to my Legends of Lightning Tournament teammates Armin Sabouri and Nick Farrow.\n\nWe have released \"nolooking,\" an experimental alpha that implements this work, on the Umbrel app store.\n\nA brand new node can become totally connected in a single transaction that opens channels to outbound peers, and could immediately swap for inbound capacity. Just by scanning a single QR code.\n\n[Source](https://github.com/chaincase-app/nolooking)\n\nWant to help? The rust [payjoin crate](https://github.com/Kixunil/payjoin) needs love in the form of code review and unit testing. Don\u2019t hesitate to reach out.\n\nDan\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/fac7c62b/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Fwd: P2EP Lightning PayJoin",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Dan Gould"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2778
        }
    },
    {
        "title": "[bitcoin-dev] Merkleize All The Things",
        "thread_messages": [
            {
                "author": "Salvatore Ingala",
                "date": "2022-11-08T09:17:42",
                "message_text_only": "Hi list,\n\nI have been working on some notes to describe an approach that uses\ncovenants in order to enable general smart contracts in bitcoin. You can\nfind them here:\n\n    https://merkle.fun\n\nThe approach has a number of desirable features:\n\n- small impact to layer 1;\n- not application-specific, very general;\n- it fits well into P2TR;\n- it does not require new cryptographic assumptions, nor any construction\nthat has not withstood the test of time.\n\nThis content was presented at the BTCAzores unconference, where it received\nthe name of MATT \u2212 short for Merkleize All The Things.\nIn fact, no other cryptographic primitive is required, other than Merkle\ntrees.\n\nI believe this construction gets close to answering the question of how\nsmall a change on bitcoin's layer 1 would suffice to enable arbitrary smart\ncontracts.\n\nIt is not yet at the stage where a formal proposal can be made, therefore\nthe proposed specs are only for illustrative purposes.\n\nThe same content is reformatted below for the mailing list.\n\nLooking forward to hearing about your comments and improvements.\nSalvatore Ingala\n\n\n==========================================\n\n\n# General smart contracts in bitcoin via covenants\n\nCovenants are UTXOs that are encumbered with restrictions on the outputs of\nthe transaction spending the UTXO. More formally, we can define a covenant\nany UTXO such that at least one of its spending conditions is valid only if\none or more of the outputs\u2019 scriptPubKey satisfies certain restrictions.\n\nGenerally, covenant proposals also add some form of introspection (that is,\nthe ability for Script to access parts of the inputs/outputs, or the\nblockchain history).\n\nIn this note, we want to explore the possibilities unleashed by the\naddition of a covenant with the following properties:\n\n- introspection limited to a single hash attached to the UTXO (the\n\u201ccovenant data\u201d), and input/output amounts;\n- pre-commitment to every possible future script (but not their data);\n- few simple opcodes operating with the covenant data.\n\nWe argue that such a simple covenant construction is enough to extend the\npower of bitcoin\u2019s layer 1 to become a universal settlement layer for\narbitrary computation.\n\nMoreover, the covenant can elegantly fit within P2TR transactions, without\nany substantial increase for the workload of bitcoin nodes.\n\nA preliminary version of these notes was presented and discussed at the\nBTCAzores Unconference [1], on 23rd September 2022.\n\n\n# Preliminaries\n\nWe can think of a smart contract as a \u201cprogram\u201d that updates a certain\nstate according to predetermined rules (which typically include access\ncontrol by authorizing only certain public keys to perform certain\nactions), and that can possibly lock/unlock some coins of the underlying\nblockchain according to the same rules.\n\nThe exact definition will be highly dependent on the properties of the\nunderlying blockchain.\n\nIn bitcoin, the only state upon which all the nodes reach consensus is the\nUTXO set; other blockchains might have other data structures as part of the\nconsensus, like a key-value store that can be updated as a side effect of\ntransaction execution.\n\nIn this section we explore the following concepts in order to set the\nframework for a definition of smart contracts that fits the structure of\nbitcoin:\n\n- the contract\u2019s state: the \u201cmemory\u201d the smart contract operates on;\n- state transitions: the rules to update the contract\u2019s state;\n- covenants: the technical means that can allow contracts to function in\nthe context of a bitcoin UTXO.\n\nIn the following, an on-chain smart contract is always represented as a\nsingle UTXO that implicitly embeds the contract\u2019s state and possibly\ncontrols some coins that are \u201clocked\u201d in it. More generally, one could\nthink of smart contracts that are represented in a set of multiple UTXOs;\nwe leave the exploration of generalizations of the framework to future\nresearch.\n\n## State\n\nAny interesting \u201cstate\u201d of a smart contract can ultimately be encoded as a\nlist, where each element is either a bit, a fixed-size integers, or an\narbitrary byte string.\n\nWhichever the choice, it does not really affect what kinds of computations\nare expressible, as long as one is able to perform some basic computations\non those elements.\n\nIn the following, we will assume without loss of generality that\ncomputations happen on a state which is a list of fixed length S = [s_1,\ns_2, \u2026, s_n], where each s_i is a byte string.\n\n### Merkleized state\n\nBy constructing a Merkle tree that has the (hashes of) the elements of S in\nthe leaves, we can produce a short commitment h_S to the entire list S with\nthe following properties (that hold for a verifier that only knows h_S):\n\n- a (log n)-sized proof can prove the value of an element s_i;\n- a (log n + |x|)-sized proof can prove the new commitment h_S\u2019, where S\u2019\nis a new list obtained by replacing the value of a certain leaf with x.\n\nThis allows to compactly commit to a RAM, and to prove correctness of RAM\nupdates.\n\nIn other words, a stateful smart contract can represent an arbitrary state\nin just a single hash, for example a 32-byte SHA256 output.\n\n### State transitions and UTXOs\n\nWe can conveniently represent a smart contract as a finite state machine\n(FSM), where exactly one node can be active at a given time. Each node has\nan associated state as defined above, and a set of transition rules that\ndefine:\n\n- who can use the rule;\n- what is the next active node in the FSM;\n- what is the state of the next active node.\n\nIt is then easy to understand how covenants can conveniently represent and\nenforce the smart contracts in this framework:\n\n- The smart contract is instantiated by creating a UTXO encumbered with a\ncovenant; the smart contract is in the initial node of the FSM.\n- The UTXO\u2019s scriptPubKey specifies the current state and the valid\ntransitions.\n- The UTXO(s) produced after a valid transition might or might not be\nfurther encumbered, according to the rules.\n\nTherefore, what is necessary in order to enable this framework in bitcoin\nScript is a covenant that allows the enforcement of such state transitions,\nby only allowing outputs that commit to a valid next node (and\ncorresponding state) in the FSM.\n\nIt is not difficult to show that arbitrary computation is possible over the\ncommitted state, as long as relatively simple arithmetic or logical\noperations are available over the state.\n\nRemark: using an acyclic FSM does not reduce the expressivity of the smart\ncontracts, as any terminating computation on bounded-size inputs which\nrequires cycles can be unrolled into an acyclic one.\n\n### Merkleized state transitions\n\nSimilarly to how using Merkle trees allows to succinctly represent\narbitrary data with a short, 32-byte long summary, the same trick allows to\nsuccinctly represent arbitrary state transitions (the smart contract\u2019s\ncode) with a single 32-byte hash. Each of the possible state transitions is\nencoded as a Script which is put in a leaf of a Merkle tree; the Merkle\nroot of this tree is a commitment to all the possible state transitions.\nThis is exactly what the taptree achieves in Taproot (see BIP-0341 [2]).\n\nLater sections in this document will suggest a possible way of how both the\ncontract\u2019s state and valid transition rules could be represented in UTXOs.\n\n## On-chain computation?!\n\nShould the chain actually do computation?\n\nIf naively designed, the execution of a contract might require a large\nnumber of transactions, which is not feasible.\n\nWhile the covenant approach does indeed enable a chain of transactions to\nperform arbitrary computation, simple economic considerations will push\nprotocol designers to perform any non-trivial computation off-chain, and\ninstead use the blockchain consensus only to verify the computation; or, if\npossible, skip the verification altogether.\n\nThe fundamental fact that a blockchain\u2019s layer 1 never actually needs to\nrun complex programs in order to enable arbitrary complex smart contracting\nwas observed in the past, for example in a 2016 post by Greg Maxwell [3].\n\nVitalik Buterin popularized the concept of \"functionality escape velocity\"\n[4] to signify the minimum amount of functionality required on layer 1 in\norder to enable anything else to be built on top (that is, on layer 2 and\nbeyond).\n\nIn the following section, we will argue that a simple covenant construction\nsuffices to achieve the functionality escape velocity in the UTXO model.\n\n\n# Commitments to computation and fraud challenges\n\nIn this section, we explore how a smart contract that requires any\nnon-trivial computation f : X --> Y (that is too expensive or not feasible\nwith on-chain Script state transitions) can be implemented with the simple\ncovenants described in the previous section.\n\nThe ideas in this section appeared in literature; the reader is referred to\nthe references for a more comprehensive discussion.\n\nWe want to be able to build contracts that allow conditions of the type\n\"f(x) = y\"; yet, we do not want layer 1 to be forced to perform any\nexpensive computation.\n\nIn the following, we assume for simplicity that Alice and Bob are the only\nparticipants of the covenant, and they both locked some funds bond_A and\nbond_B (respectively) inside the covenant\u2019s UTXO.\n\n1. Alice posts the statement \u201cf(x) = y\u201d.\n2. After a challenge period, if no challenge occurs, Alice is free to\ncontinue and unlock the funds; the statement is true.\n3. At any time before the challenge period expires, Bob can start a\nchallenge: \u201cactually, f(x) = z\u201d.\n\nIn case of a challenge, Alice and Bob enter a challenge resolution\nprotocol, arbitrated by layer 1; the winner takes the other party\u2019s bond\n(details and the exact game theory vary based on the type of protocol the\nchallenge is part of; choosing the right amount of bonds is crucial for\nprotocol design).\n\nThe remainder of this section sketches an instantiation of the challenge\nprotocol.\n\n## The bisection protocol for arbitrary computation\n\nIn this section, we sketch the challenge protocol for an arbitrary\ncomputation f : X --> Y.\n\n### Computation trace\n\nGiven the function f, it is possible to decompose the entire computation in\nsimple elementary steps, each performing a simple, atomic operation. For\nexample, if the domain of x and y is that of binary strings of a fixed\nlength, it is possible to create a boolean circuit that takes x and\nproduces y; in practice, some form of assembly-like language operating on a\nRAM might be more efficient and fitting for bitcoin Script.\n\nIn the following, we assume each elementary operation is operating on a\nRAM, encoded in the state via Merkle trees as sketched above. Therefore,\none can represent all the steps of the computation as triples tri = (st_i,\nop_i, st_{i + 1}), where st_i is the state (e.g. a canonical Merkle tree of\nthe RAM) before the i-th operation, st_{i + 1} is the state after, and op_i\nis the description of the operation (implementation-specific; it could be\nsomething like \u201cadd a to b and save the result in c).\n\nFinally, a Merkle tree M_T is constructed that has as leaves the values of\nthe individual computation steps T = {tr_0, tr_1, \u2026, tr_{N - 1}} if the\ncomputation requires N steps, producing the Merkle root h_T. The height of\nthe Merkle tree is log N. Observe that each internal node commits to the\nportion of the computation trace corresponding to its own subtree.\n\nLet\u2019s assume that the Merkle tree commitments for internal nodes are\nfurther augmented with the states st_{start} and st_{end}, respectively the\nstate before the operation of in the leftmost leaf of the subtree, and\nafter the rightmost leaf of the subtree.\n\n### Bisection protocol\n\nThe challenge protocol begins with Alice posting what she claims is the\ncomputation trace h_A, while Bob disagrees with the trace h_B != h_A;\ntherefore, the challenge starts at the root of M_T, and proceeds in steps\nin order to find a leaf where Alice and Bob disagree (which is guaranteed\nto exist, hence the disagreement). Note that the arbitration mechanism\nknows f, x and y, but not the correct computation trace hash h_T.\n\n(Bisection phase): While the challenge is at a non-leaf node of M_T, Alice\nand Bob take turns to post the two hashes corresponding to the left and\nright child of their claimed computation trace hash; moreover, they post\nthe start/end state for each child node. The protocol enforces that Alice\u2019s\ntransaction is only valid if the posted hashes h_{l; A} and h_{r; A}, and\nthe declared start/end state for each child are consistent with the\ncommitment in the current node.\n\n(Arbitration phase): If the protocol has reached the i-th leaf node, then\neach party reveals (st_i, op_i, st_{i + 1}); in fact, only the honest party\nwill be able to reveal correct values, therefore the protocol can\nadjudicate the winner.\n\nRemark: there is definitely a lot of room for optimizations; it is left for\nfuture work to find the optimal variation of the approach; moreover,\ndifferent challenge mechanisms could be more appropriate for different\nfunctions f.\n\n### Game theory (or why the chain will not see any of this)\n\nWith the right economic incentives, protocol designers can guarantee that\nplaying a losing game always loses money compared to cooperating.\nTherefore, the challenge game is never expected to be played on-chain. The\nsize of the bonds need to be appropriate to disincentivize griefing attacks.\n\n### Implementing the bisection protocol's state transitions\n\nIt is not difficult to see that the entire challenge-response protocol\nabove can be implemented using the simple state transitions described above.\n\nBefore a challenge begins, the state of the covenant contains the value of\nx, y and the computation trace computed by Alice. When starting the\nchallenge, Bob also adds its claim for the correct computation trace, and\nthe covenant enters the bisection phase.\n\nDuring the bisaction phase, the covenant contains the claimed computation\ntrace for that node of the computation protocol, according to each party.\nIn turns, each party has to reveal the corresponding computation trace for\nboth the children of the current node; the transaction is only valid if the\nhash of the current node can be computed correctly from the information\nprovided by each party about the child nodes. The protocol repeats on one\nof the two child nodes on whose computation trace the two parties disagree\n(which is guaranteed to exist). If a leaf of M_T is reached, the covenant\nenters the final arbitration phase.\n\nDuring the arbitration phase (say at the i-th leaf node of M_T), any party\ncan win the challenge by providing correct values for tr_i = (st_i, op_i,\nst_{i + 1}). Crucially, only one party is able to provide correct values,\nand Script can verify that indeed the state moves from st_i to st_{i + 1}\nby executing op_i. The challenge is over.\n\nAt any time, the covenant allows one player to automatically win the\nchallenge after a certain timeout if the other party (who is expected to\n\u201cmake his move\u201d) does not spend the covenant. This guarantees that the\nprotocol can always find a resolution.\n\n### Security model\n\nAs for other protocols (like the lightning network), a majority of miners\ncan allow a player to win a challenge by censoring the other player\u2019s\ntransactions. Therefore, the bisection protocol operates under the honest\nminer majority assumption. This is acceptable for many protocols, but it\nshould certainly be taken into account during protocol design.\n\n\n# MATT covenants\n\nWe argued that the key to arbitrary, fully general smart contracts in the\nUTXO model is to use Merkle trees, at different levels:\n\n1. succinctly represent arbitrary state with a single hash. Merkleize the\nstate!\n2. succinctly represent the possible state transitions with a single hash.\nMerkleize the Script!\n3. succinctly represent arbitrary computations with a single hash.\nMerkleize the execution!\n\n(1) and (2) alone allow contracts with arbitrary computations; (3) makes\nthem scale.\n\n   Merkleize All The Things!\n\nIn this section we sketch a design of covenant opcodes that are\ntaproot-friendly and could easily be added in a soft fork to the existing\nSegWitv1 Script.\n\n## Embedding covenant data in P2TR outputs\n\nWe can take advantage of the double-commitment structure of taproot outputs\n(that is, committing to both a public key and a Merkle tree of scripts) to\ncompactly encode both the covenant and the state transition rules inside\ntaproot outputs.\n\nThe idea is to replace the internal pubkey Q with a key Q\u2019 obtained by\ntweaking Q with the covenant data (the same process that is used to commit\nto the root of the taptree). More precisely, if d is the data committed to\nthe covenant, the covenant-data-augmented internal key Q\u2019 is defined as:\n\n    Q\u2019 = Q + int(hashTapCovenantData(Q || h_{data}))G\n\nwhere h_{data} is the sha256-hash of the covenant data. It is then easy to\nprove that the point is constructed in this way, by repeating the\ncalculation.\n\nIf there is no useful key path spend, similarly to what is suggested in\nBIP-0341 [5] for the case of scripts with no key path spends, we can use\nthe NUMS point:\n    H =\nlift_x(0x0250929b74c1a04954b78b4b6035e97a5e078a5a0f28ec96d547bfee9ace803ac0).\n\nTODO: please double check if the math above is sound.\n\n## Changes to Script\n\nThe following might be some minimal new opcodes to add for taproot\ntransactions in order to enable the construction above. This is a very\npreliminary proposal, and not yet complete nor correct.\n\n- OP_SHA256CAT: returns the SHA256 hash of the concatenation of the second\nand the first (top) element of the stack. (redundant if OP_CAT is enabled,\neven just on operands with total length up to 64 bytes)\n- OP_CHECKINPUTCOVENANTVERIFY: let x, d be the two top elements of the\nstack; behave like OP_SUCCESS if any of x and d is not exactly 32 bytes;\notherwise, check that the x is a valid x-only pubkey, and the internal\npubkey P is indeed obtained by tweaking lift_x(x) with d.\n- OP_INSPECTNUMINPUTS, OP_INSPECTNUMOUTPUTS, OP_INSPECTINPUTVALUE and\nOP_INSPECTOUTPUTVALUE - opcodes to push number on the stack of\ninputs/outputs and their amounts.\n- OP_CHECKOUTPUTCOVENANTVERIFY: given a number out_i and three 32-byte hash\nelements x, d and taptree on top of the stack, verifies that the out_i-th\noutput is a P2TR output with internal key computed as above, and tweaked\nwith taptree. This is the actual covenant opcode.\n\nTODO:\n\n- Many contracts need parties to provide additional data; simply passing it\nvia the witness faces the problem that it could be malleated. Therefore, a\nway of passing signed data is necessary. One way to address this problem\ncould be to add a commitment to the data in the annex, and add an opcode to\nverify such commitment. Since the annex is covered by the signature, this\nremoves any malleability. Another option is an OP_CHECKSIGFROMSTACK opcode,\nbut that would cost an additional signature check.\n- Bitcoin numbers in current Script are not large enough for amounts.\n\nOther observations:\n\n- OP_CHECKINPUTCOVENANTVERIFY and OP_CHECKOUTPUTCOVENANTVERIFY could have a\nmode where x is replaced with a NUMS pubkey, for example if the first\noperand is an empty array of bytes instead of a 32 byte pubkey; this saves\nabout 31 bytes when no internal pubkey is needed (so about 62 bytes for a\ntypical contract transition using both opcodes)\n- Is it worth adding other introspection opcodes, for example\nOP_INSPECTVERSION, OP_INSPECTLOCKTIME? See Liquid's Tapscript Opcodes [6].\n- Is there any malleability issue? Can covenants \u201crun\u201d without signatures,\nor is a signature always to be expected when using spending conditions with\nthe covenant encumbrance? That might be useful in contracts where no\nsignature is required to proceed with the protocol (for example, any party\ncould feed valid data to the bisection protocol above).\n- Adding some additional opcodes to manipulate stack elements might also\nbring performance improvements in applications (but not strictly necessary\nfor feasibility).\n\nRemark: the additional introspection opcodes available in Blockstream\nLiquid [6] do indeed seem to allow MATT covenants; in fact, the opcodes\nOP_CHECKINPUTCOVENANTVERIFY and OP_CHECKOUTPUTCOVENANTVERIFY could be\nreplaced by more general opcodes like the group {OP_TWEAKVERIFY,\nOP_INSPECTINPUTSCRIPTPUBKEY, OP_PUSHCURRENTINPUTINDEX,\nOP_INSPECTOUTPUTSCRIPTPUBKEY }.\n\n### Variant: bounded recursivity\n\nIn the form described above, the covenant essentially allows fully\nrecursive constructions (an arbitrary depth of the covenant execution tree\nis in practice equivalent to full recursion).\n\nIf recursivity is not desired, one could modify the covenants in a way that\nonly allows a limited depth: a counter could be attached to the covenant,\nwith the constraint that the counter must be decreased for\nOP_CHECKOUTPUTCOVENANTVERIFY. That would still allow arbitrary fraud proofs\nas long as the maximum depth is sufficient.\n\nHowever, that would likely reduce its utility and prevent certain\napplications where recursivity seems to be a requirement.\n\nThe full exploration of the design space is left for future research.\n\n\n# Applications\n\nThis section explores some of the potential use cases of the techniques\npresented above. The list is not exhaustive.\n\nGiven the generality of fraud proofs, some variant of every kind of smart\ncontracts or layer two construction should be possible with MATT covenants,\nalthough the additional requirements (for example the capital lockup and\nthe challenge period delays) needs to be accurately considered; further\nresearch is necessary to assess for what applications the tradeoffs are\nacceptable.\n\n## State channels\n\nA state channel is a generalization of a payment channel where,\nadditionally to the balance at the end of each channel, some additional\nstate is stored. The state channel also specifies what are the rules on how\nto update the channel\u2019s state.\n\nFor example, two people might play a chess game, where the state encodes\nthe current configuration of the board. The valid state transitions\ncorrespond to the valid moves; and, once the game is over, the winner takes\na specified amount of the channel\u2019s money.\n\nWith eltoo-style updates, such a game could be played entirely off-chain,\nas long as both parties are cooperating (by signing the opponent\u2019s state\nupdate).\n\nThe role of the blockchain is to guarantee that the game can be moved\nforward and eventually terminated in case the other party does not\ncooperate.\n\nIn stateful blockchain, this is simply achieved by publishing the latest\nstate (Merkleized or not) and then continuing the entire game on-chain.\nThis is expensive, especially if the state transitions require some complex\ncomputation.\n\nAn alternative that avoids moving computations on-chain is the use of a\nchallenge-response protocol, as sketched above.\n\nSimilarly to the security model of lightning channels, an honest party can\nalways win a challenge under the honest-majority of miners. Therefore, it\nis game-theoretically losing to attempt cheating in a channel.\n\n## CoinPool\n\nMultiparty state channels are possible as well; therefore, constructions\nlike CoinPool [7] should be possible, enabling multiple parties to share a\nsingle UTXO.\n\n## Zero knowledge proofs in L2 protocols\n\nProtocols based on ZK-proofs require the blockchain to be the verifier; the\nverifier is a function that takes a zero-knowledge proof and returns\ntrue/false based on its correctness.\n\nInstead of an OP_STARK operator in L1, one could think of compiling the\nOP_STARK as the function f in the protocol above.\n\nNote that covenants with a bounded \u201crecursion depth\u201d are sufficient to\nexpress OP_STARK, which in turns imply the ability to express arbitrary\nfunctions within contracts using the challenge protocol.\n\nOne advantage of this approach is that no new cryptographic assumptions are\nadded to bitcoin\u2019s layer 1 even if OP_STARK does require it; moreover, if a\ndifferent or better OP_STARK2 is discovered, the innovation can reach layer\n2 contracts without any change needed in layer 1.\n\n## Optimistic rollups\n\nJohn Light recently posted a research report on how Validity Rollups could\nbe added to bitcoin\u2019s layer 1 [8]. While no exact proposal is pushed\nforward, the suggested changes required might include a combination of\nrecursive covenants, and specific opcodes for validity proof verification.\n\nFraud proofs are the core for optimistic rollups; exploring the possibility\nof implementing optimistic rollups with MATT covenants seems a promising\ndirection. Because of the simplicity of the required changes to Script,\nthis might answer some of the costs and risks analyzed in the report, while\nproviding many of the same benefits. Notably, no novel cryptography needs\nto become part of bitcoin\u2019s layer 1.\n\nOptimistic Rollups would probably require a fully recursive version of the\ncovenant (while fraud proofs alone are possible with a limited recursion\ndepth).\n\n\n# Acknowledgments\n\nAntoine Poinsot suggested an improvement to the original proposed covenant\nopcodes, which were limited to taproot outputs without a valid key-path\nspend.\n\nThe author would also like to thank catenocrypt, Antoine Riard, Ruben\nSomsen and the participants of the BTCAzores unconference for many useful\ndiscussions and comments on early versions of this proposal.\n\n\n# References\n\nThe core idea of the bisection protocol appears to have been independently\nrediscovered multiple times. In blockchain research, it is at the core of\nfraud proof constructions with similar purposes, although not focusing on\nbitcoin or covenants; see for example:\n\n- Harry Kalodner et al. \u201cArbitrum: Scalable, private smart contracts.\u201d \u2212\n27th USENIX Security Symposium. 2018.\nhttps://www.usenix.org/system/files/conference/usenixsecurity18/sec18-kalodner.pdf\n- Jason Teutsch and Christian Reitwiessner. \u201cA scalable verification\nsolution for blockchains\u201d \u2212 TrueBit protocol. 2017.\nhttps://people.cs.uchicago.edu/~teutsch/papers/truebit.pdf\n\nThe same basic idea was already published prior to blockchain use cases;\nsee for example:\n\nRan Canetti, Ben Riva, and Guy N. Rothblum. \u201cPractical delegation of\ncomputation using multiple servers.\u201d \u2212 Proceedings of the 18th ACM\nconference on Computer and communications security. 2011.\nhttp://diyhpl.us/~bryan/papers2/bitcoin/Practical%20delegation%20of%20computation%20using%20multiple%20servers.pdf\n\n\n\n# Footnotes\n\n[1] - https://btcazores.com\n[2] - https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki\n[3] -\nhttps://bitcointalk.org/index.php?topic=1427885.msg14601127#msg14601127\n[4] - https://vitalik.ca/general/2019/12/26/mvb.html\n[5] -\nhttps://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki#constructing-and-spending-taproot-outputs\n[6] -\nhttps://github.com/ElementsProject/elements/blob/master/doc/tapscript_opcodes.md\n[7] - https://coinpool.dev/v0.1.pdf\n[8] - https://bitcoinrollups.org\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/d6f2d8a3/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-11-08T12:01:11",
                "message_text_only": "Good morning Salvatore,\n\nInteresting idea.\n\nThe idea to embed the current state is similar to something I have been musing about recently.\n\n\n> ### Game theory (or why the chain will not see any of this)\n> \n> With the right economic incentives, protocol designers can guarantee that playing a losing game always loses money compared to cooperating. Therefore, the challenge game is never expected to be played on-chain. The size of the bonds need to be appropriate to disincentivize griefing attacks.\n\nModulo bugs, operator error, misconfigurations, and other irrationalities of humans.\n\n\n\n> - OP_CHECKOUTPUTCOVENANTVERIFY: given a number out_i and three 32-byte hash elements x, d and taptree on top of the stack, verifies that the out_i-th output is a P2TR output with internal key computed as above, and tweaked with taptree. This is the actual covenant opcode.\n\nRather than get taptree from the stack, just use the same taptree as in the revelation of the P2TR.\nThis removes the need to include quining and similar techniques: just do the quining in the SCRIPT interpreter.\n\nThe entire SCRIPT that controls the covenant can be defined as a taptree with various possible branches as tapleaves.\nIf the contract is intended to terminate at some point it can have one of the tapleaves use `OP_CHECKINPUTCOVENANTVERIFY` and then determine what the output \"should\" be using e.g. `OP_CHECKTEMPLATEVERIFY`.\n\n\n> - Is it worth adding other introspection opcodes, for example OP_INSPECTVERSION, OP_INSPECTLOCKTIME? See Liquid's Tapscript Opcodes [6].\n\n`OP_CHECKTEMPLATEVERIFY` and some kind of sha256 concatenated hashing should be sufficient I think.\n\n> - Is there any malleability issue? Can covenants \u201crun\u201d without signatures, or is a signature always to be expected when using spending conditions with the covenant encumbrance? That might be useful in contracts where no signature is required to proceed with the protocol (for example, any party could feed valid data to the bisection protocol above).\n\nHmm protocol designer beware?\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Salvatore Ingala",
                "date": "2022-11-10T09:42:30",
                "message_text_only": "Hi ZmnSCPxj, Bram, Peter, David,\n\nThanks for all your comments; replies below.\n\nOn Tue, 8 Nov 2022 at 13:01, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Modulo bugs, operator error, misconfigurations, and other irrationalities\n> of humans.\n>\n\nI agree that making footguns impossible is a much more difficult problem to\nsolve!\n\nRather than get taptree from the stack, just use the same taptree as in the\n> revelation of the P2TR.\n> This removes the need to include quining and similar techniques: just do\n> the quining in the SCRIPT interpreter.\n>\n\nThat's a possibility; I suspect it would be less efficient for many\ncontracts (in particular, when the total number of states in the FSM is\nrelatively large, but each of them has only few valid transitions). We\ncould always allow both variants.\n\nAnother reason I preferred to present it in this way is to show that it is\npossible to limit the design to covenants where recursion is not allowed /\nlimited; I don't personally think recursion is bad at this time \u2212 but the\ncovenants (and the protocol for fraud challenges) do not require it in\norder to be useful.\n\nAnyway, I suggested some opcodes only as a sketch. I'm not knowledgeable\nenough to suggest the best design, and maybe it will be easier to compare\nseveral variants once we implement something on top.\n\n\nOn Wed, 9 Nov 2022 at 00:34, Bram Cohen <bram at chia.net> wrote:\n\n> Hash chained covenants in general all have about the same plateau of\n> functionality, which seems roughly reasonable to add to Bitcoin as it is\n> today but suffer from being limited and hence likely only a stepping stone\n> to greater functionality and unless whatever's put in now cleanly extends\n> to supporting more in the future it's likely to turn into a legacy\n> appendage which has to be supported. So my generic suggestion for this sort\n> of thing is that it should be proposed along with a plan for how it could\n> be extended to support full-blown covenants in the future.\n>\n\nI actually struggle to find constructions that are _not_ possible using\nsuch covenants; do you have any concrete example?\nThat would be very interesting in order to correctly classify the\nexpressive power of UTXO+Script+covenants when compared to the\n\"Turing-complete\"+stateful models.\n\nAnother probably unhelpful bit of feedback I have is that Bitcoin should\n> probably be taking verkle trees seriously because those can have\n> substantially lower size/cost/weight than merkle trees. That doesn't just\n> apply to this proposal, but to Bitcoin in general, which doesn't seem to\n> have any serious verkle tree proposals to date.\n>\n\nI am not an expert in Verkle trees, but I think the efficiency gain (if\nany) is not that interesting for many of the applications I'm suggesting,\nas most Merkle trees would be quite small.\nTherefore, I agree with Peter that the additional complexity might not be\nworth it at this time; if applications requiring large Merkle trees arise\nin practice, Verkle trees could always be added in the future as an\noptimization.\n\nMoreover, Verkle trees, or even any risky/fancy cryptography, could be used\nin layer-2 solutions enabled by the covenant, without impacting any funds\nnot locked in the covenant in case of disasters.\n\n\nOn Wed, 9 Nov 2022 at 13:07, Peter Todd <pete at petertodd.org> wrote:\n\n> Particularly since even having merkle trees in Bitcoin\n> is arguably a mistake: they allow for degenerate, weak, security modes\n> like SPV\n> that aren't clearly good for Bitcoin as a whole.\n>\n\nI disagree, as the title of this thread suggests! :)\nThanks to Merkle trees, we'll be able to keep layer 1 extremely light, so\neveryone can run a full node \u2212 while all the complexity of fancy\nconstructions is pushed to the application layer.\n\n\nOn Thu, 10 Nov 2022 at 08:39, David A. Harding <dave at dtrt.org> wrote:\n\n> > 1. Alice posts the statement \u201cf(x) = y\u201d.\n> > 2. After a challenge period, if no challenge occurs, Alice is free to\n> > continue and unlock the funds; the statement is true.\n> > 3. At any time before the challenge period expires, Bob can start a\n> > challenge: \u201cactually, f(x) = z\u201d.\n>\n> That looks to me very similar to Gregory Maxwell's script from[1]\n>\n\nZero-Knowledge contingent payments do indeed solve the problem more\nelegantly in the specific case where swapping Alice's knowledge for x with\na payment from Bob is the entire smart contract.\n\nThe covenant adds the ability to carry over some sort of state. For\nexample, imagine Alice and Bob want to play a game of chess, and the winner\ntakes all the money [*]. The \"state\" in the covenant would be the entire\nchessboard, and a valid transition is a valid chess move. The covenant\nenforces that the game proceeds according to the rules, by only allowing\ncorrect updates to the \"state\".\nMoreover, the parties participating to a covenant don't necessarily need to\nbe decided in advance, which is crucial for constructions like coinpool [1].\n\nNote that no this does not require any fraud proof, as the rules of chess\nare simple enough that each \"transition\" is a simple enough function. In\nfact, many contracts might not require fraud proofs at all.\n\nThe point of the chapter on fraud proof is to prove that full generality in\nexpressive power (that is: any state transition you can think of) is\npossible, as whenever a complex transition is required \u2212 one could instead\nreplace it with the optimistic protocol (Alice makes a claim,\ncounterparties can challenge if the claim is wrong). That allows to remove\nany expensive computation from hitting the blockchain.\n\nA particularly interesting example might be rollups (and similar\nconstructions). There, the 'state' represents a separate ledger, and a\ntransition takes the secondary ledger from a valid state to another valid\nstate, using a zero-knowledge proof. In validity rollups [2], the chain is\nrequired to actually check the validity proof, which is a very expensive\noperation (plus, the state-of-the-art requires additional cryptographic\nassumptions in layer 1, as far as I understand). The covenant would allow\nus[**] to implement optimistic rollups, where the rollup operator just\nposts the new state and the proof, and other parties have time to challenge\nit if the proof is wrong.\n\nI hope this clarifies the role of fraud proofs in the construction.\n\nBest,\nSalvatore\n\n\n[*] - I'm not suggesting using the bitcoin blockchain to play chess games,\nbut it is a convenient academic example :)\n[**] - Pending someone more expert to double check that nothing is missing!\n\n[1] - https://coinpool.dev\n[2] - https://bitcoinrollups.org\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221110/34d9b720/attachment-0001.html>"
            },
            {
                "author": "Bram Cohen",
                "date": "2022-11-08T23:34:32",
                "message_text_only": "On Tue, Nov 8, 2022 at 2:13 AM Salvatore Ingala via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> I have been working on some notes to describe an approach that uses\n> covenants in order to enable general smart contracts in bitcoin. You can\n> find them here:\n>\n>     https://merkle.fun/\n> <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>\n\nHash chained covenants in general all have about the same plateau of\nfunctionality, which seems roughly reasonable to add to Bitcoin as it is\ntoday but suffer from being limited and hence likely only a stepping stone\nto greater functionality and unless whatever's put in now cleanly extends\nto supporting more in the future it's likely to turn into a legacy\nappendage which has to be supported. So my generic suggestion for this sort\nof thing is that it should be proposed along with a plan for how it could\nbe extended to support full-blown covenants in the future.\n\nAnother probably unhelpful bit of feedback I have is that Bitcoin should\nprobably be taking verkle trees seriously because those can have\nsubstantially lower size/cost/weight than merkle trees. That doesn't just\napply to this proposal, but to Bitcoin in general, which doesn't seem to\nhave any serious verkle tree proposals to date.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/783dabea/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2022-11-09T12:07:33",
                "message_text_only": "On Tue, Nov 08, 2022 at 03:34:32PM -0800, Bram Cohen via bitcoin-dev wrote:\n> Another probably unhelpful bit of feedback I have is that Bitcoin should\n> probably be taking verkle trees seriously because those can have\n> substantially lower size/cost/weight than merkle trees. That doesn't just\n> apply to this proposal, but to Bitcoin in general, which doesn't seem to\n> have any serious verkle tree proposals to date.\n\nVerkle trees only reduce proof sizes by a factor of 6-8, and they introduce\nsignificant implementation complexity and new cryptographic assumptions. Better\nto let other crypto-systems get a few more years of experience with them before\nadding them to Bitcoin. Particularly since even having merkle trees in Bitcoin\nis arguably a mistake: they allow for degenerate, weak, security modes like SPV\nthat aren't clearly good for Bitcoin as a whole.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221109/affdcd02/attachment.sig>"
            },
            {
                "author": "David A. Harding",
                "date": "2022-11-10T07:39:10",
                "message_text_only": "On 2022-11-07 23:17, Salvatore Ingala via bitcoin-dev wrote:\n> Hi list,\n\nHi Salvatore!,\n\n> I have been working on some notes to describe an approach that uses\n> covenants in order to enable general smart contracts in bitcoin. You\n> can find them here:\n> \n>     https://merkle.fun\n\nI haven't yet been able to understand everything in your post, but I'm \nwondering if you can describe how your proposal significantly differs in \napplication from [1]?  E.g., you write:\n\n> 1. Alice posts the statement \u201cf(x) = y\u201d.\n> 2. After a challenge period, if no challenge occurs, Alice is free to \n> continue and unlock the funds; the statement is true.\n> 3. At any time before the challenge period expires, Bob can start a \n> challenge: \u201cactually, f(x) = z\u201d.\n\nThat looks to me very similar to Gregory Maxwell's script from[1] \n(comments and variable name changes mine):\n\n# Offchain, Alice posts the statement f(x) = y\n# Offchain, Bob provides Ex, an encrypted form of x that can be proven \nin zero knowledge to satisfy both f(x) = y and sha256(x) = Y\nOP_SHA256\n<Y> OP_EQUAL\nOP_IF\n   # Bob provided the preimage for Y, that preimage being the solution, \nso he can spend the funds now\n   <Bob Pubkey>\nOP_ELSE\n   # The challenge period ended, so Alice can reclaim her funds\n   <block_height+100> OP_CHECKLOCKTIMEVERIFY OP_DROP\n   <Alice Pubkey>\nOP_ENDIF\nOP_CHECKSIG\n\nThanks and apologies if I'm missing something obvious!,\n\n-Dave\n\n[1] \nhttps://bitcoincore.org/en/2016/02/26/zero-knowledge-contingent-payments-announcement/"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-11-11T21:49:58",
                "message_text_only": "Hi Salvatore,\n\nThanks for bringing forward this MATT proposal!\n\nHere my (rough) understanding of the protocol, the participants decompose\nthe entire computation into a number N of steps, each assigned a tapleaf,\neach computation is a triplet (state_start, operation, state_end), the\ntapleaves are built into a Merkle tree, the current state of the FSM is\nalso encoded in the Taproot output. The Merkle tree is committed in some\nScript branch where a timelock is present to guarantee challenge (e.g \"f(x)\n= ?\" OP_CHALLENGE + 100 OP_CSV). A funding transaction is broadcast to lock\nthe funds, participants can leverage this funding output to play out\noff-chain the computation steps. To advance the resolution, a participant\nspends the funding output with a witness embedding all the computation\ntrace encoded as Merkle branch and prove some statement \"f(x) = y\". Until\nthe CSV expires, another participant can contest by presenting another\nwitness with another computation trace. What is unclear to me is how the\ncontract's state issued off-chain can alter the pre-committed state\ntransitions. I think what could gain in clarity is the translation of the\nbisection protocol steps in more complete new opcodes.\n\nAnother high-level remark, even if we assume any arbitrary computation can\nbe encoded in a Merkle Tree, as the computation grows in complexity, the\ncorresponding trace also increases in (witness) space. There might be some\neconomic bounds on the generalized smart contracts you can engage in, as\nthe worst-case scenario might be beyond your fee-bumping reserves. Less\nflexible, but more templated opcodes for the same use-cases might make it\nmore affordable. At the same time, the ability to encode any cryptosystem\nas the function f sounds really interesting.\n\nBest,\nAntoine\n\nLe mar. 8 nov. 2022 \u00e0 05:13, Salvatore Ingala via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n> Hi list,\n>\n> I have been working on some notes to describe an approach that uses\n> covenants in order to enable general smart contracts in bitcoin. You can\n> find them here:\n>\n>     https://merkle.fun\n>\n> The approach has a number of desirable features:\n>\n> - small impact to layer 1;\n> - not application-specific, very general;\n> - it fits well into P2TR;\n> - it does not require new cryptographic assumptions, nor any construction\n> that has not withstood the test of time.\n>\n> This content was presented at the BTCAzores unconference, where it\n> received the name of MATT \u2212 short for Merkleize All The Things.\n> In fact, no other cryptographic primitive is required, other than Merkle\n> trees.\n>\n> I believe this construction gets close to answering the question of how\n> small a change on bitcoin's layer 1 would suffice to enable arbitrary smart\n> contracts.\n>\n> It is not yet at the stage where a formal proposal can be made, therefore\n> the proposed specs are only for illustrative purposes.\n>\n> The same content is reformatted below for the mailing list.\n>\n> Looking forward to hearing about your comments and improvements.\n> Salvatore Ingala\n>\n>\n> ==========================================\n>\n>\n> # General smart contracts in bitcoin via covenants\n>\n> Covenants are UTXOs that are encumbered with restrictions on the outputs\n> of the transaction spending the UTXO. More formally, we can define a\n> covenant any UTXO such that at least one of its spending conditions is\n> valid only if one or more of the outputs\u2019 scriptPubKey satisfies certain\n> restrictions.\n>\n> Generally, covenant proposals also add some form of introspection (that\n> is, the ability for Script to access parts of the inputs/outputs, or the\n> blockchain history).\n>\n> In this note, we want to explore the possibilities unleashed by the\n> addition of a covenant with the following properties:\n>\n> - introspection limited to a single hash attached to the UTXO (the\n> \u201ccovenant data\u201d), and input/output amounts;\n> - pre-commitment to every possible future script (but not their data);\n> - few simple opcodes operating with the covenant data.\n>\n> We argue that such a simple covenant construction is enough to extend the\n> power of bitcoin\u2019s layer 1 to become a universal settlement layer for\n> arbitrary computation.\n>\n> Moreover, the covenant can elegantly fit within P2TR transactions, without\n> any substantial increase for the workload of bitcoin nodes.\n>\n> A preliminary version of these notes was presented and discussed at the\n> BTCAzores Unconference [1], on 23rd September 2022.\n>\n>\n> # Preliminaries\n>\n> We can think of a smart contract as a \u201cprogram\u201d that updates a certain\n> state according to predetermined rules (which typically include access\n> control by authorizing only certain public keys to perform certain\n> actions), and that can possibly lock/unlock some coins of the underlying\n> blockchain according to the same rules.\n>\n> The exact definition will be highly dependent on the properties of the\n> underlying blockchain.\n>\n> In bitcoin, the only state upon which all the nodes reach consensus is the\n> UTXO set; other blockchains might have other data structures as part of the\n> consensus, like a key-value store that can be updated as a side effect of\n> transaction execution.\n>\n> In this section we explore the following concepts in order to set the\n> framework for a definition of smart contracts that fits the structure of\n> bitcoin:\n>\n> - the contract\u2019s state: the \u201cmemory\u201d the smart contract operates on;\n> - state transitions: the rules to update the contract\u2019s state;\n> - covenants: the technical means that can allow contracts to function in\n> the context of a bitcoin UTXO.\n>\n> In the following, an on-chain smart contract is always represented as a\n> single UTXO that implicitly embeds the contract\u2019s state and possibly\n> controls some coins that are \u201clocked\u201d in it. More generally, one could\n> think of smart contracts that are represented in a set of multiple UTXOs;\n> we leave the exploration of generalizations of the framework to future\n> research.\n>\n> ## State\n>\n> Any interesting \u201cstate\u201d of a smart contract can ultimately be encoded as a\n> list, where each element is either a bit, a fixed-size integers, or an\n> arbitrary byte string.\n>\n> Whichever the choice, it does not really affect what kinds of computations\n> are expressible, as long as one is able to perform some basic computations\n> on those elements.\n>\n> In the following, we will assume without loss of generality that\n> computations happen on a state which is a list of fixed length S = [s_1,\n> s_2, \u2026, s_n], where each s_i is a byte string.\n>\n> ### Merkleized state\n>\n> By constructing a Merkle tree that has the (hashes of) the elements of S\n> in the leaves, we can produce a short commitment h_S to the entire list S\n> with the following properties (that hold for a verifier that only knows\n> h_S):\n>\n> - a (log n)-sized proof can prove the value of an element s_i;\n> - a (log n + |x|)-sized proof can prove the new commitment h_S\u2019, where S\u2019\n> is a new list obtained by replacing the value of a certain leaf with x.\n>\n> This allows to compactly commit to a RAM, and to prove correctness of RAM\n> updates.\n>\n> In other words, a stateful smart contract can represent an arbitrary state\n> in just a single hash, for example a 32-byte SHA256 output.\n>\n> ### State transitions and UTXOs\n>\n> We can conveniently represent a smart contract as a finite state machine\n> (FSM), where exactly one node can be active at a given time. Each node has\n> an associated state as defined above, and a set of transition rules that\n> define:\n>\n> - who can use the rule;\n> - what is the next active node in the FSM;\n> - what is the state of the next active node.\n>\n> It is then easy to understand how covenants can conveniently represent and\n> enforce the smart contracts in this framework:\n>\n> - The smart contract is instantiated by creating a UTXO encumbered with a\n> covenant; the smart contract is in the initial node of the FSM.\n> - The UTXO\u2019s scriptPubKey specifies the current state and the valid\n> transitions.\n> - The UTXO(s) produced after a valid transition might or might not be\n> further encumbered, according to the rules.\n>\n> Therefore, what is necessary in order to enable this framework in bitcoin\n> Script is a covenant that allows the enforcement of such state transitions,\n> by only allowing outputs that commit to a valid next node (and\n> corresponding state) in the FSM.\n>\n> It is not difficult to show that arbitrary computation is possible over\n> the committed state, as long as relatively simple arithmetic or logical\n> operations are available over the state.\n>\n> Remark: using an acyclic FSM does not reduce the expressivity of the smart\n> contracts, as any terminating computation on bounded-size inputs which\n> requires cycles can be unrolled into an acyclic one.\n>\n> ### Merkleized state transitions\n>\n> Similarly to how using Merkle trees allows to succinctly represent\n> arbitrary data with a short, 32-byte long summary, the same trick allows to\n> succinctly represent arbitrary state transitions (the smart contract\u2019s\n> code) with a single 32-byte hash. Each of the possible state transitions is\n> encoded as a Script which is put in a leaf of a Merkle tree; the Merkle\n> root of this tree is a commitment to all the possible state transitions.\n> This is exactly what the taptree achieves in Taproot (see BIP-0341 [2]).\n>\n> Later sections in this document will suggest a possible way of how both\n> the contract\u2019s state and valid transition rules could be represented in\n> UTXOs.\n>\n> ## On-chain computation?!\n>\n> Should the chain actually do computation?\n>\n> If naively designed, the execution of a contract might require a large\n> number of transactions, which is not feasible.\n>\n> While the covenant approach does indeed enable a chain of transactions to\n> perform arbitrary computation, simple economic considerations will push\n> protocol designers to perform any non-trivial computation off-chain, and\n> instead use the blockchain consensus only to verify the computation; or, if\n> possible, skip the verification altogether.\n>\n> The fundamental fact that a blockchain\u2019s layer 1 never actually needs to\n> run complex programs in order to enable arbitrary complex smart contracting\n> was observed in the past, for example in a 2016 post by Greg Maxwell [3].\n>\n> Vitalik Buterin popularized the concept of \"functionality escape velocity\"\n> [4] to signify the minimum amount of functionality required on layer 1 in\n> order to enable anything else to be built on top (that is, on layer 2 and\n> beyond).\n>\n> In the following section, we will argue that a simple covenant\n> construction suffices to achieve the functionality escape velocity in the\n> UTXO model.\n>\n>\n> # Commitments to computation and fraud challenges\n>\n> In this section, we explore how a smart contract that requires any\n> non-trivial computation f : X --> Y (that is too expensive or not feasible\n> with on-chain Script state transitions) can be implemented with the simple\n> covenants described in the previous section.\n>\n> The ideas in this section appeared in literature; the reader is referred\n> to the references for a more comprehensive discussion.\n>\n> We want to be able to build contracts that allow conditions of the type\n> \"f(x) = y\"; yet, we do not want layer 1 to be forced to perform any\n> expensive computation.\n>\n> In the following, we assume for simplicity that Alice and Bob are the only\n> participants of the covenant, and they both locked some funds bond_A and\n> bond_B (respectively) inside the covenant\u2019s UTXO.\n>\n> 1. Alice posts the statement \u201cf(x) = y\u201d.\n> 2. After a challenge period, if no challenge occurs, Alice is free to\n> continue and unlock the funds; the statement is true.\n> 3. At any time before the challenge period expires, Bob can start a\n> challenge: \u201cactually, f(x) = z\u201d.\n>\n> In case of a challenge, Alice and Bob enter a challenge resolution\n> protocol, arbitrated by layer 1; the winner takes the other party\u2019s bond\n> (details and the exact game theory vary based on the type of protocol the\n> challenge is part of; choosing the right amount of bonds is crucial for\n> protocol design).\n>\n> The remainder of this section sketches an instantiation of the challenge\n> protocol.\n>\n> ## The bisection protocol for arbitrary computation\n>\n> In this section, we sketch the challenge protocol for an arbitrary\n> computation f : X --> Y.\n>\n> ### Computation trace\n>\n> Given the function f, it is possible to decompose the entire computation\n> in simple elementary steps, each performing a simple, atomic operation. For\n> example, if the domain of x and y is that of binary strings of a fixed\n> length, it is possible to create a boolean circuit that takes x and\n> produces y; in practice, some form of assembly-like language operating on a\n> RAM might be more efficient and fitting for bitcoin Script.\n>\n> In the following, we assume each elementary operation is operating on a\n> RAM, encoded in the state via Merkle trees as sketched above. Therefore,\n> one can represent all the steps of the computation as triples tri = (st_i,\n> op_i, st_{i + 1}), where st_i is the state (e.g. a canonical Merkle tree of\n> the RAM) before the i-th operation, st_{i + 1} is the state after, and op_i\n> is the description of the operation (implementation-specific; it could be\n> something like \u201cadd a to b and save the result in c).\n>\n> Finally, a Merkle tree M_T is constructed that has as leaves the values of\n> the individual computation steps T = {tr_0, tr_1, \u2026, tr_{N - 1}} if the\n> computation requires N steps, producing the Merkle root h_T. The height of\n> the Merkle tree is log N. Observe that each internal node commits to the\n> portion of the computation trace corresponding to its own subtree.\n>\n> Let\u2019s assume that the Merkle tree commitments for internal nodes are\n> further augmented with the states st_{start} and st_{end}, respectively the\n> state before the operation of in the leftmost leaf of the subtree, and\n> after the rightmost leaf of the subtree.\n>\n> ### Bisection protocol\n>\n> The challenge protocol begins with Alice posting what she claims is the\n> computation trace h_A, while Bob disagrees with the trace h_B != h_A;\n> therefore, the challenge starts at the root of M_T, and proceeds in steps\n> in order to find a leaf where Alice and Bob disagree (which is guaranteed\n> to exist, hence the disagreement). Note that the arbitration mechanism\n> knows f, x and y, but not the correct computation trace hash h_T.\n>\n> (Bisection phase): While the challenge is at a non-leaf node of M_T, Alice\n> and Bob take turns to post the two hashes corresponding to the left and\n> right child of their claimed computation trace hash; moreover, they post\n> the start/end state for each child node. The protocol enforces that Alice\u2019s\n> transaction is only valid if the posted hashes h_{l; A} and h_{r; A}, and\n> the declared start/end state for each child are consistent with the\n> commitment in the current node.\n>\n> (Arbitration phase): If the protocol has reached the i-th leaf node, then\n> each party reveals (st_i, op_i, st_{i + 1}); in fact, only the honest party\n> will be able to reveal correct values, therefore the protocol can\n> adjudicate the winner.\n>\n> Remark: there is definitely a lot of room for optimizations; it is left\n> for future work to find the optimal variation of the approach; moreover,\n> different challenge mechanisms could be more appropriate for different\n> functions f.\n>\n> ### Game theory (or why the chain will not see any of this)\n>\n> With the right economic incentives, protocol designers can guarantee that\n> playing a losing game always loses money compared to cooperating.\n> Therefore, the challenge game is never expected to be played on-chain. The\n> size of the bonds need to be appropriate to disincentivize griefing attacks.\n>\n> ### Implementing the bisection protocol's state transitions\n>\n> It is not difficult to see that the entire challenge-response protocol\n> above can be implemented using the simple state transitions described above.\n>\n> Before a challenge begins, the state of the covenant contains the value of\n> x, y and the computation trace computed by Alice. When starting the\n> challenge, Bob also adds its claim for the correct computation trace, and\n> the covenant enters the bisection phase.\n>\n> During the bisaction phase, the covenant contains the claimed computation\n> trace for that node of the computation protocol, according to each party.\n> In turns, each party has to reveal the corresponding computation trace for\n> both the children of the current node; the transaction is only valid if the\n> hash of the current node can be computed correctly from the information\n> provided by each party about the child nodes. The protocol repeats on one\n> of the two child nodes on whose computation trace the two parties disagree\n> (which is guaranteed to exist). If a leaf of M_T is reached, the covenant\n> enters the final arbitration phase.\n>\n> During the arbitration phase (say at the i-th leaf node of M_T), any party\n> can win the challenge by providing correct values for tr_i = (st_i, op_i,\n> st_{i + 1}). Crucially, only one party is able to provide correct values,\n> and Script can verify that indeed the state moves from st_i to st_{i + 1}\n> by executing op_i. The challenge is over.\n>\n> At any time, the covenant allows one player to automatically win the\n> challenge after a certain timeout if the other party (who is expected to\n> \u201cmake his move\u201d) does not spend the covenant. This guarantees that the\n> protocol can always find a resolution.\n>\n> ### Security model\n>\n> As for other protocols (like the lightning network), a majority of miners\n> can allow a player to win a challenge by censoring the other player\u2019s\n> transactions. Therefore, the bisection protocol operates under the honest\n> miner majority assumption. This is acceptable for many protocols, but it\n> should certainly be taken into account during protocol design.\n>\n>\n> # MATT covenants\n>\n> We argued that the key to arbitrary, fully general smart contracts in the\n> UTXO model is to use Merkle trees, at different levels:\n>\n> 1. succinctly represent arbitrary state with a single hash. Merkleize the\n> state!\n> 2. succinctly represent the possible state transitions with a single hash.\n> Merkleize the Script!\n> 3. succinctly represent arbitrary computations with a single hash.\n> Merkleize the execution!\n>\n> (1) and (2) alone allow contracts with arbitrary computations; (3) makes\n> them scale.\n>\n>    Merkleize All The Things!\n>\n> In this section we sketch a design of covenant opcodes that are\n> taproot-friendly and could easily be added in a soft fork to the existing\n> SegWitv1 Script.\n>\n> ## Embedding covenant data in P2TR outputs\n>\n> We can take advantage of the double-commitment structure of taproot\n> outputs (that is, committing to both a public key and a Merkle tree of\n> scripts) to compactly encode both the covenant and the state transition\n> rules inside taproot outputs.\n>\n> The idea is to replace the internal pubkey Q with a key Q\u2019 obtained by\n> tweaking Q with the covenant data (the same process that is used to commit\n> to the root of the taptree). More precisely, if d is the data committed to\n> the covenant, the covenant-data-augmented internal key Q\u2019 is defined as:\n>\n>     Q\u2019 = Q + int(hashTapCovenantData(Q || h_{data}))G\n>\n> where h_{data} is the sha256-hash of the covenant data. It is then easy to\n> prove that the point is constructed in this way, by repeating the\n> calculation.\n>\n> If there is no useful key path spend, similarly to what is suggested in\n> BIP-0341 [5] for the case of scripts with no key path spends, we can use\n> the NUMS point:\n>     H =\n> lift_x(0x0250929b74c1a04954b78b4b6035e97a5e078a5a0f28ec96d547bfee9ace803ac0).\n>\n> TODO: please double check if the math above is sound.\n>\n> ## Changes to Script\n>\n> The following might be some minimal new opcodes to add for taproot\n> transactions in order to enable the construction above. This is a very\n> preliminary proposal, and not yet complete nor correct.\n>\n> - OP_SHA256CAT: returns the SHA256 hash of the concatenation of the second\n> and the first (top) element of the stack. (redundant if OP_CAT is enabled,\n> even just on operands with total length up to 64 bytes)\n> - OP_CHECKINPUTCOVENANTVERIFY: let x, d be the two top elements of the\n> stack; behave like OP_SUCCESS if any of x and d is not exactly 32 bytes;\n> otherwise, check that the x is a valid x-only pubkey, and the internal\n> pubkey P is indeed obtained by tweaking lift_x(x) with d.\n> - OP_INSPECTNUMINPUTS, OP_INSPECTNUMOUTPUTS, OP_INSPECTINPUTVALUE and\n> OP_INSPECTOUTPUTVALUE - opcodes to push number on the stack of\n> inputs/outputs and their amounts.\n> - OP_CHECKOUTPUTCOVENANTVERIFY: given a number out_i and three 32-byte\n> hash elements x, d and taptree on top of the stack, verifies that the\n> out_i-th output is a P2TR output with internal key computed as above, and\n> tweaked with taptree. This is the actual covenant opcode.\n>\n> TODO:\n>\n> - Many contracts need parties to provide additional data; simply passing\n> it via the witness faces the problem that it could be malleated. Therefore,\n> a way of passing signed data is necessary. One way to address this problem\n> could be to add a commitment to the data in the annex, and add an opcode to\n> verify such commitment. Since the annex is covered by the signature, this\n> removes any malleability. Another option is an OP_CHECKSIGFROMSTACK opcode,\n> but that would cost an additional signature check.\n> - Bitcoin numbers in current Script are not large enough for amounts.\n>\n> Other observations:\n>\n> - OP_CHECKINPUTCOVENANTVERIFY and OP_CHECKOUTPUTCOVENANTVERIFY could have\n> a mode where x is replaced with a NUMS pubkey, for example if the first\n> operand is an empty array of bytes instead of a 32 byte pubkey; this saves\n> about 31 bytes when no internal pubkey is needed (so about 62 bytes for a\n> typical contract transition using both opcodes)\n> - Is it worth adding other introspection opcodes, for example\n> OP_INSPECTVERSION, OP_INSPECTLOCKTIME? See Liquid's Tapscript Opcodes [6].\n> - Is there any malleability issue? Can covenants \u201crun\u201d without signatures,\n> or is a signature always to be expected when using spending conditions with\n> the covenant encumbrance? That might be useful in contracts where no\n> signature is required to proceed with the protocol (for example, any party\n> could feed valid data to the bisection protocol above).\n> - Adding some additional opcodes to manipulate stack elements might also\n> bring performance improvements in applications (but not strictly necessary\n> for feasibility).\n>\n> Remark: the additional introspection opcodes available in Blockstream\n> Liquid [6] do indeed seem to allow MATT covenants; in fact, the opcodes\n> OP_CHECKINPUTCOVENANTVERIFY and OP_CHECKOUTPUTCOVENANTVERIFY could be\n> replaced by more general opcodes like the group {OP_TWEAKVERIFY,\n> OP_INSPECTINPUTSCRIPTPUBKEY, OP_PUSHCURRENTINPUTINDEX,\n> OP_INSPECTOUTPUTSCRIPTPUBKEY }.\n>\n> ### Variant: bounded recursivity\n>\n> In the form described above, the covenant essentially allows fully\n> recursive constructions (an arbitrary depth of the covenant execution tree\n> is in practice equivalent to full recursion).\n>\n> If recursivity is not desired, one could modify the covenants in a way\n> that only allows a limited depth: a counter could be attached to the\n> covenant, with the constraint that the counter must be decreased for\n> OP_CHECKOUTPUTCOVENANTVERIFY. That would still allow arbitrary fraud proofs\n> as long as the maximum depth is sufficient.\n>\n> However, that would likely reduce its utility and prevent certain\n> applications where recursivity seems to be a requirement.\n>\n> The full exploration of the design space is left for future research.\n>\n>\n> # Applications\n>\n> This section explores some of the potential use cases of the techniques\n> presented above. The list is not exhaustive.\n>\n> Given the generality of fraud proofs, some variant of every kind of smart\n> contracts or layer two construction should be possible with MATT covenants,\n> although the additional requirements (for example the capital lockup and\n> the challenge period delays) needs to be accurately considered; further\n> research is necessary to assess for what applications the tradeoffs are\n> acceptable.\n>\n> ## State channels\n>\n> A state channel is a generalization of a payment channel where,\n> additionally to the balance at the end of each channel, some additional\n> state is stored. The state channel also specifies what are the rules on how\n> to update the channel\u2019s state.\n>\n> For example, two people might play a chess game, where the state encodes\n> the current configuration of the board. The valid state transitions\n> correspond to the valid moves; and, once the game is over, the winner takes\n> a specified amount of the channel\u2019s money.\n>\n> With eltoo-style updates, such a game could be played entirely off-chain,\n> as long as both parties are cooperating (by signing the opponent\u2019s state\n> update).\n>\n> The role of the blockchain is to guarantee that the game can be moved\n> forward and eventually terminated in case the other party does not\n> cooperate.\n>\n> In stateful blockchain, this is simply achieved by publishing the latest\n> state (Merkleized or not) and then continuing the entire game on-chain.\n> This is expensive, especially if the state transitions require some complex\n> computation.\n>\n> An alternative that avoids moving computations on-chain is the use of a\n> challenge-response protocol, as sketched above.\n>\n> Similarly to the security model of lightning channels, an honest party can\n> always win a challenge under the honest-majority of miners. Therefore, it\n> is game-theoretically losing to attempt cheating in a channel.\n>\n> ## CoinPool\n>\n> Multiparty state channels are possible as well; therefore, constructions\n> like CoinPool [7] should be possible, enabling multiple parties to share a\n> single UTXO.\n>\n> ## Zero knowledge proofs in L2 protocols\n>\n> Protocols based on ZK-proofs require the blockchain to be the verifier;\n> the verifier is a function that takes a zero-knowledge proof and returns\n> true/false based on its correctness.\n>\n> Instead of an OP_STARK operator in L1, one could think of compiling the\n> OP_STARK as the function f in the protocol above.\n>\n> Note that covenants with a bounded \u201crecursion depth\u201d are sufficient to\n> express OP_STARK, which in turns imply the ability to express arbitrary\n> functions within contracts using the challenge protocol.\n>\n> One advantage of this approach is that no new cryptographic assumptions\n> are added to bitcoin\u2019s layer 1 even if OP_STARK does require it; moreover,\n> if a different or better OP_STARK2 is discovered, the innovation can reach\n> layer 2 contracts without any change needed in layer 1.\n>\n> ## Optimistic rollups\n>\n> John Light recently posted a research report on how Validity Rollups could\n> be added to bitcoin\u2019s layer 1 [8]. While no exact proposal is pushed\n> forward, the suggested changes required might include a combination of\n> recursive covenants, and specific opcodes for validity proof verification.\n>\n> Fraud proofs are the core for optimistic rollups; exploring the\n> possibility of implementing optimistic rollups with MATT covenants seems a\n> promising direction. Because of the simplicity of the required changes to\n> Script, this might answer some of the costs and risks analyzed in the\n> report, while providing many of the same benefits. Notably, no novel\n> cryptography needs to become part of bitcoin\u2019s layer 1.\n>\n> Optimistic Rollups would probably require a fully recursive version of the\n> covenant (while fraud proofs alone are possible with a limited recursion\n> depth).\n>\n>\n> # Acknowledgments\n>\n> Antoine Poinsot suggested an improvement to the original proposed covenant\n> opcodes, which were limited to taproot outputs without a valid key-path\n> spend.\n>\n> The author would also like to thank catenocrypt, Antoine Riard, Ruben\n> Somsen and the participants of the BTCAzores unconference for many useful\n> discussions and comments on early versions of this proposal.\n>\n>\n> # References\n>\n> The core idea of the bisection protocol appears to have been independently\n> rediscovered multiple times. In blockchain research, it is at the core of\n> fraud proof constructions with similar purposes, although not focusing on\n> bitcoin or covenants; see for example:\n>\n> - Harry Kalodner et al. \u201cArbitrum: Scalable, private smart contracts.\u201d \u2212\n> 27th USENIX Security Symposium. 2018.\n> https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-kalodner.pdf\n> - Jason Teutsch and Christian Reitwiessner. \u201cA scalable verification\n> solution for blockchains\u201d \u2212 TrueBit protocol. 2017.\n> https://people.cs.uchicago.edu/~teutsch/papers/truebit.pdf\n>\n> The same basic idea was already published prior to blockchain use cases;\n> see for example:\n>\n> Ran Canetti, Ben Riva, and Guy N. Rothblum. \u201cPractical delegation of\n> computation using multiple servers.\u201d \u2212 Proceedings of the 18th ACM\n> conference on Computer and communications security. 2011. http://diyhpl.us/~bryan/papers2/bitcoin/Practical%20delegation%20of%20computation%20using%20multiple%20servers.pdf\n>\n>\n>\n> # Footnotes\n>\n> [1] - https://btcazores.com\n> [2] - https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki\n> [3] -\n> https://bitcointalk.org/index.php?topic=1427885.msg14601127#msg14601127\n> [4] - https://vitalik.ca/general/2019/12/26/mvb.html\n> [5] -\n> https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki#constructing-and-spending-taproot-outputs\n> [6] -\n> https://github.com/ElementsProject/elements/blob/master/doc/tapscript_opcodes.md\n> [7] - https://coinpool.dev/v0.1.pdf\n> [8] - https://bitcoinrollups.org\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221111/cc91511d/attachment-0001.html>"
            },
            {
                "author": "Salvatore Ingala",
                "date": "2022-11-12T15:04:20",
                "message_text_only": "Hi Antoine,\nIt appears that my explanation of the relationship between the covenant and\nthe bisection protocol is still unclear; I'll do my best to clarify.\n\nThe bisection's Merkle tree never ends up on-chain, in any form. Therefore,\na bigger computation does not end up in a bigger witness size, which is key\nto the scalability of the approach. Only in the case of a challenge, it\nwill result in a (logarithmically) longer chain of transactions to resolve\nit. This chain of transactions could be mapped to a root-to-leaf path in\nthe Merkle tree of the computation trace.\n\nThe actual computation trace (and the corresponding Merkle tree) is only\ncomputed by the parties when they execute the computation.\nWhat's in the tapleaves is only the valid transitions at the current state\nof the protocol; that is, the valid transitions in the Finite State Machine\n(and possibly other valid exit conditions that remove the covenant\nencumbrance, if any).\n\nThe bisection protocol only makes sense as a step in a larger protocol that\nmakes use of it.\n\nPerhaps presenting the protocol in a less-than-general case might help to\nunderstand it. So let's play a simpler game using a protocol that includes\na fraud proof.\n\nAlice claims that she knows how to multiply by 256, while Bob doesn't\nbelieve her. So they make a bet: they each commit 1 coin; then Bob choses a\nnumber x; then Alice computes y = 256*x by doubling x eight times\n(expensive multiplications were disabled in a tragic DDoS accident), and\npublishes the result y. Bob independently computes 256 * x (he has a friend\nwho is a mathematician, he'll know how to do it). If the result is not y,\nBob will start a challenge; otherwise, Alice wins and takes the money.\n\n(The example is of course artificial, as redoing the computation in Script\nis cheaper than executing the fraud proof in this case!)\n\nWhat follows is an actual execution of the protocol. In the following, each\n[Si] is a UTXO corresponding to some possible FSM node, starting with the\nS0, the UTXO with 1+1 = 2 coins. Each line with \"-\" is a possible\ntransition (script in the taptree), specifying what is the next FSM node\nafter the \"==>\" symbol; the encumbrance in the scripts enforce that the\nstate of the next UTXO is updated correctly (details omitted below), and\nany other necessary conditions to ensure the integrity of the protocol.\n\n\n=====\n\n\n[S0]: Initial UTXO\n  - only Bob can spend, he must choose his number x ==> S1\n\n[S1; state: x]:\n  - only Alice can spend, she publishes her answer y ==> S2\n\n[S2. state: x, y]:\n  - after 1 day: Alice won, she can take the money     // Happy case!\nUsually that's the end\n  - Bob disagrees with the answer, post z as his answer. ==> S3\n\nThe challenge starts here! Let's put some actual numbers. x = 2; y = 508; z\n= 512.\n\nThis is what Alice computed:\n\n  2 => 4 => 8 => 16 => 32 => 64 => 127 => 254 => 508\n\nThis is what Bob computed:\n\n  2 => 4 => 8 => 16 => 32 => 64 => 128 => 256 => 512\n\nAt this time, we don't know who is right. They both built a tree that looks\nlike this (ASCII art only working in fixed-width font):\n\n             ___H18___\n            /         \\\n           /           \\\n        H14             H58\n        / \\             / \\\n       /   \\           /   \\\n      /     \\         /     \\\n    H12     H34     H56     H78\n    / \\     / \\     / \\     / \\\n  H1  H2  H3  H4  H5  H6  H7  H8\n\nRemember that each internal node commits to: the state of the computation\nbefore the leftmost leaf in the subtree, the state after the rightmost\nleaf, and the hash of sub-trace for the sub-tree. Each leaf just commits to\nthat intermediate computation step (and the operation, which here is always\n\"double the input\"). For example, H4 commits to \"16 => 32\" according to\nboth Alice's and Bob's computation traces.\n\n(From our privileged point of view, we can foresee that the earliest\ndisagreement is on the 6th step of the computation: \"64 => 127\" according\nto Alice, \"64 => 128\" according to Bob).\n\nLet's denote h_{A;18} (resp. h_{B;18}) all the information committed to in\nthe node H18, according to Alice (resp. Bob). Similarly for all the other\nnodes.\n\n[S3. state: x, y, z]: Challenge starts!\n  - Alice posts the root of her computation trace h_{A;18} ==> S4\n\n[S4. state: x, y, z, h_{A;18}]\n  - Bob posts the root of her computation trace h_{B;18} ==> S5\n\nSince they disagree, it must be the case that h_{A;18} != h_{B;18}.\n\n[S5. state: x, y, z, h_{A;18}, h_{B;18}]\n  - Alice opens the commitment h_{A;18}, by revealing H14 and H58\n(according to her) ==> S6\n\nNote that in this last transition (going to S6), the covenant enforces that\nthe child commitments are compatible: the transition is only valid if the\nstarting state of the computation according to h_{A;14} is compatible with\nh_{A;18} (that is, it's equal to x); similarly the end state of the\ncomputation in h_{A;58} must be y, and h_{A;18} can be recomputed from the\ndata provided (ensuring the integrity of the Merkle tree).\nThis is true for all the commitment openings below.\n\n[S6. state: x, y, z, (h_{A;14}, h_{A;58}), h_{B;18}]\n  - Bob opens the commitment h_{B;18}, by revealing H14 and H58 (according\nto him) ==> S7\n\n[S7. state: x, y, z, (h_{A;18}, h_{A;14}, h_{A;58}), (h_{B;18}, h_{B;14},\nh_{B;58})]\n  // We now need to choose a child where there is disagreement.\n  // If both children don't match, iterate on the left child.\n  - Anyone: if h_{A;14} == h_{B;14} ==> S8\n  - Anyone: if h_{A;14} != h_{B;14} ==> Continue challenge on H14 //\nNon-executed FSM cases omitted for brevity\n\nAt this point, the disagreement over the root is settled: Alice and Bob\nagree on the first half of the computation, but they disagree over the\nsecond half. Therefore, in S8 the protocol continues over H58.\n\n[S8. state: h_{A;58}, h_{B;58}]\n  // This is analogous to S5, just with half of the computation steps.\n  - Alice opens the commitment h_{A;58}, by revealing H56 and H78\n(according to her) ==> S9\n\n[S9. state: (h_{A;56}, h_{A;78}), h_{B;58}]\n  - Bob opens the commitment h_{B;58}, by revealing H56 and H78 (according\nto him) ==> S10\n\n[S10. state: (h_{A;56}, h_{A;78}), (h_{B;56}, h_{B;78})]\n  // Like S7, iterate on a disagreeing child\n  - Anyone: if h_{A;56} == h_{B;56} ==> continue challenge on H78 //\nNon-executed FSM cases omitted for brevity\n  - Anyone: if h_{A;56} != h_{B;56} ==> S11\n\nGetting there! The subtree now commits to just two computation steps.\n\n[S11. state: h_{A;56}, h_{B;56}]\n  // This is analogous to S5 and S8.\n  - Alice opens the commitment h_{A;56}, by revealing H5 and H6 (according\nto her) ==> S12\n\n[S12. state: (h_{A;5}, h_{A;6}), h_{B;56}]\n  - Bob opens the commitment h_{B;56}, by revealing H5 and H6 (according to\nhim) ==> S13\n\n[S13. state: (h_{A;5}, h_{A;6}), (h_{B;5}, h_{B;6})]\n  // Like S7 and S10, iterate on a disagreeing child\n  - Anyone: if h_{A;5} == h_{B;5} ==> S14\n  - Anyone: if h_{A;5} != h_{B;5} ==> continue challenge on H5 //\nNon-executed FSM cases omitted for brevity\n\nWe are now at the crucial stage: the commitment corresponds to a leaf of\nthe computation trace Merkle tree.\n\n[S14. state: h_{A;6}, h_{B;6}]\n  - Alice can take all the money if she can open h_{A;6} to a correct \"n =>\nn + n\" computation step\n  - Bob can take all the money if he can open h_{B;6} to a correct \"n => n\n+ n\" computation step\n\nThe challenge now ends quickly: Bob's hash commits to the computation step\n\"64 => 128\".\nInstead, Alice's step is the incorrect \"64 => 127\".\n\nIt's not difficult to convince oneself that, as long as the hash function\nis collision-free and the computation is deterministic, only the honest\nparty can provide correct data for this final step.\n(The bisection protocol can't do anything useful if both parties provide\nincorrect data; arguably, that is not a very interesting scenario!)\n\nCrucially, the operation in the single step is so simple that Script can\nverify it.\n\n=====\n\nIf you read until here: thank you, this was the first execution of a\nchallenge in MATT covenants!\n\nOf course, there are a few things missing in the above protocol:\n- Bonds should be added in order to incentivize cooperation.\n- The omitted FSM steps (corresponding to branches of the challenge that\nwere never taken) need to be computed nonetheless when preparing the\ncovenant.\n- Additional transitions should be added at every step (always allow\ncooperative behavior; forfait after a timeout if it's the other party's\nturn).\n- Some of those consecutive \"forced\" steps can be contracted in a single\nstep; I felt this sequence is more logical to explain the protocol, but\nimplementations would want to optimize it.\n\nYet, _all_ the code and scripts of the bisection protocol are independent\nof the actual execution, and can be precomputed (bottom up, starting from\nthe leaves) before the initial covenant is created - therefore, before x, y\nand z are chosen and committed to.\n\nWhile here each leaf is doing the same operation (doubling a number), it is\nwell-known that arbitrary computation can be decomposed in very simple\nelementary functions (like NAND gates, if we want to be minimalistic).\n\nI hope this helps in clarifying the role of the bisection protocol in smart\ncontracts using MATT covenants.\n\nBest,\nSalvatore\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221112/b63202de/attachment.html>"
            },
            {
                "author": "Rijndael",
                "date": "2022-11-30T19:42:08",
                "message_text_only": "Hello Salvatore,\n\nReally interesting idea. The walk-through of the challenge protocol helped.\n\nIn the final state:\n\n[S14. state: h_{A;6}, h_{B;6}]\n- Alice can take all the money if she can open h_{A;6} to a correct \"n => n + n\" computation step\n- Bob can take all the money if he can open h_{B;6} to a correct \"n => n + n\" computation step\n\nMy understanding of your scheme for encoding execution traces is that each leaf is (previous-state, operation, post-state) So in this case when we get to the conflicting step of the execution traces, alice might reveal something like (x=64, x+x, x=127) and bob might reveal something like (x=64, x+x, x=128). So in order for the covenant to enforce which state-transition is valid (who can spend the money), that means that `x+x` needs to be evaluated in script to tell who has posted the incorrect state. Am I understanding this final step of the bisection protocol correctly?\n\n-rijndael\n\nOn 11/12/22 10:04 AM, Salvatore Ingala via bitcoin-dev wrote:\n\n> Hi Antoine,\n> It appears that my explanation of the relationship between the covenant and the bisection protocol is still unclear; I'll do my best to clarify.\n>\n> The bisection's Merkle tree never ends up on-chain, in any form. Therefore, a bigger computation does not end up in a bigger witness size, which is key to the scalability of the approach. Only in the case of a challenge, it will result in a (logarithmically) longer chain of transactions to resolve it. This chain of transactions could be mapped to a root-to-leaf path in the Merkle tree of the computation trace.\n>\n> The actual computation trace (and the corresponding Merkle tree) is only computed by the parties when they execute the computation.\n> What's in the tapleaves is only the valid transitions at the current state of the protocol; that is, the valid transitions in the Finite State Machine (and possibly other valid exit conditions that remove the covenant encumbrance, if any).\n>\n> The bisection protocol only makes sense as a step in a larger protocol that makes use of it.\n>\n> Perhaps presenting the protocol in a less-than-general case might help to understand it. So let's play a simpler game using a protocol that includes a fraud proof.\n>\n> Alice claims that she knows how to multiply by 256, while Bob doesn't believe her. So they make a bet: they each commit 1 coin; then Bob choses a number x; then Alice computes y = 256*x by doubling x eight times (expensive multiplications were disabled in a tragic DDoS accident), and publishes the result y. Bob independently computes 256 * x (he has a friend who is a mathematician, he'll know how to do it). If the result is not y, Bob will start a challenge; otherwise, Alice wins and takes the money.\n>\n> (The example is of course artificial, as redoing the computation in Script is cheaper than executing the fraud proof in this case!)\n>\n> What follows is an actual execution of the protocol. In the following, each [Si] is a UTXO corresponding to some possible FSM node, starting with the S0, the UTXO with 1+1 = 2 coins. Each line with \"-\" is a possible transition (script in the taptree), specifying what is the next FSM node after the \"==>\" symbol; the encumbrance in the scripts enforce that the state of the next UTXO is updated correctly (details omitted below), and any other necessary conditions to ensure the integrity of the protocol.\n>\n> =====\n>\n> [S0]: Initial UTXO\n> - only Bob can spend, he must choose his number x ==> S1\n>\n> [S1; state: x]:\n> - only Alice can spend, she publishes her answer y ==> S2\n>\n> [S2. state: x, y]:\n> - after 1 day: Alice won, she can take the money // Happy case! Usually that's the end\n> - Bob disagrees with the answer, post z as his answer. ==> S3\n>\n> The challenge starts here! Let's put some actual numbers. x = 2; y = 508; z = 512.\n>\n> This is what Alice computed:\n>\n> 2 => 4 => 8 => 16 => 32 => 64 => 127 => 254 => 508\n>\n> This is what Bob computed:\n>\n> 2 => 4 => 8 => 16 => 32 => 64 => 128 => 256 => 512\n>\n> At this time, we don't know who is right. They both built a tree that looks like this (ASCII art only working in fixed-width font):\n>\n> ___H18___\n> / \\\n> / \\\n> H14 H58\n> / \\ / \\\n> / \\ / \\\n> / \\ / \\\n> H12 H34 H56 H78\n> / \\ / \\ / \\ / \\\n> H1 H2 H3 H4 H5 H6 H7 H8\n>\n> Remember that each internal node commits to: the state of the computation before the leftmost leaf in the subtree, the state after the rightmost leaf, and the hash of sub-trace for the sub-tree. Each leaf just commits to that intermediate computation step (and the operation, which here is always \"double the input\"). For example, H4 commits to \"16 => 32\" according to both Alice's and Bob's computation traces.\n>\n> (From our privileged point of view, we can foresee that the earliest disagreement is on the 6th step of the computation: \"64 => 127\" according to Alice, \"64 => 128\" according to Bob).\n>\n> Let's denote h_{A;18} (resp. h_{B;18}) all the information committed to in the node H18, according to Alice (resp. Bob). Similarly for all the other nodes.\n>\n> [S3. state: x, y, z]: Challenge starts!\n> - Alice posts the root of her computation trace h_{A;18} ==> S4\n>\n> [S4. state: x, y, z, h_{A;18}]\n> - Bob posts the root of her computation trace h_{B;18} ==> S5\n>\n> Since they disagree, it must be the case that h_{A;18} != h_{B;18}.\n>\n> [S5. state: x, y, z, h_{A;18}, h_{B;18}]\n> - Alice opens the commitment h_{A;18}, by revealing H14 and H58 (according to her) ==> S6\n>\n> Note that in this last transition (going to S6), the covenant enforces that the child commitments are compatible: the transition is only valid if the starting state of the computation according to h_{A;14} is compatible with h_{A;18} (that is, it's equal to x); similarly the end state of the computation in h_{A;58} must be y, and h_{A;18} can be recomputed from the data provided (ensuring the integrity of the Merkle tree).\n> This is true for all the commitment openings below.\n>\n> [S6. state: x, y, z, (h_{A;14}, h_{A;58}), h_{B;18}]\n> - Bob opens the commitment h_{B;18}, by revealing H14 and H58 (according to him) ==> S7\n>\n> [S7. state: x, y, z, (h_{A;18}, h_{A;14}, h_{A;58}), (h_{B;18}, h_{B;14}, h_{B;58})]\n> // We now need to choose a child where there is disagreement.\n> // If both children don't match, iterate on the left child.\n> - Anyone: if h_{A;14} == h_{B;14} ==> S8\n> - Anyone: if h_{A;14} != h_{B;14} ==> Continue challenge on H14 // Non-executed FSM cases omitted for brevity\n>\n> At this point, the disagreement over the root is settled: Alice and Bob agree on the first half of the computation, but they disagree over the second half. Therefore, in S8 the protocol continues over H58.\n>\n> [S8. state: h_{A;58}, h_{B;58}]\n> // This is analogous to S5, just with half of the computation steps.\n> - Alice opens the commitment h_{A;58}, by revealing H56 and H78 (according to her) ==> S9\n>\n> [S9. state: (h_{A;56}, h_{A;78}), h_{B;58}]\n> - Bob opens the commitment h_{B;58}, by revealing H56 and H78 (according to him) ==> S10\n>\n> [S10. state: (h_{A;56}, h_{A;78}), (h_{B;56}, h_{B;78})]\n> // Like S7, iterate on a disagreeing child\n> - Anyone: if h_{A;56} == h_{B;56} ==> continue challenge on H78 // Non-executed FSM cases omitted for brevity\n> - Anyone: if h_{A;56} != h_{B;56} ==> S11\n>\n> Getting there! The subtree now commits to just two computation steps.\n>\n> [S11. state: h_{A;56}, h_{B;56}]\n> // This is analogous to S5 and S8.\n> - Alice opens the commitment h_{A;56}, by revealing H5 and H6 (according to her) ==> S12\n>\n> [S12. state: (h_{A;5}, h_{A;6}), h_{B;56}]\n> - Bob opens the commitment h_{B;56}, by revealing H5 and H6 (according to him) ==> S13\n>\n> [S13. state: (h_{A;5}, h_{A;6}), (h_{B;5}, h_{B;6})]\n> // Like S7 and S10, iterate on a disagreeing child\n> - Anyone: if h_{A;5} == h_{B;5} ==> S14\n> - Anyone: if h_{A;5} != h_{B;5} ==> continue challenge on H5 // Non-executed FSM cases omitted for brevity\n>\n> We are now at the crucial stage: the commitment corresponds to a leaf of the computation trace Merkle tree.\n>\n> [S14. state: h_{A;6}, h_{B;6}]\n> - Alice can take all the money if she can open h_{A;6} to a correct \"n => n + n\" computation step\n> - Bob can take all the money if he can open h_{B;6} to a correct \"n => n + n\" computation step\n>\n> The challenge now ends quickly: Bob's hash commits to the computation step \"64 => 128\".\n> Instead, Alice's step is the incorrect \"64 => 127\".\n>\n> It's not difficult to convince oneself that, as long as the hash function is collision-free and the computation is deterministic, only the honest party can provide correct data for this final step.\n> (The bisection protocol can't do anything useful if both parties provide incorrect data; arguably, that is not a very interesting scenario!)\n>\n> Crucially, the operation in the single step is so simple that Script can verify it.\n>\n> =====\n>\n> If you read until here: thank you, this was the first execution of a challenge in MATT covenants!\n>\n> Of course, there are a few things missing in the above protocol:\n> - Bonds should be added in order to incentivize cooperation.\n> - The omitted FSM steps (corresponding to branches of the challenge that were never taken) need to be computed nonetheless when preparing the covenant.\n> - Additional transitions should be added at every step (always allow cooperative behavior; forfait after a timeout if it's the other party's turn).\n> - Some of those consecutive \"forced\" steps can be contracted in a single step; I felt this sequence is more logical to explain the protocol, but implementations would want to optimize it.\n>\n> Yet, _all_ the code and scripts of the bisection protocol are independent of the actual execution, and can be precomputed (bottom up, starting from the leaves) before the initial covenant is created - therefore, before x, y and z are chosen and committed to.\n>\n> While here each leaf is doing the same operation (doubling a number), it is well-known that arbitrary computation can be decomposed in very simple elementary functions (like NAND gates, if we want to be minimalistic).\n>\n> I hope this helps in clarifying the role of the bisection protocol in smart contracts using MATT covenants.\n>\n> Best,\n> Salvatore\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221130/fabd885f/attachment-0001.html>"
            },
            {
                "author": "Rijndael",
                "date": "2022-11-30T22:09:33",
                "message_text_only": "Hello Salvatore,\n\nI found my answer re-reading your original post:\n> During the arbitration phase (say at the i-th leaf node of M_T), any party can win the challenge by providing correct values for tr_i = (st_i, op_i, st_{i + 1}). Crucially, only one party is able to provide correct values, and Script can verify that indeed the state moves from st_i to st_{i + 1} by executing op_i. The challenge is over.\n\nThat raises leads to a different question: Alice initially posts a commitment to an execution trace of `f(x) = y`, `x`, and `y`. Bob Disagrees with `y` so starts the challenge protocol. Is there a commitment to `f`? In other words, the dispute protocol (as I read it) finds the leftmost step in Alice and Bob's execution traces that differ, and then rewards the coins to the participant who's \"after-value\" is computed by the step's operation applied to the \"before value\". But if the participants each present valid steps but with different operations, who wins? In other words, Alice could present [64, DECREMENT, 63] and Bob could present [64, INCREMENT, 65]. Those steps don't match, but both are valid. Is there something to ensure that before the challenge protocol starts, that the execution trace that Alice posts is for the right computation and not a different computation that yields a favorable result for her (and for which she can generate a valid merkle tree)?\n\nThanks!\n\n-rijndael\n\nOn 11/30/22 2:42 PM, Rijndael via bitcoin-dev wrote:\n\n> Hello Salvatore,\n>\n> Really interesting idea. The walk-through of the challenge protocol helped.\n>\n> In the final state:\n>\n> [S14. state: h_{A;6}, h_{B;6}]\n> - Alice can take all the money if she can open h_{A;6} to a correct \"n => n + n\" computation step\n> - Bob can take all the money if he can open h_{B;6} to a correct \"n => n + n\" computation step\n>\n> My understanding of your scheme for encoding execution traces is that each leaf is (previous-state, operation, post-state) So in this case when we get to the conflicting step of the execution traces, alice might reveal something like (x=64, x+x, x=127) and bob might reveal something like (x=64, x+x, x=128). So in order for the covenant to enforce which state-transition is valid (who can spend the money), that means that `x+x` needs to be evaluated in script to tell who has posted the incorrect state. Am I understanding this final step of the bisection protocol correctly?\n>\n> -rijndael\n>\n> On 11/12/22 10:04 AM, Salvatore Ingala via bitcoin-dev wrote:\n>\n>> Hi Antoine,\n>> It appears that my explanation of the relationship between the covenant and the bisection protocol is still unclear; I'll do my best to clarify.\n>>\n>> The bisection's Merkle tree never ends up on-chain, in any form. Therefore, a bigger computation does not end up in a bigger witness size, which is key to the scalability of the approach. Only in the case of a challenge, it will result in a (logarithmically) longer chain of transactions to resolve it. This chain of transactions could be mapped to a root-to-leaf path in the Merkle tree of the computation trace.\n>>\n>> The actual computation trace (and the corresponding Merkle tree) is only computed by the parties when they execute the computation.\n>> What's in the tapleaves is only the valid transitions at the current state of the protocol; that is, the valid transitions in the Finite State Machine (and possibly other valid exit conditions that remove the covenant encumbrance, if any).\n>>\n>> The bisection protocol only makes sense as a step in a larger protocol that makes use of it.\n>>\n>> Perhaps presenting the protocol in a less-than-general case might help to understand it. So let's play a simpler game using a protocol that includes a fraud proof.\n>>\n>> Alice claims that she knows how to multiply by 256, while Bob doesn't believe her. So they make a bet: they each commit 1 coin; then Bob choses a number x; then Alice computes y = 256*x by doubling x eight times (expensive multiplications were disabled in a tragic DDoS accident), and publishes the result y. Bob independently computes 256 * x (he has a friend who is a mathematician, he'll know how to do it). If the result is not y, Bob will start a challenge; otherwise, Alice wins and takes the money.\n>>\n>> (The example is of course artificial, as redoing the computation in Script is cheaper than executing the fraud proof in this case!)\n>>\n>> What follows is an actual execution of the protocol. In the following, each [Si] is a UTXO corresponding to some possible FSM node, starting with the S0, the UTXO with 1+1 = 2 coins. Each line with \"-\" is a possible transition (script in the taptree), specifying what is the next FSM node after the \"==>\" symbol; the encumbrance in the scripts enforce that the state of the next UTXO is updated correctly (details omitted below), and any other necessary conditions to ensure the integrity of the protocol.\n>>\n>> =====\n>>\n>> [S0]: Initial UTXO\n>> - only Bob can spend, he must choose his number x ==> S1\n>>\n>> [S1; state: x]:\n>> - only Alice can spend, she publishes her answer y ==> S2\n>>\n>> [S2. state: x, y]:\n>> - after 1 day: Alice won, she can take the money // Happy case! Usually that's the end\n>> - Bob disagrees with the answer, post z as his answer. ==> S3\n>>\n>> The challenge starts here! Let's put some actual numbers. x = 2; y = 508; z = 512.\n>>\n>> This is what Alice computed:\n>>\n>> 2 => 4 => 8 => 16 => 32 => 64 => 127 => 254 => 508\n>>\n>> This is what Bob computed:\n>>\n>> 2 => 4 => 8 => 16 => 32 => 64 => 128 => 256 => 512\n>>\n>> At this time, we don't know who is right. They both built a tree that looks like this (ASCII art only working in fixed-width font):\n>>\n>> ___H18___\n>> / \\\n>> / \\\n>> H14 H58\n>> / \\ / \\\n>> / \\ / \\\n>> / \\ / \\\n>> H12 H34 H56 H78\n>> / \\ / \\ / \\ / \\\n>> H1 H2 H3 H4 H5 H6 H7 H8\n>>\n>> Remember that each internal node commits to: the state of the computation before the leftmost leaf in the subtree, the state after the rightmost leaf, and the hash of sub-trace for the sub-tree. Each leaf just commits to that intermediate computation step (and the operation, which here is always \"double the input\"). For example, H4 commits to \"16 => 32\" according to both Alice's and Bob's computation traces.\n>>\n>> (From our privileged point of view, we can foresee that the earliest disagreement is on the 6th step of the computation: \"64 => 127\" according to Alice, \"64 => 128\" according to Bob).\n>>\n>> Let's denote h_{A;18} (resp. h_{B;18}) all the information committed to in the node H18, according to Alice (resp. Bob). Similarly for all the other nodes.\n>>\n>> [S3. state: x, y, z]: Challenge starts!\n>> - Alice posts the root of her computation trace h_{A;18} ==> S4\n>>\n>> [S4. state: x, y, z, h_{A;18}]\n>> - Bob posts the root of her computation trace h_{B;18} ==> S5\n>>\n>> Since they disagree, it must be the case that h_{A;18} != h_{B;18}.\n>>\n>> [S5. state: x, y, z, h_{A;18}, h_{B;18}]\n>> - Alice opens the commitment h_{A;18}, by revealing H14 and H58 (according to her) ==> S6\n>>\n>> Note that in this last transition (going to S6), the covenant enforces that the child commitments are compatible: the transition is only valid if the starting state of the computation according to h_{A;14} is compatible with h_{A;18} (that is, it's equal to x); similarly the end state of the computation in h_{A;58} must be y, and h_{A;18} can be recomputed from the data provided (ensuring the integrity of the Merkle tree).\n>> This is true for all the commitment openings below.\n>>\n>> [S6. state: x, y, z, (h_{A;14}, h_{A;58}), h_{B;18}]\n>> - Bob opens the commitment h_{B;18}, by revealing H14 and H58 (according to him) ==> S7\n>>\n>> [S7. state: x, y, z, (h_{A;18}, h_{A;14}, h_{A;58}), (h_{B;18}, h_{B;14}, h_{B;58})]\n>> // We now need to choose a child where there is disagreement.\n>> // If both children don't match, iterate on the left child.\n>> - Anyone: if h_{A;14} == h_{B;14} ==> S8\n>> - Anyone: if h_{A;14} != h_{B;14} ==> Continue challenge on H14 // Non-executed FSM cases omitted for brevity\n>>\n>> At this point, the disagreement over the root is settled: Alice and Bob agree on the first half of the computation, but they disagree over the second half. Therefore, in S8 the protocol continues over H58.\n>>\n>> [S8. state: h_{A;58}, h_{B;58}]\n>> // This is analogous to S5, just with half of the computation steps.\n>> - Alice opens the commitment h_{A;58}, by revealing H56 and H78 (according to her) ==> S9\n>>\n>> [S9. state: (h_{A;56}, h_{A;78}), h_{B;58}]\n>> - Bob opens the commitment h_{B;58}, by revealing H56 and H78 (according to him) ==> S10\n>>\n>> [S10. state: (h_{A;56}, h_{A;78}), (h_{B;56}, h_{B;78})]\n>> // Like S7, iterate on a disagreeing child\n>> - Anyone: if h_{A;56} == h_{B;56} ==> continue challenge on H78 // Non-executed FSM cases omitted for brevity\n>> - Anyone: if h_{A;56} != h_{B;56} ==> S11\n>>\n>> Getting there! The subtree now commits to just two computation steps.\n>>\n>> [S11. state: h_{A;56}, h_{B;56}]\n>> // This is analogous to S5 and S8.\n>> - Alice opens the commitment h_{A;56}, by revealing H5 and H6 (according to her) ==> S12\n>>\n>> [S12. state: (h_{A;5}, h_{A;6}), h_{B;56}]\n>> - Bob opens the commitment h_{B;56}, by revealing H5 and H6 (according to him) ==> S13\n>>\n>> [S13. state: (h_{A;5}, h_{A;6}), (h_{B;5}, h_{B;6})]\n>> // Like S7 and S10, iterate on a disagreeing child\n>> - Anyone: if h_{A;5} == h_{B;5} ==> S14\n>> - Anyone: if h_{A;5} != h_{B;5} ==> continue challenge on H5 // Non-executed FSM cases omitted for brevity\n>>\n>> We are now at the crucial stage: the commitment corresponds to a leaf of the computation trace Merkle tree.\n>>\n>> [S14. state: h_{A;6}, h_{B;6}]\n>> - Alice can take all the money if she can open h_{A;6} to a correct \"n => n + n\" computation step\n>> - Bob can take all the money if he can open h_{B;6} to a correct \"n => n + n\" computation step\n>>\n>> The challenge now ends quickly: Bob's hash commits to the computation step \"64 => 128\".\n>> Instead, Alice's step is the incorrect \"64 => 127\".\n>>\n>> It's not difficult to convince oneself that, as long as the hash function is collision-free and the computation is deterministic, only the honest party can provide correct data for this final step.\n>> (The bisection protocol can't do anything useful if both parties provide incorrect data; arguably, that is not a very interesting scenario!)\n>>\n>> Crucially, the operation in the single step is so simple that Script can verify it.\n>>\n>> =====\n>>\n>> If you read until here: thank you, this was the first execution of a challenge in MATT covenants!\n>>\n>> Of course, there are a few things missing in the above protocol:\n>> - Bonds should be added in order to incentivize cooperation.\n>> - The omitted FSM steps (corresponding to branches of the challenge that were never taken) need to be computed nonetheless when preparing the covenant.\n>> - Additional transitions should be added at every step (always allow cooperative behavior; forfait after a timeout if it's the other party's turn).\n>> - Some of those consecutive \"forced\" steps can be contracted in a single step; I felt this sequence is more logical to explain the protocol, but implementations would want to optimize it.\n>>\n>> Yet, _all_ the code and scripts of the bisection protocol are independent of the actual execution, and can be precomputed (bottom up, starting from the leaves) before the initial covenant is created - therefore, before x, y and z are chosen and committed to.\n>>\n>> While here each leaf is doing the same operation (doubling a number), it is well-known that arbitrary computation can be decomposed in very simple elementary functions (like NAND gates, if we want to be minimalistic).\n>>\n>> I hope this helps in clarifying the role of the bisection protocol in smart contracts using MATT covenants.\n>>\n>> Best,\n>> Salvatore\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221130/8371518e/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Merkleize All The Things",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Salvatore Ingala",
                "Antoine Riard",
                "David A. Harding",
                "Rijndael",
                "Peter Todd",
                "ZmnSCPxj",
                "Bram Cohen"
            ],
            "messages_count": 10,
            "total_messages_chars_count": 101677
        }
    },
    {
        "title": "[bitcoin-dev] brickchain",
        "thread_messages": [
            {
                "author": "Erik Aronesty",
                "date": "2022-11-08T14:16:41",
                "message_text_only": "> A) to not increase the workload of full-nodes\n\nyes, this is critical\n\n>  given the competitive nature of PoW itself\n\nvalidating nodes do not compete with PoW, i think maybe you are not sure of\nthe difference between a miner and a node\n\nnodes do validation of transactions, they do this for free, and many of\nthem provide essential services, like SPV validation for mobile\n\n\nB) to not undermine L2 systems like LN.\n\nyes, as a general rule, layered financial systems are vastly superior.  so\nthat risks incurred by edge layers are not propagated fully to the inner\nlayers.  For example L3 projects like TARO and RGB are building on\nlightning with less risk\n\nOn Wed, Oct 19, 2022 at 12:04 PM mm-studios <mm at mm-studios.com> wrote:\n\n> Thanks all for your responses.\n> so is it a no-go is because \"reduced settlement speed is a desirable\n> feature\"?\n>\n> I don';t know what weights more in this consideration:\n> A) to not increase the workload of full-nodes, being \"less difficult to\n> operate\" and hence reduce the chance of some of them giving up which would\n> lead to a negative centralization effect. (a bit cumbersome reasoning in my\n> opinion, given the competitive nature of PoW itself, which introduce an\n> accepted centralization, forcing some miners to give up). In this case the\n> fact is accepted because is decentralized enough.\n> B) to not undermine L2 systems like LN.\n>\n> in any case it is a major no-go reason, if there is not intention to speed\n> up L1.\n> Thanks\n> M\n> ------- Original Message -------\n> On Wednesday, October 19th, 2022 at 3:24 PM, Erik Aronesty <erik at q32.com>\n> wrote:\n>\n> > currently, a miner produce blocks with a limited capacity of\n> transactions that ultimately limits the global settlement throughput to a\n> reduced number of tx/s.\n>\n> reduced settlement speed is a desirable feature and isn't something we\n> need to fix\n>\n> the focus should be on layer 2 protocols that allow the ability to hold &\n> transfer, uncommitted transactions as pools / joins, so that layer 1's\n> decentralization and incentives can remain undisturbed\n>\n> protocols like mweb, for example\n>\n>\n>\n>\n> On Wed, Oct 19, 2022 at 7:34 AM mm-studios via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi Bitcoin devs,\n>> I'd like to share an idea of a method to increase throughput in the\n>> bitcoin network.\n>>\n>> Currently, a miner produce blocks with a limited capacity of transactions\n>> that ultimately limits the global settlement throughput to a reduced number\n>> of tx/s.\n>>\n>> Big-blockers proposed the removal of limits but this didn't come with\n>> undesirable effects that have been widely discussed and rejected.\n>>\n>> The main feature we wanted to preserve is 'small blocks', providing\n>> 'better network effects' I won't focus on them.\n>>\n>> The problem with small blocks is that, once a block is filled\n>> transactions, they are kept back in the mempool, waiting for their turn in\n>> future blocks.\n>>\n>> The following changes in the protocol aim to let all transactions go in\n>> the current block, while keeping the block size small. It requires changes\n>> in the PoW algorithm.\n>>\n>> Currently, the PoW algorithm consists on finding a valid hash for the\n>> block. Its validity is determined by comparing the numeric value of the\n>> block hash with a protocol-defined value difficulty.\n>>\n>> Once a miner finds a nonce for the block that satisfies the condition the\n>> new block becomes valid and can be propagated. All nodes would update their\n>> blockchains with it. (assuming no conflict resolution (orphan blocks, ...)\n>> for clarity).\n>>\n>> This process is meant to happen every 10 minutes in average.\n>>\n>> With this background information (we all already know) I go on to\n>> describe the idea:\n>>\n>> Let's allow a miner to include transactions until the block is filled,\n>> let's call this structure (coining a new term 'Brick'), B0. [brick=block\n>> that doesn't meet the difficulty rule and is filled of tx to its full\n>> capacity]\n>> Since PoW hashing is continuously active, Brick B0 would have a nonce\n>> corresponding to a minimum numeric value of its hash found until it got\n>> filled.\n>>\n>> Fully filled brick B0, with a hash that doesn't meet the difficulty rule,\n>> would be broadcasted and nodes would have it on in a separate fork as usual.\n>>\n>> At this point, instead of discarding transactions, our miner would start\n>> working on a new brick B1, linked with B0 as usual.\n>>\n>> Nodes would allow incoming regular blocks and bricks with hashes that\n>> don't satisfy the difficulty rule, provided the brick is fully filled of\n>> transactions. Bricks not fully filled would be rejected as invalid to\n>> prevent spam (except if constitutes the last brick of a brickchain,\n>> explained below).\n>>\n>> Let's assume that 10 minutes have elapsed and our miner is in a state\n>> where N bricks have been produced and the accumulated PoW calculated using\n>> mathematics (every brick contains a 'minimum hash found', when a series of\n>> 'minimum hashes' is computationally equivalent to the network difficulty is\n>> then the full 'brickchain' is valid as a Block.\n>>\n>> This calculus shall be better defined, but I hope that this idea can\n>> serve as a seed to a BIP, or otherwise deemed absurd, which might be\n>> possible and I'd be delighted to discover why a scheme like this wouldn't\n>> work.\n>>\n>> If it finally worked, it could completely flush mempools, keep\n>> transactions fees low and increase throughput without an increase in the\n>> block size that would raise other concerns related to propagation.\n>>\n>> Thank you.\n>> I look forward to your responses.\n>>\n>> --\n>> Marcos Mayorga\n>> https://twitter.com/KatlasC\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/e572675c/attachment-0001.html>"
            },
            {
                "author": "mm-studios",
                "date": "2022-11-08T14:25:04",
                "message_text_only": "------- Original Message -------\nOn Tuesday, November 8th, 2022 at 2:16 PM, Erik Aronesty <erik at q32.com> wrote:\n\n>> A) to not increase the workload of full-nodes\n>\n> yes, this is critical\n>\n>> given the competitive nature of PoW itself\n>\n> validating nodes do not compete with PoW, i think maybe you are not sure of the difference between a miner and a node\n>\n> nodes do validation of transactions, they do this for free, and many of them provide essential services, like SPV validation for mobile\n\nI think it's pretty clear that the \"competitive nature of PoW\" is not referring to verification nodes (satoshi preferred this other word).\n\n> B) to not undermine L2 systems like LN.\n>\n> yes, as a general rule, layered financial systems are vastly superior. so that risks incurred by edge layers are not propagated fully to the inner layers. For example L3 projects like TARO and RGB are building on lightning with less risk\n\nlayers also add fees to users\n\n> On Wed, Oct 19, 2022 at 12:04 PM mm-studios <mm at mm-studios.com> wrote:\n>\n>> Thanks all for your responses.\n>> so is it a no-go is because \"reduced settlement speed is a desirable feature\"?\n>>\n>> I don';t know what weights more in this consideration:\n>> A) to not increase the workload of full-nodes, being \"less difficult to operate\" and hence reduce the chance of some of them giving up which would lead to a negative centralization effect. (a bit cumbersome reasoning in my opinion, given the competitive nature of PoW itself, which introduce an accepted centralization, forcing some miners to give up). In this case the fact is accepted because is decentralized enough.\n>> B) to not undermine L2 systems like LN.\n>>\n>> in any case it is a major no-go reason, if there is not intention to speed up L1.\n>> Thanks\n>> M\n>>\n>> ------- Original Message -------\n>> On Wednesday, October 19th, 2022 at 3:24 PM, Erik Aronesty <erik at q32.com> wrote:\n>>\n>>>> currently, a miner produce blocks with a limited capacity of transactions that ultimately limits the global settlement throughput to a reduced number of tx/s.\n>>>\n>>> reduced settlement speed is a desirable feature and isn't something we need to fix\n>>>\n>>> the focus should be on layer 2 protocols that allow the ability to hold & transfer, uncommitted transactions as pools / joins, so that layer 1's decentralization and incentives can remain undisturbed\n>>>\n>>> protocols like mweb, for example\n>>>\n>>> On Wed, Oct 19, 2022 at 7:34 AM mm-studios via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> Hi Bitcoin devs,\n>>>> I'd like to share an idea of a method to increase throughput in the bitcoin network.\n>>>>\n>>>> Currently, a miner produce blocks with a limited capacity of transactions that ultimately limits the global settlement throughput to a reduced number of tx/s.\n>>>>\n>>>> Big-blockers proposed the removal of limits but this didn't come with undesirable effects that have been widely discussed and rejected.\n>>>>\n>>>> The main feature we wanted to preserve is 'small blocks', providing 'better network effects' I won't focus on them.\n>>>>\n>>>> The problem with small blocks is that, once a block is filled transactions, they are kept back in the mempool, waiting for their turn in future blocks.\n>>>>\n>>>> The following changes in the protocol aim to let all transactions go in the current block, while keeping the block size small. It requires changes in the PoW algorithm.\n>>>>\n>>>> Currently, the PoW algorithm consists on finding a valid hash for the block. Its validity is determined by comparing the numeric value of the block hash with a protocol-defined value difficulty.\n>>>>\n>>>> Once a miner finds a nonce for the block that satisfies the condition the new block becomes valid and can be propagated. All nodes would update their blockchains with it. (assuming no conflict resolution (orphan blocks, ...) for clarity).\n>>>>\n>>>> This process is meant to happen every 10 minutes in average.\n>>>>\n>>>> With this background information (we all already know) I go on to describe the idea:\n>>>>\n>>>> Let's allow a miner to include transactions until the block is filled, let's call this structure (coining a new term 'Brick'), B0. [brick=block that doesn't meet the difficulty rule and is filled of tx to its full capacity]\n>>>> Since PoW hashing is continuously active, Brick B0 would have a nonce corresponding to a minimum numeric value of its hash found until it got filled.\n>>>>\n>>>> Fully filled brick B0, with a hash that doesn't meet the difficulty rule, would be broadcasted and nodes would have it on in a separate fork as usual.\n>>>>\n>>>> At this point, instead of discarding transactions, our miner would start working on a new brick B1, linked with B0 as usual.\n>>>>\n>>>> Nodes would allow incoming regular blocks and bricks with hashes that don't satisfy the difficulty rule, provided the brick is fully filled of transactions. Bricks not fully filled would be rejected as invalid to prevent spam (except if constitutes the last brick of a brickchain, explained below).\n>>>>\n>>>> Let's assume that 10 minutes have elapsed and our miner is in a state where N bricks have been produced and the accumulated PoW calculated using mathematics (every brick contains a 'minimum hash found', when a series of 'minimum hashes' is computationally equivalent to the network difficulty is then the full 'brickchain' is valid as a Block.\n>>>>\n>>>> This calculus shall be better defined, but I hope that this idea can serve as a seed to a BIP, or otherwise deemed absurd, which might be possible and I'd be delighted to discover why a scheme like this wouldn't work.\n>>>>\n>>>> If it finally worked, it could completely flush mempools, keep transactions fees low and increase throughput without an increase in the block size that would raise other concerns related to propagation.\n>>>>\n>>>> Thank you.\n>>>> I look forward to your responses.\n>>>>\n>>>> --\n>>>> Marcos Mayorgahttps://twitter.com/KatlasC\n>>>>\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/d5ac4343/attachment-0001.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2022-11-08T15:49:10",
                "message_text_only": "> I think it's pretty clear that the \"competitive nature of PoW\" is not\nreferring to verification nodes\n\ncool, so we can agree there is no accepted centralization pressure for\nvalidating nodes then\n\n> layers also add fees to users\n\nsource?  i feel like it's obvious that the tree-like efficiencies should\nreduce fees, but i'd appreciate your research on that topic\n\n\nOn Tue, Nov 8, 2022 at 9:25 AM mm-studios <mm at mm-studios.com> wrote:\n\n>\n> ------- Original Message -------\n> On Tuesday, November 8th, 2022 at 2:16 PM, Erik Aronesty <erik at q32.com>\n> wrote:\n>\n> > A) to not increase the workload of full-nodes\n>\n> yes, this is critical\n>\n> > given the competitive nature of PoW itself\n>\n> validating nodes do not compete with PoW, i think maybe you are not sure\n> of the difference between a miner and a node\n>\n> nodes do validation of transactions, they do this for free, and many of\n> them provide essential services, like SPV validation for mobile\n>\n>\n>\n> I think it's pretty clear that the \"competitive nature of PoW\" is not\n> referring to verification nodes (satoshi preferred this other word).\n>\n> B) to not undermine L2 systems like LN.\n>\n> yes, as a general rule, layered financial systems are vastly superior. so\n> that risks incurred by edge layers are not propagated fully to the inner\n> layers. For example L3 projects like TARO and RGB are building on lightning\n> with less risk\n>\n>\n> layers also add fees to users\n>\n>\n> On Wed, Oct 19, 2022 at 12:04 PM mm-studios <mm at mm-studios.com> wrote:\n>\n>> Thanks all for your responses.\n>> so is it a no-go is because \"reduced settlement speed is a desirable\n>> feature\"?\n>>\n>> I don';t know what weights more in this consideration:\n>> A) to not increase the workload of full-nodes, being \"less difficult to\n>> operate\" and hence reduce the chance of some of them giving up which would\n>> lead to a negative centralization effect. (a bit cumbersome reasoning in my\n>> opinion, given the competitive nature of PoW itself, which introduce an\n>> accepted centralization, forcing some miners to give up). In this case the\n>> fact is accepted because is decentralized enough.\n>> B) to not undermine L2 systems like LN.\n>>\n>> in any case it is a major no-go reason, if there is not intention to\n>> speed up L1.\n>> Thanks\n>> M\n>> ------- Original Message -------\n>> On Wednesday, October 19th, 2022 at 3:24 PM, Erik Aronesty <erik at q32.com>\n>> wrote:\n>>\n>> > currently, a miner produce blocks with a limited capacity of\n>> transactions that ultimately limits the global settlement throughput to a\n>> reduced number of tx/s.\n>>\n>> reduced settlement speed is a desirable feature and isn't something we\n>> need to fix\n>>\n>> the focus should be on layer 2 protocols that allow the ability to hold &\n>> transfer, uncommitted transactions as pools / joins, so that layer 1's\n>> decentralization and incentives can remain undisturbed\n>>\n>> protocols like mweb, for example\n>>\n>>\n>>\n>>\n>> On Wed, Oct 19, 2022 at 7:34 AM mm-studios via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Hi Bitcoin devs,\n>>> I'd like to share an idea of a method to increase throughput in the\n>>> bitcoin network.\n>>>\n>>> Currently, a miner produce blocks with a limited capacity of\n>>> transactions that ultimately limits the global settlement throughput to a\n>>> reduced number of tx/s.\n>>>\n>>> Big-blockers proposed the removal of limits but this didn't come with\n>>> undesirable effects that have been widely discussed and rejected.\n>>>\n>>> The main feature we wanted to preserve is 'small blocks', providing\n>>> 'better network effects' I won't focus on them.\n>>>\n>>> The problem with small blocks is that, once a block is filled\n>>> transactions, they are kept back in the mempool, waiting for their turn in\n>>> future blocks.\n>>>\n>>> The following changes in the protocol aim to let all transactions go in\n>>> the current block, while keeping the block size small. It requires changes\n>>> in the PoW algorithm.\n>>>\n>>> Currently, the PoW algorithm consists on finding a valid hash for the\n>>> block. Its validity is determined by comparing the numeric value of the\n>>> block hash with a protocol-defined value difficulty.\n>>>\n>>> Once a miner finds a nonce for the block that satisfies the condition\n>>> the new block becomes valid and can be propagated. All nodes would update\n>>> their blockchains with it. (assuming no conflict resolution (orphan blocks,\n>>> ...) for clarity).\n>>>\n>>> This process is meant to happen every 10 minutes in average.\n>>>\n>>> With this background information (we all already know) I go on to\n>>> describe the idea:\n>>>\n>>> Let's allow a miner to include transactions until the block is filled,\n>>> let's call this structure (coining a new term 'Brick'), B0. [brick=block\n>>> that doesn't meet the difficulty rule and is filled of tx to its full\n>>> capacity]\n>>> Since PoW hashing is continuously active, Brick B0 would have a nonce\n>>> corresponding to a minimum numeric value of its hash found until it got\n>>> filled.\n>>>\n>>> Fully filled brick B0, with a hash that doesn't meet the difficulty\n>>> rule, would be broadcasted and nodes would have it on in a separate fork as\n>>> usual.\n>>>\n>>> At this point, instead of discarding transactions, our miner would start\n>>> working on a new brick B1, linked with B0 as usual.\n>>>\n>>> Nodes would allow incoming regular blocks and bricks with hashes that\n>>> don't satisfy the difficulty rule, provided the brick is fully filled of\n>>> transactions. Bricks not fully filled would be rejected as invalid to\n>>> prevent spam (except if constitutes the last brick of a brickchain,\n>>> explained below).\n>>>\n>>> Let's assume that 10 minutes have elapsed and our miner is in a state\n>>> where N bricks have been produced and the accumulated PoW calculated using\n>>> mathematics (every brick contains a 'minimum hash found', when a series of\n>>> 'minimum hashes' is computationally equivalent to the network difficulty is\n>>> then the full 'brickchain' is valid as a Block.\n>>>\n>>> This calculus shall be better defined, but I hope that this idea can\n>>> serve as a seed to a BIP, or otherwise deemed absurd, which might be\n>>> possible and I'd be delighted to discover why a scheme like this wouldn't\n>>> work.\n>>>\n>>> If it finally worked, it could completely flush mempools, keep\n>>> transactions fees low and increase throughput without an increase in the\n>>> block size that would raise other concerns related to propagation.\n>>>\n>>> Thank you.\n>>> I look forward to your responses.\n>>>\n>>> --\n>>> Marcos Mayorga\n>>> https://twitter.com/KatlasC\n>>>\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/a734558f/attachment-0001.html>"
            },
            {
                "author": "mm-studios",
                "date": "2022-11-08T16:31:15",
                "message_text_only": "------- Original Message -------\nOn Tuesday, November 8th, 2022 at 3:49 PM, Erik Aronesty <erik at q32.com> wrote:\n\n>> I think it's pretty clear that the \"competitive nature of PoW\" is not referring to verification nodes\n>\n> cool, so we can agree there is no accepted centralization pressure for validating nodes then\n\nThe centralization produced by PoW only affects miners. the rest of nodes are freely distributed.\nin the producer-consumer view consumers (blockchain builders) are satisfactorily distributed. It can't be said so about miners(block producers), who form a quite centralized subsystem with only a handful major pools producing blocks.\n\n>> layers also add fees to users\n>\n> source? i feel like it's obvious that the tree-like efficiencies should reduce fees, but i'd appreciate your research on that topic\n\nsystems(layers) where abuse is controlled by fees add up each one a cost.\n\n> On Tue, Nov 8, 2022 at 9:25 AM mm-studios <mm at mm-studios.com> wrote:\n>\n>> ------- Original Message -------\n>> On Tuesday, November 8th, 2022 at 2:16 PM, Erik Aronesty <erik at q32.com> wrote:\n>>\n>>>> A) to not increase the workload of full-nodes\n>>>\n>>> yes, this is critical\n>>>\n>>>> given the competitive nature of PoW itself\n>>>\n>>> validating nodes do not compete with PoW, i think maybe you are not sure of the difference between a miner and a node\n>>>\n>>> nodes do validation of transactions, they do this for free, and many of them provide essential services, like SPV validation for mobile\n>>\n>> I think it's pretty clear that the \"competitive nature of PoW\" is not referring to verification nodes (satoshi preferred this other word).\n>>\n>>> B) to not undermine L2 systems like LN.\n>>>\n>>> yes, as a general rule, layered financial systems are vastly superior. so that risks incurred by edge layers are not propagated fully to the inner layers. For example L3 projects like TARO and RGB are building on lightning with less risk\n>>\n>> layers also add fees to users\n>>\n>>> On Wed, Oct 19, 2022 at 12:04 PM mm-studios <mm at mm-studios.com> wrote:\n>>>\n>>>> Thanks all for your responses.\n>>>> so is it a no-go is because \"reduced settlement speed is a desirable feature\"?\n>>>>\n>>>> I don';t know what weights more in this consideration:\n>>>> A) to not increase the workload of full-nodes, being \"less difficult to operate\" and hence reduce the chance of some of them giving up which would lead to a negative centralization effect. (a bit cumbersome reasoning in my opinion, given the competitive nature of PoW itself, which introduce an accepted centralization, forcing some miners to give up). In this case the fact is accepted because is decentralized enough.\n>>>> B) to not undermine L2 systems like LN.\n>>>>\n>>>> in any case it is a major no-go reason, if there is not intention to speed up L1.\n>>>> Thanks\n>>>> M\n>>>>\n>>>> ------- Original Message -------\n>>>> On Wednesday, October 19th, 2022 at 3:24 PM, Erik Aronesty <erik at q32.com> wrote:\n>>>>\n>>>>>> currently, a miner produce blocks with a limited capacity of transactions that ultimately limits the global settlement throughput to a reduced number of tx/s.\n>>>>>\n>>>>> reduced settlement speed is a desirable feature and isn't something we need to fix\n>>>>>\n>>>>> the focus should be on layer 2 protocols that allow the ability to hold & transfer, uncommitted transactions as pools / joins, so that layer 1's decentralization and incentives can remain undisturbed\n>>>>>\n>>>>> protocols like mweb, for example\n>>>>>\n>>>>> On Wed, Oct 19, 2022 at 7:34 AM mm-studios via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>>\n>>>>>> Hi Bitcoin devs,\n>>>>>> I'd like to share an idea of a method to increase throughput in the bitcoin network.\n>>>>>>\n>>>>>> Currently, a miner produce blocks with a limited capacity of transactions that ultimately limits the global settlement throughput to a reduced number of tx/s.\n>>>>>>\n>>>>>> Big-blockers proposed the removal of limits but this didn't come with undesirable effects that have been widely discussed and rejected.\n>>>>>>\n>>>>>> The main feature we wanted to preserve is 'small blocks', providing 'better network effects' I won't focus on them.\n>>>>>>\n>>>>>> The problem with small blocks is that, once a block is filled transactions, they are kept back in the mempool, waiting for their turn in future blocks.\n>>>>>>\n>>>>>> The following changes in the protocol aim to let all transactions go in the current block, while keeping the block size small. It requires changes in the PoW algorithm.\n>>>>>>\n>>>>>> Currently, the PoW algorithm consists on finding a valid hash for the block. Its validity is determined by comparing the numeric value of the block hash with a protocol-defined value difficulty.\n>>>>>>\n>>>>>> Once a miner finds a nonce for the block that satisfies the condition the new block becomes valid and can be propagated. All nodes would update their blockchains with it. (assuming no conflict resolution (orphan blocks, ...) for clarity).\n>>>>>>\n>>>>>> This process is meant to happen every 10 minutes in average.\n>>>>>>\n>>>>>> With this background information (we all already know) I go on to describe the idea:\n>>>>>>\n>>>>>> Let's allow a miner to include transactions until the block is filled, let's call this structure (coining a new term 'Brick'), B0. [brick=block that doesn't meet the difficulty rule and is filled of tx to its full capacity]\n>>>>>> Since PoW hashing is continuously active, Brick B0 would have a nonce corresponding to a minimum numeric value of its hash found until it got filled.\n>>>>>>\n>>>>>> Fully filled brick B0, with a hash that doesn't meet the difficulty rule, would be broadcasted and nodes would have it on in a separate fork as usual.\n>>>>>>\n>>>>>> At this point, instead of discarding transactions, our miner would start working on a new brick B1, linked with B0 as usual.\n>>>>>>\n>>>>>> Nodes would allow incoming regular blocks and bricks with hashes that don't satisfy the difficulty rule, provided the brick is fully filled of transactions. Bricks not fully filled would be rejected as invalid to prevent spam (except if constitutes the last brick of a brickchain, explained below).\n>>>>>>\n>>>>>> Let's assume that 10 minutes have elapsed and our miner is in a state where N bricks have been produced and the accumulated PoW calculated using mathematics (every brick contains a 'minimum hash found', when a series of 'minimum hashes' is computationally equivalent to the network difficulty is then the full 'brickchain' is valid as a Block.\n>>>>>>\n>>>>>> This calculus shall be better defined, but I hope that this idea can serve as a seed to a BIP, or otherwise deemed absurd, which might be possible and I'd be delighted to discover why a scheme like this wouldn't work.\n>>>>>>\n>>>>>> If it finally worked, it could completely flush mempools, keep transactions fees low and increase throughput without an increase in the block size that would raise other concerns related to propagation.\n>>>>>>\n>>>>>> Thank you.\n>>>>>> I look forward to your responses.\n>>>>>>\n>>>>>> --\n>>>>>> Marcos Mayorgahttps://twitter.com/KatlasC\n>>>>>>\n>>>>>> _______________________________________________\n>>>>>> bitcoin-dev mailing list\n>>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/5a5a7222/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "brickchain",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "mm-studios",
                "Erik Aronesty"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 26910
        }
    },
    {
        "title": "[bitcoin-dev] Silicon Salon 3: Call for Presentations On Silicon-Logic-Base Cryptographic Acceleration & New Algorithms",
        "thread_messages": [
            {
                "author": "Christopher Allen",
                "date": "2022-11-17T20:32:27",
                "message_text_only": "Blockchain Commons will be facilitating Silicon Salon 3 in mid-January,\ntentatively on January 18th. We will have semiconductor designers, secure\nhardware developers, and other experts present, and we are calling for\nother contributors who are interested in making a presentation focused on\nsilicon-logic-based cryptographic acceleration or support for new\nfunctionality such as Multi-Party Computation (MPC) leveraging hardened\nsemiconductor-based security.\n\nOur Silicon Salons are an ongoing series of virtual salons intended to\nbring together digital wallet developers, semiconductor manufacturers, and\nacademics. The objective:\n\n   - *To ensure that the next generation of cryptographic semiconductors\n   meets everyone\u2019s needs, advancing the entire cryptography industry.*\n   - *Reduce is a gap between wallet requirements and semiconductor\n   development, between academic research and real-world practice; we want to\n   bridge it.*\n\nSome presentations lined up so far are:\n\n   - In pursuit of an open Secure Element: What are the elements that make\n   a semiconductor more or less \u201copen\u201d, and what is really important?\n   - Architectural considerations in creating a semiconductor for the\n   future of MPC.\n\nSee https://www.siliconsalon.info/ for our salons to date. Silicon Salon 3\nwill continue these topics.\n\nIf you are interested in making a presentation at Silicon Salon 3,\nplease contact\nus with a proposal. Include the following:\n\n   1. The title.\n   2. A summary of what your presentation will be about.\n   3. A summary of how that relates to silicon-logic-based cryptographic\n   acceleration & new functionality and/or the general topic of integrating\n   cryptography into new semiconductors. Note that this can be a discussion of\n   capabilities from the point of view of a semiconductor manufacturer, of\n   needs from a wallet manufacturer, or other discussions from someone in the\n   broader decentralized community.\n   4. The name of the presenter(s).\n   5. A description of who they are and how they or their company have the\n   expertise, capability, or reach to benefit the Silicon Salon conversation.\n\nFinal presentations should be about five minutes long, supported by a slide\ndeck or some equivalent, which you will present in our Zoom salon on the\ndate of the salon.\n\nPlease note the following deadlines for Silicon Salon 3 proposals and\ncontributions:\n\n   - *December 23* - Final date for submission of proposals.\n   - *January 4* \u2014 Blockchain Commons selection of proposals.\n   - *January 11* \u2014 Submission of draft slide decks to Blockchain Commons\n   for any comments.\n   - *January 16* \u2014 Submission of final slide decks to Blockchain Commons\n   for inclusion in post-event web pages.\n   - *January 18* \u2014 Presentation at Silicon Salon 3.\n   - *January 25* \u2014 Blockchain Commons finalization of website release of\n   the video, selected Q&A, transcripts, and final presentations.\n\nAlso, please note that the January 18th date is tentative. We are checking\nwith likely participants for conflicts, and ensuring that the holidays\nwon\u2019t cause too much conflict. If it moves, then the January deadlines will\nmove accordingly.\n\nThank you for your interest in Silicon Salon 3 and the future of\nsemiconductor integration with cryptography! If you have any questions or\nwant more information, please email us at team at blockchaincommons.com.\n\nEven if you do not want to present, please Save the Date of January 18th,\n2023, so that you can participate in the conversation. We\u2019ll make an\nannouncement as soon as we\u2019ve finalized the date and have an Eventbrite\npage available for signups.\n\nThank you to our sustaining sponsors who make Silicon Salon possible:\nBitmark, Chia, Cramium Labs (a subsidiary of CrossBar), Foundation, Proxy,\nand Unchained Capitol. We are also seeking additional sponsors. Mail us at\nteam at blockchaincommons.com or become a sponsor on GitHub\n<https://github.com/sponsors/BlockchainCommons> and let us know it\u2019s to\nsupport Silicon Salon!\n\n-- Christopher Allen, Principal Architect & Executive Director, Blockchain\nCommons\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221117/e390ac79/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Silicon Salon 3: Call for Presentations On Silicon-Logic-Base Cryptographic Acceleration & New Algorithms",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Christopher Allen"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4248
        }
    },
    {
        "title": "[bitcoin-dev] Relative txout amounts with a Merkleized Sum Tree and explicit miner fee.",
        "thread_messages": [
            {
                "author": "Andrew Melnychuk Oseen",
                "date": "2022-11-18T21:11:54",
                "message_text_only": "Can output amounts be mapped to a tap branch? For the goal of secure partial spends of a single UTXO? Looking for feedback on this idea. I got it from Taro.\n\nMerkel_tree_root_tweak = tagged_hash(\u201croot\u201d || left_hash || right_hash)\n\nTree_branch = tagged_hash(\u201cbranch\u201d || left_hash || right_hash ) || right_output_sum + left_relative_output_amount\n\nTree_leaf = tagged_hash(\"leaf\" || script ) || relative_output_amount\n\nTransaction Validation:\n\nThere would be one output with an amount that is negative.\n\nThe negative amount would flag this transaction as relative amount spends.\n\nThe miner fee would be the absolute of the output amount.\n\nThe witness would include the txout amount.\n\nTxout is less than other inputs that referencing this output.\n\nQuestions:\n\nWould this require a hard fork?\n\nWould the sum be required in the asset tree?. The sum at the root would be implicitly 1.0. How big can a taproot tree get before it is too cumbersome?\n\nCould multiple taproot trees be put inside a tweak?\n\nAm I missing anything vital?\n\nPossible Benefits\n\nPerhaps slightly increase privacy of output amounts?\n\nReduced growth rate of UTXO\u2019s. This scheme would be consuming N inputs and producing 1 output.\n\nDrawbacks\n\nI think this would disable the ability for output change addresses to be the same as inputs as the spending amounts are absolute.\n\nTransaction Example\n\nInputs : [1.5,.3,.1]\n\nTapTree:\n\nBranch sum :1\n\nChange Address : .5\n\nBranch sum: .5\n\nAlicePubKey: .2\n\nBranch sum: .3\n\nBobPub and BobHash: .1\n\nBranch sum: .2\n\nCaroPub and DavePub and CarolDaveHash : .1\n\nErinPub and CarolDaveHash and after 10days : .1\n\nOutputs: [-.0.001]\n\nAlice spending example\n\nAlice sends to new address : .1 * (sum of Inputs + outputs) = 0.18999\n\nAlice New Change Address = .1 * (sum of Inputs + outputs) = 0.18999\n\nApplication\n\nI think something like this would provide away to onboard a lot of lightning channels with a single UTXO output. An exchange could schedule open lightning channels at certain time intervals, perhaps every 10 minutes. Ideally, people would provide pubkeys and payment, to be placed in a tap leaf. Similar to selling seats for an aircraft flight.\n\nThanks for reading\n\nAndrew\n\nSent with [Proton Mail](https://proton.me/) secure email.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221118/a95e7ca4/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-11-21T23:52:00",
                "message_text_only": "Good morning Andrew,\n\n> \n> \n> Can output amounts be mapped to a tap branch? For the goal of secure partial spends of a single UTXO? Looking for feedback on this idea. I got it from Taro.\n\n\nNot at all.\n\nThe issue you are facing here is that only one tap branch will ever consume the entire input amount.\nThat is: while Taproot has multiple leaves, only exactly one leaf will ever be published onchain and that gets the whole amount.\n\nWhat you want is multiple tree leaves where ALL of them will EVENTUALLY be published, just not right now.\n\nIn that case, look at the tree structures for `OP_CHECKTEMPLATEVERIFY`, which are exactly what you are looking for, and help make `OP_CTV` a reality.\n\nWithout `OP_CHECKTEMPLATEVERIFY` it is possible to use presigned transactions in a tree structure to do this same construction.\nPresigned transactions are known to be larger than `OP_CHECKTEMPLATEVERIFY` --- signatures on taproot are 64 bytes of witness, but an `OP_CHECKTEMPLATEVERIFY` in a P2WSH reveals just 32 bytes of witness plus the `OP_CHECKTEMPLATEVERIFY` opcode.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Rijndael",
                "date": "2022-11-26T00:12:10",
                "message_text_only": "Hello Andrew,\n\nAs ZmnSCPxj mentioned, covenant schemes are probably something that you\nshould be looking at and thinking about. In addition to CTV, I'd also\nrecommend you take a look (if you haven't already) at\n`TAPLEAF_UPDATE_VERIFY`\n(https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019419.html).\n From your description, it sounds like you may be barking up a similar tree.\n\nRijndael\n\n\nOn 11/21/22 6:52 PM, ZmnSCPxj via bitcoin-dev wrote:\n> Good morning Andrew,\n>\n>>\n>> Can output amounts be mapped to a tap branch? For the goal of secure partial spends of a single UTXO? Looking for feedback on this idea. I got it from Taro.\n>\n> Not at all.\n>\n> The issue you are facing here is that only one tap branch will ever consume the entire input amount.\n> That is: while Taproot has multiple leaves, only exactly one leaf will ever be published onchain and that gets the whole amount.\n>\n> What you want is multiple tree leaves where ALL of them will EVENTUALLY be published, just not right now.\n>\n> In that case, look at the tree structures for `OP_CHECKTEMPLATEVERIFY`, which are exactly what you are looking for, and help make `OP_CTV` a reality.\n>\n> Without `OP_CHECKTEMPLATEVERIFY` it is possible to use presigned transactions in a tree structure to do this same construction.\n> Presigned transactions are known to be larger than `OP_CHECKTEMPLATEVERIFY` --- signatures on taproot are 64 bytes of witness, but an `OP_CHECKTEMPLATEVERIFY` in a P2WSH reveals just 32 bytes of witness plus the `OP_CHECKTEMPLATEVERIFY` opcode.\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            }
        ],
        "thread_summary": {
            "title": "Relative txout amounts with a Merkleized Sum Tree and explicit miner fee.",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Andrew Melnychuk Oseen",
                "Rijndael"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 5253
        }
    },
    {
        "title": "[bitcoin-dev] Custom signet for testing full RBF",
        "thread_messages": [
            {
                "author": "alicexbt",
                "date": "2022-11-20T06:36:23",
                "message_text_only": "Hi Bitcoin Developers,\n\nI have setup a [custom signet][0] for testing full RBF. You can connect to one or more of these nodes using `addnode`:\n\n13.115.34.55 (issuer, full-rbf)\nkfupbqwb2yvzzqjomfq5pkem553a6uzp2k73seqn4d46smy7azua.b32.i2p (rbf-optin)\nluvczzzppiqnc2b7poivkxlugafe3uqaj245ebjqxtceio7poaorqcyd.onion (full-rbf)\n\nExample config:\n\n```\nsignet=1\nsignetchallenge=5121035daaa313aada6310340a242af17238cc1fd8849e875940bce65a60ac7e0e0ff751ae\nproxy=127.0.0.1:9050\n\n[signet]\naddnode=luvczzzppiqnc2b7poivkxlugafe3uqaj245ebjqxtceio7poaorqcyd.onion\n\nmempoolfullrbf=1\n```\n\nExample for a simple test case:\n\n- Run 2 nodes\n- Connect node 1 with i2p node and use default opt-in rbf\n- Connect node 2 with node 1 and onion node. This node should use `mempoolfullrbf=1` in config and compile bitcoind using PR [#26454][1] branch\n- Broadcast Tx1 using node 2 and replace with Tx2 using `bumpfee` RPC\n\nIt will be fun to test with more nodes joining this custom signet. If anyone interested to test, please post your bitcoin address in [full-rbf room][2]. We can even setup an explorer if this experiment makes sense.\n\n[0]: https://en.bitcoin.it/wiki/Signet#Custom_Signet\n[1]: https://github.com/bitcoin/bitcoin/pull/26454\n[2]: #full-rbf:matrix.org\n\nSent with Proton Mail secure email.\n\n/dev/fd0"
            },
            {
                "author": "Michael Folkson",
                "date": "2022-11-22T11:20:44",
                "message_text_only": "Hi alicexbt\n\nThanks for setting this up. Generally it seems to me like an excellent idea to set up custom signets (and/or get proposals enabled on the default signet) for testing and experimenting with new proposals.\n\nI have two questions.\n\n1) In this particular case the -mempoolfullrbf configuration option is in the recent Bitcoin Core 24.0 release and so can be used both on mainnet and the default signet, testnet etc. What could be tested on this custom signet that can't be tested on the default signet with Bitcoin Core 24.0? Perhaps there are some things that are easier to test with a smaller custom signet network starting from scratch?\n\n2) I know a number of people have struggled (e.g. [0], [1]) to get a custom signet set up. I think the CTV signet took a while to get set up too. It seems you followed the instructions on the Bitcoin wiki [2] for setting this one up? Was there anything you found difficult or was counterintuitive getting this custom signet set up? You are the sole block signer on this custom signet. How regularly are you mining blocks (e.g. strictly every 10 minutes, replicating the Poisson process on mainnet, adhoc etc?) Are you running this custom signet node on the same machine as a default signet, mainnet, testnet full node? I'm a little tentative to start joining custom signet networks on the same machine that is already running other nodes but perhaps there are no problems. \n\nI'm not sure yet if I have a use case in mind for this particular custom signet but I'm very interested in custom signet setup generally and the docs/resources to make this as easy as possible so thanks again for posting about this.\n\nThanks\nMichael\n\n[0]: https://bitcoin.stackexchange.com/questions/114477/could-someone-share-with-me-some-documentations-or-sites-on-how-to-set-up-a-cust\n[1]: https://bitcoin.stackexchange.com/questions/114724/peer-discovery-on-a-custom-signet-custom-signetchallenge\n[2]: [0]: https://en.bitcoin.it/wiki/Signet#Custom_Signet\n\n--\nMichael Folkson\nEmail: michaelfolkson at protonmail.com\nKeybase: michaelfolkson\nPGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n\n\n------- Original Message -------\nOn Sunday, November 20th, 2022 at 08:36, alicexbt via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n\n> Hi Bitcoin Developers,\n> \n> I have setup a [custom signet][0] for testing full RBF. You can connect to one or more of these nodes using `addnode`:\n> \n> 13.115.34.55 (issuer, full-rbf)\n> kfupbqwb2yvzzqjomfq5pkem553a6uzp2k73seqn4d46smy7azua.b32.i2p (rbf-optin)\n> luvczzzppiqnc2b7poivkxlugafe3uqaj245ebjqxtceio7poaorqcyd.onion (full-rbf)\n> \n> Example config:\n> \n> `signet=1 signetchallenge=5121035daaa313aada6310340a242af17238cc1fd8849e875940bce65a60ac7e0e0ff751ae proxy=127.0.0.1:9050 [signet] addnode=luvczzzppiqnc2b7poivkxlugafe3uqaj245ebjqxtceio7poaorqcyd.onion mempoolfullrbf=1`\n> \n> Example for a simple test case:\n> \n> - Run 2 nodes\n> - Connect node 1 with i2p node and use default opt-in rbf\n> - Connect node 2 with node 1 and onion node. This node should use `mempoolfullrbf=1` in config and compile bitcoind using PR [#26454][1] branch\n> - Broadcast Tx1 using node 2 and replace with Tx2 using `bumpfee` RPC\n> \n> It will be fun to test with more nodes joining this custom signet. If anyone interested to test, please post your bitcoin address in [full-rbf room][2]. We can even setup an explorer if this experiment makes sense.\n> \n> [0]: https://en.bitcoin.it/wiki/Signet#Custom_Signet\n> [1]: https://github.com/bitcoin/bitcoin/pull/26454\n> [2]: #full-rbf:matrix.org\n> \n> Sent with Proton Mail secure email.\n> \n> /dev/fd0\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "alicexbt",
                "date": "2022-11-22T17:09:16",
                "message_text_only": "Hi Michael,\n\n> In this particular case the -mempoolfullrbf configuration option is in the recent Bitcoin Core 24.0 release and so can be used both on mainnet and the default signet, testnet etc. What could be tested on this custom signet that can't be tested on the default signet with Bitcoin Core 24.0? Perhaps there are some things that are easier to test with a smaller custom signet network starting from scratch?\n\n1. Signet miners and dictators are not interested to use full RBF\n2. Testnet is weird and I only use it when a project doesn't support signet\n3. Mainnet v24.0 is not released yet although Peter Todd is trying few things, I am not even sure if it will be available, testing should not depend on politics.\n4. Main/Default Signet miners and dictators did not respond or agree to use full RBF.\n\nTesting is important and I love it. I do not care about others.\n\n> I know a number of people have struggled (e.g. [0], [1]) to get a custom signet set up. I think the CTV signet took a while to get set up too. It seems you followed the instructions on the Bitcoin wiki [2] for setting this one up? Was there anything you found difficult or was counterintuitive getting this custom signet set up? You are the sole block signer on this custom signet. How regularly are you mining blocks (e.g. strictly every 10 minutes, replicating the Poisson process on mainnet, adhoc etc?) Are you running this custom signet node on the same machine as a default signet, mainnet, testnet full node? I'm a little tentative to start joining custom signet networks on the same machine that is already running other nodes but perhaps there are no problems. \n\nI had no issues except this command:\n\n``\n$ ../contrib/signet/miner --cli=\"./bitcoin-cli\" calibrate --grind-cmd=\"./bitcoin-util grind\" --seconds=600\n```\n\nI had no clue we need to wait for some seconds/minutes for output. Although its okay.\n\nI used default settings and it should mine with it forever or my AWS subscription is cancelled. \n\nI am trying to help Bitcoin. Although not a big influencer. If most of the developers think its okay to test it directly on mainnet, there is nothing wrong with it. You will get some insights/bugs from this experiment if enough users try it.\n\n\nSent with Proton Mail secure email.ichael\n\n/dev/fd0\n\n------- Original Message -------\nOn Tuesday, November 22nd, 2022 at 4:50 PM, Michael Folkson <michaelfolkson at protonmail.com> wrote:\n\n\n> Hi alicexbt\n> \n> Thanks for setting this up. Generally it seems to me like an excellent idea to set up custom signets (and/or get proposals enabled on the default signet) for testing and experimenting with new proposals.\n> \n> I have two questions.\n> \n> 1) In this particular case the -mempoolfullrbf configuration option is in the recent Bitcoin Core 24.0 release and so can be used both on mainnet and the default signet, testnet etc. What could be tested on this custom signet that can't be tested on the default signet with Bitcoin Core 24.0? Perhaps there are some things that are easier to test with a smaller custom signet network starting from scratch?\n> \n> 2) I know a number of people have struggled (e.g. 0, 1) to get a custom signet set up. I think the CTV signet took a while to get set up too. It seems you followed the instructions on the Bitcoin wiki 2 for setting this one up? Was there anything you found difficult or was counterintuitive getting this custom signet set up? You are the sole block signer on this custom signet. How regularly are you mining blocks (e.g. strictly every 10 minutes, replicating the Poisson process on mainnet, adhoc etc?) Are you running this custom signet node on the same machine as a default signet, mainnet, testnet full node? I'm a little tentative to start joining custom signet networks on the same machine that is already running other nodes but perhaps there are no problems.\n> \n> I'm not sure yet if I have a use case in mind for this particular custom signet but I'm very interested in custom signet setup generally and the docs/resources to make this as easy as possible so thanks again for posting about this.\n> \n> Thanks\n> Michael\n> \n> 0: https://bitcoin.stackexchange.com/questions/114477/could-someone-share-with-me-some-documentations-or-sites-on-how-to-set-up-a-cust\n> 1: https://bitcoin.stackexchange.com/questions/114724/peer-discovery-on-a-custom-signet-custom-signetchallenge\n> 2: 0: https://en.bitcoin.it/wiki/Signet#Custom_Signet\n> \n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> Keybase: michaelfolkson\n> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n> \n> \n> ------- Original Message -------\n> On Sunday, November 20th, 2022 at 08:36, alicexbt via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:\n> \n> \n> \n> > Hi Bitcoin Developers,\n> > \n> > I have setup a custom signet for testing full RBF. You can connect to one or more of these nodes using `addnode`:\n> > \n> > 13.115.34.55 (issuer, full-rbf)\n> > kfupbqwb2yvzzqjomfq5pkem553a6uzp2k73seqn4d46smy7azua.b32.i2p (rbf-optin)\n> > luvczzzppiqnc2b7poivkxlugafe3uqaj245ebjqxtceio7poaorqcyd.onion (full-rbf)\n> > \n> > Example config:\n> > \n> > `signet=1 signetchallenge=5121035daaa313aada6310340a242af17238cc1fd8849e875940bce65a60ac7e0e0ff751ae proxy=127.0.0.1:9050 [signet] addnode=luvczzzppiqnc2b7poivkxlugafe3uqaj245ebjqxtceio7poaorqcyd.onion mempoolfullrbf=1`\n> > \n> > Example for a simple test case:\n> > \n> > - Run 2 nodes\n> > - Connect node 1 with i2p node and use default opt-in rbf\n> > - Connect node 2 with node 1 and onion node. This node should use `mempoolfullrbf=1` in config and compile bitcoind using PR #26454 branch\n> > - Broadcast Tx1 using node 2 and replace with Tx2 using `bumpfee` RPC\n> > \n> > It will be fun to test with more nodes joining this custom signet. If anyone interested to test, please post your bitcoin address in full-rbf room. We can even setup an explorer if this experiment makes sense.\n> > \n> > Sent with Proton Mail secure email.\n> > \n> > /dev/fd0\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            }
        ],
        "thread_summary": {
            "title": "Custom signet for testing full RBF",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "alicexbt",
                "Michael Folkson"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 11230
        }
    },
    {
        "title": "[bitcoin-dev] Wallet policies for descriptor wallets",
        "thread_messages": [
            {
                "author": "Salvatore Ingala",
                "date": "2022-11-21T11:27:25",
                "message_text_only": "Hi list,\n\nFollowing up on this topic, I now opened a pull request with the BIP\nproposal:\n\n     https://github.com/bitcoin/bips/pull/1389\n\nI also attempted a proof-of-concept of how an integration of wallet\npolicies to HWI might look like:\n\n     https://github.com/bitcoin-core/HWI/pull/647\n\nwhich might help to provide context, and also serves as a demo of the\npossible UX flows with hardware signers (as currently implemented in the\nLedger bitcoin app).\n\nThere are no substantial changes to the initial version proposed to the\nlist:\n- some additional restrictions to the allowed descriptors were added as\nfurther simplifications;\n- added test vectors and observations on backwards compatibility;\n- general improvements to the text.\n\nI look forward to your comments and improvements.\nSalvatore Ingala\n\nOn Thu, 5 May 2022 at 16:32, Salvatore Ingala <salvatore.ingala at gmail.com>\nwrote:\n\n> In the implementation work to implement descriptors and miniscript support\n> in hardware wallets [a][b], I encountered a number of challenges. Some of\n> them are technical in nature (e.g. due to constraints of embedded\n> development). Others are related to the attempts of shaping a good user\n> experience; with bitcoin reaching more people who are not tech-savvy,\n> self-custody is only as secure as what those newcomers can use easily\n> enough.\n>\n> The main tool that I am using to address some of these challenges is a\n> layer that sits _on top_ of descriptors/miniscript, while staying very\n> close to it. Since there is nothing that is vendor-specific in the vast\n> majority of the approach I'm currently using, I tried to distill it here\n> for your comments, and will propose a BIP if this is deemed valuable.\n>\n> I called the language \"wallet policies\" (suggestions for a better name are\n> welcome). I believe an approach based on wallet policies can benefit all\n> hardware wallets (stateless or not) that want to securely support complex\n> scripts; moreover, wallet policies are close enough to descriptors that\n> their integration should be extremely easy for any software wallet that is\n> currently using descriptors.\n>\n> [a]: https://blog.ledger.com/bitcoin-2 - early demo\n> [b]: https://blog.ledger.com/miniscript-is-coming - miniscript example\n>\n>\n> Salvatore Ingala\n>\n>\n> ======================================================\n>\n> This document starts with a discussion on the motivation for wallet\n> policies, followed by their formal definition, and some recommendations for\n> implementations.\n>\n> == Rationale ==\n>\n> Output script descriptors [1] were introduced in bitcoin-core as a way to\n> represent collections of output scripts. It is a very general and flexible\n> language, designed to catch all the possible use-cases of bitcoin wallets\n> (that is, if you know the script and you have the necessary keys, it will\n> be possible to sign transactions with bitcoin-core's descriptor-based\n> wallets).\n>\n> Unfortunately, descriptors are not a perfect match for the typical usage\n> of hardware wallets. Most hardware wallets have the following limitations\n> compared to a general-purpose machine running bitcoin-core:\n>\n> - they are embedded devices with limited RAM and computational power;\n> - they might not be able to import additional private keys (all the keys\n> are generated from a single seed via [BIP-32](\n> https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki));\n> - they might not have permanent storage (*stateless* hardware wallet\n> design).\n>\n> Moreover, other limitations like the limited size of the screen might\n> affect what design choices are available in practice. Therefore, minimizing\n> the size of the information shown on-screen is important for a good user\n> experience.\n>\n> A more native, compact representation of the wallet receive/change would\n> also benefit the UX of software wallets using descriptors to represent\n> software wallets using descriptors/miniscript for multisignature or other\n> complex locking conditions.\n>\n> === Security and UX concerns of scripts in hardware wallets ===\n>\n> For a hardware wallet, allowing the usage of complex scripts presents\n> challenges in terms of both security and user experience.\n>\n> ==== Security issues ====\n>\n> One of the security properties that hardware wallets strive to guarantee\n> is the following: **as long as the user correctly verifies the information\n> that is shown on the hardware wallet's screen before approving, no action\n> can be performed without the user's consent**.\n> This must hold even in scenarios where the attacker has full control of\n> the machine that is connected to the hardware wallet, and can execute\n> arbitrary requests or tamper with the legitimate user's requests.\n>\n> Therefore, it is not at all trivial to allow complex scripts, especially\n> if they contain keys that belong to third parties.\n> The hardware wallet must guarantee that the user knows precisely *what*\n> \"policy\" is being used to spend the funds, and that the \"unspent\" funds (if\n> any) will be protected by the same policy. This makes it impossible for an\n> attacker to surreptitiously modify the policy, therefore stealing or\n> burning user's funds.\n>\n> ==== UX issues ====\n>\n> With miniscript (and taproot trees) allowing substantially more complex\n> spending policies to be used, it becomes more challenging to make sure that\n> the user is able _in practice_ to verify the information on the screen.\n> Therefore, there are two fundamental design goals to strive for:\n> - Minimize the amount of information that is shown on screen - so that the\n> user can actually validate it.\n> - Minimize the number of times the user has to validate such information.\n>\n> Designing a secure protocol for the coordination of a descriptor wallet\n> among distant parties is also a challenging problem that is out of scope in\n> this document. See BIP-129 [2] for an approach designed for multisignature\n> wallets.\n>\n> === Policy registration as a solution ===\n>\n> A solution to address the security concerns, and part of the UX concerns,\n> is to have a *registration* flow for the wallet policy in the hardware\n> wallet. The \"wallet policy\" must contain enough information to generate all\n> the relevant addresses/scripts, and for the hardware wallet to identify the\n> keys that it controls and that are needed to spend the funds sent to those\n> addresses.\n>\n> Before a new policy is used for the first time, the user will register a\n> `wallet policy` into the hardware wallet. While the details of the process\n> are out of scope in this document, the flow should be something similar to\n> the following:\n>\n> 1) The software wallet initiates a _wallet policy registration_ on the\n> hardware wallet; the information should include the wallet policy, but also\n> a unique *name* that identifies the policy.\n> 2) The hardware wallet shows the wallet policy to the user using the\n> secure screen.\n> 3) After inspecting the policy and comparing it with a trusted source (for\n> example a printed backup), the user approves the policy.\n> 4) If stateful, the hardware wallet persists the policy in its permanent\n> memory; if stateless, it returns a \"proof of registration\".\n>\n> The details of how to create a proof of registration are out of scope for\n> this document; using a *message authentication codes* on a hash committing\n> to the wallet policy, its name and any additional metadata is an effective\n> solution if correctly executed.\n>\n> Once a policy is registered, the hardware wallet can perform the usual\n> operations securely:\n> - generating receive and change addresses;\n> - showing addresses on the secure screen;\n> - sign transactions spending from a wallet, while correctly identifying\n> change addresses and computing the transaction fees.\n>\n> Before any of the actions mentioned above, the hardware wallet will\n> retrieve the policy from its permanent storage if stateful; if stateless it\n> will validate the _proof of registration_ before using the wallet policy\n> provided by the client.\n> Once the previously registered policy is correctly identified and approved\n> by the user (for example by its name), and *as long as the policy\n> registration was executed securely*, hardware wallets can provide a user\n> experience similar to the usual one for single-signature transactions.\n>\n> === Avoiding blowup in descriptor size ===\n>\n> While reusing a pubkey in different branches of a miniscript is explicitly\n> forbidden by miniscript (as it has certain negative security implications),\n> it is still reasonable to reuse the same *xpub* in multiple places, albeit\n> with different final steps of derivation (so that the actual pubkeys that\n> are used in the script are indeed different).\n>\n> For example, using Taproot, a *3*-of-*5* multisignature wallet could use:\n> - a key path with a 5-of-5 MuSig\n> - a script tree with a tree of 10 different 3-of-3 MuSig2 scripts, that\n> are generated, plus a leaf with a fallback *3*-of-*5* multisignature using\n> plain multisignature (with `OP_CHECKSIGADD`).\n>\n> This could look similar to:\n>\n> ```\n> tr(musig2(xpubA,xpubB,xpubC,xpubD,xpubE)/<0;1>/*), {\n>   {\n>     {\n>       pk(musig2(xpubA,xpubB,xpubC)/<2;3>/*),\n>       {\n>         pk(musig2(xpubA,xpubB,xpubD)/<4;5>/*)\n>         pk(musig2(xpubA,xpubB,xpubE)/<6;7>/*),\n>       }\n>     },\n>     {\n>       pk(musig2(xpubA,xpubC,xpubD)/<8;9>/*),\n>       {\n>         pk(musig2(xpubA,xpubC,xpubE)/<10;11>/*),\n>         pk(musig2(xpubA,xpubD,xpubE)/<12;13>/*)\n>       }\n>     }\n>   },\n>   {\n>     {\n>       pk(musig2(xpubB,xpubC,xpubD)/<14;15>/*),\n>       pk(musig2(xpubB,xpubC,xpubE)/<16;17>/*)\n>     },\n>     {\n>       pk(musig2(xpubB,xpubD,xpubE)/<18;19>/*),\n>       {\n>         pk(musig2(xpubC,xpubD,xpubE)/<20;21>/*),\n>         sortedmulti_a(3,\n>           xpubA/<22;23>/*,\n>           xpubB/<22;23>/*,\n>           xpubC/<22;23>/*,\n>           xpubD/<22;23>/*,\n>           xpubE/<22;23>/*)\n>       }\n>     }\n>   }\n> })\n> ```\n>\n> Note that each root xpub appears 8 times. With xpubs being up to 118 bytes\n> long, the length of the full descriptor can get extremely long (the problem\n> gets *exponentially* worse with larger multisignature schemes).\n>\n> Replacing the common part of the key with a short key placeholder and\n> moving the key expression separately helps to keep the size of the wallet\n> policy small, which is crucial to allow human inspection in the\n> registration flow.\n>\n> === Restrictions on the supported descriptors ====\n>\n> The policy language proposed in this document purposely targets only a\n> stricter subset of the output descriptors language, and it attempts to\n> generalize in the most natural way the approach that is already used for\n> single-signature *accounts* (as described in BIP-44 [3], BIP-49 [4], BIP-84\n> [5], or BIP-86 [6]), or in multisignature setups (see for example BIP-48\n> [7] and BIP-87 [8]).\n>\n> Unlike the BIPs mentioned above, it is not tied to any specific script\n> template, as it applies to arbitrary scripts that can be represented with\n> descriptors and miniscript.\n>\n> Supporting only a reduced feature set when compared to output descriptors\n> helps in implementations (especially on hardware wallets), while attempting\n> to capture all the common use cases. More features can be added in the\n> future if motivated by real world necessity.\n>\n> By keeping the structure of the wallet policy language very close to that\n> of descriptors, it should be straightforward to:\n> - write wallet policy parsers;\n> - extract the descriptors defined by a wallet policy;\n> - convert a pair of descriptors describing a wallet \"account\" used in\n> current implementations into the corresponding wallet policy.\n>\n>\n> == Wallet policies ==\n>\n> This section formally defines wallet policies, and how they relate to\n> output script descriptors.\n>\n> === Formal definition ===\n>\n> A wallet policy is composed by a wallet descriptor template, together with\n> a vector of key information items.\n>\n> ==== Wallet descriptor template ====\n>\n> A wallet descriptor template is a `SCRIPT` expression.\n>\n> `SCRIPT` expressions:\n> - `sh(SCRIPT)` (top level only): P2SH embed the argument.\n> - `wsh(SCRIPT)` (top level or inside `sh` only): P2WSH embed the argument.\n> - `pkh(KP)` (not inside `tr`): P2PKH output for the given public key (use\n> `addr` if you only know the pubkey hash).\n> - `wpkh(KP)` (top level or inside `sh` only): P2WPKH output for the given\n> compressed pubkey.\n> - `multi(k,KP_1,KP_2,...,KP_n)`: k-of-n multisig script.\n> - `sortedmulti(k,KP_1,KP_2,...,KP_n)`: k-of-n multisig script with keys\n> sorted lexicographically in the resulting script.\n> - `tr(KP)` or `tr(KP,TREE)` (top level only): P2TR output with the\n> specified key as internal key, and optionally a tree of script paths.\n> - any valid miniscript template (inside `wsh` or `tr` only).\n>\n> `TREE` expressions:\n> - any `SCRIPT` expression\n> - An open brace `{`, a `TREE` expression, a comma `,`, a `TREE`\n> expression, and a closing brace `}`\n>\n> Note: \"miniscript templates\" are not formally defined in this version of\n> the document, but it is straightforward to adapt this approach.\n>\n> `KP` expressions (key placeholders) consist of\n> - a single character `@`\n> - followed by a non-negative decimal number, with no leading zeros (except\n> for `@0`).\n> - possibly followed by either:\n>   - the string  `/**`, or\n>   - a string of the form `/<NUM;NUM>/*`, for two distinct decimal numbers\n> `NUM` representing unhardened derivations\n>\n> The `/**` in the placeholder template represents commonly used paths for\n> receive/change addresses, and is equivalent to `<0;1>`.\n>\n> The placeholder `@i` for some number *i* represents the *i*-th key in the\n> vector of key origin information (which must be of size at least *i* + 1,\n> or the wallet policy is invalid).\n>\n> ==== Key informations vector ====\n>\n> Each element of the key origin information vector is a `KEY` expression.\n>\n> - Optionally, key origin information, consisting of:\n>   - An open bracket `[`\n>   - Exactly 8 hex characters for the fingerprint of the master key from\n> which this key is derived from (see [BIP32](\n> https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki) for\n> details)\n>   - Followed by zero or more `/NUM'` path elements to indicate hardened\n> derivation steps between the fingerprint and the xpub that follows\n>   - A closing bracket `]`\n> - Followed by the actual key, which is either\n>   - a hex-encoded pubkey, which is either\n>     - inside `wpkh` and `wsh`, only compressed public keys are permitted\n> (exactly 66 hex characters starting with `02` or `03`.\n>     - inside `tr`, x-only pubkeys are also permitted (exactly 64 hex\n> characters).\n>   - a serialized extended public key (`xpub`) (as defined in [BIP 32](\n> https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki))\n>\n> The placeholder `@i` for some number *i* represents the *i*-th key in the\n> vector of key orIgin information (which must be of size at least *i* + 1,\n> or the wallet policy is invalid).\n>\n> The policy template is invalid if any placeholder `@i` has derivation\n> steps while the corresponding `(i+1)`-th element of the keys vector is not\n> an xpub.\n>\n> ==== Additional rules ====\n>\n> The wallet policy is invalid if any placeholder expression with additional\n> derivation steps is used when the corresponding key information is not an\n> xpub.\n>\n> The key information vector *should* be ordered so that placeholder `@i`\n> never appear for the first time before an occurrence of `@j`  for some `j <\n> i`; for example, the first placeholder is always `@0`, the next one is\n> `@1`, etc.\n>\n> === Descriptor derivation ===\n>\n> From a wallet descriptor template (and the associated vector of key\n> informations), one can therefore obtain the 1-dimensional descriptor for\n> receive and change addresses by:\n>\n> - replacing each key placeholder with the corresponding key origin\n> information;\n> - replacing every `/**`  with `/0/*` for the receive descriptor, and\n> `/1/*` for the change descriptor;\n> - replacing every `/<M,N>` with  `/M` for the receive descriptor, and `/N`\n> for the change descriptor.\n>\n> For example, the wallet descriptor `pkh(@0/**)` with key information\n> `[\"[d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL\"]`\n> produces the following two descriptors:\n>\n> - Receive descriptor:\n> `pkh([d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL/0/*)`\n>\n> - Change descriptor:\n> `pkh([d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL/1/*)`\n>\n> === Implementation guidelines ===\n>\n> Implementations must not necessarily implement all of the possible wallet\n> policies defined by this standard, but it is recommended to clearly\n> document any limitation.\n>\n> Implementations can add additional metadata that is stored together with\n> the wallet policy for the purpose of wallet policy registration and later\n> usage. Metadata can be vendor-specific and is out of the scope of this\n> document.\n>\n> Any implementation in a general-purpose software wallet allowing arbitrary\n> scripts (or any scripts that involve external cosigners) should put great\n> care into a process for backing up a wallet policy. In fact, unlike typical\n> single-signature scenarios, the seed alone is no longer enough to discover\n> wallet policies with existing funds, and the loss of the backup is likely\n> to lead to permanent loss of funds.\n>\n> Avoiding key reuse among different wallet accounts is also extremely\n> important, but out of scope for this document.\n>\n> == Examples ==\n>\n> Some examples of wallet descriptor templates (vectors of keys omitted for\n> simplicity):\n> - Template for a native segwit account:\n>   wpkh(@0/**)\n> - Template for a taproot BIP86 account:\n>   tr(@0/**)\n> - Template for a native segwit 2-of-3:\n>   wsh(sortedmulti(2, at 0/**, at 1/**, at 2/**))\n> - Template with miniscript for \"1 of 2 equally likely keys\":\n>   wsh(or_b(pk(@0/**),s:pk(@1/**)))\n>\n> More examples (esp. targeting miniscript on taproot) will be added in the\n> future.\n>\n> == References ==\n>\n> * [1] - Output Script Descriptors:\n> https://github.com/bitcoin/bitcoin/blob/master/doc/descriptors.md\n> * [2] - BIP-129 (Bitcoin Secure Multisig Setup):\n> https://github.com/bitcoin/bips/blob/master/bip-0129.mediawiki\n> * [3] - BIP-44:\n> https://github.com/bitcoin/bips/blob/master/bip-0044.mediawiki\n> * [4] - BIP-49:\n> https://github.com/bitcoin/bips/blob/master/bip-0049.mediawiki\n> * [5] - BIP-84:\n> https://github.com/bitcoin/bips/blob/master/bip-0084.mediawiki\n> * [6] - BIP-86:\n> https://github.com/bitcoin/bips/blob/master/bip-0086.mediawiki\n> * [7] - BIP-48:\n> https://github.com/bitcoin/bips/blob/master/bip-0048.mediawiki\n> * [8] - BIP-87:\n> https://github.com/bitcoin/bips/blob/master/bip-0087.mediawiki\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221121/7e1792e5/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Wallet policies for descriptor wallets",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Salvatore Ingala"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 19107
        }
    },
    {
        "title": "[bitcoin-dev] Ephemeral Anchors: Fixing V3 Package RBF againstpackage limit pinning",
        "thread_messages": [
            {
                "author": "Greg Sanders",
                "date": "2022-11-30T15:32:36",
                "message_text_only": "Small update.\n\nA bit ago I went ahead and implemented ephemeral anchors on top of the V3\nproposal to see what the complexity looks like:\nhttps://github.com/bitcoin/bitcoin/pull/26403\n\nRoughly 130 loc excluding tests, using OP_2 instead of OP_TRUE to not camp\nthe value that is used elsewhere.\n\nPlease let me know if you have any early feedback on this!\n\nGreg\n\nOn Thu, Oct 20, 2022 at 9:42 AM Greg Sanders <gsanders87 at gmail.com> wrote:\n\n> So it doesn't look like I'm ignoring a good question:\n>\n> No solid noninteractive ideas, unless we get some very flexible sighash\n> softfork. Interactively, I think you can get collaborative fee bumps under\n> the current consensus regime and ephemeral anchors. The child will just be\n> built with inputs from different people.\n>\n> On Wed, Oct 19, 2022 at 11:12 AM James O'Beirne <james.obeirne at gmail.com>\n> wrote:\n>\n>> I'm also very happy to see this proposal, since it gets us closer to\n>> having a mechanism that allows the contribution to feerate in an\n>> \"unauthenticated\" way, which seems to be a very helpful feature for vaults\n>> and other contracting protocols.\n>>\n>> One possible advantage of the sponsors interface -- and I'm curious for\n>> your input here Greg -- is that with sponsors, assuming we relaxed the \"one\n>> sponsor per sponsoree\" constraint, multiple uncoordinated parties can\n>> collaboratively bump a tx's feerate. A simple example would be a batch\n>> withdrawal from an exchange could be created with a low feerate, and then\n>> multiple users with a vested interest of expedited confirmation could all\n>> \"chip in\" to raise the feerate with multiple sponsor transactions.\n>>\n>> Having a single ephemeral output seems to create a situation where a\n>> single UTXO has to shoulder the burden of CPFPing a package. Is there some\n>> way we could (possibly later) amend the ephemeral anchor interface to allow\n>> for this kind of collaborative sponsoring? Could you maybe see \"chained\"\n>> ephemeral anchors that would allow this?\n>>\n>>\n>> On Tue, Oct 18, 2022 at 12:52 PM Jeremy Rubin via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Excellent proposal and I agree it does capture much of the spirit of\n>>> sponsors w.r.t. how they might be used for V3 protocols.\n>>>\n>>> The only drawbacks I see is they don't work for lower tx version\n>>> contracts, so there's still something to be desired there, and that the\n>>> requirement to sweep the output must be incentive compatible for the miner,\n>>> or else they won't enforce it (pass the buck onto the future bitcoiners).\n>>> The Ephemeral UTXO concept can be a consensus rule (see\n>>> https://rubin.io/public/pdfs/multi-txn-contracts.pdf \"Intermediate\n>>> UTXO\") we add later on in lieu of managing them by incentive, so maybe it's\n>>> a cleanup one can punt.\n>>>\n>>> One question I have is if V3 is designed for lightning, and this is\n>>> designed for lightning, is there any sense in requiring these outputs for\n>>> v3? That might help with e.g. anonymity set, as well as potentially keep\n>>> the v3 surface smaller.\n>>>\n>>> On Tue, Oct 18, 2022 at 11:51 AM Greg Sanders via bitcoin-dev <\n>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> > does that effectively mark output B as unspendable once the child\n>>>> gets confirmed?\n>>>>\n>>>> Not at all. It's a normal spend like before, since the parent has been\n>>>> confirmed. It's completely unrestricted, not being bound to any\n>>>> V3/ephemeral anchor restrictions on size, version, etc.\n>>>>\n>>>> On Tue, Oct 18, 2022 at 11:47 AM Arik Sosman via bitcoin-dev <\n>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>\n>>>>> Hi Greg,\n>>>>>\n>>>>> Thank you very much for sharing your proposal!\n>>>>>\n>>>>> I think there's one thing about the second part of your proposal that\n>>>>> I'm missing. Specifically, assuming the scenario of a v3 transaction with\n>>>>> three outputs, A, B, and the ephemeral anchor OP_TRUE. If a child\n>>>>> transaction spends A and OP_TRUE, does that effectively mark output B as\n>>>>> unspendable once the child gets confirmed? If so, isn't the implication\n>>>>> therefore that to safely spend a transaction with an ephemeral anchor, all\n>>>>> outputs must be spent? Thanks!\n>>>>>\n>>>>> Best,\n>>>>> Arik\n>>>>>\n>>>>> On Tue, Oct 18, 2022, at 6:52 AM, Greg Sanders via bitcoin-dev wrote:\n>>>>>\n>>>>> Hello Everyone,\n>>>>>\n>>>>> Following up on the \"V3 Transaction\" discussion here\n>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-September/020937.html\n>>>>> , I would like to elaborate a bit further on some potential follow-on work\n>>>>> that would make pinning severely constrained in many setups].\n>>>>>\n>>>>> V3 transactions may solve bip125 rule#3 and rule#5 pinning attacks\n>>>>> under some constraints[0]. This means that when a replacement is to be made\n>>>>> and propagated, it costs the expected amount of fees to do so. This is a\n>>>>> great start. What's left in this subset of pinning is *package limit*\n>>>>> pinning. In other words, a fee-paying transaction cannot enter the mempool\n>>>>> due to the existing mempool package it is being added to already being too\n>>>>> large in count or vsize.\n>>>>>\n>>>>> Zooming into the V3 simplified scenario for sake of discussion, though\n>>>>> this problem exists in general today:\n>>>>>\n>>>>> V3 transactions restrict the package limit of a V3 package to one\n>>>>> parent and one child. If the parent transaction includes two outputs which\n>>>>> can be immediately spent by separate parties, this allows one party to\n>>>>> disallow a spend from the other. In Gloria's proposal for ln-penalty, this\n>>>>> is worked around by reducing the number of anchors per commitment\n>>>>> transaction to 1, and each version of the commitment transaction has a\n>>>>> unique party's key on it. The honest participant can spend their version\n>>>>> with their anchor and package RBF the other commitment transaction safely.\n>>>>>\n>>>>> What if there's only one version of the commitment transaction, such\n>>>>> as in other protocols like duplex payment channels, eltoo? What about multi\n>>>>> party payments?\n>>>>>\n>>>>> In the package RBF proposal, if the parent transaction is identical to\n>>>>> an existing transaction in the mempool, the parent will be detected and\n>>>>> removed from the package proposal. You are then left with a single V3 child\n>>>>> transaction, which is then proposed for entry into the mempool. In the case\n>>>>> of another parent output already being spent, this is simply rejected,\n>>>>> regardless of feerate of the new child.\n>>>>>\n>>>>> I have two proposed solutions, of which I strongly prefer the latter:\n>>>>>\n>>>>> 1) Expand a carveout for \"sibling eviction\", where if the new child is\n>>>>> paying \"enough\" to bump spends from the same parent, it knocks its sibling\n>>>>> out of the mempool and takes the one child slot. This would solve it, but\n>>>>> is a new eviction paradigm that would need to be carefully worked through.\n>>>>>\n>>>>> 2) Ephemeral Anchors (my real policy-only proposal)\n>>>>>\n>>>>> Ephemeral Anchors is a term which means an output is watermarked as an\n>>>>> output that MUST be spent in a V3 package. We mark this anchor by being the\n>>>>> bare script `OP_TRUE` and of course make these outputs standard to relay\n>>>>> and spend with empty witness data.\n>>>>>\n>>>>> Also as a simplifying assumption, we require the parent transaction\n>>>>> with such an output to be 0-fee. This makes mempool reasoning simpler in\n>>>>> case the child-spend is somehow evicted, guaranteeing the parent will be as\n>>>>> well.\n>>>>>\n>>>>> Implications:\n>>>>>\n>>>>> a) If the ephemeral anchor MUST be spent, we can allow *any* value,\n>>>>> even dust, even 0, without worrying about bloating the utxo set. We relax\n>>>>> this policy for maximum smart contract flexibility and specification\n>>>>> simplicity..\n>>>>>\n>>>>> b) Since this anchor MUST be spent, any spending of other outputs in\n>>>>> the same parent transaction MUST directly double-spend prior spends of the\n>>>>> ephemeral anchor. This causes the 1 block CSV timelock on outputs to be\n>>>>> removed in these situations. This greatly magnifies composability of smart\n>>>>> contracts, as now we can do things like safely splice directly into new\n>>>>> channels, into statechains, your custodial wallet account, your cold\n>>>>> wallet, wherever, without requiring other wallets to support arbitrary\n>>>>> scripts. Also it hurts that 1 CSV time locked scripts may not be miniscript\n>>>>> compatible to begin with...\n>>>>>\n>>>>> c) *Anyone* can bump the transaction, without any transaction key\n>>>>> material. This is essentially achieving Jeremy's Transaction Sponsors (\n>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-September/018168.html)\n>>>>> proposal without consensus changes. As long as someone gets a fully signed\n>>>>> parent, they can execute a bump with minimal wallet tooling. If a\n>>>>> transaction author doesn\u2019t want a \u201csponsor\u201d, do not include the output.\n>>>>>\n>>>>> d) Lightning Carve-out(\n>>>>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-October/002240.html)\n>>>>> is superseded by this logic, as we are not restricted to two immediately\n>>>>> spendable output scenarios. In its place, robust multi-party fee bumping is\n>>>>> possible.\n>>>>>\n>>>>> e) This also benefits more traditional wallet scenarios, as change\n>>>>> outputs can no longer be pinned, and RBF/CPFP becomes robust. Payees in\n>>>>> simple spends cannot pin you. Batched payouts become a lot less painful.\n>>>>> This was one of the motivating use cases that created the term \u201cpinning\u201d in\n>>>>> the first place(\n>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-February/015717.html),\n>>>>> even if LN/L2 discussion has largely overtaken it due to HTLC theft risks.\n>>>>>\n>>>>> Open Question(s):\n>>>>>\n>>>>>\n>>>>>    1.\n>>>>>\n>>>>>    If we allow non-zero value in ephemeral outputs, does this open up\n>>>>>    a MEV we are worried about? Wallets should toss all the value directly to\n>>>>>    fees, and add their own additional fees on top, otherwise miners have\n>>>>>    incentive to make the smallest utxo burn transaction to claim those funds.\n>>>>>    They just confirmed your parent transaction anyways, so do we care?\n>>>>>    2.\n>>>>>\n>>>>>    SIGHASH_GROUP like constructs would allow uncommitted ephemeral\n>>>>>    anchors to be added at spend time, depending on spending requirements.\n>>>>>    SIGHASH_SINGLE already allows this.\n>>>>>\n>>>>>\n>>>>>\n>>>>>\n>>>>> Hopefully this gives people something to consider as we move forward\n>>>>> in thinking about mempool design within the constraints we have today.\n>>>>>\n>>>>>\n>>>>> Greg\n>>>>>\n>>>>> 0: With V3 transactions where you have \"veto power\" over all the\n>>>>> inputs in that transaction. Therefore something like ANYONECANPAY is still\n>>>>> broken. We need a more complex solution, which I\u2019m punting for the sake of\n>>>>> progress.\n>>>>> _______________________________________________\n>>>>> bitcoin-dev mailing list\n>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>\n>>>>>\n>>>>> _______________________________________________\n>>>>> bitcoin-dev mailing list\n>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221130/c6217750/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Ephemeral Anchors: Fixing V3 Package RBF againstpackage limit pinning",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Greg Sanders"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 11933
        }
    }
]