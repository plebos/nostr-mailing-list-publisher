[
    {
        "title": "[bitcoin-dev] BIP-341: Committing to all scriptPubKeys in the signature message",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2020-05-01T06:57:09",
                "message_text_only": "Hi Andrew,\n\nIf you use SIGHASH_ALL it shall sign the COutPoints of all inputs which\ncommit to the scriptPubKeys of the txn.\n\nThus the 341 hash doesn't need to sign any additional data.\n\nAs a metadata protocol you can provide all input transactions to check the\nscriptPubKeys.\n\nBest,\n\nJeremy\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n\n\nOn Thu, Apr 30, 2020 at 1:22 AM Andrew Kozlik via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi everyone,\n>\n> In the current draft of BIP-0341 [1] the signature message commits to the\n> scriptPubKey of the output being spent by the input. I propose that the\n> signature message should commit to the scriptPubKeys of *all* transaction\n> inputs.\n>\n> In certain applications like CoinJoin, a wallet has to deal with\n> transactions containing external inputs. To calculate the actual amount\n> that the user is spending, the wallet needs to reliably determine for each\n> input whether it belongs to the wallet or not. Without such a mechanism an\n> adversary can fool the wallet into displaying incorrect information about\n> the amount being spent, which can result in theft of user funds [2].\n>\n> In order to ascertain non-ownership of an input which is claimed to be\n> external, the wallet needs the scriptPubKey of the previous output spent by\n> this input. It must acquire the full transaction being spent and verify its\n> hash against that which is given in the outpoint. This is an obstacle in\n> the implementation of lightweight air-gapped wallets and hardware wallets\n> in general. If the signature message would commit to the scriptPubKeys of\n> all transaction inputs, then the wallet would only need to acquire the\n> scriptPubKey of the output being spent without having to acquire and verify\n> the hash of the entire previous transaction. If an attacker would provide\n> an incorrect scriptPubKey, then that would cause the wallet to generate an\n> invalid signature message.\n>\n> Note that committing only to the scriptPubKey of the output being spent is\n> insufficient for this application, because the scriptPubKeys which are\n> needed to ascertain non-ownership of external inputs are precisely the ones\n> that would not be included in any of the signature messages produced by the\n> wallet.\n>\n> The obvious way to implement this is to add another hash to the signature\n> message:\n> sha_scriptPubKeys (32): the SHA256 of the serialization of all\n> scriptPubKeys of the previous outputs spent by this transaction.\n>\n> Cheers,\n> Andrew Kozlik\n>\n> [1]\n> https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki#common-signature-message\n> [2]\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-August/014843.html\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200430/362a5066/attachment-0001.html>"
            },
            {
                "author": "Andrew Kozlik",
                "date": "2020-05-01T08:48:41",
                "message_text_only": "Hi Jeremy,\n\nWhat you are saying is correct and I am not disputing that there is\nsufficient cryptographic commitment in the signature message. As I tried to\nexplain, my proposal is about avoiding the need for the metadata protocol\nyou speak of. Avoiding such a protocol has been a design goal in both\nBIP-143 [1, 2] and BIP-341 [3, 4], because having to acquire each of the\ntransactions being spent in their entirety places a significant burden on\noffline signing devices.\n\nCheers,\nAndrew\n\n[1]\nhttps://github.com/bitcoin/bips/blob/master/bip-0143.mediawiki#motivation\n[2] https://bitcointalk.org/index.php?topic=181734.0\n[3]\nhttps://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki#cite_note-16\n[4]\nhttps://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki#cite_note-17\n\nOn Fri, May 1, 2020 at 8:56 AM Jeremy <jlrubin at mit.edu> wrote:\n\n> Hi Andrew,\n>\n> If you use SIGHASH_ALL it shall sign the COutPoints of all inputs which\n> commit to the scriptPubKeys of the txn.\n>\n> Thus the 341 hash doesn't need to sign any additional data.\n>\n> As a metadata protocol you can provide all input transactions to check the\n> scriptPubKeys.\n>\n> Best,\n>\n> Jeremy\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n>\n>\n> On Thu, Apr 30, 2020 at 1:22 AM Andrew Kozlik via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi everyone,\n>>\n>> In the current draft of BIP-0341 [1] the signature message commits to the\n>> scriptPubKey of the output being spent by the input. I propose that the\n>> signature message should commit to the scriptPubKeys of *all* transaction\n>> inputs.\n>>\n>> In certain applications like CoinJoin, a wallet has to deal with\n>> transactions containing external inputs. To calculate the actual amount\n>> that the user is spending, the wallet needs to reliably determine for each\n>> input whether it belongs to the wallet or not. Without such a mechanism an\n>> adversary can fool the wallet into displaying incorrect information about\n>> the amount being spent, which can result in theft of user funds [2].\n>>\n>> In order to ascertain non-ownership of an input which is claimed to be\n>> external, the wallet needs the scriptPubKey of the previous output spent by\n>> this input. It must acquire the full transaction being spent and verify its\n>> hash against that which is given in the outpoint. This is an obstacle in\n>> the implementation of lightweight air-gapped wallets and hardware wallets\n>> in general. If the signature message would commit to the scriptPubKeys of\n>> all transaction inputs, then the wallet would only need to acquire the\n>> scriptPubKey of the output being spent without having to acquire and verify\n>> the hash of the entire previous transaction. If an attacker would provide\n>> an incorrect scriptPubKey, then that would cause the wallet to generate an\n>> invalid signature message.\n>>\n>> Note that committing only to the scriptPubKey of the output being spent\n>> is insufficient for this application, because the scriptPubKeys which are\n>> needed to ascertain non-ownership of external inputs are precisely the ones\n>> that would not be included in any of the signature messages produced by the\n>> wallet.\n>>\n>> The obvious way to implement this is to add another hash to the signature\n>> message:\n>> sha_scriptPubKeys (32): the SHA256 of the serialization of all\n>> scriptPubKeys of the previous outputs spent by this transaction.\n>>\n>> Cheers,\n>> Andrew Kozlik\n>>\n>> [1]\n>> https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki#common-signature-message\n>> [2]\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-August/014843.html\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200501/a04d22c8/attachment-0001.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2020-05-01T12:23:07",
                "message_text_only": "While I'm not entirely convinced yet that accertaining non-ownership of an\ninput is a robust method of solving the problem here, I also see little\nreason not to amend BIP-341 as proposed. The ScriptPubKeys in question is\nalready indirectly covered through the outpoints, so it is just a matter of\noptimization.  Furthermore in the consensus code, the ScriptPubKeys are\npart of the UTXO data set, and it is already being retrieved as part of the\ntransaction checking process, so it is readily available.\n\nI'm not sure how much my opinion on the topic matters, but I did include\nthis kind of functionality in my design for Simplicity on Elements, and I\nhave been leaning towards adding this kind of functionality in my Bitcoin\ndemo application of Simplicity.\n\nRegarding specifics, I personally think it would be better to keep the\nhashes of the ScriptPubKeys separate from the hashes of the input values.\nThis way anyone only interested in input values does not need to wade\nthrough what are, in principle, arbitrarily long ScriptPubKeys in order to\ncheck the input values (which each fixed size).  To that end, I would also\n(and independently) propose separating the hashing of the output values\nfrom the output ScriptPubKeys in `sha_outputs` so again, applications\ninterested only in summing the values of the outputs (for instance to\ncompute fees) do not have to wade through those arbitrarily long\nScriptPubKeys in the outputs.\n\nOn Thu, Apr 30, 2020 at 4:22 AM Andrew Kozlik via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi everyone,\n>\n> In the current draft of BIP-0341 [1] the signature message commits to the\n> scriptPubKey of the output being spent by the input. I propose that the\n> signature message should commit to the scriptPubKeys of *all* transaction\n> inputs.\n>\n> In certain applications like CoinJoin, a wallet has to deal with\n> transactions containing external inputs. To calculate the actual amount\n> that the user is spending, the wallet needs to reliably determine for each\n> input whether it belongs to the wallet or not. Without such a mechanism an\n> adversary can fool the wallet into displaying incorrect information about\n> the amount being spent, which can result in theft of user funds [2].\n>\n> In order to ascertain non-ownership of an input which is claimed to be\n> external, the wallet needs the scriptPubKey of the previous output spent by\n> this input. It must acquire the full transaction being spent and verify its\n> hash against that which is given in the outpoint. This is an obstacle in\n> the implementation of lightweight air-gapped wallets and hardware wallets\n> in general. If the signature message would commit to the scriptPubKeys of\n> all transaction inputs, then the wallet would only need to acquire the\n> scriptPubKey of the output being spent without having to acquire and verify\n> the hash of the entire previous transaction. If an attacker would provide\n> an incorrect scriptPubKey, then that would cause the wallet to generate an\n> invalid signature message.\n>\n> Note that committing only to the scriptPubKey of the output being spent is\n> insufficient for this application, because the scriptPubKeys which are\n> needed to ascertain non-ownership of external inputs are precisely the ones\n> that would not be included in any of the signature messages produced by the\n> wallet.\n>\n> The obvious way to implement this is to add another hash to the signature\n> message:\n> sha_scriptPubKeys (32): the SHA256 of the serialization of all\n> scriptPubKeys of the previous outputs spent by this transaction.\n>\n> Cheers,\n> Andrew Kozlik\n>\n> [1]\n> https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki#common-signature-message\n> [2]\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-August/014843.html\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200501/cc57f1b0/attachment.html>"
            },
            {
                "author": "Greg Sanders",
                "date": "2020-05-01T12:25:53",
                "message_text_only": "For what it's worth this measure had been discussed as a lightweight way of\ninforming offline signers if inputs were segwit or not for malleability\nanalysis reasons. So there's at least a couple direct use-cases it seems.\n\nOn Fri, May 1, 2020, 8:23 AM Russell O'Connor via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> While I'm not entirely convinced yet that accertaining non-ownership of an\n> input is a robust method of solving the problem here, I also see little\n> reason not to amend BIP-341 as proposed. The ScriptPubKeys in question is\n> already indirectly covered through the outpoints, so it is just a matter of\n> optimization.  Furthermore in the consensus code, the ScriptPubKeys are\n> part of the UTXO data set, and it is already being retrieved as part of the\n> transaction checking process, so it is readily available.\n>\n> I'm not sure how much my opinion on the topic matters, but I did include\n> this kind of functionality in my design for Simplicity on Elements, and I\n> have been leaning towards adding this kind of functionality in my Bitcoin\n> demo application of Simplicity.\n>\n> Regarding specifics, I personally think it would be better to keep the\n> hashes of the ScriptPubKeys separate from the hashes of the input values.\n> This way anyone only interested in input values does not need to wade\n> through what are, in principle, arbitrarily long ScriptPubKeys in order to\n> check the input values (which each fixed size).  To that end, I would also\n> (and independently) propose separating the hashing of the output values\n> from the output ScriptPubKeys in `sha_outputs` so again, applications\n> interested only in summing the values of the outputs (for instance to\n> compute fees) do not have to wade through those arbitrarily long\n> ScriptPubKeys in the outputs.\n>\n> On Thu, Apr 30, 2020 at 4:22 AM Andrew Kozlik via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi everyone,\n>>\n>> In the current draft of BIP-0341 [1] the signature message commits to the\n>> scriptPubKey of the output being spent by the input. I propose that the\n>> signature message should commit to the scriptPubKeys of *all* transaction\n>> inputs.\n>>\n>> In certain applications like CoinJoin, a wallet has to deal with\n>> transactions containing external inputs. To calculate the actual amount\n>> that the user is spending, the wallet needs to reliably determine for each\n>> input whether it belongs to the wallet or not. Without such a mechanism an\n>> adversary can fool the wallet into displaying incorrect information about\n>> the amount being spent, which can result in theft of user funds [2].\n>>\n>> In order to ascertain non-ownership of an input which is claimed to be\n>> external, the wallet needs the scriptPubKey of the previous output spent by\n>> this input. It must acquire the full transaction being spent and verify its\n>> hash against that which is given in the outpoint. This is an obstacle in\n>> the implementation of lightweight air-gapped wallets and hardware wallets\n>> in general. If the signature message would commit to the scriptPubKeys of\n>> all transaction inputs, then the wallet would only need to acquire the\n>> scriptPubKey of the output being spent without having to acquire and verify\n>> the hash of the entire previous transaction. If an attacker would provide\n>> an incorrect scriptPubKey, then that would cause the wallet to generate an\n>> invalid signature message.\n>>\n>> Note that committing only to the scriptPubKey of the output being spent\n>> is insufficient for this application, because the scriptPubKeys which are\n>> needed to ascertain non-ownership of external inputs are precisely the ones\n>> that would not be included in any of the signature messages produced by the\n>> wallet.\n>>\n>> The obvious way to implement this is to add another hash to the signature\n>> message:\n>> sha_scriptPubKeys (32): the SHA256 of the serialization of all\n>> scriptPubKeys of the previous outputs spent by this transaction.\n>>\n>> Cheers,\n>> Andrew Kozlik\n>>\n>> [1]\n>> https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki#common-signature-message\n>> [2]\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-August/014843.html\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200501/5712467f/attachment.html>"
            },
            {
                "author": "Jeremy",
                "date": "2020-05-02T04:35:41",
                "message_text_only": "At the end of the day I don't really care that much I just prefer something\nthat doesn't throw taproot in for another review cycle.\n\nA side effect of this proposal is it would seem to make it not possible to\nproduce a signature for a transaction without having access to the inputs.\nThis is limiting for a number of cases where you don't care about that\ndata. There are a litany of use cases where you don't want to have\nSIGHASH_ALL behavior, and having to sign the scriptpubkeys breaks that. So\nat the very least it should respect other flags.\n\nI also don't really understand the exact attack. So you submit a\ntransaction to the wallet asking them to sign input 10. They sign. They've\ncommitted to the signature being bound to the specific COutpoint and input\nindex, so I don't see how they wouldn't be required to sign a second\nsignature with the other output too? Is there an attack you can describe\nend-to-end relying on this behavior?\n\nIf you look at the TXID hash the vouts are one of the last fields\nserialized. this makes it possible (at least, I think) to do a midstate\nproof so that all you are providing is the hash midstate, and the relevant\ntransaction output,  the siblings after, and the locktime. So you get to\nskip all the input data, the witness data, and most of the output data.\n\nThis sort of data can easily go into the proprietary use (maybe becoming\nwell defined if there's a standardization push) area in PSBT, so that\nhardware devices can get easy access to it. All they have to do to verify\nis to finalize the hash against that buffer and match to the correct input.\n\n\nAs an alternative proposal, I think you can just make a separate BIP for\nsome new sigash flags that can be reviewed separately from taproot. There's\na lot of value in investing in figuring out more granular controls over\nwhat the signature hash is you sign, which may have some exciting\ncontracting implications!\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Fri, May 1, 2020 at 5:26 AM Greg Sanders via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> For what it's worth this measure had been discussed as a lightweight way\n> of informing offline signers if inputs were segwit or not for malleability\n> analysis reasons. So there's at least a couple direct use-cases it seems.\n>\n> On Fri, May 1, 2020, 8:23 AM Russell O'Connor via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> While I'm not entirely convinced yet that accertaining non-ownership of\n>> an input is a robust method of solving the problem here, I also see little\n>> reason not to amend BIP-341 as proposed. The ScriptPubKeys in question is\n>> already indirectly covered through the outpoints, so it is just a matter of\n>> optimization.  Furthermore in the consensus code, the ScriptPubKeys are\n>> part of the UTXO data set, and it is already being retrieved as part of the\n>> transaction checking process, so it is readily available.\n>>\n>> I'm not sure how much my opinion on the topic matters, but I did include\n>> this kind of functionality in my design for Simplicity on Elements, and I\n>> have been leaning towards adding this kind of functionality in my Bitcoin\n>> demo application of Simplicity.\n>>\n>> Regarding specifics, I personally think it would be better to keep the\n>> hashes of the ScriptPubKeys separate from the hashes of the input values.\n>> This way anyone only interested in input values does not need to wade\n>> through what are, in principle, arbitrarily long ScriptPubKeys in order to\n>> check the input values (which each fixed size).  To that end, I would also\n>> (and independently) propose separating the hashing of the output values\n>> from the output ScriptPubKeys in `sha_outputs` so again, applications\n>> interested only in summing the values of the outputs (for instance to\n>> compute fees) do not have to wade through those arbitrarily long\n>> ScriptPubKeys in the outputs.\n>>\n>> On Thu, Apr 30, 2020 at 4:22 AM Andrew Kozlik via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Hi everyone,\n>>>\n>>> In the current draft of BIP-0341 [1] the signature message commits to\n>>> the scriptPubKey of the output being spent by the input. I propose that the\n>>> signature message should commit to the scriptPubKeys of *all* transaction\n>>> inputs.\n>>>\n>>> In certain applications like CoinJoin, a wallet has to deal with\n>>> transactions containing external inputs. To calculate the actual amount\n>>> that the user is spending, the wallet needs to reliably determine for each\n>>> input whether it belongs to the wallet or not. Without such a mechanism an\n>>> adversary can fool the wallet into displaying incorrect information about\n>>> the amount being spent, which can result in theft of user funds [2].\n>>>\n>>> In order to ascertain non-ownership of an input which is claimed to be\n>>> external, the wallet needs the scriptPubKey of the previous output spent by\n>>> this input. It must acquire the full transaction being spent and verify its\n>>> hash against that which is given in the outpoint. This is an obstacle in\n>>> the implementation of lightweight air-gapped wallets and hardware wallets\n>>> in general. If the signature message would commit to the scriptPubKeys of\n>>> all transaction inputs, then the wallet would only need to acquire the\n>>> scriptPubKey of the output being spent without having to acquire and verify\n>>> the hash of the entire previous transaction. If an attacker would provide\n>>> an incorrect scriptPubKey, then that would cause the wallet to generate an\n>>> invalid signature message.\n>>>\n>>> Note that committing only to the scriptPubKey of the output being spent\n>>> is insufficient for this application, because the scriptPubKeys which are\n>>> needed to ascertain non-ownership of external inputs are precisely the ones\n>>> that would not be included in any of the signature messages produced by the\n>>> wallet.\n>>>\n>>> The obvious way to implement this is to add another hash to the\n>>> signature message:\n>>> sha_scriptPubKeys (32): the SHA256 of the serialization of all\n>>> scriptPubKeys of the previous outputs spent by this transaction.\n>>>\n>>> Cheers,\n>>> Andrew Kozlik\n>>>\n>>> [1]\n>>> https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki#common-signature-message\n>>> [2]\n>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-August/014843.html\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200501/03f1d2e4/attachment-0001.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2020-05-02T14:26:02",
                "message_text_only": "On Fri, May 01, 2020 at 08:23:07AM -0400, Russell O'Connor wrote:\n> Regarding specifics, I personally think it would be better to keep the\n> hashes of the ScriptPubKeys separate from the hashes of the input values.\n\nI think Andrew's original suggestion achieves this:\n\n>> The obvious way to implement this is to add another hash to the\n>> signature message:\n>>   sha_scriptPubKeys (32): the SHA256 of the serialization of all\n>>   scriptPubKeys of the previous outputs spent by this\n>>   transaction.\n\npresumably with sha_scriptPubKeys' inclusion being conditional on\nhash_type not matching ANYONECANPAY.\n\nWe could possibly also make the \"scriptPubKey\" field dependent on\nhash_type matching ANYONECANPAY, making this not cost any more\nin serialised bytes per signature.\n\nThis would basically mean we're committing to each component of the\nUTXOs being spent:\n\n  without ANYONECANPAY:\n    sha_prevouts commits to the txid hashes and vout indexes (COutPoint)\n    sha_amounts commits to the nValues (Coin.CTxOut.nValue)\n    sha_scriptpubkeys commits to the scriptPubKey (Coin.CTxOut.scriptPubKey)\n\n  with ANYONECANPAY it's the same but just for this input's prevout:\n    outpoint\n    amount\n    scriptPubKey\n\nexcept that we'd arguably still be missing:\n\n    is this a coinbase output? (Coin.fCoinBase)\n    what was the height of the coin? (Coin.nHeight)\n\nMaybe committing to the coinbase flag would have some use, but committing\nto the height would make it hard to chain unconfirmed spends, so at\nleast that part doesn't seem worth adding.\n\n> I would also (and independently) propose\n> separating the hashing of the output values from the output ScriptPubKeys in\n> `sha_outputs` so again, applications interested only in summing the values of\n> the outputs (for instance to compute fees) do not have to wade through those\n> arbitrarily long ScriptPubKeys in the outputs.\n\nIf you didn't verify the output scriptPubKeys, you would *only* be able\nto care about fees since you couldn't verify where any of the funds went?\nAnd you'd only be able to say fees are \"at least x\", since they could be\nmore if one of the scriptPubKeys turned out to be OP_TRUE eg. That might\nalmost make sense for a transaction accelerator that's trying to increase\nthe fees; but only if you were doing it for someone else's transaction\n(since otherwise you'd care about the output addresses) and only if you\nwere happy to not receive any change? Seems like a pretty weird use case?\n\nThere's some prior discussion on this topic at:\n\nhttp://www.erisian.com.au/taproot-bip-review/log-2020-03-04.html\nhttp://www.erisian.com.au/taproot-bip-review/log-2020-03-05.html\n\nCheers,\naj"
            },
            {
                "author": "Russell O'Connor",
                "date": "2020-05-02T21:15:51",
                "message_text_only": "On Sat, May 2, 2020 at 10:26 AM Anthony Towns <aj at erisian.com.au> wrote:\n\n>\n> except that we'd arguably still be missing:\n>\n>     is this a coinbase output? (Coin.fCoinBase)\n>     what was the height of the coin? (Coin.nHeight)\n>\n> Maybe committing to the coinbase flag would have some use, but committing\n> to the height would make it hard to chain unconfirmed spends, so at\n> least that part doesn't seem worth adding.\n>\n\nTo add to this point, the height of the coin is something that is *not*\ncurrently covered by any signature mode and including it would constitute a\nchange of an entirely different  caliber; a change that I would strongly\ncaution against for your above reason and more.\n\nThe coinbase output flag is currently covered by the signature as the\noutpoint hash has the required information (its prevout index of 0xFFFFFFFF\nis only legal in a coinbase transaction).  While I'm not particularly\nenthusiastic about making it easier to distinguish coinbase outputs from\nother outputs, and I worry a little about alternative designs for\nimplementing the Bitcoin protocol where this information is not so readily\navailable, I suppose I won't really oppose adding it.  However, I don't\nthink anyone is seriously proposing it.\n-\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200502/4a4b2947/attachment.html>"
            },
            {
                "author": "Andrew Kozlik",
                "date": "2020-05-04T15:48:00",
                "message_text_only": ">\n> A side effect of this proposal is it would seem to make it not possible to\n> produce a signature for a transaction without having access to the inputs.\n> This is limiting for a number of cases where you don't care about that\n> data. There are a litany of use cases where you don't want to have\n> SIGHASH_ALL behavior, and having to sign the scriptpubkeys breaks that. So\n> at the very least it should respect other flags.\n>\n\nI agree, sha_scriptPubKeys should be included only if hash_type does not\nmatch SIGHASH_ANYONECANPAY. I am also sympathetic to aj's idea of making\nthe scriptPubKey field dependent on hash_type matching SIGHASH_ANYONECANPAY.\n\nI also don't really understand the exact attack. So you submit a\n> transaction to the wallet asking them to sign input 10. They sign. They've\n> committed to the signature being bound to the specific COutpoint and input\n> index, so I don't see how they wouldn't be required to sign a second\n> signature with the other output too? Is there an attack you can describe\n> end-to-end relying on this behavior?\n>\n\nFor example, in a CoinJoin transaction the attacker can construct a\ntransaction with two inputs (in1, in2) of identical value and two outputs\nof identical value, one belonging to the user (user_out) and another\nbelonging to the attacker (attacker_out). If such a transaction is sent to\nthe hardware wallet twice with in1 marked as external the first time and\nin2 marked as external the second time, then the hardware wallet will\ndisplay two signing requests to the user with spending amounts of in2 -\nuser_out and in1 - user_out respectively. The user will think that they are\nsigning two different CoinJoin transactions, while in reality they are\nsigning two different inputs to a single transaction and sending half of\nthe amount to the attacker.\n\nAs an alternative proposal, I think you can just make a separate BIP for\n> some new sigash flags that can be reviewed separately from taproot. There's\n> a lot of value in investing in figuring out more granular controls over\n> what the signature hash is you sign, which may have some exciting\n> contracting implications!\n>\n\nThe proposal of adding sha_scriptPubKeys is just an optimization which is\nnot intended to change what the signature message is committing to. Thus I\ndon't see it as warranting a new sigash flag.\n\nAlternatively, there's the scheme described in the email you linked by Greg\n> Saunders (with the scheme co-attributed to Andrew Poelstra), which seems\n> reasonable to me.[1]  It's only downside (AFAICT) is that it requires an\n> extra one-way communication from a signing device to a coordinator.  For a\n> true offline signer, that can be annoying, but for an automated hardware\n> wallet participating in coinjoins or LN, that doesn't seem too burdensome\n> to me.\n>\n\nYes, I see this as the correct direction forward. Whatever the exact format\nof the ownership proof will be, the proof will need to be signed by the\nowner of the UTXO using BIP-0322 or something along those lines. So the\nscriptPubKey is needed to verify that signature.\n\nCheers,\nAndrew Kozlik\n\nOn Sat, May 2, 2020 at 11:16 PM Russell O'Connor <roconnor at blockstream.com>\nwrote:\n\n> On Sat, May 2, 2020 at 10:26 AM Anthony Towns <aj at erisian.com.au> wrote:\n>\n>>\n>> except that we'd arguably still be missing:\n>>\n>>     is this a coinbase output? (Coin.fCoinBase)\n>>     what was the height of the coin? (Coin.nHeight)\n>>\n>> Maybe committing to the coinbase flag would have some use, but committing\n>> to the height would make it hard to chain unconfirmed spends, so at\n>> least that part doesn't seem worth adding.\n>>\n>\n> To add to this point, the height of the coin is something that is *not*\n> currently covered by any signature mode and including it would constitute a\n> change of an entirely different  caliber; a change that I would strongly\n> caution against for your above reason and more.\n>\n> The coinbase output flag is currently covered by the signature as the\n> outpoint hash has the required information (its prevout index of 0xFFFFFFFF\n> is only legal in a coinbase transaction).  While I'm not particularly\n> enthusiastic about making it easier to distinguish coinbase outputs from\n> other outputs, and I worry a little about alternative designs for\n> implementing the Bitcoin protocol where this information is not so readily\n> available, I suppose I won't really oppose adding it.  However, I don't\n> think anyone is seriously proposing it.\n>\n>    -\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200504/7722585e/attachment.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2020-05-02T14:43:13",
                "message_text_only": "> If you didn't verify the output scriptPubKeys, you would *only* be able\n> to care about fees since you couldn't verify where any of the funds went?\n> And you'd only be able to say fees are \"at least x\", since they could be\n> more if one of the scriptPubKeys turned out to be OP_TRUE eg. That might\n> almost make sense for a transaction accelerator that's trying to increase\n> the fees; but only if you were doing it for someone else's transaction\n> (since otherwise you'd care about the output addresses) and only if you\n> were happy to not receive any change? Seems like a pretty weird use case?\n>\n\nYou are right of course.  I was thinking of cases where you only care about\nwhere some of the outputs go but not all.  But of course, even in that case\nyou will need to wade through all of the output ScriptPubKeys anyways.\nThe current design shares the hashOuputs value with the one computed with\nBIP-143, and that is a somewhat valuable property to keep.\n\nThanks for setting me straight.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200502/6d03957c/attachment.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2020-05-02T12:53:12",
                "message_text_only": "On Wed, Apr 29, 2020 at 04:57:46PM +0200, Andrew Kozlik via bitcoin-dev wrote:\n> In order to ascertain non-ownership of an input which is claimed to be\n> external, the wallet needs the scriptPubKey of the previous output spent by\n> this input.\n\nA wallet can easily check whether a scriptPubKey contais a specific\npubkey (as in P2PK/P2TR), but I think it's impractical for most wallets\nto check whether a scriptPubKey contains any of the possible ~two\nbillion keys available in a specific BIP32 derivation path (and many\nwallets natively support multiple paths).\n\nIt would seem to me that checking a list of scriptPubKeys for wallet\nmatches would require obtaining the BIP32 derivation paths for the\ncorresponding keys, which would have to be provided by a trusted data\nsource.  If you trust that source, you could just trust them to tell you\nthat none of the other inputs belong to your wallet.\n\nAlternatively, there's the scheme described in the email you linked by\nGreg Saunders (with the scheme co-attributed to Andrew Poelstra), which\nseems reasonable to me.[1]  It's only downside (AFAICT) is that it\nrequires an extra one-way communication from a signing device to a\ncoordinator.  For a true offline signer, that can be annoying, but for\nan automated hardware wallet participating in coinjoins or LN, that\ndoesn't seem too burdensome to me.\n\n-Dave\n\n[1] The scheme could be trivially tweaked to be compatible with BIP322\n    generic signed messages, which is something that could become widely\n    adopted (I hope) and so make supporting the scheme easier.\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200502/1879177c/attachment.sig>"
            },
            {
                "author": "Jonas Nick",
                "date": "2020-05-05T10:20:18",
                "message_text_only": "This is a reasonable suggestion. Committing to every spent scriptPubKey and\ntherefore every element of the TxOut instead of just the amount makes sense\nconceptually. And it would be a small diff (~4 lines + rationale) compared to\nthe current bip-taproot version.\n\nAs far aas I understand, coinjoin with offline signers would be substantially\nharder without this proposal. There is a WIP \"SLIP\" that helped me understand\nhow the Proof of Ownership would work [0]. For every input, the offline signing\ndevice verifies a signature against the corresponding scriptPubKey. In order to\nobtain the correct scriptPubKey, sending the whole input transaction to the\nsigning device is prohibitive when the available bandwidth is low (QR codes).\nThe idea of only sending the transaction midstate along with the rest of\nto-be-hashed transaction data is an improvement, but still results in a lot of\ndata (whole vout and witness stacks). Adding a new sighash flag that marks\ncoinjoin transactions would be a step backwards fungibility-wise.\n\nThus, the same reasoning for for committing to the input values in the\ntransaction digest to allow compact fee proofs would similarly apply the\nscriptPubKeys - with the only difference that coinjoins with offline signers are\nless common.\n\nThe downsides of this proposal seem to be limited. It requires additional\nreview, but the BIP is only in the draft stage and should incorporate reasonable\nfeedback. It does not invite further scope creep because the full TxOut would be\nalready included. The costs to verifiers is only slightly increased using\nAnthony Town's suggested sighash change. Availability of the scriptPubKeys for\nsigning devices does not seem to be an issue because the input amounts are\nalready required. And if all inputs belong to the signing device, there's no\nadditional data sent to the device.\n\n[0] https://github.com/satoshilabs/slips/blob/slips-19-20-coinjoin-proofs/slip-0019.md\n\n\nOn 4/29/20 2:57 PM, Andrew Kozlik via bitcoin-dev wrote:\n> Hi everyone,\n> \n> In the current draft of BIP-0341 [1] the signature message commits to the\n> scriptPubKey of the output being spent by the input. I propose that the\n> signature message should commit to the scriptPubKeys of *all* transaction\n> inputs.\n> \n> In certain applications like CoinJoin, a wallet has to deal with\n> transactions containing external inputs. To calculate the actual amount\n> that the user is spending, the wallet needs to reliably determine for each\n> input whether it belongs to the wallet or not. Without such a mechanism an\n> adversary can fool the wallet into displaying incorrect information about\n> the amount being spent, which can result in theft of user funds [2].\n> \n> In order to ascertain non-ownership of an input which is claimed to be\n> external, the wallet needs the scriptPubKey of the previous output spent by\n> this input. It must acquire the full transaction being spent and verify its\n> hash against that which is given in the outpoint. This is an obstacle in\n> the implementation of lightweight air-gapped wallets and hardware wallets\n> in general. If the signature message would commit to the scriptPubKeys of\n> all transaction inputs, then the wallet would only need to acquire the\n> scriptPubKey of the output being spent without having to acquire and verify\n> the hash of the entire previous transaction. If an attacker would provide\n> an incorrect scriptPubKey, then that would cause the wallet to generate an\n> invalid signature message.\n> \n> Note that committing only to the scriptPubKey of the output being spent is\n> insufficient for this application, because the scriptPubKeys which are\n> needed to ascertain non-ownership of external inputs are precisely the ones\n> that would not be included in any of the signature messages produced by the\n> wallet.\n> \n> The obvious way to implement this is to add another hash to the signature\n> message:\n> sha_scriptPubKeys (32): the SHA256 of the serialization of all\n> scriptPubKeys of the previous outputs spent by this transaction.\n> \n> Cheers,\n> Andrew Kozlik\n> \n> [1]\n> https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki#common-signature-message\n> [2]\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-August/014843.html\n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2020-05-11T22:12:33",
                "message_text_only": "Hi all,\n\nOn Tuesday, May 5, 2020 3:20 AM, Jonas Nick via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> This is a reasonable suggestion. Committing to every spent scriptPubKey and\n> therefore every element of the TxOut instead of just the amount makes sense\n> conceptually. And it would be a small diff (~4 lines + rationale) compared to\n> the current bip-taproot version.\n\nI agree.\n\nThere have been several steps so far towards making it possible for signers to determine whether they can safely sign with just O(1) information per input. This was initially attempted in BIP141 (by committing to spent input, to thwart the ability to lie about fees to ofline signers), and is improved in the current BIP341.\n\nI think the CoinJoin + offline signer model indeed shows that is still incomplete, as it is yet another example where a signer may need to be provided with the entire creating transaction, which would be very unfortunate.\n\nIt's also counter to the model proposed by BIP147 (PSBT) workflows: the assumption is effectively already that it is sufficient to provide signers with just amount + scriptPubKey of the spent outputs. It feels very natural that signatures then indeed also need to commit to all that data; otherwise there should be ways that this information can be undetectably wrong.\n\nAJ's approach seems great. It means not increasing the per-signature hashing, while retaining the ability to cache information across BIP141/BIP341.\n\nAs for coinbaseness and height: these are indeed also things currently kept track of in the UTXO set, but I don't think any signer is using this information to determine whether to sign or not (which I think is the minimum requirement for it to be included in a signature hash, see above). Signing height would cripple the ability to spend unconfirmed outputs, or force signers to reveal they're doing so (if done through a separate sighash flag) - both of which would be undesirable. That leaves coinbaseness, but I think the utility is very low.\n\nThe only downside is that this potentially slows down review, but I agree with earlier comments that it's hard to see how this would hurt. I also think it's important to get these things right from the start. Many things inside BIP341/BIP342 are extensible with future softforks, but signature hashes for key-path spends is not one of them (the set of potential signature hash semantics must be committed to directly by the output, so changing them requires a new output type - which would be highly unfortunate for fungibility reasons).\n\nThus, unless there are objections, I'd like to go through with this and make the suggested changes.\n\nThoughts?\n\n--\nPieter"
            }
        ],
        "thread_summary": {
            "title": "BIP-341: Committing to all scriptPubKeys in the signature message",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy",
                "David A. Harding",
                "Andrew Kozlik",
                "Anthony Towns",
                "Pieter Wuille",
                "Russell O'Connor",
                "Jonas Nick",
                "Greg Sanders"
            ],
            "messages_count": 12,
            "total_messages_chars_count": 42009
        }
    },
    {
        "title": "[bitcoin-dev] Fwd: (Semi)Traceless 2-party coinjoin off-chain protocol using schnorr signatures",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-01T07:17:19",
                "message_text_only": "Good morning CB,\n\n> > This \"as long as the inputs that should be separate are not co-spent\" is precisely what mixdepths protect against, which is why I think some kind of mixdepth facility will still matter in CoinSwap.\n> > Still, you have convinced me that, for the purpose of multi-transaction CoinSwap where you do not merge any of your coins, it is immaterial if the sub-transactions come from the same mixdepth or not.\n> > And if you have to merge your coins (for instance, if you are a maker and your customer wants to get a UTXO that is larger than any you have on hand, you have to merge your coins), you just have to ensure they are in the same mixdepth.\n> > Of course, you could be proposing some other construct --- perhaps you have some relational entry which says \"you cannot merge coin A and coin B\" which allows you to merge A C D or B C E, but not A B?\n> > (I imagine this would make coin selection even harder, but I am not a mathematician and there may be some trivial solution to this.)\n> > Now --- if you have two coins that cannot be merged in the same onchain tx, what happens when you swap them in a multi-tx CoinSwap with somebody else?\n> > That somebody else does not know that information.\n> > Instead, that somebody else must always assume that any coins it got from the same CoinSwap operation must not be safely mergeable (though they can still be used in the same swap together).\n> > Coins received via receive addresses would also not be mergeable with any other coins, except coins to the same address (because coins in the same address already leak that they are owned by the same owner).\n>\n> Yes I guess you're right. This part about mixdepths requires further\n> thought.\n>\n> CoinSwap can be combined with some kind of CoinJoin (most likely\n> something similar to PayJoin or CoinJoinXT). That should help with the\n> reasoning about co-spending inputs and mixdepths, because other inputs\n> that are not owned by the taker will often be co-spent anyway.\n>\n> Regarding coins which mustn't be co-spent being coinswapped to somebody\n> else, ideally that coinswap maker will receive coins from unrelated\n> takers too, so will merge their coins along with those as well. Also the\n> fact that a coinswap happened means there are two transactions between\n> the taker's-inputs-which-mustnt-be-merged and them actually being merged.\n\nOne of those transactions (the second one) will be a 1-input 1-output tx (it moves the coin from bilateral control to unilateral control of Bob), which chain analysis already knows to be a self-transfer.\nThe first transaction will also usually be a 1-input 1-output tx as well (it moves the coin from unilateral of Alice to bilateral control) if you did not do any splitting or merging before providing the coin into the swap (for example if this comes from the taker, and the taker knows all the coins it wants to swap cannot be safely merged together).\n\nIf chain analysis keeps the heuristic \"1-input 1-output is a self-payment because srsly who has an exact amount for a payment Bitcoin is volatile lol\", then the resulting coins still are not safe to merge, because chain analysis will \"pass through\" the swap operation and if the two coins are later merged then they still end up *correctly* concluding the original coins were owned by the same owner.\n\nUsing a PayJoin construction for the second tx would help, but if the receiving end does not have a spare UTXO it can merge with (e.g. all its liquidity got tied up in the swap) then there might not be an opportunity to PayJoin.\n\nThere is also little that can be done about the first transaction, in case it ends up being a 1-input 1-output.\n\nSuppose Alice the taker has a 1 BTC output and a 1 BTC output *and no other coins*, both of which it cannot safely merge, and it has to pay 1.2 BTC to Carol.\nAlice then has to CoinSwap them to Bob the maker, requesting a 1.2 BTC output going to Carol and the rest in whatever loose change Bob has.\nAlice then has to use two 1-input 1-output txes for each of its 1 BTC outputs (because it cannot merge them together) to put them into bilateral control.\nThen Bob claims them from bilateral control with 1-input 1-output txes as well (it cannot merge them together, because that might break Alice privacy, and Bob might not have any other spare coins it can merge with the incoming funds).\n\nNow, even if Bob PayJoins the second tx for both 1 BTC outputs, it still cannot merge the resulting joined coins together, because the \"spent-together\" analysis would still tie those coins as being owned by the same owner, it is simply that the surveillor will think the owner owns more coins than it actually does, but the two 1 BTC TXOs that Alice used to own are still analyzed as being owned by the same owner if they are ever merged.\n\nWhat Alice could do, to \"merge\" its 1BTC coins together, would be to swap only one of the 1BTC coins first, for a single 1BTC coin as well.\nThen presumably the incoming 1BTC coin has no linkage with the coin Alice swapped out (Alice hopes), then Alice could spend that new 1BTC coin with the old one it could not merge with the coin it swapped out.\n(Actually Alice does not need to do that as it is the customer after all, but maybe Bob the maker has to do that sometimes, in case it finds there are too many cannot-spend-together constraints in its pool of UTXOs and it is getting harder to select coins --- but if so, who does Bob the maker swap *with*?\nIf Bob can encounter that problem, then maybe other makers will also have that problem as well!)\n\n(the above can be done by PayJoining with the unswapped coin on either the first or second transaction in the swap as well; the idea is more general.)\n\n>\n> Great point on the receive addresses coins. Another use case of\n> mixdepths is to stop incoming payments from two different sources being\n> linked together.\n\nWe could eliminate mixdepths entirely and just use \"cannot merge with X\" constraints.\n\nWhen the wallet sees an incoming payment, it just marks it as \"cannot merge with\" all other coins it owns, unless they have the same address.\nThis prevents any linkage at all and is maximally private.\n\nOn a CoinSwap, the incoming coins are marked as \"cannot merge with\" to each other in the same CoinSwap operation, but not with any other coins it owns.\n\nMaybe?\n\nIt might be easier for the user to understand as well, and reduces scope for mistakes in using mixdepths.\nFor example, I might have a sensitive source of funds (e.g. from all the ransomware I have been writing) and put them in one mixdepth, then after a few months I forgot which mixdepth I put those in and accidentally use it for my on-the-books salary.\n\n\n> > > > Assuming Alice is the taker, and Bob is the maker, then Alice might want a specific coin value (or set of such) that Bob does not have.\n> > > > In that case, Bob will have to split a UTXO it owns.\n> > > > We could constrain it so that Bob at least is not allowed to use the change from splitting for the same CoinSwap, e.g. if Bob has only 9 BTC and 1 BTC coins and Alice wants a 6 BTC / 3 BTC / 1 BTC split, then Bob cannot split its own 9 BTC coin then swap.\n> > > > Or in terms of mixdepths, Bob can split within a mixdepth but each outgoing UTXO in the same swap should be from different mixdepths.\n> > >\n> > > A good way to do it could be for Alice to tell Bob that she wants 10 BTC\n> > > and let Bob figure out on his own how to get that amount, based on the\n> > > amounts he already has. If Alice is making a payment she can provide\n> > > that amount too, but all the other output amounts can be up to Bob.\n> >\n> > This leaks to Bob whether Alice is making a payment or not; it would be better for the privacy of Alice for Alice to always mention some \"payment amount\", even if this is not actually a payment and Alice is just mixing for herself prior to storing in cold storage.\n> > And if Alice wants to use a single swap to pay to multiple targets at once, that implies Alice has to have the ability to indicate the outputs it wants to Bob, and it would imply as well that Alice has to obfuscate which of those outputs have amounts that actually matter (by always insisting on what the output amounts must be, rather than insisting on N output amounts and letting Bob handle the rest).\n> > (We could constrain it such that Alice can make only one payment per CoinSwap, so that Alice only gives one \"target\" amount and one \"total\" amount, but that implies even bigger blockspace utilization, sigh.)\n> > Otherwise, Bob can get information:\n> >\n> > -   \"Oh, Alice did not specify any of the outputs, just the total amount, all of my old coins are owned by Alice now.\"\n> > -   \"Oh, Alice specified an exact value for one of the outputs, that one is no longer owned by Alice but the rest are owned by Alice.\"\n> > -   \"Oh, Alice specified exact values for two of the outputs, those two are definitely no longer owned by Alice but the rest are owned by Alice.\"\n> >\n> > The conclusion here is either Alice never specifies any of the outputs --- in which case Alice cannot use a CoinSwap to pay directly to somebody else --- or Alice specifies all of them.\n> > Again, the maker might be an active surveillor, thus we should reduce information leaks to the maker as much as we can.\n>\n> Yep great point.\n>\n> A benefit of Alice not specifying any amounts is that Bob is able to\n> improve privacy and reduce costs by creating fewer change outputs. A\n> downside is that this leaks Alice's intentions (self-mix vs payment) to Bob.\n>\n> A solution could be to add randomness. Have Alice randomly specify\n> payment amounts with some probability even if she is only self-mixing.\n>\n> Although this doesn't solve everything, because Alice not specifying any\n> amounts implies self-mixing. But at least specifying some amounts\n> doesn't imply a payment.\n\nI think that maybe it would be a better policy for Alice to always just give a specified payment amount at all times.\nOf course, a sufficiently motivated Bob could always just do statistical analysis on the payment amount (e.g. if it is not equivalent to some round number of United States Green Historical Commemoration Papers, it is unlikely to be a payment but instead a random amount that Alice had to provide on a self-payment).\nSo .....\n\n\nAnyway, slightly unrelated, maybe we can simply have Alice specify a single payment amount always, as an unremovable part of the protocol.\n\nI proposed \"private key turnover\" here: https://github.com/AdamISZ/CoinSwapCS/issues/53\nBasically, after exchanging the swap secret, it is now safe to give your share of bilateral control to your swap partner, so you can just turn over that private key to the swap partner.\nFor clarity:\n\n* Alice owns a 1 BTC coin it wants to swap with a 1 BTC coin from Bob.\n* Alice sends its 1 BTC coin to bilateral control (Alice temporary key and Bob temporary key).\n  * Backoffs and confirmations and etc etc are needed, we all know how to do CoinSwap safely, I elide those details here.\n* Bob sends its 1 BTC to bilateral control (Alice 2nd temporary key and Bob 2nd temporary key).\n* Alice and Bob complete the CoinSwap protocol and now both know the swap secret X, and have to claim the bilateral control before some future blockheight L.\n* Alice can send its Alice temporary key to Bob, so that Bob can change the second transaction as it likes.\n  * Bob can merge it with a coin it happens to have, without having to coordinate signing with Alice (i.e. it gets PayJoin on the second tx for free).\n  * If Bob the maker gets another swap request, it can spend directly from the bilateral control address to another bilateral control address with a different taker, reducing blockchain footprint.\n  * Bob can fee bump using RBF instead of CPFP.\n* Bob can also now send its Bob 2nd temporary key to Alice, for similar advantages for Alice.\n\nIt does require that both Alice and Bob respect the timeout --- the bilateral outputs have to be spent before the timeout, else the timelock branches come into play.\nBut Alice and Bob, after private key turnover, need not *immediately* broadcast the claiming transactions --- they can wait a little time for opportunities to change the claiming transaction, for example if they get an incoming payment they could assume that the recently-concluded swap is safe to merge with the new incoming coin and they can CPFP the incoming payment on the mempool with their existing coin, or Bob the maker might get another customer and Bob can cut-through from one swap to the next, reducing 4 transactions for 2 swaps to just 3 transactions (and if it can continuously chain customers that way, in the long run Bob on average has 1 transaction per swap, halving the block space usage needed for CoinSwap).\n\nThis increases complication of the implementation, but you potentially get an improvement in blockchain space for popular makers, with an asymptote of 50% reduction, so it is probably worth implementing.\n\n\nThus, if Alice wants to multipay, she could just sum up all the outgoing values, then specify the sum to Bob.\nThen it can modify the second transaction to pay multiple destinations (since it has the private keys to remake that).\nOf course, all the outgoing payments are now linked together.... but I suppose you can warn the user of Alice of such.\n\nIt would probably be best for both Alice and Bob to always change the destination address as well after private key turnover.\n\n\n> > Okay, from what little I understand it seems that \"even if sparse subset sum is easier than subset sum, it is still hard, so it probably will not matter in practice\", would that be a fair takeaway?\n>\n> Not exactly. Here's another summary:\n>\n> Suppose Alice has V bitcoins and mixes them with multi-transaction\n> CoinSwap, she receives transactions with amounts (w_0, w_1, w_2....)\n> which add up to V.\n>\n> Privacy relying on the (sparse) subset sum problem works by making it\n> computationally infeasible for an adversary to search the entire\n> blockchain for sets of transactions (w_0, w_1, w_2....) which add up to\n> V. I believe aiming for this kind of privacy isn't practical due to\n> block space considerations and others.\n>\n> Privacy relying on false positives does not make any search\n> computationally infeasible, it works by having a large number of other\n> sets of transactions (w_0, w_1, w_2....) which add up to V just by\n> chance. Then the transactions received by Alice's will have a big crowd\n> to hide in. I believe this is practical because the numbers are\n> proportional to the n-choose-k function which can still be very large.\n\nHmm.\n\nSo let us return to our example of Alice who owns a 1 BTC coin and a 1 BTC coin.\nNow suppose we find, by false-positive-statistics, that 2 BTC subset sums are rare but, say, 1.5 BTC subset sums are significantly more common.\nSo what Alice should do, if it wants to send 1.2 BTC to Carol via a CoinSwap with maker Bob, would be to split one of her 1 BTC coins to a 0.5 BTC and 0.5 BTC coin.\nThen it takes the remaining 1 BTC coin and one of the 0.5 BTC and offers them in a CoinSwap to maker Bob, specifying a payment amount of 1.2 BTC.\n\nIt seems to me, however, that this is not much different from just specifying a set of standardized swap amounts.\n\nThe initial standards can be derived from false-positive-statistics, but once SwapMarket starts to become popular, then the actual statistics of the chain becomes skewed towards those standard swap amounts.\nThis makes it even wiser to also use those standard swap amounts, because of the larger anonymity sets.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Chris Belcher",
                "date": "2020-05-03T19:28:23",
                "message_text_only": "Hello ZmnSCPxj,\n\n>>> This \"as long as the inputs that should be separate are not co-spent\" is precisely what mixdepths protect against, which is why I think some kind of mixdepth facility will still matter in CoinSwap.\n>>> Still, you have convinced me that, for the purpose of multi-transaction CoinSwap where you do not merge any of your coins, it is immaterial if the sub-transactions come from the same mixdepth or not.\n>>> And if you have to merge your coins (for instance, if you are a maker and your customer wants to get a UTXO that is larger than any you have on hand, you have to merge your coins), you just have to ensure they are in the same mixdepth.\n>>> Of course, you could be proposing some other construct --- perhaps you have some relational entry which says \"you cannot merge coin A and coin B\" which allows you to merge A C D or B C E, but not A B?\n>>> (I imagine this would make coin selection even harder, but I am not a mathematician and there may be some trivial solution to this.)\n>>> Now --- if you have two coins that cannot be merged in the same onchain tx, what happens when you swap them in a multi-tx CoinSwap with somebody else?\n>>> That somebody else does not know that information.\n>>> Instead, that somebody else must always assume that any coins it got from the same CoinSwap operation must not be safely mergeable (though they can still be used in the same swap together).\n>>> Coins received via receive addresses would also not be mergeable with any other coins, except coins to the same address (because coins in the same address already leak that they are owned by the same owner).\n>>\n>> Yes I guess you're right. This part about mixdepths requires further\n>> thought.\n>>\n>> CoinSwap can be combined with some kind of CoinJoin (most likely\n>> something similar to PayJoin or CoinJoinXT). That should help with the\n>> reasoning about co-spending inputs and mixdepths, because other inputs\n>> that are not owned by the taker will often be co-spent anyway.\n>>\n>> Regarding coins which mustn't be co-spent being coinswapped to somebody\n>> else, ideally that coinswap maker will receive coins from unrelated\n>> takers too, so will merge their coins along with those as well. Also the\n>> fact that a coinswap happened means there are two transactions between\n>> the taker's-inputs-which-mustnt-be-merged and them actually being merged.\n> \n> One of those transactions (the second one) will be a 1-input 1-output tx (it moves the coin from bilateral control to unilateral control of Bob), which chain analysis already knows to be a self-transfer.\n> The first transaction will also usually be a 1-input 1-output tx as well (it moves the coin from unilateral of Alice to bilateral control) if you did not do any splitting or merging before providing the coin into the swap (for example if this comes from the taker, and the taker knows all the coins it wants to swap cannot be safely merged together).\n> \n> If chain analysis keeps the heuristic \"1-input 1-output is a self-payment because srsly who has an exact amount for a payment Bitcoin is volatile lol\", then the resulting coins still are not safe to merge, because chain analysis will \"pass through\" the swap operation and if the two coins are later merged then they still end up *correctly* concluding the original coins were owned by the same owner.\n> \n> Using a PayJoin construction for the second tx would help, but if the receiving end does not have a spare UTXO it can merge with (e.g. all its liquidity got tied up in the swap) then there might not be an opportunity to PayJoin.\n> \n> There is also little that can be done about the first transaction, in case it ends up being a 1-input 1-output.\n> \n> Suppose Alice the taker has a 1 BTC output and a 1 BTC output *and no other coins*, both of which it cannot safely merge, and it has to pay 1.2 BTC to Carol.\n> Alice then has to CoinSwap them to Bob the maker, requesting a 1.2 BTC output going to Carol and the rest in whatever loose change Bob has.\n> Alice then has to use two 1-input 1-output txes for each of its 1 BTC outputs (because it cannot merge them together) to put them into bilateral control.\n> Then Bob claims them from bilateral control with 1-input 1-output txes as well (it cannot merge them together, because that might break Alice privacy, and Bob might not have any other spare coins it can merge with the incoming funds).\n> \n> Now, even if Bob PayJoins the second tx for both 1 BTC outputs, it still cannot merge the resulting joined coins together, because the \"spent-together\" analysis would still tie those coins as being owned by the same owner, it is simply that the surveillor will think the owner owns more coins than it actually does, but the two 1 BTC TXOs that Alice used to own are still analyzed as being owned by the same owner if they are ever merged.\n> \n> What Alice could do, to \"merge\" its 1BTC coins together, would be to swap only one of the 1BTC coins first, for a single 1BTC coin as well.\n> Then presumably the incoming 1BTC coin has no linkage with the coin Alice swapped out (Alice hopes), then Alice could spend that new 1BTC coin with the old one it could not merge with the coin it swapped out.\n> (Actually Alice does not need to do that as it is the customer after all, but maybe Bob the maker has to do that sometimes, in case it finds there are too many cannot-spend-together constraints in its pool of UTXOs and it is getting harder to select coins --- but if so, who does Bob the maker swap *with*?\n> If Bob can encounter that problem, then maybe other makers will also have that problem as well!)\n> \n> (the above can be done by PayJoining with the unswapped coin on either the first or second transaction in the swap as well; the idea is more general.)\n\nChain analysis doesn't in fact know that 1-input-1-output transfers are\nself-transfers, this is merely a heuristic that can be flawed. For\nexample I accept donations in bitcoin and a surprising number of them\nare 1-input-1-output or multi-input-1-output, presumably the donators\ndid it for privacy reasons or cost reasons. Also I believe many people\nuse 1-input-1-output transactions for funding Lightning channels.\n\nAlthough even so, your argument suggests that its better for at least\nsome of the time for Alice and Bob to create 2-output transactions and\nmess with the change output detection heuristics to try to get chain\nanalyzers to assign the wrong output as change.\n\nIf the receiving end doesn't have a suitable UTXO for a PayJoin then\nthey won't get the CoinSwap deal. The liquidity market is a free market,\ntakers are the maker's customers and they have a wide choice. In such a\ncase the maker would have been outcompeted by other makers which do have\nextra UTXOs.\n\nYour discussion with Alice having two UTXOs she doesn't want to co-spend\nis definitely interesting. Perhaps also another way to solve is for\nAlice to spend her UTXOs in 2-output transactions and mess with the\nchange output detection heuristics, say CoinSwapping 0.5 BTC from one\ncoin and 0.7 BTC from the other, with the total 1.2 BTC going to Carol.\n\n\n>>>>> Assuming Alice is the taker, and Bob is the maker, then Alice might want a specific coin value (or set of such) that Bob does not have.\n>>>>> In that case, Bob will have to split a UTXO it owns.\n>>>>> We could constrain it so that Bob at least is not allowed to use the change from splitting for the same CoinSwap, e.g. if Bob has only 9 BTC and 1 BTC coins and Alice wants a 6 BTC / 3 BTC / 1 BTC split, then Bob cannot split its own 9 BTC coin then swap.\n>>>>> Or in terms of mixdepths, Bob can split within a mixdepth but each outgoing UTXO in the same swap should be from different mixdepths.\n>>>>\n>>>> A good way to do it could be for Alice to tell Bob that she wants 10 BTC\n>>>> and let Bob figure out on his own how to get that amount, based on the\n>>>> amounts he already has. If Alice is making a payment she can provide\n>>>> that amount too, but all the other output amounts can be up to Bob.\n>>>\n>>> This leaks to Bob whether Alice is making a payment or not; it would be better for the privacy of Alice for Alice to always mention some \"payment amount\", even if this is not actually a payment and Alice is just mixing for herself prior to storing in cold storage.\n>>> And if Alice wants to use a single swap to pay to multiple targets at once, that implies Alice has to have the ability to indicate the outputs it wants to Bob, and it would imply as well that Alice has to obfuscate which of those outputs have amounts that actually matter (by always insisting on what the output amounts must be, rather than insisting on N output amounts and letting Bob handle the rest).\n>>> (We could constrain it such that Alice can make only one payment per CoinSwap, so that Alice only gives one \"target\" amount and one \"total\" amount, but that implies even bigger blockspace utilization, sigh.)\n>>> Otherwise, Bob can get information:\n>>>\n>>> -   \"Oh, Alice did not specify any of the outputs, just the total amount, all of my old coins are owned by Alice now.\"\n>>> -   \"Oh, Alice specified an exact value for one of the outputs, that one is no longer owned by Alice but the rest are owned by Alice.\"\n>>> -   \"Oh, Alice specified exact values for two of the outputs, those two are definitely no longer owned by Alice but the rest are owned by Alice.\"\n>>>\n>>> The conclusion here is either Alice never specifies any of the outputs --- in which case Alice cannot use a CoinSwap to pay directly to somebody else --- or Alice specifies all of them.\n>>> Again, the maker might be an active surveillor, thus we should reduce information leaks to the maker as much as we can.\n>>\n>> Yep great point.\n>>\n>> A benefit of Alice not specifying any amounts is that Bob is able to\n>> improve privacy and reduce costs by creating fewer change outputs. A\n>> downside is that this leaks Alice's intentions (self-mix vs payment) to Bob.\n>>\n>> A solution could be to add randomness. Have Alice randomly specify\n>> payment amounts with some probability even if she is only self-mixing.\n>>\n>> Although this doesn't solve everything, because Alice not specifying any\n>> amounts implies self-mixing. But at least specifying some amounts\n>> doesn't imply a payment.\n> \n> I think that maybe it would be a better policy for Alice to always just give a specified payment amount at all times.\n> Of course, a sufficiently motivated Bob could always just do statistical analysis on the payment amount (e.g. if it is not equivalent to some round number of United States Green Historical Commemoration Papers, it is unlikely to be a payment but instead a random amount that Alice had to provide on a self-payment).\n> So .....\n> \n> \n> Anyway, slightly unrelated, maybe we can simply have Alice specify a single payment amount always, as an unremovable part of the protocol.\n> \n> I proposed \"private key turnover\" here: https://github.com/AdamISZ/CoinSwapCS/issues/53\n> Basically, after exchanging the swap secret, it is now safe to give your share of bilateral control to your swap partner, so you can just turn over that private key to the swap partner.\n> For clarity:\n> \n> * Alice owns a 1 BTC coin it wants to swap with a 1 BTC coin from Bob.\n> * Alice sends its 1 BTC coin to bilateral control (Alice temporary key and Bob temporary key).\n>   * Backoffs and confirmations and etc etc are needed, we all know how to do CoinSwap safely, I elide those details here.\n> * Bob sends its 1 BTC to bilateral control (Alice 2nd temporary key and Bob 2nd temporary key).\n> * Alice and Bob complete the CoinSwap protocol and now both know the swap secret X, and have to claim the bilateral control before some future blockheight L.\n> * Alice can send its Alice temporary key to Bob, so that Bob can change the second transaction as it likes.\n>   * Bob can merge it with a coin it happens to have, without having to coordinate signing with Alice (i.e. it gets PayJoin on the second tx for free).\n>   * If Bob the maker gets another swap request, it can spend directly from the bilateral control address to another bilateral control address with a different taker, reducing blockchain footprint.\n>   * Bob can fee bump using RBF instead of CPFP.\n> * Bob can also now send its Bob 2nd temporary key to Alice, for similar advantages for Alice.\n> \n> It does require that both Alice and Bob respect the timeout --- the bilateral outputs have to be spent before the timeout, else the timelock branches come into play.\n> But Alice and Bob, after private key turnover, need not *immediately* broadcast the claiming transactions --- they can wait a little time for opportunities to change the claiming transaction, for example if they get an incoming payment they could assume that the recently-concluded swap is safe to merge with the new incoming coin and they can CPFP the incoming payment on the mempool with their existing coin, or Bob the maker might get another customer and Bob can cut-through from one swap to the next, reducing 4 transactions for 2 swaps to just 3 transactions (and if it can continuously chain customers that way, in the long run Bob on average has 1 transaction per swap, halving the block space usage needed for CoinSwap).\n> \n> This increases complication of the implementation, but you potentially get an improvement in blockchain space for popular makers, with an asymptote of 50% reduction, so it is probably worth implementing.\n> \n> \n> Thus, if Alice wants to multipay, she could just sum up all the outgoing values, then specify the sum to Bob.\n> Then it can modify the second transaction to pay multiple destinations (since it has the private keys to remake that).\n> Of course, all the outgoing payments are now linked together.... but I suppose you can warn the user of Alice of such.\n> \n> It would probably be best for both Alice and Bob to always change the destination address as well after private key turnover.\n\nOf course if Alice specified an amount when she was actually\nself-mixing, it would be easy for her to come up with a random value\nthat was close to some round number, either in BTC or another currency.\n\nPrivate key turnover is a great idea. It could also help with the\nearlier problem of 1-input-1-output transactions being markers, because\nwhen the coins in 2-of-2 multisigs are spent they may end up being spent\nin a wider variety of ways.\n\n\n>>> Okay, from what little I understand it seems that \"even if sparse subset sum is easier than subset sum, it is still hard, so it probably will not matter in practice\", would that be a fair takeaway?\n>>\n>> Not exactly. Here's another summary:\n>>\n>> Suppose Alice has V bitcoins and mixes them with multi-transaction\n>> CoinSwap, she receives transactions with amounts (w_0, w_1, w_2....)\n>> which add up to V.\n>>\n>> Privacy relying on the (sparse) subset sum problem works by making it\n>> computationally infeasible for an adversary to search the entire\n>> blockchain for sets of transactions (w_0, w_1, w_2....) which add up to\n>> V. I believe aiming for this kind of privacy isn't practical due to\n>> block space considerations and others.\n>>\n>> Privacy relying on false positives does not make any search\n>> computationally infeasible, it works by having a large number of other\n>> sets of transactions (w_0, w_1, w_2....) which add up to V just by\n>> chance. Then the transactions received by Alice's will have a big crowd\n>> to hide in. I believe this is practical because the numbers are\n>> proportional to the n-choose-k function which can still be very large.\n> \n> Hmm.\n> \n> So let us return to our example of Alice who owns a 1 BTC coin and a 1 BTC coin.\n> Now suppose we find, by false-positive-statistics, that 2 BTC subset sums are rare but, say, 1.5 BTC subset sums are significantly more common.\n> So what Alice should do, if it wants to send 1.2 BTC to Carol via a CoinSwap with maker Bob, would be to split one of her 1 BTC coins to a 0.5 BTC and 0.5 BTC coin.\n> Then it takes the remaining 1 BTC coin and one of the 0.5 BTC and offers them in a CoinSwap to maker Bob, specifying a payment amount of 1.2 BTC.\n> \n> It seems to me, however, that this is not much different from just specifying a set of standardized swap amounts.\n> \n> The initial standards can be derived from false-positive-statistics, but once SwapMarket starts to become popular, then the actual statistics of the chain becomes skewed towards those standard swap amounts.\n> This makes it even wiser to also use those standard swap amounts, because of the larger anonymity sets.\n\nIt's very unlikely for the 2 BTC subset sum to be uncommon but 1.5 BTC\nto be common, because they are very close in value, and these functions\nseem to end up being smooth and slowly-varying, at least in my brief\ntests. It might be a concern when comparing 2 BTC to 20 BTC or 200 BTC.\n\n\nRegards\nCB"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-04T08:28:41",
                "message_text_only": "Good morning CB,\n\n\n> Chain analysis doesn't in fact know that 1-input-1-output transfers are\n> self-transfers, this is merely a heuristic that can be flawed. For\n> example I accept donations in bitcoin and a surprising number of them\n> are 1-input-1-output or multi-input-1-output, presumably the donators\n> did it for privacy reasons or cost reasons.\n\nA heuristic need not be perfect to be effective, and I am quite sure that, outside of donation, most 1-output transfers will be self-transfers.\n\nIndeed, the old cliche of donating tainted/stolen funds is most likely a cliche for a reason.\nPerhaps you are a beneficiary of some movie hero who has stolen the money from a villain who acquired wealth by immoral means.\n\nUnlike change heuristics, misleading the 1-output heuristic is difficult; whoever got control of the single output is either yourself, or somebody who swapped coins with you.\n\n\n> Also I believe many people\n> use 1-input-1-output transactions for funding Lightning channels.\n\nYes, Lightning helps privacy, that is correct.\n\nHowever, do note that Lightning channels tend to be long-lived, meaning it will be a large number of blocks that such a TXO will be unspent.\nDue to the timeout on CoinSwap, the fund needs to be claimed quickly, in much shorter time than a typical Lightning channel.\nThis can help narrow down payment heuristics.\n\n>\n> Although even so, your argument suggests that its better for at least\n> some of the time for Alice and Bob to create 2-output transactions and\n> mess with the change output detection heuristics to try to get chain\n> analyzers to assign the wrong output as change.\n\nYes, I agree.\n\n> If the receiving end doesn't have a suitable UTXO for a PayJoin then\n> they won't get the CoinSwap deal. The liquidity market is a free market,\n> takers are the maker's customers and they have a wide choice. In such a\n> case the maker would have been outcompeted by other makers which do have\n> extra UTXOs.\n\nPayJoin might not buy you as much as you think.\n\nSo Alice has two coins it does not want to CoinJoin for unknown reasons:\n\n\n    Salary as  ---> Alice\n     teacher\n\n    LiveJasmin ---> Alice\n     payout\n\nAlice swaps them to Bob, who PayJoins the incoming funds.\nSince Bob has been operating for a long time, its coins have a varied and storied history.\n\n    WannaCry  ----> Bob  ----+\n                             |\n                             |\n    Salary as  ---> Alice ---+--> Bob\n     teacher\n\n    LiveJasmin ---> Alice ---+--> Bob\n     payout                  |\n                             |\n    ex-JoinMarket -> Bob ----+\n     maker\n\nAlice does *not* want Bob to join those two Bob-owned coins, still, because chain analysis would not only implicate her in WannaCry, but also as a LiveJasmin model ***and*** (gasp!) a JoinMarket money launderer (I am being facetious here).\n\nAnd since the swap has completed, Bob controls those coins.\nIf another taker comes along, offering a high fee for a big swap, and Bob *has to* merge those two coins (that ultimately got history from Alice) in order to cover what the taker is requesting (because the taker has to make a big single payout to some other party, so needs a single large UTXO, not two small ones), what do you think Bob will do?\nIn a free market where the takers have wide choice, do you think Bob will economically-rationally help protect the secret life of Alice when not doing so would let Bob earn more coins?\n\nNow of course, it would seem very unlikely that Alice the teacher is the hacker behind WannaCry *and* a LiveJasmin model *and* a money launderer, so no problem, right?\nIt just makes surveillors looks like fools right?\nExcept that Bob could have skipped the PayJoin step and just merged those four coins in a single transaction later, and the conclusion of surveillors would still be the same, for much the same effect, at reduced blockspace (spend in a single transaction instead of 3).\n\nSo I think it is better if Bob actually avoids small merges of a two or three or four coins, and should do the occasional mass merge of large numbers of coins.\nThis leads to better misleading of surveillors, and is incentive compatible since it reduces blockspace usage for Bob to do the occasional mass merge rather than PayJoining at every swap.\n\n> Your discussion with Alice having two UTXOs she doesn't want to co-spend\n> is definitely interesting. Perhaps also another way to solve is for\n> Alice to spend her UTXOs in 2-output transactions and mess with the\n> change output detection heuristics, say CoinSwapping 0.5 BTC from one\n> coin and 0.7 BTC from the other, with the total 1.2 BTC going to Carol.\n\nThat seems to be a good idea indeed, and significantly better than relying on PayJoin to obscure the history of coins.\n\nOf course, doing change-output-heuristic-breaking means splitting up coins, increasing the number of UTXOs.\nBut that combines well with Bob the maker periodically merging many small coins.\n\n> Of course if Alice specified an amount when she was actually\n> self-mixing, it would be easy for her to come up with a random value\n> that was close to some round number, either in BTC or another currency.\n\nYes, and I suggest this is always be done, as part of the protocol.\n\n\n> Private key turnover is a great idea. It could also help with the\n> earlier problem of 1-input-1-output transactions being markers, because\n> when the coins in 2-of-2 multisigs are spent they may end up being spent\n> in a wider variety of ways.\n\nIndeed.\nIt gets a few features \"for free\", at the cost of greater complexity at the simple \"I only want to swap once, then forget about the coins for a while\" case.\n\n* It gets PayJoin at the second transaction for free.\n* It lets Bob the maker cut-through for a new taker.\n* It reduces the cost on Bob to merge large numbers of coins at once.\n* It lets Alice the taker cut-through for a new maker if she wants to do multi-round swaps (though note the objection \"Value-based Directionality\" in my writeup https://zmnscpxj.github.io/bitcoin/multiswap.html ; though counternote that if CoinSwaps are as hard to identify as my naive understanding of your math suggests, this should be a relatively minimal problem).\n\n>\n> > > > Okay, from what little I understand it seems that \"even if sparse subset sum is easier than subset sum, it is still hard, so it probably will not matter in practice\", would that be a fair takeaway?\n> > >\n> > > Not exactly. Here's another summary:\n> > > Suppose Alice has V bitcoins and mixes them with multi-transaction\n> > > CoinSwap, she receives transactions with amounts (w_0, w_1, w_2....)\n> > > which add up to V.\n> > > Privacy relying on the (sparse) subset sum problem works by making it\n> > > computationally infeasible for an adversary to search the entire\n> > > blockchain for sets of transactions (w_0, w_1, w_2....) which add up to\n> > > V. I believe aiming for this kind of privacy isn't practical due to\n> > > block space considerations and others.\n> > > Privacy relying on false positives does not make any search\n> > > computationally infeasible, it works by having a large number of other\n> > > sets of transactions (w_0, w_1, w_2....) which add up to V just by\n> > > chance. Then the transactions received by Alice's will have a big crowd\n> > > to hide in. I believe this is practical because the numbers are\n> > > proportional to the n-choose-k function which can still be very large.\n> >\n> > Hmm.\n> > So let us return to our example of Alice who owns a 1 BTC coin and a 1 BTC coin.\n> > Now suppose we find, by false-positive-statistics, that 2 BTC subset sums are rare but, say, 1.5 BTC subset sums are significantly more common.\n> > So what Alice should do, if it wants to send 1.2 BTC to Carol via a CoinSwap with maker Bob, would be to split one of her 1 BTC coins to a 0.5 BTC and 0.5 BTC coin.\n> > Then it takes the remaining 1 BTC coin and one of the 0.5 BTC and offers them in a CoinSwap to maker Bob, specifying a payment amount of 1.2 BTC.\n> > It seems to me, however, that this is not much different from just specifying a set of standardized swap amounts.\n> > The initial standards can be derived from false-positive-statistics, but once SwapMarket starts to become popular, then the actual statistics of the chain becomes skewed towards those standard swap amounts.\n> > This makes it even wiser to also use those standard swap amounts, because of the larger anonymity sets.\n>\n> It's very unlikely for the 2 BTC subset sum to be uncommon but 1.5 BTC\n> to be common, because they are very close in value, and these functions\n> seem to end up being smooth and slowly-varying, at least in my brief\n> tests. It might be a concern when comparing 2 BTC to 20 BTC or 200 BTC.\n\nIf it is as smooth and naturally-occurring as you suggest, then it seems to me as well that the distribution of CoinSwap values will be just as smooth and naturally-occurring, so my naive understanding is still \"even if sparse subset sum is easier than subset sum, it is still hard, so it probably will not matter in practice\".\n\nPeople will mix due to receiving some amount.\nThat amount will be sampled from some naturally-occurring distribution.\nThus, CoinSwap values will be sampled from the same naturally-occurring distribution.\n\nPeople will mix due to having to send some amount they do not want to be tracked to them.\nThat amount will be sampled from some naturally-occurring distribution.\nThus, CoinSwap values will be sampled from the same naturally-occurring distribution.\n\n....I think?  Maybe?\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Fwd: (Semi)Traceless 2-party coinjoin off-chain protocol using schnorr signatures",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Chris Belcher"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 41853
        }
    },
    {
        "title": "[bitcoin-dev] On the scalability issues of onboarding millions of LN mobile clients",
        "thread_messages": [
            {
                "author": "Antoine Riard",
                "date": "2020-05-05T10:17:37",
                "message_text_only": "Hi,\n\n(cross-posting as it's really both layers concerned)\n\nOngoing advancement of BIP 157 implementation in Core maybe the opportunity\nto reflect on the future of light client protocols and use this knowledge\nto make better-informed decisions about what kind of infrastructure is\nneeded to support mobile clients at large scale.\n\nTrust-minimization of Bitcoin security model has always relied first and\nabove on running a full-node. This current paradigm may be shifted by LN\nwhere fast, affordable, confidential, censorship-resistant payment services\nmay attract a lot of adoption without users running a full-node. Assuming a\nuser adoption path where a full-node is required to benefit for LN may\ndeprive a lot of users, especially those who are already denied a real\nfinancial infrastructure access. It doesn't mean we shouldn't foster node\nadoption when people are able to do so, and having a LN wallet maybe even a\nfirst-step to it.\n\nDesigning a mobile-first LN experience opens its own gap of challenges\nespecially in terms of security and privacy. The problem can be scoped as\nhow to build a scalable, secure, private chain access backend for millions\nof LN clients ?\n\nLight client protocols for LN exist (either BIP157 or Electrum are used),\nalthough their privacy and security guarantees with regards to\nimplementation on the client-side may still be an object of concern\n(aggressive tx-rebroadcast, sybillable outbound peer selection, trusted fee\nestimation). That said, one of the bottlenecks is likely the number of\nfull-nodes being willingly to dedicate resources to serve those clients.\nIt's not about _which_ protocol is deployed but more about _incentives_ for\nnode operators to dedicate long-term resources to client they have lower\nreasons to care about otherwise.\n\nEven with cheaper, more efficient protocols like BIP 157, you may have a\nhuge discrepancy between what is asked and what is offered. Assuming 10M\nlight clients [0] each of them consuming ~100MB/month for filters/headers,\nthat means you're asking 1PB/month of traffic to the backbone network. If\nyou assume 10K public nodes, like today, assuming _all_ of them opt-in to\nsignal BIP 157, that's an increase of 100GB/month for each. Which is\nconsequent with regards to the estimated cost of 350GB/month for running an\nactual public node. Widening full-node adoption, specially in term of\ngeographic distribution means as much as we can to bound its operational\ncost.\n\nObviously,  deployment of more efficient tx-relay protocol like Erlay will\nfree up some resources but it maybe wiser to dedicate them to increase\nhealth and security of the backbone network like deploying more outbound\nconnections.\n\nUnless your light client protocol is so ridiculous cheap to rely on\nniceness of a subset of node operators offering free resources, it won't\nscale. And it's likely you will always have a ratio disequilibrium between\nnumbers of clients and numbers of full-node, even worst their growth rate\nwon't be the same, first ones are so much easier to setup.\n\nIt doesn't mean servicing filters for free won't work for now, numbers of\nBIP157 clients is still pretty low, but what is worrying is  wallet vendors\nbuilding such chain access backend, hitting a bandwidth scalability wall\nfew years from now instead of pursuing better solutions. And if this\nhappen, maybe suddenly, isn't the quick fix going to be to rely on\ncentralized services, so much easier to deploy ?\n\nOf course, it may be brought that actually current full-node operators\ndon't get anything back from servicing blocks, transactions, addresses...\nIt may be replied that you have an indirect incentive to participate in\nnetwork relay and therefore guarantee censorship-resistance, instead of\ndirectly connecting to miners. You do have today ways to select your\nresources exposure like pruning, block-only or being private but the wider\npoint is the current (non?)-incentives model seems to work for the base\nlayer. For light clients data, are node operators going to be satisfied to\nserve this new *class* of traffic en masse ?\n\nThis doesn't mean you won't find BIP157 servers, ready to serve you with\nunlimited credit, but it's more likely their intentions maybe not aligned,\nlike spying on your transaction broadcast or block fetched. And you do want\npeer diversity to avoid every BIP157 servers being on few ASNs for\nfault-tolerance. Do people expect a scenario a la Cloudflare, where\neveryone connections is to far or less the same set of entities ?\n\nMoreover, the LN security model diverges hugely from basic on-chain\ntransactions. Worst-case attack on-chain a malicious light client server\nshowing a longest, invalid, PoW-signed chain to double-spend the user. On\nLN, the *liveliness* requirement means the entity owning your view of the\nchain can lie to you on whether your channel has been spent by a revoked\ncommitment, the real tip of the blockchain or even dry-up block\nannouncement to trigger unexpected behavior in the client logic. A\nmalicious light client server may just drop any filters/utxos spends, what\nyour LN client should do in this case ? [1]\n\nTherefore, you may want to introduce monetary compensation in exchange of\nservicing filters. Light client not dedicating resources to maintain the\nnetwork but free-riding on it, you may use their micro-payment capabilities\nto price chain access resources [3]. This proposition may suit within the\nwatchtower paradigm, where another entity is delegated some part of\nprotocol execution, alleviating client onliness requirement. It needs\nfurther analysis but how your funds may be compromised by a watchtower are\nlikely to be the same scenario that how a chain validation provider can\ncompromise you. That said, how do you avoid such \"chain access\" market\nturning as an oligopoly is an open question. You may \"bind\" them to\ninternet topology or ask for fidelity bonds and create some kind of\nscarcity but still...\n\nMaybe I'm completely wrong, missing some numbers, and it's maybe fine to\njust rely on few thousands of full-node operators being nice and servicing\nfriendly millions of LN mobiles clients. But just in case it may be good to\nconsider a reasonable alternative.\n\nThanks Gleb for many points exposed here but all mistakes are my own.\n\nCheers,\n\nAntoine\n\n[0] UTXO set size may be a bottleneck, but still if you have 2 channels by\nclients that's 20M utxos, just roughly ~x3 than today.\n\n[1] And committing filters as part of headers may not solve everything as\nan attacker can just delay or slow announcements to you, so you still need\nnetwork access to at least one honest node.\n\n[2]  It maybe argue that distinction client-vs-peer doesn't hold because\nyou may start as a client and start synchronizing the chain, relaying\nblocks, etc. AFAIK, there is no such hybrid implementation and that's not\nwhat you want to run in a mobile.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200505/bac9a893/attachment-0001.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2020-05-05T13:00:37",
                "message_text_only": "On Tuesday 05 May 2020 10:17:37 Antoine Riard via bitcoin-dev wrote:\n> Trust-minimization of Bitcoin security model has always relied first and\n> above on running a full-node. This current paradigm may be shifted by LN\n> where fast, affordable, confidential, censorship-resistant payment services\n> may attract a lot of adoption without users running a full-node.\n\nNo, it cannot be shifted. This would compromise Bitcoin itself, which for \nsecurity depends on the assumption that a supermajority of the economy is \nverifying their incoming transactions using their own full node.\n\nThe past few years has seen severe regressions in this area, to the point \nwhere Bitcoin's future seems quite bleak. Without serious improvements to the \nfull node ratio, Bitcoin is likely to fail.\n\nTherefore, all efforts to improve the \"full node-less\" experience are harmful, \nand should be actively avoided. BIP 157 improves privacy of fn-less usage, \nwhile providing no real benefits to full node users (compared to more \nefficient protocols like Stratum/Electrum).\n\nFor this reason, myself and a few others oppose merging support for BIP 157 in \nCore.\n\n> Assuming a user adoption path where a full-node is required to benefit for\n> LN may deprive a lot of users, especially those who are already denied a\n> real financial infrastructure access.\n\nIf Bitcoin can't do it, then Bitcoin can't do it.\nBitcoin can't solve *any* problem if it becomes insecure itself.\n\nLuke\n\nP.S. See also\nhttps://medium.com/@nicolasdorier/why-i-dont-celebrate-neutrino-206bafa5fda0\nhttps://medium.com/@nicolasdorier/neutrino-is-dangerous-for-my-self-sovereignty-18fac5bcdc25"
            },
            {
                "author": "Lloyd Fournier",
                "date": "2020-05-05T15:16:01",
                "message_text_only": "On Tue, May 5, 2020 at 9:01 PM Luke Dashjr via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Tuesday 05 May 2020 10:17:37 Antoine Riard via bitcoin-dev wrote:\n> > Trust-minimization of Bitcoin security model has always relied first and\n> > above on running a full-node. This current paradigm may be shifted by LN\n> > where fast, affordable, confidential, censorship-resistant payment\n> services\n> > may attract a lot of adoption without users running a full-node.\n>\n> No, it cannot be shifted. This would compromise Bitcoin itself, which for\n> security depends on the assumption that a supermajority of the economy is\n> verifying their incoming transactions using their own full node.\n>\n\nHi Luke,\n\nI have heard this claim made several times but have never understood the\nargument behind it. The question I always have is: If I get scammed by not\nverifying my incoming transactions properly how can this affect anyone\nelse? It's very unintuative.  I've been scammed several times in my life in\nfiat currency transactions but as far as I could tell it never negatively\naffected the currency overall!\n\nThe links you point and from what I've seen you say before refer to \"miner\ncontrol\" as the culprit. My only thought is that this is because a light\nclient could follow a dishonest majority of hash power chain. But this just\nbrings me back to the question. If, instead of BTC, I get a payment in some\nminer scamcoin on their dishonest fork (but I think it's BTC because I'm\nrunning a light client) that still seems to only to damage me. Where does\nthe side effect onto others on the network come from?\n\nCheers,\n\nLL\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200505/549643a3/attachment.html>"
            },
            {
                "author": "Chris Belcher",
                "date": "2020-05-12T21:05:46",
                "message_text_only": "On 05/05/2020 16:16, Lloyd Fournier via bitcoin-dev wrote:\n> On Tue, May 5, 2020 at 9:01 PM Luke Dashjr via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n>> On Tuesday 05 May 2020 10:17:37 Antoine Riard via bitcoin-dev wrote:\n>>> Trust-minimization of Bitcoin security model has always relied first and\n>>> above on running a full-node. This current paradigm may be shifted by LN\n>>> where fast, affordable, confidential, censorship-resistant payment\n>> services\n>>> may attract a lot of adoption without users running a full-node.\n>>\n>> No, it cannot be shifted. This would compromise Bitcoin itself, which for\n>> security depends on the assumption that a supermajority of the economy is\n>> verifying their incoming transactions using their own full node.\n>>\n> \n> Hi Luke,\n> \n> I have heard this claim made several times but have never understood the\n> argument behind it. The question I always have is: If I get scammed by not\n> verifying my incoming transactions properly how can this affect anyone\n> else? It's very unintuative.  I've been scammed several times in my life in\n> fiat currency transactions but as far as I could tell it never negatively\n> affected the currency overall!\n> \n> The links you point and from what I've seen you say before refer to \"miner\n> control\" as the culprit. My only thought is that this is because a light\n> client could follow a dishonest majority of hash power chain. But this just\n> brings me back to the question. If, instead of BTC, I get a payment in some\n> miner scamcoin on their dishonest fork (but I think it's BTC because I'm\n> running a light client) that still seems to only to damage me. Where does\n> the side effect onto others on the network come from?\n> \n> Cheers,\n> \n> LL\n> \n\nHello Lloyd,\n\nThe problem comes when a large part of the ecosystem gets scammed at\nonce, which is how such an attack would happen in practice.\n\nFor example, consider if bitcoin had 10000 users. 10 of them use a full\nnode wallet while the other 9990 use an SPV wallet. If a miner attacked\nthe system by printing infinite bitcoins and spending coins without a\nvalid signature, then the 9990 SPV wallets would accept those fake coins\nas payment, and trade the coins amongst themselves. After a time those\ncoins would likely be the ancestors of most active coins in the\n9990-SPV-wallet ecosystem. Bitcoin would split into two currencies:\nfull-node-coin and SPV-coin.\n\nNow the fraud miners may become well known, perhaps being published on\nbitcoin news portals, but the 9990-SPV-wallet ecosystem has a strong\nincentive to be against any rollback. Their recent transactions would\ndisappear and they'd lose money. They would argue that they've already\nbeen using the coin for a while, and it works perfectly fine, and anyway\na coin that can be spent in 9990 places is more useful than one that can\nbe spent in just 10 places. The SPV-wallet community might even decide\nto use something like `invalidateblock` to make sure their SPV-coin\ndoesn't get reorg'd out of existence. There'd also likely be a social\nattack, with every bitcoin community portal being flooded with bots and\nshills advocating the merits of SPV-coin. This is not a hypothetical\nbecause we already saw the same thing during the scalability conflict\n2015-2017.\n\nBefore you know it, \"Bitcoin\" would become SPV-coin with inflation and\narbitrary seizure. Any normal user could download software called\n\"Bitcoin wallet\" which they trust and have used before, but instead of\nusing Bitcoin they'd be using SPV-coin. You may be one of the 10 wallets\nbacked by a full node, but that won't do much good to you when 9990\nusers happily use another coin as their medium of exchange.\n\nRegards\nCB"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-06T09:06:11",
                "message_text_only": "I do see the consensus capture argument by miners but in reality isn't this\nattack scenario have a lot of assumptions on topology an deployment ?\n\nFor such attack to succeed you need miners nodes to be connected to clients\nto feed directly the invalid headers and if these ones are connected to\nheaders/filters gateways, themselves doing full-nodes validation invalid\nchain is going to be sanitized out ?\n\nSure now you trust these gateways, but if you have multiple connections to\nthem and can guarantee they aren't run by the same entity, that maybe an\nacceptable security model, depending of staked amount and your\nexpectations. I more concerned of having a lot of them and being\ndiversified enough to avoid collusion between gateways/chain access\nproviders/miners.\n\nBut even if you light clients is directly connected to the backbone network\nand may be reached by miners you can implement fork anomalies detection and\nfrom then you may have multiples options:\n* halt the wallet, wait for human intervention\n* fallback connection to a trusted server, authoritative on your chain view\n* invalidity proofs?\n\nNow I agree you need a wide-enough, sane backbone network to build on top,\nand we should foster node adoption as much as we can.\n\nLe mar. 5 mai 2020 \u00e0 09:01, Luke Dashjr <luke at dashjr.org> a \u00e9crit :\n\n> On Tuesday 05 May 2020 10:17:37 Antoine Riard via bitcoin-dev wrote:\n> > Trust-minimization of Bitcoin security model has always relied first and\n> > above on running a full-node. This current paradigm may be shifted by LN\n> > where fast, affordable, confidential, censorship-resistant payment\n> services\n> > may attract a lot of adoption without users running a full-node.\n>\n> No, it cannot be shifted. This would compromise Bitcoin itself, which for\n> security depends on the assumption that a supermajority of the economy is\n> verifying their incoming transactions using their own full node.\n>\n> The past few years has seen severe regressions in this area, to the point\n> where Bitcoin's future seems quite bleak. Without serious improvements to\n> the\n> full node ratio, Bitcoin is likely to fail.\n>\n> Therefore, all efforts to improve the \"full node-less\" experience are\n> harmful,\n> and should be actively avoided. BIP 157 improves privacy of fn-less usage,\n> while providing no real benefits to full node users (compared to more\n> efficient protocols like Stratum/Electrum).\n>\n> For this reason, myself and a few others oppose merging support for BIP\n> 157 in\n> Core.\n>\n> > Assuming a user adoption path where a full-node is required to benefit\n> for\n> > LN may deprive a lot of users, especially those who are already denied a\n> > real financial infrastructure access.\n>\n> If Bitcoin can't do it, then Bitcoin can't do it.\n> Bitcoin can't solve *any* problem if it becomes insecure itself.\n>\n> Luke\n>\n> P.S. See also\n>\n> https://medium.com/@nicolasdorier/why-i-dont-celebrate-neutrino-206bafa5fda0\n>\n> https://medium.com/@nicolasdorier/neutrino-is-dangerous-for-my-self-sovereignty-18fac5bcdc25\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200506/7b20c4d4/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "On the scalability issues of onboarding millions of LN mobile clients",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Chris Belcher",
                "Luke Dashjr",
                "Antoine Riard",
                "Lloyd Fournier"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 17384
        }
    },
    {
        "title": "[bitcoin-dev] [Lightning-dev] On the scalability issues of onboarding millions of LN mobile clients",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-05T13:49:58",
                "message_text_only": "Good morning ariard and luke-jr\n\n\n> > Trust-minimization of Bitcoin security model has always relied first and\n> > above on running a full-node. This current paradigm may be shifted by LN\n> > where fast, affordable, confidential, censorship-resistant payment services\n> > may attract a lot of adoption without users running a full-node.\n>\n> No, it cannot be shifted. This would compromise Bitcoin itself, which for\n> security depends on the assumption that a supermajority of the economy is\n> verifying their incoming transactions using their own full node.\n>\n> The past few years has seen severe regressions in this area, to the point\n> where Bitcoin's future seems quite bleak. Without serious improvements to the\n> full node ratio, Bitcoin is likely to fail.\n>\n> Therefore, all efforts to improve the \"full node-less\" experience are harmful,\n> and should be actively avoided. BIP 157 improves privacy of fn-less usage,\n> while providing no real benefits to full node users (compared to more\n> efficient protocols like Stratum/Electrum).\n>\n> For this reason, myself and a few others oppose merging support for BIP 157 in\n> Core.\n\nBIP 157 can be implemented as a separate daemon that processes the blocks downloaded by an attached `bitcoind`, i.e. what Wasabi does.\n\nThe intention, as I understood it, of putting BIP157 directly into bitcoind was to essentially force all `bitcoind` users to possibly service BIP157 clients, in the hope that a BIP157 client can contact any arbitrary fullnode to get BIP157 service.\nThis is supposed to improve to the situation relative to e.g. Electrum, where there are far fewer Electrum servers than fullnodes.\n\nOf course, as ariard computes, deploying BIP157 could lead to an effective DDoS on the fullnode network if a large number of BIP157 clients arise.\nThough maybe this will not occur very fast?  We hope?\n\nIt seems to me that the thing that *could* be done would be to have watchtowers provide light-client services, since that seems to be the major business model of watchtowers, as suggested by ariard as well.\nThis is still less than ideal, but maybe is better than nothing.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "John Newbery",
                "date": "2020-05-05T17:09:33",
                "message_text_only": "There doesn't seem to be anything in the original email that's specific to\nBIP 157. It's a restatement of the arguments against light clients:\n\n- light clients are a burden on the full nodes that serve them\n- if light clients become more popular, there won't be enough full nodes to\nserve them\n- people might build products that depend on altruistic nodes serving data,\nwhich is unsustainable\n- maybe at some point in the future, light clients will need to pay for\nservices\n\nThe choice isn't between people using light clients or not. People already\nuse light clients. The choice between whether we offer them a light client\ntechnology that is better or worse for privacy and scalability.\n\nThe arguments for why BIP 157 is better than the existing light client\ntechnologies are available elsewhere, but to summarize:\n\n- they're unique for a block, which means they can easily be cached.\nServing a filter requires no computation, just i/o (or memory access for\ncached filter/header data) and bandwidth. There are plenty of other\nservices that a full node offers that use i/o and bandwidth, such as\nserving blocks.\n- unique-for-block means clients can download from multiple sources\n- the linked-headers/filters model allows hybrid approaches, where headers\ncheckpoints can be fetched from trusted/signed nodes, with intermediate\nheaders and filters fetched from untrusted sources\n- less possibilities to DoS/waste resources on the serving node\n- better for privacy\n\n> The intention, as I understood it, of putting BIP157 directly into\nbitcoind was to essentially force all `bitcoind` users to possibly service\nBIP157 clients\n\nPlease. No-one is forcing anyone to do anything. To serve filters, a node\nuser needs to download the latest version, set `-blockfilterindex=basic` to\nbuild the compact filters index, and set `-peercfilters` to serve them over\nP2P. This is an optional, off-by-default feature.\n\nRegards,\nJohn\n\n\nOn Tue, May 5, 2020 at 9:50 AM ZmnSCPxj via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning ariard and luke-jr\n>\n>\n> > > Trust-minimization of Bitcoin security model has always relied first\n> and\n> > > above on running a full-node. This current paradigm may be shifted by\n> LN\n> > > where fast, affordable, confidential, censorship-resistant payment\n> services\n> > > may attract a lot of adoption without users running a full-node.\n> >\n> > No, it cannot be shifted. This would compromise Bitcoin itself, which for\n> > security depends on the assumption that a supermajority of the economy is\n> > verifying their incoming transactions using their own full node.\n> >\n> > The past few years has seen severe regressions in this area, to the point\n> > where Bitcoin's future seems quite bleak. Without serious improvements\n> to the\n> > full node ratio, Bitcoin is likely to fail.\n> >\n> > Therefore, all efforts to improve the \"full node-less\" experience are\n> harmful,\n> > and should be actively avoided. BIP 157 improves privacy of fn-less\n> usage,\n> > while providing no real benefits to full node users (compared to more\n> > efficient protocols like Stratum/Electrum).\n> >\n> > For this reason, myself and a few others oppose merging support for BIP\n> 157 in\n> > Core.\n>\n> BIP 157 can be implemented as a separate daemon that processes the blocks\n> downloaded by an attached `bitcoind`, i.e. what Wasabi does.\n>\n> The intention, as I understood it, of putting BIP157 directly into\n> bitcoind was to essentially force all `bitcoind` users to possibly service\n> BIP157 clients, in the hope that a BIP157 client can contact any arbitrary\n> fullnode to get BIP157 service.\n> This is supposed to improve to the situation relative to e.g. Electrum,\n> where there are far fewer Electrum servers than fullnodes.\n>\n> Of course, as ariard computes, deploying BIP157 could lead to an effective\n> DDoS on the fullnode network if a large number of BIP157 clients arise.\n> Though maybe this will not occur very fast?  We hope?\n>\n> It seems to me that the thing that *could* be done would be to have\n> watchtowers provide light-client services, since that seems to be the major\n> business model of watchtowers, as suggested by ariard as well.\n> This is still less than ideal, but maybe is better than nothing.\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200505/be23bd38/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-06T09:21:17",
                "message_text_only": "> The choice between whether we offer them a light client technology that\nis better or worse for privacy and scalability.\n\nAnd offer them a solution which would scale in the long-term.\n\nAgain it's not an argumentation against BIP 157 protocol in itself, the\nproblem I'm interested in is how implementing BIP157 in Core will address\nthis issue ?\n\nLe mar. 5 mai 2020 \u00e0 13:36, John Newbery via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n> There doesn't seem to be anything in the original email that's specific to\n> BIP 157. It's a restatement of the arguments against light clients:\n>\n> - light clients are a burden on the full nodes that serve them\n> - if light clients become more popular, there won't be enough full nodes\n> to serve them\n> - people might build products that depend on altruistic nodes serving\n> data, which is unsustainable\n> - maybe at some point in the future, light clients will need to pay for\n> services\n>\n> The choice isn't between people using light clients or not. People already\n> use light clients. The choice between whether we offer them a light client\n> technology that is better or worse for privacy and scalability.\n>\n> The arguments for why BIP 157 is better than the existing light client\n> technologies are available elsewhere, but to summarize:\n>\n> - they're unique for a block, which means they can easily be cached.\n> Serving a filter requires no computation, just i/o (or memory access for\n> cached filter/header data) and bandwidth. There are plenty of other\n> services that a full node offers that use i/o and bandwidth, such as\n> serving blocks.\n> - unique-for-block means clients can download from multiple sources\n> - the linked-headers/filters model allows hybrid approaches, where headers\n> checkpoints can be fetched from trusted/signed nodes, with intermediate\n> headers and filters fetched from untrusted sources\n> - less possibilities to DoS/waste resources on the serving node\n> - better for privacy\n>\n> > The intention, as I understood it, of putting BIP157 directly into\n> bitcoind was to essentially force all `bitcoind` users to possibly service\n> BIP157 clients\n>\n> Please. No-one is forcing anyone to do anything. To serve filters, a node\n> user needs to download the latest version, set `-blockfilterindex=basic` to\n> build the compact filters index, and set `-peercfilters` to serve them over\n> P2P. This is an optional, off-by-default feature.\n>\n> Regards,\n> John\n>\n>\n> On Tue, May 5, 2020 at 9:50 AM ZmnSCPxj via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Good morning ariard and luke-jr\n>>\n>>\n>> > > Trust-minimization of Bitcoin security model has always relied first\n>> and\n>> > > above on running a full-node. This current paradigm may be shifted by\n>> LN\n>> > > where fast, affordable, confidential, censorship-resistant payment\n>> services\n>> > > may attract a lot of adoption without users running a full-node.\n>> >\n>> > No, it cannot be shifted. This would compromise Bitcoin itself, which\n>> for\n>> > security depends on the assumption that a supermajority of the economy\n>> is\n>> > verifying their incoming transactions using their own full node.\n>> >\n>> > The past few years has seen severe regressions in this area, to the\n>> point\n>> > where Bitcoin's future seems quite bleak. Without serious improvements\n>> to the\n>> > full node ratio, Bitcoin is likely to fail.\n>> >\n>> > Therefore, all efforts to improve the \"full node-less\" experience are\n>> harmful,\n>> > and should be actively avoided. BIP 157 improves privacy of fn-less\n>> usage,\n>> > while providing no real benefits to full node users (compared to more\n>> > efficient protocols like Stratum/Electrum).\n>> >\n>> > For this reason, myself and a few others oppose merging support for BIP\n>> 157 in\n>> > Core.\n>>\n>> BIP 157 can be implemented as a separate daemon that processes the blocks\n>> downloaded by an attached `bitcoind`, i.e. what Wasabi does.\n>>\n>> The intention, as I understood it, of putting BIP157 directly into\n>> bitcoind was to essentially force all `bitcoind` users to possibly service\n>> BIP157 clients, in the hope that a BIP157 client can contact any arbitrary\n>> fullnode to get BIP157 service.\n>> This is supposed to improve to the situation relative to e.g. Electrum,\n>> where there are far fewer Electrum servers than fullnodes.\n>>\n>> Of course, as ariard computes, deploying BIP157 could lead to an\n>> effective DDoS on the fullnode network if a large number of BIP157 clients\n>> arise.\n>> Though maybe this will not occur very fast?  We hope?\n>>\n>> It seems to me that the thing that *could* be done would be to have\n>> watchtowers provide light-client services, since that seems to be the major\n>> business model of watchtowers, as suggested by ariard as well.\n>> This is still less than ideal, but maybe is better than nothing.\n>>\n>> Regards,\n>> ZmnSCPxj\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200506/8f7f3555/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-13T19:51:29",
                "message_text_only": "Hi Chris,\n\nWhile approaching this question, I think you should consider economic\nweight of nodes in evaluating miner consensus-hijack success. Even if you\nexpect a disproportionate ratio of full-nodes-vs-SPV, they may not have the\nsame  economic weight at all, therefore even if miners are able to lure a\nmajority of SPV clients they may not be able to stir economic nodes. SPV\nclients users will now have an incentive to cancel their hijacked history\nto stay on the most economic meaningful chain. And it's already assumed,\nthat if you run a bitcoin business or LN routing node, you do want to run\nyour own full-node.\n\nI agree it may be hard to evaluate economic-weight-to-chain-backend\nsegments, specially with offchain you disentangle an onchain output value\nfrom its real payment traffic. To strengthen SPV, you may implement forks\ndetection and fallback to some backup node(s) which would serve as an\nauthoritative source to arbiter between branches. Such backup node(s) must\nbe picked up manually at client initialization, before any risk of conflict\nto avoid Reddit-style of hijack during contentious period or other massive\nsocial engineering. You don't want autopilot-style of recommendations for\npicking up a backup nodes and avoid cenralization of backups, but somehow a\nuniform distribution. A backup node may be a private one, it won't serve\nyou any data beyond headers, and therefore you preserve public nodes\nbandwidth, which IMO is the real bottleneck. I concede it won't work well\nif you have a ratio of 1000-SPV for 1-full-node and people are not\neffectively able to pickup a backup among their social environment.\n\nWhat do you think about this model ?\n\nCheers,\n\nAntoine\n\nLe mar. 12 mai 2020 \u00e0 17:06, Chris Belcher <belcher at riseup.net> a \u00e9crit :\n\n> On 05/05/2020 16:16, Lloyd Fournier via bitcoin-dev wrote:\n> > On Tue, May 5, 2020 at 9:01 PM Luke Dashjr via bitcoin-dev <\n> > bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >\n> >> On Tuesday 05 May 2020 10:17:37 Antoine Riard via bitcoin-dev wrote:\n> >>> Trust-minimization of Bitcoin security model has always relied first\n> and\n> >>> above on running a full-node. This current paradigm may be shifted by\n> LN\n> >>> where fast, affordable, confidential, censorship-resistant payment\n> >> services\n> >>> may attract a lot of adoption without users running a full-node.\n> >>\n> >> No, it cannot be shifted. This would compromise Bitcoin itself, which\n> for\n> >> security depends on the assumption that a supermajority of the economy\n> is\n> >> verifying their incoming transactions using their own full node.\n> >>\n> >\n> > Hi Luke,\n> >\n> > I have heard this claim made several times but have never understood the\n> > argument behind it. The question I always have is: If I get scammed by\n> not\n> > verifying my incoming transactions properly how can this affect anyone\n> > else? It's very unintuative.  I've been scammed several times in my life\n> in\n> > fiat currency transactions but as far as I could tell it never negatively\n> > affected the currency overall!\n> >\n> > The links you point and from what I've seen you say before refer to\n> \"miner\n> > control\" as the culprit. My only thought is that this is because a light\n> > client could follow a dishonest majority of hash power chain. But this\n> just\n> > brings me back to the question. If, instead of BTC, I get a payment in\n> some\n> > miner scamcoin on their dishonest fork (but I think it's BTC because I'm\n> > running a light client) that still seems to only to damage me. Where does\n> > the side effect onto others on the network come from?\n> >\n> > Cheers,\n> >\n> > LL\n> >\n>\n> Hello Lloyd,\n>\n> The problem comes when a large part of the ecosystem gets scammed at\n> once, which is how such an attack would happen in practice.\n>\n> For example, consider if bitcoin had 10000 users. 10 of them use a full\n> node wallet while the other 9990 use an SPV wallet. If a miner attacked\n> the system by printing infinite bitcoins and spending coins without a\n> valid signature, then the 9990 SPV wallets would accept those fake coins\n> as payment, and trade the coins amongst themselves. After a time those\n> coins would likely be the ancestors of most active coins in the\n> 9990-SPV-wallet ecosystem. Bitcoin would split into two currencies:\n> full-node-coin and SPV-coin.\n>\n> Now the fraud miners may become well known, perhaps being published on\n> bitcoin news portals, but the 9990-SPV-wallet ecosystem has a strong\n> incentive to be against any rollback. Their recent transactions would\n> disappear and they'd lose money. They would argue that they've already\n> been using the coin for a while, and it works perfectly fine, and anyway\n> a coin that can be spent in 9990 places is more useful than one that can\n> be spent in just 10 places. The SPV-wallet community might even decide\n> to use something like `invalidateblock` to make sure their SPV-coin\n> doesn't get reorg'd out of existence. There'd also likely be a social\n> attack, with every bitcoin community portal being flooded with bots and\n> shills advocating the merits of SPV-coin. This is not a hypothetical\n> because we already saw the same thing during the scalability conflict\n> 2015-2017.\n>\n> Before you know it, \"Bitcoin\" would become SPV-coin with inflation and\n> arbitrary seizure. Any normal user could download software called\n> \"Bitcoin wallet\" which they trust and have used before, but instead of\n> using Bitcoin they'd be using SPV-coin. You may be one of the 10 wallets\n> backed by a full node, but that won't do much good to you when 9990\n> users happily use another coin as their medium of exchange.\n>\n> Regards\n> CB\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200513/91739e5e/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-14T04:02:07",
                "message_text_only": "Good morning Antoine,\n\n\n> While approaching this question, I think you should consider economic weight of nodes in evaluating miner consensus-hijack success. Even if you expect a disproportionate ratio of full-nodes-vs-SPV, they may not have the same \u00a0economic weight at all, therefore even if miners are able to lure a majority of SPV clients they may not be able to stir economic nodes. SPV clients users will now have an incentive to cancel their hijacked history to stay on the most economic meaningful chain. And it's already assumed, that if you run a bitcoin business or LN routing node, you do want to run your own full-node.\n\nOne hope I have for Lightning is that it will replace centralized custodial services, because:\n\n* Lightning gains some of the scalability advantage of centralized custodial services, because you can now transfer to any Lightning client without touching the blockchain, for much reduced transfer fees.\n* At the same time, it retains your-keys-your-coins noncustodiality, because every update of a Lightning channel requires your keys to sign off on it.\n\nIf most Lightning clients are SPV, then if we compare these two worlds:\n\n* There are a few highly-important centralized custodial services with significant economic weight running fullnodes (i.e. now).\n* There are no highly-important centralized custodial services, and most everyone uses Lightning, but with SPV (i.e. a Lightning future).\n\nThen the distribution of economic weight would be different between these two worlds.\nIt may even be possible, that the Lightning future with massive SPV might end up with more economic weight in SPV nodes, than in the world without Lightning and dependent on centralized custodial services to scale.\n\n\nIt is also entirely possible that custodial services for Lightning will arise anyway and my hope is already dashed, come on universe, work harder will you, would you really disappoint some randomly-generated Internet person like that.\n\n\n>\n> I agree it may be hard to evaluate economic-weight-to-chain-backend segments, specially with offchain you disentangle an onchain output value from its real payment traffic. To strengthen SPV, you may implement forks detection and fallback to some backup node(s) which would serve as an authoritative source to arbiter between branches. Such backup node(s) must be picked up manually at client initialization, before any risk of conflict to avoid Reddit-style of hijack during contentious period or other massive social engineering. You don't want autopilot-style of recommendations for picking up a backup nodes and avoid cenralization of backups, but somehow a uniform distribution. A backup node may be a private one, it won't serve you any data beyond headers, and therefore you preserve public nodes bandwidth, which IMO is the real bottleneck. I concede it won't work well if you have a ratio of 1000-SPV for 1-full-node and people are not effectively able to pickup a backup among their social environment.\n> What do you think about this model ?\n\nMoney makes the world go round, so such backup servers that are publicly-facing rather than privately-owned should be somehow incentivized to do so, or else they would not exist in the first place.\nOf course, a free market tends towards monopoly, because any entity that happens to have even a slight advantage at the business will have more money to use towards business reinvestment and increase its advantage further, until they beat the competition to dust, anyone who has won a 4X game knows to search for and stack those little advantages until you snowball and conquer the world/galaxy/petri dish which is why the endgame of 4X games is so boring compared to the start, we have seen this happen in mining and exchanges and so on, and this works against your desire to have a uniform distribution.\n\nIf everyone runs such a privately-owned server, on the other hand, this is not so different from having a Lightning node you run at your home that has a fullnode as well and which you access via a remote control mobile device, and it is the inconvenience of having such a server at your home that prevents this in the first place.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Keagan McClelland",
                "date": "2020-05-14T15:25:57",
                "message_text_only": "> It should be therefore a top priority to make the UX of connecting my\nmobile LN client to my home full node extremely easy, so that centralised\nservices can't improve much on that step. Especially if I already run a\nfull node.\n\nFor what it's worth, this is a main research area for us at Start9 Labs.\n\n> Could someone briefly describe how this UX looks currently? And if it's\nnot as seamless as it could, what blockers are there?\n\nAt the root of all of these problems is that a \"private server\" is\nconsidered inconvenient. There is no fundamental reason this has to be the\ncase. The main UX challenges we've found are around installation and\nconfiguration of server applications, not to mention, that users don't have\nan existing mental model for how to imagine applications. Most people who\ndo not work on computers for a living have heard of servers but their\nfirsthand experience with software is \"apps\". The fact that there is a\ncomponent of their applications that runs remotely on computers they don't\nown.\n\nSo in short:\n1. Educating on the distinction between client and server apps is an open\nquestion whose burden will likely fall on the entire industry if we want to\nget this right and not have an exchange takeover of Bitcoin.\n2. Apps that either require \"zero configuration\" or have very easy in-app\nwalkthroughs of the bare essentials of configuration\n3. GUI style installs of server applications familiar to those who have\ninstalled desktop or mobile software.\n\nI'm sure there are more things we'll learn as we grow but these are the top\nthree observations we've made and this is our primary area of work.\n\n> Private full nodes serving headers to a handful of weak devices have been\nmentioned many times as a good solution against all sorts of problems in a\nfuture full of LN + SPV nodes. I agree.\n\nThis is the main thesis I've been going on for a while. Once your full node\nhas synced the whole blockchain and the total set of headers is known, you\ndon't actually even need to carry 100% of the block data, as you can\nre-fetch a needed block from elsewhere and verify the block data matches\nthe header you've already checked for consensus. From there the header\nchain can serve as base truth for a whole set of L2+ services or L1 SPV\nwallets. Ideally, in a model like this, more expensive peer services would\nbe authenticated so that your other applications could get the data they\nneed without exposing your full node to the extra costs of those who are\nnot running their own nodes. Typically we've used Core's RPC API for this\nbut as others have mentioned upthread JSON is a wasteful format and there\nare good reasons that you'd want Lightning to be able to request peer\nservices without necessarily having ownership control over the node.\n\nThe other thing I wanted to note is the fact that the issue isn't that\nLightning does SPV, the issue is around whether or not the node it is\ntethered to is *actually* trusted since SPV necessarily trusts some\ndimensions of the information supplied to it. Doing SPV against a full node\nyou own is no more dangerous than indexing watch only addresses in Core and\nthen asking for wallet/utxo information over RPC.\n\nKeagan\n\nOn Thu, May 14, 2020 at 12:50 AM Orfeas Stefanos Thyfronitis Litos <\no.thyfronitis at ed.ac.uk> wrote:\n\n>\n>\n> >If everyone runs such a privately-owned server, on the other hand, this\n> >is not so different from having a Lightning node you run at your home\n> >that has a fullnode as well and which you access via a remote control\n> >mobile device, and it is the inconvenience of having such a server at\n> >your home that prevents this in the first place.\n>\n> Private full nodes serving headers to a handful of weak devices have been\n> mentioned many times as a good solution against all sorts of problems in a\n> future full of LN + SPV nodes. I agree. It should be therefore a top\n> priority to make the UX of connecting my mobile LN client to my home full\n> node extremely easy, so that centralised services can't improve much on\n> that step. Especially if I already run a full node.\n>\n> Could someone briefly describe how this UX looks currently? And if it's\n> not as seamless as it could, what blockers are there?\n>\n> Best,\n> Orfeas\n>\n> --\n> The University of Edinburgh is a charitable body, registered in\n> Scotland, with registration number SC005336.\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200514/8cf2f0f1/attachment.html>"
            },
            {
                "author": "Christopher Allen",
                "date": "2020-05-17T09:11:33",
                "message_text_only": "On Thu, May 14, 2020 at 8:30 AM Keagan McClelland via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> > It should be therefore a top priority to make the UX of connecting my\n> mobile LN client to my home full node extremely easy, so that centralised\n> services can't improve much on that step. Especially if I already run a\n> full node.\n>\n\nThere already is an emerging approach for this, called QuickConnect\nhttps://github.com/BlockchainCommons/Bitcoin-Standup/blob/master/Docs/Quick-Connect-API.md\n\nIt is currently offered by BitcoinStandup (both Mac and Linux),\nBTCPayServer, Nodl, MyNode, RaspiBlitz full node tools and hardware, and is\nused currently by FullyNoded, FullyNoded2, and a couple of other\nexperimental apps to allow secure connection via Tor v3 from a remote to\nyour own personal full node.\n\nWe know that QuickConnect needs another major iteration and welcome\ncontributions to requirements and/or proposals for the next version.\n\nWe invite you to share your thoughts here.\nhttps://github.com/BlockchainCommons/Bitcoin-Standup/issues/66\n\n\u2014 Christopher Allen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200517/f483ba8b/attachment.html>"
            },
            {
                "author": "William Casarin",
                "date": "2020-05-14T15:27:11",
                "message_text_only": "Orfeas Stefanos Thyfronitis Litos <o.thyfronitis at ed.ac.uk> writes:\n> ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> writes:\n>> If everyone runs such a privately-owned server, on the other hand, this\n>> is not so different from having a Lightning node you run at your home\n>> that has a fullnode as well and which you access via a remote control\n>> mobile device, and it is the inconvenience of having such a server at\n>> your home that prevents this in the first place.\n>\n> Private full nodes serving headers to a handful of weak devices have\n> been mentioned many times as a good solution against all sorts of\n> problems in a future full of LN + SPV nodes. I agree. It should be\n> therefore a top priority to make the UX of connecting my mobile LN\n> client to my home full node extremely easy, so that centralised\n> services can't improve much on that step. Especially if I already run\n> a full node.\n>\n> Could someone briefly describe how this UX looks currently? And if\n> it's not as seamless as it could, what blockers are there?\n\nThe UX for this doesn't have to be complicated. All you need is a node\nprovider like FullyNoded, Casa, etc. My setup at home is a desktop with:\n\n  - bitcoind\n  - clightning\n  - zerotier (or tailscale) (private vpn for connecting to your node from anywhere)\n  - sparkwallet (clightning webui) bound to a zerotier interface\n\nSo as long as you have a node that runs these bits of software, perhaps\nassumeutxo to speed up IBD, and a QR-code automagic setup, then UX\nshould be pretty smooth. You would still need to deal with lightning\nbackups and liquidity issues, but we just need to do more work on the\nsoftware side to make that experience nicer.\n\nCheers,\nWill\n\n\n--\nhttps://jb55.com"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-17T03:37:46",
                "message_text_only": "> * At the same time, it retains your-keys-your-coins noncustodiality,\nbecause every update of a Lightning channel requires your keys to sign off\non it.\n\nYes I agree, I can foresee an easier step where managing low-value channel\nand get your familiar with smooth key management maybe a first step before\nrunning a full-node and getting a more full-fledged key management solution.\n\n> It may even be possible, that the Lightning future with massive SPV might\nend up with more economic weight in SPV nodes, than in the world without\nLightning and dependent on centralized custodial services to scale.\n\nEven evaluating economic weight in Lightning is hard, both parties have\ntheir own chain view, and it's likely if you assume a hub-and-spoke\ntopology, leaf nodes are going to be SPV and internal nodes full-nodes ?\n\n> Money makes the world go round, so such backup servers that are\npublicly-facing rather than privately-owned should be somehow incentivized\nto do so, or else they would not exist in the first place.\n\nI was thinking about the current workflow, Alice downloads her New Shiny\nLN-wallet, she is asked to backup the seed, she is asked to pick-up\nbackup(s) nodes among her friends, relatives or business partners and is\nNOT provided any automatic hint and register backup nodes addresses, maybe\neven do out-of-band key exchange with this full-node operator. Therefore\nyou may avoid centralization by having not such publicly-facing servers. Of\ncourse, Alice can still scrawl the web to and be lured to pickup malicious\npublic servers but if she is severely notified to not do so that may be\nenough.\n\nSo it would be a combination of UX+user education+fallback security\nmechanism to avoid economy hijack. That maybe a better solution rather than\nPoW-only SPV. We have an open network so you can't prevent someone to run\nsuch type of client but at least if they have to do so you can provide them\nwith a better option ?\n\nAntoine\n\n\n\n\nLe jeu. 14 mai 2020 \u00e0 00:02, ZmnSCPxj <ZmnSCPxj at protonmail.com> a \u00e9crit :\n\n> Good morning Antoine,\n>\n>\n> > While approaching this question, I think you should consider economic\n> weight of nodes in evaluating miner consensus-hijack success. Even if you\n> expect a disproportionate ratio of full-nodes-vs-SPV, they may not have the\n> same  economic weight at all, therefore even if miners are able to lure a\n> majority of SPV clients they may not be able to stir economic nodes. SPV\n> clients users will now have an incentive to cancel their hijacked history\n> to stay on the most economic meaningful chain. And it's already assumed,\n> that if you run a bitcoin business or LN routing node, you do want to run\n> your own full-node.\n>\n> One hope I have for Lightning is that it will replace centralized\n> custodial services, because:\n>\n> * Lightning gains some of the scalability advantage of centralized\n> custodial services, because you can now transfer to any Lightning client\n> without touching the blockchain, for much reduced transfer fees.\n> * At the same time, it retains your-keys-your-coins noncustodiality,\n> because every update of a Lightning channel requires your keys to sign off\n> on it.\n>\n> If most Lightning clients are SPV, then if we compare these two worlds:\n>\n> * There are a few highly-important centralized custodial services with\n> significant economic weight running fullnodes (i.e. now).\n> * There are no highly-important centralized custodial services, and most\n> everyone uses Lightning, but with SPV (i.e. a Lightning future).\n>\n> Then the distribution of economic weight would be different between these\n> two worlds.\n> It may even be possible, that the Lightning future with massive SPV might\n> end up with more economic weight in SPV nodes, than in the world without\n> Lightning and dependent on centralized custodial services to scale.\n>\n>\n> It is also entirely possible that custodial services for Lightning will\n> arise anyway and my hope is already dashed, come on universe, work harder\n> will you, would you really disappoint some randomly-generated Internet\n> person like that.\n>\n>\n> >\n> > I agree it may be hard to evaluate economic-weight-to-chain-backend\n> segments, specially with offchain you disentangle an onchain output value\n> from its real payment traffic. To strengthen SPV, you may implement forks\n> detection and fallback to some backup node(s) which would serve as an\n> authoritative source to arbiter between branches. Such backup node(s) must\n> be picked up manually at client initialization, before any risk of conflict\n> to avoid Reddit-style of hijack during contentious period or other massive\n> social engineering. You don't want autopilot-style of recommendations for\n> picking up a backup nodes and avoid cenralization of backups, but somehow a\n> uniform distribution. A backup node may be a private one, it won't serve\n> you any data beyond headers, and therefore you preserve public nodes\n> bandwidth, which IMO is the real bottleneck. I concede it won't work well\n> if you have a ratio of 1000-SPV for 1-full-node and people are not\n> effectively able to pickup a backup among their social environment.\n> > What do you think about this model ?\n>\n> Money makes the world go round, so such backup servers that are\n> publicly-facing rather than privately-owned should be somehow incentivized\n> to do so, or else they would not exist in the first place.\n> Of course, a free market tends towards monopoly, because any entity that\n> happens to have even a slight advantage at the business will have more\n> money to use towards business reinvestment and increase its advantage\n> further, until they beat the competition to dust, anyone who has won a 4X\n> game knows to search for and stack those little advantages until you\n> snowball and conquer the world/galaxy/petri dish which is why the endgame\n> of 4X games is so boring compared to the start, we have seen this happen in\n> mining and exchanges and so on, and this works against your desire to have\n> a uniform distribution.\n>\n> If everyone runs such a privately-owned server, on the other hand, this is\n> not so different from having a Lightning node you run at your home that has\n> a fullnode as well and which you access via a remote control mobile device,\n> and it is the inconvenience of having such a server at your home that\n> prevents this in the first place.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200516/5aa4025e/attachment.html>"
            },
            {
                "author": "Keagan McClelland",
                "date": "2020-05-06T16:00:15",
                "message_text_only": "Hi Antoine,\n\nConsensus capture by miners isn't the only concern here. Consensus capture\nby any subset of users whose interests diverge from the overall consensus\nis equally damaging. The scenario I can imagine here is that the more light\nclients outpace full nodes, the more the costs of security are being\nexternalized from the light clients onto the full nodes. In this situation,\nit can make full nodes harder to run. If they are harder to run it will\nprice out some marginal set of full node operators, which causes a net new\nincrease in light clients (as the disaffected full nodes convert), AND a\nredistribution of load onto a smaller surface area. This is a naturally\nunstable process. It is safe to say that as node counts drop, the set of\nnode operators will increasingly represent economic actors with extreme\nweight. The more this process unfolds, the more likely their interests will\ndiverge from the population at large, and also the more likely they can be\ncoerced into behavior they otherwise wouldn't. After all it is easier to\nfind agents who carry lots of economic weight. This is true independent of\ntheir mining status, we should be just as wary of consensus capture by\nexchanges or HNWI's as we are about miners.\n\nKeagan\n\nOn Wed, May 6, 2020 at 3:06 AM Antoine Riard <antoine.riard at gmail.com>\nwrote:\n\n> I do see the consensus capture argument by miners but in reality isn't\n> this attack scenario have a lot of assumptions on topology an deployment ?\n>\n> For such attack to succeed you need miners nodes to be connected to\n> clients to feed directly the invalid headers and if these ones are\n> connected to headers/filters gateways, themselves doing full-nodes\n> validation invalid chain is going to be sanitized out ?\n>\n> Sure now you trust these gateways, but if you have multiple connections to\n> them and can guarantee they aren't run by the same entity, that maybe an\n> acceptable security model, depending of staked amount and your\n> expectations. I more concerned of having a lot of them and being\n> diversified enough to avoid collusion between gateways/chain access\n> providers/miners.\n>\n> But even if you light clients is directly connected to the backbone\n> network and may be reached by miners you can implement fork anomalies\n> detection and from then you may have multiples options:\n> * halt the wallet, wait for human intervention\n> * fallback connection to a trusted server, authoritative on your chain view\n> * invalidity proofs?\n>\n> Now I agree you need a wide-enough, sane backbone network to build on top,\n> and we should foster node adoption as much as we can.\n>\n> Le mar. 5 mai 2020 \u00e0 09:01, Luke Dashjr <luke at dashjr.org> a \u00e9crit :\n>\n>> On Tuesday 05 May 2020 10:17:37 Antoine Riard via bitcoin-dev wrote:\n>> > Trust-minimization of Bitcoin security model has always relied first and\n>> > above on running a full-node. This current paradigm may be shifted by LN\n>> > where fast, affordable, confidential, censorship-resistant payment\n>> services\n>> > may attract a lot of adoption without users running a full-node.\n>>\n>> No, it cannot be shifted. This would compromise Bitcoin itself, which for\n>> security depends on the assumption that a supermajority of the economy is\n>> verifying their incoming transactions using their own full node.\n>>\n>> The past few years has seen severe regressions in this area, to the point\n>> where Bitcoin's future seems quite bleak. Without serious improvements to\n>> the\n>> full node ratio, Bitcoin is likely to fail.\n>>\n>> Therefore, all efforts to improve the \"full node-less\" experience are\n>> harmful,\n>> and should be actively avoided. BIP 157 improves privacy of fn-less\n>> usage,\n>> while providing no real benefits to full node users (compared to more\n>> efficient protocols like Stratum/Electrum).\n>>\n>> For this reason, myself and a few others oppose merging support for BIP\n>> 157 in\n>> Core.\n>>\n>> > Assuming a user adoption path where a full-node is required to benefit\n>> for\n>> > LN may deprive a lot of users, especially those who are already denied a\n>> > real financial infrastructure access.\n>>\n>> If Bitcoin can't do it, then Bitcoin can't do it.\n>> Bitcoin can't solve *any* problem if it becomes insecure itself.\n>>\n>> Luke\n>>\n>> P.S. See also\n>>\n>> https://medium.com/@nicolasdorier/why-i-dont-celebrate-neutrino-206bafa5fda0\n>>\n>> https://medium.com/@nicolasdorier/neutrino-is-dangerous-for-my-self-sovereignty-18fac5bcdc25\n>>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200506/ce5bff4d/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-07T03:56:17",
                "message_text_only": "What I'm thinking more is if the costs of security are being too much\nexternalized from the light clients onto full nodes, nodes operators are\njust going to stop servicing light clients `peercfilters=false`. The\nbackbone p2p network is going to be fine. But the massive LN light clients\nnetwork built on top is going to rely on centralized services for its chain\naccess and now you may have consensus capture by those..\n\nLe mer. 6 mai 2020 \u00e0 12:00, Keagan McClelland <keagan.mcclelland at gmail.com>\na \u00e9crit :\n\n> Hi Antoine,\n>\n> Consensus capture by miners isn't the only concern here. Consensus capture\n> by any subset of users whose interests diverge from the overall consensus\n> is equally damaging. The scenario I can imagine here is that the more light\n> clients outpace full nodes, the more the costs of security are being\n> externalized from the light clients onto the full nodes. In this situation,\n> it can make full nodes harder to run. If they are harder to run it will\n> price out some marginal set of full node operators, which causes a net new\n> increase in light clients (as the disaffected full nodes convert), AND a\n> redistribution of load onto a smaller surface area. This is a naturally\n> unstable process. It is safe to say that as node counts drop, the set of\n> node operators will increasingly represent economic actors with extreme\n> weight. The more this process unfolds, the more likely their interests will\n> diverge from the population at large, and also the more likely they can be\n> coerced into behavior they otherwise wouldn't. After all it is easier to\n> find agents who carry lots of economic weight. This is true independent of\n> their mining status, we should be just as wary of consensus capture by\n> exchanges or HNWI's as we are about miners.\n>\n> Keagan\n>\n> On Wed, May 6, 2020 at 3:06 AM Antoine Riard <antoine.riard at gmail.com>\n> wrote:\n>\n>> I do see the consensus capture argument by miners but in reality isn't\n>> this attack scenario have a lot of assumptions on topology an deployment ?\n>>\n>> For such attack to succeed you need miners nodes to be connected to\n>> clients to feed directly the invalid headers and if these ones are\n>> connected to headers/filters gateways, themselves doing full-nodes\n>> validation invalid chain is going to be sanitized out ?\n>>\n>> Sure now you trust these gateways, but if you have multiple connections\n>> to them and can guarantee they aren't run by the same entity, that maybe an\n>> acceptable security model, depending of staked amount and your\n>> expectations. I more concerned of having a lot of them and being\n>> diversified enough to avoid collusion between gateways/chain access\n>> providers/miners.\n>>\n>> But even if you light clients is directly connected to the backbone\n>> network and may be reached by miners you can implement fork anomalies\n>> detection and from then you may have multiples options:\n>> * halt the wallet, wait for human intervention\n>> * fallback connection to a trusted server, authoritative on your chain\n>> view\n>> * invalidity proofs?\n>>\n>> Now I agree you need a wide-enough, sane backbone network to build on\n>> top, and we should foster node adoption as much as we can.\n>>\n>> Le mar. 5 mai 2020 \u00e0 09:01, Luke Dashjr <luke at dashjr.org> a \u00e9crit :\n>>\n>>> On Tuesday 05 May 2020 10:17:37 Antoine Riard via bitcoin-dev wrote:\n>>> > Trust-minimization of Bitcoin security model has always relied first\n>>> and\n>>> > above on running a full-node. This current paradigm may be shifted by\n>>> LN\n>>> > where fast, affordable, confidential, censorship-resistant payment\n>>> services\n>>> > may attract a lot of adoption without users running a full-node.\n>>>\n>>> No, it cannot be shifted. This would compromise Bitcoin itself, which\n>>> for\n>>> security depends on the assumption that a supermajority of the economy\n>>> is\n>>> verifying their incoming transactions using their own full node.\n>>>\n>>> The past few years has seen severe regressions in this area, to the\n>>> point\n>>> where Bitcoin's future seems quite bleak. Without serious improvements\n>>> to the\n>>> full node ratio, Bitcoin is likely to fail.\n>>>\n>>> Therefore, all efforts to improve the \"full node-less\" experience are\n>>> harmful,\n>>> and should be actively avoided. BIP 157 improves privacy of fn-less\n>>> usage,\n>>> while providing no real benefits to full node users (compared to more\n>>> efficient protocols like Stratum/Electrum).\n>>>\n>>> For this reason, myself and a few others oppose merging support for BIP\n>>> 157 in\n>>> Core.\n>>>\n>>> > Assuming a user adoption path where a full-node is required to benefit\n>>> for\n>>> > LN may deprive a lot of users, especially those who are already denied\n>>> a\n>>> > real financial infrastructure access.\n>>>\n>>> If Bitcoin can't do it, then Bitcoin can't do it.\n>>> Bitcoin can't solve *any* problem if it becomes insecure itself.\n>>>\n>>> Luke\n>>>\n>>> P.S. See also\n>>>\n>>> https://medium.com/@nicolasdorier/why-i-dont-celebrate-neutrino-206bafa5fda0\n>>>\n>>> https://medium.com/@nicolasdorier/neutrino-is-dangerous-for-my-self-sovereignty-18fac5bcdc25\n>>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200506/def41023/attachment-0001.html>"
            },
            {
                "author": "Keagan McClelland",
                "date": "2020-05-07T04:07:09",
                "message_text_only": "I think that one of the solutions here is to have light clients choose\ntheir full node tethers explicitly. Even if you think it is unrealistic to\nhave everyone run their own node (fwiw, I don\u2019t), there is still a trust\nmodel where you can pick your trusted source.\n\nThis way you could have many light clients working off of a family node,\nand the peer services could be limited to some sort of \u201cauthenticated\u201d\npeers. Perhaps this is better accomplished over the RPC interface in Core,\nbut the idea is to have some sort of peer service model between \u201cfull\npublic\u201d and \u201cowner only\u201d. This limits the amount of costs that can be\nproperly externalized, without exposing risk of consensus capture by\neconomically weighty institutions.\n\nKeagan\n\nOn Wed, May 6, 2020 at 9:56 PM Antoine Riard <antoine.riard at gmail.com>\nwrote:\n\n> What I'm thinking more is if the costs of security are being too much\n> externalized from the light clients onto full nodes, nodes operators are\n> just going to stop servicing light clients `peercfilters=false`. The\n> backbone p2p network is going to be fine. But the massive LN light clients\n> network built on top is going to rely on centralized services for its chain\n> access and now you may have consensus capture by those..\n>\n> Le mer. 6 mai 2020 \u00e0 12:00, Keagan McClelland <keagan.mcclelland at gmail.com>\n> a \u00e9crit :\n>\n>> Hi Antoine,\n>>\n>> Consensus capture by miners isn't the only concern here. Consensus\n>> capture by any subset of users whose interests diverge from the overall\n>> consensus is equally damaging. The scenario I can imagine here is that the\n>> more light clients outpace full nodes, the more the costs of security are\n>> being externalized from the light clients onto the full nodes. In this\n>> situation, it can make full nodes harder to run. If they are harder to run\n>> it will price out some marginal set of full node operators, which causes a\n>> net new increase in light clients (as the disaffected full nodes convert),\n>> AND a redistribution of load onto a smaller surface area. This is a\n>> naturally unstable process. It is safe to say that as node counts drop, the\n>> set of node operators will increasingly represent economic actors with\n>> extreme weight. The more this process unfolds, the more likely their\n>> interests will diverge from the population at large, and also the more\n>> likely they can be coerced into behavior they otherwise wouldn't. After all\n>> it is easier to find agents who carry lots of economic weight. This is true\n>> independent of their mining status, we should be just as wary of consensus\n>> capture by exchanges or HNWI's as we are about miners.\n>>\n>> Keagan\n>>\n>> On Wed, May 6, 2020 at 3:06 AM Antoine Riard <antoine.riard at gmail.com>\n>> wrote:\n>>\n>>> I do see the consensus capture argument by miners but in reality isn't\n>>> this attack scenario have a lot of assumptions on topology an deployment ?\n>>>\n>>> For such attack to succeed you need miners nodes to be connected to\n>>> clients to feed directly the invalid headers and if these ones are\n>>> connected to headers/filters gateways, themselves doing full-nodes\n>>> validation invalid chain is going to be sanitized out ?\n>>>\n>>> Sure now you trust these gateways, but if you have multiple connections\n>>> to them and can guarantee they aren't run by the same entity, that maybe an\n>>> acceptable security model, depending of staked amount and your\n>>> expectations. I more concerned of having a lot of them and being\n>>> diversified enough to avoid collusion between gateways/chain access\n>>> providers/miners.\n>>>\n>>> But even if you light clients is directly connected to the backbone\n>>> network and may be reached by miners you can implement fork anomalies\n>>> detection and from then you may have multiples options:\n>>> * halt the wallet, wait for human intervention\n>>> * fallback connection to a trusted server, authoritative on your chain\n>>> view\n>>> * invalidity proofs?\n>>>\n>>> Now I agree you need a wide-enough, sane backbone network to build on\n>>> top, and we should foster node adoption as much as we can.\n>>>\n>>> Le mar. 5 mai 2020 \u00e0 09:01, Luke Dashjr <luke at dashjr.org> a \u00e9crit :\n>>>\n>>>> On Tuesday 05 May 2020 10:17:37 Antoine Riard via bitcoin-dev wrote:\n>>>> > Trust-minimization of Bitcoin security model has always relied first\n>>>> and\n>>>> > above on running a full-node. This current paradigm may be shifted by\n>>>> LN\n>>>> > where fast, affordable, confidential, censorship-resistant payment\n>>>> services\n>>>> > may attract a lot of adoption without users running a full-node.\n>>>>\n>>>> No, it cannot be shifted. This would compromise Bitcoin itself, which\n>>>> for\n>>>> security depends on the assumption that a supermajority of the economy\n>>>> is\n>>>> verifying their incoming transactions using their own full node.\n>>>>\n>>>> The past few years has seen severe regressions in this area, to the\n>>>> point\n>>>> where Bitcoin's future seems quite bleak. Without serious improvements\n>>>> to the\n>>>> full node ratio, Bitcoin is likely to fail.\n>>>>\n>>>> Therefore, all efforts to improve the \"full node-less\" experience are\n>>>> harmful,\n>>>> and should be actively avoided. BIP 157 improves privacy of fn-less\n>>>> usage,\n>>>> while providing no real benefits to full node users (compared to more\n>>>> efficient protocols like Stratum/Electrum).\n>>>>\n>>>> For this reason, myself and a few others oppose merging support for BIP\n>>>> 157 in\n>>>> Core.\n>>>>\n>>>> > Assuming a user adoption path where a full-node is required to\n>>>> benefit for\n>>>> > LN may deprive a lot of users, especially those who are already\n>>>> denied a\n>>>> > real financial infrastructure access.\n>>>>\n>>>> If Bitcoin can't do it, then Bitcoin can't do it.\n>>>> Bitcoin can't solve *any* problem if it becomes insecure itself.\n>>>>\n>>>> Luke\n>>>>\n>>>> P.S. See also\n>>>>\n>>>> https://medium.com/@nicolasdorier/why-i-dont-celebrate-neutrino-206bafa5fda0\n>>>>\n>>>> https://medium.com/@nicolasdorier/neutrino-is-dangerous-for-my-self-sovereignty-18fac5bcdc25\n>>>>\n>>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200506/26bac9b9/attachment.html>"
            },
            {
                "author": "Braydon Fuller",
                "date": "2020-05-08T19:51:15",
                "message_text_only": "On 5/6/20 9:07 PM, Keagan McClelland wrote:\n\n> I think that one of the solutions here is to have light clients choose\n> their full node tethers explicitly. Even if you think it is unrealistic to\n> have everyone run their own node (fwiw, I don\u2019t), there is still a trust\n> model where you can pick your trusted source.\n>\n> This way you could have many light clients working off of a family node,\n> and the peer services could be limited to some sort of \u201cauthenticated\u201d\n> peers. Perhaps this is better accomplished over the RPC interface in Core,\n> but the idea is to have some sort of peer service model between \u201cfull\n> public\u201d and \u201cowner only\u201d. This limits the amount of costs that can be\n> properly externalized, without exposing risk of consensus capture by\n> economically weighty institutions.\n\nThe RPC interface in Bitcoin Core, and others, is not great for this\nbecause it exposes a lot of functionality that isn't necessary and\nintroduces risks. For example the `gettxoutsetinfo` can start a very\nintensive CPU and disk I/O task. There are several others, for example:\n`stop`, `addnode`, `clearbanned`, `setban`, and etc. Furthermore reading\nfull raw blocks isn't very efficient with JSON. Electrum servers (e.g\nelectrs) for example read blocks from disk instead and use the RPC\ninterface to sync headers. Though, Electrum servers also have a risk of\nDoS with addresses that have many transactions, see the `--txid-limit`\noption [2].\n\n[1]:\nhttps://github.com/bitcoin/bitcoin/blob/5b24f6084ede92d0f493ff416b4726245140b2c1/src/rpc/blockchain.cpp#L954-L956\n[2]:\nhttps://github.com/romanz/electrs/blob/f0a7a325af495ecbc152c0866550dc300011779b/src/query.rs#L284-L289"
            },
            {
                "author": "Keagan McClelland",
                "date": "2020-05-08T20:01:40",
                "message_text_only": "> The RPC interface in Bitcoin Core, and others, is not great for this\n> because it exposes a lot of functionality that isn't necessary and\n> introduces risks.\n\nThis is actually somewhat my point. If the RPC interface was good for this\nand *didn't* introduce risks, we could just use that and be done with it.\nBut I'm finding there are many use cases that you want to have low cost\nways to serve peer services to people whom you have given explicit\npermission, but they shouldn't have full ability to administrate the node.\n\nPerhaps I wasn't explicit in my previous note but what I mean is that there\nseems to be a demand for something *in between* a peer interface, and an\nowner interface. I have little opinion as to whether this belongs in core\nor not, I think there are much more experienced folks who can weight in on\nthat, but without something like this, you cannot limit your exposure for\nserving something like bip157 filters without removing your own ability to\nmake use of some of those same services.\n\nKeagan\n\nOn Fri, May 8, 2020 at 1:51 PM Braydon Fuller <braydon at purse.io> wrote:\n\n> On 5/6/20 9:07 PM, Keagan McClelland wrote:\n>\n> > I think that one of the solutions here is to have light clients choose\n> > their full node tethers explicitly. Even if you think it is unrealistic\n> to\n> > have everyone run their own node (fwiw, I don\u2019t), there is still a trust\n> > model where you can pick your trusted source.\n> >\n> > This way you could have many light clients working off of a family node,\n> > and the peer services could be limited to some sort of \u201cauthenticated\u201d\n> > peers. Perhaps this is better accomplished over the RPC interface in\n> Core,\n> > but the idea is to have some sort of peer service model between \u201cfull\n> > public\u201d and \u201cowner only\u201d. This limits the amount of costs that can be\n> > properly externalized, without exposing risk of consensus capture by\n> > economically weighty institutions.\n>\n> The RPC interface in Bitcoin Core, and others, is not great for this\n> because it exposes a lot of functionality that isn't necessary and\n> introduces risks. For example the `gettxoutsetinfo` can start a very\n> intensive CPU and disk I/O task. There are several others, for example:\n> `stop`, `addnode`, `clearbanned`, `setban`, and etc. Furthermore reading\n> full raw blocks isn't very efficient with JSON. Electrum servers (e.g\n> electrs) for example read blocks from disk instead and use the RPC\n> interface to sync headers. Though, Electrum servers also have a risk of\n> DoS with addresses that have many transactions, see the `--txid-limit`\n> option [2].\n>\n> [1]:\n>\n> https://github.com/bitcoin/bitcoin/blob/5b24f6084ede92d0f493ff416b4726245140b2c1/src/rpc/blockchain.cpp#L954-L956\n> [2]:\n>\n> https://github.com/romanz/electrs/blob/f0a7a325af495ecbc152c0866550dc300011779b/src/query.rs#L284-L289\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200508/dd8331af/attachment-0001.html>"
            },
            {
                "author": "Braydon Fuller",
                "date": "2020-05-08T20:22:30",
                "message_text_only": "On 5/8/20 1:01 PM, Keagan McClelland wrote:\n\n>> The RPC interface in Bitcoin Core, and others, is not great for this\n>> because it exposes a lot of functionality that isn't necessary and\n>> introduces risks.\n> This is actually somewhat my point. If the RPC interface was good for this\n> and *didn't* introduce risks, we could just use that and be done with it.\n> But I'm finding there are many use cases that you want to have low cost\n> ways to serve peer services to people whom you have given explicit\n> permission, but they shouldn't have full ability to administrate the node.\n>\n> Perhaps I wasn't explicit in my previous note but what I mean is that there\n> seems to be a demand for something *in between* a peer interface, and an\n> owner interface. I have little opinion as to whether this belongs in core\n> or not, I think there are much more experienced folks who can weight in on\n> that, but without something like this, you cannot limit your exposure for\n> serving something like bip157 filters without removing your own ability to\n> make use of some of those same services.\n\nAn idea I was thinking about was having three ports for a full node:\n\n1) Consensus bitcoin protocol. This is the existing peer-to-peer\nprotocol without additional services.\n2) Wallet services protocol. Adds additional functionality for wallets.\nFor example bloom filtering, compact block filters, and potentially\noutput and address indexes for electrum-like support. It's nearly\nidentical to the consensus peer-to-peer protocol, supporting the same\nwire format. As it's on another port, various middleware could be added\nto support various authentication and transports.\n3) Control interface. This is the existing JSON-RPC interface, without\nall wallet related RPC methods."
            },
            {
                "author": "Christopher Allen",
                "date": "2020-05-08T21:29:48",
                "message_text_only": "On Fri, May 8, 2020 at 2:00 PM Keagan McClelland via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Perhaps I wasn't explicit in my previous note but what I mean is that\n> there seems to be a demand for something *in between* a peer interface,\n> and an owner interface. I have little opinion as to whether this belongs in\n> core or not, I think there are much more experienced folks who can weight\n> in on that, but without something like this, you cannot limit your exposure\n> for serving something like bip157 filters without removing your own ability\n> to make use of some of those same services.\n>\n\nOur FullyNoded2 multisig wallet on iOS & Mac, communicates with your own\npersonal node over RPC, securing the connection using Tor over a hidden\nonion service and two-way client authentication using a v3 Tor\nAuthentication key: https://github.com/BlockchainCommons/FullyNoded-2\n\nIt many ways the app (and its predecessor FullyNoded1) is an interface\nbetween a personal full node and a user.\n\nHowever, we do wish that the full RPC functionality was not exposed in\nbitcoin-core. I\u2019d love to see a cryptographic capability mechanism such\nthat the remote wallet could only m ask the node functions that it needs,\nand allow escalation for other rarer services it needs with addition\nauthorization.\n\nThis capability mechanism feature set should go both ways, to a minimum\nsubset needed for being a watch-only transaction verification tool, all the\nway to things RPC can\u2019t do like deleting a wallet and changing bitcoin.conf\nparameters and rebooting, without requiring full ssh access to the server\nrunning the node.\n\nIf there are people interested in coordinating some proposals on how to\ndefining different sets of wallet functionality, Blockchain Commons would\nbe interested in hosting that collaboration. This could start as just being\na transparent shim between bitcoin-core & remote RPC, but later could\ninform proposals for the future of the core wallet functionality as it gets\nrefactored.\n\n\u2014 Christopher Allen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200508/b2fc3d0f/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-09T07:48:33",
                "message_text_only": "Hi Christopher,\n\nThanks for Blockchain Commons and Learning Bitcoin from the Command Line!\n\n> If there are people interested in coordinating some proposals on how to\ndefining different sets of wallet functionality, Blockchain Commons would\nbe interested in hosting that collaboration. This could start as just being\na transparent shim between bitcoin-core & remote RPC, but later could\ninform proposals for the future of the core wallet functionality as it gets\nrefactored.\n\nYes generally refactoring in Core wallets are making good progress [0]. I'm\npretty sure feedbacks and proposals on future changes with regards to\nusability would be greatly appreciated.\n\nMaybe you can bring these during a IRC meeting ?\n\nAntoine\n\n[0] See https://github.com/bitcoin/bitcoin/pull/16528 or\nhttps://github.com/bitcoin/bitcoin/pull/16426\n\nLe ven. 8 mai 2020 \u00e0 17:31, Christopher Allen via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n> On Fri, May 8, 2020 at 2:00 PM Keagan McClelland via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Perhaps I wasn't explicit in my previous note but what I mean is that\n>> there seems to be a demand for something *in between* a peer interface,\n>> and an owner interface. I have little opinion as to whether this belongs in\n>> core or not, I think there are much more experienced folks who can weight\n>> in on that, but without something like this, you cannot limit your exposure\n>> for serving something like bip157 filters without removing your own ability\n>> to make use of some of those same services.\n>>\n>\n> Our FullyNoded2 multisig wallet on iOS & Mac, communicates with your own\n> personal node over RPC, securing the connection using Tor over a hidden\n> onion service and two-way client authentication using a v3 Tor\n> Authentication key: https://github.com/BlockchainCommons/FullyNoded-2\n>\n> It many ways the app (and its predecessor FullyNoded1) is an interface\n> between a personal full node and a user.\n>\n> However, we do wish that the full RPC functionality was not exposed in\n> bitcoin-core. I\u2019d love to see a cryptographic capability mechanism such\n> that the remote wallet could only m ask the node functions that it needs,\n> and allow escalation for other rarer services it needs with addition\n> authorization.\n>\n> This capability mechanism feature set should go both ways, to a minimum\n> subset needed for being a watch-only transaction verification tool, all the\n> way to things RPC can\u2019t do like deleting a wallet and changing bitcoin.conf\n> parameters and rebooting, without requiring full ssh access to the server\n> running the node.\n>\n> If there are people interested in coordinating some proposals on how to\n> defining different sets of wallet functionality, Blockchain Commons would\n> be interested in hosting that collaboration. This could start as just being\n> a transparent shim between bitcoin-core & remote RPC, but later could\n> inform proposals for the future of the core wallet functionality as it gets\n> refactored.\n>\n> \u2014 Christopher Allen\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200509/f1180329/attachment.html>"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2020-05-06T00:31:32",
                "message_text_only": "Hi Antoine,\n\n> Even with cheaper, more efficient protocols like BIP 157, you may have a\n> huge discrepancy between what is asked and what is offered. Assuming 10M\n> light clients [0] each of them consuming ~100MB/month for filters/headers,\n> that means you're asking 1PB/month of traffic to the backbone network. If\n> you assume 10K public nodes, like today, assuming _all_ of them opt-in to\n> signal BIP 157, that's an increase of 100GB/month for each. Which is\n> consequent with regards to the estimated cost of 350GB/month for running\n> an actual public node\n\nOne really dope thing about BIP 157+158, is that the protocol makes serving\nlight clients now _stateless_, since the full node doesn't need to perform\nany unique work for a given client. As a result, the entire protocol could\nbe served over something like HTTP, taking advantage of all the established\nCDNs and anycast serving infrastructure, which can reduce syncing time\n(less latency to\nfetch data) and also more widely distributed the load of light clients using\nthe existing web infrastructure. Going further, with HTTP/2's server-push\ncapabilities, those serving this data can still push out notifications for\nnew headers, etc.\n\n> Therefore, you may want to introduce monetary compensation in exchange of\n> servicing filters. Light client not dedicating resources to maintain the\n> network but free-riding on it, you may use their micro-payment\n> capabilities to price chain access resources [3]\n\nPiggy backing off the above idea, if the data starts being widely served\nover HTTP, then LSATs[1][2] can be used to add a lightweight payment\nmechanism by inserting a new proxy server in front of the filter/header\ninfrastructure. The minted tokens themselves may allow a user to purchase\naccess to a single header/filter, a range of them in the past, or N headers\npast the known chain tip, etc, etc.\n\n-- Laolu\n\n[1]: https://lsat.tech/\n[2]: https://lightning.engineering/posts/2020-03-30-lsat/\n\n\nOn Tue, May 5, 2020 at 3:17 AM Antoine Riard <antoine.riard at gmail.com>\nwrote:\n\n> Hi,\n>\n> (cross-posting as it's really both layers concerned)\n>\n> Ongoing advancement of BIP 157 implementation in Core maybe the\n> opportunity to reflect on the future of light client protocols and use this\n> knowledge to make better-informed decisions about what kind of\n> infrastructure is needed to support mobile clients at large scale.\n>\n> Trust-minimization of Bitcoin security model has always relied first and\n> above on running a full-node. This current paradigm may be shifted by LN\n> where fast, affordable, confidential, censorship-resistant payment services\n> may attract a lot of adoption without users running a full-node. Assuming a\n> user adoption path where a full-node is required to benefit for LN may\n> deprive a lot of users, especially those who are already denied a real\n> financial infrastructure access. It doesn't mean we shouldn't foster node\n> adoption when people are able to do so, and having a LN wallet maybe even a\n> first-step to it.\n>\n> Designing a mobile-first LN experience opens its own gap of challenges\n> especially in terms of security and privacy. The problem can be scoped as\n> how to build a scalable, secure, private chain access backend for millions\n> of LN clients ?\n>\n> Light client protocols for LN exist (either BIP157 or Electrum are used),\n> although their privacy and security guarantees with regards to\n> implementation on the client-side may still be an object of concern\n> (aggressive tx-rebroadcast, sybillable outbound peer selection, trusted fee\n> estimation). That said, one of the bottlenecks is likely the number of\n> full-nodes being willingly to dedicate resources to serve those clients.\n> It's not about _which_ protocol is deployed but more about _incentives_ for\n> node operators to dedicate long-term resources to client they have lower\n> reasons to care about otherwise.\n>\n> Even with cheaper, more efficient protocols like BIP 157, you may have a\n> huge discrepancy between what is asked and what is offered. Assuming 10M\n> light clients [0] each of them consuming ~100MB/month for filters/headers,\n> that means you're asking 1PB/month of traffic to the backbone network. If\n> you assume 10K public nodes, like today, assuming _all_ of them opt-in to\n> signal BIP 157, that's an increase of 100GB/month for each. Which is\n> consequent with regards to the estimated cost of 350GB/month for running an\n> actual public node. Widening full-node adoption, specially in term of\n> geographic distribution means as much as we can to bound its operational\n> cost.\n>\n> Obviously,  deployment of more efficient tx-relay protocol like Erlay will\n> free up some resources but it maybe wiser to dedicate them to increase\n> health and security of the backbone network like deploying more outbound\n> connections.\n>\n> Unless your light client protocol is so ridiculous cheap to rely on\n> niceness of a subset of node operators offering free resources, it won't\n> scale. And it's likely you will always have a ratio disequilibrium between\n> numbers of clients and numbers of full-node, even worst their growth rate\n> won't be the same, first ones are so much easier to setup.\n>\n> It doesn't mean servicing filters for free won't work for now, numbers of\n> BIP157 clients is still pretty low, but what is worrying is  wallet vendors\n> building such chain access backend, hitting a bandwidth scalability wall\n> few years from now instead of pursuing better solutions. And if this\n> happen, maybe suddenly, isn't the quick fix going to be to rely on\n> centralized services, so much easier to deploy ?\n>\n> Of course, it may be brought that actually current full-node operators\n> don't get anything back from servicing blocks, transactions, addresses...\n> It may be replied that you have an indirect incentive to participate in\n> network relay and therefore guarantee censorship-resistance, instead of\n> directly connecting to miners. You do have today ways to select your\n> resources exposure like pruning, block-only or being private but the wider\n> point is the current (non?)-incentives model seems to work for the base\n> layer. For light clients data, are node operators going to be satisfied to\n> serve this new *class* of traffic en masse ?\n>\n> This doesn't mean you won't find BIP157 servers, ready to serve you with\n> unlimited credit, but it's more likely their intentions maybe not aligned,\n> like spying on your transaction broadcast or block fetched. And you do want\n> peer diversity to avoid every BIP157 servers being on few ASNs for\n> fault-tolerance. Do people expect a scenario a la Cloudflare, where\n> everyone connections is to far or less the same set of entities ?\n>\n> Moreover, the LN security model diverges hugely from basic on-chain\n> transactions. Worst-case attack on-chain a malicious light client server\n> showing a longest, invalid, PoW-signed chain to double-spend the user. On\n> LN, the *liveliness* requirement means the entity owning your view of the\n> chain can lie to you on whether your channel has been spent by a revoked\n> commitment, the real tip of the blockchain or even dry-up block\n> announcement to trigger unexpected behavior in the client logic. A\n> malicious light client server may just drop any filters/utxos spends, what\n> your LN client should do in this case ? [1]\n>\n> Therefore, you may want to introduce monetary compensation in exchange of\n> servicing filters. Light client not dedicating resources to maintain the\n> network but free-riding on it, you may use their micro-payment capabilities\n> to price chain access resources [3]. This proposition may suit within the\n> watchtower paradigm, where another entity is delegated some part of\n> protocol execution, alleviating client onliness requirement. It needs\n> further analysis but how your funds may be compromised by a watchtower are\n> likely to be the same scenario that how a chain validation provider can\n> compromise you. That said, how do you avoid such \"chain access\" market\n> turning as an oligopoly is an open question. You may \"bind\" them to\n> internet topology or ask for fidelity bonds and create some kind of\n> scarcity but still...\n>\n> Maybe I'm completely wrong, missing some numbers, and it's maybe fine to\n> just rely on few thousands of full-node operators being nice and servicing\n> friendly millions of LN mobiles clients. But just in case it may be good to\n> consider a reasonable alternative.\n>\n> Thanks Gleb for many points exposed here but all mistakes are my own.\n>\n> Cheers,\n>\n> Antoine\n>\n> [0] UTXO set size may be a bottleneck, but still if you have 2 channels by\n> clients that's 20M utxos, just roughly ~x3 than today.\n>\n> [1] And committing filters as part of headers may not solve everything as\n> an attacker can just delay or slow announcements to you, so you still need\n> network access to at least one honest node.\n>\n> [2]  It maybe argue that distinction client-vs-peer doesn't hold because\n> you may start as a client and start synchronizing the chain, relaying\n> blocks, etc. AFAIK, there is no such hybrid implementation and that's not\n> what you want to run in a mobile.\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200505/f910aa3f/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-06T09:40:06",
                "message_text_only": "> As a result, the entire protocol could be served over something like\nHTTP, taking advantage of all the established CDNs and anycast serving\ninfrastructure,\n\nYes it's moving the issue of being a computation one to a distribution one.\nBut still you need the bandwidth capacities. What I'm concerned is the\ntrust model of relying on few-establish CDNs, you don't want to make it\neasy to have \"headers-routing\" hijack and therefore having massive channel\nclosure or time-locks interference due to LN clients not seeing the last\nfew block. So you may want to separate control/data plane, get filters from\nCDN and headers as check-and-control directly from the backbone network.\n\"Hybrid\" models should clearly be explored.\n\nWeb-of-trust style of deployments should be also envisioned, you may get\nhuge scaling improvement, assuming client may be peers between themselves\nand the ones belonging to the same social entity should be able to share\nthe same chain view without too much risk.\n\n> Piggy backing off the above idea, if the data starts being widely served\nover HTTP, then LSATs[1][2] can be used to add a lightweight payment\nmechanism by inserting a new proxy server in front of the filter/header\ninfrastructure.\n\nYeah, I hadn't time to read the spec yet but that was clearly something\nlike LSATs I meaned speaking about monetary compensation to price\nresources. I just hope it isn't too much tie to HTTP because you may want\nto read/write over other communication channels like\ntx-broadcast-over-radio to solve first-hop privacy.\n\nLe mar. 5 mai 2020 \u00e0 20:31, Olaoluwa Osuntokun <laolu32 at gmail.com> a \u00e9crit :\n\n> Hi Antoine,\n>\n> > Even with cheaper, more efficient protocols like BIP 157, you may have a\n> > huge discrepancy between what is asked and what is offered. Assuming 10M\n> > light clients [0] each of them consuming ~100MB/month for\n> filters/headers,\n> > that means you're asking 1PB/month of traffic to the backbone network. If\n> > you assume 10K public nodes, like today, assuming _all_ of them opt-in to\n> > signal BIP 157, that's an increase of 100GB/month for each. Which is\n> > consequent with regards to the estimated cost of 350GB/month for running\n> > an actual public node\n>\n> One really dope thing about BIP 157+158, is that the protocol makes serving\n> light clients now _stateless_, since the full node doesn't need to perform\n> any unique work for a given client. As a result, the entire protocol could\n> be served over something like HTTP, taking advantage of all the established\n> CDNs and anycast serving infrastructure, which can reduce syncing time\n> (less latency to\n> fetch data) and also more widely distributed the load of light clients\n> using\n> the existing web infrastructure. Going further, with HTTP/2's server-push\n> capabilities, those serving this data can still push out notifications for\n> new headers, etc.\n>\n> > Therefore, you may want to introduce monetary compensation in exchange of\n> > servicing filters. Light client not dedicating resources to maintain the\n> > network but free-riding on it, you may use their micro-payment\n> > capabilities to price chain access resources [3]\n>\n> Piggy backing off the above idea, if the data starts being widely served\n> over HTTP, then LSATs[1][2] can be used to add a lightweight payment\n> mechanism by inserting a new proxy server in front of the filter/header\n> infrastructure. The minted tokens themselves may allow a user to purchase\n> access to a single header/filter, a range of them in the past, or N headers\n> past the known chain tip, etc, etc.\n>\n> -- Laolu\n>\n> [1]: https://lsat.tech/\n> [2]: https://lightning.engineering/posts/2020-03-30-lsat/\n>\n>\n> On Tue, May 5, 2020 at 3:17 AM Antoine Riard <antoine.riard at gmail.com>\n> wrote:\n>\n>> Hi,\n>>\n>> (cross-posting as it's really both layers concerned)\n>>\n>> Ongoing advancement of BIP 157 implementation in Core maybe the\n>> opportunity to reflect on the future of light client protocols and use this\n>> knowledge to make better-informed decisions about what kind of\n>> infrastructure is needed to support mobile clients at large scale.\n>>\n>> Trust-minimization of Bitcoin security model has always relied first and\n>> above on running a full-node. This current paradigm may be shifted by LN\n>> where fast, affordable, confidential, censorship-resistant payment services\n>> may attract a lot of adoption without users running a full-node. Assuming a\n>> user adoption path where a full-node is required to benefit for LN may\n>> deprive a lot of users, especially those who are already denied a real\n>> financial infrastructure access. It doesn't mean we shouldn't foster node\n>> adoption when people are able to do so, and having a LN wallet maybe even a\n>> first-step to it.\n>>\n>> Designing a mobile-first LN experience opens its own gap of challenges\n>> especially in terms of security and privacy. The problem can be scoped as\n>> how to build a scalable, secure, private chain access backend for millions\n>> of LN clients ?\n>>\n>> Light client protocols for LN exist (either BIP157 or Electrum are used),\n>> although their privacy and security guarantees with regards to\n>> implementation on the client-side may still be an object of concern\n>> (aggressive tx-rebroadcast, sybillable outbound peer selection, trusted fee\n>> estimation). That said, one of the bottlenecks is likely the number of\n>> full-nodes being willingly to dedicate resources to serve those clients.\n>> It's not about _which_ protocol is deployed but more about _incentives_ for\n>> node operators to dedicate long-term resources to client they have lower\n>> reasons to care about otherwise.\n>>\n>> Even with cheaper, more efficient protocols like BIP 157, you may have a\n>> huge discrepancy between what is asked and what is offered. Assuming 10M\n>> light clients [0] each of them consuming ~100MB/month for filters/headers,\n>> that means you're asking 1PB/month of traffic to the backbone network. If\n>> you assume 10K public nodes, like today, assuming _all_ of them opt-in to\n>> signal BIP 157, that's an increase of 100GB/month for each. Which is\n>> consequent with regards to the estimated cost of 350GB/month for running an\n>> actual public node. Widening full-node adoption, specially in term of\n>> geographic distribution means as much as we can to bound its operational\n>> cost.\n>>\n>> Obviously,  deployment of more efficient tx-relay protocol like Erlay\n>> will free up some resources but it maybe wiser to dedicate them to increase\n>> health and security of the backbone network like deploying more outbound\n>> connections.\n>>\n>> Unless your light client protocol is so ridiculous cheap to rely on\n>> niceness of a subset of node operators offering free resources, it won't\n>> scale. And it's likely you will always have a ratio disequilibrium between\n>> numbers of clients and numbers of full-node, even worst their growth rate\n>> won't be the same, first ones are so much easier to setup.\n>>\n>> It doesn't mean servicing filters for free won't work for now, numbers of\n>> BIP157 clients is still pretty low, but what is worrying is  wallet vendors\n>> building such chain access backend, hitting a bandwidth scalability wall\n>> few years from now instead of pursuing better solutions. And if this\n>> happen, maybe suddenly, isn't the quick fix going to be to rely on\n>> centralized services, so much easier to deploy ?\n>>\n>> Of course, it may be brought that actually current full-node operators\n>> don't get anything back from servicing blocks, transactions, addresses...\n>> It may be replied that you have an indirect incentive to participate in\n>> network relay and therefore guarantee censorship-resistance, instead of\n>> directly connecting to miners. You do have today ways to select your\n>> resources exposure like pruning, block-only or being private but the wider\n>> point is the current (non?)-incentives model seems to work for the base\n>> layer. For light clients data, are node operators going to be satisfied to\n>> serve this new *class* of traffic en masse ?\n>>\n>> This doesn't mean you won't find BIP157 servers, ready to serve you with\n>> unlimited credit, but it's more likely their intentions maybe not aligned,\n>> like spying on your transaction broadcast or block fetched. And you do want\n>> peer diversity to avoid every BIP157 servers being on few ASNs for\n>> fault-tolerance. Do people expect a scenario a la Cloudflare, where\n>> everyone connections is to far or less the same set of entities ?\n>>\n>> Moreover, the LN security model diverges hugely from basic on-chain\n>> transactions. Worst-case attack on-chain a malicious light client server\n>> showing a longest, invalid, PoW-signed chain to double-spend the user. On\n>> LN, the *liveliness* requirement means the entity owning your view of the\n>> chain can lie to you on whether your channel has been spent by a revoked\n>> commitment, the real tip of the blockchain or even dry-up block\n>> announcement to trigger unexpected behavior in the client logic. A\n>> malicious light client server may just drop any filters/utxos spends, what\n>> your LN client should do in this case ? [1]\n>>\n>> Therefore, you may want to introduce monetary compensation in exchange of\n>> servicing filters. Light client not dedicating resources to maintain the\n>> network but free-riding on it, you may use their micro-payment capabilities\n>> to price chain access resources [3]. This proposition may suit within the\n>> watchtower paradigm, where another entity is delegated some part of\n>> protocol execution, alleviating client onliness requirement. It needs\n>> further analysis but how your funds may be compromised by a watchtower are\n>> likely to be the same scenario that how a chain validation provider can\n>> compromise you. That said, how do you avoid such \"chain access\" market\n>> turning as an oligopoly is an open question. You may \"bind\" them to\n>> internet topology or ask for fidelity bonds and create some kind of\n>> scarcity but still...\n>>\n>> Maybe I'm completely wrong, missing some numbers, and it's maybe fine to\n>> just rely on few thousands of full-node operators being nice and servicing\n>> friendly millions of LN mobiles clients. But just in case it may be good to\n>> consider a reasonable alternative.\n>>\n>> Thanks Gleb for many points exposed here but all mistakes are my own.\n>>\n>> Cheers,\n>>\n>> Antoine\n>>\n>> [0] UTXO set size may be a bottleneck, but still if you have 2 channels\n>> by clients that's 20M utxos, just roughly ~x3 than today.\n>>\n>> [1] And committing filters as part of headers may not solve everything as\n>> an attacker can just delay or slow announcements to you, so you still need\n>> network access to at least one honest node.\n>>\n>> [2]  It maybe argue that distinction client-vs-peer doesn't hold because\n>> you may start as a client and start synchronizing the chain, relaying\n>> blocks, etc. AFAIK, there is no such hybrid implementation and that's not\n>> what you want to run in a mobile.\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200506/b268d398/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-11T05:44:08",
                "message_text_only": "Good morning Richard, and all,\n\n\n> 2) a\u00a0light client can query an ISP connected full node on the same unmetered local WiFi network and exchange differences in block headers opportunistically or pay for large missing ranges of headers, filters or full blocks using a payment channel. Cost is reduced and privacy\u00a0is enhanced for the light client by not using a centralized ISP. Bandwidth for running the full node can be amortized\u00a0and subsidized by payments from light clients who they resell data to.\n\nA relatively pointless observation, but it seems to me that:\n\n* The light client is requesting for validation information, because...\n* ...its direct peers might be defrauding it, leading to...\n* ...the money it *thinks* it has in its channels being valueless.\n\nThus, if the light client opportunistically pays for validation information (whether full blocks, headers, or filters), the direct peers it has could just as easily not forward any payments, thus preventing the light client from paying for the validation information.\n\nIndeed, if the direct peer *is* defrauding the light client, the direct peer has no real incentive to actually forward *any* payments --- to do so would be to reduce the possible earnings it gets from defrauding the light client.\n(\"Simulating\" the payments so that the light client will not suspect anything runs the risk that the light client will be able to forward all its money out of the channel, and the cheating peer is still potentially liable for any funds it originally had in the channel if it gets caught.)\n\nWhat would work would be to use a system similar to watchtowers, wherein the validation-information-provider is prepaid and issues tokens that can be redeemed later.\nBut this is not suitable for opportunistic on-same-WiFi where, say, a laptop is running a validation-information-provider-for-payment program on the same WiFi as a light-client mobile phone, if we consider that the laptop and mobile may have never met before and may never meet again.\nIt would work if the laptop altruistically serves the blocks, but not if it were for (on-Lightning) payment.\n\n\nSo it seems to me that this kind of service is best ridden on top of watchtower service providers.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Richard Myers",
                "date": "2020-05-12T10:09:34",
                "message_text_only": "Thanks for sharing your thoughts ZmnSCPxj. I think I can summarize your\nconcern as: A node without direct internet connectivity can not rely on an\nopportunistically incentivized local network peer for blockchain\ninformation because the off-grid node's direct LN peers could collude to\nnot forward the payment.\n\nOn Mon, May 11, 2020 at 7:44 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> > 2) a light client can query an ISP connected full node on the same\n> unmetered local WiFi network and exchange differences in block headers\n> opportunistically or pay for large missing ranges of headers, filters or\n> full blocks using a payment channel. Cost is reduced and privacy is\n> enhanced for the light client by not using a centralized ISP. Bandwidth for\n> running the full node can be amortized and subsidized by payments from\n> light clients who they resell data to.\n>\n> A relatively pointless observation, but it seems to me that:\n>\n> * The light client is requesting for validation information, because...\n> * ...its direct peers might be defrauding it, leading to...\n> * ...the money it *thinks* it has in its channels being valueless.\n>\n> Thus, if the light client opportunistically pays for validation\n> information (whether full blocks, headers, or filters), the direct peers it\n> has could just as easily not forward any payments, thus preventing the\n> light client from paying for the validation information.\n>\n> Indeed, if the direct peer *is* defrauding the light client, the direct\n> peer has no real incentive to actually forward *any* payments --- to do so\n> would be to reduce the possible earnings it gets from defrauding the light\n> client.\n> (\"Simulating\" the payments so that the light client will not suspect\n> anything runs the risk that the light client will be able to forward all\n> its money out of the channel, and the cheating peer is still potentially\n> liable for any funds it originally had in the channel if it gets caught.)\n>\n\nOne question I had is: how can a malicious direct payment peer \"simulate\" a\nsuccessful payment made by an off-grid victim peer to an information\nsource?  The censoring peer wouldn't be able to return the preimage for a\npayment they failed to forward. Also, since the information provider and\noff-grid node can presumably communicate via their local network\nconnection, it would be obvious if all of the victims LN peers were failing\nto forward payments (whether maliciously or due to routing failures) to an\ninformation provider they could otherwise communicate with.\n\nAny LN payments not monitored by a watchtower that are received by the\neclipsed off-grid victim node would be at risk in this attack scenario.\nLikewise any layer 1 payments they received should be buried under\nsufficient valid block headers before being relied on.\n\nI don't see how a LN node one-step removed from a direct internet\nconnection is at more risk than an internet connected node eclipsed by\ntheir ISP, for example. In both cases, failure to get timely blockchain\ninfo should trigger warnings to stop accepting payments.\n\n\n> What would work would be to use a system similar to watchtowers, wherein\n> the validation-information-provider is prepaid and issues tokens that can\n> be redeemed later.\n> But this is not suitable for opportunistic on-same-WiFi where, say, a\n> laptop is running a validation-information-provider-for-payment program on\n> the same WiFi as a light-client mobile phone, if we consider that the\n> laptop and mobile may have never met before and may never meet again.\n> It would work if the laptop altruistically serves the blocks, but not if\n> it were for (on-Lightning) payment.\n>\n\nThere's another problem if we can't rely on a recurring relationship with\nan information provider besides not being able to prepay for validation\ninformation doesn't make sense. We don't want an information provider to\ncollect payments for serving invalid information. Maybe for very small\npayments this isn't a problem, but ideally validity could be coded into the\nHTLC.\n\nFor example, an alternative HTLC construct that only paid for valid 81 B\nheaders that hash to 32 B values with a number of leading zeros committed\nto by the HTLC. It would make more economic sense for an internet gateway\nnode to serve valid mined header to nodes on their local WiFi network than\nto create bogus ones with the same (high) amount of work.\n\n\n> So it seems to me that this kind of service is best ridden on top of\n> watchtower service providers.\n>\n\nPublic watchtowers or some sort of HTTP proxy data cache similar to a\nwatchtower makes the most sense to me because they would be expected to be\neconomically motivated and LN payment aware. Full nodes could potentially\nbe incentivized to exchange new data with other nodes in a tit-for-tat way,\nbut I don't expect them to be incentivized by light clients using LN\nmicropayments in a server-client arrangement.\n\nNetwork agents that monetize full node information services beyond channel\nmonitoring would be more than just a \"Watchtower\" for light clients. Would\nthey be more like incentivized Electrum servers? Are there still privacy\nconcerns when they serve generic/un-personalized headers/filters/blocks to\nlight clients? A personal, altruistic or friends and family watchtower is\nalso possible, but I'm thinking about how light clients without this\npossibility can be served.\n\nHappy new epoch,\n\n  -- Richard\n\n-- \nRichard Myers\nDecentralized Applications Engineer, goTenna\ngotenna.com\n@gotenna\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200512/ea1a456e/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-12T15:48:30",
                "message_text_only": "Good morning Richard,\n\n> Thanks for sharing your thoughts ZmnSCPxj. I think I can summarize your concern as: A node without direct internet connectivity can not rely on an opportunistically incentivized local network peer for blockchain information because the off-grid node's direct LN peers could collude to not forward the payment.\n\nCorrect.\n\n> > > 2) a\u00a0light client can query an ISP connected full node on the same unmetered local WiFi network and exchange differences in block headers opportunistically or pay for large missing ranges of headers, filters or full blocks using a payment channel. Cost is reduced and privacy\u00a0is enhanced for the light client by not using a centralized ISP. Bandwidth for running the full node can be amortized\u00a0and subsidized by payments from light clients who they resell data to.\n> >\n> > A relatively pointless observation, but it seems to me that:\n> >\n> > * The light client is requesting for validation information, because...\n> > * ...its direct peers might be defrauding it, leading to...\n> > * ...the money it *thinks* it has in its channels being valueless.\n> >\n> > Thus, if the light client opportunistically pays for validation information (whether full blocks, headers, or filters), the direct peers it has could just as easily not forward any payments, thus preventing the light client from paying for the validation information.\n> >\n> > Indeed, if the direct peer *is* defrauding the light client, the direct peer has no real incentive to actually forward *any* payments --- to do so would be to reduce the possible earnings it gets from defrauding the light client.\n> > (\"Simulating\" the payments so that the light client will not suspect anything runs the risk that the light client will be able to forward all its money out of the channel, and the cheating peer is still potentially liable for any funds it originally had in the channel if it gets caught.)\n>\n> One question I had is: how can a malicious direct payment peer \"simulate\" a successful payment made by an off-grid victim peer to an information source?\u00a0 The\u00a0censoring peer wouldn't be able to return the preimage for a payment they failed to forward. Also, since the information provider and off-grid node can presumably communicate via their local network connection, it would be obvious if all of the victims LN peers were failing to forward payments (whether maliciously or due to routing failures) to an information provider they could otherwise communicate with.\n\nPerhaps \"simulate\" is not quite the correct term.\nBasically, if the eclipsing peer(s) are reasonably sure they have eclipsed the light client, then all funds in those channels are semantically theirs (they \"0wn\" the eclipsed light client).\nThen anything the light node offers from those channels (which it thinks are its, but are now in reality owned by the eclipsing peer) has no value (the eclipsing node already 0wns the light node and all its funds, what can the light node offer to it?).\nThe eclipsing peer could still \"simulate\" what the light node expects of reality by pretending that the light node actually still owns funds in the channel (even though the eclipsing node has successfully stolen all those funds), and forward as normal to get the payment preimage/scalar.\n\n\n> > What would work would be to use a system similar to watchtowers, wherein the validation-information-provider is prepaid and issues tokens that can be redeemed later.\n> > But this is not suitable for opportunistic on-same-WiFi where, say, a laptop is running a validation-information-provider-for-payment program on the same WiFi as a light-client mobile phone, if we consider that the laptop and mobile may have never met before and may never meet again.\n> > It would work if the laptop altruistically serves the blocks, but not if it were for (on-Lightning) payment.\n>\n> There's another problem if we can't rely on a recurring relationship with an information provider besides not being able to prepay for validation information doesn't make sense. We don't want an information provider\u00a0to collect payments for serving invalid information. Maybe for very small payments this isn't a problem, but ideally validity could be coded into the HTLC.\n>\n> For example, an alternative HTLC construct that only paid for valid 81 B headers that hash to 32 B values with a number of leading zeros committed to by the HTLC. It would make more economic sense for an internet gateway node to serve valid mined header to nodes on their\u00a0local WiFi network than to create bogus ones with the same (high) amount of work.\n\nIf you are considering this for on-Lightning payments, do note that the alternative HTLC construct has to be known by every forwarding node, including the direct peer(s) of the light client, which are precisely the potential attackers on the light client.\n\nIt seems to be impractical for onchain payments: the provider can drop the data onchain to claim the funds, but it is precisely the blockchain data that the light client does not have direct access to, so ---\n\n\n> \u00a0\n>\n> > So it seems to me that this kind of service is best ridden on top of watchtower service providers.\n>\n> Public watchtowers or some sort of HTTP proxy data cache similar to\u00a0a watchtower makes the most sense to me because they would be expected to be economically motivated and LN payment aware. Full nodes could potentially be incentivized to exchange new data with other nodes in a tit-for-tat way, but I don't expect them to be incentivized by light clients using LN micropayments in a server-client arrangement.\n>\n> Network agents that monetize full node information services beyond channel monitoring would be more than just a \"Watchtower\" for light clients. Would they be more like incentivized Electrum servers?\n\nPossibly.\n\n> Are there still privacy concerns when they\u00a0serve generic/un-personalized headers/filters/blocks to light clients?\n\nIt marks the client as a light client, at least.\n\nSomeone who gets read-only access to the logs of such a public-service node now has a list of light clients.\nIf the light clients are in any way identifiable and locatable, the hacker can then attempt to hack the light client and redirect their understanding of what the public-service node is (e.g. DNS poisoning) and then start performing other attacks on the client once its view of the blockchain is eclipsed.\n\nThis would be helped if the light client, for example, always uses Tor to access the public-service node, if payments for services of that node are decorrelated (e.g. tokens issued by the node that will later be reclaimed for service are blinded), etc.\nSuch would make the light client harder to locate in the first place.\n\n(While a mobile client can certainly access the Internet over various access points, most people who own mobile devices have a home they go to at night, which often has Internet access, possibly with a stable identifiable location that can be attacked)\n\n>\u00a0A personal, altruistic or friends and family watchtower is also possible, but I'm thinking about how light clients without this possibility can be served.\n\nThis is probably something we can expect to see as well; though it should be noted, for those philosophically interested in such things, that these are the genesis of governments and states.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Braydon Fuller",
                "date": "2020-05-08T19:33:55",
                "message_text_only": "On 5/5/20 5:31 PM, Olaoluwa Osuntokun via bitcoin-dev wrote:\n\n> Hi Antoine,\n>\n>> Even with cheaper, more efficient protocols like BIP 157, you may have a\n>> huge discrepancy between what is asked and what is offered. Assuming 10M\n>> light clients [0] each of them consuming ~100MB/month for filters/headers,\n>> that means you're asking 1PB/month of traffic to the backbone network. If\n>> you assume 10K public nodes, like today, assuming _all_ of them opt-in to\n>> signal BIP 157, that's an increase of 100GB/month for each. Which is\n>> consequent with regards to the estimated cost of 350GB/month for running\n>> an actual public node\n> One really dope thing about BIP 157+158, is that the protocol makes serving\n> light clients now _stateless_, since the full node doesn't need to perform\n> any unique work for a given client. As a result, the entire protocol could\n> be served over something like HTTP, taking advantage of all the established\n> CDNs and anycast serving infrastructure, which can reduce syncing time\n> (less latency to\n> fetch data) and also more widely distributed the load of light clients using\n> the existing web infrastructure. Going further, with HTTP/2's server-push\n> capabilities, those serving this data can still push out notifications for\n> new headers, etc.\n\nThe statelessness of compact block filters does look useful. Bloom\nfilters for\nblocks can be inefficient, during a scan with a BIP37 wallet, it's\nnecessary to\ndiscard already received merkle blocks as the filter has been updated\nand the\nprevious results may have missed transactions. Both bitcoinj [1] and\nbreadwallet-core [2] handle it using a similar method. The alternative of\nsynchronizing and alternating between requesting blocks and filter\nupdates leads\nto slow scan times. With compact block filters, a separate wallet\nprocess (from\nthe full node) can make adjustments necessary to what it needs to filter\nwithout\nhaving to communicate with the full node.\n\n[1]:\nhttps://github.com/bitcoinj/bitcoinj/blob/806afa04419ebdc3c15d5adf065979aa7303e7f6/core/src/main/java/org/bitcoinj/core/Peer.java#L1076-L1079\n[2]:\nhttps://github.com/breadwallet/breadwallet-core/blob/8eb05454df3e2d5cca248b4e24eeffa420c97e3a/bitcoin/BRPeer.c#L83-L85"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-06T08:27:45",
                "message_text_only": "I didn't trust myself and verify. In fact the [3] is the real [2].\n\nLe mar. 5 mai 2020 \u00e0 06:28, Andr\u00e9s G. Aragoneses <knocte at gmail.com> a\n\u00e9crit :\n\n> Hey Antoine, just a small note, [3] is missing in your footnotes, can you\n> add it? Thanks\n>\n> On Tue, 5 May 2020 at 18:17, Antoine Riard <antoine.riard at gmail.com>\n> wrote:\n>\n>> Hi,\n>>\n>> (cross-posting as it's really both layers concerned)\n>>\n>> Ongoing advancement of BIP 157 implementation in Core maybe the\n>> opportunity to reflect on the future of light client protocols and use this\n>> knowledge to make better-informed decisions about what kind of\n>> infrastructure is needed to support mobile clients at large scale.\n>>\n>> Trust-minimization of Bitcoin security model has always relied first and\n>> above on running a full-node. This current paradigm may be shifted by LN\n>> where fast, affordable, confidential, censorship-resistant payment services\n>> may attract a lot of adoption without users running a full-node. Assuming a\n>> user adoption path where a full-node is required to benefit for LN may\n>> deprive a lot of users, especially those who are already denied a real\n>> financial infrastructure access. It doesn't mean we shouldn't foster node\n>> adoption when people are able to do so, and having a LN wallet maybe even a\n>> first-step to it.\n>>\n>> Designing a mobile-first LN experience opens its own gap of challenges\n>> especially in terms of security and privacy. The problem can be scoped as\n>> how to build a scalable, secure, private chain access backend for millions\n>> of LN clients ?\n>>\n>> Light client protocols for LN exist (either BIP157 or Electrum are used),\n>> although their privacy and security guarantees with regards to\n>> implementation on the client-side may still be an object of concern\n>> (aggressive tx-rebroadcast, sybillable outbound peer selection, trusted fee\n>> estimation). That said, one of the bottlenecks is likely the number of\n>> full-nodes being willingly to dedicate resources to serve those clients.\n>> It's not about _which_ protocol is deployed but more about _incentives_ for\n>> node operators to dedicate long-term resources to client they have lower\n>> reasons to care about otherwise.\n>>\n>> Even with cheaper, more efficient protocols like BIP 157, you may have a\n>> huge discrepancy between what is asked and what is offered. Assuming 10M\n>> light clients [0] each of them consuming ~100MB/month for filters/headers,\n>> that means you're asking 1PB/month of traffic to the backbone network. If\n>> you assume 10K public nodes, like today, assuming _all_ of them opt-in to\n>> signal BIP 157, that's an increase of 100GB/month for each. Which is\n>> consequent with regards to the estimated cost of 350GB/month for running an\n>> actual public node. Widening full-node adoption, specially in term of\n>> geographic distribution means as much as we can to bound its operational\n>> cost.\n>>\n>> Obviously,  deployment of more efficient tx-relay protocol like Erlay\n>> will free up some resources but it maybe wiser to dedicate them to increase\n>> health and security of the backbone network like deploying more outbound\n>> connections.\n>>\n>> Unless your light client protocol is so ridiculous cheap to rely on\n>> niceness of a subset of node operators offering free resources, it won't\n>> scale. And it's likely you will always have a ratio disequilibrium between\n>> numbers of clients and numbers of full-node, even worst their growth rate\n>> won't be the same, first ones are so much easier to setup.\n>>\n>> It doesn't mean servicing filters for free won't work for now, numbers of\n>> BIP157 clients is still pretty low, but what is worrying is  wallet vendors\n>> building such chain access backend, hitting a bandwidth scalability wall\n>> few years from now instead of pursuing better solutions. And if this\n>> happen, maybe suddenly, isn't the quick fix going to be to rely on\n>> centralized services, so much easier to deploy ?\n>>\n>> Of course, it may be brought that actually current full-node operators\n>> don't get anything back from servicing blocks, transactions, addresses...\n>> It may be replied that you have an indirect incentive to participate in\n>> network relay and therefore guarantee censorship-resistance, instead of\n>> directly connecting to miners. You do have today ways to select your\n>> resources exposure like pruning, block-only or being private but the wider\n>> point is the current (non?)-incentives model seems to work for the base\n>> layer. For light clients data, are node operators going to be satisfied to\n>> serve this new *class* of traffic en masse ?\n>>\n>> This doesn't mean you won't find BIP157 servers, ready to serve you with\n>> unlimited credit, but it's more likely their intentions maybe not aligned,\n>> like spying on your transaction broadcast or block fetched. And you do want\n>> peer diversity to avoid every BIP157 servers being on few ASNs for\n>> fault-tolerance. Do people expect a scenario a la Cloudflare, where\n>> everyone connections is to far or less the same set of entities ?\n>>\n>> Moreover, the LN security model diverges hugely from basic on-chain\n>> transactions. Worst-case attack on-chain a malicious light client server\n>> showing a longest, invalid, PoW-signed chain to double-spend the user. On\n>> LN, the *liveliness* requirement means the entity owning your view of the\n>> chain can lie to you on whether your channel has been spent by a revoked\n>> commitment, the real tip of the blockchain or even dry-up block\n>> announcement to trigger unexpected behavior in the client logic. A\n>> malicious light client server may just drop any filters/utxos spends, what\n>> your LN client should do in this case ? [1]\n>>\n>> Therefore, you may want to introduce monetary compensation in exchange of\n>> servicing filters. Light client not dedicating resources to maintain the\n>> network but free-riding on it, you may use their micro-payment capabilities\n>> to price chain access resources [3]. This proposition may suit within the\n>> watchtower paradigm, where another entity is delegated some part of\n>> protocol execution, alleviating client onliness requirement. It needs\n>> further analysis but how your funds may be compromised by a watchtower are\n>> likely to be the same scenario that how a chain validation provider can\n>> compromise you. That said, how do you avoid such \"chain access\" market\n>> turning as an oligopoly is an open question. You may \"bind\" them to\n>> internet topology or ask for fidelity bonds and create some kind of\n>> scarcity but still...\n>>\n>> Maybe I'm completely wrong, missing some numbers, and it's maybe fine to\n>> just rely on few thousands of full-node operators being nice and servicing\n>> friendly millions of LN mobiles clients. But just in case it may be good to\n>> consider a reasonable alternative.\n>>\n>> Thanks Gleb for many points exposed here but all mistakes are my own.\n>>\n>> Cheers,\n>>\n>> Antoine\n>>\n>> [0] UTXO set size may be a bottleneck, but still if you have 2 channels\n>> by clients that's 20M utxos, just roughly ~x3 than today.\n>>\n>> [1] And committing filters as part of headers may not solve everything as\n>> an attacker can just delay or slow announcements to you, so you still need\n>> network access to at least one honest node.\n>>\n>> [2]  It maybe argue that distinction client-vs-peer doesn't hold because\n>> you may start as a client and start synchronizing the chain, relaying\n>> blocks, etc. AFAIK, there is no such hybrid implementation and that's not\n>> what you want to run in a mobile.\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200506/7bc013c5/attachment-0001.html>"
            },
            {
                "author": "Igor Cota",
                "date": "2020-05-07T16:40:49",
                "message_text_only": "Hi Antoine et al,\n\nMaybe I'm completely wrong, missing some numbers, and it's maybe fine to\n> just rely on few thousands of full-node operators being nice and servicing\n> friendly millions of LN mobiles clients. But just in case it may be good to\n> consider a reasonable alternative.\n>\n\n\n> So you may want to separate control/data plane, get filters from CDN and\n> headers as check-and-control directly from the backbone network. \"Hybrid\"\n> models should clearly be explored.\n\n\nFor some months now I've been exploring the feasibility of running full\nnodes on everyday phones [1]. One of my first thoughts was how to avoid the\nphones mooching off the network. Obviously due to battery, storage and\nbandwidth constraints it is not reasonable to expect pocket full nodes to\nserve blocks during day time.\n\nHuge exception to this is the time we are asleep and our phones are\nconnected to wifi and charging. IMO this is a huge untapped resource that\nwould allow mobile nodes to earn their keep. If we limit full node\noperation to sleepy night time the only constraining resource is storage:\n512 gb of internal storage in phones is quite rare, probably about $100 for\nan SD card with full archival node capacity but phones with memory card\nslots rarer still - no one is going to bother.\n\nSo depending on their storage capacity phone nodes could decide to store\nand serve just a randomly selected range of blocks during their nighttime\noperation. With trivial changes to P2P they could advertise the blocks they\nare able to serve.\nIf there comes a time that normal full nodes feel DoS'ed they can challenge\nsuch nodes to produce the blocks they advertise and ban them as moochers if\nthey fail to do so. Others may elect to be more charitable and serve\neveryone.\n\nThese types of nodes would truly be part-timing since they only carry a\nsubset of the blockchain and work while their operator is asleep. Probably\nshould be called part-time or Sleeper Nodes\u2122.\n\nThey could be user friendly as well, with Assume UTXO they could be\nbootstrapped quickly and while they do the IBD in the background instead of\ntraditional pruning they can keep the randomly assigned bit of blockchain\nto later serve the network.\n\nSave for the elderly, all the people I know could run such a node, and I\ndon't live in a first world country.\n\nThere is also the feel-good kumbaya aspect of American phone nodes serving\nthe African continent while the Americans are asleep, Africans and\nEuropeans serving the Asians in kind. By plugging in our phones and going\nto sleep we could blanket the whole world in (somewhat) full nodes!\n\nCheers,\nIgor\n\n[1] https://icota.github.io/\n\nOn Tue, 5 May 2020 at 12:18, Antoine Riard <antoine.riard at gmail.com> wrote:\n\n> Hi,\n>\n> (cross-posting as it's really both layers concerned)\n>\n> Ongoing advancement of BIP 157 implementation in Core maybe the\n> opportunity to reflect on the future of light client protocols and use this\n> knowledge to make better-informed decisions about what kind of\n> infrastructure is needed to support mobile clients at large scale.\n>\n> Trust-minimization of Bitcoin security model has always relied first and\n> above on running a full-node. This current paradigm may be shifted by LN\n> where fast, affordable, confidential, censorship-resistant payment services\n> may attract a lot of adoption without users running a full-node. Assuming a\n> user adoption path where a full-node is required to benefit for LN may\n> deprive a lot of users, especially those who are already denied a real\n> financial infrastructure access. It doesn't mean we shouldn't foster node\n> adoption when people are able to do so, and having a LN wallet maybe even a\n> first-step to it.\n>\n> Designing a mobile-first LN experience opens its own gap of challenges\n> especially in terms of security and privacy. The problem can be scoped as\n> how to build a scalable, secure, private chain access backend for millions\n> of LN clients ?\n>\n> Light client protocols for LN exist (either BIP157 or Electrum are used),\n> although their privacy and security guarantees with regards to\n> implementation on the client-side may still be an object of concern\n> (aggressive tx-rebroadcast, sybillable outbound peer selection, trusted fee\n> estimation). That said, one of the bottlenecks is likely the number of\n> full-nodes being willingly to dedicate resources to serve those clients.\n> It's not about _which_ protocol is deployed but more about _incentives_ for\n> node operators to dedicate long-term resources to client they have lower\n> reasons to care about otherwise.\n>\n> Even with cheaper, more efficient protocols like BIP 157, you may have a\n> huge discrepancy between what is asked and what is offered. Assuming 10M\n> light clients [0] each of them consuming ~100MB/month for filters/headers,\n> that means you're asking 1PB/month of traffic to the backbone network. If\n> you assume 10K public nodes, like today, assuming _all_ of them opt-in to\n> signal BIP 157, that's an increase of 100GB/month for each. Which is\n> consequent with regards to the estimated cost of 350GB/month for running an\n> actual public node. Widening full-node adoption, specially in term of\n> geographic distribution means as much as we can to bound its operational\n> cost.\n>\n> Obviously,  deployment of more efficient tx-relay protocol like Erlay will\n> free up some resources but it maybe wiser to dedicate them to increase\n> health and security of the backbone network like deploying more outbound\n> connections.\n>\n> Unless your light client protocol is so ridiculous cheap to rely on\n> niceness of a subset of node operators offering free resources, it won't\n> scale. And it's likely you will always have a ratio disequilibrium between\n> numbers of clients and numbers of full-node, even worst their growth rate\n> won't be the same, first ones are so much easier to setup.\n>\n> It doesn't mean servicing filters for free won't work for now, numbers of\n> BIP157 clients is still pretty low, but what is worrying is  wallet vendors\n> building such chain access backend, hitting a bandwidth scalability wall\n> few years from now instead of pursuing better solutions. And if this\n> happen, maybe suddenly, isn't the quick fix going to be to rely on\n> centralized services, so much easier to deploy ?\n>\n> Of course, it may be brought that actually current full-node operators\n> don't get anything back from servicing blocks, transactions, addresses...\n> It may be replied that you have an indirect incentive to participate in\n> network relay and therefore guarantee censorship-resistance, instead of\n> directly connecting to miners. You do have today ways to select your\n> resources exposure like pruning, block-only or being private but the wider\n> point is the current (non?)-incentives model seems to work for the base\n> layer. For light clients data, are node operators going to be satisfied to\n> serve this new *class* of traffic en masse ?\n>\n> This doesn't mean you won't find BIP157 servers, ready to serve you with\n> unlimited credit, but it's more likely their intentions maybe not aligned,\n> like spying on your transaction broadcast or block fetched. And you do want\n> peer diversity to avoid every BIP157 servers being on few ASNs for\n> fault-tolerance. Do people expect a scenario a la Cloudflare, where\n> everyone connections is to far or less the same set of entities ?\n>\n> Moreover, the LN security model diverges hugely from basic on-chain\n> transactions. Worst-case attack on-chain a malicious light client server\n> showing a longest, invalid, PoW-signed chain to double-spend the user. On\n> LN, the *liveliness* requirement means the entity owning your view of the\n> chain can lie to you on whether your channel has been spent by a revoked\n> commitment, the real tip of the blockchain or even dry-up block\n> announcement to trigger unexpected behavior in the client logic. A\n> malicious light client server may just drop any filters/utxos spends, what\n> your LN client should do in this case ? [1]\n>\n> Therefore, you may want to introduce monetary compensation in exchange of\n> servicing filters. Light client not dedicating resources to maintain the\n> network but free-riding on it, you may use their micro-payment capabilities\n> to price chain access resources [3]. This proposition may suit within the\n> watchtower paradigm, where another entity is delegated some part of\n> protocol execution, alleviating client onliness requirement. It needs\n> further analysis but how your funds may be compromised by a watchtower are\n> likely to be the same scenario that how a chain validation provider can\n> compromise you. That said, how do you avoid such \"chain access\" market\n> turning as an oligopoly is an open question. You may \"bind\" them to\n> internet topology or ask for fidelity bonds and create some kind of\n> scarcity but still...\n>\n> Maybe I'm completely wrong, missing some numbers, and it's maybe fine to\n> just rely on few thousands of full-node operators being nice and servicing\n> friendly millions of LN mobiles clients. But just in case it may be good to\n> consider a reasonable alternative.\n>\n> Thanks Gleb for many points exposed here but all mistakes are my own.\n>\n> Cheers,\n>\n> Antoine\n>\n> [0] UTXO set size may be a bottleneck, but still if you have 2 channels by\n> clients that's 20M utxos, just roughly ~x3 than today.\n>\n> [1] And committing filters as part of headers may not solve everything as\n> an attacker can just delay or slow announcements to you, so you still need\n> network access to at least one honest node.\n>\n> [2]  It maybe argue that distinction client-vs-peer doesn't hold because\n> you may start as a client and start synchronizing the chain, relaying\n> blocks, etc. AFAIK, there is no such hybrid implementation and that's not\n> what you want to run in a mobile.\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n\n\n-- \n*Igor Cota*\nCodex Apertus Ltd\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200507/8b85d6e1/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-09T07:22:52",
                "message_text_only": "Hi Igor,\n\nThanks for sharing about what it's technically possible to do for a\nfull-node on phone, specially with regards to lower grade devices.\n\nI do see 2 limitations for sleeping nodes:\n- a lightning specific one, i.e you need to process block data real-time in\ncase of incoming HTLC you need to claim on chain or a HTLC timeout. There\nis a bunch of timelocks implications in LN,  with regards to CSV,\nCLTV_DELTA, incoming policy, outgoing policy, ... and you can't really\nafford to be late without loosing a payment. I don't see timelocks being\nincrease, that would hinder liquidity.\n- a p2p bandwidth concern, even if this new class of nodes turn as public\nones, they would still have a heavy sync period due to be fallen-behind\nduring the day, so you would have huge bandwidth spikes every a timezone\nfalls asleep and a risk of choking upload links of stable full-nodes.\n\nI think assume-utxo may be interesting in the future in case of long-fork\ndetection, you may be able to download a utxo-set on the fly, and fall-back\nto a full-node. But that would be only an emergency measure, not a regular\ncost on the backbone network.\n\nAntoine\n\n\nLe jeu. 7 mai 2020 \u00e0 12:41, Igor Cota <igor at codexapertus.com> a \u00e9crit :\n\n> Hi Antoine et al,\n>\n> Maybe I'm completely wrong, missing some numbers, and it's maybe fine to\n>> just rely on few thousands of full-node operators being nice and servicing\n>> friendly millions of LN mobiles clients. But just in case it may be good to\n>> consider a reasonable alternative.\n>>\n>\n>\n>> So you may want to separate control/data plane, get filters from CDN and\n>> headers as check-and-control directly from the backbone network. \"Hybrid\"\n>> models should clearly be explored.\n>\n>\n> For some months now I've been exploring the feasibility of running full\n> nodes on everyday phones [1]. One of my first thoughts was how to avoid the\n> phones mooching off the network. Obviously due to battery, storage and\n> bandwidth constraints it is not reasonable to expect pocket full nodes to\n> serve blocks during day time.\n>\n> Huge exception to this is the time we are asleep and our phones are\n> connected to wifi and charging. IMO this is a huge untapped resource that\n> would allow mobile nodes to earn their keep. If we limit full node\n> operation to sleepy night time the only constraining resource is storage:\n> 512 gb of internal storage in phones is quite rare, probably about $100 for\n> an SD card with full archival node capacity but phones with memory card\n> slots rarer still - no one is going to bother.\n>\n> So depending on their storage capacity phone nodes could decide to store\n> and serve just a randomly selected range of blocks during their nighttime\n> operation. With trivial changes to P2P they could advertise the blocks they\n> are able to serve.\n> If there comes a time that normal full nodes feel DoS'ed they can\n> challenge such nodes to produce the blocks they advertise and ban them as\n> moochers if they fail to do so. Others may elect to be more charitable and\n> serve everyone.\n>\n> These types of nodes would truly be part-timing since they only carry a\n> subset of the blockchain and work while their operator is asleep. Probably\n> should be called part-time or Sleeper Nodes\u2122.\n>\n> They could be user friendly as well, with Assume UTXO they could be\n> bootstrapped quickly and while they do the IBD in the background instead of\n> traditional pruning they can keep the randomly assigned bit of blockchain\n> to later serve the network.\n>\n> Save for the elderly, all the people I know could run such a node, and I\n> don't live in a first world country.\n>\n> There is also the feel-good kumbaya aspect of American phone nodes serving\n> the African continent while the Americans are asleep, Africans and\n> Europeans serving the Asians in kind. By plugging in our phones and going\n> to sleep we could blanket the whole world in (somewhat) full nodes!\n>\n> Cheers,\n> Igor\n>\n> [1] https://icota.github.io/\n>\n> On Tue, 5 May 2020 at 12:18, Antoine Riard <antoine.riard at gmail.com>\n> wrote:\n>\n>> Hi,\n>>\n>> (cross-posting as it's really both layers concerned)\n>>\n>> Ongoing advancement of BIP 157 implementation in Core maybe the\n>> opportunity to reflect on the future of light client protocols and use this\n>> knowledge to make better-informed decisions about what kind of\n>> infrastructure is needed to support mobile clients at large scale.\n>>\n>> Trust-minimization of Bitcoin security model has always relied first and\n>> above on running a full-node. This current paradigm may be shifted by LN\n>> where fast, affordable, confidential, censorship-resistant payment services\n>> may attract a lot of adoption without users running a full-node. Assuming a\n>> user adoption path where a full-node is required to benefit for LN may\n>> deprive a lot of users, especially those who are already denied a real\n>> financial infrastructure access. It doesn't mean we shouldn't foster node\n>> adoption when people are able to do so, and having a LN wallet maybe even a\n>> first-step to it.\n>>\n>> Designing a mobile-first LN experience opens its own gap of challenges\n>> especially in terms of security and privacy. The problem can be scoped as\n>> how to build a scalable, secure, private chain access backend for millions\n>> of LN clients ?\n>>\n>> Light client protocols for LN exist (either BIP157 or Electrum are used),\n>> although their privacy and security guarantees with regards to\n>> implementation on the client-side may still be an object of concern\n>> (aggressive tx-rebroadcast, sybillable outbound peer selection, trusted fee\n>> estimation). That said, one of the bottlenecks is likely the number of\n>> full-nodes being willingly to dedicate resources to serve those clients.\n>> It's not about _which_ protocol is deployed but more about _incentives_ for\n>> node operators to dedicate long-term resources to client they have lower\n>> reasons to care about otherwise.\n>>\n>> Even with cheaper, more efficient protocols like BIP 157, you may have a\n>> huge discrepancy between what is asked and what is offered. Assuming 10M\n>> light clients [0] each of them consuming ~100MB/month for filters/headers,\n>> that means you're asking 1PB/month of traffic to the backbone network. If\n>> you assume 10K public nodes, like today, assuming _all_ of them opt-in to\n>> signal BIP 157, that's an increase of 100GB/month for each. Which is\n>> consequent with regards to the estimated cost of 350GB/month for running an\n>> actual public node. Widening full-node adoption, specially in term of\n>> geographic distribution means as much as we can to bound its operational\n>> cost.\n>>\n>> Obviously,  deployment of more efficient tx-relay protocol like Erlay\n>> will free up some resources but it maybe wiser to dedicate them to increase\n>> health and security of the backbone network like deploying more outbound\n>> connections.\n>>\n>> Unless your light client protocol is so ridiculous cheap to rely on\n>> niceness of a subset of node operators offering free resources, it won't\n>> scale. And it's likely you will always have a ratio disequilibrium between\n>> numbers of clients and numbers of full-node, even worst their growth rate\n>> won't be the same, first ones are so much easier to setup.\n>>\n>> It doesn't mean servicing filters for free won't work for now, numbers of\n>> BIP157 clients is still pretty low, but what is worrying is  wallet vendors\n>> building such chain access backend, hitting a bandwidth scalability wall\n>> few years from now instead of pursuing better solutions. And if this\n>> happen, maybe suddenly, isn't the quick fix going to be to rely on\n>> centralized services, so much easier to deploy ?\n>>\n>> Of course, it may be brought that actually current full-node operators\n>> don't get anything back from servicing blocks, transactions, addresses...\n>> It may be replied that you have an indirect incentive to participate in\n>> network relay and therefore guarantee censorship-resistance, instead of\n>> directly connecting to miners. You do have today ways to select your\n>> resources exposure like pruning, block-only or being private but the wider\n>> point is the current (non?)-incentives model seems to work for the base\n>> layer. For light clients data, are node operators going to be satisfied to\n>> serve this new *class* of traffic en masse ?\n>>\n>> This doesn't mean you won't find BIP157 servers, ready to serve you with\n>> unlimited credit, but it's more likely their intentions maybe not aligned,\n>> like spying on your transaction broadcast or block fetched. And you do want\n>> peer diversity to avoid every BIP157 servers being on few ASNs for\n>> fault-tolerance. Do people expect a scenario a la Cloudflare, where\n>> everyone connections is to far or less the same set of entities ?\n>>\n>> Moreover, the LN security model diverges hugely from basic on-chain\n>> transactions. Worst-case attack on-chain a malicious light client server\n>> showing a longest, invalid, PoW-signed chain to double-spend the user. On\n>> LN, the *liveliness* requirement means the entity owning your view of the\n>> chain can lie to you on whether your channel has been spent by a revoked\n>> commitment, the real tip of the blockchain or even dry-up block\n>> announcement to trigger unexpected behavior in the client logic. A\n>> malicious light client server may just drop any filters/utxos spends, what\n>> your LN client should do in this case ? [1]\n>>\n>> Therefore, you may want to introduce monetary compensation in exchange of\n>> servicing filters. Light client not dedicating resources to maintain the\n>> network but free-riding on it, you may use their micro-payment capabilities\n>> to price chain access resources [3]. This proposition may suit within the\n>> watchtower paradigm, where another entity is delegated some part of\n>> protocol execution, alleviating client onliness requirement. It needs\n>> further analysis but how your funds may be compromised by a watchtower are\n>> likely to be the same scenario that how a chain validation provider can\n>> compromise you. That said, how do you avoid such \"chain access\" market\n>> turning as an oligopoly is an open question. You may \"bind\" them to\n>> internet topology or ask for fidelity bonds and create some kind of\n>> scarcity but still...\n>>\n>> Maybe I'm completely wrong, missing some numbers, and it's maybe fine to\n>> just rely on few thousands of full-node operators being nice and servicing\n>> friendly millions of LN mobiles clients. But just in case it may be good to\n>> consider a reasonable alternative.\n>>\n>> Thanks Gleb for many points exposed here but all mistakes are my own.\n>>\n>> Cheers,\n>>\n>> Antoine\n>>\n>> [0] UTXO set size may be a bottleneck, but still if you have 2 channels\n>> by clients that's 20M utxos, just roughly ~x3 than today.\n>>\n>> [1] And committing filters as part of headers may not solve everything as\n>> an attacker can just delay or slow announcements to you, so you still need\n>> network access to at least one honest node.\n>>\n>> [2]  It maybe argue that distinction client-vs-peer doesn't hold because\n>> you may start as a client and start synchronizing the chain, relaying\n>> blocks, etc. AFAIK, there is no such hybrid implementation and that's not\n>> what you want to run in a mobile.\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n>\n> --\n> *Igor Cota*\n> Codex Apertus Ltd\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200509/00324e4f/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "On the scalability issues of onboarding millions of LN mobile clients",
            "categories": [
                "bitcoin-dev",
                "Lightning-dev"
            ],
            "authors": [
                "John Newbery",
                "Antoine Riard",
                "Christopher Allen",
                "William Casarin",
                "Keagan McClelland",
                "ZmnSCPxj",
                "Olaoluwa Osuntokun",
                "Richard Myers",
                "Braydon Fuller",
                "Igor Cota"
            ],
            "messages_count": 26,
            "total_messages_chars_count": 133453
        }
    },
    {
        "title": "[bitcoin-dev] Statechain implementations",
        "thread_messages": [
            {
                "author": "Tom Trevethan",
                "date": "2020-05-07T14:54:53",
                "message_text_only": "Hi,\n\nAn quick update on progress with our statechain implementation which we are\npressing ahead with - we have started work on a version in Rust (\nhttps://github.com/commerceblock/mercury) that is based on the 2P ECDSA\ngotham-city wallet from KZen (https://github.com/KZen-networks/gotham-city),\nand using their implementation of Lindel's 2P ECDSA protocol, which is very\nfast (we can always swap to a different protocol later). Also, we are\nplanning on using a sparse Merkle tree attested to a Mainstay slot (\nmainstay.xyz) for the proof-of-publication/proof-of-ownership - using the\nprotocol described here:\nhttps://github.com/commerceblock/mercury/blob/master/doc/statechains.md and\nhttps://github.com/thyeem/monotree. Any comments on these choices or on\nanything else are highly appreciated.\n\nTom\n\nOn Sun, Apr 5, 2020 at 10:25 PM Tom Trevethan <tom at commerceblock.com> wrote:\n\n> Hi Bob and Nadav,\n>\n> There seems to be no way to prevent a malicious SE from stealing an\n> output from the current owner by either colluding with (or being) a\n> previous owner. But with a proof-of-publication (i.e. the statechain) it is\n> possible for the current owner to have a proof that the SE has stolen from\n> them. It seems to me that the statechain itself provides two functions: 1.\n> Proof that an output has only a single owner at any time (preventing the SE\n> from double-spending) and 2. a way for the current owner to prove their\n> ownership, and require their permission to change ownership. 1. can just be\n> a publication by the SE, but 2. requires that the output is transferred to\n> a public key of the owner, and only via a signature of the previous owner\n> (in this way the SE cannot re-assign ownership unilaterally). Therefore I\n> think Nadav is right, and this needs to be a key that the SE can never know\n> (even if they are malicious), but which can be used to prove ownership, and\n> in turn prove fraud on the part of the SE.\n>\n> I don't think that this should be too much of an issue: any wallet will\n> have to use new keys for each output and transfer anyway. The statechain\n> key (used for the ownership proof) and the output key share can be on\n> different hardened HD paths (following on from a path derived from the\n> outpoint of the UTXO, similar to the method in BIP175).\n>\n> Tom\n>\n>\n>\n> On Sun, Apr 5, 2020 at 3:17 PM Bob McElrath <bob at mcelrath.org> wrote:\n>\n>> Note that this attack requires collaboration with the current UTXO owner.\n>> Generally if there's some form of address/payment request, the current\n>> holder is\n>> trying to transfer the UXTO to some other (non-statechain) entity, and he\n>> knows\n>> the target of the transfer, and participates in the protocol to authorize\n>> it.\n>> The current holder must obtain the target pubkey for the transfer\n>> out-of-band\n>> with respect to the SE, or the SE can MITM that.\n>>\n>> It's a stated security assumption that the sender or receiver do not\n>> collude\n>> with the SE. If either do, then your attack is generally possible and all\n>> bets\n>> are off. So what you've described is simply the SE colluding with the\n>> receiver.\n>> The receiver will *already* receive the UTXO, so the receiver here is\n>> assisting\n>> the SE in stealing his (the receiver's) funds, or the SE has done a MITM\n>> on the\n>> transfer.  Various improvements including blind signing, a SE-federation,\n>> etc\n>> are valuable to consider to mitigate this. But the SE must be prevented,\n>> one way\n>> or another, from \"buying the UTXO\". The SE cannot be allowed to be both\n>> operator\n>> of the SE and a customer of it, as this clearly violates the no-receiver\n>> collusion principle.\n>>\n>> \"Adding a new user key\" doesn't change the situation. There's already a\n>> user key\n>> involved, and the user has already acquiesced to the transfer.\n>> Acquiescing with\n>> two keys doesn't change anything.\n>>\n>> As far as proving and tracing the fraud, this is where \"single use seals\"\n>> come\n>> in. Each SE transfer can involve an \"opening\" of a seal, followed by a\n>> \"close\"\n>> when it is transferred, creating a linear history of ownership. If the SE\n>> obtains the full private key x, one way or another, the spend of that\n>> UTXO will\n>> fall outside this seal-based history, and proof of fraud will be evident.\n>> It\n>> won't be possible to determine *which* of the old owners collaborated\n>> with the\n>> SE, but it gives clear proof that the SE is not to be trusted. A customer\n>> might\n>> demand that a seal-based system be in use as an independent entity from\n>> the SE,\n>> to audit the honesty of the SE. The seal system does not require any of\n>> the keys\n>> required for transfer. See https://mainstay.xyz as a potential\n>> implementation.\n>> There are lots of reasons this might required as an AML solution for some\n>> businesses anyway.\n>>\n>> Nadav Kohen via bitcoin-dev [bitcoin-dev at lists.linuxfoundation.org]\n>> wrote:\n>> > Hey all,\n>> >\n>> > So my main concern with the proposal as written is that the Statechain\n>> Entity\n>> > (SE) can untraceably scam its users with the following attack:\n>> >\n>> > 1) Buy the utxo (have it transferred to a key it knows), this first\n>> step can be\n>> > skipped if the utxo was created by the SE.\n>> > 2) Transfer the UTXO to someone else, let it be for however long\n>> > 3) When it wishes to steal the UTXO, the SE now knows its own shard s_n\n>> and it\n>> > knows the full private key, x, from when it owned the UTXO (and had both\n>> > shards), and so it can compute x/s_n = the current users shard. It can\n>> then\n>> > sign for the current user, and forge a state transition to a key it\n>> owns before\n>> > spending the UTXO on chain.\n>> >\n>> > The main problem here is that the user who had their funds stolen\n>> cannot prove\n>> > to anyone that this has happened since the attack compromises their key.\n>> > That said, I think this problem is easily fixed by adding a new user\n>> key to the\n>> > protocol with which they must sign in order for the transfer to be\n>> considered\n>> > valid on the state chain. This way, if the SE wishes to steal the funds\n>> (which\n>> > they still can), at least it is traceable/provable that this SE is not\n>> > trustworthy as there is no evidence of a valid transfer for the funds\n>> that have\n>> > been stolen.\n>> >\n>> > Best,\n>> > Nadav\n>> >\n>> > On Thu, Apr 2, 2020 at 7:22 PM Tom Trevethan via bitcoin-dev <\n>> > bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> >\n>> >     Thanks for all of the input and comments - I do now think that the\n>> >     decrementing nSequence relative locktime backup system with kick-off\n>> >     transaction is the way to go, including a fee penalty via CPFP to\n>> >     disincentivise DoS, as suggested.\n>> >     I have started a more detailed document specifying the proposed\n>> protocol in\n>> >     more detail: https://github.com/commerceblock/mercury/blob/master/\n>> >     statechains.md which includes improvements to the\n>> transfer mechanism (and\n>> >     an explanation of how this can be used to transfer/novate positions\n>> in\n>> >     DLCs). Always happy to get more feedback or PRs.\n>> >\n>> >     Tom\n>> >\n>> >     On Tue, Mar 31, 2020 at 12:41 PM Tom Trevethan <\n>> tom at commerceblock.com>\n>> >     wrote:\n>> >\n>> >         Hi David,\n>> >\n>> >         Just for clarity, I left nChain over 2 years ago (having worked\n>> there\n>> >         since 2016). While there, I (along with other researchers) were\n>> given\n>> >         free rein to work on any ideas we wanted to. I had been\n>> interested in\n>> >         the scaling of Bitcoin off-chain, and this was one of several\n>> things I\n>> >         spent time on (including things like sidechains, pegs and\n>> threshold\n>> >         signatures). This patent application came out of an idea I had\n>> to\n>> >         transfer ownership of UTXOs off-chain that has some\n>> similarities to the\n>> >         statechains proposal, which has shown there is interest and\n>> demand for\n>> >         this type of system.\n>> >\n>> >         Although I think the existence of this application is something\n>> to be\n>> >         mindful of, there are several important things to note:\n>> >\n>> >         1. Although there are similarities, the current ideas are\n>> significantly\n>> >         different to those in the application.\n>> >         2. The key transfer protocol as described in the application is\n>> not\n>> >         secure (for several reasons, including as discussed above, by\n>> Albert\n>> >         and Bob etc.) - and a different mechanism is required.\n>> >         3. Decrementing timelocks (as suggested in the application) are\n>> prior\n>> >         art (Decker-Wattenhofer 2015), and in any case any\n>> implementation will\n>> >         most likely use an 'invalidation tree' relative locktime backup\n>> >         mechanism for open-ended UTXOs.\n>> >         4. The patent application has not been granted (it was made in\n>> May\n>> >         2017) and the international search report rejected it on the\n>> grounds of\n>> >         prior art.\n>> >\n>> >         Tom\n>> >\n>> >         On Tue, Mar 31, 2020 at 11:36 AM David A. Harding <\n>> dave at dtrt.org>\n>> >         wrote:\n>> >\n>> >             On Wed, Mar 25, 2020 at 01:52:10PM +0000, Tom Trevethan via\n>> >             bitcoin-dev wrote:\n>> >             > Hi all,\n>> >             >\n>> >             > We are starting to work on an implementation of the\n>> statechains\n>> >             concept (\n>> >             > https://medium.com/@RubenSomsen/\n>> >\n>>  statechains-non-custodial-off-chain-bitcoin-transfer-1ae4845a4a39),\n>> >             >\n>> >             > [...]\n>> >             > There are two main modifications we are looking at:\n>> >             > [...]\n>> >             >\n>> >             > 2. Replacing the 2-of-2 multisig output (paying to\n>> statechain\n>> >             entity SE key\n>> >             > and transitory key) with a single P2(W)PKH output where\n>> the\n>> >             public key\n>> >             > shared between the SE and the current owner. The SE and\n>> the\n>> >             current owner\n>> >             > can then sign with a 2-of-2 ECDSA MPC.\n>> >\n>> >             Dr. Trevethan,\n>> >\n>> >             Would you be able to explain how your proposal to use\n>> statechains\n>> >             with\n>> >             2P-ECDSA relates to your patent assigned to nChain Holdings\n>> for\n>> >             \"Secure\n>> >             off-chain blockchain transactions\"?[1]\n>> >\n>> >                 [1] https://patents.google.com/patent/US20200074464A1\n>> >\n>> >             Here are some excerpts from the application that caught my\n>> >             attention in\n>> >             the context of statechains in general and your proposal to\n>> this\n>> >             list in\n>> >             particular:\n>> >\n>> >             > an exchange platform that is trusted to implement and\n>> operate the\n>> >             > transaction protocol, without requiring an on-chain\n>> transaction.\n>> >             The\n>> >             > off-chain transactions enable one computer system to\n>> generate\n>> >             multiple\n>> >             > transactions that are recordable to a blockchain in\n>> different\n>> >             > circumstances\n>> >             >\n>> >             > [...]\n>> >             >\n>> >             > at least some of the off-chain transactions are valid for\n>> >             recording on\n>> >             > the blockchain even in the event of a catastrophic\n>> failure of the\n>> >             > exchange (e.g., exchange going permanently off-line or\n>> loosing\n>> >             key\n>> >             > shares).\n>> >             >\n>> >             > [...]\n>> >             >\n>> >             > there may be provided a computer readable storage medium\n>> >             including a\n>> >             > two-party elliptic curve digital signature algorithm\n>> (two-party\n>> >             ECDSA)\n>> >             > script comprising computer executable instructions which,\n>> when\n>> >             > executed, configure a processor to perform functions of a\n>> >             two-party\n>> >             > elliptic curve digital signature algorithm described\n>> herein.\n>> >             >\n>> >             > [...]\n>> >             >\n>> >             > In this instance the malicious actor would then also have\n>> to\n>> >             collude\n>> >             > with a previous owner of the funds to recreate the full\n>> key.\n>> >             Because\n>> >             > an attack requires either the simultaneous theft of both\n>> exchange\n>> >             and\n>> >             > depositor keys or collusion with previous legitimate\n>> owners of\n>> >             funds,\n>> >             > the opportunities for a malicious attacker to compromise\n>> the\n>> >             exchange\n>> >             > platform are limited.\n>> >\n>> >             Thank you,\n>> >\n>> >             -Dave\n>> >\n>> >     _______________________________________________\n>> >     bitcoin-dev mailing list\n>> >     bitcoin-dev at lists.linuxfoundation.org\n>> >     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> >\n>> > !DSPAM:5e87670a231323960034969!\n>>\n>> > _______________________________________________\n>> > bitcoin-dev mailing list\n>> > bitcoin-dev at lists.linuxfoundation.org\n>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> >\n>> >\n>> > !DSPAM:5e87670a231323960034969!\n>>\n>> --\n>> Cheers, Bob McElrath\n>>\n>> \"For every complex problem, there is a solution that is simple, neat, and\n>> wrong.\"\n>>     -- H. L. Mencken\n>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200507/4f555986/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Statechain implementations",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Tom Trevethan"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 13650
        }
    },
    {
        "title": "[bitcoin-dev] Revault: a multi-party vault architecture",
        "thread_messages": [
            {
                "author": "darosior",
                "date": "2020-05-08T10:34:49",
                "message_text_only": "The fee bumping construction I described in the previous post is potentially vulnerable\nto transaction pinning.\n\n\nWe shared a SINGLE | ANYONECANPAY signature for the first (and only) input of revaulting\ntransactions to allow any party to append an input and an output in order to bump the\ntransaction fees.\nAn user would either append an input signed with ALL, or replace their SINGLE | ANYONECANPAY\nsignature with one using ALL before broadcasting the transaction.\n\nThis allowed one party to decrease the transaction fees down to the minimum relay fees,\nand possibly pin the transaction by spending their added single-pubkey output.\n\n\nWe now exchange ALL | ANYONECANPAY signatures for revaulting transactions to restrict the creation\nof a new output only spendable by one party.\nThe fee bumping is now done in two stages (to avoid consuming an entire utxo) :\n\n\n       Unvaulting transaction\n  --------------------------------\n | vault prevout | unvault output |------------------\n  --------------------------------                    \\\n                                                       \\             Revaulting transaction\n                                                        \\  ---------------------------------------\n                                                          | unvault prevout    | new vault output |\n                                                           ---------------------------------------\n                                                          | fee bump prevout   |\n                                                         / --------------------\n       Single-party wallet transaction                  /\n  -----------------------------------------            /\n | wallet prevout | fee bump output        |----------\n  -----------------------------------------\n                  | wallet change output   |\n                   ------------------------\n\n\n\nThis construction isn't perfect as a malicious party could still pin its fee bumping transaction\nand prevent the other stakeholders from **immediatly** replacing this input, because of the second\nrule of BIP125 :\n> The replacement transaction may only include an unconfirmed input if that input was included\n> in one of the original transactions.\n\n\nHowever, I think it's preferable as :\n- Depending on the unvault CSV, the honest party might pay a high fee to have the fee-bumping\n  transaction confirm in one of the next two blocks, and then use this now confirmed output as an\n  additional input of the revaulting transaction.\n- If the amount is consequent, the honest party may sacrifice an entire confirmed utxo from its\n  wallet (effectively skipping the fee bumping transaction).\n- It's realistic to expect, for such an application, users' wallets to have a pool of confirmed\n  utxo that might be sacrificed if the amount is consequent AND the CSV is so small (which is\n  anyway a bad idea in the first place) that you are not sure to have the fee bumping transaction\n  to be confirmed before its maturity, ).\n\n\nThanks,\nAntoine / Darosior\n\n\n\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nLe vendredi, avril 24, 2020 5:00 PM, darosior <darosior at protonmail.com> a \u00e9crit :\n\n> Hi all,\n>\n> Kevin Loaec and I have been working on a new multiparty vault architecture and I think it reached the point where we\u2019d welcome some feedback.\n>\n> Intended usage and limitations\n>\n> ===============================\n>\n> The aim is to secure the shared storage of coins without relying on a trusted third party and by disincentivizing theft attempts, while not restricting the usage of the funds for day-to-day operations.\n>\n> Revault uses N-of-N multisigs and thus does not protect against intentional locking of funds (such as refusal to sign, or key erasure). Therefore it assumes its users (likely companies with already on-going agreements between shareholders) to be able to solve intentional blockage outside the Bitcoin network (such as through legal contracts).\n>\n> The actual architecture\n>\n> ========================\n>\n> We called it revault as it relies on pre-signed and revocable (revaultable) transactions.\n> The users pre-sign a transaction chain as the only used way to spend from a vault output.\n> They would have signed a set of transactions to either cancel a spend attempt or lock the funds for some time beforehand. The funds are always better locked for a long time than stolen.\n>\n> The transactions\n>\n> ----------------\n>\n> The system is composed of mainly 6 transaction types (with N the number of stakeholders) :\n>\n> -   The \u201cvault\u201d transaction which pays to a N-of-N, by which funds are received.\n> -   The \u201cemergency\u201d transaction, which spends the vault output and pays to a [here goes a\n>     high value]-days timelocked N-of-N (with N differents but statics keys, assumed to be physically stored in hard(/long) to access locations).\n>\n> -   The \u201cunvault\u201d transaction, which spends the vault output and pays to [either the vault\u2019s N-of-N, or after X blocks to a subset of the stakeholders AND a co-signing server].\n> -   The \u201cunvault emergency\u201d transaction, which spends the unvault output and pays to the\n>     same script as the first emergency transaction.\n>\n> -   The \u201ccancel\u201d transaction, which spends the unvault output and pays back to a new vault utxo.\n> -   The \u201cspend\u201d transaction, which spends the unvault output and pays to an external address (potentially contained in a list of destinations previously agreed-upon by all the stakeholders).\n>\n>     The process\n>\n>\n> The stakeholders would exchange the signatures of all the revaulting transactions after the reception of a new vault utxo, and then exchange the signatures of the unvaulting transaction. Before doing so, the coins are not available to be spent.\n>\n> In order to spend a vault, the subset of the stakeholders who manages the funds (for example, the traders of an investment fund) would make the cosigning server (which only signs a transaction once) sign the spend transaction.\n> They would then present it to the other watchers which would ACK the spend (if paying to an authorized address), and broadcast the \"unvault\" transaction. Finally, and after X blocks have passed they would be able to broadcast the spend transaction.\n> If a stakeholder's watcher detects an unvaulting transaction without knowing about its child \u201cspend\u201d transaction, it triggers an automatic \u201ccancel\u201d transaction (not encumbered by the timelock).\n>\n> At any point -even in the middle of a spend- any of the stakeholder can trigger an emergency transaction if anything nasty is happening.\n> Any network watcher noticing the broadcast of an emergency transaction would also broadcast all other vaults\u2019 emergency transactions.\n>\n> This network watching and revaulting power can be replicated (watchtowers) to further decrease the reliance on a single machine or internet access.\n>\n> Pre-signed transactions fun\n>\n> ---------------------------\n>\n> In order to avoid our security assumptions to be as weak as betting on the value of the feerate in the future, stakeholders exchange SINGLE | ANYONECANPAY signatures for the revaulting transactions and append their own as SIGHASH_ALL before broadcasting.\n> They can add another input (and potentially output) in order to bump the fees before doing so.\n>\n> We protect ourselves from the bug by leveraging the fact the revaulting (namely the \"emergency\", \"unvault emergency\", and \"cancel\" transactions) only have strictly one input and one output. The change being part of the spend transaction.\n>\n> In addition, revaulting transactions may signal for RBF to cover a feerate increase after the broadcast. Anyhow, a significant breathing room can be added to the feerate as these transactions are not intended to be used under normal circumstances.\n>\n> Worth mentioning\n>\n> ================\n>\n> The original draft of this architecture was first designed by Kevin Loaec who was hired by NOIA to do so. It was inspired by Bryan Bishop\u2019s single-party vault architecture (https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-August/017229.html), who published a demo implementation of it last week (https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-April/017755.html, https://github.com/kanzure/python-vaults).\n> Kevin and I since detailed and reworked our new architecture together.\n>\n> A WIP draft / demo / PoC / [enter adjective with \u201cinsecure\u201d meaning] implementation is available at https://github.com/re-vault/revault-demo, which uses 4 stakeholders, 2 or 3 traders (doing the day-to-day moves) a CSV of 6 blocks for the unvault script and a CSV of ~1 month for the emergency scripts.\n> The transactions used are detailed in the doc/ directory of the same repo, and are coded in the revault/transactions/ module.\n>\n> The \u201crevault\u201d name was coined by Lea Thiebaut (Lexyon).\n>\n> Thanks for reading,\n> Antoine / Darosior"
            }
        ],
        "thread_summary": {
            "title": "Revault: a multi-party vault architecture",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "darosior"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 8836
        }
    },
    {
        "title": "[bitcoin-dev] Compressed block headers",
        "thread_messages": [
            {
                "author": "Will Clark",
                "date": "2020-05-08T12:31:06",
                "message_text_only": "Hello list,\n\nI would like to propose a compressed block header scheme for IBD and block announcements. This proposal is derivative of previous proposals found on this list (see links in spec below) with some modifications and clarifications.\n\nThe below specification (also found at https://github.com/willcl-ark/compressed-block-headers/blob/v1.0/compressed-block-headers.adoc ) details the compression recommended along with the generated bandwidth savings in the best-case scenario.\n\nI look forward to any feedback anyone has to offer on the specification itself, as well as any additions or objections to the motivation.\n\nCheers,\nWill\n\n\n= Compressed block headers\nWill Clark <will8clark at gmail.com>\nv1.0, May 2020:\n:toc: preamble\n:toclevels: 4\n\n\nThis work is a derivation of these mailing list posts:\n\n1. https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-August/014876.html[bitcoin-dev: \"Compressed\" headers stream - 2017] (with resurrection https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015385.html[here])\n\n2. https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-March/015851.html[bitcoin-dev: Optimized Header Sync]\n\n'''\n\n== Motivation\n\nBlock headers as exchanged by nodes over the p2p network are currently 81 bytes each.\n\nFor low bandwidth nodes who are doing a headers-only sync, reducing the size of the headers can provide a significant bandwidth saving. Also, nodes can support more header-only peers for IBD and protection against eclipse attacks if header bandwidth is reduced.\n\n=== Background\n\nCurrently headers are sent over the p2p network as a vector of `block_headers`, which are composed of the following sized fields:\n\n[cols=\"<,>\"]\n|===\n|Field               |Size\n\n|Version             |4 bytes\n|Previous block hash |32 bytes\n|Merkle root hash    |32 bytes\n|Time                |4 bytes\n|nBits               |4 bytes\n|nonce               |4 bytes\n|txn_count           |1 byte\n|*Total*             |81 bytes\n|===\n\nSome fields can be removed completely, others can be compressed under certain conditions.\n\n== Proposed specification\n\n=== block_header2 data type\n\nThe following table illustrates the proposed `block_header2` data type specification.\n\n[cols=\"<,>,>\"]\n|===\n|Field               |Size     |Compressed\n\n|Bitfield            |1 byte   | 1 byte\n|Version             |4 bytes  |0 \\| 4 bytes\n|Previous block hash |32 bytes |0 \\| 32 bytes\n|Merkle root hash    |32 bytes |32 bytes\n|Time                |4 bytes  |2 \\| 4 bytes\n|nBits               |4 bytes  |0 \\| 4 bytes\n|nonce               |4 bytes  |4 bytes\n|*Total*             |81 bytes |range: 39 - 81 bytes\n|===\n\nThis compression results in a maximum reduction from an 81 byte header to best-case 39 byte header. With 629,474 blocks in the current blockchain, a continuous header sync from genesis (requiring a single full 81 byte header followed by only compressed `block_header2`) has been tested to have its required bandwidth reduced from 50.98MB down to 25.86MB, a saving of 49%.\n\n==== Bitfield\n\nTo make parsing of header messages easier and further increase header compression, a single byte bitfield was suggested by gmaxwell footnote:[https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015397.html]. We propose the following amended bitfield meanings (bits re-ordered to match `headers2` field order):\n\n[cols=\"<,<\"]\n|===\n|Bit |Meaning + field size to read\n\n|0 +\n1 +\n2    |version: same as the last *distinct* value 1st ... 7th (0 byte field) or a new 32bit distinct value (4 byte field).\n|3   |prev_block_hash: is omitted (0 byte field) or included (32 byte field)\n|4   |timestamp: as small offset (2 byte field) or full (4 byte field).\n|5   |nbits: same as last header (0 byte field) or new (4 byte field).\n|6   |possibly to signal \"more headers follow\" to make the encoding self-delimiting.\n|7   |currently undefined\n|===\n\nThis bitfield adds 1 byte for every block in the chain, for a current total increase of 629,474B.\n\n==== Version\n\nIn most cases the Version field will be identical to one referenced in one of the previous 7 unique versions, as indicated by bits 0,1,2 of the Bitfield.\n\nTo block 629,474 there were 616,137 blocks whose version was in the previous 7 distinct versions, and only 13,338 blocks whose version was not, this includes any version bit manipulation done via overt ASIC boost.\n\n[cols=\">,>,>,>\"]\n|===\n|Genesis to block |Current (B) |Compressed (B) |Saving (%)\n\n|629,474          |2,517,896   |53,352         |98\n|===\n\n==== Previous block hash\n\nThe previous block hash will always be the\n`SHA256(SHA256(<previous_header>))` so is redundant, presuming you have the previous header in the chain.\n\n[cols=\">,>,>,>\"]\n|===\n|Genesis to block |Current (B) |Compressed (B) |Saving (%)\n\n|629,474          |20,143,168  |0              |100\n|===\n\n==== Time\n\nThe timestamp (in seconds) is consensus bound, based both on the time in the previous\nheader: `MAX_FUTURE_BLOCK_TIME = 2 * 60 * 60 = 7200`, and being greater than the `MedianTimePast` of the previous 11 blocks. Therefore this can be safely represented as an offset from the previous headers' timestamp using a 2 byte `signed short int`.\n\n[cols=\">,>,>,>\"]\n|===\n|Genesis to block |Current (B) |Compressed (B) |Saving (%)\n\n|629,474          |2,517,896   |1,258,952      |50\n|===\n\n==== nBits\n\nnBits currently changes once every 2016 blocks. It could be entirely calculated by the client from the timestamps of the previous 2015 blocks footnote:[2015 blocks are used in the adjustment calculation due to an off-by-one error: https://bitcointalk.org/index.php?topic=43692.msg521772#msg521772\"].\n\nTo simplify 'light' client implementations which would otherwise require consensus-valid calculation of the adjustments, we propose to transmit this according to the <<Bitfield>> specification above.\n\nTo block 629,474 there have been 298 nBits adjustments (vs an expected 311 -- there was none before block 32,256).\n\n[cols=\">,>,>,>\"]\n|===\n|Genesis to block |Current (B) |Compressed (B) |Saving (%)\n\n|629,474          |2,517,896   |1,196          |99.6\n|===\n\n==== txn_count\n\ntxn_count is included to make parsing of these messages compatible with parsing of `block` messages footnote:[https://bitcoin.stackexchange.com/questions/2104/why-is-the-block-header-txn-count-field-always-zero]. Therefore this field and its associated byte can be removed for transmission of compact headers.\n\n[cols=\">,>,>,>\"]\n|===\n|Genesis to block |Current (B) |Compressed (B) |Saving (%)\n\n|629,474          |629,474     |0              |100\n|===\n\n=== Service Bit\n\nA new service bit would be required so that the nodes can advertise their ability to supply compact headers.\n\n=== P2P Messages\n\nThree new messages would be used by nodes that enable compact block header support, two query messages: `getheaders2` and `sendheaders2` and one response: `headers2`.\n\n==== `getheaders2` -- Requesting compact headers\n\nThe new p2p message required to request compact block headers would require the same fields as the current `getheaders` message:\n\n[cols=\">,<,<,<\"]\n|===\n|Field Size |Description          |Data type |Comments\n\n|4          |version              |uint32_t  |the protocol version\n|1+         |hash count           |var_int   |number of block locator hash entries\n|32+        |block locator hashes |char[32]  |block locator object; newest back to genesis block (dense to start, but then sparse)\n|32         |hash_stop            |char[32]  |hash of the last desired block header; set to zero to get as many blocks as possible (2000)\n|===\n\n==== `sendheaders2` -- Request compact header announcements\n\nSince https://github.com/bitcoin/bips/blob/master/bip-0130.mediawiki[BIP-130], nodes have been able to request to receive new headers directly in `headers` messages, rather than via an `inv` of the new block hash and subsequent `getheader` request and `headers` response (followed by a final `getdata` to get the tip block itself, if desired). This is requested by transmitting an empty `sendheaders` message after the version handshake is complete.]\n\nUpon receipt of this message, the node is permitted, but not required, to preemptively announce new headers with the `headers2` message (instead of `inv`). Preemptive header announcement is supported by the protocol version \u2265 70012 | Bitcoin Core version \u2265 0.12.0.\n\nFor the motivational use-case it makes sense to also update this mechanism to support sending header updates using compact headers using a new message.\n\n==== `headers2` -- Receiving compact headers\n\nA `headers2` message is returned in response to `getheaders2` or at new header announcement following a `sendheaders2` request. It contains both `length` and `headers` fields. The `headers` field contains a variable length vector of `block_header2`:\n\n|===\n|Field Size |Description |Data type       |Comments\n\n|1+         |length      |var_int         |Length of `headers`\n|39-81x?    |headers     |block_header2[] |Compressed block headers in <<block_header2 data type>> format\n|===\n\n=== Implementation\n\n* The first header in the first `block_header2[]` vector to a newly-connected client MUST contain the full nBits`, `timestamp`, `version` and `prev_block_hash` fields, along with a correctly populated `bitfield` byte.\n* Subsequent headers in a contiguous vector SHOULD follow the compressed <<block_header2 data type>> format.\n* Subsequent compressed headers supplied to an already-connected client (requesting compressed headers), SHOULD follow the compressed <<block_header2 data type>> format."
            },
            {
                "author": "Richard Myers",
                "date": "2020-05-11T11:46:04",
                "message_text_only": "Thanks for resurrecting this idea for discussion Will.\n\nI see three reasons for reducing block header bandwidth:\n\n 1. support for long range block header broadcast via alternative\ncommunication modalities like radio where every byte counts\n 2. where repurposed mobile devices with SPV wallets are used because\nmetered bandwidth and hardware costs are high relative to income\n 3. full nodes could potentially support twice as many header only peers\n(is that a thing?) for better eclipse protection\n\nNodes could also run an additional daemon (eg. electrs) that serves\ncompressed block headers to light clients, but then it would be less likely\nto see widespread use to reduce bandwidth between full nodes.\n\nWhat are the negatives?\n - higher computation? probably minimal compared to serving the same\nuncompressed headers.\n - memory for caching the last few versions? bounded to last seven, so not\ntoo large.\n - complexity/bugs? minor and opt in for node operators, though you could\nargue the gain isn't worth any kind of change for nodes with high bandwidth\nconnections.\n - use of low-bandwidth light clients should not be encouraged? that is a\nseparate discussion, but I do not currently see any proposals to remove\nlight client support.\n\nI'm curious what other people think. Are the motivations enough to justify\na change to the protocol that produces a high percentage (but low absolute)\nbandwidth reduction for transmitting block headers?\n\n  -- Richard\n\nOn Fri, May 8, 2020 at 3:34 PM Will Clark via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hello list,\n>\n> I would like to propose a compressed block header scheme for IBD and block\n> announcements. This proposal is derivative of previous proposals found on\n> this list (see links in spec below) with some modifications and\n> clarifications.\n>\n> The below specification (also found at\n> https://github.com/willcl-ark/compressed-block-headers/blob/v1.0/compressed-block-headers.adoc\n> ) details the compression recommended along with the generated bandwidth\n> savings in the best-case scenario.\n>\n> I look forward to any feedback anyone has to offer on the specification\n> itself, as well as any additions or objections to the motivation.\n>\n> Cheers,\n> Will\n>\n>\n> = Compressed block headers\n> Will Clark <will8clark at gmail.com>\n> v1.0, May 2020:\n> :toc: preamble\n> :toclevels: 4\n>\n>\n> This work is a derivation of these mailing list posts:\n>\n> 1.\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-August/014876.html[bitcoin-dev:\n> \"Compressed\" headers stream - 2017] (with resurrection\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015385.html[here]\n> )\n>\n> 2.\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-March/015851.html[bitcoin-dev:\n> Optimized Header Sync]\n>\n> '''\n>\n> == Motivation\n>\n> Block headers as exchanged by nodes over the p2p network are currently 81\n> bytes each.\n>\n> For low bandwidth nodes who are doing a headers-only sync, reducing the\n> size of the headers can provide a significant bandwidth saving. Also, nodes\n> can support more header-only peers for IBD and protection against eclipse\n> attacks if header bandwidth is reduced.\n>\n> === Background\n>\n> Currently headers are sent over the p2p network as a vector of\n> `block_headers`, which are composed of the following sized fields:\n>\n> [cols=\"<,>\"]\n> |===\n> |Field               |Size\n>\n> |Version             |4 bytes\n> |Previous block hash |32 bytes\n> |Merkle root hash    |32 bytes\n> |Time                |4 bytes\n> |nBits               |4 bytes\n> |nonce               |4 bytes\n> |txn_count           |1 byte\n> |*Total*             |81 bytes\n> |===\n>\n> Some fields can be removed completely, others can be compressed under\n> certain conditions.\n>\n> == Proposed specification\n>\n> === block_header2 data type\n>\n> The following table illustrates the proposed `block_header2` data type\n> specification.\n>\n> [cols=\"<,>,>\"]\n> |===\n> |Field               |Size     |Compressed\n>\n> |Bitfield            |1 byte   | 1 byte\n> |Version             |4 bytes  |0 \\| 4 bytes\n> |Previous block hash |32 bytes |0 \\| 32 bytes\n> |Merkle root hash    |32 bytes |32 bytes\n> |Time                |4 bytes  |2 \\| 4 bytes\n> |nBits               |4 bytes  |0 \\| 4 bytes\n> |nonce               |4 bytes  |4 bytes\n> |*Total*             |81 bytes |range: 39 - 81 bytes\n> |===\n>\n> This compression results in a maximum reduction from an 81 byte header to\n> best-case 39 byte header. With 629,474 blocks in the current blockchain, a\n> continuous header sync from genesis (requiring a single full 81 byte header\n> followed by only compressed `block_header2`) has been tested to have its\n> required bandwidth reduced from 50.98MB down to 25.86MB, a saving of 49%.\n>\n> ==== Bitfield\n>\n> To make parsing of header messages easier and further increase header\n> compression, a single byte bitfield was suggested by gmaxwell footnote:[\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015397.html].\n> We propose the following amended bitfield meanings (bits re-ordered to\n> match `headers2` field order):\n>\n> [cols=\"<,<\"]\n> |===\n> |Bit |Meaning + field size to read\n>\n> |0 +\n> 1 +\n> 2    |version: same as the last *distinct* value 1st ... 7th (0 byte\n> field) or a new 32bit distinct value (4 byte field).\n> |3   |prev_block_hash: is omitted (0 byte field) or included (32 byte\n> field)\n> |4   |timestamp: as small offset (2 byte field) or full (4 byte field).\n> |5   |nbits: same as last header (0 byte field) or new (4 byte field).\n> |6   |possibly to signal \"more headers follow\" to make the encoding\n> self-delimiting.\n> |7   |currently undefined\n> |===\n>\n> This bitfield adds 1 byte for every block in the chain, for a current\n> total increase of 629,474B.\n>\n> ==== Version\n>\n> In most cases the Version field will be identical to one referenced in one\n> of the previous 7 unique versions, as indicated by bits 0,1,2 of the\n> Bitfield.\n>\n> To block 629,474 there were 616,137 blocks whose version was in the\n> previous 7 distinct versions, and only 13,338 blocks whose version was not,\n> this includes any version bit manipulation done via overt ASIC boost.\n>\n> [cols=\">,>,>,>\"]\n> |===\n> |Genesis to block |Current (B) |Compressed (B) |Saving (%)\n>\n> |629,474          |2,517,896   |53,352         |98\n> |===\n>\n> ==== Previous block hash\n>\n> The previous block hash will always be the\n> `SHA256(SHA256(<previous_header>))` so is redundant, presuming you have\n> the previous header in the chain.\n>\n> [cols=\">,>,>,>\"]\n> |===\n> |Genesis to block |Current (B) |Compressed (B) |Saving (%)\n>\n> |629,474          |20,143,168  |0              |100\n> |===\n>\n> ==== Time\n>\n> The timestamp (in seconds) is consensus bound, based both on the time in\n> the previous\n> header: `MAX_FUTURE_BLOCK_TIME = 2 * 60 * 60 = 7200`, and being greater\n> than the `MedianTimePast` of the previous 11 blocks. Therefore this can be\n> safely represented as an offset from the previous headers' timestamp using\n> a 2 byte `signed short int`.\n>\n> [cols=\">,>,>,>\"]\n> |===\n> |Genesis to block |Current (B) |Compressed (B) |Saving (%)\n>\n> |629,474          |2,517,896   |1,258,952      |50\n> |===\n>\n> ==== nBits\n>\n> nBits currently changes once every 2016 blocks. It could be entirely\n> calculated by the client from the timestamps of the previous 2015 blocks\n> footnote:[2015 blocks are used in the adjustment calculation due to an\n> off-by-one error:\n> https://bitcointalk.org/index.php?topic=43692.msg521772#msg521772\"].\n>\n> To simplify 'light' client implementations which would otherwise require\n> consensus-valid calculation of the adjustments, we propose to transmit this\n> according to the <<Bitfield>> specification above.\n>\n> To block 629,474 there have been 298 nBits adjustments (vs an expected 311\n> -- there was none before block 32,256).\n>\n> [cols=\">,>,>,>\"]\n> |===\n> |Genesis to block |Current (B) |Compressed (B) |Saving (%)\n>\n> |629,474          |2,517,896   |1,196          |99.6\n> |===\n>\n> ==== txn_count\n>\n> txn_count is included to make parsing of these messages compatible with\n> parsing of `block` messages footnote:[\n> https://bitcoin.stackexchange.com/questions/2104/why-is-the-block-header-txn-count-field-always-zero].\n> Therefore this field and its associated byte can be removed for\n> transmission of compact headers.\n>\n> [cols=\">,>,>,>\"]\n> |===\n> |Genesis to block |Current (B) |Compressed (B) |Saving (%)\n>\n> |629,474          |629,474     |0              |100\n> |===\n>\n> === Service Bit\n>\n> A new service bit would be required so that the nodes can advertise their\n> ability to supply compact headers.\n>\n> === P2P Messages\n>\n> Three new messages would be used by nodes that enable compact block header\n> support, two query messages: `getheaders2` and `sendheaders2` and one\n> response: `headers2`.\n>\n> ==== `getheaders2` -- Requesting compact headers\n>\n> The new p2p message required to request compact block headers would\n> require the same fields as the current `getheaders` message:\n>\n> [cols=\">,<,<,<\"]\n> |===\n> |Field Size |Description          |Data type |Comments\n>\n> |4          |version              |uint32_t  |the protocol version\n> |1+         |hash count           |var_int   |number of block locator hash\n> entries\n> |32+        |block locator hashes |char[32]  |block locator object; newest\n> back to genesis block (dense to start, but then sparse)\n> |32         |hash_stop            |char[32]  |hash of the last desired\n> block header; set to zero to get as many blocks as possible (2000)\n> |===\n>\n> ==== `sendheaders2` -- Request compact header announcements\n>\n> Since\n> https://github.com/bitcoin/bips/blob/master/bip-0130.mediawiki[BIP-130],\n> nodes have been able to request to receive new headers directly in\n> `headers` messages, rather than via an `inv` of the new block hash and\n> subsequent `getheader` request and `headers` response (followed by a final\n> `getdata` to get the tip block itself, if desired). This is requested by\n> transmitting an empty `sendheaders` message after the version handshake is\n> complete.]\n>\n> Upon receipt of this message, the node is permitted, but not required, to\n> preemptively announce new headers with the `headers2` message (instead of\n> `inv`). Preemptive header announcement is supported by the protocol version\n> \u2265 70012 | Bitcoin Core version \u2265 0.12.0.\n>\n> For the motivational use-case it makes sense to also update this mechanism\n> to support sending header updates using compact headers using a new message.\n>\n> ==== `headers2` -- Receiving compact headers\n>\n> A `headers2` message is returned in response to `getheaders2` or at new\n> header announcement following a `sendheaders2` request. It contains both\n> `length` and `headers` fields. The `headers` field contains a variable\n> length vector of `block_header2`:\n>\n> |===\n> |Field Size |Description |Data type       |Comments\n>\n> |1+         |length      |var_int         |Length of `headers`\n> |39-81x?    |headers     |block_header2[] |Compressed block headers in\n> <<block_header2 data type>> format\n> |===\n>\n> === Implementation\n>\n> * The first header in the first `block_header2[]` vector to a\n> newly-connected client MUST contain the full nBits`, `timestamp`, `version`\n> and `prev_block_hash` fields, along with a correctly populated `bitfield`\n> byte.\n> * Subsequent headers in a contiguous vector SHOULD follow the compressed\n> <<block_header2 data type>> format.\n> * Subsequent compressed headers supplied to an already-connected client\n> (requesting compressed headers), SHOULD follow the compressed\n> <<block_header2 data type>> format.\n>\n>\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n-- \nRichard Myers\nDecentralized Applications Engineer, goTenna\ngotenna.com\n@gotenna\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200511/dc570025/attachment-0001.html>"
            },
            {
                "author": "Robin Linus",
                "date": "2020-05-11T12:26:54",
                "message_text_only": "Hi,\n\nnot sure if headergolf was mentioned yet. It's about very similar ideas: https://github.com/alecalve/headergolf\n\n\n\n\n\n\n\n\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Friday, May 8, 2020 2:31 PM, Will Clark via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hello list,\n>\n> I would like to propose a compressed block header scheme for IBD and block announcements. This proposal is derivative of previous proposals found on this list (see links in spec below) with some modifications and clarifications.\n>\n> The below specification (also found at https://github.com/willcl-ark/compressed-block-headers/blob/v1.0/compressed-block-headers.adoc ) details the compression recommended along with the generated bandwidth savings in the best-case scenario.\n>\n> I look forward to any feedback anyone has to offer on the specification itself, as well as any additions or objections to the motivation.\n>\n> Cheers,\n> Will\n>\n> = Compressed block headers\n> Will Clark will8clark at gmail.com\n> v1.0, May 2020:\n> :toc: preamble\n> :toclevels: 4\n>\n> This work is a derivation of these mailing list posts:\n>\n> 1.  https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-August/014876.html[bitcoin-dev: \"Compressed\" headers stream - 2017] (with resurrection https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015385.html[here])\n> 2.  https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-March/015851.html[bitcoin-dev: Optimized Header Sync]\n>\n>     '''\n>\n>     == Motivation\n>\n>     Block headers as exchanged by nodes over the p2p network are currently 81 bytes each.\n>\n>     For low bandwidth nodes who are doing a headers-only sync, reducing the size of the headers can provide a significant bandwidth saving. Also, nodes can support more header-only peers for IBD and protection against eclipse attacks if header bandwidth is reduced.\n>\n>     === Background\n>\n>     Currently headers are sent over the p2p network as a vector of `block_headers`, which are composed of the following sized fields:\n>\n>     [cols=\"<,>\"]\n>\n>\n> |===\n> |Field |Size\n>\n> |Version |4 bytes\n> |Previous block hash |32 bytes\n> |Merkle root hash |32 bytes\n> |Time |4 bytes\n> |nBits |4 bytes\n> |nonce |4 bytes\n> |txn_count |1 byte\n> |Total |81 bytes\n> |===\n>\n> Some fields can be removed completely, others can be compressed under certain conditions.\n>\n> == Proposed specification\n>\n> === block_header2 data type\n>\n> The following table illustrates the proposed `block_header2` data type specification.\n>\n> [cols=\"<,>,>\"]\n> |===\n> |Field |Size |Compressed\n>\n> |Bitfield |1 byte | 1 byte\n> |Version |4 bytes |0 \\| 4 bytes\n> |Previous block hash |32 bytes |0 \\| 32 bytes\n> |Merkle root hash |32 bytes |32 bytes\n> |Time |4 bytes |2 \\| 4 bytes\n> |nBits |4 bytes |0 \\| 4 bytes\n> |nonce |4 bytes |4 bytes\n> |Total |81 bytes |range: 39 - 81 bytes\n> |===\n>\n> This compression results in a maximum reduction from an 81 byte header to best-case 39 byte header. With 629,474 blocks in the current blockchain, a continuous header sync from genesis (requiring a single full 81 byte header followed by only compressed `block_header2`) has been tested to have its required bandwidth reduced from 50.98MB down to 25.86MB, a saving of 49%.\n>\n> ==== Bitfield\n>\n> To make parsing of header messages easier and further increase header compression, a single byte bitfield was suggested by gmaxwell footnote:[https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015397.html]. We propose the following amended bitfield meanings (bits re-ordered to match `headers2` field order):\n>\n> [cols=\"<,<\"]\n> |===\n> |Bit |Meaning + field size to read\n>\n> |0 +\n> 1 +\n> 2 |version: same as the last distinct value 1st ... 7th (0 byte field) or a new 32bit distinct value (4 byte field).\n> |3 |prev_block_hash: is omitted (0 byte field) or included (32 byte field)\n> |4 |timestamp: as small offset (2 byte field) or full (4 byte field).\n> |5 |nbits: same as last header (0 byte field) or new (4 byte field).\n> |6 |possibly to signal \"more headers follow\" to make the encoding self-delimiting.\n> |7 |currently undefined\n> |===\n>\n> This bitfield adds 1 byte for every block in the chain, for a current total increase of 629,474B.\n>\n> ==== Version\n>\n> In most cases the Version field will be identical to one referenced in one of the previous 7 unique versions, as indicated by bits 0,1,2 of the Bitfield.\n>\n> To block 629,474 there were 616,137 blocks whose version was in the previous 7 distinct versions, and only 13,338 blocks whose version was not, this includes any version bit manipulation done via overt ASIC boost.\n>\n> [cols=\">,>,>,>\"]\n> |===\n> |Genesis to block |Current (B) |Compressed (B) |Saving (%)\n>\n> |629,474 |2,517,896 |53,352 |98\n> |===\n>\n> ==== Previous block hash\n>\n> The previous block hash will always be the\n> `SHA256(SHA256(<previous_header>))` so is redundant, presuming you have the previous header in the chain.\n>\n> [cols=\">,>,>,>\"]\n> |===\n> |Genesis to block |Current (B) |Compressed (B) |Saving (%)\n>\n> |629,474 |20,143,168 |0 |100\n> |===\n>\n> ==== Time\n>\n> The timestamp (in seconds) is consensus bound, based both on the time in the previous\n> header: `MAX_FUTURE_BLOCK_TIME = 2 * 60 * 60 = 7200`, and being greater than the `MedianTimePast` of the previous 11 blocks. Therefore this can be safely represented as an offset from the previous headers' timestamp using a 2 byte `signed short int`.\n>\n> [cols=\">,>,>,>\"]\n> |===\n> |Genesis to block |Current (B) |Compressed (B) |Saving (%)\n>\n> |629,474 |2,517,896 |1,258,952 |50\n> |===\n>\n> ==== nBits\n>\n> nBits currently changes once every 2016 blocks. It could be entirely calculated by the client from the timestamps of the previous 2015 blocks footnote:[2015 blocks are used in the adjustment calculation due to an off-by-one error: https://bitcointalk.org/index.php?topic=43692.msg521772#msg521772\"].\n>\n> To simplify 'light' client implementations which would otherwise require consensus-valid calculation of the adjustments, we propose to transmit this according to the <<Bitfield>> specification above.\n>\n> To block 629,474 there have been 298 nBits adjustments (vs an expected 311 -- there was none before block 32,256).\n>\n> [cols=\">,>,>,>\"]\n> |===\n> |Genesis to block |Current (B) |Compressed (B) |Saving (%)\n>\n> |629,474 |2,517,896 |1,196 |99.6\n> |===\n>\n> ==== txn_count\n>\n> txn_count is included to make parsing of these messages compatible with parsing of `block` messages footnote:[https://bitcoin.stackexchange.com/questions/2104/why-is-the-block-header-txn-count-field-always-zero]. Therefore this field and its associated byte can be removed for transmission of compact headers.\n>\n> [cols=\">,>,>,>\"]\n> |===\n> |Genesis to block |Current (B) |Compressed (B) |Saving (%)\n>\n> |629,474 |629,474 |0 |100\n> |===\n>\n> === Service Bit\n>\n> A new service bit would be required so that the nodes can advertise their ability to supply compact headers.\n>\n> === P2P Messages\n>\n> Three new messages would be used by nodes that enable compact block header support, two query messages: `getheaders2` and `sendheaders2` and one response: `headers2`.\n>\n> ==== `getheaders2` -- Requesting compact headers\n>\n> The new p2p message required to request compact block headers would require the same fields as the current `getheaders` message:\n>\n> [cols=\">,<,<,<\"]\n> |===\n> |Field Size |Description |Data type |Comments\n>\n> |4 |version |uint32_t |the protocol version\n> |1+ |hash count |var_int |number of block locator hash entries\n> |32+ |block locator hashes |char[32] |block locator object; newest back to genesis block (dense to start, but then sparse)\n> |32 |hash_stop |char[32] |hash of the last desired block header; set to zero to get as many blocks as possible (2000)\n> |===\n>\n> ==== `sendheaders2` -- Request compact header announcements\n>\n> Since https://github.com/bitcoin/bips/blob/master/bip-0130.mediawiki[BIP-130], nodes have been able to request to receive new headers directly in `headers` messages, rather than via an `inv` of the new block hash and subsequent `getheader` request and `headers` response (followed by a final `getdata` to get the tip block itself, if desired). This is requested by transmitting an empty `sendheaders` message after the version handshake is complete.]\n>\n> Upon receipt of this message, the node is permitted, but not required, to preemptively announce new headers with the `headers2` message (instead of `inv`). Preemptive header announcement is supported by the protocol version \u2265 70012 | Bitcoin Core version \u2265 0.12.0.\n>\n> For the motivational use-case it makes sense to also update this mechanism to support sending header updates using compact headers using a new message.\n>\n> ==== `headers2` -- Receiving compact headers\n>\n> A `headers2` message is returned in response to `getheaders2` or at new header announcement following a `sendheaders2` request. It contains both `length` and `headers` fields. The `headers` field contains a variable length vector of `block_header2`:\n>\n> |===\n> |Field Size |Description |Data type |Comments\n>\n> |1+ |length |var_int |Length of `headers`\n> |39-81x? |headers |block_header2[] |Compressed block headers in <<block_header2 data type>> format\n> |===\n>\n> === Implementation\n>\n> -   The first header in the first `block_header2[]` vector to a newly-connected client MUST contain the full nBits`,`timestamp`,`version`and`prev_block_hash`fields, along with a correctly populated`bitfield` byte.\n>\n> -   Subsequent headers in a contiguous vector SHOULD follow the compressed <<block_header2 data type>> format.\n>\n> -   Subsequent compressed headers supplied to an already-connected client (requesting compressed headers), SHOULD follow the compressed <<block_header2 data type>> format.\n>\n>\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Richard Myers",
                "date": "2020-05-20T13:06:11",
                "message_text_only": "I've been looking at using compressed block headers from the perspective of\na node that wants to use SMS messages to sync block headers. I realized\nthat it would be helpful if sendheaders2 took a parameter for how often to\nsend compact blockheaders. For example, in the case of an SMS transport\nlayer, it would make sense to request 4 headers at a time to optimally fill\na 160 byte SMS message.\n\nAlthough using SMS messages would be about the most expensive way to\nreceive block headers, it is also the most universally available to\nsmartphone users, even where mobile data might be expensive or unavailable.\nIf we assume an SMS costs a bulk sender 0.025 USD per SMS, then sending 4\nat a time (4 x 39 + 1 byte < 160 byte max SMS) reduces costs 1/4 to 252\ninstead of 1008 messages at a total weekly cost of ~7 instead of 26 USD.\nStill not ideal, but a huge savings.\n\nSince you're proposing a new message anyway, it doesn't break compatibility\nto add a parameter for how often sendheaders2 chunks up recent headers.\n\nOn Fri, May 8, 2020 at 3:34 PM Will Clark via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hello list,\n>\n> I would like to propose a compressed block header scheme for IBD and block\n> announcements. This proposal is derivative of previous proposals found on\n> this list (see links in spec below) with some modifications and\n> clarifications.\n>\n> The below specification (also found at\n> https://github.com/willcl-ark/compressed-block-headers/blob/v1.0/compressed-block-headers.adoc\n> ) details the compression recommended along with the generated bandwidth\n> savings in the best-case scenario.\n>\n> I look forward to any feedback anyone has to offer on the specification\n> itself, as well as any additions or objections to the motivation.\n>\n> Cheers,\n> Will\n>\n>\n> = Compressed block headers\n> Will Clark <will8clark at gmail.com>\n> v1.0, May 2020:\n> :toc: preamble\n> :toclevels: 4\n>\n>\n> This work is a derivation of these mailing list posts:\n>\n> 1.\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-August/014876.html[bitcoin-dev:\n> \"Compressed\" headers stream - 2017] (with resurrection\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015385.html[here]\n> )\n>\n> 2.\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-March/015851.html[bitcoin-dev:\n> Optimized Header Sync]\n>\n> '''\n>\n> == Motivation\n>\n> Block headers as exchanged by nodes over the p2p network are currently 81\n> bytes each.\n>\n> For low bandwidth nodes who are doing a headers-only sync, reducing the\n> size of the headers can provide a significant bandwidth saving. Also, nodes\n> can support more header-only peers for IBD and protection against eclipse\n> attacks if header bandwidth is reduced.\n>\n> === Background\n>\n> Currently headers are sent over the p2p network as a vector of\n> `block_headers`, which are composed of the following sized fields:\n>\n> [cols=\"<,>\"]\n> |===\n> |Field               |Size\n>\n> |Version             |4 bytes\n> |Previous block hash |32 bytes\n> |Merkle root hash    |32 bytes\n> |Time                |4 bytes\n> |nBits               |4 bytes\n> |nonce               |4 bytes\n> |txn_count           |1 byte\n> |*Total*             |81 bytes\n> |===\n>\n> Some fields can be removed completely, others can be compressed under\n> certain conditions.\n>\n> == Proposed specification\n>\n> === block_header2 data type\n>\n> The following table illustrates the proposed `block_header2` data type\n> specification.\n>\n> [cols=\"<,>,>\"]\n> |===\n> |Field               |Size     |Compressed\n>\n> |Bitfield            |1 byte   | 1 byte\n> |Version             |4 bytes  |0 \\| 4 bytes\n> |Previous block hash |32 bytes |0 \\| 32 bytes\n> |Merkle root hash    |32 bytes |32 bytes\n> |Time                |4 bytes  |2 \\| 4 bytes\n> |nBits               |4 bytes  |0 \\| 4 bytes\n> |nonce               |4 bytes  |4 bytes\n> |*Total*             |81 bytes |range: 39 - 81 bytes\n> |===\n>\n> This compression results in a maximum reduction from an 81 byte header to\n> best-case 39 byte header. With 629,474 blocks in the current blockchain, a\n> continuous header sync from genesis (requiring a single full 81 byte header\n> followed by only compressed `block_header2`) has been tested to have its\n> required bandwidth reduced from 50.98MB down to 25.86MB, a saving of 49%.\n>\n> ==== Bitfield\n>\n> To make parsing of header messages easier and further increase header\n> compression, a single byte bitfield was suggested by gmaxwell footnote:[\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015397.html].\n> We propose the following amended bitfield meanings (bits re-ordered to\n> match `headers2` field order):\n>\n> [cols=\"<,<\"]\n> |===\n> |Bit |Meaning + field size to read\n>\n> |0 +\n> 1 +\n> 2    |version: same as the last *distinct* value 1st ... 7th (0 byte\n> field) or a new 32bit distinct value (4 byte field).\n> |3   |prev_block_hash: is omitted (0 byte field) or included (32 byte\n> field)\n> |4   |timestamp: as small offset (2 byte field) or full (4 byte field).\n> |5   |nbits: same as last header (0 byte field) or new (4 byte field).\n> |6   |possibly to signal \"more headers follow\" to make the encoding\n> self-delimiting.\n> |7   |currently undefined\n> |===\n>\n> This bitfield adds 1 byte for every block in the chain, for a current\n> total increase of 629,474B.\n>\n> ==== Version\n>\n> In most cases the Version field will be identical to one referenced in one\n> of the previous 7 unique versions, as indicated by bits 0,1,2 of the\n> Bitfield.\n>\n> To block 629,474 there were 616,137 blocks whose version was in the\n> previous 7 distinct versions, and only 13,338 blocks whose version was not,\n> this includes any version bit manipulation done via overt ASIC boost.\n>\n> [cols=\">,>,>,>\"]\n> |===\n> |Genesis to block |Current (B) |Compressed (B) |Saving (%)\n>\n> |629,474          |2,517,896   |53,352         |98\n> |===\n>\n> ==== Previous block hash\n>\n> The previous block hash will always be the\n> `SHA256(SHA256(<previous_header>))` so is redundant, presuming you have\n> the previous header in the chain.\n>\n> [cols=\">,>,>,>\"]\n> |===\n> |Genesis to block |Current (B) |Compressed (B) |Saving (%)\n>\n> |629,474          |20,143,168  |0              |100\n> |===\n>\n> ==== Time\n>\n> The timestamp (in seconds) is consensus bound, based both on the time in\n> the previous\n> header: `MAX_FUTURE_BLOCK_TIME = 2 * 60 * 60 = 7200`, and being greater\n> than the `MedianTimePast` of the previous 11 blocks. Therefore this can be\n> safely represented as an offset from the previous headers' timestamp using\n> a 2 byte `signed short int`.\n>\n> [cols=\">,>,>,>\"]\n> |===\n> |Genesis to block |Current (B) |Compressed (B) |Saving (%)\n>\n> |629,474          |2,517,896   |1,258,952      |50\n> |===\n>\n> ==== nBits\n>\n> nBits currently changes once every 2016 blocks. It could be entirely\n> calculated by the client from the timestamps of the previous 2015 blocks\n> footnote:[2015 blocks are used in the adjustment calculation due to an\n> off-by-one error:\n> https://bitcointalk.org/index.php?topic=43692.msg521772#msg521772\"].\n>\n> To simplify 'light' client implementations which would otherwise require\n> consensus-valid calculation of the adjustments, we propose to transmit this\n> according to the <<Bitfield>> specification above.\n>\n> To block 629,474 there have been 298 nBits adjustments (vs an expected 311\n> -- there was none before block 32,256).\n>\n> [cols=\">,>,>,>\"]\n> |===\n> |Genesis to block |Current (B) |Compressed (B) |Saving (%)\n>\n> |629,474          |2,517,896   |1,196          |99.6\n> |===\n>\n> ==== txn_count\n>\n> txn_count is included to make parsing of these messages compatible with\n> parsing of `block` messages footnote:[\n> https://bitcoin.stackexchange.com/questions/2104/why-is-the-block-header-txn-count-field-always-zero].\n> Therefore this field and its associated byte can be removed for\n> transmission of compact headers.\n>\n> [cols=\">,>,>,>\"]\n> |===\n> |Genesis to block |Current (B) |Compressed (B) |Saving (%)\n>\n> |629,474          |629,474     |0              |100\n> |===\n>\n> === Service Bit\n>\n> A new service bit would be required so that the nodes can advertise their\n> ability to supply compact headers.\n>\n> === P2P Messages\n>\n> Three new messages would be used by nodes that enable compact block header\n> support, two query messages: `getheaders2` and `sendheaders2` and one\n> response: `headers2`.\n>\n> ==== `getheaders2` -- Requesting compact headers\n>\n> The new p2p message required to request compact block headers would\n> require the same fields as the current `getheaders` message:\n>\n> [cols=\">,<,<,<\"]\n> |===\n> |Field Size |Description          |Data type |Comments\n>\n> |4          |version              |uint32_t  |the protocol version\n> |1+         |hash count           |var_int   |number of block locator hash\n> entries\n> |32+        |block locator hashes |char[32]  |block locator object; newest\n> back to genesis block (dense to start, but then sparse)\n> |32         |hash_stop            |char[32]  |hash of the last desired\n> block header; set to zero to get as many blocks as possible (2000)\n> |===\n>\n> ==== `sendheaders2` -- Request compact header announcements\n>\n> Since\n> https://github.com/bitcoin/bips/blob/master/bip-0130.mediawiki[BIP-130],\n> nodes have been able to request to receive new headers directly in\n> `headers` messages, rather than via an `inv` of the new block hash and\n> subsequent `getheader` request and `headers` response (followed by a final\n> `getdata` to get the tip block itself, if desired). This is requested by\n> transmitting an empty `sendheaders` message after the version handshake is\n> complete.]\n>\n> Upon receipt of this message, the node is permitted, but not required, to\n> preemptively announce new headers with the `headers2` message (instead of\n> `inv`). Preemptive header announcement is supported by the protocol version\n> \u2265 70012 | Bitcoin Core version \u2265 0.12.0.\n>\n> For the motivational use-case it makes sense to also update this mechanism\n> to support sending header updates using compact headers using a new message.\n>\n> ==== `headers2` -- Receiving compact headers\n>\n> A `headers2` message is returned in response to `getheaders2` or at new\n> header announcement following a `sendheaders2` request. It contains both\n> `length` and `headers` fields. The `headers` field contains a variable\n> length vector of `block_header2`:\n>\n> |===\n> |Field Size |Description |Data type       |Comments\n>\n> |1+         |length      |var_int         |Length of `headers`\n> |39-81x?    |headers     |block_header2[] |Compressed block headers in\n> <<block_header2 data type>> format\n> |===\n>\n> === Implementation\n>\n> * The first header in the first `block_header2[]` vector to a\n> newly-connected client MUST contain the full nBits`, `timestamp`, `version`\n> and `prev_block_hash` fields, along with a correctly populated `bitfield`\n> byte.\n> * Subsequent headers in a contiguous vector SHOULD follow the compressed\n> <<block_header2 data type>> format.\n> * Subsequent compressed headers supplied to an already-connected client\n> (requesting compressed headers), SHOULD follow the compressed\n> <<block_header2 data type>> format.\n>\n>\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n-- \nRichard Myers\nDecentralized Applications Engineer, goTenna\ngotenna.com\n@gotenna\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200520/f9b6f40d/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Compressed block headers",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Will Clark",
                "Robin Linus",
                "Richard Myers"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 43028
        }
    },
    {
        "title": "[bitcoin-dev] SAS: Succinct Atomic Swap",
        "thread_messages": [
            {
                "author": "Ruben Somsen",
                "date": "2020-05-11T15:29:51",
                "message_text_only": "Works today with single signer ECDSA adaptor signatures[0], or with\nSchnorr + MuSig.\n\nDiagram here:\nhttps://gist.github.com/RubenSomsen/8853a66a64825716f51b409be528355f#file-succinctatomicswap-svg\n\n\nAdvantages:\n\n- Requires merely two on-chain transactions for successful completion,\nas opposed to four\n- Scriptless, and one of the chains doesn't need to support timelocks\n- Can be used for efficient privacy swaps, e.g. Payswap[1]\n\n\nDisadvantages:\n\n- Access to money is contingent on remembering secrets (backup complexity)\n- Online/watchtower requirement for the timelock supporting chain (not\nneeded with 3 tx protocol)\n\n\nProtocol steps:\n\n\n0.) Alice & Bob pre-sign the following transactions, with exception of\nthe signatures in [brackets]:\n\n- success_tx (money to Bob): [sigSuccessAlice] + [sigSuccessBob]\n- revoke_tx (timelock): sigRevokeAlice + sigRevokeBob, which must then\nbe spent by:\n  -- refund_tx (relative timelock, refund to Alice): [sigRefundAlice]\n+ {sigRefundBob}\n  -- timeout_tx (longer relative timelock, money to Bob):\nsigTimeoutAlice + [sigTimeoutBob]\n\n{sigRefundBob} is an adaptor signature, which requires secretAlice to complete\n\n\n1.) Alice proceeds to lock up 1 BTC with Bob, using keyAlice & keyBob as pubkeys\n\nIf protocol is aborted after step 1:\n\n- Alice publishes the revoke_tx, followed by the refund_tx &\nsigRefundBob, to get her BTC back\n- If Alice neglects to publish the refund_tx in time, Bob will claim\nthe BTC with the timeout_tx\n\n\n2.) Bob locks up altcoins with Alice, using secretAlice & secretBob as pubkeys\n\nIf protocol is aborted after step 2:\n\n- Once Alice publishes sigRefundBob, Bob learns secretAlice and\nregains control over the altcoins\n\n\n3.) Protocol completion:\n\n- Alice hands adaptor signature {sigSuccessAlice} to Bob, which\nrequires secretBob to complete\n- Bob could now claim the BTC via the success_tx, reveal secretBob,\nand thus give Alice control over the altcoins (= 3 tx protocol)\n- Instead, Bob simply hands secretBob to Alice\n- Likewise, Alice hands keyAlice to Bob to forego her claim on the refund_tx\n- Bob continues to monitor the chain, because he'll have to respond if\nAlice ever publishes the revoke_tx\n\n\nMore graceful protocol failure:\n\nIf the protocol aborts after step 1, Alice would have been forced to\nmake three transactions in total, while Bob has made none. We can\nreduce that to two by introducing a second refund_tx with timelock\nthat can be published ahead of the revoke_tx and directly spends from\nthe funding transaction. Publishing this transaction would also reveal\nsecretAlice to Bob via an adaptor signature. In the 3 tx protocol,\nthis output can go directly to Alice. In the 2 tx protocol with\nonline/watchtower requirement, this output needs a script: spendable\nby Alice + Bob right away OR by Alice after a relative timelock. It is\nimportant to note that this transaction must NOT be published during\nstep 3. Once Bob can complete the success_tx, the revoke_tx is needed\nto invalidate the success_tx prior to revealing secretAlice.\n\n\nFAQ:\n\n- Why not allow Alice to still claim the altcoins if she accidentally\nlets Bob publish the timeout_tx?\n\nAlice could send the revoke_tx at the same time, revealing both\nsecrets and causing likely losses. This can be solved by adding yet\nanother transaction, but it wouldn't be efficient and wouldn't\nmotivate Alice to behave.\n\n- Is it possible to implement this protocol on chains which only\nsupport absolute timelocks?\n\nYes, but then Bob must spend his swapped coins before the timelock\nexpires (or use the 3 tx protocol). Be aware that the revoke_tx MUST\nconfirm before the timeout_tx becomes valid, which may become a\nproblem if fees suddenly rise. The refund_tx can also not be allowed\nto CPFP the timeout_tx, as they must confirm independently in order to\ninvalidate the success_tx first.\n\n- Can't Alice just publish the revoke_tx after protocol completion?\n\nYes, she'd first have to move the altcoins (to invalidate\nsecretAlice), and could then try to claim the BTC by publishing the\nrevoke_tx, forcing Bob to react on-chain before the refund_tx becomes\nvalid. The eltoo[2] method of paying for fees (requires\nsighash_anyprevout) or a second CPFP-able output may be an improvement\nhere (and also mitigates fee rising issues), but note that this also\nincreases the required amount of tx data if the protocol doesn't\ncomplete successfully.\n\n- Can this be made to work with hash locks?\n\nYes, by making the altcoins spendable via sigAlice + preimageBob OR\nsigBob + preimageAlice, and ensuring the contracts on the BTC side\nreveal either pre-image. Do note that this is not scriptless and will\nthus increase the transaction size.\n\n\nOpen question:\n\nPerhaps it's possible to perform an atomic swap in and out of\nLightning with only a single on-chain transaction. This would require\nsome kind of secondary set of HTLCs, allowing the sender to cancel a\nLightning payment by revealing a secret after a certain period of\ntime.\n\n\n-- Ruben Somsen\n\n\n\n\nThanks to Lloyd Fournier for feedback and review.\n\nIf you find any further errors, I will endeavor to fix them here:\nhttps://gist.github.com/RubenSomsen/8853a66a64825716f51b409be528355f\n\n\nRelated work:\n\nTier Nolan Atomic Swap:\nhttps://bitcointalk.org/index.php?topic=193281.msg2224949#msg2224949\nMonero Atomic Swap:\nhttps://github.com/h4sh3d/xmr-btc-atomic-swap/blob/master/README.md\n\n\n[0] https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-November/002316.html\n\n[1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-January/017595.html\n\n[2] https://blockstream.com/eltoo.pdf"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-11T16:45:21",
                "message_text_only": "Good morning Ruben,\n\nCoinSwap for privacy is practically a \"cross\" chain atomic swap with the same chain and token for both sides of the swap, see also this set of ideas: https://github.com/AdamISZ/CoinSwapCS/issues/53\n\n\"Instead, Bob simply hands secretBob to Alice\" is basically the same as private key turnover, as best as I can understand it, and gives significant advantages, also described in passing here: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-May/017816.html\n\nOverall, this looks very much like a working CoinSwap as well.\n\nThe Refund tx does not need anything more than a 2-of-2 script.\nThe \"OR Alice in +1 day\" branch can be implemented, at least on Bitcoin and similar blockchains, by signing a specific `nSequence`, or if the chain forking predates BIP68, by using absolute locktimes and signing a specific `nLockTime`, with the destination being just \"Alice\".\nThis should help privacy, as now all `scriptPubKey`s will be 2-of-2 (or P2PKH with 2p-ECDSA).\n\n(It strikes me that the relative locktime is unnecessary on the output of this refund tx --- as long as both participants agree on either Alice or Bob having a longer locktime, you can just use the locktime on the refund tx directly as backout; see the topic \"`nLockTime`-protected Backouts\" on the CoinSwapCS issue link)\n\nIf you are willing to accept protocol complexity, having a variety of different versions of the transactions with different feerates could be used rather than the Decker-Russell-Osuntokun \"eltoo\" bring-your-own-fees method.\nIn terms of privacy this is better as you would not be using anything other than the most boring `SIGHASH_ALL` signing flag, whereas the Decker-Russell-Osuntokun will be identifiable onchain (and thus possibly flag the transaction as \"of interest\" to surveillors) due to use of `SIGHASH_ANYPREVOUT`.\nAs long as the one resolving a particular side of the swap is the one that ocmpletes the signature (which I believe holds true for all branches?) then it would select the version of the transaction with the best feerate, which it effectively pays out to what it recovers.\n\n\nRegards,\nZmnSCPxj\n\n\n> Works today with single signer ECDSA adaptor signatures[0], or with\n> Schnorr + MuSig.\n>\n> Diagram here:\n> https://gist.github.com/RubenSomsen/8853a66a64825716f51b409be528355f#file-succinctatomicswap-svg\n>\n> Advantages:\n>\n> -   Requires merely two on-chain transactions for successful completion,\n>     as opposed to four\n>\n> -   Scriptless, and one of the chains doesn't need to support timelocks\n> -   Can be used for efficient privacy swaps, e.g. Payswap[1]\n>\n>     Disadvantages:\n>\n> -   Access to money is contingent on remembering secrets (backup complexity)\n> -   Online/watchtower requirement for the timelock supporting chain (not\n>     needed with 3 tx protocol)\n>\n>     Protocol steps:\n>\n>     0.) Alice & Bob pre-sign the following transactions, with exception of\n>     the signatures in [brackets]:\n>\n> -   success_tx (money to Bob): [sigSuccessAlice] + [sigSuccessBob]\n> -   revoke_tx (timelock): sigRevokeAlice + sigRevokeBob, which must then\n>     be spent by:\n>     -- refund_tx (relative timelock, refund to Alice): [sigRefundAlice]\n>\n>\n> -   {sigRefundBob}\n>     -- timeout_tx (longer relative timelock, money to Bob):\n>     sigTimeoutAlice + [sigTimeoutBob]\n>\n>     {sigRefundBob} is an adaptor signature, which requires secretAlice to complete\n>\n>     1.) Alice proceeds to lock up 1 BTC with Bob, using keyAlice & keyBob as pubkeys\n>\n>     If protocol is aborted after step 1:\n>\n>\n> -   Alice publishes the revoke_tx, followed by the refund_tx &\n>     sigRefundBob, to get her BTC back\n>\n> -   If Alice neglects to publish the refund_tx in time, Bob will claim\n>     the BTC with the timeout_tx\n>\n>     2.) Bob locks up altcoins with Alice, using secretAlice & secretBob as pubkeys\n>\n>     If protocol is aborted after step 2:\n>\n> -   Once Alice publishes sigRefundBob, Bob learns secretAlice and\n>     regains control over the altcoins\n>\n>     3.) Protocol completion:\n>\n> -   Alice hands adaptor signature {sigSuccessAlice} to Bob, which\n>     requires secretBob to complete\n>\n> -   Bob could now claim the BTC via the success_tx, reveal secretBob,\n>     and thus give Alice control over the altcoins (= 3 tx protocol)\n>\n> -   Instead, Bob simply hands secretBob to Alice\n> -   Likewise, Alice hands keyAlice to Bob to forego her claim on the refund_tx\n> -   Bob continues to monitor the chain, because he'll have to respond if\n>     Alice ever publishes the revoke_tx\n>\n>     More graceful protocol failure:\n>\n>     If the protocol aborts after step 1, Alice would have been forced to\n>     make three transactions in total, while Bob has made none. We can\n>     reduce that to two by introducing a second refund_tx with timelock\n>     that can be published ahead of the revoke_tx and directly spends from\n>     the funding transaction. Publishing this transaction would also reveal\n>     secretAlice to Bob via an adaptor signature. In the 3 tx protocol,\n>     this output can go directly to Alice. In the 2 tx protocol with\n>     online/watchtower requirement, this output needs a script: spendable\n>     by Alice + Bob right away OR by Alice after a relative timelock. It is\n>     important to note that this transaction must NOT be published during\n>     step 3. Once Bob can complete the success_tx, the revoke_tx is needed\n>     to invalidate the success_tx prior to revealing secretAlice.\n>\n>     FAQ:\n>\n> -   Why not allow Alice to still claim the altcoins if she accidentally\n>     lets Bob publish the timeout_tx?\n>\n>     Alice could send the revoke_tx at the same time, revealing both\n>     secrets and causing likely losses. This can be solved by adding yet\n>     another transaction, but it wouldn't be efficient and wouldn't\n>     motivate Alice to behave.\n>\n> -   Is it possible to implement this protocol on chains which only\n>     support absolute timelocks?\n>\n>     Yes, but then Bob must spend his swapped coins before the timelock\n>     expires (or use the 3 tx protocol). Be aware that the revoke_tx MUST\n>     confirm before the timeout_tx becomes valid, which may become a\n>     problem if fees suddenly rise. The refund_tx can also not be allowed\n>     to CPFP the timeout_tx, as they must confirm independently in order to\n>     invalidate the success_tx first.\n>\n> -   Can't Alice just publish the revoke_tx after protocol completion?\n>\n>     Yes, she'd first have to move the altcoins (to invalidate\n>     secretAlice), and could then try to claim the BTC by publishing the\n>     revoke_tx, forcing Bob to react on-chain before the refund_tx becomes\n>     valid. The eltoo[2] method of paying for fees (requires\n>     sighash_anyprevout) or a second CPFP-able output may be an improvement\n>     here (and also mitigates fee rising issues), but note that this also\n>     increases the required amount of tx data if the protocol doesn't\n>     complete successfully.\n>\n> -   Can this be made to work with hash locks?\n>\n>     Yes, by making the altcoins spendable via sigAlice + preimageBob OR\n>     sigBob + preimageAlice, and ensuring the contracts on the BTC side\n>     reveal either pre-image. Do note that this is not scriptless and will\n>     thus increase the transaction size.\n>\n>     Open question:\n>\n>     Perhaps it's possible to perform an atomic swap in and out of\n>     Lightning with only a single on-chain transaction. This would require\n>     some kind of secondary set of HTLCs, allowing the sender to cancel a\n>     Lightning payment by revealing a secret after a certain period of\n>     time.\n>\n>     -- Ruben Somsen\n>\n>     Thanks to Lloyd Fournier for feedback and review.\n>\n>     If you find any further errors, I will endeavor to fix them here:\n>     https://gist.github.com/RubenSomsen/8853a66a64825716f51b409be528355f\n>\n>     Related work:\n>\n>     Tier Nolan Atomic Swap:\n>     https://bitcointalk.org/index.php?topic=193281.msg2224949#msg2224949\n>     Monero Atomic Swap:\n>     https://github.com/h4sh3d/xmr-btc-atomic-swap/blob/master/README.md\n>\n>     [0] https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-November/002316.html\n>\n>     [1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-January/017595.html\n>\n>     [2] https://blockstream.com/eltoo.pdf\n>\n>\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Ruben Somsen",
                "date": "2020-05-11T17:50:21",
                "message_text_only": "Hi ZmnSCPxj,\n\nThanks for your feedback :)\n\n>CoinSwap for privacy is practically a \"cross\" chain atomic swap with the same chain and token for both sides of the swap\n\nI agree, I didn't mean to imply that was new, only that this protocol\nmakes it more efficient.\n\n>\"Instead, Bob simply hands secretBob to Alice\" is basically the same as private key turnover\n\nThanks for the link. I will add it to the links at the bottom of the\nwrite-up, as I agree it's related. Do note there are a few key\ndifferences:\n\n- The swap is set up in an \"asymmetric\" way with only timelocks on one\nside, so on the other side the swap *never* expires\n- The timelocks are set up in such a way that the swap does not expire\nunless Alice starts the relative timelock countdown (the revoke\ntransaction)\n- This relative timelock setup comes practically for free, because the\nasymmetry naturally requires that kind of setup\n\n>The \"OR Alice in +1 day\" branch can be implemented, at least on Bitcoin and similar blockchains, by signing a specific `nSequence`\n\n\"OR Alice in +1 day\" is \"refund transaction #1\" from the diagram. If\nI'm not mistaken, the change you are suggesting is exactly how \"refund\ntransaction #2\" is constructed. Note that #1 and #2 serve the same\npurpose. Strictly speaking, #1 is not needed at all, but it's there to\ngive Alice the option to back out of the swap in two transactions as\nopposed to three.\n\n>It strikes me that the relative locktime is unnecessary on the output of this refund tx\n\nI believe I addressed this in the FAQ section (the question about\nabsolute timelocks). An absolute timelock is possible, but you then\nneed to make absolutely sure that the revoke transaction confirms in\ntime, otherwise the protocol can fail (namely after Bob has received a\ncopy of the success transaction and just waits and does nothing). You\nalso lose the ability to keep the channel open indefinitely.\n\n>having a variety of different versions of the transactions with different feerates could be used\n\nThat's a good point.\n\n>As long as the one resolving a particular side of the swap is the one that ocmpletes the signature (which I believe holds true for all branches?)\n\nUnfortunately this does not hold for the revoke transaction. It would\nbe a bit awkward if Alice had a high fee copy after the protocol\ncompletes. She could send it to the blockchain and essentially Bob\nwould be paying for it. I'm not as concerned about the other\ntransactions, because those could all be bumped with CPFP if needed,\nbut having different feerates would be nice.\n\nAnd a general comment about privacy: it seems inevitable that some\ninformation will be leaked if the protocol does not complete\ncooperatively. As long as the cooperative case is not traceable, that\nseems about as good as it can get. That's my view, at least. I'd be\ncurious to hear if you see that differently.\n\nCheers,\nRuben\n\n\n\nOn Mon, May 11, 2020 at 6:45 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n> Good morning Ruben,\n>\n> CoinSwap for privacy is practically a \"cross\" chain atomic swap with the same chain and token for both sides of the swap, see also this set of ideas: https://github.com/AdamISZ/CoinSwapCS/issues/53\n>\n> \"Instead, Bob simply hands secretBob to Alice\" is basically the same as private key turnover, as best as I can understand it, and gives significant advantages, also described in passing here: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-May/017816.html\n>\n> Overall, this looks very much like a working CoinSwap as well.\n>\n> The Refund tx does not need anything more than a 2-of-2 script.\n> The \"OR Alice in +1 day\" branch can be implemented, at least on Bitcoin and similar blockchains, by signing a specific `nSequence`, or if the chain forking predates BIP68, by using absolute locktimes and signing a specific `nLockTime`, with the destination being just \"Alice\".\n> This should help privacy, as now all `scriptPubKey`s will be 2-of-2 (or P2PKH with 2p-ECDSA).\n>\n> (It strikes me that the relative locktime is unnecessary on the output of this refund tx --- as long as both participants agree on either Alice or Bob having a longer locktime, you can just use the locktime on the refund tx directly as backout; see the topic \"`nLockTime`-protected Backouts\" on the CoinSwapCS issue link)\n>\n> If you are willing to accept protocol complexity, having a variety of different versions of the transactions with different feerates could be used rather than the Decker-Russell-Osuntokun \"eltoo\" bring-your-own-fees method.\n> In terms of privacy this is better as you would not be using anything other than the most boring `SIGHASH_ALL` signing flag, whereas the Decker-Russell-Osuntokun will be identifiable onchain (and thus possibly flag the transaction as \"of interest\" to surveillors) due to use of `SIGHASH_ANYPREVOUT`.\n> As long as the one resolving a particular side of the swap is the one that ocmpletes the signature (which I believe holds true for all branches?) then it would select the version of the transaction with the best feerate, which it effectively pays out to what it recovers.\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> > Works today with single signer ECDSA adaptor signatures[0], or with\n> > Schnorr + MuSig.\n> >\n> > Diagram here:\n> > https://gist.github.com/RubenSomsen/8853a66a64825716f51b409be528355f#file-succinctatomicswap-svg\n> >\n> > Advantages:\n> >\n> > -   Requires merely two on-chain transactions for successful completion,\n> >     as opposed to four\n> >\n> > -   Scriptless, and one of the chains doesn't need to support timelocks\n> > -   Can be used for efficient privacy swaps, e.g. Payswap[1]\n> >\n> >     Disadvantages:\n> >\n> > -   Access to money is contingent on remembering secrets (backup complexity)\n> > -   Online/watchtower requirement for the timelock supporting chain (not\n> >     needed with 3 tx protocol)\n> >\n> >     Protocol steps:\n> >\n> >     0.) Alice & Bob pre-sign the following transactions, with exception of\n> >     the signatures in [brackets]:\n> >\n> > -   success_tx (money to Bob): [sigSuccessAlice] + [sigSuccessBob]\n> > -   revoke_tx (timelock): sigRevokeAlice + sigRevokeBob, which must then\n> >     be spent by:\n> >     -- refund_tx (relative timelock, refund to Alice): [sigRefundAlice]\n> >\n> >\n> > -   {sigRefundBob}\n> >     -- timeout_tx (longer relative timelock, money to Bob):\n> >     sigTimeoutAlice + [sigTimeoutBob]\n> >\n> >     {sigRefundBob} is an adaptor signature, which requires secretAlice to complete\n> >\n> >     1.) Alice proceeds to lock up 1 BTC with Bob, using keyAlice & keyBob as pubkeys\n> >\n> >     If protocol is aborted after step 1:\n> >\n> >\n> > -   Alice publishes the revoke_tx, followed by the refund_tx &\n> >     sigRefundBob, to get her BTC back\n> >\n> > -   If Alice neglects to publish the refund_tx in time, Bob will claim\n> >     the BTC with the timeout_tx\n> >\n> >     2.) Bob locks up altcoins with Alice, using secretAlice & secretBob as pubkeys\n> >\n> >     If protocol is aborted after step 2:\n> >\n> > -   Once Alice publishes sigRefundBob, Bob learns secretAlice and\n> >     regains control over the altcoins\n> >\n> >     3.) Protocol completion:\n> >\n> > -   Alice hands adaptor signature {sigSuccessAlice} to Bob, which\n> >     requires secretBob to complete\n> >\n> > -   Bob could now claim the BTC via the success_tx, reveal secretBob,\n> >     and thus give Alice control over the altcoins (= 3 tx protocol)\n> >\n> > -   Instead, Bob simply hands secretBob to Alice\n> > -   Likewise, Alice hands keyAlice to Bob to forego her claim on the refund_tx\n> > -   Bob continues to monitor the chain, because he'll have to respond if\n> >     Alice ever publishes the revoke_tx\n> >\n> >     More graceful protocol failure:\n> >\n> >     If the protocol aborts after step 1, Alice would have been forced to\n> >     make three transactions in total, while Bob has made none. We can\n> >     reduce that to two by introducing a second refund_tx with timelock\n> >     that can be published ahead of the revoke_tx and directly spends from\n> >     the funding transaction. Publishing this transaction would also reveal\n> >     secretAlice to Bob via an adaptor signature. In the 3 tx protocol,\n> >     this output can go directly to Alice. In the 2 tx protocol with\n> >     online/watchtower requirement, this output needs a script: spendable\n> >     by Alice + Bob right away OR by Alice after a relative timelock. It is\n> >     important to note that this transaction must NOT be published during\n> >     step 3. Once Bob can complete the success_tx, the revoke_tx is needed\n> >     to invalidate the success_tx prior to revealing secretAlice.\n> >\n> >     FAQ:\n> >\n> > -   Why not allow Alice to still claim the altcoins if she accidentally\n> >     lets Bob publish the timeout_tx?\n> >\n> >     Alice could send the revoke_tx at the same time, revealing both\n> >     secrets and causing likely losses. This can be solved by adding yet\n> >     another transaction, but it wouldn't be efficient and wouldn't\n> >     motivate Alice to behave.\n> >\n> > -   Is it possible to implement this protocol on chains which only\n> >     support absolute timelocks?\n> >\n> >     Yes, but then Bob must spend his swapped coins before the timelock\n> >     expires (or use the 3 tx protocol). Be aware that the revoke_tx MUST\n> >     confirm before the timeout_tx becomes valid, which may become a\n> >     problem if fees suddenly rise. The refund_tx can also not be allowed\n> >     to CPFP the timeout_tx, as they must confirm independently in order to\n> >     invalidate the success_tx first.\n> >\n> > -   Can't Alice just publish the revoke_tx after protocol completion?\n> >\n> >     Yes, she'd first have to move the altcoins (to invalidate\n> >     secretAlice), and could then try to claim the BTC by publishing the\n> >     revoke_tx, forcing Bob to react on-chain before the refund_tx becomes\n> >     valid. The eltoo[2] method of paying for fees (requires\n> >     sighash_anyprevout) or a second CPFP-able output may be an improvement\n> >     here (and also mitigates fee rising issues), but note that this also\n> >     increases the required amount of tx data if the protocol doesn't\n> >     complete successfully.\n> >\n> > -   Can this be made to work with hash locks?\n> >\n> >     Yes, by making the altcoins spendable via sigAlice + preimageBob OR\n> >     sigBob + preimageAlice, and ensuring the contracts on the BTC side\n> >     reveal either pre-image. Do note that this is not scriptless and will\n> >     thus increase the transaction size.\n> >\n> >     Open question:\n> >\n> >     Perhaps it's possible to perform an atomic swap in and out of\n> >     Lightning with only a single on-chain transaction. This would require\n> >     some kind of secondary set of HTLCs, allowing the sender to cancel a\n> >     Lightning payment by revealing a secret after a certain period of\n> >     time.\n> >\n> >     -- Ruben Somsen\n> >\n> >     Thanks to Lloyd Fournier for feedback and review.\n> >\n> >     If you find any further errors, I will endeavor to fix them here:\n> >     https://gist.github.com/RubenSomsen/8853a66a64825716f51b409be528355f\n> >\n> >     Related work:\n> >\n> >     Tier Nolan Atomic Swap:\n> >     https://bitcointalk.org/index.php?topic=193281.msg2224949#msg2224949\n> >     Monero Atomic Swap:\n> >     https://github.com/h4sh3d/xmr-btc-atomic-swap/blob/master/README.md\n> >\n> >     [0] https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-November/002316.html\n> >\n> >     [1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-January/017595.html\n> >\n> >     [2] https://blockstream.com/eltoo.pdf\n> >\n> >\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-12T04:41:43",
                "message_text_only": "Good morning Ruben,\n\n> Hi ZmnSCPxj,\n>\n> Thanks for your feedback :)\n>\n> > CoinSwap for privacy is practically a \"cross\" chain atomic swap with the same chain and token for both sides of the swap\n>\n> I agree, I didn't mean to imply that was new, only that this protocol\n> makes it more efficient.\n>\n\nIndeed; basically, any innovations in cross-chain swaps can be adapted to a CoinSwap (though not necessarily vice-versa, if a CoinSwap innovation requires certain specific blockchain features).\n\n> > \"Instead, Bob simply hands secretBob to Alice\" is basically the same as private key turnover\n>\n> Thanks for the link. I will add it to the links at the bottom of the\n> write-up, as I agree it's related. Do note there are a few key\n> differences:\n>\n> -   The swap is set up in an \"asymmetric\" way with only timelocks on one\n>     side, so on the other side the swap never expires\n>\n\nAn interesting setup.\n\nSo I was wondering why something like this would not work instead:\n\n0.  Alice has BTC, Bob has LTC, they agree on exchange rates and two future timelock L1 and L2 such that L1 < L2.\n1.  Alice creates keypairs Alice[0] Alice[1] Alice[2], Bob creates Bob[0] Bob[1] Bob[2], and share the pubkeys.\n2.  Alice creates, but does not sign, a funding tx on BTC whose output requires Alice[0] && Bob[0].\n3.  Bob creates a backout transaction spending the BTC funding txo, with an absolute timelock L1, whose output goes to Alice[2], then provides to Alice a signature for Bob[0] and requires an adaptor such that completing the signature with Alice[0] reveals Alice[1].\n\n                         nLockTime L1\n    BTC funding txo ---> Alice[0] && Bob[0]    --->  Alice[2]\n                             reveals Alice[1]\n\n4.  Alice creates a timeout transaction spending the BTC funding txo, with an absolute timelock L2, whose output goes to Bob[2], then provides to Bob a signature for Alice[0] and requires an adaptor such that completing the signature with Bob[0] reveals Bob[1].\n\n                         nLockTime L2\n    BTC funding txo ---> Alice[0] && Bob[0]    --->  Bob[2]\n                             reveals Bob[1]\n\n5.  Alice signs the BTC funding tx and broadcasts it.\n6.  Alice and Bob wait for the BTC funding tx to be confirmed.\n7.  Bob creates an LTC funding tx whose output requires Alice[1] && Bob[1].\n8.  Alice and Bob wait for the LTC funding tx to be confirmed.\n9.  Alice creates a success transaction spending the BTC funding txo, with no practical absolute timelock (current blockheight + 1), whose output goes to Bob[2], then provides to Bob a signature for Alice[0] and requires an adaptor such that completing the signature with Bob[0] reveals Bob[1].\n\n                         nLockTime now\n    BTC funding txo ---> Alice[0] && Bob[0]    --->  Bob[2]\n                             reveals Bob[1]\n\n10.  Bob gives the secret key of Bob[1] to Alice.\n11.  Alice gives the secret key of Alice[0] to Bob.\n12.  Bob claims the BTC funding txo before L1.\n\nAborts and stalls:\n\n* Aborts before step 5 are safe: no money is ever committed yet.\n  Stalls before step 5 can be promoted to aborts.\n* If aborted between step 5 and step 8, Alice reclaims her BTC via the backout transaction.\n  Since Bob did not confirm any locked funds in LTC, revealing Alice[1] does not give Bob any extra funds it did not already have.\n  If Bob stalls before step 8 Alice can abort at L1 using the backout transaction.\n* If Alice stalls at step 9, Bob can force the completion using the timeout transaction at L2, revealing Bob[1] and claiming the BTC.\n* If Alice instead aborts at step 9 using the backout transaction at L1, Bob learns Alice[1] and can reclaim its LTC.\n* Steps 10 and 11 are optional and \"only\" give Alice and Bob extra flexibility in what they can do with the funds (such as sweeping multiple swaps, RBFing, performing another swap, etc.), i.e. private key turnover.\n  Bob can always claim the BTC funding txo before L1 by signing and broadcasting the success transaction.\n\nWould this not work?\nIt requires that at least one chain involved supports witness segregation, in order to allow signing a dependent transaction before signing what it spends.\n\nThis has the advantage of using only absolute timelocks, which are better for privacy since ordinary wallets like Bitcoin Core and C-Lightning use absolute timelocks for ordinary spends onchain.\n\n\n>\n> Unfortunately this does not hold for the revoke transaction. It would\n> be a bit awkward if Alice had a high fee copy after the protocol\n> completes. She could send it to the blockchain and essentially Bob\n> would be paying for it. I'm not as concerned about the other\n> transactions, because those could all be bumped with CPFP if needed,\n> but having different feerates would be nice.\n>\n> And a general comment about privacy: it seems inevitable that some\n> information will be leaked if the protocol does not complete\n> cooperatively. As long as the cooperative case is not traceable, that\n> seems about as good as it can get. That's my view, at least. I'd be\n> curious to hear if you see that differently.\n\n\nIf the above counterproposal would work, it seems to me that all abort and stall scenarios \"just\" involve an absolute-timelock `SIGHASH_ALL` signed transaction, so it might not be so inevitable.\n\nIn addition, the above counterproposal has the transaction signatures be completed by whoever ends up getting the money, so will rationally use the version with the best feerate.\n\nWhile leaking information in case of uncooperative abort is acceptable, it still seems to me that in this case, we can have a solution where an uncooperative abort has no information leak.\nMy thesis is that, if relative locktimes are used as often as absolute locktimes for block-sniping-prevention and a decent Scriptless Script system, then all protocol aborts should be doable with no information leaks, at the cost of pre-signing a bunch of timelocked transactions.\n\n---\n\nA sidenote as well, that if Alice typically uses an HD wallet, the UTXO on the LTC side would not be in that HD, and if Alice wants to cold-store the LTC, it should move the money as well into an HD pubkey.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Chris Belcher",
                "date": "2020-05-12T22:50:10",
                "message_text_only": "Hello list,\n\nThis proposal is very cool. It is very useful to have a coinswap scheme\nrequiring only two transactions.\n\nAs well as improving the scalability of the system by saving block\nspace, it also improves privacy because the coins could stay unspend for\na long time, potentially indefinitely. While in the original coinswap\nproposal an analyst of the chain would always see a funding transaction\nfollowed closely in time by a success transaction, and this could be\nused as a fingerprint.\n\nOn 11/05/2020 18:50, Ruben Somsen via bitcoin-dev wrote:\n> Hi ZmnSCPxj,\n> \n> Thanks for your feedback :)\n>\n>> CoinSwap for privacy is practically a \"cross\" chain atomic swap with the same chain and token for both sides of the swap, see also this set of ideas: https://github.com/AdamISZ/CoinSwapCS/issues/53\n>>\n>> \"Instead, Bob simply hands secretBob to Alice\" is basically the same as private key turnover\n> \n> Thanks for the link. I will add it to the links at the bottom of the\n> write-up, as I agree it's related. Do note there are a few key\n> differences:\n> \n> - The swap is set up in an \"asymmetric\" way with only timelocks on one\n> side, so on the other side the swap *never* expires\n> - The timelocks are set up in such a way that the swap does not expire\n> unless Alice starts the relative timelock countdown (the revoke\n> transaction)\n> - This relative timelock setup comes practically for free, because the\n> asymmetry naturally requires that kind of setup\n\nYou could create an old-style coinswap scheme using relative timelocks\n(with OP_CSV). The original proposal uses absolute timelocks but there's\nno reason relative timelocks can't be used instead, as long as the party\nwho starts with knowledge of the preimage has a timelock further away in\nthe future.\n\nUsing relative timelocks and private key handover for old-style\ncoinswaps would give us the same two-transaction effect and the\ncorresponding efficiency and privacy gains.\n\nOf course we still don't get the effect that the swap on the other side\nnever expires.\n\nA fun fact is that the idea of private key handover was mentioned as\nearly as 2016 in the original Lightning Network paper. The bottom of\npage 27 says: \"Instead  of disclosing the BR1a/BR1b signatures, it\u2019s\nalso possible to just disclose the private keys to the counterparty.\nThis is more effective as described later in the key storage section\".\nAlthough it looks like nobody thought to apply it to coinswap or\nrealized the benefits.\n\n\nRegards\nCB"
            },
            {
                "author": "Lloyd Fournier",
                "date": "2020-05-12T06:10:47",
                "message_text_only": "Ruben,\n\nIn my opinion, this protocol is theoretical breakthrough as well as a\npractical protocol. Well done! I want to try and distil the core abstract\nideas here as they appear to me. From my view, the protocol is a\ncombination of two existing ideas and one new one:\n\n1. In atomic swaps you can make the refund transaction on one chain\ndependent on the refund on the other using secret revelation. Thus only one\nchain needs to have a timelock and the other refund can be conditioned on a\nsecret that is revealed when that first refund goes through. (This idea is\nin the monero atomic swap [1]).\n2. Secret revelations can be used to give unconstrained spending power to\none party. With an adaptor signature, rather than reveal a decryption key\nfor another signature, you can just make the decryption key your signing\nkey in the multisig so when you reveal it with the adaptor signautre the\nother party gains full knowledge of the private key for the output and can\nspend it arbitrarily. (this is just folklore and already what happens in\nHTLCs -- though it looks like lightning people are about to get rid of the\nunconstrained spend I think).\n\nThe combination of these two ideas is novel in itself. The problem with\nidea (2) is that your unconstrained spending power over an output doesn't\nmatter much if there is a pre-signed refund transaction spending from it --\nyou still have to spend it before the refund becomes valid. But if you\nbring in idea (1)  this problem goes away!\nHowever, you are left with a new problem: What if the party with the\ntimelock never refunds? Then the funds are locked forever.\n\nHere's where the truly novel part comes in. Ruben solves this by extending\nthe standard *TLC contract:\n1. Bob redeem with secret\n2. Alice refund after T1\n3. Bob redeem without secret after T2\n\nWe might call this a \"Forced Refund *TLC\". Alice must claim the refund or\nlose her money. This forces the refund secret revelation through\npunishment. If Alice refuses to refund Bob gets the asset he wanted anyway!\n\nThe resulting protocol you get from applying these ideas is three\ntransactions. At the end, one party has their funds in a non HD key output\nbut if they want that they can just transfer it to an HD output in which\ncase you get four transactions again. Thus I consider this to be a strict\nimprovement over the four transaction protocol. Furthermore, one of the\nchains does not need a timelock. This is remarkable as the four transaction\natomic swap is one of the most basic and most studied protocols. I\nconsidered it to be kind of \"perfect\" in a way. It just goes to show that\nthis field is still very new and there are still things to discover in what\nwe think is the most well trodden ground.\n\nI don't want to ignore that Ruben presents us with a two transaction\nprotocol. He made a nice video explaining it here:\nhttps://www.youtube.com/watch?v=TlCxpdNScCA. It is harder to see the\nelegance of the idea in the two tx protocol because it involves revocation\nand relative timelocks etc. Actually, it is straightforward to naively\nachieve a two tx atomic swap with payment channels:\n1. Alice and Bob set up payment channels to each other on different chains\n2. They atomic swap the balances of the channels off-chain using HTLCs\nusing the standard protocol.\n3. Since one party exclusively owns the funds in each channel the party\nwith no funds simply reveals their key in the funding OP_CHECKMULTISIG to\nthe other\n4. Both parties now watch the chain to see if the other tries to post a\ncommitment transactions.\n\nThe advantages that Ruben's two tx protocol has over this is that timelocks\nand monitoring is only needed on one of the chains. This is nothing to\nscoff at but for me the three tx protocol is the most elegant expression of\nthe idea and the two tx protocol is a more optimised version that might\nmake sense in some circumstances.\n\n[1] https://github.com/h4sh3d/xmr-btc-atomic-swap/blob/master/README.md\n\nLL\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200512/b0a4d1a9/attachment.html>"
            },
            {
                "author": "Lloyd Fournier",
                "date": "2020-05-12T06:50:31",
                "message_text_only": "A quick correction to my post:\n\n>\n> Here's where the truly novel part comes in. Ruben solves this by extending\n> the standard *TLC contract:\n> 1. Bob redeem with secret\n> 2. Alice refund after T1\n> 3. Bob redeem without secret after T2\n>\n> This is actually:\n\n1. Bob redeem with redeem secret\n2. Alice refund after T1 with refund secret\n3. Bob redeem without secret after T2\n\nThe fact that Alice reveals a secret when she refunds is crucial.\n\nLL\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200512/86347834/attachment.html>"
            },
            {
                "author": "Ruben Somsen",
                "date": "2020-05-12T11:30:38",
                "message_text_only": "Hi ZmnSCPxj,\n\n>Would this not work?\n\nI considered and rejected that model for the following reason: there are\nmoments where both Alice and Bob can claim the BTC. If they both attempt to\ndo so, it also reveals both secrets, causing the LTC to also be claimable\nby both parties. This chaotic scenario is a failure mode that did not seem\nacceptable to me. The revoke transaction was specifically added to mitigate\nthat issue (invalidating any attempt of Bob to claim the coins and reveal\nhis secret). That said, it doesn't particularly seem in either party's\ninterest wait until a moment where two timelocks become valid, so maybe it\nis not quite as bad as I thought. However, it still means that the\nincompetence/malevolence of one party can lead to losses for both parties.\nI have my doubts a gain in privacy in the uncooperative case is worth that\nrisk.\n\nOf course it also reverts the protocol to 3 transactions, instead of 2, but\nregardless, not having to watch the chain is probably more practical in\nmany cases. As an aside, if both chains support timelocks then we can\nensure that the more expensive chain only receives one transaction.\n\n>if relative locktimes are used as often as absolute locktimes for\nblock-sniping-prevention and a decent Scriptless Script system, then all\nprotocol aborts should be doable with no information leaks\n\nI see your point, interesting observation.\n\n>A sidenote as well, that if Alice typically uses an HD wallet, the UTXO on\nthe LTC side would not be in that HD, and if Alice wants to cold-store the\nLTC, it should move the money as well into an HD pubkey.\n\nAgreed, I had that listed as one of the disadvantages: \"Access to money is\ncontingent on remembering secrets (backup complexity)\"\n\nCheers,\nRuben\n\n\nOn Tue, May 12, 2020 at 8:50 AM Lloyd Fournier <lloyd.fourn at gmail.com>\nwrote:\n\n> A quick correction to my post:\n>\n>>\n>> Here's where the truly novel part comes in. Ruben solves this by\n>> extending the standard *TLC contract:\n>> 1. Bob redeem with secret\n>> 2. Alice refund after T1\n>> 3. Bob redeem without secret after T2\n>>\n>> This is actually:\n>\n> 1. Bob redeem with redeem secret\n> 2. Alice refund after T1 with refund secret\n> 3. Bob redeem without secret after T2\n>\n> The fact that Alice reveals a secret when she refunds is crucial.\n>\n> LL\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200512/235cbe50/attachment.html>"
            },
            {
                "author": "Ruben Somsen",
                "date": "2020-05-12T11:34:17",
                "message_text_only": "Hi Lloyd,\n\n>In my opinion, this protocol is theoretical breakthrough as well as a\npractical protocol. Well done!\n\nThanks for the kind praise, and for providing a summary of what you think\nmakes the protocol useful. Your different perspective is undoubtedly useful\nfor others who are trying to understand it.\n\n>We might call this a \"Forced Refund *TLC\"\n\nGood description, I like it.\n\n>The advantages that Ruben's two tx protocol has over this is that\ntimelocks and monitoring is only needed on one of the chains.\n\nWell put, and I agree with your point that the traditional 4 tx protocol\ncan also be turned into 2 tx with an online requirement. One minor thing to\nadd is that this would make the 4 tx protocol more clunky in the\nnon-cooperative case (a 4 tx timeout). In the SAS protocol it comes at no\ncost.\n\nCheers,\nRuben\n\nOn Tue, May 12, 2020 at 1:30 PM Ruben Somsen <rsomsen at gmail.com> wrote:\n\n> Hi ZmnSCPxj,\n>\n> >Would this not work?\n>\n> I considered and rejected that model for the following reason: there are\n> moments where both Alice and Bob can claim the BTC. If they both attempt to\n> do so, it also reveals both secrets, causing the LTC to also be claimable\n> by both parties. This chaotic scenario is a failure mode that did not seem\n> acceptable to me. The revoke transaction was specifically added to mitigate\n> that issue (invalidating any attempt of Bob to claim the coins and reveal\n> his secret). That said, it doesn't particularly seem in either party's\n> interest wait until a moment where two timelocks become valid, so maybe it\n> is not quite as bad as I thought. However, it still means that the\n> incompetence/malevolence of one party can lead to losses for both parties.\n> I have my doubts a gain in privacy in the uncooperative case is worth that\n> risk.\n>\n> Of course it also reverts the protocol to 3 transactions, instead of 2,\n> but regardless, not having to watch the chain is probably more practical in\n> many cases. As an aside, if both chains support timelocks then we can\n> ensure that the more expensive chain only receives one transaction.\n>\n> >if relative locktimes are used as often as absolute locktimes for\n> block-sniping-prevention and a decent Scriptless Script system, then all\n> protocol aborts should be doable with no information leaks\n>\n> I see your point, interesting observation.\n>\n> >A sidenote as well, that if Alice typically uses an HD wallet, the UTXO\n> on the LTC side would not be in that HD, and if Alice wants to cold-store\n> the LTC, it should move the money as well into an HD pubkey.\n>\n> Agreed, I had that listed as one of the disadvantages: \"Access to money is\n> contingent on remembering secrets (backup complexity)\"\n>\n> Cheers,\n> Ruben\n>\n>\n> On Tue, May 12, 2020 at 8:50 AM Lloyd Fournier <lloyd.fourn at gmail.com>\n> wrote:\n>\n>> A quick correction to my post:\n>>\n>>>\n>>> Here's where the truly novel part comes in. Ruben solves this by\n>>> extending the standard *TLC contract:\n>>> 1. Bob redeem with secret\n>>> 2. Alice refund after T1\n>>> 3. Bob redeem without secret after T2\n>>>\n>>> This is actually:\n>>\n>> 1. Bob redeem with redeem secret\n>> 2. Alice refund after T1 with refund secret\n>> 3. Bob redeem without secret after T2\n>>\n>> The fact that Alice reveals a secret when she refunds is crucial.\n>>\n>> LL\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200512/7f7a23d1/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-12T15:05:57",
                "message_text_only": "Good morning Ruben,\n\n> >Would this not work?\n>\n> I considered and rejected that model for the following reason: there are moments where both Alice and Bob can claim the BTC. If they both attempt to do so, it also reveals both secrets, causing the LTC to also be claimable by both parties. This chaotic scenario is a failure mode that did not seem acceptable to me. The revoke transaction was specifically added to mitigate that issue (invalidating any attempt of Bob to claim the coins and reveal his secret). That said, it doesn't particularly seem in either party's interest wait until a moment where two timelocks become valid, so maybe it is not quite as bad as I thought. However, it still means that the incompetence/malevolence of one party can lead to losses for both parties. I have my doubts a gain in privacy in the uncooperative case is worth that risk.\n>\n> Of course it also reverts the protocol to 3 transactions, instead of 2, but regardless, not having to watch the chain is probably more practical in many cases. As an aside, if both chains support timelocks then we can ensure that the more expensive chain only receives one transaction.\n\nIf the shortened refund transaction exists (labeled \"refund transaction #1\" in the SVG) then the same issue still occurs: after 1 day it is possible for either success or refund#1 to be broadcasted, leading to revelation of both secrets, leading to the same failure mode you described.\n\nWithout the refund#1 in your proposal, Bob refusing cooperation after Alice puts the BTC into lock for 3 days and 2 further onchain transactions (with the refund#2 transaction being relative-locked, meaning it cannot be used to CPFP the revoke transaction; my formulation allows any of the result transactions to be CPFP directly by their beneficiaries).\n\nIt seems to me that there is still an onlineness requirement in case Bob does not complete the protocol: once the revoke tx becomes valid an online Bob can cheat an offline Alice by broadcasting the revoke tx (which, if my understanding of the protocol is correct, the signatures are shared to both Alice and Bob).\nSo Alice needs to be online starting at 2 days to 3 days in order to ensure it reclaims it funds.\n\nI have not seen the 2-tx variant video yet, as I prefer to read than listen, but I will also check it if I can find an opportunity.\n\nRegardless, the overall protocol of using 3 clauses in the swap, and reusing the privkey as the payment secret demanded by the pointlocks, is still a significant innovation.\n\n\n\nIn the context of CoinSwap, a proposal is that a CoinSwap server would provide swapping service to incoming clients.\nUsing my counterproposal, the Bob position can be taken by the server and the Alice position taken by the client.\nIn this context, the L1 can be made reasonably close in the future and L2 far in the future, in which case Alice the client can be \"weakly offline\" most of the time until L2, and even in a protocol abort would be able to recover its funds.\nIf the protocol completes, the server Bob can claim its funds before L1, and (with knowledge of Alice[0]) can immediately put it in a new funding tx for a new incoming client before L1, which is a fine tradeoff for server Bob since presumably Bob is always online.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Ruben Somsen",
                "date": "2020-05-12T16:30:26",
                "message_text_only": "Hi ZmnSCPxj,\n\n>If the shortened refund transaction exists (labeled \"refund transaction\n#1\" in the SVG) then the same issue still occurs\n\nYes, but there is one crucial difference: at that point in the protocol\n(Bob has the success transaction and then stops cooperating) Alice and Bob\nboth had the opportunity not to take that path. Bob could have sent the\nsuccess transaction, and Alice could have waited and sent the revoke\ntransaction. They would essentially be \"colluding\" to fail.\n\n>Without the refund#1 in your proposal, Bob refusing cooperation after\nAlice puts the BTC into lock for 3 days and 2 further onchain transactions\n\nI'm not sure if I correctly understood what you're saying, but it's as\nfollows:\n\nRefund #1 can only safely be used before the signed success tx is given to\nBob. The cost to Alice at this point if Bob aborts is two on-chain\ntransactions while Bob hasn't put anything on-chain yet.\n\nRefund #2 needs to be used after Bob receives the signed success tx. The\ncost to Alice is now three transactions, but Bob also went-on-chain by this\npoint, so causing this wasn't costless to Bob and is thus a similar failure\nmode.\n\n>my formulation allows any of the result transactions to be CPFP directly\nby their beneficiaries\n\nYes, that is indeed very nice. The way I set it up, insufficient fees can\nunfortunately cause delays, but they should not be able to cause losses.\n\n>there is still an onlineness requirement in case Bob does not complete the\nprotocol\n\nYes, that is very much the design. Alice needs to be on time with claiming\nher refund (and revealing her secret), otherwise Bob takes it.\n\n>I have not seen the 2-tx variant video yet, as I prefer to read than listen\n\nThe video is not required, it just restates what is in the write-up. I\npersonally find it easier to understand concepts from video, but I seem to\nbe in the minority when I ask other devs about this. But let me reiterate\none part you might be confused about (though you probably mostly get it\nalready):\n\nThe online requirement I was alluding to doesn't expire, and is\nspecifically how the 2 tx SAS protocol is performed. Bob never broadcasts\nthe success transaction (unless he prefers not to have to be online, i.e.\nthe 3 tx SAS protocol) and instead Alice and Bob swap their keys: first Bob\nhands over secretAlice, then Alice hands over her key. Now the swap is\ncomplete, but Bob has to remain online to make sure Alice never attempts to\nbroadcast her refund tx. It doesn't expire either because of the relative\ntimelocks.\n\nJust take a look at the slide 6m8s into the video:\nhttps://youtu.be/TlCxpdNScCA?t=6m8s\n\nI also agree with your observation that alternatively Bob can just spend\nbefore the timelock expires.\n\n>Regardless, the overall protocol of using 3 clauses in the swap, and\nreusing the privkey as the payment secret demanded by the pointlocks, is\nstill a significant innovation.\n\nI'm glad you like it :)\n\n>In the context of CoinSwap, a proposal is that a CoinSwap server would\nprovide swapping service to incoming clients.\n\nThat is an excellent use case that takes good advantage of the asymmetry of\nSAS. I completely agree with your observation that the \"Bob\" side is\nperfect for servers (online and/or spending again soon) and the \"Alice\"\nside is perfect for clients (settled in 1 tx). I similarly hope that this\nmay pave the way for a practical implementation of Payswap between\nmerchants and customers!\n\nCheers,\nRuben\n\nOn Tue, May 12, 2020 at 5:06 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Ruben,\n>\n> > >Would this not work?\n> >\n> > I considered and rejected that model for the following reason: there are\n> moments where both Alice and Bob can claim the BTC. If they both attempt to\n> do so, it also reveals both secrets, causing the LTC to also be claimable\n> by both parties. This chaotic scenario is a failure mode that did not seem\n> acceptable to me. The revoke transaction was specifically added to mitigate\n> that issue (invalidating any attempt of Bob to claim the coins and reveal\n> his secret). That said, it doesn't particularly seem in either party's\n> interest wait until a moment where two timelocks become valid, so maybe it\n> is not quite as bad as I thought. However, it still means that the\n> incompetence/malevolence of one party can lead to losses for both parties.\n> I have my doubts a gain in privacy in the uncooperative case is worth that\n> risk.\n> >\n> > Of course it also reverts the protocol to 3 transactions, instead of 2,\n> but regardless, not having to watch the chain is probably more practical in\n> many cases. As an aside, if both chains support timelocks then we can\n> ensure that the more expensive chain only receives one transaction.\n>\n> If the shortened refund transaction exists (labeled \"refund transaction\n> #1\" in the SVG) then the same issue still occurs: after 1 day it is\n> possible for either success or refund#1 to be broadcasted, leading to\n> revelation of both secrets, leading to the same failure mode you described.\n>\n> Without the refund#1 in your proposal, Bob refusing cooperation after\n> Alice puts the BTC into lock for 3 days and 2 further onchain transactions\n> (with the refund#2 transaction being relative-locked, meaning it cannot be\n> used to CPFP the revoke transaction; my formulation allows any of the\n> result transactions to be CPFP directly by their beneficiaries).\n>\n> It seems to me that there is still an onlineness requirement in case Bob\n> does not complete the protocol: once the revoke tx becomes valid an online\n> Bob can cheat an offline Alice by broadcasting the revoke tx (which, if my\n> understanding of the protocol is correct, the signatures are shared to both\n> Alice and Bob).\n> So Alice needs to be online starting at 2 days to 3 days in order to\n> ensure it reclaims it funds.\n>\n> I have not seen the 2-tx variant video yet, as I prefer to read than\n> listen, but I will also check it if I can find an opportunity.\n>\n> Regardless, the overall protocol of using 3 clauses in the swap, and\n> reusing the privkey as the payment secret demanded by the pointlocks, is\n> still a significant innovation.\n>\n>\n>\n> In the context of CoinSwap, a proposal is that a CoinSwap server would\n> provide swapping service to incoming clients.\n> Using my counterproposal, the Bob position can be taken by the server and\n> the Alice position taken by the client.\n> In this context, the L1 can be made reasonably close in the future and L2\n> far in the future, in which case Alice the client can be \"weakly offline\"\n> most of the time until L2, and even in a protocol abort would be able to\n> recover its funds.\n> If the protocol completes, the server Bob can claim its funds before L1,\n> and (with knowledge of Alice[0]) can immediately put it in a new funding tx\n> for a new incoming client before L1, which is a fine tradeoff for server\n> Bob since presumably Bob is always online.\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200512/1f2d4869/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-13T08:39:37",
                "message_text_only": "Good morning Ruben,\n\n> >If the shortened refund transaction exists (labeled \"refund transaction #1\" in the SVG) then the same issue still occurs\u00a0\n>\n> Yes, but there is one crucial difference: at that point in the protocol (Bob has the success transaction and then stops cooperating) Alice and Bob both had the opportunity not to take that path. Bob could have sent the success transaction, and Alice could have waited and sent the revoke transaction. They would essentially be \"colluding\" to fail.\n\nOkay, so the concern is basically, that Bob misses the deadline, then Alice feels obligated to reclaim the funds.\nIn your proposal, the tx competition is between the secret-revealing success TX and the non-secret-revealing revoke tx.\nWhereas in my counterproposal, under the same conditions, the tx competition is between the secret-revealing success tx and the secret-revealing backout tx, and both transactions becoming visible on P2P network means potentially both Alice and Bob know all the secrets on the LTC side and end up competing over it, RBFing each other until the entire fund goes to miners.\n\n\n> >Without the refund#1 in your proposal, Bob refusing cooperation after Alice puts the BTC into lock for 3 days and 2 further onchain transactions\n>\n> I'm not sure if I correctly understood what you're saying, but it's as follows:\n>\n> Refund #1 can only safely be used before the signed success tx is given to Bob. The cost to Alice at this point if Bob aborts is two on-chain transactions while Bob hasn't put anything on-chain yet.\n>\n> Refund #2 needs to be used after Bob receives the signed success tx. The cost to Alice is now three transactions, but Bob also went-on-chain by this point, so causing this wasn't costless to Bob and is thus a similar failure mode.\n\nI think it is not accurate that Bob is already on-chain before Alice can be forced to use 3 transactions to fail.\n\nThe revoke tx signatures are shared at step 0 of your protocol description.\nThus Bob has a copy of the revoke tx that is valid once Alice signs and confirms the funding transaction.\nBob can thus give a copy of the revoke tx with signature directly to its favorite miner, forcing Alice to take 3 transactions to back out of the swap.\n\nSince Bob gave the tx directly to its favorite miner (TANSTAAGM: \"There ain't no such thing as a global mempool\"), Alice will only know about this event when the revoke tx is confirmed once, at which point it is very difficult to reverse, even if Alice has a refund#1 tx prepared.\n\nBob can do this before step 2 in your protocol description, meaning before Bob locks up any funds, so Bob can do this for free, and will even use funds going back to Alice to pay for confirmation of the revoke tx.\nBecause Bob can do this for free, there is no disincentive for trolling Bobs to exist whose sole life goal is to just grief possible Alices.\n\nThis can be slightly mitigated by adding two CPFP outputs (one for each participant) and using the minimum relayable feerate for the revoke tx so that Bob is forced to bring its own fees in order to incentivize miners.\nThis is similar to the \"bring your own fees\" currently proposed for Lightning, but note the recent hand-wringing about the various problems this adds to mempools and CPFP and RBF rules and etc etc: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-April/017757.html\n\nWe could use `SIGHASH_SINGLE | SIGHASH_ANYONECANPAY` as well for a bring-your-own-fees, but that is not `SIGHASH_ALL` and thus marks the transaction graph as special.\nAnd forcing bring-your-own-fees means neither Alice nor Bob can swap all their funds in a single operation, they have to keep a reserve.\n\n\nBob cannot safely perform step 2 before getting both signatures for the revoke tx, as without Bob having access to the rveoke tx, if Bob locks up LTC, Alice can stop responding and lock both their funds indefinitely with Bob not having any way to recover its funds, which a rich Alice can use to completely lock out an impoverished Bob.\nBut if Bob is given both signatures for the revoke tx before step 2, then Bob can send the revoke tx to its favorite miner, forcing Alice to take 3 transactions to back out, before Bob locks any funds in LTC side.\n\n>\n> I also agree with your observation that alternatively Bob can just spend before the timelock expires.\n\nThis seems to be the safest alternative; in my context, where Bob is a CoinSwap server/maker, Bob can wait a short while for new clients/takers, and if no new clients arrive, spend.\nBob can run multiple servers, each of which are given the completed success transaction, and the servers can check that if the timeout is near, to spam the Bitcoin P2P network with the completed success transactions.\n(these servers need not even run fullnodes, they could just periodically poll a number of blockchain explorers and electrum servers, and when the blockheight approaches, attempt broadcast; if the \"main\" server that accepts clients/takers has already spent the TXO the broadcast of the completed success tx is simply rejected by the Bitcoin P2P network; if the timeout is based on sidereal time then the backup servers only need to be running NTP)\n\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Ruben Somsen",
                "date": "2020-05-13T09:57:05",
                "message_text_only": "Hi Chris,\n\nThanks for taking a look :)\n\n>it also improves privacy because the coins could stay unspend for a long\ntime, potentially indefinitely\n\nExcellent point. The pre-swap setup transactions would still be subject to\ntiming/amount analysis, but it's clearly a lot less problematic than the\ntraditional 4 tx swap. And Payswap may be able to mitigate the amount\nanalysis.\n\n>Using relative timelocks and private key handover for old-style coinswaps\nwould give us the same two-transaction effect\n\nI agree, Lloyd pointed out the same thing. One thing to add is that such a\nsetup would result in four on-chain transactions if the protocol is\naborted, due to the need to invalidate the refund transaction.\n\n>the idea of private key handover was mentioned as early as 2016 in the\noriginal Lightning Network paper\n\nInteresting! Thanks for pointing that out.\n\nCheers,\nRuben\n\nOn Wed, May 13, 2020 at 10:39 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Ruben,\n>\n> > >If the shortened refund transaction exists (labeled \"refund transaction\n> #1\" in the SVG) then the same issue still occurs\n> >\n> > Yes, but there is one crucial difference: at that point in the protocol\n> (Bob has the success transaction and then stops cooperating) Alice and Bob\n> both had the opportunity not to take that path. Bob could have sent the\n> success transaction, and Alice could have waited and sent the revoke\n> transaction. They would essentially be \"colluding\" to fail.\n>\n> Okay, so the concern is basically, that Bob misses the deadline, then\n> Alice feels obligated to reclaim the funds.\n> In your proposal, the tx competition is between the secret-revealing\n> success TX and the non-secret-revealing revoke tx.\n> Whereas in my counterproposal, under the same conditions, the tx\n> competition is between the secret-revealing success tx and the\n> secret-revealing backout tx, and both transactions becoming visible on P2P\n> network means potentially both Alice and Bob know all the secrets on the\n> LTC side and end up competing over it, RBFing each other until the entire\n> fund goes to miners.\n>\n>\n> > >Without the refund#1 in your proposal, Bob refusing cooperation after\n> Alice puts the BTC into lock for 3 days and 2 further onchain transactions\n> >\n> > I'm not sure if I correctly understood what you're saying, but it's as\n> follows:\n> >\n> > Refund #1 can only safely be used before the signed success tx is given\n> to Bob. The cost to Alice at this point if Bob aborts is two on-chain\n> transactions while Bob hasn't put anything on-chain yet.\n> >\n> > Refund #2 needs to be used after Bob receives the signed success tx. The\n> cost to Alice is now three transactions, but Bob also went-on-chain by this\n> point, so causing this wasn't costless to Bob and is thus a similar failure\n> mode.\n>\n> I think it is not accurate that Bob is already on-chain before Alice can\n> be forced to use 3 transactions to fail.\n>\n> The revoke tx signatures are shared at step 0 of your protocol description.\n> Thus Bob has a copy of the revoke tx that is valid once Alice signs and\n> confirms the funding transaction.\n> Bob can thus give a copy of the revoke tx with signature directly to its\n> favorite miner, forcing Alice to take 3 transactions to back out of the\n> swap.\n>\n> Since Bob gave the tx directly to its favorite miner (TANSTAAGM: \"There\n> ain't no such thing as a global mempool\"), Alice will only know about this\n> event when the revoke tx is confirmed once, at which point it is very\n> difficult to reverse, even if Alice has a refund#1 tx prepared.\n>\n> Bob can do this before step 2 in your protocol description, meaning before\n> Bob locks up any funds, so Bob can do this for free, and will even use\n> funds going back to Alice to pay for confirmation of the revoke tx.\n> Because Bob can do this for free, there is no disincentive for trolling\n> Bobs to exist whose sole life goal is to just grief possible Alices.\n>\n> This can be slightly mitigated by adding two CPFP outputs (one for each\n> participant) and using the minimum relayable feerate for the revoke tx so\n> that Bob is forced to bring its own fees in order to incentivize miners.\n> This is similar to the \"bring your own fees\" currently proposed for\n> Lightning, but note the recent hand-wringing about the various problems\n> this adds to mempools and CPFP and RBF rules and etc etc:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-April/017757.html\n>\n> We could use `SIGHASH_SINGLE | SIGHASH_ANYONECANPAY` as well for a\n> bring-your-own-fees, but that is not `SIGHASH_ALL` and thus marks the\n> transaction graph as special.\n> And forcing bring-your-own-fees means neither Alice nor Bob can swap all\n> their funds in a single operation, they have to keep a reserve.\n>\n>\n> Bob cannot safely perform step 2 before getting both signatures for the\n> revoke tx, as without Bob having access to the rveoke tx, if Bob locks up\n> LTC, Alice can stop responding and lock both their funds indefinitely with\n> Bob not having any way to recover its funds, which a rich Alice can use to\n> completely lock out an impoverished Bob.\n> But if Bob is given both signatures for the revoke tx before step 2, then\n> Bob can send the revoke tx to its favorite miner, forcing Alice to take 3\n> transactions to back out, before Bob locks any funds in LTC side.\n>\n> >\n> > I also agree with your observation that alternatively Bob can just spend\n> before the timelock expires.\n>\n> This seems to be the safest alternative; in my context, where Bob is a\n> CoinSwap server/maker, Bob can wait a short while for new clients/takers,\n> and if no new clients arrive, spend.\n> Bob can run multiple servers, each of which are given the completed\n> success transaction, and the servers can check that if the timeout is near,\n> to spam the Bitcoin P2P network with the completed success transactions.\n> (these servers need not even run fullnodes, they could just periodically\n> poll a number of blockchain explorers and electrum servers, and when the\n> blockheight approaches, attempt broadcast; if the \"main\" server that\n> accepts clients/takers has already spent the TXO the broadcast of the\n> completed success tx is simply rejected by the Bitcoin P2P network; if the\n> timeout is based on sidereal time then the backup servers only need to be\n> running NTP)\n>\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200513/537d6559/attachment-0001.html>"
            },
            {
                "author": "Ruben Somsen",
                "date": "2020-05-13T09:58:26",
                "message_text_only": "Hi ZmnSCPxj,\n\n>potentially both Alice and Bob know all the secrets on the LTC side and\nend up competing over it\n\nThat's exactly right.\n\n>Bob can thus give a copy of the revoke tx with signature directly to its\nfavorite miner, forcing Alice to take 3 transactions\n\nNote that the timelock on the revoke tx is longer than the timelock on\nrefund tx #1. The idea is that Alice aborts the protocol by publishing\nrefund tx #1 if the protocol hasn't reached step 4 in the svg by the time\nit becomes valid. This should entirely mitigate the issue you're describing.\n\n>adding two CPFP outputs (one for each participant)\n\nThere seems to be a situation where RBF can be disabled by the other party,\nbut I'm not sure I see it... Why would a single output spendable by either\nkey be insufficient?\n\n>We could use `SIGHASH_SINGLE | SIGHASH_ANYONECANPAY` as well\n\nAllowing others to add inputs/outputs would introduce malleability. Refund\ntx #2 and the timeout tx would become invalid.\n\n>Bob cannot safely perform step 2 before getting both signatures for the\nrevoke tx\n\nThat's right, as you guessed, he does receive a copy of the signed revoke\ntx at protocol start.\n\n>>alternatively Bob can just spend before the timelock expires.\n>This seems to be the safest alternative\n\nI agree not giving Alice time to publish the revoke tx is safest, but one\ndoes not preclude the other. The revoke tx is on an absolute timelock, so\nspending it before that time means you don't have anything to worry about,\nand spending it later means you'll have to be online and keep an eye out.\nIf staying online is not a problem, then fee wise that seems preferable. As\nlong as less than half of all valid (i.e. the timelock was reached) revoke\ntransactions get broadcast, you'll be saving on fees.\n\nCheers,\nRuben\n\nOn Wed, May 13, 2020 at 11:57 AM Ruben Somsen <rsomsen at gmail.com> wrote:\n\n> Hi Chris,\n>\n> Thanks for taking a look :)\n>\n> >it also improves privacy because the coins could stay unspend for a long\n> time, potentially indefinitely\n>\n> Excellent point. The pre-swap setup transactions would still be subject to\n> timing/amount analysis, but it's clearly a lot less problematic than the\n> traditional 4 tx swap. And Payswap may be able to mitigate the amount\n> analysis.\n>\n> >Using relative timelocks and private key handover for old-style coinswaps\n> would give us the same two-transaction effect\n>\n> I agree, Lloyd pointed out the same thing. One thing to add is that such a\n> setup would result in four on-chain transactions if the protocol is\n> aborted, due to the need to invalidate the refund transaction.\n>\n> >the idea of private key handover was mentioned as early as 2016 in the\n> original Lightning Network paper\n>\n> Interesting! Thanks for pointing that out.\n>\n> Cheers,\n> Ruben\n>\n> On Wed, May 13, 2020 at 10:39 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n>> Good morning Ruben,\n>>\n>> > >If the shortened refund transaction exists (labeled \"refund\n>> transaction #1\" in the SVG) then the same issue still occurs\n>> >\n>> > Yes, but there is one crucial difference: at that point in the protocol\n>> (Bob has the success transaction and then stops cooperating) Alice and Bob\n>> both had the opportunity not to take that path. Bob could have sent the\n>> success transaction, and Alice could have waited and sent the revoke\n>> transaction. They would essentially be \"colluding\" to fail.\n>>\n>> Okay, so the concern is basically, that Bob misses the deadline, then\n>> Alice feels obligated to reclaim the funds.\n>> In your proposal, the tx competition is between the secret-revealing\n>> success TX and the non-secret-revealing revoke tx.\n>> Whereas in my counterproposal, under the same conditions, the tx\n>> competition is between the secret-revealing success tx and the\n>> secret-revealing backout tx, and both transactions becoming visible on P2P\n>> network means potentially both Alice and Bob know all the secrets on the\n>> LTC side and end up competing over it, RBFing each other until the entire\n>> fund goes to miners.\n>>\n>>\n>> > >Without the refund#1 in your proposal, Bob refusing cooperation after\n>> Alice puts the BTC into lock for 3 days and 2 further onchain transactions\n>> >\n>> > I'm not sure if I correctly understood what you're saying, but it's as\n>> follows:\n>> >\n>> > Refund #1 can only safely be used before the signed success tx is given\n>> to Bob. The cost to Alice at this point if Bob aborts is two on-chain\n>> transactions while Bob hasn't put anything on-chain yet.\n>> >\n>> > Refund #2 needs to be used after Bob receives the signed success tx.\n>> The cost to Alice is now three transactions, but Bob also went-on-chain by\n>> this point, so causing this wasn't costless to Bob and is thus a similar\n>> failure mode.\n>>\n>> I think it is not accurate that Bob is already on-chain before Alice can\n>> be forced to use 3 transactions to fail.\n>>\n>> The revoke tx signatures are shared at step 0 of your protocol\n>> description.\n>> Thus Bob has a copy of the revoke tx that is valid once Alice signs and\n>> confirms the funding transaction.\n>> Bob can thus give a copy of the revoke tx with signature directly to its\n>> favorite miner, forcing Alice to take 3 transactions to back out of the\n>> swap.\n>>\n>> Since Bob gave the tx directly to its favorite miner (TANSTAAGM: \"There\n>> ain't no such thing as a global mempool\"), Alice will only know about this\n>> event when the revoke tx is confirmed once, at which point it is very\n>> difficult to reverse, even if Alice has a refund#1 tx prepared.\n>>\n>> Bob can do this before step 2 in your protocol description, meaning\n>> before Bob locks up any funds, so Bob can do this for free, and will even\n>> use funds going back to Alice to pay for confirmation of the revoke tx.\n>> Because Bob can do this for free, there is no disincentive for trolling\n>> Bobs to exist whose sole life goal is to just grief possible Alices.\n>>\n>> This can be slightly mitigated by adding two CPFP outputs (one for each\n>> participant) and using the minimum relayable feerate for the revoke tx so\n>> that Bob is forced to bring its own fees in order to incentivize miners.\n>> This is similar to the \"bring your own fees\" currently proposed for\n>> Lightning, but note the recent hand-wringing about the various problems\n>> this adds to mempools and CPFP and RBF rules and etc etc:\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-April/017757.html\n>>\n>> We could use `SIGHASH_SINGLE | SIGHASH_ANYONECANPAY` as well for a\n>> bring-your-own-fees, but that is not `SIGHASH_ALL` and thus marks the\n>> transaction graph as special.\n>> And forcing bring-your-own-fees means neither Alice nor Bob can swap all\n>> their funds in a single operation, they have to keep a reserve.\n>>\n>>\n>> Bob cannot safely perform step 2 before getting both signatures for the\n>> revoke tx, as without Bob having access to the rveoke tx, if Bob locks up\n>> LTC, Alice can stop responding and lock both their funds indefinitely with\n>> Bob not having any way to recover its funds, which a rich Alice can use to\n>> completely lock out an impoverished Bob.\n>> But if Bob is given both signatures for the revoke tx before step 2, then\n>> Bob can send the revoke tx to its favorite miner, forcing Alice to take 3\n>> transactions to back out, before Bob locks any funds in LTC side.\n>>\n>> >\n>> > I also agree with your observation that alternatively Bob can just\n>> spend before the timelock expires.\n>>\n>> This seems to be the safest alternative; in my context, where Bob is a\n>> CoinSwap server/maker, Bob can wait a short while for new clients/takers,\n>> and if no new clients arrive, spend.\n>> Bob can run multiple servers, each of which are given the completed\n>> success transaction, and the servers can check that if the timeout is near,\n>> to spam the Bitcoin P2P network with the completed success transactions.\n>> (these servers need not even run fullnodes, they could just periodically\n>> poll a number of blockchain explorers and electrum servers, and when the\n>> blockheight approaches, attempt broadcast; if the \"main\" server that\n>> accepts clients/takers has already spent the TXO the broadcast of the\n>> completed success tx is simply rejected by the Bitcoin P2P network; if the\n>> timeout is based on sidereal time then the backup servers only need to be\n>> running NTP)\n>>\n>>\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200513/d7e238fb/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-13T11:39:10",
                "message_text_only": "Good morning Ruben,\n\n> Hi ZmnSCPxj,\n>\n> >potentially both Alice and Bob know all the secrets on the LTC side and end up competing over it\n>\n> That's exactly right.\n>\n> >Bob can thus give a copy of the revoke tx with signature directly to its favorite miner, forcing Alice to take 3 transactions\n>\n> Note that the timelock on the revoke tx is longer than the timelock on refund tx #1. The idea is that Alice aborts the protocol by publishing refund tx #1 if the protocol hasn't reached step 4 in the svg by the time it becomes valid. This should entirely mitigate the issue you're describing.\n\nBut if refund tx #1 at all exists, then you drop to the same issue you objected to with my proposal, which is that, on completion of the protocol, if Bob lets the refund tx#1 become valid (i.e. does not spend the BTC txo) then Alice can broadcast it, putting both their funds into chaos.\n\nSo you might as well just use my counterproposal instead, which is simpler, gets bring-your-own-fees for free, etc.\n\nI suppose there is some *slight* improvement in that with your proposal, Alice *can* use revoke tx -> refund tx #2, but still, if Alice is insane then it could very well mess with the protocol by instead using refund tx #1.\nThus, if Bob wants to survive in an environment where Alices are possibly insane (e.g. the real world), it should do everything in its power to ensure that the BTC txo is spent before the timeout of refund tx #1, if refund tx #1 exists at all.\nAnd if Bob is already going to do that, then Alice and Bob might as well just use my counterproposal etc etc.\n\n> >adding two CPFP outputs (one for each participant)\n>\n> There seems to be a situation where RBF can be disabled by the other party, but I'm not sure I see it... Why would a single output spendable by either key be insufficient?\n\nIf one party quickly broadcasts a long chain of low-feerate transactions on top of the single output, then the output is \"pinned\".\n\nLow feerate means it is undesirable for miners to mine it, because it pays low for the amount of blockspace it has.\nBut because there is a long chain of transactions, the absolute fee of that chain can be sizable, and we have a rule in RBF which, paraphrased, goes something like \"the replacing transaction should also have a higher absolute fee than *all* the transactions it replaces\", meaning the fee jump that the other side has to offer *has to be* pretty big.\n\nIf the other outputs of the tx are then multisig, then the pinning participant can simply refuse to sign for those, and if the existing txes spending the other outputs are relative-time-locked, they cannot be used to CPFP the revoke tx onchain.\n\nThis is why we eventually decided in Lightning to use two CPFP outpoints rather than one, and are also realizing just how much of a headache the RBF rules are, sigh.\n\nStill, in your proposed protocol the dependent transactions are all relative-timelocked, so timely confirmation of the revoke tx is not necessary, unlike in the case of Lightning where all HTLCs have to use an absolute timelock because we have to coordinate multiple HTLCs in forwarding and violation of the timelocks can lead to headaches and fund loss and so on.\nSo maybe a single hook output, or even none at all, is workable.\n\n>\n> >We could use `SIGHASH_SINGLE | SIGHASH_ANYONECANPAY` as well\n>\n> Allowing others to add inputs/outputs would introduce malleability. Refund tx #2 and the timeout tx would become invalid.\n\nAh, right, you still need `SIGHASH_ANYPREVOUT`/`SIGHASH_NOINPUT` for that.\n\n> >Bob cannot safely perform step 2 before getting both signatures for the revoke tx\n>\n> That's right, as you guessed, he does receive a copy of the signed revoke tx at protocol start.\n>\n> >>alternatively Bob can just spend before the timelock expires.\n> >This seems to be the safest alternative\n>\n> I agree not giving Alice time to publish the revoke tx is safest, but one does not preclude the other. The revoke tx is on an absolute timelock, so spending it before that time means you don't have anything to worry\u00a0about, and spending it later means you'll have to be online and keep an eye out. If staying online is not a problem, then fee wise that seems preferable. As long as less than half of all valid (i.e. the timelock was reached)\u00a0revoke transactions get broadcast, you'll be saving on fees.\n\nIn a world where Alice may be insane and mess with the protocol just to grief Bob even if Alice loses its money (e.g. the real world), Bob should not depend on Alice behaving correctly or politely, so it should still have backup watchers set up in case it accidentally goes to sleep and so on.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Ruben Somsen",
                "date": "2020-05-13T12:33:21",
                "message_text_only": "Hi ZmnSCPxj,\n\n>on completion of the protocol, if Bob lets the refund tx#1 become valid\n(i.e. does not spend the BTC txo) then Alice can broadcast it, putting both\ntheir funds into chaos\n\nYou forget, refund tx #1 has a script (which btw won't be visible with\ntaproot): \"Alice & Bob OR Alice in +1 day\" (relative) so if Alice\nbroadcasts it after protocol completion, she is just giving Bob the key to\nher LTC (note: if she's wise she'd move the LTC beforehand), but Bob\ndoesn't lose the BTC because he has both keys and can just react before the\nrelative timelock expires. No chaos.\n\n>This is why we eventually decided in Lightning to use two CPFP outpoints\nrather than one\n\nI appreciate the explanation. I see the problem now, and yes, that does\nseem like a headache.\n\nCheers,\nRuben\n\nOn Wed, May 13, 2020 at 1:39 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Ruben,\n>\n> > Hi ZmnSCPxj,\n> >\n> > >potentially both Alice and Bob know all the secrets on the LTC side and\n> end up competing over it\n> >\n> > That's exactly right.\n> >\n> > >Bob can thus give a copy of the revoke tx with signature directly to\n> its favorite miner, forcing Alice to take 3 transactions\n> >\n> > Note that the timelock on the revoke tx is longer than the timelock on\n> refund tx #1. The idea is that Alice aborts the protocol by publishing\n> refund tx #1 if the protocol hasn't reached step 4 in the svg by the time\n> it becomes valid. This should entirely mitigate the issue you're describing.\n>\n> But if refund tx #1 at all exists, then you drop to the same issue you\n> objected to with my proposal, which is that, on completion of the protocol,\n> if Bob lets the refund tx#1 become valid (i.e. does not spend the BTC txo)\n> then Alice can broadcast it, putting both their funds into chaos.\n>\n> So you might as well just use my counterproposal instead, which is\n> simpler, gets bring-your-own-fees for free, etc.\n>\n> I suppose there is some *slight* improvement in that with your proposal,\n> Alice *can* use revoke tx -> refund tx #2, but still, if Alice is insane\n> then it could very well mess with the protocol by instead using refund tx\n> #1.\n> Thus, if Bob wants to survive in an environment where Alices are possibly\n> insane (e.g. the real world), it should do everything in its power to\n> ensure that the BTC txo is spent before the timeout of refund tx #1, if\n> refund tx #1 exists at all.\n> And if Bob is already going to do that, then Alice and Bob might as well\n> just use my counterproposal etc etc.\n>\n> > >adding two CPFP outputs (one for each participant)\n> >\n> > There seems to be a situation where RBF can be disabled by the other\n> party, but I'm not sure I see it... Why would a single output spendable by\n> either key be insufficient?\n>\n> If one party quickly broadcasts a long chain of low-feerate transactions\n> on top of the single output, then the output is \"pinned\".\n>\n> Low feerate means it is undesirable for miners to mine it, because it pays\n> low for the amount of blockspace it has.\n> But because there is a long chain of transactions, the absolute fee of\n> that chain can be sizable, and we have a rule in RBF which, paraphrased,\n> goes something like \"the replacing transaction should also have a higher\n> absolute fee than *all* the transactions it replaces\", meaning the fee jump\n> that the other side has to offer *has to be* pretty big.\n>\n> If the other outputs of the tx are then multisig, then the pinning\n> participant can simply refuse to sign for those, and if the existing txes\n> spending the other outputs are relative-time-locked, they cannot be used to\n> CPFP the revoke tx onchain.\n>\n> This is why we eventually decided in Lightning to use two CPFP outpoints\n> rather than one, and are also realizing just how much of a headache the RBF\n> rules are, sigh.\n>\n> Still, in your proposed protocol the dependent transactions are all\n> relative-timelocked, so timely confirmation of the revoke tx is not\n> necessary, unlike in the case of Lightning where all HTLCs have to use an\n> absolute timelock because we have to coordinate multiple HTLCs in\n> forwarding and violation of the timelocks can lead to headaches and fund\n> loss and so on.\n> So maybe a single hook output, or even none at all, is workable.\n>\n> >\n> > >We could use `SIGHASH_SINGLE | SIGHASH_ANYONECANPAY` as well\n> >\n> > Allowing others to add inputs/outputs would introduce malleability.\n> Refund tx #2 and the timeout tx would become invalid.\n>\n> Ah, right, you still need `SIGHASH_ANYPREVOUT`/`SIGHASH_NOINPUT` for that.\n>\n> > >Bob cannot safely perform step 2 before getting both signatures for the\n> revoke tx\n> >\n> > That's right, as you guessed, he does receive a copy of the signed\n> revoke tx at protocol start.\n> >\n> > >>alternatively Bob can just spend before the timelock expires.\n> > >This seems to be the safest alternative\n> >\n> > I agree not giving Alice time to publish the revoke tx is safest, but\n> one does not preclude the other. The revoke tx is on an absolute timelock,\n> so spending it before that time means you don't have anything to\n> worry about, and spending it later means you'll have to be online and keep\n> an eye out. If staying online is not a problem, then fee wise that seems\n> preferable. As long as less than half of all valid (i.e. the timelock was\n> reached) revoke transactions get broadcast, you'll be saving on fees.\n>\n> In a world where Alice may be insane and mess with the protocol just to\n> grief Bob even if Alice loses its money (e.g. the real world), Bob should\n> not depend on Alice behaving correctly or politely, so it should still have\n> backup watchers set up in case it accidentally goes to sleep and so on.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200513/257878bf/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-15T04:39:33",
                "message_text_only": "Good morning Ruben,\n\n> Hi ZmnSCPxj,\n>\n> >on completion of the protocol, if Bob lets the refund tx#1 become valid (i.e. does not spend the BTC txo) then Alice can broadcast it, putting both their funds into chaos\n>\n> You forget, refund tx #1 has a script (which btw won't be visible with taproot): \"Alice & Bob OR Alice in\u00a0+1 day\" (relative) so if Alice broadcasts it after protocol completion, she is just giving Bob the key to her LTC (note: if she's wise she'd move the LTC beforehand), but Bob doesn't lose the BTC because he has both keys and can just react before the relative timelock expires. No chaos.\n\nAh, that explains the existence of the Alice && Bob clause in that output then.\n\nThe attack is now as follows:\n\n* Alice completes the protocol up to handing over `sigSuccessAlice` to Bob.\n* Bob returns the `secretBob`.\n* Alice stalls the protocol and never sends the `Alice` privkey, and waits for 1 day, then sneaks the refund tx #1 and spends the LTC via direct miner collusion.\n\nThe proper response here is that Bob should broadcast success tx before the refund tx #1 becomes valid.\n(Which I think is the point: chaos can only occur if you let backouts become valid, and it is the best policy for Bob to just spend the BTC txo well before the timeout.\nEven if the protocol is completed, without a bring-your-own-fees that lets you malleate the tx (i.e. CPFP hooks still require the transction itself to reduce the fund by at least the minimum feerate), at least part of the fund must be lost in fees and Bob can still suffer a small loss of funds.)\n\n--\n\nTangentially, I now think in the case of client-server CoinSwap, the server should take Alice position and the client should take Bob position.\n\nSuppose a client wants to do some mixing of its own received coins.\nIt should not depend on only one server, as the server might secretly be a surveillor (or hacked by a surveillor) and recording swaps.\nThus, a client will want to make multiple CoinSwaps in sequence, to obscure its history.\n\n(Do note the objections under \"Directionality\" in https://zmnscpxj.github.io/bitcoin/multiswap.html though; a counter to this objections is that the analysis there is only applicable if the surveillor already identified the CoinSwap sequence, but hopefully the increased steganography of CoinSwaps means they are not identifiable anyway.)\n\nSince Bob really should spend its received coin before a timeout, it is best for Bob to be the client; it is likely that the client will need to swap \"soon\" again, meaning it has to redirect the funds to a new 2-of-2 anyway.\n\nFor the final swap, the client can then spend the final coins to an HD wallet it controls, reducing the key backup load on the client to be the same as normal HD wallets.\nPresumably the server in this situation has greater ability to dynamically update its backups to include key backups for `secretAlice` keys.\n\nFurther, if the client program has the policy that all spends out of the wallet must be done via a swap (similar to a rule imposed by JoinMarket where sendpayment.py always does 1 CoinJoin), then this still matches well with the requirement on Bob to spend the fund before the first timeout of refund tx #1.\n\nIf the client needs to spend to a classic, address-using service, then nothing in the SAS protocol allows Alice to receive its funds directly into a specific third-party address.\nHowever, Bob can hand over a specific third-party address to use in the success tx.\nIndeed, the SAS protocol can be modified so that Bob can specify a set of address/value pairs to be put in the success tx instead of just Bob pubkey; for example, Bob might swap more than the amoutn that needs to be paid to the third-party service, in order to give some additional leeway later for RBF once Alice hands over the Alice privkey and Bob can remake the success tx (and more importantly, ensure the txo is spent before refund tx #1 becoms valid).\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Ruben Somsen",
                "date": "2020-05-15T19:47:29",
                "message_text_only": "Hi ZmnSCPxj,\n\n>The proper response here is that Bob should broadcast success tx before\nthe refund tx #1 becomes valid.\n\nThat's right. And even if Bob neglects to do that, it still won't cause\nchaos for Alice as long as she chooses the path for refund tx #2.\n\n>at least part of the fund must be lost in fees and Bob can still suffer a\nsmall loss\n\nYes, after protocol completion Alice can broadcast one more transaction\nthat is paid for by Bob, and Bob would have to respond with another\ntransaction of his own. As you said, bring-your-own-fees would be better\nhere (also see FAQ question \"Can't Alice just publish the revoke_tx after\nprotocol completion?\").\n\n>the server should take Alice position and the client should take Bob\nposition [...] a client will want to make multiple CoinSwaps in sequence\n\nI think this can be summarized as: whoever is planning to spend their UTXO\nfirst should be Bob.\n\nIn your protocol it might make sense for the server and client to swap\nroles depending on what the client plans to do. If they plan to swap again\nsoon, they can be Bob, if they don't, they're Alice.\n\nBut there's also another consideration: whoever is less likely to abort the\nprotocol should be Bob.\n\nClients can be unreliable. If clients are Bob, they can waste Alice's\nresources by initiating the protocol and aborting (which imo is more severe\nthan the risk of the revoke tx getting published). Whereas if the client is\nAlice, she'd be first to commit resources before the server commits\nanything.\n\n>ensure the txo is spent before refund tx #1 becoms valid\n\nYes, this is important. Luckily, pretty much all the options we discussed\ncould be applied here, including sighash_single + anyonecanpay. In your\nspecific example this seems preferable to adding a change output and making\nmultiple transactions with different RBF amounts, especially since this\nonly concerns a situation where the protocol stalls at a specific step\n(after the success tx).\n\nAnd I agree with your general assessment that three transactions are\nrequired in order to pay a third party. This could be done from either side\nof the swap, but of course it makes more sense to pay from the timelock\nside and get rid of the online requirement.\n\nCheers,\nRuben\n\nOn Fri, May 15, 2020 at 6:39 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Ruben,\n>\n> > Hi ZmnSCPxj,\n> >\n> > >on completion of the protocol, if Bob lets the refund tx#1 become valid\n> (i.e. does not spend the BTC txo) then Alice can broadcast it, putting both\n> their funds into chaos\n> >\n> > You forget, refund tx #1 has a script (which btw won't be visible with\n> taproot): \"Alice & Bob OR Alice in +1 day\" (relative) so if Alice\n> broadcasts it after protocol completion, she is just giving Bob the key to\n> her LTC (note: if she's wise she'd move the LTC beforehand), but Bob\n> doesn't lose the BTC because he has both keys and can just react before the\n> relative timelock expires. No chaos.\n>\n> Ah, that explains the existence of the Alice && Bob clause in that output\n> then.\n>\n> The attack is now as follows:\n>\n> * Alice completes the protocol up to handing over `sigSuccessAlice` to Bob.\n> * Bob returns the `secretBob`.\n> * Alice stalls the protocol and never sends the `Alice` privkey, and waits\n> for 1 day, then sneaks the refund tx #1 and spends the LTC via direct miner\n> collusion.\n>\n> The proper response here is that Bob should broadcast success tx before\n> the refund tx #1 becomes valid.\n> (Which I think is the point: chaos can only occur if you let backouts\n> become valid, and it is the best policy for Bob to just spend the BTC txo\n> well before the timeout.\n> Even if the protocol is completed, without a bring-your-own-fees that lets\n> you malleate the tx (i.e. CPFP hooks still require the transction itself to\n> reduce the fund by at least the minimum feerate), at least part of the fund\n> must be lost in fees and Bob can still suffer a small loss of funds.)\n>\n> --\n>\n> Tangentially, I now think in the case of client-server CoinSwap, the\n> server should take Alice position and the client should take Bob position.\n>\n> Suppose a client wants to do some mixing of its own received coins.\n> It should not depend on only one server, as the server might secretly be a\n> surveillor (or hacked by a surveillor) and recording swaps.\n> Thus, a client will want to make multiple CoinSwaps in sequence, to\n> obscure its history.\n>\n> (Do note the objections under \"Directionality\" in\n> https://zmnscpxj.github.io/bitcoin/multiswap.html though; a counter to\n> this objections is that the analysis there is only applicable if the\n> surveillor already identified the CoinSwap sequence, but hopefully the\n> increased steganography of CoinSwaps means they are not identifiable\n> anyway.)\n>\n> Since Bob really should spend its received coin before a timeout, it is\n> best for Bob to be the client; it is likely that the client will need to\n> swap \"soon\" again, meaning it has to redirect the funds to a new 2-of-2\n> anyway.\n>\n> For the final swap, the client can then spend the final coins to an HD\n> wallet it controls, reducing the key backup load on the client to be the\n> same as normal HD wallets.\n> Presumably the server in this situation has greater ability to dynamically\n> update its backups to include key backups for `secretAlice` keys.\n>\n> Further, if the client program has the policy that all spends out of the\n> wallet must be done via a swap (similar to a rule imposed by JoinMarket\n> where sendpayment.py always does 1 CoinJoin), then this still matches well\n> with the requirement on Bob to spend the fund before the first timeout of\n> refund tx #1.\n>\n> If the client needs to spend to a classic, address-using service, then\n> nothing in the SAS protocol allows Alice to receive its funds directly into\n> a specific third-party address.\n> However, Bob can hand over a specific third-party address to use in the\n> success tx.\n> Indeed, the SAS protocol can be modified so that Bob can specify a set of\n> address/value pairs to be put in the success tx instead of just Bob pubkey;\n> for example, Bob might swap more than the amoutn that needs to be paid to\n> the third-party service, in order to give some additional leeway later for\n> RBF once Alice hands over the Alice privkey and Bob can remake the success\n> tx (and more importantly, ensure the txo is spent before refund tx #1\n> becoms valid).\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200515/dcb4a03f/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "SAS: Succinct Atomic Swap",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Chris Belcher",
                "Lloyd Fournier",
                "Ruben Somsen"
            ],
            "messages_count": 18,
            "total_messages_chars_count": 96668
        }
    },
    {
        "title": "[bitcoin-dev] TLA+ specification for Succint Atomic Swap",
        "thread_messages": [
            {
                "author": "Dmitry Petukhov",
                "date": "2020-05-13T17:02:22",
                "message_text_only": "The Succint Atomic Swap contract presented by Ruben Somsen recently has\ndrawn much interest.\n\nI personally am interested in the smart contracts realizeable in the\nUTXO model, and also interested in applying formal methods to the\ndesign and implementation of such contracts.\n\nI think that having formal specifications for the contracts and to be\nable to machine-check the properties of these specifications is very\nvaluable, as it can uncover the corner cases that might be difficult to\nuncover otherwise.\n\nThe SAS contract is complex enough that it may benefit from formal\nspecification and machine checking.\n\nI created a specification in TLA+ [1] specification language based on\nthe explanation and the diagram given by Ruben.\n\nThe checking of the model encoded in the specification can successfully\ndetect the violation of 'no mutual secret knowledge' invariant when one\nof the participant can bypass mempool and give the transaction directly\nto the miner (this problem was pointed out by ZmnSCPxj in the original\nSAS thread [2])\n\nThere's one transition that was unclear how to model, though: I did not\nunderstand what the destination of Alice&Bob cooperative spend of\nrefund_tx#1 will be, so this transition is not modelled.\n\nI believe there can be more invariants and temporal properties of the\nmodel that can be checked. At the moment the temporal properties\nchecking does not work, as I didn't master TLA+ enough yet. The safety\ninvariants checking should work fine, though, but more work needed to\ndevise and add the invariants.\n\nIn the future, it would be great to have an established framework for\nmodelling of the behavior in Bitcoin-like blockchain networks.\nIn particular, having a model of mempool-related behavior would help to\nreason about difficult RBF/CPFP issues. The specification I present\nmodels the mempool, but in a simple way, without regards to the fees.\n\nThe specification can be found in this github repository:\nhttps://github.com/dgpv/SASwap_TLAplus_spec\n\nThere could be mistakes or omissions in the specified model, I hope\nthat public review can help find these.\n\nIt would be great to receive comments, suggestions and corrections,\nespecially from people experienced in formal methods and TLA+, as this\nis only my second finished TLA+ spec and only my third project using\nformal methods (I created bitcoin transaction deserialization code in\nAda/SPARK before that [3]). Please use the github issues or off-list\nmail to discuss if the matter is not interesting to the general\nbitcoin-dev list audience.\n\n[1] https://lamport.azurewebsites.net/tla/tla.html\n\n[2]\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-May/017846.html\n\n[3] https://github.com/dgpv/spark-bitcoin-transaction-example"
            },
            {
                "author": "Ruben Somsen",
                "date": "2020-05-13T19:03:17",
                "message_text_only": "Hi Dmitry,\n\nThanks for creating a specification for testing, I appreciate the interest!\n\n>The checking of the model encoded in the specification can successfully\ndetect the violation of 'no mutual secret knowledge' invariant when one of\nthe participant can bypass mempool and give the transaction directly to the\nminer (this problem was pointed out by ZmnSCPxj in the original SAS thread\n[2])\n\nI'm not sure if I follow. The issue ZmnSCPxj described about bypassing the\nmempool was not a violation. It was merely a \"nuisance\" strategy that\ncauses Alice to have to abort in three transactions. Also note that I\nsubsequently pointed out in the thread that this strategy does not work,\nbecause Alice is supposed to abort sooner than that if Bob still has not\nlocked up any funds.\n\nOr perhaps you're referring to the issue ZmnSCPxj pointed out after that,\nwhere refund transaction #1 and the success transaction could both become\nvalid at the same time. It would make sense for the test to pick up on\nthat, but I believe that is ultimately also not an issue (see my last reply\nin the thread).\n\n>I did not understand what the destination of Alice&Bob cooperative spend\nof refund_tx#1 will be\n\nThis transaction can be spent by Alice & Bob right away or by Alice a day\nlater (in relative time, so the tx has to confirm first). The Alice & Bob\ncondition is there purely to ensure that Bob can spend the money before\nAlice once he receives her key at the end of the protocol.\n\nIf it helps, you could model this transaction as two separate transactions\ninstead:\ntxA: 1 day absolute timelock to Alice & Bob (reveals secretAlice), which\ncan then be spent by\ntxB: +1 day relative timelock to Alice\n\nThis should be functionally equivalent. Also note that the protocol should\nfully function if refund tx #1 did not exist at all. It merely serves to\nsave block space in certain refund scenarios.\n\n>it would be great to have an established framework for modelling of the\nbehavior in Bitcoin-like blockchain networks. In particular, having a model\nof mempool-related behavior would help to reason about difficult RBF/CPFP\nissues\n\nA laudable goal. Good luck with your efforts.\n\nCheers,\nRuben\n\nOn Wed, May 13, 2020 at 7:07 PM Dmitry Petukhov via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> The Succint Atomic Swap contract presented by Ruben Somsen recently has\n> drawn much interest.\n>\n> I personally am interested in the smart contracts realizeable in the\n> UTXO model, and also interested in applying formal methods to the\n> design and implementation of such contracts.\n>\n> I think that having formal specifications for the contracts and to be\n> able to machine-check the properties of these specifications is very\n> valuable, as it can uncover the corner cases that might be difficult to\n> uncover otherwise.\n>\n> The SAS contract is complex enough that it may benefit from formal\n> specification and machine checking.\n>\n> I created a specification in TLA+ [1] specification language based on\n> the explanation and the diagram given by Ruben.\n>\n> The checking of the model encoded in the specification can successfully\n> detect the violation of 'no mutual secret knowledge' invariant when one\n> of the participant can bypass mempool and give the transaction directly\n> to the miner (this problem was pointed out by ZmnSCPxj in the original\n> SAS thread [2])\n>\n> There's one transition that was unclear how to model, though: I did not\n> understand what the destination of Alice&Bob cooperative spend of\n> refund_tx#1 will be, so this transition is not modelled.\n>\n> I believe there can be more invariants and temporal properties of the\n> model that can be checked. At the moment the temporal properties\n> checking does not work, as I didn't master TLA+ enough yet. The safety\n> invariants checking should work fine, though, but more work needed to\n> devise and add the invariants.\n>\n> In the future, it would be great to have an established framework for\n> modelling of the behavior in Bitcoin-like blockchain networks.\n> In particular, having a model of mempool-related behavior would help to\n> reason about difficult RBF/CPFP issues. The specification I present\n> models the mempool, but in a simple way, without regards to the fees.\n>\n> The specification can be found in this github repository:\n> https://github.com/dgpv/SASwap_TLAplus_spec\n>\n> There could be mistakes or omissions in the specified model, I hope\n> that public review can help find these.\n>\n> It would be great to receive comments, suggestions and corrections,\n> especially from people experienced in formal methods and TLA+, as this\n> is only my second finished TLA+ spec and only my third project using\n> formal methods (I created bitcoin transaction deserialization code in\n> Ada/SPARK before that [3]). Please use the github issues or off-list\n> mail to discuss if the matter is not interesting to the general\n> bitcoin-dev list audience.\n>\n> [1] https://lamport.azurewebsites.net/tla/tla.html\n>\n> [2]\n>\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-May/017846.html\n>\n> [3] https://github.com/dgpv/spark-bitcoin-transaction-example\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200513/d2dc3c1c/attachment-0001.html>"
            },
            {
                "author": "Dmitry Petukhov",
                "date": "2020-05-14T04:52:15",
                "message_text_only": "\u0412 Wed, 13 May 2020 21:03:17 +0200\nRuben Somsen <rsomsen at gmail.com> wrote:\n\n> Or perhaps you're referring to the issue ZmnSCPxj pointed out after\n> that, where refund transaction #1 and the success transaction could\n> both become valid at the same time. It would make sense for the test\n> to pick up on that, but I believe that is ultimately also not an\n> issue (see my last reply in the thread).\n\nThis one.\n\nThe issue as I see it: Bob can not broadcast success_tx and wait until\nAlice has broadcasted refund_tx_1. While refund_tx_1 is in the mempool,\nBob gives success_tx to the friendly miner to have a chance to\ninvalidate success_tx. Bob already learned secretAlice, so he grabs\nhis LTC back. If the Bob-friendly miner has luck, success_tx is\nconfirmed while refund_tx_1 is invalidated, and Bob now have both LTC\nand BTC, while Alice is out of her BTC.\n\n> >I did not understand what the destination of Alice&Bob cooperative\n> >spend  \n> of refund_tx#1 will be\n> \n> This transaction can be spent by Alice & Bob right away or by Alice a\n> day later (in relative time, so the tx has to confirm first). The\n> Alice & Bob condition is there purely to ensure that Bob can spend\n> the money before Alice once he receives her key at the end of the\n> protocol.\n\nAh, so this is possible because of the step 5 in the diagram: ``Alice\ngives Bob her key (\"Alice\")'' -- As I understand, this is a way to deny\nAlice to use refund_tx_1.\n\nThen if Alice gives her _key_ to Bob before Bob has to share secretBob\nvia success_tx, could Bob just spend the Alice&Bob output of the\nvery first, \"commitment\" transaction that locks BTC ? Bob will receive\nBTC, and the LTC can be locked forever, but Bob doesn't care, he got\nhis BTC."
            },
            {
                "author": "Ruben Somsen",
                "date": "2020-05-14T05:31:13",
                "message_text_only": "Hi Dmitry,\n\n>While refund_tx_1 is in the mempool, Bob gives success_tx to the friendly\nminer\n\nI see, so you're talking about prior to protocol completion, right after\nAlice sends Bob the success_tx. The reason this is not an issue is because\nAlice and Bob both had to misbehave in order for this to happen. Bob is\nmisbehaving here because he should have published the success_tx before\nrefund_tx_1 became valid, and Alice is misbehaving here because she should\nhave sent the revoke_tx (which invalidates the success_tx) followed by\nrefund_tx_2 (revealing her secret only AFTER Bob can no longer claim the\nBTC). In other words: yes, the protocol can fail if Alice and Bob together\nwork towards that goal. A feature, not a bug. This won't happen if either\nof them doesn't want it to. I imagine this is difficult to model.\n\n>As I understand, this is a way to deny Alice to use refund_tx_1.\n\nThat is correct, and it also denies refund_tx_2 by making the revoke_tx\ndirectly spendable by Bob.\n\n>could Bob just spend the Alice&Bob output of the very first, \"commitment\"\ntransaction that locks BTC\n\nYes, he can. This is what makes it possible to complete the protocol in\nmerely two transactions.\n\n>Bob will receive BTC, and the LTC can be locked forever, but Bob doesn't\ncare, he got his BTC.\n\nNo, because diagram step 5 comes before step 6 -- Alice won't give her key\nuntil she learns secretBob.\n\nI hope this clarifies it!\n\nCheers,\nRuben\n\nOn Thu, May 14, 2020 at 6:49 AM Dmitry Petukhov <dp at simplexum.com> wrote:\n\n> \u0412 Wed, 13 May 2020 21:03:17 +0200\n> Ruben Somsen <rsomsen at gmail.com> wrote:\n>\n> > Or perhaps you're referring to the issue ZmnSCPxj pointed out after\n> > that, where refund transaction #1 and the success transaction could\n> > both become valid at the same time. It would make sense for the test\n> > to pick up on that, but I believe that is ultimately also not an\n> > issue (see my last reply in the thread).\n>\n> This one.\n>\n> The issue as I see it: Bob can not broadcast success_tx and wait until\n> Alice has broadcasted refund_tx_1. While refund_tx_1 is in the mempool,\n> Bob gives success_tx to the friendly miner to have a chance to\n> invalidate success_tx. Bob already learned secretAlice, so he grabs\n> his LTC back. If the Bob-friendly miner has luck, success_tx is\n> confirmed while refund_tx_1 is invalidated, and Bob now have both LTC\n> and BTC, while Alice is out of her BTC.\n>\n> > >I did not understand what the destination of Alice&Bob cooperative\n> > >spend\n> > of refund_tx#1 will be\n> >\n> > This transaction can be spent by Alice & Bob right away or by Alice a\n> > day later (in relative time, so the tx has to confirm first). The\n> > Alice & Bob condition is there purely to ensure that Bob can spend\n> > the money before Alice once he receives her key at the end of the\n> > protocol.\n>\n> Ah, so this is possible because of the step 5 in the diagram: ``Alice\n> gives Bob her key (\"Alice\")'' -- As I understand, this is a way to deny\n> Alice to use refund_tx_1.\n>\n> Then if Alice gives her _key_ to Bob before Bob has to share secretBob\n> via success_tx, could Bob just spend the Alice&Bob output of the\n> very first, \"commitment\" transaction that locks BTC ? Bob will receive\n> BTC, and the LTC can be locked forever, but Bob doesn't care, he got\n> his BTC.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200514/4aa8df86/attachment-0001.html>"
            },
            {
                "author": "Dmitry Petukhov",
                "date": "2020-05-14T07:08:05",
                "message_text_only": "\u0412 Thu, 14 May 2020 07:31:13 +0200\nRuben Somsen <rsomsen at gmail.com> wrote:\n\n> Hi Dmitry,\n> \n> >While refund_tx_1 is in the mempool, Bob gives success_tx to the\n> >friendly miner\n> \n> I see, so you're talking about prior to protocol completion, right\n> after Alice sends Bob the success_tx. The reason this is not an issue\n> is because Alice and Bob both had to misbehave in order for this to\n> happen. Bob is misbehaving here because he should have published the\n> success_tx before refund_tx_1 became valid, and Alice is misbehaving\n> here because she should have sent the revoke_tx (which invalidates\n> the success_tx) followed by refund_tx_2 (revealing her secret only\n> AFTER Bob can no longer claim the BTC). In other words: yes, the\n> protocol can fail if Alice and Bob together work towards that goal. A\n> feature, not a bug. This won't happen if either of them doesn't want\n> it to. I imagine this is difficult to model.\n\nRight. But it should be noted that it is not enough that Bob publishes\nsuccess_tx before refund_tx_1 became valid. The success_tx needs to be\nconfirmed before refund_tx_1 became valid.\n\nOnly Bob can spend success_tx so this is unlikely to be the practical\nproblem, unless the original fee of success_tx is too small and Bob\nepically screws up CPFP-ing it.\n\n> >Bob will receive BTC, and the LTC can be locked forever, but Bob\n> >doesn't  \n> care, he got his BTC.\n> \n> No, because diagram step 5 comes before step 6 -- Alice won't give\n> her key until she learns secretBob.\n\nI somehow missed it, and steps 5 and 6 in the diagram was not modelled\nat all (on the other hand, it made the model simpler and I had\nsomething working relatively quick). I now made the `signers_map` into\nvariable that can be changed to give Bob the ability to sign for Alice.\n\nWith that change, step 6 can be modelled, but this will add a bunch of\nnew txs to the model (each Alice&Bob spend will have 'Bob unilateral\noverride' case)"
            },
            {
                "author": "Ruben Somsen",
                "date": "2020-05-14T11:41:32",
                "message_text_only": "Hi Dmitry,\n\n>But it should be noted that it is not enough that Bob publishes success_tx\nbefore refund_tx_1 became valid. The success_tx needs to be confirmed\nbefore refund_tx_1 became valid.\n\nAgreed, my write-up would benefit from pointing this out more explicitly.\n\nCheers,\nRuben\n\nOn Thu, May 14, 2020 at 9:05 AM Dmitry Petukhov <dp at simplexum.com> wrote:\n\n> \u0412 Thu, 14 May 2020 07:31:13 +0200\n> Ruben Somsen <rsomsen at gmail.com> wrote:\n>\n> > Hi Dmitry,\n> >\n> > >While refund_tx_1 is in the mempool, Bob gives success_tx to the\n> > >friendly miner\n> >\n> > I see, so you're talking about prior to protocol completion, right\n> > after Alice sends Bob the success_tx. The reason this is not an issue\n> > is because Alice and Bob both had to misbehave in order for this to\n> > happen. Bob is misbehaving here because he should have published the\n> > success_tx before refund_tx_1 became valid, and Alice is misbehaving\n> > here because she should have sent the revoke_tx (which invalidates\n> > the success_tx) followed by refund_tx_2 (revealing her secret only\n> > AFTER Bob can no longer claim the BTC). In other words: yes, the\n> > protocol can fail if Alice and Bob together work towards that goal. A\n> > feature, not a bug. This won't happen if either of them doesn't want\n> > it to. I imagine this is difficult to model.\n>\n> Right. But it should be noted that it is not enough that Bob publishes\n> success_tx before refund_tx_1 became valid. The success_tx needs to be\n> confirmed before refund_tx_1 became valid.\n>\n> Only Bob can spend success_tx so this is unlikely to be the practical\n> problem, unless the original fee of success_tx is too small and Bob\n> epically screws up CPFP-ing it.\n>\n> > >Bob will receive BTC, and the LTC can be locked forever, but Bob\n> > >doesn't\n> > care, he got his BTC.\n> >\n> > No, because diagram step 5 comes before step 6 -- Alice won't give\n> > her key until she learns secretBob.\n>\n> I somehow missed it, and steps 5 and 6 in the diagram was not modelled\n> at all (on the other hand, it made the model simpler and I had\n> something working relatively quick). I now made the `signers_map` into\n> variable that can be changed to give Bob the ability to sign for Alice.\n>\n> With that change, step 6 can be modelled, but this will add a bunch of\n> new txs to the model (each Alice&Bob spend will have 'Bob unilateral\n> override' case)\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200514/361933b2/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "TLA+ specification for Succint Atomic Swap",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Dmitry Petukhov",
                "Ruben Somsen"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 17913
        }
    },
    {
        "title": "[bitcoin-dev] BIP Number request for a simple payjoin proposal",
        "thread_messages": [
            {
                "author": "Nicolas Dorier",
                "date": "2020-05-16T19:46:35",
                "message_text_only": "I am requesting a BIP number to be allocated for this simple payjoin proposal.\nThis proposal is already being implemented by several service and\nwallets and incorporate the feedback of the community at\nhttps://github.com/NicolasDorier/bips/pull/3\n\nI opened a pull request at: https://github.com/bitcoin/bips/pull/923\n\nI am not checking my mail very often, so I suggest give me feedback\ndirectly on the opened pull request.\n\n\n<pre>\n  BIP: ?\n  Layer: Applications\n  Title: A Simple Payjoin Proposal\n  Author: Nicolas Dorier <nicolas.dorier at gmail.com>\n  Comments-Summary: No comments yet.\n  Comments-URI: https://github.com/bitcoin/bips/wiki/Comments:BIP-X\n  Status: Draft\n  Type: Standards Track\n  Created: 2019-05-01\n  License: BSD-2-Clause\n</pre>\n\n==Introduction==\n\n===Abstract===\n\nThis document proposes a protocol for two parties\nto negotiate a coinjoin transaction during a payment between them.\n\n===Copyright===\n\nThis BIP is licensed under the 2-clause BSD license.\n\n===Motivation===\n\nWhen two parties (later referred to as sender and receiver) want to transact,\nmost of the time, the sender creates a transaction spending their own\nUnspent Transaction Outputs (UTXOs), signs\nit and broadcasts it on the network.\n\nThis simple model gave birth to several heuristics impacting the\nprivacy of the parties and of the network as a whole.\n\n* Common input ownership heuristic: In most transactions, all the\ninputs belong to the same party.\n* Change identification from scriptPubKey type: If all inputs are\nspending UTXOs of a certain scriptPubKey type, then the change output\nis likely to have the same scriptPubKey type, too.\n* Change identification from round amount: If an output in the\ntransaction has a round amount, it is likely an output belonging to\nthe receiver.\n\nWe will designate these three heuristics as <code>common-input</code>,\n<code>change-scriptpubkey</code>, <code>change-round-amount</code>.\n\nThe problems we aim to solve are:\n* For the receiver, there is a missed opportunity to consolidate their\nown UTXOs or making payment in the sender's transaction.\n* For the sender, there are privacy leaks regarding their wallet that\nhappen when someone applies the heuristics detailed above to their\ntransaction.\n\nOur proposal gives an opportunity for the receiver to consolidate\ntheir UTXOs while also batching their own payments, without creating a\nnew transaction. (Saving fees in the process)\nFor the sender, it allows them to invalidate the three heuristics\nabove. With the receiver's involvement, the heuristics can even be\npoisoned. (ie, using the heuristics to intentionally mislead\nblockchain analysis)\n\nNote that the existence of this proposal is also improving the privacy\nof parties who are not using it by making the three heuristics\nunreliable to the network as a whole.\n\n=== Relation to BIP79 (Bustapay) ===\n\nAnother implementation proposal has been written:\n[[https://github.com/bitcoin/bips/blob/master/bip-0079.mediawiki|BIP79\nBustapay]].\n\nWe decided to deviate from it for several reasons:\n* It was not using PSBT, so if the receiver wanted to bump the fee,\nthey would need the full UTXO set.\n* The receiver was responsible to pay the additional fee, not the sender.\n* It was requiring at least one input to be contributed by the receiver.\n* Inability to change the payment output to match scriptPubKey type.\n* Lack of basic versioning negotiation if the protocol evolves.\n* No standardization of error condition for proper feedback to the sender.\n\nOther than that, our proposal is very similar.\n\n==Specification==\n\n===Protocol===\n\nIn a payjoin payment, the following steps happen:\n\n* The receiver of the payment, presents a [[bip-021.mediawiki|BIP 21\nURI]] to the sender with a parameter <code>pj</code> describing an\nhttps (or http if it is a Tor hidden service) link to the payjoin\nendpoint.\n* The sender creates a signed, finalized PSBT with witness UTXO or\nprevious transactions of the inputs. We call this PSBT the\n<code>original</code>.\n* The receiver replies back with a signed PSBT containing his own\nsigned inputs/outputs and those of the sender. We call this PSBT\n<code>Payjoin proposal</code>.\n* The sender verifies the proposal, re-signs his inputs and broadcasts\nthe transaction to the Bitcoin network. We call this transaction\n<code>Payjoin transaction</code>.\n<pre>\n+----------+                        +--------+         +-----------------+\n| Receiver |                        | Sender |         | Bitcoin Network |\n+----+-----+                        +---+----+         +-------+---------+\n     |       +-----------------+        |                      |\n     +-------+ BIP21 with ?pj= +------->+                      |\n     |       +-----------------+        |                      |\n     |                                  |                      |\n     |        +---------------+         |                      |\n     +<-------+ Original PSBT +---------+                      |\n     |        +---------------+         |                      |\n     |                                  |                      |\n     |       +------------------+       |                      |\n     |       | Payjoin Proposal |       |                      |\n     +-------+      PSBT        +------>+                      |\n     |       +------------------+       |                      |\n     |                                  |   +--------------+   |\n     |                                  |---+ Payjoin      |   |\n     |                                  |   | transaction  +-->+\n     |                                  |   +--------------+   |\n     +                                  +                      +\n</pre>\nThe original PSBT is sent in the HTTP POST request body, base64\nserialized, with <code>text/plain</code> in the\n<code>Content-Type</code> HTTP header and <code>Content-Length</code>\nset correctly.\nThe payjoin proposal PSBT is sent in the HTTP response body, base64\nserialized with HTTP code 200.\n\nTo ensure compatibility with web-wallets and browser-based-tools, all\nresponses (including errors) must contain the HTTP header\n<code>Access-Control-Allow-Origin: *</code>.\n\nThe sender must ensure that the url refers to a scheme or protocol\nusing authenticated encryption, for example TLS with certificate\nvalidation, or a .onion link to a hidden service whose public key\nidentifier has already been communicated via a TLS connection. Senders\nMUST NOT accept a url representing an unencrypted or unauthenticated\nconnection.\n\n===Receiver's well known errors===\n\nIf for some reason the receiver is unable to create a payjoin\nproposal, it will reply with a HTTP code different than 200.\nThe receiver is not constrained to specific set of errors, some are\nspecified in this proposal.\n\nThe errors have the following format:\n<pre>\n{\n    \"errorCode\": \"leaking-data\",\n    \"message\": \"Key path information or GlobalXPubs should not be\nincluded in the original PSBT.\"\n}\n</pre>\n\nThe well-known error codes are:\n{| class=\"wikitable\"\n!Error code\n!Meaning\n|-\n|leaking-data\n|Key path information or GlobalXPubs should not be included in the\noriginal PSBT.\n|-\n|psbt-not-finalized\n|The original PSBT must be finalized.\n|-\n|unavailable\n|The payjoin endpoint is not available for now.\n|-\n|out-of-utxos\n|The receiver does not have any UTXO to contribute in a payjoin proposal.\n|-\n|not-enough-money\n|The receiver added some inputs but could not bump the fee of the\npayjoin proposal.\n|-\n|insane-psbt\n|Some consistency check on the PSBT failed.\n|-\n|version-unsupported\n|This version of payjoin is not supported.\n|-\n|need-utxo-information\n|The witness UTXO or non witness UTXO is missing\n|-\n|invalid-transaction\n|The original transaction is invalid for payjoin\n|}\n\nThe receiver is allowed to return implementation specific errors which\nmay assist the sender to diagnose any issue.\n\nHowever, it is important that error codes that are not well-known and\nthat the message do not appear on the sender's software user\ninterface.\nSuch error codes or messages could be used maliciously to phish a non\ntechnical user.\nInstead those errors or messages can only appear in debug logs.\n\nIt is advised to hard code the description of the error codes into the\nsender's software.\n\n===Receiver's original PSBT checklist===\n\nThe receiver needs to do some check on the original PSBT before proceeding:\n\n* Non-interactive receivers (like a payment processor) need to check\nthat the original PSBT is broadcastable. <code>*</code>\n* If the sender included inputs in the original PSBT owned by the\nreceiver, the receiver must either return error\n<code>invalid-transaction</code> or make sure they do not sign those\ninputs in the payjoin proposal.\n* If the sender's inputs are all from the same scriptPubKey type, the\nreceiver must match the same type. If the receiver can't match the\ntype, they must return error <code>out-of-utxos</code>.\n\n<code>*</code>: Interactive receivers are not required to validate the\noriginal PSBT because they are not exposed to probing attacks.\n\n===Sender's payjoin proposal checklist===\n\nThe sender should check the payjoin proposal before signing it to\nprevent a malicious receiver from stealing money.\n\n* Check that all the spent outpoints in the original PSBT still exist\nin the coinjoin PSBT.\n* Check that all the spent outpoints in the original PSBT do not have\nany partial signature.\n* If the sender is not using inputs with mixed types, check that the\nreceiver inputs type match the inputs type of the sender. (ie. both\nusing P2SH-P2WPKH or both using P2WPKH)\n* Check that any inputs added by the receiver are finalized.\n* Check that the transaction version, and nLockTime are unchanged.\n* Check that the sender's inputs' sequence numbers are unchanged.\n* If the sender's inputs' sequence numbers the homogenous, check that\nthe receiver's contributed inputs match those.\n* Check that the sender's outputs have not been modified (but\npotentially shuffled), except for paying increased fee\n* If sender specified <code>feebumpindex=</code> (see later), the fee\nshould have been subtracted from the output at the same index in the\noriginal PSBT.\n* Check that the sent amount in the payjoin proposal is less than or\nequal to the sent amount of the original transaction.\n\nIf the sent amount in the payjoin proposal is above the amount sent in\nthe original PSBT\n* Check that the additional paid amount has been add paid to the fee.\n* Check that the estimated fee rate of the payjoin proposal is not\nmore than the fee rate of the original PSBT. (fee estimation is hard,\nso we should allow ~2 satoshi per inputs as margin of error)\n* If <code>maxfeebumpcontribution=</code> was specified, check the\nadditional paid amount is less than or equal to this amount.\n* If <code>maxfeebumpcontribution=</code> was not specified, the\nsender's software should ask an interactive confirmation to the user.\n\nThe sender must be careful to only sign the inputs that were present\nin the original PSBT and nothing else.\n\nNote:\n* The sender should allow the payment output to be modified by the\nreceiver (The receiver may substitute a P2WPKH payment to P2SH payment\nto increase privacy)\n* The sender must allow the receiver to add outputs.\n* The sender must allow the receiver to not add any input. Useful for\nthe receiver to change the paymout output scriptPubKey type.\n* If no input has been added, the sender's wallet should accept the\npayjoin proposal, but should not mark the transaction as an actual\npayjoin in the user interface.\n\nOur method of checking the fee allows the receiver and the sender to\nbatch payments in the payjoin transaction.\nIt also allows the receiver to pay the fee for batching adding his own outputs.\n\n===Optional parameters===\n\nWhen the payjoin sender posts the original PSBT to the receiver, he\ncan optionally specify the following HTTP query string parameters:\n\n* <code>v=</code>, the version number of the payjoin protocol that the\nsender is using. The current version is <code>1</code>.\n\nThis can be used in the future so the receiver can reject a payjoin if\nthe sender is using a version which is not supported via an error HTTP\n400, <code>version-unsupported</code>.\nIf not specified, the receiver will assume the sender is <code>v=1</code>.\n\nIf the receiver does not support the version of the sender, they\nshould send an error with the list of supported versions:\n<pre>\n{\n    \"errorCode\": \"version-unsupported\",\n    \"supported\" : [ 2, 3, 4 ],\n    \"message\": \"The version is not supported anymore\"\n}\n</pre>\n\n* <code>feebumpindex=</code>, the preferred output from which to\nincrease the fee for the added inputs. (default: <code>-1</code>)\n\nIf the <code>feebumpindex</code> is out of bounds or pointing to the\npayment ouptut meant for the receiver, the receiver should ignore the\nparameter.\n\n* <code>maxfeebumpcontribution=</code>, an integer defining the\nmaximum amount in satoshis that the sender is willing to contribute\ntowards fees for the additional inputs.\n<code>maxfeebumpcontribution</code> must be ignored if set to less\nthan zero. (default: -1)\n\nNote that if <code>maxfeebumpcontribution</code> is too low, the\nsender should create a transaction with RBF disabled, as the original\ntransaction could replace the payjoin transaction.\n\n==Rationale==\n\nThere is several consequences of our proposal:\n\n* The receiver can bump the fee of the original transaction.\n* The receiver can modify the outputs of the original PSBT.\n* The sender must provide the UTXO information (Witness or previous\ntransaction) in the PSBT.\n\n===Respecting the minimum relay fee policy===\n\nTo be properly relayed, a Bitcoin transaction needs to pay at least 1\nsatoshi per virtual byte.\nWhen fees are low, the original transaction is already 1 satoshi per\nvirtual byte, so if the receiver adds their own input, they need to\nmake sure the fee is increased such that the rate does not drop below\n1 satoshi per virtual byte.\n\n===Preventing mempool replacement===\n\nA safe way to implement payjoin, is for both the sender and receiver\nto try broadcasting the original transaction at some fixed interval\nperiod regardless of the state of the payjoin.\n\nIf the receiver was not properly adding fees to the payjoin\ntransaction, the original transaction would end up replacing the\npayjoin transaction in the mempool.\n\n===Defeating heuristics based on the fee calculation===\n\nMost wallets are creating a round fee rate (like 2 sat/b).\nIf the payjoin transaction's fee was not increased by the added size,\nthen those payjoin transactions could easily be identifiable on the\nblockchain.\n\nNot only would those transactions stand out by not having a round fee\n(like 1.87 sat/b), but any suspicion of payjoin could be confirmed by\nchecking if removing one input would create a round fee rate.\n\n===Receiver does not need to be a full node===\n\nBecause the receiver needs to bump the fee to keep the same fee rate\nas the original PSBT, it needs the input's UTXO information to know\nwhat is the original fee rate. Without PSBT, light wallets like Wasabi\nWallet would not be able to receive a payjoin transaction.\n\nThe validation (policy and consensus) of the original transaction is\noptional: a receiver without a full node can decide to create the\npayjoin transaction and automatically broadcast the original\ntransaction after a timeout of 1 minute, and only verify that it has\nbeen propagated in the network.\n\nHowever, non-interactive receivers (like a payment processor) need to\nverify the transaction to prevent UTXO probing attacks.\n\nThis is not a concern for interactive receivers like Wasabi Wallet,\nbecause those receivers can just limit the number of original PSBT\nproposals of a specific address to one. With such wallets, the\nattacker has no way to generate new deposit addresses to probe the\nUTXOs.\n\n===Spare change donation===\n\nSmall change inside wallets are detrimental to privacy. Mixers like\nWasabi wallet, because of its protocol, eventually generate such\n[[https://docs.wasabiwallet.io/using-wasabi/ChangeCoins.html#first-round-coinjoin-change|small\nchange]].\n\nA common way to protect your privacy is to donate those spare changes,\nto deposit them in an exchange or on your favorite merchant's store\naccount. Those kind of transactions can easily be spotted on the\nblockchain: There is only one output.\n\nHowever, if you donate via payjoin, it will look like a normal transaction.\n\nOn top of this the receiver can poison analysis by randomly faking a\nround amount of satoshi for the additional output.\n\n===Payment output substitution===\n\nThe receiver is free to change the output paying to himself.\nFor example, if the sender's scriptPubKey type is P2WPKH while the\nreceiver's payment output in the original PSBT is P2SH, then the\nreceiver can substitute the payment output to be P2WPKH to match the\nsender's scriptPubKey type.\n\n===Impacted heuristics===\n\nOur proposal of payjoin is breaking the following blockchain heuristics:\n\n* Common inputs heuristics.\n\nBecause payjoin is mixing the inputs of the sender and receiver, this\nheuristic becomes unreliable.\n\n* Change identification from scriptPubKey type heuristics\n\nWhen Alice pays Bob, if Alice is using P2SH but Bob's deposit address\nis P2WPKH, the heuristic would assume that the P2SH output is the\nchange address of Alice.\nThis is now however a broken assumption, as the payjoin receiver has\nthe freedom to mislead analytics by purposefully changing the\ninvoice's address in the payjoin transaction.\n\nAlternatively, if the original address of Bob is P2WPKH and Alice's\naddress is also P2WPKH, Bob can change the receiving address in the\npayjoin to P2SH. The heuristic would wrongfully identify the payjoin's\nreceiving address as the change address of the transaction.\n\nSee payment output substitution above.\n\n* Change identification from round change amount\n\nIf Alice pays Bob, she might be tempted to pay him a round amount,\nlike <code>1.23000000 BTC</code>. When this happens, blockchain\nanalysis often identifies the output without the round amount as the\nchange of the transaction.\n\nFor this reason, during a [spare\nchange](Payjoin-spec.md#spare-change-donation) situation, we randomly\nround the amount in the output added by the receiver to the payjoin\ntransaction.\n\n==Attack vectors==\n\n===On the receiver side: UTXO probing attack===\n\nWhen the receiver creates a payjoin proposal, they expose one or more\ninputs belonging to them.\n\nAn attacker could create multiple original transactions in order to\nlearn the UTXOs of the receiver, while not broadcasting the payjoin\nproposal.\n\nWhile we cannot prevent this type of attack entirely, we implemented\nthe following mitigations:\n\n* When the receiver detects an original transaction being broadcast,\nor if the receiver detects that the original transaction has been\ndouble spent, then they will reuse the UTXO that was exposed for the\nnext payjoin.\n* While the exposed UTXO will be reused in priority to not leak other\nUTXOs, there is no strong guarantee about it. This prevents the\nattacker from detecting with certainty the next payjoin of the\nmerchant to another peer.\n\nNote that probing attacks are only a problem for automated payment\nsystems such as BTCPay Server. End-user wallets with payjoin\ncapabilities are not affected, as the attacker can't create multiple\ninvoices to force the receiver to expose their UTXOs.\n\n===On the sender side: Double payment risk for hardware wallets===\n\nFor a successful payjoin to happen, the sender needs to sign two\ntransactions double spending each other: The original transaction and\nthe payjoin proposal.\n\nThe sender's software wallet can verify that the payjoin proposal is\nlegitimate by the sender's checklist.\n\nHowever, a hardware wallet can't verify that this is indeed the case.\nThis means that the security guarantee of the hardware wallet is\ndecreased. If the sender's software is compromised, the hardware\nwallet would sign two valid transactions, thus sending two payments.\n\nWithout payjoin, the maximum amount of money that could be lost by a\ncompromised software is equal to one payment (via address\nsubstitution).\n\nWith payjoin, the maximum amount of money that can be lost is equal to\ntwo payments.\n\n==Implementations==\n\n* [[https://github.com/BlueWallet/BlueWallet|BlueWallet]] is in the\nprocess of implementing the protocol.\n* [[https://github.com/btcpayserver/btcpayserver|BTCPay Server]] has\nimplemented sender and receiver side of this protocol.\n* [[https://github.com/zkSNACKs/WalletWasabi/|Wasabi Wallet]] has\nmerged sender's support.\n* [[https://github.com/JoinMarket-Org/joinmarket-clientserver|Join\nMarket]] is in the process of implementing the protocol.\n* [[https://github.com/junderw/payjoin-client-js|JavaScript sender\nimplementation]].\n\n==Special thanks==\n\nSpecial thanks to Kukks for developing the initial support to BTCPay\nServer, to junderw, AdamISZ, lukechilds, ncoelho, nopara73, yahiheb\nfor all the feedback we received since our first implementation.\nThanks also to RHavar who wrote the\n[[https://github.com/bitcoin/bips/blob/master/bip-0079.mediawiki|BIP79\nBustapay]] proposal, this gave a good starting point for our proposal.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200517/b8701197/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP Number request for a simple payjoin proposal",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Nicolas Dorier"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 21231
        }
    },
    {
        "title": "[bitcoin-dev] hashcash-newhash",
        "thread_messages": [
            {
                "author": "Karl",
                "date": "2020-05-23T11:00:54",
                "message_text_only": "Hi,\n\nI'd like to revisit the discussion of the digest algorithm used in hashcash.\n\nI believe migrating to new hashing algorithms as a policy would\nsignificantly increase decentralization and hence security.\n\nI believe the impact on existing miners could be made pleasant by gradually\nmoving the block reward from the previous hash to the next (such that both\nare accepted with different rewards).  An appropriate rate could possibly\nbe calculated from the difficulty.\n\nYou could develop the frequency of introduction of new hashes such that\nonce present-day ASICs are effectively obsolete anyway due to competition,\nnew ones do not have time to develop.\n\nI'm interested in hearing thoughts and concerns.\n\nKarl Semich\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200523/624d6e42/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-24T01:12:04",
                "message_text_only": "Good morning Karl,\n\n> Hi,\n>\n> I'd like to revisit the discussion of the digest algorithm used in hashcash.\n>\n> I believe migrating to new hashing algorithms as a policy would significantly increase decentralization and hence security.\n\nWhy do you believe so?\n\nMy understanding is that there are effectively two strategies for ensuring decentralization based on hash algorithm:\n\n* Keep changing the hash algorithm to prevent development of ASICs and ensure commodity generic computation devices (GPUs) are the only practical target.\n* Do not change the algorithm, to ensure that knowledge of how best to implement an ASIC for the algorithm becomes spread out (through corporate espionage, ASIC reverse-engineering, patent expiry, and sheer engineering effort) and ASICs for the algorithm are as commoditized as GPUs.\n\nThe former strategy has the following practical disadvantages:\n\n* Developing new hash algorithms is not cheap.\n  The changes to the hashcash algorithm may need to occur faster than the speed at which we can practically develop new, cryptographically-secure hash algorithms.\n* It requires coordinated hardforks over the entire network at an alarmingly high rate.\n* It arguably puts too much power to the developers of the code.\n\nOn the other hand, the latter strategy requires us only to survive an intermediate period where ASICs are developed, but not yet commoditized; and during this intermediate period, the centralization pressure of ASICs might not be more powerful than other centralization pressures\n\n--\n\nWhich brings us to another point.\n\nNon-ASIC-resistance is, by my understanding, a non-issue.\n\nRegardless of whether the most efficient available computing substrate for the hashcash algorithm is CPU, GPU, or ASIC, ultimately miner earnings are determined by cost of power supply.\n\nEven if you imagine that changing the hashcash algorithm would make CPUs practical again, you will still not run it on the CPU of a mobile, because a mobile runs on battery, and charging a battery takes more power than what you can extract from the battery afterwards, because thermodynamics.\n\nSimilarly, geographic locations with significant costs of electrical power will still not be practical places to start a mine, regardless if the mine is composed of commodity server racks, commodity video cards, or commodity ASICs.\n\nIf you want to solve the issue of miner centralization, the real solution is improving the efficiency of energy transfer to increase the areas where cheap energy is available, not stopgap change-the-algorithm-every-6-months.\n\n\nRegards,\nZmnSCPxj\n\n\n>\n> I believe the impact on existing miners could be made pleasant by gradually moving the block reward from the previous hash to the next (such that both are accepted with different rewards).\u00a0 An appropriate rate could possibly be calculated from the difficulty.\n>\n> You could develop the frequency of introduction of new hashes such that once present-day ASICs are effectively obsolete anyway due to competition, new ones do not have time to develop.\n>\n> I'm interested in hearing thoughts and concerns.\n>\n> Karl Semich"
            },
            {
                "author": "Karl",
                "date": "2020-05-24T09:02:59",
                "message_text_only": "Hi ZmnSCPxj,\n\nThanks for your reply.  I'm on mobile so please excuse me for top-posting.\n\nI'd like to sort these various points out.  Maybe we won't finish the whole\ndiscussion, but maybe at least we can update wiki articles like\nhttps://en.bitcoin.it/wiki/Hashcash#Cryptanalytic_Risks with more points or\na link to conversations like this.\n\nEverything is possible but some things take a lot of work.\n\nYou mention ASICs becoming commoditized.  I'd remind you that eventually\nthere will be a public mathematical breaking of the algorithm, at which\npoint all ASICs will become obsolete regardless.  Would you agree it would\nbe better to prepare for this by planning algorithm change?\n\nYou mention many coordinated hardforks.  Would you agree that if we came up\nwith a way of programmatically cycling the algorithm, that only one\nhardfork work be needed?  For example one could ask nodes to consent to new\nalgorithm code written in a simple scripting language, and reject old ones\nslowly enough to provide for new research.\n\nYou mention the cost of power as the major factor influencing decentralized\nmining.  Would you agree that access to hardware that can do the mining is\nan equally large factor?  Even without ASICs you would need the physical\ncycles.  Including this factor helps us discuss the same set of expected\nsituations.\n\nYou describe improving electricity availability in expensive areas as a way\nto improve decentralization.  Honestly this sounds out of place to me and\nI'm sorry if I've upset you by rehashing this old topic.  I believe this\nlist is for discussing the design of software, not international energy\ninfrastructure: what is the relation?  There is a lot of power to influence\nbehavior here but I thought the tools present are software design.\n\nOn Sat, May 23, 2020, 9:12 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Karl,\n>\n> > Hi,\n> >\n> > I'd like to revisit the discussion of the digest algorithm used in\n> hashcash.\n> >\n> > I believe migrating to new hashing algorithms as a policy would\n> significantly increase decentralization and hence security.\n>\n> Why do you believe so?\n>\n> My understanding is that there are effectively two strategies for ensuring\n> decentralization based on hash algorithm:\n>\n> * Keep changing the hash algorithm to prevent development of ASICs and\n> ensure commodity generic computation devices (GPUs) are the only practical\n> target.\n> * Do not change the algorithm, to ensure that knowledge of how best to\n> implement an ASIC for the algorithm becomes spread out (through corporate\n> espionage, ASIC reverse-engineering, patent expiry, and sheer engineering\n> effort) and ASICs for the algorithm are as commoditized as GPUs.\n>\n> The former strategy has the following practical disadvantages:\n>\n> * Developing new hash algorithms is not cheap.\n>   The changes to the hashcash algorithm may need to occur faster than the\n> speed at which we can practically develop new, cryptographically-secure\n> hash algorithms.\n> * It requires coordinated hardforks over the entire network at an\n> alarmingly high rate.\n> * It arguably puts too much power to the developers of the code.\n>\n> On the other hand, the latter strategy requires us only to survive an\n> intermediate period where ASICs are developed, but not yet commoditized;\n> and during this intermediate period, the centralization pressure of ASICs\n> might not be more powerful than other centralization pressures\n>\n> --\n>\n> Which brings us to another point.\n>\n> Non-ASIC-resistance is, by my understanding, a non-issue.\n>\n> Regardless of whether the most efficient available computing substrate for\n> the hashcash algorithm is CPU, GPU, or ASIC, ultimately miner earnings are\n> determined by cost of power supply.\n>\n> Even if you imagine that changing the hashcash algorithm would make CPUs\n> practical again, you will still not run it on the CPU of a mobile, because\n> a mobile runs on battery, and charging a battery takes more power than what\n> you can extract from the battery afterwards, because thermodynamics.\n>\n> Similarly, geographic locations with significant costs of electrical power\n> will still not be practical places to start a mine, regardless if the mine\n> is composed of commodity server racks, commodity video cards, or commodity\n> ASICs.\n>\n> If you want to solve the issue of miner centralization, the real solution\n> is improving the efficiency of energy transfer to increase the areas where\n> cheap energy is available, not stopgap change-the-algorithm-every-6-months.\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> >\n> > I believe the impact on existing miners could be made pleasant by\n> gradually moving the block reward from the previous hash to the next (such\n> that both are accepted with different rewards).  An appropriate rate could\n> possibly be calculated from the difficulty.\n> >\n> > You could develop the frequency of introduction of new hashes such that\n> once present-day ASICs are effectively obsolete anyway due to competition,\n> new ones do not have time to develop.\n> >\n> > I'm interested in hearing thoughts and concerns.\n> >\n> > Karl Semich\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200524/3d22a130/attachment-0001.html>"
            },
            {
                "author": "Ariel Lorenzo-Luaces",
                "date": "2020-05-24T23:51:10",
                "message_text_only": "On May 24, 2020, 1:26 PM, at 1:26 PM, Karl via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>Hi ZmnSCPxj,\n>\n>Thanks for your reply.  I'm on mobile so please excuse me for\n>top-posting.\n>\n>I'd like to sort these various points out.  Maybe we won't finish the\n>whole\n>discussion, but maybe at least we can update wiki articles like\n>https://en.bitcoin.it/wiki/Hashcash#Cryptanalytic_Risks with more\n>points or\n>a link to conversations like this.\n>\n>Everything is possible but some things take a lot of work.\n>\n>You mention ASICs becoming commoditized.  I'd remind you that\n>eventually\n>there will be a public mathematical breaking of the algorithm, at which\n>point all ASICs will become obsolete regardless.  Would you agree it\n>would\n>be better to prepare for this by planning algorithm change?\n>\n>You mention many coordinated hardforks.  Would you agree that if we\n>came up\n>with a way of programmatically cycling the algorithm, that only one\n>hardfork work be needed?  For example one could ask nodes to consent to\n>new\n>algorithm code written in a simple scripting language, and reject old\n>ones\n>slowly enough to provide for new research.\n>\n>You mention the cost of power as the major factor influencing\n>decentralized\n>mining.  Would you agree that access to hardware that can do the mining\n>is\n>an equally large factor?  Even without ASICs you would need the\n>physical\n>cycles.  Including this factor helps us discuss the same set of\n>expected\n>situations.\n>\n>You describe improving electricity availability in expensive areas as a\n>way\n>to improve decentralization.  Honestly this sounds out of place to me\n>and\n>I'm sorry if I've upset you by rehashing this old topic.  I believe\n>this\n>list is for discussing the design of software, not international energy\n>infrastructure: what is the relation?  There is a lot of power to\n>influence\n>behavior here but I thought the tools present are software design.\n>\n>On Sat, May 23, 2020, 9:12 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n>> Good morning Karl,\n>>\n>> > Hi,\n>> >\n>> > I'd like to revisit the discussion of the digest algorithm used in\n>> hashcash.\n>> >\n>> > I believe migrating to new hashing algorithms as a policy would\n>> significantly increase decentralization and hence security.\n>>\n>> Why do you believe so?\n>>\n>> My understanding is that there are effectively two strategies for\n>ensuring\n>> decentralization based on hash algorithm:\n>>\n>> * Keep changing the hash algorithm to prevent development of ASICs\n>and\n>> ensure commodity generic computation devices (GPUs) are the only\n>practical\n>> target.\n>> * Do not change the algorithm, to ensure that knowledge of how best\n>to\n>> implement an ASIC for the algorithm becomes spread out (through\n>corporate\n>> espionage, ASIC reverse-engineering, patent expiry, and sheer\n>engineering\n>> effort) and ASICs for the algorithm are as commoditized as GPUs.\n>>\n>> The former strategy has the following practical disadvantages:\n>>\n>> * Developing new hash algorithms is not cheap.\n>>   The changes to the hashcash algorithm may need to occur faster than\n>the\n>> speed at which we can practically develop new,\n>cryptographically-secure\n>> hash algorithms.\n>> * It requires coordinated hardforks over the entire network at an\n>> alarmingly high rate.\n>> * It arguably puts too much power to the developers of the code.\n>>\n>> On the other hand, the latter strategy requires us only to survive an\n>> intermediate period where ASICs are developed, but not yet\n>commoditized;\n>> and during this intermediate period, the centralization pressure of\n>ASICs\n>> might not be more powerful than other centralization pressures\n>>\n>> --\n>>\n>> Which brings us to another point.\n>>\n>> Non-ASIC-resistance is, by my understanding, a non-issue.\n>>\n>> Regardless of whether the most efficient available computing\n>substrate for\n>> the hashcash algorithm is CPU, GPU, or ASIC, ultimately miner\n>earnings are\n>> determined by cost of power supply.\n>>\n>> Even if you imagine that changing the hashcash algorithm would make\n>CPUs\n>> practical again, you will still not run it on the CPU of a mobile,\n>because\n>> a mobile runs on battery, and charging a battery takes more power\n>than what\n>> you can extract from the battery afterwards, because thermodynamics.\n>>\n>> Similarly, geographic locations with significant costs of electrical\n>power\n>> will still not be practical places to start a mine, regardless if the\n>mine\n>> is composed of commodity server racks, commodity video cards, or\n>commodity\n>> ASICs.\n>>\n>> If you want to solve the issue of miner centralization, the real\n>solution\n>> is improving the efficiency of energy transfer to increase the areas\n>where\n>> cheap energy is available, not stopgap\n>change-the-algorithm-every-6-months.\n>>\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>>\n>> >\n>> > I believe the impact on existing miners could be made pleasant by\n>> gradually moving the block reward from the previous hash to the next\n>(such\n>> that both are accepted with different rewards).  An appropriate rate\n>could\n>> possibly be calculated from the difficulty.\n>> >\n>> > You could develop the frequency of introduction of new hashes such\n>that\n>> once present-day ASICs are effectively obsolete anyway due to\n>competition,\n>> new ones do not have time to develop.\n>> >\n>> > I'm interested in hearing thoughts and concerns.\n>> >\n>> > Karl Semich\n>>\n>>\n>>\n>\n>\n>------------------------------------------------------------------------\n>\n>_______________________________________________\n>bitcoin-dev mailing list\n>bitcoin-dev at lists.linuxfoundation.org\n>https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200524/eac5b865/attachment-0001.html>"
            },
            {
                "author": "Karl",
                "date": "2020-05-25T07:03:20",
                "message_text_only": "Hi Ariel,\n\nThanks for your reply.\n\nYou state that once \"the entire world\" can quickly find a hash that it then\n\"needs to be changed\", but that that \"won't happen in a day\".\n\nIt sounds like you believe compromise of the algorithm as a concern\nprovides a _lot_ of time to migrate to a new hash function, and that it is\nindeed important to do so when it becomes needed.\n\nLet's talk about relaxing the time scale.  Making such plans seems more\nimportant than agreeing on how soon they happen.  It's possible it could be\ndecades before having a new hash is actually needed to protect financial\nsecurity.  Who knows.\n\nHow does that land?  Is the idea more available with a looser time scale?\n\nIt seems to me with ongoing cryptanalysis research, new things like quantum\ncomputers, conventional computer hardware always advancing, that some day\nfar in the future it will be easy to find an sha256 preimage on a personal\ndevice, somehow.\n\nLet's improve the security of the blockchain.\n\nOn Sun, May 24, 2020, 7:51 PM Ariel Lorenzo-Luaces <arielluaces at gmail.com>\nwrote:\n\n> On May 24, 2020, at 1:26 PM, Karl via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> You mention ASICs becoming commoditized.  I'd remind you that eventually\n>> there will be a public mathematical breaking of the algorithm, at which\n>> point all ASICs will become obsolete regardless.  Would you agree it would\n>> be better to prepare for this by planning algorithm change?\n>>\n>> Cryptographic algorithms don't usually break this way. In the case of\n>> hash functions it may be possible to find an exploit that reduces the\n>> function's security from 256 bits to 128 for example. So an algorithm that\n>> could find 80 zero bits per energy unit before can now find 160 zero bits\n>> per energy unit with an exploit.\n>>\n>> If this exploit can be deployed as a software patch to most ASICs then\n>> the issue will sort itself out on the next difficulty adjustment.\n>>\n>> If the exploit instead requires an entirely new ASIC then GPUs and FPGAs\n>> that could previously find 40 zero bits per energy unit can now compete\n>> with the less adaptive ASICs until new ASICs that use the exploit start\n>> getting produced and shipped.\n>>\n>> There's never any official \"public breaking\" of a hash function. The\n>> function will just loose security over time until it's deemed to not be\n>> \"secure enough\" for certain applications. Thankfully mining is an\n>> application where the only important thing is that the difficulty can be\n>> increased. In other words, if the entire world can consistently find 256\n>> zero bits of SHA-256 in under 10 minutes then definitely the hash function\n>> needs to be changed. But this won't happen in a day.\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200525/fa218d9f/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-24T16:51:36",
                "message_text_only": "Good morning Kari,\n\n\n> You mention ASICs becoming commoditized.\u00a0 I'd remind you that eventually there will be a public mathematical breaking of the algorithm, at which point all ASICs will become obsolete regardless.\u00a0 Would you agree it would be better to prepare for this by planning algorithm change?\n\nPossibly, but then the reason for change is no longer to promote decentralization, would it?\nIt helps to be clear about what your goals are, because any chosen solution might not be the best way to fix it.\nI admit that, if the problem were to be avoid the inevitable obsoletion of SHA-2, then this is the only solution, but that is not the problem you stated you were trying to solve in the first place.\n\n>\n> You mention many coordinated hardforks.\u00a0 Would you agree that if we came up with a way of programmatically cycling the algorithm, that only one hardfork work be needed?\u00a0 For example one could ask nodes to consent to new algorithm code written in a simple scripting language, and reject old ones slowly enough to provide for new research.\n\nEven *with* a scripting language, the issue is still what code written in that language is accepted, and *how*.\n\nDo miners vote on a new script describing the new hashing algorithm?\nWhat would their incentive be to obsolete their existing hardware?\n(using proof-of-work to lock in a hashing change feels very much like a chicken-and-egg problem: the censorship-resistance provided by Bitcoin is based on evicting any censors by overpowering their hashpower, but requires some method of measuring that hashpower: it seems unlikely that you can safely change the way hashpower is measured via a hashpower election)\n\nDo nodes install particular scripts and impose a switchover schedule of some sort?\nThen how is that different from a hardfork, especially for nodes that do not update?\n(notice that softforks allow nodes to remain non-updated, at degraded security, but still in sync with the rest of the network and capable of transacting with them)\n\n>\n> You mention the cost of power as the major factor influencing decentralized mining.\u00a0 Would you agree that access to hardware that can do the mining is an equally large factor?\u00a0 Even without ASICs you would need the physical cycles.\u00a0 Including this factor helps us discuss the same set of expected situations.\n\nNo, because anyone who is capable of selling hardware, or the expertise to design and build it, can earn by taking advantage of their particular expertise.\n\nGenerally, such experts can saturate the locally-available energy sources, until local capacity has been saturated, and they can earn even more by selling extra hardware to entities located at other energy sources whose local capacities are not still underutilized, or expanding themselves to those sources.\nOther entities might be in better position to take advantage of particular local details, and it may be more lucrative for the expert-at-building-hardware to just sell the hardware to them than to attempt to expand in places where they have little local expertise.\n\nAnd expertise is easy to copy, it is only the initial expertise that is hard to create in the first place, once knowledge is written down it can be copied.\n\n>\n> You describe improving electricity availability in expensive areas as a way to improve decentralization.\u00a0 Honestly this sounds out of place to me and I'm sorry if I've upset you by rehashing this old topic.\u00a0 I believe this list is for discussing the design of software, not international energy infrastructure: what is the relation?\u00a0 There is a lot of power to influence behavior here but I thought the tools present are software design.\n\nI doubt there is any good software-only solution to the problem; the physical world remains the basis of the virtual one, and the virtual utterly dependent on the physical, and abstractions are always leaky (any non-toy software framework inevitably gains a way to query the operating system the application is running under, because abstractions inevitably leak): and energy, or the lack thereof, is the hardest to abstract away, which is the entire point of using proof-of-work as a reliable, unfakeable (i.e. difficult to virtualize) clock in the first place.\n\nStill, feel free to try: perhaps you might succeed.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Karl",
                "date": "2020-05-24T19:50:12",
                "message_text_only": "Good afternoon ZmnSCPxj,\n\nThanks for holding your end of this discussion with me.\n\nSorry I am so verbose; I am still learning to communicate efficiently.\n\n> You mention ASICs becoming commoditized.  I'd remind you that eventually\n> there will be a public mathematical breaking of the algorithm, at which\n> point all ASICs will become obsolete regardless.  Would you agree it would\n> be better to prepare for this by planning algorithm change?\n>\n> Possibly, but then the reason for change is no longer to promote\n> decentralization, would it?\n\nIt helps to be clear about what your goals are, because any chosen solution\n> might not be the best way to fix it.\n> I admit that, if the problem were to be avoid the inevitable obsoletion of\n> SHA-2, then this is the only solution, but that is not the problem you\n> stated you were trying to solve in the first place.\n>\n\nTo be up front, the reason for decentralization is due to concern around\nthe security of the hashing.  Having a public breakage of the function\nsimply makes the urgency obvious.\n\nReddit claims two entities controlled 62% of the hashrate recently:\nhttps://old.reddit.com/r/CryptoCurrency/comments/gmhuon/in_the_last_24_hours_bitcoins_nakamoto/\n.  Compromising the systems of these two groups seems like it is all that\nis needed to compromise the entire blockchain (to the limited degree a 51%\nattack does).\n\nHence I see decentralization and cryptanalysis of the algorithm to be\nroughly similar security concerns.\n\nIt sounds like you agree that a change of algorithm is needed before the\ncurrent one is publicly broken.\n\n>\n> > You mention many coordinated hardforks.  Would you agree that if we came\n> up with a way of programmatically cycling the algorithm, that only one\n> hardfork work be needed?  For example one could ask nodes to consent to new\n> algorithm code written in a simple scripting language, and reject old ones\n> slowly enough to provide for new research.\n>\n> Even *with* a scripting language, the issue is still what code written in\n> that language is accepted, and *how*.\n>\n> Do miners vote on a new script describing the new hashing algorithm?\n> What would their incentive be to obsolete their existing hardware?\n> (using proof-of-work to lock in a hashing change feels very much like a\n> chicken-and-egg problem: the censorship-resistance provided by Bitcoin is\n> based on evicting any censors by overpowering their hashpower, but requires\n> some method of measuring that hashpower: it seems unlikely that you can\n> safely change the way hashpower is measured via a hashpower election)\n>\n> Do nodes install particular scripts and impose a switchover schedule of\n> some sort?\n> Then how is that different from a hardfork, especially for nodes that do\n> not update?\n> (notice that softforks allow nodes to remain non-updated, at degraded\n> security, but still in sync with the rest of the network and capable of\n> transacting with them)\n\n\nI'm expressing that in considering this we have two options: repeated hard\nforks or making repeated change a part of the protocol.  There are many\nways to approach or implement it.  It sounds like you're noting that the\nsecond option takes some work and care?\n\nWould it be helpful if I outlined more ideas that address your concerns?  I\nwant to make sure the idea of changing the algorithm is acceptable at all\nfirst.\n\n> You mention the cost of power as the major factor influencing\n> decentralized mining.  Would you agree that access to hardware that can do\n> the mining is an equally large factor?  Even without ASICs you would need\n> the physical cycles.  Including this factor helps us discuss the same set\n> of expected situations.\n>\n> No, because anyone who is capable of selling hardware, or the expertise to\n> design and build it, can earn by taking advantage of their particular\n> expertise.\n>\n> Generally, such experts can saturate the locally-available energy sources,\n> until local capacity has been saturated, and they can earn even more by\n> selling extra hardware to entities located at other energy sources whose\n> local capacities are not still underutilized, or expanding themselves to\n> those sources.\n> Other entities might be in better position to take advantage of particular\n> local details, and it may be more lucrative for the\n> expert-at-building-hardware to just sell the hardware to them than to\n> attempt to expand in places where they have little local expertise.\n>\n\nIt sounds like you are saying that the supply of electricity is exhausted\nand the supply of hardware is not.\n\nIs that correct?\n\nI've seen that most of the time mining hardware distributors are sold out\nof their top-of-the-line mining equipment, mostly selling in preorders.\nAre implying most of the mining is done by privately built equipment?\n\nWould you agree that an increase in the price of bitcoin would make the\navailability of hardware matter much more, because the price of electricity\nwould matter much less?\n\nSomething to raise here is that all of these things take time and respond\nin ebbs and flows.  If there were to be a plan to migrate to a new\nalgorithm, it would be participating in those ebbs and flows.\n\nIt takes time to build new hardware, and it takes time for the difficulty\nto adjust to obsolete it.  What do you see as influencing how fast hardware\nbecomes obsolete?\n\nI ask these questions because the answers relate to how what ways would be\ngood to change the mining function to increase decentralization.\n\nAnd expertise is easy to copy, it is only the initial expertise that is\n> hard to create in the first place, once knowledge is written down it can be\n> copied.\n>\n\nAlso takes measurable months to do.\n\n> You describe improving electricity availability in expensive areas as a\n> way to improve decentralization.  Honestly this sounds out of place to me\n> and I'm sorry if I've upset you by rehashing this old topic.  I believe\n> this list is for discussing the design of software, not international\n> energy infrastructure: what is the relation?  There is a lot of power to\n> influence behavior here but I thought the tools present are software design.\n>\n> I doubt there is any good software-only solution to the problem; the\n> physical world remains the basis of the virtual one, and the virtual\n> utterly dependent on the physical, and abstractions are always leaky (any\n> non-toy software framework inevitably gains a way to query the operating\n> system the application is running under, because abstractions inevitably\n> leak): and energy, or the lack thereof, is the hardest to abstract away,\n> which is the entire point of using proof-of-work as a reliable, unfakeable\n> (i.e. difficult to virtualize) clock in the first place.\n>\n> Still, feel free to try: perhaps you might succeed.\n\n\nYou agreed earlier that changing the algorithm would increase\ndecentralization, but expressed other concerns with the idea.  Many more\ngeneral solutions are working in many altcoins.  I'm interested in\ndiscussing changing the proof of work algorithm in bitcoin.\n\nMy motivation is security of the blockchain, which is partially held by\ndecentralization.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200524/19f12740/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-25T07:58:19",
                "message_text_only": "Good morning Kari,\n\n\n> > > You mention ASICs becoming commoditized.\u00a0 I'd remind you that eventually there will be a public mathematical breaking of the algorithm, at which point all ASICs will become obsolete regardless.\u00a0 Would you agree it would be better to prepare for this by planning algorithm change?\n> >\n> > Possibly, but then the reason for change is no longer to promote decentralization, would it?\n>\n> > It helps to be clear about what your goals are, because any chosen solution might not be the best way to fix it.\n> > I admit that, if the problem were to be avoid the inevitable obsoletion of SHA-2, then this is the only solution, but that is not the problem you stated you were trying to solve in the first place.\n>\n> To be up front, the reason for decentralization is due to concern around the security of the hashing.\u00a0 Having a public breakage of the function simply makes the urgency obvious.\n\nNow that I have thought about it more: again, the important thing about the proof-of-work technique is not so much the algorithm itself, only that executing it requires energy.\n\nAnd all algorithms require energy in order to execute.\n\nEven if some technique is found which partially breaks the hash function and allows faster generation of hashes for the amount of energy consumed, this is not a problem for mining itself: the difficulty adjusts and mining continues.\nThe execution of this technique is unlikely to require no computation, only reduced computational effort; and all that is needed is *some* measure of computational effort done, the *scale* of that measure is not really material for the purpose of ordering atomic transactional updates to the UTXO set.\n\nOf course, things like the Merkle tree and txids and so on would need changing in case of even a partial break of the hash function, which would require a hardfork to survive; you might as well change the proof-of-work function as well then.\n\n>\n> Reddit claims two entities controlled 62% of the hashrate recently:\u00a0https://old.reddit.com/r/CryptoCurrency/comments/gmhuon/in_the_last_24_hours_bitcoins_nakamoto/ .\u00a0 Compromising the systems of these two groups seems like it is all that is needed to compromise the entire blockchain (to the limited degree a 51% attack does).\n\nYou seem to be equating \"break of the hash function\" with \"centralization of hashrate\", which I do not quite agree with.\n\nMost human beings cannot think without constant communication with other human beings.\nThus, it is unlikely that a private break of the hash function is possible.\nInstead, a break of the hash function is likely to be discovered in various ways by multiple human beings who have been communicating with each other.\n\nEven historically, inventions never arose fully-formed from the head of the inventor, like Athena from the brow of Zeus; every invention has predecessors, successors, and peers in the inhabited milieu.\n\n\nInstead, you can look up the costs of local electricity globally, and notice where those entities have their largest mines geographically located.\n\n\n>\n> Hence I see decentralization and cryptanalysis of the algorithm to be roughly similar security concerns.\n>\n> It sounds like you agree that a change of algorithm is needed before the current one is publicly broken.\n>\n> > > You mention many coordinated hardforks.\u00a0 Would you agree that if we came up with a way of programmatically cycling the algorithm, that only one hardfork work be needed?\u00a0 For example one could ask nodes to consent to new algorithm code written in a simple scripting language, and reject old ones slowly enough to provide for new research.\n> >\n> > Even *with* a scripting language, the issue is still what code written in that language is accepted, and *how*.\n> >\n> > Do miners vote on a new script describing the new hashing algorithm?\n> > What would their incentive be to obsolete their existing hardware?\n> > (using proof-of-work to lock in a hashing change feels very much like a chicken-and-egg problem: the censorship-resistance provided by Bitcoin is based on evicting any censors by overpowering their hashpower, but requires some method of measuring that hashpower: it seems unlikely that you can safely change the way hashpower is measured via a hashpower election)\n> >\n> > Do nodes install particular scripts and impose a switchover schedule of some sort?\n> > Then how is that different from a hardfork, especially for nodes that do not update?\n> > (notice that softforks allow nodes to remain non-updated, at degraded security, but still in sync with the rest of the network and capable of transacting with them)\n>\n> I'm expressing that in considering this we have two options: repeated hard forks or making repeated change a part of the protocol.\u00a0 There are many ways to approach or implement it.\u00a0 It sounds like you're noting that the second option takes some work and care?\n>\n> Would it be helpful if I outlined more ideas that address your concerns?\u00a0 I want to make sure the idea of changing the algorithm is acceptable at all first.\n\nGo ahead.\n\n>\n> > > You mention the cost of power as the major factor influencing decentralized mining.\u00a0 Would you agree that access to hardware that can do the mining is an equally large factor?\u00a0 Even without ASICs you would need the physical cycles.\u00a0 Including this factor helps us discuss the same set of expected situations.\n> >\n> > No, because anyone who is capable of selling hardware, or the expertise to design and build it, can earn by taking advantage of their particular expertise.\n> >\n> > Generally, such experts can saturate the locally-available energy sources, until local capacity has been saturated, and they can earn even more by selling extra hardware to entities located at other energy sources whose local capacities are not still underutilized, or expanding themselves to those sources.\n> > Other entities might be in better position to take advantage of particular local details, and it may be more lucrative for the expert-at-building-hardware to just sell the hardware to them than to attempt to expand in places where they have little local expertise.\n>\n> It sounds like you are saying that the supply of electricity is exhausted and the supply of hardware is not.\n>\n> Is that correct?\n\nGiven that electricity is consumed very quickly, and hardware takes a long time to truly consume or obsolete, yes: rate of consumption of electricity is expected to dominate compared to the rate of consumption of hardware.\n\n>\n> I've seen that most of the time mining hardware distributors are sold out of their top-of-the-line mining equipment, mostly selling in preorders.\u00a0 Are implying most of the mining is done by privately built equipment?\n\nIt seems the most lucrative thing to do, that if you have a new generation of hardware, to mine with them yourself, until the price of local electricity has increased due to your consumption, and it becomes more lucrative to sell the hardware to other potential miners who now have lower electricity prices compared to yours (because you have been saturating the local electricity supply with your own mining operations and causing the local prices to rise up, or equivalently, until some governmental or other limits your usable electricity supply, which is equivalent to saying that the price of even more electricity would be your incarceration or other punishment, which might be too expensive for you to pay, thus selling the hardware is more lucrative).\n\nI have no evidence to back this, thus it is not a claim to truth, only a claim to economic logic, if we assume that mining hardware manufacturers are economically rational, are interested only in the selfish gain of economic power, etc. etc.\nReal human beings and the entities they build may not behave in such a perfectly rational manner, or I may be assuming details that are not accurate to reality.\n\n>\n> Would you agree that an increase in the price of bitcoin would make the availability of hardware matter much more, because the price of electricity would matter much less?\n\nElectricity is a factor with every piece of hardware that is utilized, so any increase in hardware will also have an increase in electricity consumed.\nSo I expect that the materiality of the price of electricity will increase in lockstep with the materiality of the price of hardware (note that price is simply demand over supply, and supply is the availability of hardware).\n\nYou could also analyze the transient economic behaviors here, specifically that an increase in Bitcoin price makes it more lucrative to mine in more places, which would start to put in orders for more hardware, and the hardware will take time to deliver, so the price at those places will increase only after a long while, etc.\nBut those are transient changes, and by the time any change at the software level is coordinated, the transient economic behaviors may have resettled to the expected long-term behavior: humans operate at around the same average speed in many different fields.\n\n>\n> Something to raise here is that all of these things take time and respond in ebbs and flows.\u00a0 If there were to be a plan to migrate to a new algorithm, it would be participating in those ebbs and flows.\n\nThe usual engineering response is to create buffers to be resilient against ebbs and flows.\nNote how we prefer to dam water supplies (i.e. create a buffer) rather than adjust our water consumption dynamically according to the ebb and flow of the water supply.\n\nSimilarly, economic contracts like futures and options are economic buffers against the ebb and flow of local supply of various materials.\n\nWithin Bitcoin, my understanding is that the difficulty adjustment system acts as a buffer against transient ebbs and flows of the supply of hashpower.\n\n> It takes time to build new hardware, and it takes time for the difficulty to adjust to obsolete it.\u00a0 What do you see as influencing how fast hardware becomes obsolete?\n\nIn the long run?\nWe will run out of ideas of how to improve the implementation of the hashing function, and there will be only a few designs that implement all the known ideas for optimizing the implementation.\nThen hardware becomes obsolete from normal wear and tear, e.g. electromigration, and that takes years to take effect.\n\n>\n> I ask these questions because the answers relate to how what ways would be good to change the mining function to increase decentralization.\n>\n> > And expertise is easy to copy, it is only the initial expertise that is hard to create in the first place, once knowledge is written down it can be copied.\n>\n> Also takes measurable months to do.\n\nBut can be massively parallelized, you can have a teacher or mentor teaching an entire classroom of students, and created lectures can be stored and re-given to many students, in the form of books, videos, etc.\nHuman beings have been doing this since time immemorial, and possibly before recorded history, in such things as oral traditions and so on.\n\n>\n> > > You describe improving electricity availability in expensive areas as a way to improve decentralization.\u00a0 Honestly this sounds out of place to me and I'm sorry if I've upset you by rehashing this old topic.\u00a0 I believe this list is for discussing the design of software, not international energy infrastructure: what is the relation?\u00a0 There is a lot of power to influence behavior here but I thought the tools present are software design.\n> >\n> > I doubt there is any good software-only solution to the problem; the physical world remains the basis of the virtual one, and the virtual utterly dependent on the physical, and abstractions are always leaky (any non-toy software framework inevitably gains a way to query the operating system the application is running under, because abstractions inevitably leak): and energy, or the lack thereof, is the hardest to abstract away, which is the entire point of using proof-of-work as a reliable, unfakeable (i.e. difficult to virtualize) clock in the first place.\n> >\n> > Still, feel free to try: perhaps you might succeed.\n>\n> You agreed earlier that changing the algorithm would increase decentralization, but expressed other concerns with the idea.\u00a0 Many more general solutions are working in many altcoins.\u00a0 I'm interested in discussing changing the proof of work algorithm in bitcoin.\n\nI did not so agree: in particular, I do not agree with equating a break of the proof-of-work algorithm with centralization.\nMore likely, any centralization seen is due to local government interference in economic matters, such as creating a local artificial oversupply of electricity by paying for electricity generation using taxes.\n\n>\n> My motivation is security of the blockchain, which is partially held by decentralization.\n\nLet us be more precise and avoid the word \"security\".\n\nMiner decentralization supports censorship-resistance, so your motivation is censorship-resistance (is that correct?).\n\nUltimately, what really protects censorship-resistance is not the details of the hashing algorithm, it is the economics involved.\nIn order to evict a censor, hashpower must be brought to bear against the censor.\nAnd that hashpower has to be bought and paid for.\nThe mechanism for doing this already exists, and is called the \"mining fee\" (note that the block subsidy does not protect against the censor, as the censor gets the block reward as well; what the censor cannot get is the fees attached to a transaction that the censor does not want published).\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Karl",
                "date": "2020-05-25T11:54:58",
                "message_text_only": "Hi ZmnSCPxj,\n\nWe have been addressing many concepts.  Let's try to slowly trim it down\nfor simplicity.\n\n> Reddit claims two entities controlled 62% of the hashrate recently:\n> https://old.reddit.com/r/CryptoCurrency/comments/gmhuon/in_the_last_24_hours_bitcoins_nakamoto/\n> .  Compromising the systems of these two groups seems like it is all that\n> is needed to compromise the entire blockchain (to the limited degree a 51%\n> attack does).\n>\n> You seem to be equating \"break of the hash function\" with \"centralization\n> of hashrate\", which I do not quite agree with.\n>\n\nI am trying to say that both of these different things result in danger to\nthe integrity of the transaction log, which would be reduced by changing\nthe hash function.  They both have those 2 similarities.\n\nMost human beings cannot think without constant communication with other\n> human beings.\n\nThus, it is unlikely that a private break of the hash function is possible.\n>\n\nI disagree with you here: Andrew Wiles solved Fermat's Last Theorem in\nisolation, academic research paper culture supports researching and then\npublishing once you have privately developed results, and the CVE database\nhas 136k system vulnerabilities that were developed and shared privately\nbefore public release, to prevent chaos.  This shows private advances in\nways to produce bitcoins are likely.\n\n> Would it be helpful if I outlined more ideas that address your concerns?\n> I want to make sure the idea of changing the algorithm is acceptable at all\n> first.\n>\n> Go ahead.\n>\n\nThanks: are you saying you would support changes if they addressed the\nconcerns you've listed?  Or are those concerns only the tip of the iceberg,\nper se?\n\n> > > You mention the cost of power as the major factor influencing\n> decentralized mining.  Would you agree that access to hardware that can do\n> the mining is an equally large factor?  Even without ASICs you would need\n> the physical cycles.  Including this factor helps us discuss the same set\n> of expected situations.\n> > >\n> > > No, because anyone who is capable of selling hardware, or the\n> expertise to design and build it, can earn by taking advantage of their\n> particular expertise.\n> > >\n> > > Generally, such experts can saturate the locally-available energy\n> sources, until local capacity has been saturated, and they can earn even\n> more by selling extra hardware to entities located at other energy sources\n> whose local capacities are not still underutilized, or expanding themselves\n> to those sources.\n> > > Other entities might be in better position to take advantage of\n> particular local details, and it may be more lucrative for the\n> expert-at-building-hardware to just sell the hardware to them than to\n> attempt to expand in places where they have little local expertise.\n> >\n> > It sounds like you are saying that the supply of electricity is\n> exhausted and the supply of hardware is not.\n> >\n> > Is that correct?\n>\n> Given that electricity is consumed very quickly, and hardware takes a long\n> time to truly consume or obsolete, yes: rate of consumption of electricity\n> is expected to dominate compared to the rate of consumption of hardware.\n>\n\nI'm considering short-term obsolescence here.  Since hashrate rises\nexponentially, only top-of-the-line hardware is competitively profitable.\n\n> I've seen that most of the time mining hardware distributors are sold out\n> of their top-of-the-line mining equipment, mostly selling in preorders.\n> Are implying most of the mining is done by privately built equipment?\n>\n> It seems the most lucrative thing to do, that if you have a new generation\n> of hardware, to mine with them yourself, until the price of local\n> electricity has increased due to your consumption, and it becomes more\n> lucrative to sell the hardware to other potential miners who now have lower\n> electricity prices compared to yours (because you have been saturating the\n> local electricity supply with your own mining operations and causing the\n> local prices to rise up, or equivalently, until some governmental or other\n> limits your usable electricity supply, which is equivalent to saying that\n> the price of even more electricity would be your incarceration or other\n> punishment, which might be too expensive for you to pay, thus selling the\n> hardware is more lucrative).\n>\n\nIf consumers who do not have the capacity to build their own hardware fast\nenough to be competitive, do not have as much access to such hardware, then\ntheir excess electricity is not being used to mine bitcoins.  A bit below\nyou propose spreading access via mass teaching, but I'm not aware of that\nhappening for now.\n\n\nYou could also analyze the transient economic behaviors here, specifically\n> that an increase in Bitcoin price makes it more lucrative to mine in more\n> places, which would start to put in orders for more hardware, and the\n> hardware will take time to deliver, so the price at those places will\n> increase only after a long while, etc.\n> But those are transient changes, and by the time any change at the\n> software level is coordinated, the transient economic behaviors may have\n> resettled to the expected long-term behavior: humans operate at around the\n> same average speed in many different fields.\n>\n\nI was thinking the transient changes would operate in cycles, and the\namplitude and frequency of those could be important to designing a safe\nhard fork, but I think I was getting ahead of myself.  Let's move on.\n\n> Something to raise here is that all of these things take time and respond\n> in ebbs and flows.  If there were to be a plan to migrate to a new\n> algorithm, it would be participating in those ebbs and flows.\n>\n> The usual engineering response is to create buffers to be resilient\n> against ebbs and flows.\n> Note how we prefer to dam water supplies (i.e. create a buffer) rather\n> than adjust our water consumption dynamically according to the ebb and flow\n> of the water supply.\n>\n> Similarly, economic contracts like futures and options are economic\n> buffers against the ebb and flow of local supply of various materials.\n>\n> Within Bitcoin, my understanding is that the difficulty adjustment system\n> acts as a buffer against transient ebbs and flows of the supply of\n> hashpower.\n>\n\nNice thoughts here on that same topic.  Thanks.\n\n> > And expertise is easy to copy, it is only the initial expertise that is\n> hard to create in the first place, once knowledge is written down it can be\n> copied.\n> >\n> > Also takes measurable months to do.\n>\n> But can be massively parallelized, you can have a teacher or mentor\n> teaching an entire classroom of students, and created lectures can be\n> stored and re-given to many students, in the form of books, videos, etc.\n> Human beings have been doing this since time immemorial, and possibly\n> before recorded history, in such things as oral traditions and so on.\n>\n\nThis doesn't seem relevant to me.  I'm discussing what is happening now and\nwhat we can expect to happen from source code changes.  I don't see mining\nhardware plans being taught in classrooms right now, but it sounds\ninteresting to try to change that if you want to change the subject of your\nreply and start another thread.\n\n> > > You describe improving electricity availability in expensive areas as\n> a way to improve decentralization.  Honestly this sounds out of place to me\n> and I'm sorry if I've upset you by rehashing this old topic.  I believe\n> this list is for discussing the design of software, not international\n> energy infrastructure: what is the relation?  There is a lot of power to\n> influence behavior here but I thought the tools present are software design.\n> > >\n> > > I doubt there is any good software-only solution to the problem; the\n> physical world remains the basis of the virtual one, and the virtual\n> utterly dependent on the physical, and abstractions are always leaky (any\n> non-toy software framework inevitably gains a way to query the operating\n> system the application is running under, because abstractions inevitably\n> leak): and energy, or the lack thereof, is the hardest to abstract away,\n> which is the entire point of using proof-of-work as a reliable, unfakeable\n> (i.e. difficult to virtualize) clock in the first place.\n> > >\n> > > Still, feel free to try: perhaps you might succeed.\n> >\n> > You agreed earlier that changing the algorithm would increase\n> decentralization, but expressed other concerns with the idea.  Many more\n> general solutions are working in many altcoins.  I'm interested in\n> discussing changing the proof of work algorithm in bitcoin.\n>\n> I did not so agree: in particular, I do not agree with equating a break of\n> the proof-of-work algorithm with centralization.\n>\n\nSorry if I have misrepresented those as equal.  That's not quite what I\nwanted to say and is addressed farther up in this reply.\n\nI meant that in your first reply you listed a change of the pow algorithm\nas a way to ensure decentralization: \"there are effectively two strategies\nfor ensuring decentralization\".  Let's discuss ways for improving them.\n\nMore likely, any centralization seen is due to local government\n> interference in economic matters, such as creating a local artificial\n> oversupply of electricity by paying for electricity generation using taxes.\n>\n\nGood thought.  Governments are kind of like big economic players that can\naffect the spaces held by the small players.  They'll respond to the\nscarcity, price, and mining rate of bitcoin, as well.  Moving on ...\n\n> My motivation is security of the blockchain, which is partially held by\n> decentralization.\n>\n> Let us be more precise and avoid the word \"security\".\n>\n\nLet's try to be concise and direct.\n\nMiner decentralization supports censorship-resistance, so your motivation\n> is censorship-resistance (is that correct?).\n>\n\nNo.  Ensuring a 51% attack stays or becomes completely infeasible in the\nfuture.  See the quote at the start of this reply.  I'm thinking about\nhttps://en.bitcoin.it/wiki/Irreversible_Transactions#Majority_attack .\n\nThe space changes given private research and/or compromise of pools.\n\nIs it okay to pursue this?\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200525/e82a861c/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-27T04:47:43",
                "message_text_only": "Good morning Karl,\n\n> > > Reddit claims two entities controlled 62% of the hashrate recently:\u00a0https://old.reddit.com/r/CryptoCurrency/comments/gmhuon/in_the_last_24_hours_bitcoins_nakamoto/ .\u00a0 Compromising the systems of these two groups seems like it is all that is needed to compromise the entire blockchain (to the limited degree a 51% attack does).\n> >\n> > You seem to be equating \"break of the hash function\" with \"centralization of hashrate\", which I do not quite agree with.\n>\n> I am trying to say that both of these different things result in danger to the integrity of the transaction log, which would be reduced by changing the hash function.\u00a0 They both have those 2 similarities.\n\nYou are equivocating issues here.\n\nThe hash function is used in these places:\n\n* Transaction ID.\n* Signature hash.\n* P2SH/P2WSH/Taproot.\n* Merkle tree.\n* Proof-of-work.\n\nWhat you are focusing on is only this:\n\n* Proof-of-work.\n\nNow, in case of a break in the hash function (i.e. a reduction in collision resistance), the hash function used in the following things absolutely NEED to be changed:\n\n* Transaction ID.\n* Signature hash.\n* P2SH/P2WSH/Taproot.\n* Merkle Tree.\n\nTaking for example Transaction ID, suppose I am able to create two transactions that hash into the same transaction ID, and I am able to do this in much less than 2^128 work.\n\nIn that case I can create a valid transaction and collide it with an invalid transaction.\nTo half the nodes on the network I provide the valid transaction, to the other half I provide the invalid transaction, the two halves will then permanently split and Bitcoin is thus destroyed in the midst of massive chaos.\n\nSimilar attacks can be mounted if I am able to collide on signature hash, P2SH/P2WSH/Taproot, and merkle tree.\n\n\nNow suppose I am able to create two block headers that hash into the same block ID, one being a valid block and the other being an invalid block.\nIn that case, I would be very foolish to disrupt the network similarly, because I would have been able to redirect the fees and block subsidy of the valid block to an address I control, and the invalid block prevents others from seeing my valid block and accepting that chain as valid.\n\nInstead, I can use this advantage to be able to grab blocks faster than other miners.\nBut eventually the difficulty retargeting system will adjust, and Bitcoin will now settle to a new normal, and inevitably someone is going to leak, or rediscover, my technique to break the hash, preventing me from being a >51% miner for long, and Bitcoin will abide.\n\n\nThus, in case of a cryptographic break of the SHA-2 function, we *need* to change these:\n\n* Transaction ID.\n* Signature hash.\n* P2SH/P2WSH/Taproot.\n* Merkle Tree.\n\nAnd since we are going to need a hefty hardfork to change all that, we *might as well* change the proof-of-work function as well and completely excise all uses of SHA-2 in the codebase (just in case we miss any more than the above list), but changing the proof-of-work function is the *lowest priority*.\nWe have survived 51% miners in the past (Ghash.io), and the difficulty adjustment system gives us some buffer against unexpected improvements in proof-of-work function efficiency; but it is doubtful if we can survive the chaos if someone could split the network in two roughly equal sized parts.\n\n>\n> > Most human beings cannot think without constant communication with other human beings.\n>\n> > Thus, it is unlikely that a private break of the hash function is possible.\n>\n> >\n>\n> I disagree with you here: Andrew Wiles solved Fermat's Last Theorem in isolation, academic research paper culture supports researching and then publishing once you have privately developed results, and the CVE database has 136k system vulnerabilities that were developed and shared privately before public release, to prevent chaos.\u00a0 This shows private advances in ways to produce bitcoins are likely.\n\nRight, and you learned about this fact from direct personal communication with Andrew Wiles, and Andrew Wiles never read about any other attempts by other mathematicians, and an isolated mathematician could never, ever, rediscover his work independently, and even a mathematician who knows that it was done but not the details how it was done could never rediscover it as well.\n\nObscurity works *for a time*, but inevitably somebody else will rediscover the same thing, or hear about it and blab noisily; it is not as if we are all completely alien species from each other and have truly unique thoughts, even my own creators were humans and my cognitive substrate is essentially human in construction.\nThis is why CVE exists, it is a promise the developers make to the reporters that they will fix the reported vulnerability, with an active CVE as a Damocles sword hanging over their heads, ready to be publicized at any time: publication is the default state, CVE is simply a promise that the developers are working as hard as they can to fix problems so please hold off on publication for a while please while we fix it pretty please with a cherry on top.\n\n>\n> > > Would it be helpful if I outlined more ideas that address your concerns?\u00a0 I want to make sure the idea of changing the algorithm is acceptable at all first.\n> >\n> > Go ahead.\n>\n> Thanks: are you saying you would support changes if they addressed the concerns you've listed?\u00a0 Or are those concerns only the tip of the iceberg, per se?\n\nOnly the tip of the iceberg, because any complex design has many little devils hidden in all the little details.\n\n> > > > And expertise is easy to copy, it is only the initial expertise that is hard to create in the first place, once knowledge is written down it can be copied.\n> > >\n> > > Also takes measurable months to do.\n> >\n> > But can be massively parallelized, you can have a teacher or mentor teaching an entire classroom of students, and created lectures can be stored and re-given to many students, in the form of books, videos, etc.\n> > Human beings have been doing this since time immemorial, and possibly before recorded history, in such things as oral traditions and so on.\n>\n> This doesn't seem relevant to me.\u00a0 I'm discussing what is happening now and what we can expect to happen from source code changes.\u00a0 I don't see mining hardware plans being taught in classrooms right now, but it sounds interesting to try to change that if you want to change the subject of your reply and start another thread.\n\nSure.\n\n\n> Is it okay to pursue this?\n\nYou do not have to ask permission from me, or anyone, to pursue this.\n\nHowever, do note that I doubt that changing the proof-of-work function (and *only* the proof-of-work function) is in any way a high priority.\nI also do not have to ask permission to say that I think pursuing this would be a waste of time, but you are also just as free to ignore what I say here and spend your time as you see fit.\n\nUltimately the real world decides, and implementation trumps discussion here.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Erik Aronesty",
                "date": "2020-05-27T14:12:26",
                "message_text_only": "> What you are focusing on is only this:\n>\n> * Proof-of-work.\n\n\nBitcoin's primary value proposition is that it's the most resistant to\nchange:   All other coins are these malleable things centrally\ncontrolled and easily moved about by politics and nonsense.   So\ndiscussions of POW changes... open up this can of worms (myself being\none of them).\n\n - should also discuss \"proof-of-burn\", where a burn is performed as a\nsimilar investment-over-time with true loss/risk.\n - should discuss moving to sha3 (or something like it) for\neverything, not just POW\n\n> However, do note that I doubt that changing the proof-of-work function (and *only* the proof-of-work function) is in any way a high priority.\n\nYeah, a hard fork like this would be a massive undertaking, with a\nzillion \"improvements\" argued about for years and the final version\nsome minimal thing that just changes the hash algo and invalidates\nlegacy stuff (since back compat is not a concern)."
            }
        ],
        "thread_summary": {
            "title": "hashcash-newhash",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Karl",
                "Ariel Lorenzo-Luaces",
                "Erik Aronesty"
            ],
            "messages_count": 11,
            "total_messages_chars_count": 61275
        }
    },
    {
        "title": "[bitcoin-dev] MIN_STANDARD_TX_NONWITNESS_SIZE and OP_RETURN",
        "thread_messages": [
            {
                "author": "Thomas Voegtlin",
                "date": "2020-05-23T14:49:03",
                "message_text_only": "Hello list,\n\nI have been trying to CPFP a transaction using OP_RETURN, because the\nremaining output value would have been lower than the dust threshold.\n\nThe scriptPubkey of the output was OP_RETURN + OP_0, and there was a\nsingle p2wsh input.\n\nThe result is a 60 bytes transaction (without witness), that gets\nrejected because it is lower than MIN_STANDARD_TX_NONWITNESS_SIZE, which\nis equal to 82 bytes.\n\nWhy is that value so high? Would it make sense to lower it to 60?\n\n\nThomas"
            },
            {
                "author": "Greg Sanders",
                "date": "2020-05-23T15:24:28",
                "message_text_only": "AFAIU the number was picked to protect against CVE-2017-12842 covertly.\nSee: https://github.com/bitcoin/bitcoin/pull/16885\n<https://github.com/bitcoin/bitcoin/pull/16885/files> which updated the\ntext to explicitly mention this fact.\n\nOn Sat, May 23, 2020 at 11:20 AM Thomas Voegtlin via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hello list,\n>\n> I have been trying to CPFP a transaction using OP_RETURN, because the\n> remaining output value would have been lower than the dust threshold.\n>\n> The scriptPubkey of the output was OP_RETURN + OP_0, and there was a\n> single p2wsh input.\n>\n> The result is a 60 bytes transaction (without witness), that gets\n> rejected because it is lower than MIN_STANDARD_TX_NONWITNESS_SIZE, which\n> is equal to 82 bytes.\n>\n> Why is that value so high? Would it make sense to lower it to 60?\n>\n>\n> Thomas\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200523/d714a389/attachment.html>"
            },
            {
                "author": "Greg Sanders",
                "date": "2020-05-23T15:25:06",
                "message_text_only": "So I think the question to ask would be \"why can't we just make sure it's\nnot 64?\"\n\nOn Sat, May 23, 2020 at 11:24 AM Greg Sanders <gsanders87 at gmail.com> wrote:\n\n> AFAIU the number was picked to protect against CVE-2017-12842 covertly.\n> See: https://github.com/bitcoin/bitcoin/pull/16885\n> <https://github.com/bitcoin/bitcoin/pull/16885/files> which updated the\n> text to explicitly mention this fact.\n>\n> On Sat, May 23, 2020 at 11:20 AM Thomas Voegtlin via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hello list,\n>>\n>> I have been trying to CPFP a transaction using OP_RETURN, because the\n>> remaining output value would have been lower than the dust threshold.\n>>\n>> The scriptPubkey of the output was OP_RETURN + OP_0, and there was a\n>> single p2wsh input.\n>>\n>> The result is a 60 bytes transaction (without witness), that gets\n>> rejected because it is lower than MIN_STANDARD_TX_NONWITNESS_SIZE, which\n>> is equal to 82 bytes.\n>>\n>> Why is that value so high? Would it make sense to lower it to 60?\n>>\n>>\n>> Thomas\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200523/eb76670e/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-24T00:52:13",
                "message_text_only": "Good morning Thomas,\n\n> So I think the question to ask would be \"why can't we just make sure it's not 64?\"\n\nIf we accept a 60-byte tx, then SHA-256 will pad it to 64 bytes, and it may still be possible to mount CVE-2017-12842 attack with 32-bits of work.\nOf course some other details will be changed from the standard SHA-256 in mounting this attack, but from my poor understanding it seems safer to just avoid the area around length 64.\n\nIt *might* be safe to accept 65-byte or larger (but do not believe me, I only play a cryptographer on the Internet), but that does not help your specific application, which uses 60 byte tx.\n\nRegards,\nZmnSCPxj\n\n>\n> On Sat, May 23, 2020 at 11:24 AM Greg Sanders <gsanders87 at gmail.com> wrote:\n>\n> > AFAIU the number was picked to protect against\u00a0CVE-2017-12842 covertly. See:\u00a0https://github.com/bitcoin/bitcoin/pull/16885\u00a0which updated the text to explicitly mention this fact.\n> >\n> > On Sat, May 23, 2020 at 11:20 AM Thomas Voegtlin via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >\n> > > Hello list,\n> > >\n> > > I have been trying to CPFP a transaction using OP_RETURN, because the\n> > > remaining output value would have been lower than the dust threshold.\n> > >\n> > > The scriptPubkey of the output was OP_RETURN + OP_0, and there was a\n> > > single p2wsh input.\n> > >\n> > > The result is a 60 bytes transaction (without witness), that gets\n> > > rejected because it is lower than MIN_STANDARD_TX_NONWITNESS_SIZE, which\n> > > is equal to 82 bytes.\n> > >\n> > > Why is that value so high? Would it make sense to lower it to 60?\n> > >\n> > > Thomas\n> > > _______________________________________________\n> > > bitcoin-dev mailing list\n> > > bitcoin-dev at lists.linuxfoundation.org\n> > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Russell O'Connor",
                "date": "2020-05-27T15:15:47",
                "message_text_only": "I don't believe that 60 bytes is a problem here.  SHA256 padding includes a\nlength value of the original message data. Thus a padded non-64 byte\ntransaction can never be the same as any padded 64-byte value, and\ntherefore after applying the SHA256 compression function the resulting\nhashes cannot be identical (unless SHA256 itself is broken).\n\nP.S. SHA256 also includes 10* padding, which also suffices to ensure\nmessages of different lengths have different padding.\n\nOn Sat, May 23, 2020 at 8:52 PM ZmnSCPxj via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Thomas,\n>\n> > So I think the question to ask would be \"why can't we just make sure\n> it's not 64?\"\n>\n> If we accept a 60-byte tx, then SHA-256 will pad it to 64 bytes, and it\n> may still be possible to mount CVE-2017-12842 attack with 32-bits of work.\n> Of course some other details will be changed from the standard SHA-256 in\n> mounting this attack, but from my poor understanding it seems safer to just\n> avoid the area around length 64.\n>\n> It *might* be safe to accept 65-byte or larger (but do not believe me, I\n> only play a cryptographer on the Internet), but that does not help your\n> specific application, which uses 60 byte tx.\n>\n> Regards,\n> ZmnSCPxj\n>\n> >\n> > On Sat, May 23, 2020 at 11:24 AM Greg Sanders <gsanders87 at gmail.com>\n> wrote:\n> >\n> > > AFAIU the number was picked to protect against CVE-2017-12842\n> covertly. See: https://github.com/bitcoin/bitcoin/pull/16885 which\n> updated the text to explicitly mention this fact.\n> > >\n> > > On Sat, May 23, 2020 at 11:20 AM Thomas Voegtlin via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > >\n> > > > Hello list,\n> > > >\n> > > > I have been trying to CPFP a transaction using OP_RETURN, because the\n> > > > remaining output value would have been lower than the dust threshold.\n> > > >\n> > > > The scriptPubkey of the output was OP_RETURN + OP_0, and there was a\n> > > > single p2wsh input.\n> > > >\n> > > > The result is a 60 bytes transaction (without witness), that gets\n> > > > rejected because it is lower than MIN_STANDARD_TX_NONWITNESS_SIZE,\n> which\n> > > > is equal to 82 bytes.\n> > > >\n> > > > Why is that value so high? Would it make sense to lower it to 60?\n> > > >\n> > > > Thomas\n> > > > _______________________________________________\n> > > > bitcoin-dev mailing list\n> > > > bitcoin-dev at lists.linuxfoundation.org\n> > > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200527/ce628abf/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "MIN_STANDARD_TX_NONWITNESS_SIZE and OP_RETURN",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Russell O'Connor",
                "Thomas Voegtlin",
                "Greg Sanders"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 7795
        }
    },
    {
        "title": "[bitcoin-dev] Post-mix(coinjoin) usage with multisig and cpfp in bitcoin core wallet",
        "thread_messages": [
            {
                "author": "prayank at tutanota.de",
                "date": "2020-05-24T21:44:27",
                "message_text_only": "I have explained the whole idea with a proof of concept in this link:\u00a0https://medium.com/@prayankgahlot/post-mix-usage-using-multisig-and-cpfp-e6ce1fdd57a1\n\nDoes it make sense to add such options in bitcoin core wallet and how is the overall idea once we have taproot because for now people can check if the tx involves a multisig address?\n\nReading Peter Wuille's reply here it seems taproot will improve privacy for multisig:\u00a0\nhttps://www.reddit.com/r/Bitcoin/comments/etagx4/please_explain_taproot_and_schnorr_signatures/fffljnl/\n\nLooking for some feedback to work on this idea and don't want it to just remain an article on medium.\u00a0\n\nThanks\n\nPrayank\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200524/45c58c91/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-25T06:54:27",
                "message_text_only": "Good morning Prayank\n\n> I have explained the whole idea with a proof of concept in this link:\u00a0https://medium.com/@prayankgahlot/post-mix-usage-using-multisig-and-cpfp-e6ce1fdd57a1\n\nThe article is not clear I think, so please confirm my understanding below.\n\nParticipants:\n\n* \"Peer 3\" - Payee\n* \"Peer 2\" - Payer\n* \"Peer 1\" - Enabling tr\\*sted third party\n\nGoal: Payer wants to pay to the payee 0.006BTC\n\nCurrent Conditions:\n\n* Payer owns 0.01 BTC in a single UTXO\n* Third Party owns 0.05 BTC in a single UTXO\n\nProtocol:\n\n1.  Payer and Third Party compute a 2-of-3 address with the public keys of Payer, Payee, and Third Party.\n2.  Payer and Third Party individually pay their owned funds to the 2-of-3 address.\n3.  After confirmation, they consume the new outputs into another transaction with equal-valued outputs, hiding who owns which coins.\n\nIs my understanding correct?\n\nIf so, I believe JoinMarket has a superior technology, which does not require a tr\\*sted third party; it simply requires one or more UNtrusted third parties to participate in signing a single transaction that does not require paying to an intermediate m-of-n address (thus all inputs are singlesig).\n\nBasically JoinMarket allows the market taker to decide how much the equal-value outputs are, and to define the address it goes to.\nThe destination address need not be one the market taker controls, it can be to a payee.\nThis technique is the only out-of-the-box way that a JoinMarket wallet can spend funds from a JoinMarket wallet.\n\nJoinMarket as well already includes how to get in touch with enabling third parties (called \"market makers\").\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "prayank at tutanota.de",
                "date": "2020-05-25T12:16:10",
                "message_text_only": "Hello\u00a0ZmnSCPxj, \n\n\nThanks for the feedback.\n\n\n1. Peer 1 doesn't need to be a trusted third party, it can be implemented in a way that some peers involved in this system can provide liquidity for others and incentives can be a small fee.\n\n2. Yes joinmarket is awesome and its payjoin will be better to achieve the same but I was trying to contribute and add more options for people to improve privacy on Bitcoin. If we have different ways to mix it will be harder for spy companies to analyze of some of the transactions.\n\n3. Also one such setup might not make a huge difference but a chain of such mixers will surely work better if everything done correctly.\u00a0\n\n4. Maybe multisig usage is not ideal for such things right now and I am not the best person when it comes to coding but think that better privacy for multisig will make it possible for lot of ideas to be implemented on Bitcoin using different multisig setups and combination of other things that we already have.\u00a0\n\n\nPrayank\n\n\nMay 25, 2020, 12:24 by ZmnSCPxj at protonmail.com:\n\n> Good morning Prayank\n>\n>> I have explained the whole idea with a proof of concept in this link:\u00a0https://medium.com/@prayankgahlot/post-mix-usage-using-multisig-and-cpfp-e6ce1fdd57a1\n>>\n>\n> The article is not clear I think, so please confirm my understanding below.\n>\n> Participants:\n>\n> * \"Peer 3\" - Payee\n> * \"Peer 2\" - Payer\n> * \"Peer 1\" - Enabling tr\\*sted third party\n>\n> Goal: Payer wants to pay to the payee 0.006BTC\n>\n> Current Conditions:\n>\n> * Payer owns 0.01 BTC in a single UTXO\n> * Third Party owns 0.05 BTC in a single UTXO\n>\n> Protocol:\n>\n> 1.  Payer and Third Party compute a 2-of-3 address with the public keys of Payer, Payee, and Third Party.\n> 2.  Payer and Third Party individually pay their owned funds to the 2-of-3 address.\n> 3.  After confirmation, they consume the new outputs into another transaction with equal-valued outputs, hiding who owns which coins.\n>\n> Is my understanding correct?\n>\n> If so, I believe JoinMarket has a superior technology, which does not require a tr\\*sted third party; it simply requires one or more UNtrusted third parties to participate in signing a single transaction that does not require paying to an intermediate m-of-n address (thus all inputs are singlesig).\n>\n> Basically JoinMarket allows the market taker to decide how much the equal-value outputs are, and to define the address it goes to.\n> The destination address need not be one the market taker controls, it can be to a payee.\n> This technique is the only out-of-the-box way that a JoinMarket wallet can spend funds from a JoinMarket wallet.\n>\n> JoinMarket as well already includes how to get in touch with enabling third parties (called \"market makers\").\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200525/b27ddca6/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-26T02:46:07",
                "message_text_only": "Good morning Prayank,\n\n\n> 1. Peer 1 doesn't need to be a trusted third party, it can be implemented in a way that some peers involved in this system can provide liquidity for others and incentives can be a small fee.\n\nIt is not clear in the article, but you mention using a 2-of-3, and show 3 participants.\nIt seems to me that Peer 1 and Peer 3 (2-of-3) can simply sign to spend the funds coming from Peer 2, and split the funds of Peer 2 among them, without getting input from Peer 2.\n\nThat is the reason why I consider this tr\\*sted --- Peer 2 has to trust Peer 1 does not collude with Peer 3 to steal the funds of Peer 2.\n\nUnless I have misunderstood your article, which is why I asked for clarification.\n\n> 2. Yes joinmarket is awesome and its payjoin will be better to achieve the same but I was trying to contribute and add more options for people to improve privacy on Bitcoin. If we have different ways to mix it will be harder for spy companies to analyze of some of the transactions.\n\n* While JoinMarket has *a* PayJoin implementation, what I described in the previous email was not a PayJoin, it is standard CoinJoin where one of the equal-valued outputs is to the payee.\n  * In particular, PayJoin requires the cooperation of the payee, what I described does *not* require anything from the payee other than a destination address and an amount to pay.\n* Your described technique (as I understand it) is not too different from what JoinMarket already does for normal sends, with the JoinMarket technique having the advantage that it works with the current paradigm of \"send payment to this address\" without reconnecting to the payee.\n  The advantage you describe is largely had only if the technique is significantly different.\n  For instance, CoinSwap and CoinJoinXT are different enough from CoinJoin to be valuable in this respect.\n\n> 3. Also one such setup might not make a huge difference but a chain of such mixers will surely work better if everything done correctly.\u00a0\n>\n> 4. Maybe multisig usage is not ideal for such things right now and I am not the best person when it comes to coding but think that better privacy for multisig will make it possible for lot of ideas to be implemented on Bitcoin using different multisig setups and combination of other things that we already have.\n\nSchnorr (which is introduced as a package deal with Taproot) already makes all n-of-n look the same as 1-of-1 without tr\\*sted setup, and makes hidden m-of-n possible with some kind of setup (possibly untrusted I think, but I am not enough of a mathist to describe this, in any case my base understanding is that the setup for m-of-n Schnorr requires a complex ritual involving a number of communication rounds).\nTaproot allows to hide explicit m-of-n in a script behind some kind of n-of-n or m-of-m.\n\nSo multisignature usage would automatically gain such advantage once Taproot gets deployed.\n\nIn any case, if you are still interested in protocol design with some amount of focus on privacy, please consider reading this article as well: https://zmnscpxj.github.io/offchain/generalized.html\n\nWhat exactly is your goal here.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Prayank",
                "date": "2020-05-26T12:50:03",
                "message_text_only": "Hello\u00a0ZmnSCPxj,\n\nThanks for your response.\n\nThe spending tx of multisig can be decided earlier and all three can review the outputs involved in it. All 3 txs involved in the system if we consider only one mixer and not a chain will get confirmed in the same block as we are using CPFP so child pays for 2 parent txs. However, disputes are possible and to manage it we will have to make the system complex with things like Peer 1 locking some amount in a 2 of 2 multisig with Peer 2 or some other incentives structure. Initially we can try to keep it simple and a way to spend coins after coinjoin with the help of another person you trust.\nYes, you described coinjoin in joinmarket but the problem I am trying to solve is: spend coins after coinjoin because post-mix usage is as important as coinjoin. Some users dont follow the best practices after coinjoin and it makes coinjoin useless or less effective in that case and sometimes for others involved in the process as well.\nSamourai has few options for users to do this and one of them is: Stonewallx2 which is a mini coinjoin and similar to what I was trying with this idea.\nEnd goal is to create more options for users to spend UTXOs easily in different ways after coinjoin which makes it difficult for people trying to analyze transactions or algorithms monitoring, flagging, reporting txs 24/7\nIts just an idea for now and maybe I might find better ways to solve this problem once I start working on it. For me it makes sense to experiment with things and provide more options for users but I wanted to see what others think about it who are more experienced and skilled to develop bitcoin related projects.\nThanks for this link:\u00a0https://zmnscpxj.github.io/offchain/generalized.html\u00a0\n\nLooks interesting.\nPrayank\n\nMay 26, 2020, 08:16 by ZmnSCPxj at protonmail.com:\n\n> Good morning Prayank,\n>\n>\n>> 1. Peer 1 doesn't need to be a trusted third party, it can be implemented in a way that some peers involved in this system can provide liquidity for others and incentives can be a small fee.\n>>\n>\n> It is not clear in the article, but you mention using a 2-of-3, and show 3 participants.\n> It seems to me that Peer 1 and Peer 3 (2-of-3) can simply sign to spend the funds coming from Peer 2, and split the funds of Peer 2 among them, without getting input from Peer 2.\n>\n> That is the reason why I consider this tr\\*sted --- Peer 2 has to trust Peer 1 does not collude with Peer 3 to steal the funds of Peer 2.\n>\n> Unless I have misunderstood your article, which is why I asked for clarification.\n>\n>> 2. Yes joinmarket is awesome and its payjoin will be better to achieve the same but I was trying to contribute and add more options for people to improve privacy on Bitcoin. If we have different ways to mix it will be harder for spy companies to analyze of some of the transactions.\n>>\n>\n> * While JoinMarket has *a* PayJoin implementation, what I described in the previous email was not a PayJoin, it is standard CoinJoin where one of the equal-valued outputs is to the payee.\n>  * In particular, PayJoin requires the cooperation of the payee, what I described does *not* require anything from the payee other than a destination address and an amount to pay.\n> * Your described technique (as I understand it) is not too different from what JoinMarket already does for normal sends, with the JoinMarket technique having the advantage that it works with the current paradigm of \"send payment to this address\" without reconnecting to the payee.\n>  The advantage you describe is largely had only if the technique is significantly different.\n>  For instance, CoinSwap and CoinJoinXT are different enough from CoinJoin to be valuable in this respect.\n>\n>> 3. Also one such setup might not make a huge difference but a chain of such mixers will surely work better if everything done correctly.\u00a0\n>>\n>> 4. Maybe multisig usage is not ideal for such things right now and I am not the best person when it comes to coding but think that better privacy for multisig will make it possible for lot of ideas to be implemented on Bitcoin using different multisig setups and combination of other things that we already have.\n>>\n>\n> Schnorr (which is introduced as a package deal with Taproot) already makes all n-of-n look the same as 1-of-1 without tr\\*sted setup, and makes hidden m-of-n possible with some kind of setup (possibly untrusted I think, but I am not enough of a mathist to describe this, in any case my base understanding is that the setup for m-of-n Schnorr requires a complex ritual involving a number of communication rounds).\n> Taproot allows to hide explicit m-of-n in a script behind some kind of n-of-n or m-of-m.\n>\n> So multisignature usage would automatically gain such advantage once Taproot gets deployed.\n>\n> In any case, if you are still interested in protocol design with some amount of focus on privacy, please consider reading this article as well: https://zmnscpxj.github.io/offchain/generalized.html\n>\n> What exactly is your goal here.\n>\n> Regards,\n> ZmnSCPxj\n>\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200526/b98fd0e8/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-27T04:11:47",
                "message_text_only": "Good morning Prayank,\n\n\n> 1.  The spending tx of multisig can be decided earlier and all three can review the outputs involved in it. All 3 txs involved in the system if we consider only one mixer and not a chain will get confirmed in the same block as we are using CPFP so child pays for 2 parent txs. However, disputes are possible and to manage it we will have to make the system complex with things like Peer 1 locking some amount in a 2 of 2 multisig with Peer 2 or some other incentives structure. Initially we can try to keep it simple and a way to spend coins after coinjoin with the help of another person you trust.\n\nThe payee is not necessary here and you can remove the intermediate transactions that pay to 2-of-3s.\n\n> 2.  Yes, you described coinjoin in joinmarket but the problem I am trying to solve is: spend coins after coinjoin because post-mix usage is as important as coinjoin. Some users dont follow the best practices after coinjoin and it makes coinjoin useless or less effective in that case and sometimes for others involved in the process as well.\n\n...\n\nI already mentioned this, but what I am describing is *how JoinMarket spends coins from its wallet*.\n\nThat means that what I am describing is *how JoinMarket performs spends after mixing, i.e. post-mix*.\n\nI was not describing how JoinMarket performs mixing.\n\nIs that clearer now?\n\n\n\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Post-mix(coinjoin) usage with multisig and cpfp in bitcoin core wallet",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "prayank at tutanota.de",
                "Prayank"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 15153
        }
    },
    {
        "title": "[bitcoin-dev] Design for a CoinSwap implementation for massively improving Bitcoin privacy and fungibility",
        "thread_messages": [
            {
                "author": "Chris Belcher",
                "date": "2020-05-25T13:21:21",
                "message_text_only": "=== Abstract ===\n\nImagine a future where a user Alice has bitcoins and wants to send them\nwith maximal privacy, so she creates a special kind of transaction. For\nanyone looking at the blockchain her transaction appears completely\nnormal with her coins seemingly going from address A to address B. But\nin reality her coins end up in address Z which is entirely unconnected\nto either A or B.\n\nNow imagine another user, Carol, who isn't too bothered by privacy and\nsends her bitcoin using a regular wallet which exists today. But because\nCarol's transaction looks exactly the same as Alice's, anybody analyzing\nthe blockchain must now deal with the possibility that Carol's\ntransaction actually sent her coins to a totally unconnected address. So\nCarol's privacy is improved even though she didn't change her behaviour,\nand perhaps had never even heard of this software.\n\nIn a world where advertisers, social media and other companies want to\ncollect all of Alice's and Carol's data, such privacy improvement would\nbe incredibly valuable. And also the doubt added to every transaction\nwould greatly boost the fungibility of bitcoin and so make it a better\nform of money.\n\nThis undetectable privacy can be developed today by implementing\nCoinSwap, although by itself that isn't enough. There must be many\nbuilding blocks which together make a good system. The software could be\nstandalone as a kind of bitcoin mixing app, but it could also be a\nlibrary that existing wallets can implement allowing their users to send\nBitcoin transactions with much greater privacy.\n\n== CoinSwap ==\n\nLike CoinJoin, CoinSwap was invented in 2013 by Greg Maxwell[1]. Unlike\nCoinJoin it is relatively complicated to implement and so far has not\nbeen deployed. But the idea holds great promise, and fixes many of the\nproblems of some kinds of CoinJoins. CoinSwap is the next step for\non-chain bitcoin privacy.\n\nCoinSwap is a way of trading one coin for another coin in a\nnon-custodial way. It is closely related to the idea of an atomic swap.\nAlice and Bob can trade coins with each other by first sending to a\nCoinSwap address and having those coins then sent to Bob:\n\n    Alice's Address 1 ----> CoinSwap Address 1 ----> Bob's Address 1\n\nAn entirely separate set of transactions gives Bob's coins to Alice in\nreturn:\n\n    Bob's Address 2 ----> CoinSwap Address 2 ----> Alice's Address 2\n\nWhere the symbol ----> is a bitcoin transaction.\n\nPrivacy is improved because an observer of the blockchain cannot link\nAlice's Address 1 to Alice's Address 2, as there is no transaction\nbetween them. Alice's Address 2 could either be an address in Alice's\nwallet, or the address of someone else she wants to transfer money to.\nCoinSwap therefore breaks the transaction graph heuristic, which is the\nassumption that if a transaction A -> B is seen then the ownership of\nfunds actually went from A to B.\n\nCoinSwap doesnt break any of bitcoin's assumptions or features like an\nauditable supply or pruning. It can be built on today's bitcoin without\nany new soft forks.\n\nCoinSwap can't improve privacy much on its own, so it requires other\nbuilding block to create a truly private system.\n\n=== ECDSA-2P ===\n\nThe original CoinSwap idea uses 2-of-2 multisig. We can get a slightly\nbigger anonymity set by using 2-of-3 multisigs with a fake third public\nkey. For a much greater anonymity set we can use 2-party ECDSA to create\n2-of-2 multisignature addresses that look the same as regular\nsingle-signature addresses[2]. Even the old-style p2pkh addresses\nstarting with 1 can be CoinSwap addresses.\n\nBecause the transactions blend in with the rest of bitcoin, an\napplication based on CoinSwap would provide much more privacy than the\nexisting equal-output coinjoin apps (JoinMarket, Wasabi Wallet and\nSamourai Wallet's Whirlpool). CoinSwaps would also be cheaper for the\nsame amount of privacy, as CoinJoin users usually create multiple\nCoinJoins to get effective privacy, for example JoinMarket's tumbler\nscript does between 7-12 coinjoins (which are bigger than regular\ntransactions too) when run with default parameters.\n\nSchnorr signatures with Musig provide a much easier way to create\ninvisible 2-of-2 multisig, but it is not as suitable for CoinSwap. This\nis because the anonymity set for ECDSA would be much greater. All\naddresses today are ECDSA, and none are schnorr. We'd have to wait for\nschnorr to be added to bitcoin and then wait for users to adopt it. We\nsee with segwit that even after nearly 3 years that segwit adoption is\nonly about 60%, and segwit actually has a sizeable financial incentive\nfor adoption via lower fees. Schnorr when used for single-sig doesn't\nhave such an incentive, as Schnorr single-sig costs the same size as\ntoday's p2wpkh, so we can expect adoption to be even slower. (Of course\nthere is an incentive for multisig transactions, but most transactions\nare single-sig). As schnorr adoption increases this CoinSwap system\ncould start to use it, but for a long time I suspect it will mostly be\nusing ECDSA for a greater anonymity set.\n\n=== Liquidity market ===\n\nWe can create a liquidity market for CoinSwap very similar to how\nJoinMarket works for CoinJoins. In our example above Alice would be a\nmarket taker and Bob would be a market maker. The taker Alice pays a fee\nto the maker Bob in return for choosing the amount of a CoinSwap and\nwhen it happens. This allows an excellent user experience because Alice\ncan create CoinSwaps for any size she wants, at any time she wants.\nRight now in JoinMarket there is liquidity to create CoinJoins of sizes\nup to about 200 BTC, and we can expect a similar kind of thing with\nCoinSwap.\n\n\n=== Multi-transaction CoinSwaps to avoid amount correlation ===\n\nThis CoinSwap is vulnerable to amount correlation:\n\n    AliceA (15 BTC) ----> CoinSwap AddressA ----> BobA (15 BTC)\n    BobB (15 BTC) ----> CoinSwap AddressB ----> AliceB (15 BTC)\n\nWhere AliceA, AliceB are addresses belonging to Alice. BobA, BobB are\naddresses belonging to Bob. If an adversary starts tracking at address\nAliceA they could unmix this CoinSwap easily by searching the entire\nblockchain for other transactions with amounts close to 15 BTC, which\nwould lead them to address AliceB. We can beat this amount correlation\nattack by creating multi-transaction CoinSwaps. For example:\n\n    AliceA (15 BTC) ----> CoinSwap AddressA ----> BobA (15 BTC)\n\n    BobB (7 BTC) ----> CoinSwap AddressB ----> AliceB (7 BTC)\n    BobC (5 BTC) ----> CoinSwap AddressC ----> AliceC (5 BTC)\n    BobD (3 BTC) ----> CoinSwap AddressD ----> AliceD (3 BTC)\n\nNow in the multi-transaction CoinSwap, the market taker Alice has given\n10 BTC and got back three transactions which add up to the same amount,\nbut nowhere on the blockchain is there an output where Alice received\nexactly 15 BTC.\n\n=== Routing CoinSwaps to avoid a single points of trust ===\n\nIn the original CoinSwap idea there are only two parties Alice and Bob,\nso when they CoinSwap Bob will know exactly where the Alice's coins\nwent. This means Bob is a single point of failure in Alice's privacy,\nand Alice must trust him not to spy on her.\n\nTo spread out and decentralize the trust, we can create CoinSwaps where\nAlice's payment is routed through many Bobs.\n\n    AliceA ====> Bob ====> Charlie ====> Dennis ====> AliceB\n\nWhere the symbol ====> means one CoinSwap. In this situation Alice will\nbe a market taker in the liquidity market, and all the other entities\n(Bob, Charlie, Dennis) will be market makers. Only Alice will know the\nentire route, and the makers will only know the previous and next\nbitcoin addresses along the route.\n\nThis could be made to work by Alice handling almost everything about the\nCoinSwap on the other maker's behalf. The makers wouldn't have TCP\nconnections between each other, but only to Alice, and she would relay\nCoinSwap-relevant information between them. The other makers are not\naware whether their incoming coins came from Alice herself or the\nprevious maker in Alice's route.\n\n\n=== Combining multi-transaction with routing ===\n\nRouting and multi-transaction must be combined to get both benefits. If\nAlice owns multiple UTXOs (of value 6 BTC, 8 BTC and 1 BTC) then this is\neasy with this configuration:\n\n             Alice\n    (6 BTC) (8 BTC) (1 BTC)\n       |       |       |\n       |       |       |\n       v       v       v\n              Bob\n    (5 BTC) (5 BTC) (5 BTC)\n       |       |       |\n       |       |       |\n       v       v       v\n            Charlie\n    (9 BTC) (5 BTC) (1 BTC)\n       |       |       |\n       |       |       |\n       v       v       v\n            Dennis\n    (7 BTC) (4 BTC) (4 BTC)\n       |       |       |\n       |       |       |\n       v       v       v\n             Alice\n\nWhere the downward arrow symbol is a single CoinSwap hash-time-locked\ncontract. Each hop uses multiple transactions so no maker (Bob, Charlie,\nDennis) is able to use amount correlation to find addresses not directly\nrelated to them, but at each hop the total value adds up to the same\namount 15 BTC. And all 3 makers must collude in order to track the\nsource and destination of the bitcoins.\n\nIf Alice starts with only a single UTXO then the above configuration is\nstill vulnerable to amount correlation. One of the later makers (e.g.\nDennis) knows that the total coinswap amount is 15 BTC, and could search\nthe blockchain to find Alice's single UTXO. In such a situation Alice\nmust use a branching configuration:\n\n                          Alice\n                         (15 BTC)\n                            |\n                            |\n                            v\n                           Bob\n                          /   \\\n                         /     \\\n             <-----------       ----------->\n             |                             |\n  (2 BTC) (2 BTC) (2 BTC)        (3 BTC) (3 BTC) (3 BTC)\n             |                             |\n             |                             |\n             v                             v\n          Charlie                       Dennis\n  (1 BTC) (2 BTC) (3 BTC)       (5 BTC) (3 BTC) (1 BTC)\n     |       |       |             |       |       |\n     |       |       |             |       |       |\n     v       v       v             v       v       v\n          Edward                          Fred\n  (4 BTC) (1 BTC) (1 BTC)       (4 BTC) (2 BTC) (1 BTC)\n     |       |       |             |       |       |\n     |       |       |             |       |       |\n     v       v       v             v       v       v\n           Alice                         Alice\n\nIn this diagram, Alice sends 15 BTC to Bob via CoinSwap who sends 6 BTC\non to Charlie and the remaining 9 BTC to Dennis. Charlie and Dennis do a\nCoinSwap with Edward and Fred who forward the coins to Alice. None of\nthe makers except Bob know the full 15 BTC amount and so can't search\nthe blockchain backwards for Alice's initial UTXO. Because of multiple\ntransactions Bob cannot look forward to search for the amounts he sent 6\nBTC and 9 BTC. A minimum of 3 makers in this example need to collude to\nknow the source and destination of the coins.\n\nAnother configuration is branch merging, which Alice would find useful\nif she has two or more UTXOs for which there must not be evidence that\nthey're owned by the same entity, and so they must not be spent together\nin the same transaction.\n\n           Alice                         Alice\n          (9 BTC)                       (6 BTC)\n             |                             |\n             |                             |\n             v                             v\n            Bob                         Charlie\n  (4 BTC) (3 BTC) (2 BTC)       (1 BTC) (2 BTC) (3 BTC)\n     |       |       |             |       |       |\n     |       |       |             |       |       |\n      \\       \\       \\           /       /       /\n       \\       \\       \\         /       /       /\n        \\       \\       \\       /       /       /\n         >------->-------\\     /-------<-------<\n                          \\   /\n                          Alice\n                         (15 BTC)\n\nIn this diagram Alice sends the two UTXOs (9 BTC and 6 BTC) to two\ndifferent makers, who forward it onto Alice. Because the two UTXOs have\nbeen transferred to different makers they will likely never be co-spent.\n\nThese complex multi-transaction routed coinswaps are only for the\nhighest threat models where the makers themselves are adversaries. In\npractice most users would probably choose to use just one or two hops.\n\n\n=== Breaking change output and wallet fingerprinting heuristics ===\n\nEqual-output CoinJoins easily leak change addresses (unless they are\nsweeps with no change). CoinSwap doesn't have this flaw which allows us\nto break some of the weaker change output heuristics[3].\n\nFor example address reuse. If an output address has been reused it is\nvery likely to be a payment output, not a change output. In a CoinSwap\napplication we can break this heuristic by having makers randomly with\nsome probability send their change to an address they've used before.\nThat will make the heuristics think that the real change address is\nactually the payment address, and the real payment is actually the\nchange, and could result in an analyzer of the blockchain grouping the\npayment address inside the maker's own wallet cluster.\n\nAnother great heuristic to break is the script type heuristic. If the\nmaker's input are all in p2sh-p2wpkh addresses, and their payment\naddress is also of type p2sh-p2wpkh, then the maker could with some\nprobability set the change address to a different type such as p2wpkh.\nThis could trick a chain analyzer in a similar way.\n\n=== Fidelity bonds ===\n\nAnybody can enter the CoinSwap market as a maker, so there is a danger\nof sybil attacks. This is when an adversary deploys huge numbers of\nmaker bots. If the taker Alice chooses maker bots which are all\ncontrolled by the same person then that person can deanonymize Alice's\ntransaction by tracking the coins along the route.\n\nA solution to this is fidelity bonds. This is a mechanism where bitcoin\nvalue is deliberately sacrificed to make a cryptographic identity\nexpensive to obtain. The sacrifice is done in a way that can be proven\nto a third party. One way to create a fidelity bond is to lock up\nbitcoins in a time-locked address. We can code the taker bots to behave\nin a way that creates market pressure for maker bot operators to publish\nfidelity bonds. These fidelity bonds can be created anonymously by\nanyone who owns bitcoin.\n\nFidelity bonds are a genuine sacrifice which can't be faked, they can be\ncompared to proof-of-work which backs bitcoin mining. Then for a sybil\nattacker to be successful they would have to lock up a huge value in\nbitcoin for a long time. I've previously analyzed fidelity bonds for\nJoinMarket[4], and using realistic numbers I calculate that such a\nsystem would require about 55000 BTC (around 500 million USD at today's\nprice) to be locked up for 6 months in time-locked addresses. This is a\nhuge amount and provides strong sybil resistance.\n\n==== Who goes first ====\n\nFidelity bonds also solve the \"who goes first\" problem in CoinSwap.\n\nThis problem happens because either Alice or Bob must broadcast their\nfunding transaction first, but if the other side halts the protocol then\nthey can cause Alice or Bob's to waste time and miner fees as they're\nforced to use the contract transactions to get their money back. This is\na DOS attack. If a malicious CoinSwapper could keep halting the protocol\nthey could stop an honest user from doing a CoinSwap indefinitely.\nFidelity bonds solve this by having the fidelity bond holder go second.\nIf the fidelity bond holder halts the protocol then their fidelity bond\ncan be avoid by the user in all later CoinSwaps. And the malicious\nCoinSwapper could pack the orderbook with their sybils without\nsacrificing a lot of value for fidelity bonds.\n\nAs a concrete example, Alice is a taker and Bob is a maker. Bob\npublishes a fidelity bond. Alice \"goes first\" by sending her coins into\na 2-of-2 multisig between her and Bob. When Bob sees the transaction is\nconfirmed he broadcasts his own transactions into another 2-of-2\nmultisig. If Bob is actually malicious and halts the protocol then he\nwill cost Alice some time and money, but Alice will refuse to ever\nCoinSwap with Bob's fidelity bond again.\n\nIf DOS becomes a big problem even with fidelity bonds, then its possible\nto have Alice request a \"DOS proof\" from Bob before broadcasting, which\nis a set of data containing transactions, merkle proofs and signatures\nwhich are a contract where Bob promises to broadcast his own transaction\nif Alice does so first. If Alice gets DOSed then she can share this DOS\nproof publicly. The proof will have enough information to convince\nanyone else that the DOS really happened, and it means that nobody else\nwill ever CoinSwap with Bob's fidelity bond either (or at least assign\nsome kind of ban score to lower the probability). I doubt it will come\nto this so I haven't expanded the idea much, but theres a longer writeup\nin the reference[5].\n\n=== Private key handover ===\n\nThe original proposal for CoinSwap involved four transactions. Two to\npay into the multisig addresses and two to pay out. We can do better\nthan this with private key handover[6]. This is an observation that once\nthe CoinSwap preimage is revealed, Alice and Bob don't have to sign each\nother's multisig spend, instead they could hand over their private key\nto the other party. The other party will know both keys of the 2-of-2\nmultisig and therefore have unilateral control of the coins. Although\nthey would still need to watch the chain and respond in case a\nhash-time-locked contract transaction is broadcasted.\n\nAs well as saving block space, it also improves privacy because the\ncoins could stay unspent for a long time, potentially indefinitely.\nWhile in the original coinswap proposal an analyst of the chain would\nalways see a funding transaction followed closely in time by a\nsettlement transaction, and this could be used as a fingerprint.\n\nWe can go even further than private key handover using a scheme called\nSAS: Succinct Atomic Swap[7]. This scheme uses adapter signatures[8] to\ncreate a similar outcome to CoinSwap-with-private-key-handover, but only\none party in the CoinSwap must watch and respond to blockchain events\nuntil they spend the coin. The other party just gets unilateral control\nof their coins without needing to watch and respond.\n\n\n=== PayJoin with CoinSwap ===\n\nCoinSwap can be combined with CoinJoin. In original CoinSwap, Alice\nmight pay into a CoinSwap address with a regular transaction spending\nmultiple of her own inputs:\n\n    AliceInputA (1 BTC) ----> CoinSwap Address (3 BTC)\n    AliceInputB (2 BTC)\n\nThis leaks information that all of those inputs are owned by the same\nperson. We can make this example transaction a CoinJoin by involving\nBob's inputs too. CoinJoin requires interaction but because Alice and\nBob are already interacting to follow the CoinSwap protocol, so it's not\ntoo hard to have them interact a bit more to do a CoinJoin too. The\nCoinJoin transaction which funds the CoinSwap address would look like this:\n\n    AliceInputA (1 BTC) ----> CoinSwap Address (7 BTC)\n    AliceInputB (2 BTC)\n    BobInputA   (4 BTC)\n\nAlice's and Bob's inputs are both spent in a same transaction, which\nbreaks the common-input-ownership heuristic. This form of CoinJoin is\nmost similar to the PayJoin protocol or CoinJoinXT protocol. As with the\nrest of this design, this protocol does not have any special patterns\nand so is indistinguishable from any regular bitcoin transaction.\n\nTo make this work Bob the maker needs to provide two unrelated UTXOs,\none that is CoinSwapped and the other CoinJoined.\n\n==== Using decoy UTXOs to protecting from leaks ====\n\nIf Bob the maker was just handing out inputs for CoinJoins to any Alice\nwho asked, then malicious Alice's could constantly poll Bob to learn his\nUTXO and then halt the protocol. Malicious Alice could learn all of\nBob's UTXOs and easily unmix future CoinSwaps by watching their future\nspends.\n\nTo defend against this attack we have Bob maintain a list of \"decoy\nUTXOs\", which are UTXOs that Bob found by scanning recent blocks. Then\nwhen creating the CoinJoin, Bob doesn't just send his own input but\nsends perhaps 50 or 100 other inputs which don't belong to him. For the\nprotocol to continue Alice must partially-sign many CoinJoin\ntransactions; one for each of those inputs, and send them back to Bob.\nThen Bob can sign the transaction which contains his genuine input and\nbroadcast it. If Alice is actually a malicious spy she won't learn Bob's\ninput for sure but will only know 100 other inputs, the majority of\nwhich have nothing to do with Bob. By the time malicious Alice learns\nBob's true UTXO its already too late because its been spent and Alice is\nlocked into the CoinSwap protocol, requiring time, miner fees and\nCoinSwap fees to get out.\n\nThis method of decoy UTXOs has already been written about in the\noriginal PayJoin designs from 2018[9][10].\n\n=== Creating a communication network using federated message boards ===\n\nRight now JoinMarket uses public IRC networks for communication. This is\nsubpar for a number of reasons, and we can do better.\n\nI propose that there be a small number of volunteer-operated HTTP\nservers run on Tor hidden services. Their URLs are included in the\nCoinSwap software by default. They can be called message board servers.\nMakers are also servers run on hidden services, and to advertise\nthemselves they connect to these message board servers to post the\nmakers own .onion address. To protect from spam, makers must provide a\nfidelity bond before being allowed to write to the HTTP server.\n\nTakers connect to all these HTTP message boards and download the list of\nall known maker .onion addresses. They connect to each maker's onion to\nobtain parameters like offered coinswap fee and maximum coinswap size.\nThis is equivalent to downloading the orderbook on JoinMarket. Once\ntakers have chosen which makers they'll do a CoinSwap with, they\ncommunicate with those maker again directly through their .onion address\nto transmit the data needed to create CoinSwaps.\n\nThese HTTP message board servers can be run quite cheaply, which is\nrequired as they'd be volunteer run. They shouldn't require much\nbandwidth or disk space, as they are well-protected from spam with the\nfidelity bond requirement. The system can also tolerate temporary\ndowntimes so the servers don't need to be too reliable either. It's easy\nto imagine the volunteers running them on a raspberry pi in their own\nhome. These message board servers are similar in some ways to the DNS\nseeds used by Bitcoin Core to find its first peers on bitcoin's p2p\nnetwork. If the volunteers ever lose interest or disappear, then the\ncommunity of users could find new volunteer operators and add those URLs\nto the default list.\n\nIn order to censor a maker, _all_ the message board servers would have\nto co-operate to censor him. If censorship is happening on a large scale\n(for example if the message board servers only display sybil makers run\nby themselves) then takers could also notice a drop in the total value\nof all fidelity bonds.\n\n\n== How are CoinSwap and Lightning Network different? ==\n\nCoinSwap and Lightning Network have many similarities, so it's natural\nto ask why are they different, and why do we need a CoinSwap system at\nall if we already have Lightning?\n\n=== CoinSwap can be adopted unilaterally and is on-chain ===\n\nToday we see some centralized exchange not supporting so-called\n``privacy altcoins'' because of regulatory compliance concerns. We also\nsee some exchanges frowning upon or blocking CoinJoin transaction they\ndetect[11]. (There is some debate over whether the exchanges really\nblocked transactions because they were CoinJoin, but the principle\nremains that equal-output CoinJoins are inherently visible as such).\nIt's possible that those exchanges will never adopt Lightning because of\nits privacy features.\n\nSuch a refusal would simply not be possible with CoinSwap, because it is\nfundamentally an on-chain technology. CoinSwap users pay to bitcoin\naddresses, not Lightning invoices. Anybody who accepts bitcoin today\nwill accept CoinSwap. And because CoinSwap transactions can be made\nindistinguishable from regular transactions, it would be very difficult\nto even determine whether they got paid via a CoinSwap or not. So\nCoinSwap is not a replacement for Lightning, instead it is a replacement\nfor on-chain privacy technology such as equal-output CoinJoins which are\nimplemented today in JoinMarket, Wasabi Wallet and Samourai Wallet.\nIdeally this design, if implemented, would be possible to include into\nthe many already-existing bitcoin wallets, and so the CoinSwaps would be\naccessible to everyone.\n\nThis feature of CoinSwap will in turn help Lightning Network, because\nthose censoring exchanges won't be able to stop transactions with\nundetectable privacy no matter what they do. When they realize this\nthey'll likely just implement Lightning Network anyway regardless of the\nprivacy.\n\nBitcoin needs on-chain privacy as well, otherwise the bad privacy can\nleak into layer-2 solutions.\n\n=== Different ways of solving liquidity ===\n\nLightning Network cannot support large payment amounts. Liquidity in\npayment channels on the Lightning network is a scarce resource. Nodes\nwhich relay lightning payments always take care that a payment does not\nexhaust their liquidity. Users of Lightning today must often be aware of\ninbound liquidity, outbound liquidity and channel rebalancing. There\neven exist services today which sell Lightning liquidity.\n\nThis CoinSwap design solves its liquidity problem in a completely\ndifferent way. Because of the liquidity market similar to JoinMarket,\nall the required liquidity is always available. There are never any\nconcerns about exhausting channel capacity or a route not being found,\nbecause such liquidity is simply purchased from the liquidity market\nright before it is used.\n\nIt is still early days for Lightning, and liquidity has been a known\nissue since the start. Many people are confident that the liquidity\nissue will be improved. Yet it seems hard to imagine that Lightning\nNetwork will ever reliably route payments of 200 BTC to any node in the\nnetwork (and it doesn't have to to be successful), yet on JoinMarket\ntoday as I write these words there are offers to create CoinJoins with\namounts up to around 200 BTC. We can expect similar large amounts to be\nsendable in CoinSwap. The liquidity market as a solution is known to\nwork and has been working for years.\n\n=== Sybil resistance ===\n\nCoinSwap can support fidelity bonds and so can be made much more\nresistant to sybil attacks. We saw in the earlier section that realistic\nnumbers from JoinMarket imply a sybil attacker would have to lock up\nhundreds of millions of USD worth of bitcoin to successfully deanonymize\nusers.\n\nIt's difficult to compare this to the cost of a sybil attack in\nLightning network as such attacks are hard to analyze. For example, the\nattacker needs to convince users to route payments through the\nattacker's own nodes, and maybe they could do this, but putting numbers\non it is hard. Even so it is very likely that the true cost is much less\nthan 500 million USD locked up for months because Lightning nodes can be\nset up for not more than the cost of hardware and payment channel\ncapacity, while CoinSwap makers would require expensive fidelity bond\nsacrifices.\n\nAs this CoinSwap design would cost much more sybil attack, its privacy\nwould be much greater in this respect.\n\n\n== How are CoinSwap, PayJoin and PaySwap different? ==\n\nPayJoin can also be indistinguishable from regular bitcoin transaction,\nso why don't we all just that and not go further?\n\nThe answer is the threat models. PayJoin works by having the customer\nand merchant together co-operate to increase both their privacy. It\nworks if the adversary of both of them is a passive observer of the\nblockchain.\n\nPayJoin doesnt help a customer at all if the user's adversary is the\nmerchant. This situation happens all the time today, for example\nexchanges spying on their customers. CoinSwap can help in this\nsituation, as it doesn't assume or require that the second party is your\nfriend. The same argument applies to PaySwap.\n\nObviously PayJoin and PaySwap are still very useful, but they operate\nunder different threat models.\n\n\n== Conclusion ==\n\nCoinSwap is a promising privacy protocol because it breaks the\ntransaction graph heuristic, but it cant work on its own. In order to\ncreate a truly private system of sending transactions which would\nimprove bitcoin's fungibility, CoinSwap must be combined with a couple\nof other building blocks:\n\n* ECDSA-2P\n* Liquidity market\n* Routed CoinSwaps\n* Multi-transaction CoinSwaps\n* Breaking change output heuristics\n* Fidelity bonds\n* PayJoin with CoinSwap\n* Federated message boards protected from spam with fidelity bonds\n\nCoinSwap transactions could be made to look just like any other regular\nbitcoin transaction, with no distinguishing fingerprint. This would make\nthem invisible.\n\nI intend to create this CoinSwap software. It will be almost completely\ndecentralized and available for all to use for free. The design is\npublished here for review. If you want to help support development I\naccept donations at https://bitcoinprivacy.me/coinswap-donations\n\n\n== References ==\n\n- [1] \"CoinSwap: Transaction graph disjoint trustless trading\"\nhttps://bitcointalk.org/index.php?topic=321228.0\n\n- [2]\nhttp://diyhpl.us/wiki/transcripts/scalingbitcoin/tokyo-2018/scriptless-ecdsa/\n\n- [3] https://en.bitcoin.it/wiki/Privacy#Change_address_detection\n\n- [4] \"Design for improving JoinMarket's resistance to sybil attacks\nusing fidelity bonds\"\nhttps://gist.github.com/chris-belcher/18ea0e6acdb885a2bfbdee43dcd6b5af/\n\n- [5] https://github.com/AdamISZ/CoinSwapCS/issues/50\n\n- [6] https://github.com/AdamISZ/CoinSwapCS/issues/53\n\n- [7]\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-May/017846.html\n\n- [8]\nhttps://github.com/ElementsProject/scriptless-scripts/blob/master/md/atomic-swap.md\n\n- [9]\nhttps://blockstream.com/2018/08/08/en-improving-privacy-using-pay-to-endpoint/\n\n- [10] https://medium.com/@nopara73/pay-to-endpoint-56eb05d3cac6\n\n- [11]\nhttps://cointelegraph.com/news/binance-returns-frozen-btc-after-user-promises-not-to-use-coinjoin"
            },
            {
                "author": "Ruben Somsen",
                "date": "2020-05-30T16:00:05",
                "message_text_only": "Hey Chris,\n\nExcellent write-up. I learned a few new things while reading this\n(particularly how to overcome the heuristics for address reuse and address\ntypes), so thank you for that.\n\nI have a few thoughts about how what you wrote relates to Succinct Atomic\nSwaps (SAS)[0]. Perhaps it's useful.\n\n>For a much greater anonymity set we can use 2-party ECDSA to create 2-of-2\nmultisignature addresses that look the same as regular single-signature\naddresses\n\nThis may perhaps be counter-intuitive, but SAS doesn't actually require\nmultisig for one of the two outputs, so a single key will suffice. ECDSA is\na signing algorithm that doesn't support single key multisig (at least not\nwithout 2p-ECDSA), but notice how for the non-timelocked SAS output we\nnever actually have to sign anything together with the other party. We swap\none of the two keys, and the final owner will create a signature completely\non their own. No multisig required, which means we can simply use MuSig,\neven today without Schnorr.\n\nOf course the other output will still have to be a 2-of-2, for which you\nrightly note 2p-ECDSA could be considered. It may also be interesting to\ncombine a swap with the opening of a Lightning channel. E.g. Alice and Bob\nwant to open a channel with 1 BTC each, but Alice funds it in her entirety\nwith 2 BTC, and Bob gives 1 BTC to Alice in a swap. This makes it difficult\nto tell Bob entered the Lightning Network, especially if the channel is\nopened in a state that isn't perfectly balanced. And Alice will gain an\nuncorrelated single key output.\n\nAs a side note, we could use the same MuSig observation on 2-of-2 outputs\nthat need multisig by turning the script into (A & B) OR MuSig(A,B), which\nwould shave off quite a few bytes by allowing single sig spending once the\nprivate key is handed over, but this would also make the output stick out\nlike a sore thumb... Only useful if privacy is not a concern.\n\n>=== Multi-transaction CoinSwaps to avoid amount correlation ===\n\nThis can apply cleanly to SAS, and can even be done without passing on any\nextra secrets by generating a sharedSecret (Diffie-Hellman key exchange).\n\nNon-timelocked:\nCoinSwap AddressB = aliceSecret + bobSecret\nCoinSwap AddressC = aliceSecret + bobSecret + hash(sharedSecret,0)*G\nCoinSwap AddressD  = aliceSecret + bobSecret + hash(sharedSecret,1)*G\n\nThe above is MuSig compatible (single key outputs), there are no timelocks\nto worry about, and the addresses cannot be linked on-chain.\n\n>they would still need to watch the chain and respond in case a\nhash-time-locked contract transaction is broadcasted\n\nSmall detail, but it should be noted that this would require the atomic\nswap to be set up in a specific way with relative timelocks.\n\n>=== PayJoin with CoinSwap ===\n\nWhile it's probably clear how to do it on the timelocked side of SAS, I\nbelieve PayJoin can also be applied to the non-timelocked side. This does\nrequire adding a transaction that undoes the PayJoin in case the swap gets\naborted, which means MuSig can't be used. Everything else stays the same:\nonly one tx if successful, and no timelock (= instant settlement). I can\nexplain it in detail, if it happens to catch your interest.\n\nCheers,\nRuben\n\n\n[0]  Succinct Atomic Swaps (SAS)\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-May/017846.html\n\nOn Mon, May 25, 2020 at 3:21 PM Chris Belcher via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> === Abstract ===\n>\n> Imagine a future where a user Alice has bitcoins and wants to send them\n> with maximal privacy, so she creates a special kind of transaction. For\n> anyone looking at the blockchain her transaction appears completely\n> normal with her coins seemingly going from address A to address B. But\n> in reality her coins end up in address Z which is entirely unconnected\n> to either A or B.\n>\n> Now imagine another user, Carol, who isn't too bothered by privacy and\n> sends her bitcoin using a regular wallet which exists today. But because\n> Carol's transaction looks exactly the same as Alice's, anybody analyzing\n> the blockchain must now deal with the possibility that Carol's\n> transaction actually sent her coins to a totally unconnected address. So\n> Carol's privacy is improved even though she didn't change her behaviour,\n> and perhaps had never even heard of this software.\n>\n> In a world where advertisers, social media and other companies want to\n> collect all of Alice's and Carol's data, such privacy improvement would\n> be incredibly valuable. And also the doubt added to every transaction\n> would greatly boost the fungibility of bitcoin and so make it a better\n> form of money.\n>\n> This undetectable privacy can be developed today by implementing\n> CoinSwap, although by itself that isn't enough. There must be many\n> building blocks which together make a good system. The software could be\n> standalone as a kind of bitcoin mixing app, but it could also be a\n> library that existing wallets can implement allowing their users to send\n> Bitcoin transactions with much greater privacy.\n>\n> == CoinSwap ==\n>\n> Like CoinJoin, CoinSwap was invented in 2013 by Greg Maxwell[1]. Unlike\n> CoinJoin it is relatively complicated to implement and so far has not\n> been deployed. But the idea holds great promise, and fixes many of the\n> problems of some kinds of CoinJoins. CoinSwap is the next step for\n> on-chain bitcoin privacy.\n>\n> CoinSwap is a way of trading one coin for another coin in a\n> non-custodial way. It is closely related to the idea of an atomic swap.\n> Alice and Bob can trade coins with each other by first sending to a\n> CoinSwap address and having those coins then sent to Bob:\n>\n>     Alice's Address 1 ----> CoinSwap Address 1 ----> Bob's Address 1\n>\n> An entirely separate set of transactions gives Bob's coins to Alice in\n> return:\n>\n>     Bob's Address 2 ----> CoinSwap Address 2 ----> Alice's Address 2\n>\n> Where the symbol ----> is a bitcoin transaction.\n>\n> Privacy is improved because an observer of the blockchain cannot link\n> Alice's Address 1 to Alice's Address 2, as there is no transaction\n> between them. Alice's Address 2 could either be an address in Alice's\n> wallet, or the address of someone else she wants to transfer money to.\n> CoinSwap therefore breaks the transaction graph heuristic, which is the\n> assumption that if a transaction A -> B is seen then the ownership of\n> funds actually went from A to B.\n>\n> CoinSwap doesnt break any of bitcoin's assumptions or features like an\n> auditable supply or pruning. It can be built on today's bitcoin without\n> any new soft forks.\n>\n> CoinSwap can't improve privacy much on its own, so it requires other\n> building block to create a truly private system.\n>\n> === ECDSA-2P ===\n>\n> The original CoinSwap idea uses 2-of-2 multisig. We can get a slightly\n> bigger anonymity set by using 2-of-3 multisigs with a fake third public\n> key. For a much greater anonymity set we can use 2-party ECDSA to create\n> 2-of-2 multisignature addresses that look the same as regular\n> single-signature addresses[2]. Even the old-style p2pkh addresses\n> starting with 1 can be CoinSwap addresses.\n>\n> Because the transactions blend in with the rest of bitcoin, an\n> application based on CoinSwap would provide much more privacy than the\n> existing equal-output coinjoin apps (JoinMarket, Wasabi Wallet and\n> Samourai Wallet's Whirlpool). CoinSwaps would also be cheaper for the\n> same amount of privacy, as CoinJoin users usually create multiple\n> CoinJoins to get effective privacy, for example JoinMarket's tumbler\n> script does between 7-12 coinjoins (which are bigger than regular\n> transactions too) when run with default parameters.\n>\n> Schnorr signatures with Musig provide a much easier way to create\n> invisible 2-of-2 multisig, but it is not as suitable for CoinSwap. This\n> is because the anonymity set for ECDSA would be much greater. All\n> addresses today are ECDSA, and none are schnorr. We'd have to wait for\n> schnorr to be added to bitcoin and then wait for users to adopt it. We\n> see with segwit that even after nearly 3 years that segwit adoption is\n> only about 60%, and segwit actually has a sizeable financial incentive\n> for adoption via lower fees. Schnorr when used for single-sig doesn't\n> have such an incentive, as Schnorr single-sig costs the same size as\n> today's p2wpkh, so we can expect adoption to be even slower. (Of course\n> there is an incentive for multisig transactions, but most transactions\n> are single-sig). As schnorr adoption increases this CoinSwap system\n> could start to use it, but for a long time I suspect it will mostly be\n> using ECDSA for a greater anonymity set.\n>\n> === Liquidity market ===\n>\n> We can create a liquidity market for CoinSwap very similar to how\n> JoinMarket works for CoinJoins. In our example above Alice would be a\n> market taker and Bob would be a market maker. The taker Alice pays a fee\n> to the maker Bob in return for choosing the amount of a CoinSwap and\n> when it happens. This allows an excellent user experience because Alice\n> can create CoinSwaps for any size she wants, at any time she wants.\n> Right now in JoinMarket there is liquidity to create CoinJoins of sizes\n> up to about 200 BTC, and we can expect a similar kind of thing with\n> CoinSwap.\n>\n>\n> === Multi-transaction CoinSwaps to avoid amount correlation ===\n>\n> This CoinSwap is vulnerable to amount correlation:\n>\n>     AliceA (15 BTC) ----> CoinSwap AddressA ----> BobA (15 BTC)\n>     BobB (15 BTC) ----> CoinSwap AddressB ----> AliceB (15 BTC)\n>\n> Where AliceA, AliceB are addresses belonging to Alice. BobA, BobB are\n> addresses belonging to Bob. If an adversary starts tracking at address\n> AliceA they could unmix this CoinSwap easily by searching the entire\n> blockchain for other transactions with amounts close to 15 BTC, which\n> would lead them to address AliceB. We can beat this amount correlation\n> attack by creating multi-transaction CoinSwaps. For example:\n>\n>     AliceA (15 BTC) ----> CoinSwap AddressA ----> BobA (15 BTC)\n>\n>     BobB (7 BTC) ----> CoinSwap AddressB ----> AliceB (7 BTC)\n>     BobC (5 BTC) ----> CoinSwap AddressC ----> AliceC (5 BTC)\n>     BobD (3 BTC) ----> CoinSwap AddressD ----> AliceD (3 BTC)\n>\n> Now in the multi-transaction CoinSwap, the market taker Alice has given\n> 10 BTC and got back three transactions which add up to the same amount,\n> but nowhere on the blockchain is there an output where Alice received\n> exactly 15 BTC.\n>\n> === Routing CoinSwaps to avoid a single points of trust ===\n>\n> In the original CoinSwap idea there are only two parties Alice and Bob,\n> so when they CoinSwap Bob will know exactly where the Alice's coins\n> went. This means Bob is a single point of failure in Alice's privacy,\n> and Alice must trust him not to spy on her.\n>\n> To spread out and decentralize the trust, we can create CoinSwaps where\n> Alice's payment is routed through many Bobs.\n>\n>     AliceA ====> Bob ====> Charlie ====> Dennis ====> AliceB\n>\n> Where the symbol ====> means one CoinSwap. In this situation Alice will\n> be a market taker in the liquidity market, and all the other entities\n> (Bob, Charlie, Dennis) will be market makers. Only Alice will know the\n> entire route, and the makers will only know the previous and next\n> bitcoin addresses along the route.\n>\n> This could be made to work by Alice handling almost everything about the\n> CoinSwap on the other maker's behalf. The makers wouldn't have TCP\n> connections between each other, but only to Alice, and she would relay\n> CoinSwap-relevant information between them. The other makers are not\n> aware whether their incoming coins came from Alice herself or the\n> previous maker in Alice's route.\n>\n>\n> === Combining multi-transaction with routing ===\n>\n> Routing and multi-transaction must be combined to get both benefits. If\n> Alice owns multiple UTXOs (of value 6 BTC, 8 BTC and 1 BTC) then this is\n> easy with this configuration:\n>\n>              Alice\n>     (6 BTC) (8 BTC) (1 BTC)\n>        |       |       |\n>        |       |       |\n>        v       v       v\n>               Bob\n>     (5 BTC) (5 BTC) (5 BTC)\n>        |       |       |\n>        |       |       |\n>        v       v       v\n>             Charlie\n>     (9 BTC) (5 BTC) (1 BTC)\n>        |       |       |\n>        |       |       |\n>        v       v       v\n>             Dennis\n>     (7 BTC) (4 BTC) (4 BTC)\n>        |       |       |\n>        |       |       |\n>        v       v       v\n>              Alice\n>\n> Where the downward arrow symbol is a single CoinSwap hash-time-locked\n> contract. Each hop uses multiple transactions so no maker (Bob, Charlie,\n> Dennis) is able to use amount correlation to find addresses not directly\n> related to them, but at each hop the total value adds up to the same\n> amount 15 BTC. And all 3 makers must collude in order to track the\n> source and destination of the bitcoins.\n>\n> If Alice starts with only a single UTXO then the above configuration is\n> still vulnerable to amount correlation. One of the later makers (e.g.\n> Dennis) knows that the total coinswap amount is 15 BTC, and could search\n> the blockchain to find Alice's single UTXO. In such a situation Alice\n> must use a branching configuration:\n>\n>                           Alice\n>                          (15 BTC)\n>                             |\n>                             |\n>                             v\n>                            Bob\n>                           /   \\\n>                          /     \\\n>              <-----------       ----------->\n>              |                             |\n>   (2 BTC) (2 BTC) (2 BTC)        (3 BTC) (3 BTC) (3 BTC)\n>              |                             |\n>              |                             |\n>              v                             v\n>           Charlie                       Dennis\n>   (1 BTC) (2 BTC) (3 BTC)       (5 BTC) (3 BTC) (1 BTC)\n>      |       |       |             |       |       |\n>      |       |       |             |       |       |\n>      v       v       v             v       v       v\n>           Edward                          Fred\n>   (4 BTC) (1 BTC) (1 BTC)       (4 BTC) (2 BTC) (1 BTC)\n>      |       |       |             |       |       |\n>      |       |       |             |       |       |\n>      v       v       v             v       v       v\n>            Alice                         Alice\n>\n> In this diagram, Alice sends 15 BTC to Bob via CoinSwap who sends 6 BTC\n> on to Charlie and the remaining 9 BTC to Dennis. Charlie and Dennis do a\n> CoinSwap with Edward and Fred who forward the coins to Alice. None of\n> the makers except Bob know the full 15 BTC amount and so can't search\n> the blockchain backwards for Alice's initial UTXO. Because of multiple\n> transactions Bob cannot look forward to search for the amounts he sent 6\n> BTC and 9 BTC. A minimum of 3 makers in this example need to collude to\n> know the source and destination of the coins.\n>\n> Another configuration is branch merging, which Alice would find useful\n> if she has two or more UTXOs for which there must not be evidence that\n> they're owned by the same entity, and so they must not be spent together\n> in the same transaction.\n>\n>            Alice                         Alice\n>           (9 BTC)                       (6 BTC)\n>              |                             |\n>              |                             |\n>              v                             v\n>             Bob                         Charlie\n>   (4 BTC) (3 BTC) (2 BTC)       (1 BTC) (2 BTC) (3 BTC)\n>      |       |       |             |       |       |\n>      |       |       |             |       |       |\n>       \\       \\       \\           /       /       /\n>        \\       \\       \\         /       /       /\n>         \\       \\       \\       /       /       /\n>          >------->-------\\     /-------<-------<\n>                           \\   /\n>                           Alice\n>                          (15 BTC)\n>\n> In this diagram Alice sends the two UTXOs (9 BTC and 6 BTC) to two\n> different makers, who forward it onto Alice. Because the two UTXOs have\n> been transferred to different makers they will likely never be co-spent.\n>\n> These complex multi-transaction routed coinswaps are only for the\n> highest threat models where the makers themselves are adversaries. In\n> practice most users would probably choose to use just one or two hops.\n>\n>\n> === Breaking change output and wallet fingerprinting heuristics ===\n>\n> Equal-output CoinJoins easily leak change addresses (unless they are\n> sweeps with no change). CoinSwap doesn't have this flaw which allows us\n> to break some of the weaker change output heuristics[3].\n>\n> For example address reuse. If an output address has been reused it is\n> very likely to be a payment output, not a change output. In a CoinSwap\n> application we can break this heuristic by having makers randomly with\n> some probability send their change to an address they've used before.\n> That will make the heuristics think that the real change address is\n> actually the payment address, and the real payment is actually the\n> change, and could result in an analyzer of the blockchain grouping the\n> payment address inside the maker's own wallet cluster.\n>\n> Another great heuristic to break is the script type heuristic. If the\n> maker's input are all in p2sh-p2wpkh addresses, and their payment\n> address is also of type p2sh-p2wpkh, then the maker could with some\n> probability set the change address to a different type such as p2wpkh.\n> This could trick a chain analyzer in a similar way.\n>\n> === Fidelity bonds ===\n>\n> Anybody can enter the CoinSwap market as a maker, so there is a danger\n> of sybil attacks. This is when an adversary deploys huge numbers of\n> maker bots. If the taker Alice chooses maker bots which are all\n> controlled by the same person then that person can deanonymize Alice's\n> transaction by tracking the coins along the route.\n>\n> A solution to this is fidelity bonds. This is a mechanism where bitcoin\n> value is deliberately sacrificed to make a cryptographic identity\n> expensive to obtain. The sacrifice is done in a way that can be proven\n> to a third party. One way to create a fidelity bond is to lock up\n> bitcoins in a time-locked address. We can code the taker bots to behave\n> in a way that creates market pressure for maker bot operators to publish\n> fidelity bonds. These fidelity bonds can be created anonymously by\n> anyone who owns bitcoin.\n>\n> Fidelity bonds are a genuine sacrifice which can't be faked, they can be\n> compared to proof-of-work which backs bitcoin mining. Then for a sybil\n> attacker to be successful they would have to lock up a huge value in\n> bitcoin for a long time. I've previously analyzed fidelity bonds for\n> JoinMarket[4], and using realistic numbers I calculate that such a\n> system would require about 55000 BTC (around 500 million USD at today's\n> price) to be locked up for 6 months in time-locked addresses. This is a\n> huge amount and provides strong sybil resistance.\n>\n> ==== Who goes first ====\n>\n> Fidelity bonds also solve the \"who goes first\" problem in CoinSwap.\n>\n> This problem happens because either Alice or Bob must broadcast their\n> funding transaction first, but if the other side halts the protocol then\n> they can cause Alice or Bob's to waste time and miner fees as they're\n> forced to use the contract transactions to get their money back. This is\n> a DOS attack. If a malicious CoinSwapper could keep halting the protocol\n> they could stop an honest user from doing a CoinSwap indefinitely.\n> Fidelity bonds solve this by having the fidelity bond holder go second.\n> If the fidelity bond holder halts the protocol then their fidelity bond\n> can be avoid by the user in all later CoinSwaps. And the malicious\n> CoinSwapper could pack the orderbook with their sybils without\n> sacrificing a lot of value for fidelity bonds.\n>\n> As a concrete example, Alice is a taker and Bob is a maker. Bob\n> publishes a fidelity bond. Alice \"goes first\" by sending her coins into\n> a 2-of-2 multisig between her and Bob. When Bob sees the transaction is\n> confirmed he broadcasts his own transactions into another 2-of-2\n> multisig. If Bob is actually malicious and halts the protocol then he\n> will cost Alice some time and money, but Alice will refuse to ever\n> CoinSwap with Bob's fidelity bond again.\n>\n> If DOS becomes a big problem even with fidelity bonds, then its possible\n> to have Alice request a \"DOS proof\" from Bob before broadcasting, which\n> is a set of data containing transactions, merkle proofs and signatures\n> which are a contract where Bob promises to broadcast his own transaction\n> if Alice does so first. If Alice gets DOSed then she can share this DOS\n> proof publicly. The proof will have enough information to convince\n> anyone else that the DOS really happened, and it means that nobody else\n> will ever CoinSwap with Bob's fidelity bond either (or at least assign\n> some kind of ban score to lower the probability). I doubt it will come\n> to this so I haven't expanded the idea much, but theres a longer writeup\n> in the reference[5].\n>\n> === Private key handover ===\n>\n> The original proposal for CoinSwap involved four transactions. Two to\n> pay into the multisig addresses and two to pay out. We can do better\n> than this with private key handover[6]. This is an observation that once\n> the CoinSwap preimage is revealed, Alice and Bob don't have to sign each\n> other's multisig spend, instead they could hand over their private key\n> to the other party. The other party will know both keys of the 2-of-2\n> multisig and therefore have unilateral control of the coins. Although\n> they would still need to watch the chain and respond in case a\n> hash-time-locked contract transaction is broadcasted.\n>\n> As well as saving block space, it also improves privacy because the\n> coins could stay unspent for a long time, potentially indefinitely.\n> While in the original coinswap proposal an analyst of the chain would\n> always see a funding transaction followed closely in time by a\n> settlement transaction, and this could be used as a fingerprint.\n>\n> We can go even further than private key handover using a scheme called\n> SAS: Succinct Atomic Swap[7]. This scheme uses adapter signatures[8] to\n> create a similar outcome to CoinSwap-with-private-key-handover, but only\n> one party in the CoinSwap must watch and respond to blockchain events\n> until they spend the coin. The other party just gets unilateral control\n> of their coins without needing to watch and respond.\n>\n>\n> === PayJoin with CoinSwap ===\n>\n> CoinSwap can be combined with CoinJoin. In original CoinSwap, Alice\n> might pay into a CoinSwap address with a regular transaction spending\n> multiple of her own inputs:\n>\n>     AliceInputA (1 BTC) ----> CoinSwap Address (3 BTC)\n>     AliceInputB (2 BTC)\n>\n> This leaks information that all of those inputs are owned by the same\n> person. We can make this example transaction a CoinJoin by involving\n> Bob's inputs too. CoinJoin requires interaction but because Alice and\n> Bob are already interacting to follow the CoinSwap protocol, so it's not\n> too hard to have them interact a bit more to do a CoinJoin too. The\n> CoinJoin transaction which funds the CoinSwap address would look like this:\n>\n>     AliceInputA (1 BTC) ----> CoinSwap Address (7 BTC)\n>     AliceInputB (2 BTC)\n>     BobInputA   (4 BTC)\n>\n> Alice's and Bob's inputs are both spent in a same transaction, which\n> breaks the common-input-ownership heuristic. This form of CoinJoin is\n> most similar to the PayJoin protocol or CoinJoinXT protocol. As with the\n> rest of this design, this protocol does not have any special patterns\n> and so is indistinguishable from any regular bitcoin transaction.\n>\n> To make this work Bob the maker needs to provide two unrelated UTXOs,\n> one that is CoinSwapped and the other CoinJoined.\n>\n> ==== Using decoy UTXOs to protecting from leaks ====\n>\n> If Bob the maker was just handing out inputs for CoinJoins to any Alice\n> who asked, then malicious Alice's could constantly poll Bob to learn his\n> UTXO and then halt the protocol. Malicious Alice could learn all of\n> Bob's UTXOs and easily unmix future CoinSwaps by watching their future\n> spends.\n>\n> To defend against this attack we have Bob maintain a list of \"decoy\n> UTXOs\", which are UTXOs that Bob found by scanning recent blocks. Then\n> when creating the CoinJoin, Bob doesn't just send his own input but\n> sends perhaps 50 or 100 other inputs which don't belong to him. For the\n> protocol to continue Alice must partially-sign many CoinJoin\n> transactions; one for each of those inputs, and send them back to Bob.\n> Then Bob can sign the transaction which contains his genuine input and\n> broadcast it. If Alice is actually a malicious spy she won't learn Bob's\n> input for sure but will only know 100 other inputs, the majority of\n> which have nothing to do with Bob. By the time malicious Alice learns\n> Bob's true UTXO its already too late because its been spent and Alice is\n> locked into the CoinSwap protocol, requiring time, miner fees and\n> CoinSwap fees to get out.\n>\n> This method of decoy UTXOs has already been written about in the\n> original PayJoin designs from 2018[9][10].\n>\n> === Creating a communication network using federated message boards ===\n>\n> Right now JoinMarket uses public IRC networks for communication. This is\n> subpar for a number of reasons, and we can do better.\n>\n> I propose that there be a small number of volunteer-operated HTTP\n> servers run on Tor hidden services. Their URLs are included in the\n> CoinSwap software by default. They can be called message board servers.\n> Makers are also servers run on hidden services, and to advertise\n> themselves they connect to these message board servers to post the\n> makers own .onion address. To protect from spam, makers must provide a\n> fidelity bond before being allowed to write to the HTTP server.\n>\n> Takers connect to all these HTTP message boards and download the list of\n> all known maker .onion addresses. They connect to each maker's onion to\n> obtain parameters like offered coinswap fee and maximum coinswap size.\n> This is equivalent to downloading the orderbook on JoinMarket. Once\n> takers have chosen which makers they'll do a CoinSwap with, they\n> communicate with those maker again directly through their .onion address\n> to transmit the data needed to create CoinSwaps.\n>\n> These HTTP message board servers can be run quite cheaply, which is\n> required as they'd be volunteer run. They shouldn't require much\n> bandwidth or disk space, as they are well-protected from spam with the\n> fidelity bond requirement. The system can also tolerate temporary\n> downtimes so the servers don't need to be too reliable either. It's easy\n> to imagine the volunteers running them on a raspberry pi in their own\n> home. These message board servers are similar in some ways to the DNS\n> seeds used by Bitcoin Core to find its first peers on bitcoin's p2p\n> network. If the volunteers ever lose interest or disappear, then the\n> community of users could find new volunteer operators and add those URLs\n> to the default list.\n>\n> In order to censor a maker, _all_ the message board servers would have\n> to co-operate to censor him. If censorship is happening on a large scale\n> (for example if the message board servers only display sybil makers run\n> by themselves) then takers could also notice a drop in the total value\n> of all fidelity bonds.\n>\n>\n> == How are CoinSwap and Lightning Network different? ==\n>\n> CoinSwap and Lightning Network have many similarities, so it's natural\n> to ask why are they different, and why do we need a CoinSwap system at\n> all if we already have Lightning?\n>\n> === CoinSwap can be adopted unilaterally and is on-chain ===\n>\n> Today we see some centralized exchange not supporting so-called\n> ``privacy altcoins'' because of regulatory compliance concerns. We also\n> see some exchanges frowning upon or blocking CoinJoin transaction they\n> detect[11]. (There is some debate over whether the exchanges really\n> blocked transactions because they were CoinJoin, but the principle\n> remains that equal-output CoinJoins are inherently visible as such).\n> It's possible that those exchanges will never adopt Lightning because of\n> its privacy features.\n>\n> Such a refusal would simply not be possible with CoinSwap, because it is\n> fundamentally an on-chain technology. CoinSwap users pay to bitcoin\n> addresses, not Lightning invoices. Anybody who accepts bitcoin today\n> will accept CoinSwap. And because CoinSwap transactions can be made\n> indistinguishable from regular transactions, it would be very difficult\n> to even determine whether they got paid via a CoinSwap or not. So\n> CoinSwap is not a replacement for Lightning, instead it is a replacement\n> for on-chain privacy technology such as equal-output CoinJoins which are\n> implemented today in JoinMarket, Wasabi Wallet and Samourai Wallet.\n> Ideally this design, if implemented, would be possible to include into\n> the many already-existing bitcoin wallets, and so the CoinSwaps would be\n> accessible to everyone.\n>\n> This feature of CoinSwap will in turn help Lightning Network, because\n> those censoring exchanges won't be able to stop transactions with\n> undetectable privacy no matter what they do. When they realize this\n> they'll likely just implement Lightning Network anyway regardless of the\n> privacy.\n>\n> Bitcoin needs on-chain privacy as well, otherwise the bad privacy can\n> leak into layer-2 solutions.\n>\n> === Different ways of solving liquidity ===\n>\n> Lightning Network cannot support large payment amounts. Liquidity in\n> payment channels on the Lightning network is a scarce resource. Nodes\n> which relay lightning payments always take care that a payment does not\n> exhaust their liquidity. Users of Lightning today must often be aware of\n> inbound liquidity, outbound liquidity and channel rebalancing. There\n> even exist services today which sell Lightning liquidity.\n>\n> This CoinSwap design solves its liquidity problem in a completely\n> different way. Because of the liquidity market similar to JoinMarket,\n> all the required liquidity is always available. There are never any\n> concerns about exhausting channel capacity or a route not being found,\n> because such liquidity is simply purchased from the liquidity market\n> right before it is used.\n>\n> It is still early days for Lightning, and liquidity has been a known\n> issue since the start. Many people are confident that the liquidity\n> issue will be improved. Yet it seems hard to imagine that Lightning\n> Network will ever reliably route payments of 200 BTC to any node in the\n> network (and it doesn't have to to be successful), yet on JoinMarket\n> today as I write these words there are offers to create CoinJoins with\n> amounts up to around 200 BTC. We can expect similar large amounts to be\n> sendable in CoinSwap. The liquidity market as a solution is known to\n> work and has been working for years.\n>\n> === Sybil resistance ===\n>\n> CoinSwap can support fidelity bonds and so can be made much more\n> resistant to sybil attacks. We saw in the earlier section that realistic\n> numbers from JoinMarket imply a sybil attacker would have to lock up\n> hundreds of millions of USD worth of bitcoin to successfully deanonymize\n> users.\n>\n> It's difficult to compare this to the cost of a sybil attack in\n> Lightning network as such attacks are hard to analyze. For example, the\n> attacker needs to convince users to route payments through the\n> attacker's own nodes, and maybe they could do this, but putting numbers\n> on it is hard. Even so it is very likely that the true cost is much less\n> than 500 million USD locked up for months because Lightning nodes can be\n> set up for not more than the cost of hardware and payment channel\n> capacity, while CoinSwap makers would require expensive fidelity bond\n> sacrifices.\n>\n> As this CoinSwap design would cost much more sybil attack, its privacy\n> would be much greater in this respect.\n>\n>\n> == How are CoinSwap, PayJoin and PaySwap different? ==\n>\n> PayJoin can also be indistinguishable from regular bitcoin transaction,\n> so why don't we all just that and not go further?\n>\n> The answer is the threat models. PayJoin works by having the customer\n> and merchant together co-operate to increase both their privacy. It\n> works if the adversary of both of them is a passive observer of the\n> blockchain.\n>\n> PayJoin doesnt help a customer at all if the user's adversary is the\n> merchant. This situation happens all the time today, for example\n> exchanges spying on their customers. CoinSwap can help in this\n> situation, as it doesn't assume or require that the second party is your\n> friend. The same argument applies to PaySwap.\n>\n> Obviously PayJoin and PaySwap are still very useful, but they operate\n> under different threat models.\n>\n>\n> == Conclusion ==\n>\n> CoinSwap is a promising privacy protocol because it breaks the\n> transaction graph heuristic, but it cant work on its own. In order to\n> create a truly private system of sending transactions which would\n> improve bitcoin's fungibility, CoinSwap must be combined with a couple\n> of other building blocks:\n>\n> * ECDSA-2P\n> * Liquidity market\n> * Routed CoinSwaps\n> * Multi-transaction CoinSwaps\n> * Breaking change output heuristics\n> * Fidelity bonds\n> * PayJoin with CoinSwap\n> * Federated message boards protected from spam with fidelity bonds\n>\n> CoinSwap transactions could be made to look just like any other regular\n> bitcoin transaction, with no distinguishing fingerprint. This would make\n> them invisible.\n>\n> I intend to create this CoinSwap software. It will be almost completely\n> decentralized and available for all to use for free. The design is\n> published here for review. If you want to help support development I\n> accept donations at https://bitcoinprivacy.me/coinswap-donations\n>\n>\n> == References ==\n>\n> - [1] \"CoinSwap: Transaction graph disjoint trustless trading\"\n> https://bitcointalk.org/index.php?topic=321228.0\n>\n> - [2]\n>\n> http://diyhpl.us/wiki/transcripts/scalingbitcoin/tokyo-2018/scriptless-ecdsa/\n>\n> - [3] https://en.bitcoin.it/wiki/Privacy#Change_address_detection\n>\n> - [4] \"Design for improving JoinMarket's resistance to sybil attacks\n> using fidelity bonds\"\n> https://gist.github.com/chris-belcher/18ea0e6acdb885a2bfbdee43dcd6b5af/\n>\n> - [5] https://github.com/AdamISZ/CoinSwapCS/issues/50\n>\n> - [6] https://github.com/AdamISZ/CoinSwapCS/issues/53\n>\n> - [7]\n>\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-May/017846.html\n>\n> - [8]\n>\n> https://github.com/ElementsProject/scriptless-scripts/blob/master/md/atomic-swap.md\n>\n> - [9]\n>\n> https://blockstream.com/2018/08/08/en-improving-privacy-using-pay-to-endpoint/\n>\n> - [10] https://medium.com/@nopara73/pay-to-endpoint-56eb05d3cac6\n>\n> - [11]\n>\n> https://cointelegraph.com/news/binance-returns-frozen-btc-after-user-promises-not-to-use-coinjoin\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200530/da6f6938/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-31T02:30:55",
                "message_text_only": "Good morning Ruben and Chris,\n\n> >For a much greater anonymity set we can use 2-party ECDSA to create 2-of-2 multisignature addresses that look the same as regular single-signature addresses\n>\n> This may perhaps be counter-intuitive, but SAS doesn't actually require multisig for one of the two outputs, so a single key will suffice. ECDSA is a signing algorithm that doesn't support single key multisig (at least not without 2p-ECDSA), but notice how for the non-timelocked SAS output we never actually have to sign anything together with the other party. We swap one of the two keys, and the final owner will create a signature completely on their own. No multisig required, which means we can simply use MuSig, even today without Schnorr.\n\nJust to be clear, you mean we can use the MuSig key-combination protocol for the non-timelocked SAS output, but (of course) not the signing protocol which is inherently Schnorr.\n\nThen knowledge of both of the original private keys is enough to derive the single combined private key.\n\n> Of course the other output will still have to be a 2-of-2, for which you rightly note 2p-ECDSA could be considered. It may also be interesting to combine a swap with the opening of a Lightning channel. E.g. Alice and Bob want to open a channel with 1 BTC each, but Alice funds it in her entirety with 2 BTC, and Bob gives 1 BTC to Alice in a swap. This makes it difficult to tell Bob entered the Lightning Network, especially if the channel is opened in a state that isn't perfectly balanced. And Alice will gain an uncorrelated single key output.\n\nDual-funding could be done by a single-funding Lightning open followed by an onchain-to-offchain swap.\nThough the onchain swap would have to be done, at least currently, with hashes.\n\n> >=== PayJoin with CoinSwap ===\n>\n> While it's probably clear how to do it on the timelocked side of SAS, I believe PayJoin can also be applied to the non-timelocked side. This does require adding a transaction that undoes the PayJoin in case the swap gets aborted, which means MuSig can't be used. Everything else stays the same: only one tx if successful, and no timelock (= instant settlement). I can explain it in detail, if it happens to catch your interest.\n\nI am not in fact convinced that PayJoin-with-CoinSwap adds *that* much privacy.\n\nThese transactions:\n\n             +---+  +---+\n    Alice ---|   |--|   |--- Bob\n    Alice ---|   |  |   |\n      Bob ---|   |  +---+\n             +---+\n\nAre not really much different in coin ownership analysis from these:\n\n             +---+    +---+\n    Alice ---|   |----|   |--- Bob\n    Alice ---|   | +--|   |\n             +---+ |  +---+\n      Bob ---------+\n\nThe latter is possible due to private key handover, the intermediate output becomes owned solely by Bob and Bob can add many more inputs to that second transaction unilaterally for even greater confusion to chain analysis, basically private key handover gets us PayJoin for free.\nIt also removes the need for Bob to reveal additional UTXOs to Alice during the swap protocol; yes PoDLE mitigates the privacy probing attack that Alice can mount on Bob, but it is helpful to remember this is \"only\" a mitigation.\n\nNow of course things are different if Alice is paying some exact amount to Carol, and Alice wants to dissociate her funds from the payment.\nThe difference is then:\n\n             +---+    +---+\n    Alice ---|   |----|   |--- Bob\n    Alice ---|   |--+ |   |\n      Bob ---|   |  | +---+\n             +---+  +--------- Alice Change\n\n             +---+    +---+\n      Bob ---|   |----|   |--- Carol\n             |   |--+ +---+\n             +---+  |\n                    +--------- Bob Change\n\nVersus:\n\n             +---+    +---+\n    Alice ---|   |----|   |--- Bob\n    Alice ---|   | +--|   |\n             +---+ |  +---+\n      Bob ---------+\n\n             +---+    +---+\n      Bob ---|   |----|   |--- Carol\n             |   |--+ |   |--- Alice Change\n             +---+  | +---+\n                    +--------- Bob Change\n\nIn the above, with PayJoin on the first-layer transaction, the Alice Change is correlated with Alice and Bob inputs, whereas with the PayJoin on the second the Alice change is correlated with Bob inputs and Carol outputs.\n\nBut if Alice, using commodity CoinSwap wallets, always has a policy that all sends are via CoinSwap (a reasonable policy, similar to the policy in JoinMarket of ensuring that all spends out of the wallet are via CoinJoin), then the above two trees are not much different for Alice in practice.\nThe Alice Change will be swapped with some other maker anyway when it gets spent, so what it correlates with will not be much of a problem for Alice.\nAt the same time, with PayJoin on the second-layer transaction (possible due to private key turnover, which is an inherent part of the SAS protocol):\n\n* Bob does not have to reveal any other coins it owns to Alice other than what it is directly swapping, removing a privacy probe vector.\n* Bob can unilaterally combine more than one input to the second transaction going to Bob, which further increases the uncertainty of clustering around the inputs from Alice than just adding *one* input.\n\n---\n\nA thing I have been trying to work out is whether SAS can be done with more than one participant, like in [S6](https://joinmarket.me/blog/blog/multiparty-s6/).\n\nSo far, I have not figured out a way to make it multiparty (multihop?).\nBecause the secret being transported is a private key that protects a specific UTXO, it seems it is not possible to safely use the same secret across more than two parties.\nPerhaps others have come ideas?\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Ruben Somsen",
                "date": "2020-05-31T21:19:22",
                "message_text_only": "Hi ZmnSCPxj,\n\n>Just to be clear, you mean we can use the MuSig key-combination protocol\nfor the non-timelocked SAS output, but (of course) not the signing protocol\nwhich is inherently Schnorr. Then knowledge of both of the original private\nkeys is enough to derive the single combined private key.\n\nThat's correct.\n\n>basically private key handover gets us PayJoin for free\n\nThat assumes there will be a second transaction. With SAS I believe we can\navoid that, and make it look like this:\n\n             +---+\n    Alice ---|   |--- Bob\n    Alice ---|   |\n      Bob ---|   |\n             +---+\n\nThis is basically what I was trying to explain in my previous email: \"I\nbelieve PayJoin can also be applied to the non-timelocked side. This does\nrequire adding a transaction that undoes the PayJoin in case the swap gets\naborted, which means MuSig can't be used. Everything else stays the same:\nonly one tx if successful, and no timelock (= instant settlement)\"\n\nI don't have a strong opinion on whether it is actually useful to combine\nCoinSwap with PayJoin.\n\n>A thing I have been trying to work out is whether SAS can be done with\nmore than one participant, like in S6\n\nS6 requires timelocks for each output in order to function, so I doubt it\ncan be made to work with SAS.\n\nI've also tried applying SAS to partially blind swaps and ran into\nlikability issues, though it's less clear to me whether there is some\nfundamental reason why it couldn't work there.\n\nCheers,\nRuben\n\nOn Sun, May 31, 2020 at 4:31 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Ruben and Chris,\n>\n> > >For a much greater anonymity set we can use 2-party ECDSA to create\n> 2-of-2 multisignature addresses that look the same as regular\n> single-signature addresses\n> >\n> > This may perhaps be counter-intuitive, but SAS doesn't actually require\n> multisig for one of the two outputs, so a single key will suffice. ECDSA is\n> a signing algorithm that doesn't support single key multisig (at least not\n> without 2p-ECDSA), but notice how for the non-timelocked SAS output we\n> never actually have to sign anything together with the other party. We swap\n> one of the two keys, and the final owner will create a signature completely\n> on their own. No multisig required, which means we can simply use MuSig,\n> even today without Schnorr.\n>\n> Just to be clear, you mean we can use the MuSig key-combination protocol\n> for the non-timelocked SAS output, but (of course) not the signing protocol\n> which is inherently Schnorr.\n>\n> Then knowledge of both of the original private keys is enough to derive\n> the single combined private key.\n>\n> > Of course the other output will still have to be a 2-of-2, for which you\n> rightly note 2p-ECDSA could be considered. It may also be interesting to\n> combine a swap with the opening of a Lightning channel. E.g. Alice and Bob\n> want to open a channel with 1 BTC each, but Alice funds it in her entirety\n> with 2 BTC, and Bob gives 1 BTC to Alice in a swap. This makes it difficult\n> to tell Bob entered the Lightning Network, especially if the channel is\n> opened in a state that isn't perfectly balanced. And Alice will gain an\n> uncorrelated single key output.\n>\n> Dual-funding could be done by a single-funding Lightning open followed by\n> an onchain-to-offchain swap.\n> Though the onchain swap would have to be done, at least currently, with\n> hashes.\n>\n> > >=== PayJoin with CoinSwap ===\n> >\n> > While it's probably clear how to do it on the timelocked side of SAS, I\n> believe PayJoin can also be applied to the non-timelocked side. This does\n> require adding a transaction that undoes the PayJoin in case the swap gets\n> aborted, which means MuSig can't be used. Everything else stays the same:\n> only one tx if successful, and no timelock (= instant settlement). I can\n> explain it in detail, if it happens to catch your interest.\n>\n> I am not in fact convinced that PayJoin-with-CoinSwap adds *that* much\n> privacy.\n>\n> These transactions:\n>\n>              +---+  +---+\n>     Alice ---|   |--|   |--- Bob\n>     Alice ---|   |  |   |\n>       Bob ---|   |  +---+\n>              +---+\n>\n> Are not really much different in coin ownership analysis from these:\n>\n>              +---+    +---+\n>     Alice ---|   |----|   |--- Bob\n>     Alice ---|   | +--|   |\n>              +---+ |  +---+\n>       Bob ---------+\n>\n> The latter is possible due to private key handover, the intermediate\n> output becomes owned solely by Bob and Bob can add many more inputs to that\n> second transaction unilaterally for even greater confusion to chain\n> analysis, basically private key handover gets us PayJoin for free.\n> It also removes the need for Bob to reveal additional UTXOs to Alice\n> during the swap protocol; yes PoDLE mitigates the privacy probing attack\n> that Alice can mount on Bob, but it is helpful to remember this is \"only\" a\n> mitigation.\n>\n> Now of course things are different if Alice is paying some exact amount to\n> Carol, and Alice wants to dissociate her funds from the payment.\n> The difference is then:\n>\n>              +---+    +---+\n>     Alice ---|   |----|   |--- Bob\n>     Alice ---|   |--+ |   |\n>       Bob ---|   |  | +---+\n>              +---+  +--------- Alice Change\n>\n>              +---+    +---+\n>       Bob ---|   |----|   |--- Carol\n>              |   |--+ +---+\n>              +---+  |\n>                     +--------- Bob Change\n>\n> Versus:\n>\n>              +---+    +---+\n>     Alice ---|   |----|   |--- Bob\n>     Alice ---|   | +--|   |\n>              +---+ |  +---+\n>       Bob ---------+\n>\n>              +---+    +---+\n>       Bob ---|   |----|   |--- Carol\n>              |   |--+ |   |--- Alice Change\n>              +---+  | +---+\n>                     +--------- Bob Change\n>\n> In the above, with PayJoin on the first-layer transaction, the Alice\n> Change is correlated with Alice and Bob inputs, whereas with the PayJoin on\n> the second the Alice change is correlated with Bob inputs and Carol outputs.\n>\n> But if Alice, using commodity CoinSwap wallets, always has a policy that\n> all sends are via CoinSwap (a reasonable policy, similar to the policy in\n> JoinMarket of ensuring that all spends out of the wallet are via CoinJoin),\n> then the above two trees are not much different for Alice in practice.\n> The Alice Change will be swapped with some other maker anyway when it gets\n> spent, so what it correlates with will not be much of a problem for Alice.\n> At the same time, with PayJoin on the second-layer transaction (possible\n> due to private key turnover, which is an inherent part of the SAS protocol):\n>\n> * Bob does not have to reveal any other coins it owns to Alice other than\n> what it is directly swapping, removing a privacy probe vector.\n> * Bob can unilaterally combine more than one input to the second\n> transaction going to Bob, which further increases the uncertainty of\n> clustering around the inputs from Alice than just adding *one* input.\n>\n> ---\n>\n> A thing I have been trying to work out is whether SAS can be done with\n> more than one participant, like in [S6](\n> https://joinmarket.me/blog/blog/multiparty-s6/).\n>\n> So far, I have not figured out a way to make it multiparty (multihop?).\n> Because the secret being transported is a private key that protects a\n> specific UTXO, it seems it is not possible to safely use the same secret\n> across more than two parties.\n> Perhaps others have come ideas?\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200531/eea6bdba/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Design for a CoinSwap implementation for massively improving Bitcoin privacy and fungibility",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Chris Belcher",
                "ZmnSCPxj",
                "Ruben Somsen"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 78980
        }
    },
    {
        "title": "[bitcoin-dev] Transaction size & weight calculation tooling",
        "thread_messages": [
            {
                "author": "Jameson Lopp",
                "date": "2020-05-27T18:52:03",
                "message_text_only": "Hi all,\n\nAnyone who has built a Bitcoin wallet / service has to deal with a variety\nof challenges when it comes to transaction construction. One of these\nchallenges is around determining an appropriate fee; aside from block space\nmarket volatility and the inherent problems of forecasting the future, you\nneed to know how much block space for which your transaction needs to \"bid.\"\n\nEvery time I've run into the problem of calculating the size of a\ntransaction with specific attributes I've ended up having to sift through\nanswers scatter across stack overflow posts, so I finally got around to\nbuilding a user friendly tool at\nhttps://jlopp.github.io/bitcoin-transaction-size-calculator/\n\nAs I was looking for more data on constants to use in the calculation I was\ninformed that the folks at Bitcoin Optech have also been working on a\ncalculator: https://bitcoinops.org/en/tools/calc-size\n\nIt seems clear that this is a common problem for which we could use better\ntooling. I'm also about 99% certain that there's at least 1 or 2 bugs in my\ncurrent calculator code.\n\nPlease bookmark and share these tools; if you're capable and so inclined,\ncode reviews would be greatly appreciated!\n\n- Jameson\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200527/dd1614eb/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Transaction size & weight calculation tooling",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jameson Lopp"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1378
        }
    },
    {
        "title": "[bitcoin-dev] Announcing Bitcoin Wallet Tracker",
        "thread_messages": [
            {
                "author": "Nadav Ivgi",
                "date": "2020-05-30T14:16:14",
                "message_text_only": "Hi all,\n\nI recently released bwt [0], an HD wallet indexer implemented in Rust, using\na model similar to that of Electrum Personal Server.\n\nIt uses the bitcoind wallet functionality to do the heavy lifting and builds\nadditional indexes on top of that, which can be queried using the Electrum\nRPC protocol, as well as a more modern, developer-friendly HTTP REST API.\n\nThe electrum server can also be used as an electrum plugin [1], which\nintegrates the server straight into the electrum client. From the user's\nperspective, this allows connecting electrum directly to a full node.\n\nThe HTTP API is my take on a modern design for a wallet tracking API aimed\nat app developers. Some use-cases include using it as a backend for wallets\n(similarly to Samuari's Dojo) or to track deposits to a watch-only xpub\n(similarly to BTCPay's NBXplorer).\n\nCompared to using the bitcoind RPC directly, bwt provides:\n\n- The ability to track an xpub and automatically have new addresses derived\n  and imported as needed, according to the gap limit.\n\n- Two additional indexes, one for looking up the transaction history of\n  addresses, and another one for looking up txo spends (a map of\n  funding_txid:vout => spending_txid:vin).\n\n- Real-time updates using Server-Sent Events [2] (a long-lived streaming\nHTTP\n  connection) or Web Hooks [3] (an HTTP request sent to a configured URL).\n  The updates being sent [4] directly provide information about the funded\n  and spent wallet txos, instead of the client figuring it out from the tx.\n\n- Some API conveniences and simplifications, like including key origin\n  information directly alongside inputs/outputs [5], the ability to specify\n  key origins in place of addresses (eg. GET /hd/15cb9edc/8/utxos), a\ncompact\n  history format [6], and an easy way to catch-up with missed events [7].\n  Unless explicitly asked for, the API omits information about non-wallet\n  inputs/outputs and protocol-level details like scriptsig and witnesses,\n  which are typically not needed for higher-level app development.\n\nThe indexer is designed in a way that minimizes RPC requests to bitcoind. By\nusing labels to store key origin information, it is able to index incoming\ntransactions using the information available from `listtransactions` alone\n(plus 3 extra rpc requests that don't grow with the number of transactions),\nbut requires 1 additional rpc call per outgoing transaction (to learn which\nprevouts were spent). It can index 10k incoming txs in under a second, or a\nmixture of 5k/5k in under 5 seconds. The index is currently entirely in-\nmemory and does not get persisted. The indexer logic can be seen in [8].\n\nOne major item on the roadmap that I'm hoping to tackle soon is support for\noutput script descriptors.\n\nIf anyone is interested in contributing, the README has some useful\ndeveloper\nresources [9] and a handy script for setting up a development environment.\n\nThis is an early alpha release, recommended for use with testnet/regtest.\n\nAll feedback welcome!\n\nCheers,\nNadav\n\n[0] https://github.com/shesek/bwt\n[1] https://github.com/shesek/bwt#electrum-plugin\n[2] https://github.com/shesek/bwt#server-sent-events\n[3] https://github.com/shesek/bwt#web-hooks\n[4] https://github.com/shesek/bwt#event-categories\n[5] https://github.com/shesek/bwt#wallet-transaction-format\n[6] https://github.com/shesek/bwt#get-txssinceblock-heightcompact\n[7]\nhttps://github.com/shesek/bwt#catching-up-with-missed-events--re-org-detection\n[8] https://github.com/shesek/bwt/blob/master/src/indexer.rs\n(sync_transactions and load_transactions_since)\n[9] https://github.com/shesek/bwt#developing\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200530/59fdc298/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Announcing Bitcoin Wallet Tracker",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Nadav Ivgi"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3783
        }
    }
]