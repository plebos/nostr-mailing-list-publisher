[
    {
        "title": "[bitcoin-dev] reviving op_difficulty",
        "thread_messages": [
            {
                "author": "Thomas Hartman",
                "date": "2020-09-01T20:07:21",
                "message_text_only": "This is in reply to David harding\u2019s message at \n\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-August/018129.html <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-August/018129.html>\n\n(For some reason didn\u2019t arrive in my inbox, so I was late noticing it, and I am replying in this way. Sorry if it screws up threading.)\n\nPowswap sounds great! And it doesn\u2019t require any protocol changes! Very cool.\n\nOne potential problem I see with powswap is iiuc you need something like watchtowers, or the loser of the bet can sweep the funds if the winner is napping. Related, I\u2019d also like to have trades happening in lightning channels, and I\u2019m not sure how this race affects the security assumptions there. \n\nFurther question about powswap. \n\nIt\u2019s currently block 64632 with retarget in 808 blocks. I\u2019d like to bet that \n\n* the first 6 blocks after the retarget are found in under an hour\n* AND the new difficulty exceeds some threshold. Is such a bet currently possible with powswap?\n\nI see how pow swap lets you bet on hashrate (ie block times) from current time till some future time. But I would like to also bet on hashrate of slices of time in the future. Possible? \n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200901/a447e8f1/attachment.html>"
            },
            {
                "author": "Thomas Hartman",
                "date": "2020-09-02T14:40:28",
                "message_text_only": "Replying to myself:\n\nIIUC, Powswap seems to only create contracts from current time to future time.\n\nBut, you can create synthetic hashrate binaries for time span in the\nfuture time A to time B, using powswap, by subtracting\n\n(current time to B) - (current time to A)\n\nIE, buy first, sell second.\n\nOn Tue, Sep 1, 2020 at 4:07 PM Thomas Hartman <thomashartman1 at gmail.com> wrote:\n>\n> This is in reply to David harding\u2019s message at\n>\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-August/018129.html\n>\n> (For some reason didn\u2019t arrive in my inbox, so I was late noticing it, and I am replying in this way. Sorry if it screws up threading.)\n>\n> Powswap sounds great! And it doesn\u2019t require any protocol changes! Very cool.\n>\n> One potential problem I see with powswap is iiuc you need something like watchtowers, or the loser of the bet can sweep the funds if the winner is napping. Related, I\u2019d also like to have trades happening in lightning channels, and I\u2019m not sure how this race affects the security assumptions there.\n>\n> Further question about powswap.\n>\n> It\u2019s currently block 64632 with retarget in 808 blocks. I\u2019d like to bet that\n>\n> * the first 6 blocks after the retarget are found in under an hour\n> * AND the new difficulty exceeds some threshold. Is such a bet currently possible with powswap?\n>\n> I see how pow swap lets you bet on hashrate (ie block times) from current time till some future time. But I would like to also bet on hashrate of slices of time in the future. Possible?\n>\n>"
            },
            {
                "author": "Jeremy",
                "date": "2020-09-02T18:27:00",
                "message_text_only": "Yep this is a good example construction. I'd also point out that modulo a\nprivacy improvement, you can also script it as something like:\n\nIF   IF <T> CLTV B DROP CHECKSIG ELSE <T2> CLTV DROP A CHECKSIG ENDIF ELSE\n2 A B 2 CHECKMULTI ENDIF\n\nThis way you equivalently have cooperative closing / early closing\npositions, but you make the redeem script non-interactive to setup which\nenable someone to pay into one of these contracts without doing\npre-signeds. This is unfortunate for privacy as the script is then visible,\nbut in a taproot world it's fine.\n\nOf course the non interactivity goes away if you want non-binary outcomes\n(e.g., Alice gets 1.5 Coin and Bob gets .5 Coin in case A, Bob gets 1.5\nCoin Alice gets .5 coin in Case B).\n\nAnd it's also possible to mix relative and absolute time locks for some\nadded fun behavior (e.g., you win if > Time and > Blocks)\n\n\nA while back I put together some python code which handles these embedded\nin basic channels between two parties (no routing). This enables you to\nhigh-frequency update and model a hashrate perpetual swap, assuming your\ncounterparty is online.\n\n\nThe general issue with this construction family is that the contracts are\nmetastable. E.g., if you're targeting a 100 block deficit , that means you\nhave 100 blocks of time to claim the funds before either party can win. So\nthere's some minimum times and hashrate moves to play with, and the less\n\"clearly correct\" you were, the less clearly correct the execution will be.\nThis makes the channel version of the contract compelling as you can update\nand revoke frequently on further out contracts.\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Sat, Aug 22, 2020 at 9:47 AM David A. Harding via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Sun, Aug 16, 2020 at 11:41:30AM -0400, Thomas Hartman via bitcoin-dev\n> wrote:\n> > First, I would like to pay respects to tamas blummer, RIP.\n> >\n> >\n> https://bitcoinmagazine.com/articles/remembering-tamas-blummer-pioneering-bitcoin-developer\n>\n> RIP, Tamas.\n>\n> > Tamas proposed an additional opcode for enabling bitcoin difficulty\n> > futures, on this list at\n> >\n> >\n> https://www.mail-archive.com/bitcoin-dev@lists.linuxfoundation.org/msg07991.html\n>\n> Subsequent to Blummer's post, I heard from Jeremy Rubin about a\n> scheme[1] that allows difficulty futures without requiring any changes\n> to Bitcoin.  In short, it takes advantage of the fact that changes in\n> difficulty also cause a difference in maturation time between timelocks\n> and height-locks.  As an simple example:\n>\n> 1. Alice and Bob create an unsigned transaction that deposits their\n>    money into a 2-of-2 multisig.\n>\n> 2. They cooperate to create and sign two conflicting spends from the\n> multisig:\n>\n>     a. Pays Alice with an nLockTime(height) of CURRENT_HEIGHT + 2016 blocks\n>\n>     b. Pays Bob with an nLockTime(time) of CURRENT_TIME + 2016 * 10 * 60\n> seconds\n>\n> 3. After both conflicting spends are signed, Alice and Bob sign and\n>    broadcast the deposit transaction from #1.\n>\n> 4. If hashrate increases during the subsequent period, the spend that\n>    pays Alice will mature first, so she broadcasts it and receives that\n>    money.  If hashrate decreases, the spend to Bob matures first, so he\n>    receives the money.\n>\n> Of course, this basic formula can be tweaked to create other contracts,\n> e.g. a contract that only pays if hashrate goes down more than 25%.\n>\n> As far as I can tell, this method should be compatible with offchain\n> commitments (e.g. payments within channels) and could be embedded in a\n> taproot commitment using OP_CLTV or OP_CSV instead of nLockTime.\n>\n> -Dave\n>\n> [1] https://powswap.com/\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200902/a7d3b225/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "reviving op_difficulty",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy",
                "Thomas Hartman"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 6993
        }
    },
    {
        "title": "[bitcoin-dev] Detailed protocol design for routed multi-transaction CoinSwap",
        "thread_messages": [
            {
                "author": "Chris Belcher",
                "date": "2020-09-03T09:00:00",
                "message_text_only": "Hello ZmnSCPxj,\n\n\nOn 25/08/2020 04:16, ZmnSCPxj wrote:\n> \n> Good morning Antoine,\n> \n> \n>> Note, I think this is independent of picking up either relative or absolute timelocks as what matters is the block delta between two links.\n> \n> I believe it is quite dependent on relative locktimes.\n> Relative locktimes *require* a contract transaction to kick off the relative locktime period.\n> On the other hand, with Scriptless Script (which we know how to do with 2p-ECDSA only, i.e. doable pre-Taproot), absolute locktimes do not need a contract transaction.\n> \n> With absolute locktimes + Scriptless SCript, in a single onchain PTLC, one participant holds a completely-signed timelock transaction while the other participant holds a completely-signed pointlock transaction.\n> This can be arranged by having one side offer partial signatures for the transaction of the other, and once completing the signature, not sharing it with the other until we are ready to actually broadcast the transaction of our own volition.\n> There is no transaction that both participants hold in completely-signed form.\n> \n> This should remove most of the shenanigans possible, and makes the 30xRBF safe for any range of fees.\n> I think.\n> \n> Since for each PTLC a participant holds only its \"own\" transaction, it is possible for a participant to define its range of fees for the RBF versions of the transaction it owns, without negotiation with the other participant.\n> Since the fee involved is deducted from its own transaction, each participant can define this range of RBFed fees and impose it on the partial signatures it gets from the other participant.\n> \n> --\n> \n> Private key turnover is still useful even in an absolute-timelock world.\n> \n> If we need to bump up the block delta between links, it might be impractical to have the total delta of a multi-hop swap be too long at the taker.\n> \n> As a concrete example, suppose A is a taker who wants to route over makers B and C.\n> However, B and C require a CLTV delta of 1 week.\n> \n> If A wants to route \"directly\" A->B->C->A, then if something bad happens, it could be looking at having its funds locked for two weeks.\n> \n> To reduce this risk, A can instead first swap A->B->A, then when that completes, A->C->A.\n> This limits its funding lockup to 1 week.\n> \n> Private key turnover is useful since as soon as the A->B->A swap completes, it can directly fund the A->C->A swap from the B-side funding transaction of the A->B->A swap.\n> \n>          |   A->B->A         |    A->C->A           |\n>          :                   :                      :\n>       A -:->funding A&B--> B :                      :\n>          :                   :                      :\n>       B -:->funding A&B -----:--> funding A&C --> C :\n>          :                   :                      :\n>          :                   :C-> funding A&C ------:-> to-cold  A -->\n>          :                   :                      :\n> \n> This increases the number of transactions by 1 per swap beyond the first, compared to a direct routing A->B->C->A, but this may be worth it for A if the timelocks involved are too big for A.\n> \n> With 2p-ECDSA, a funding A&C looks exactly the same as a to-cold A, so B is unable to reliably determine if it is the last hop in the route.\n> \n> Without private key turnover, A would have:\n> \n>                       **NO** private key turnover!\n> \n>          |   A->B->A         |    A->C->A                      |\n>          :                   :                                 :\n>       A -:->funding A&B--> B :                                 :\n>          :                   :                                 :\n>       B -:->funding A&B -----:--> claim A -> funding A&C --> C :\n>          :                   :                                 :\n>          :                   :           C-> funding A&C ------:-> to-cold  A -->\n>          :                   :                                 :\n> \n> So if timelock-deltas are possibly-high (to reduce the probability of the MAD-HTLC argument, and other attacks, succeeding), takers might prefer to route by completing one swap first before starting the next one, and private key turnover is useful by reducing blockspace required by each hop.\n> \n> For reference, this is how it looks like with a single A->B->C->A swap with private key turnover:\n> \n>          |   A->B->C->A      |\n>          :                   :\n>       A -:->funding A&B--> B :\n>          :                   :\n>       B -:->funding B&C -> C :\n>          :                   :\n>       C -:->funding A&C -----:-> to-cold A -->\n>          :                   :\n> \n> This is still smaller than in the A->B->A, A->C->A with private key turnover, by one funding tx per hop.\n> However, A risks a much higher timelock (twice the timelock).\n> Thus, A might prefer a lower timelock in exchange for paying for an additional transaction.\n> \n> Regards,\n> ZmnSCPxj\n> \n\n\nSeparating the timelock and hashlock cases into two separate\ntransactions is a nice way to solve many of these problems.\n\nA big downside is that it really ruins the property of allowing coins to\nremain unspent indefinitely. That has privacy implications: if a coin\nremains unspent for longer than 2 weeks (or another short locktime) then\nfor sure the transaction was not a CoinSwap, and so the anonymity set of\nthe CoinSwap system would be far smaller For this reason I'm pretty\ndesperate to solve the vulnerability without losing the coins remaining\nunspent indefinitely feature.\n\nWe need to solve the vulnerability you found, which I'll call the\nriskless theft attempt problem. So what do you think of this solution:\n\n\n== Building block 1: A, B and C having different contract txes ==\n\nIn the original proposal each CoinSwap peer has the same contract\ntransaction, and either side can broadcast it whenever they like. This\nactually isn't necessary. We can have a contract transaction\nfully-signed but only known to one peer, with a possibly-different\ntransaction transaction fully-signed and only known to the other peer.\n\nObviously for the CoinSwap to work both contract transactions must have\nthe same hash-time-locked contract, but they can differ in other ways.\n\n== Building block 2: collateral payments ==\n\nThe riskless theft attempt problem happens because the previous owner of\nthe coins knows the fully-signed contract transaction and can broadcast\nit at no cost to themselves. So to solve the problem we add a cost.\n\nThere is a 2of2 multisig made up of Bob's and Charlie's keys. The\nassociated contract transaction known to Bob must now also have one of\nBob's single-sig inputs. The outputs are such that some of the money\nfrom Bob's input now ends up in the HTLC output. The result is that\nafter the CoinSwap if Bob broadcasts his contract transaction but fails\nto take the money from the HTLC output, then Bob will have lost money.\n\nI'm calling this idea collateral payments, by analogy with collateral\nused for loans. A collateral is someone valuable a debtor puts on the\ntable, and if they don't repay the loan then they lose the collateral\n(presumably the creditor sells it to repay the loan).\n\nHere is a diagram of the contract transaction known to Bob:\n\n    multisig (B+C) [I btc]---> (B+timelock_B OR C+hash) [I+K-M~ btc]\n    collateral(B)  [J btc]     (Bob)                    [J-K btc]\n\nwhere:\n    I = CoinSwap amount\n    J = Value of Bob's collateral input\n    K = Value that Bob loses if he broadcasts his contract tx but doesnt\nget the money\n    M~ = miner fee (random variable)\n\nThe value K is something that can be set by the protocol, and made high\nenough so that doing a riskless theft attempt is not worth it. Probably\nthe value of K will be quite small because the odds of a riskless\npayment attempt succeeding is very small (assuming the makers all use\nmultiple redundant watchtowers). Mostly likely K will be smaller than\nM~, so if the collateral is lost to Bob then the miners will the ones to\ngain, rather than Charlie.\n\nThe other contract transaction, known only to Charlie, does not contain\na collateral input or collateral value (K), because Charlie can't do a\nriskless theft attempt to Bob.\n\nIf Bob ever spends his collateral input in another transaction, then his\ncontract transaction will become invalid. However Bob will only be\nharming himself, so he'll never do this.\n\nI think this might be a fruitful idea, and soon I'll modify my earlier\ndetailed design to include it, and see if it can be made to work with no\nweird edge cases or attacks.\n\n\n\n=== Appendix: Brief historical note about separate contract txes ===\n\nSeparating hash- and time-lock branches into different transactions as\nin ZmnSCPxj's design is actually very similar to the way the original\n2013 CoinSwap design worked:\nhttps://bitcointalk.org/index.php?topic=321228.0\n\nThe timelock branch was a transaction locked with nLockTime. And the\nhashlock branch is another transaction spending to an output requiring\nCarol's public key + hash preimage.\n\nHowever Adam Gibson in 2017 found a vulnerability to this:\nhttps://github.com/AdamISZ/CoinSwapCS/blob/master/docs/coinswap_tweak.md\n\nThe vulnerability is that even though Carol doesn't know the hash\npreimage, she can still broadcast the hashlock transaction, which sends\nthe coins _into_ the hashlock contract, and that invalidates Alice's\ntimelock transaction. Carol is the only one who can spend the coins but\nshe doesn't know the hash preimage. The protocol then degenerates to the\nMAD (mutually assured destruction) case because the coins are locked\nforever.\n\nAdam Gibson's fix was to include the hashlock and timelock branches into\nthe same transaction known to both peers, which is exactly the design I\nused and for which all these vulnerabilities were found.\n\nI realize now there is another way to solve the vulnerability, which is\nto include a (Alice pubkey + OP_CLTV timelock) in Carol's contract\ntransaction. This means that if Carol broadcasts her contract tx (called\nTX_2 in the text) without knowing the preimage then Alice can still get\nher money back after a timeout, breaking the MAD situation. The crucial\npart making this work is that Alice won't know the fully-signed Carol\ncontract transaction, and so won't be able to unilaterally broadcast it.\nI believe this fix makes the scheme equivalent to ZmnSCPxj's idea of\nseparated transactions, but without scriptless scripts (and so the\nscheme is less useful)\n\n\nKind regards\nCB"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-09-03T09:45:53",
                "message_text_only": "Good morning Chris,\n\n> A big downside is that it really ruins the property of allowing coins to\n> remain unspent indefinitely. That has privacy implications: if a coin\n> remains unspent for longer than 2 weeks (or another short locktime) then\n> for sure the transaction was not a CoinSwap, and so the anonymity set of\n> the CoinSwap system would be far smaller For this reason I'm pretty\n> desperate to solve the vulnerability without losing the coins remaining\n> unspent indefinitely feature.\n\nAh, right.... accept no small privacy leaks!\n\n>\n> We need to solve the vulnerability you found, which I'll call the\n> riskless theft attempt problem. So what do you think of this solution:\n>\n> == Building block 1: A, B and C having different contract txes ==\n>\n> In the original proposal each CoinSwap peer has the same contract\n> transaction, and either side can broadcast it whenever they like. This\n> actually isn't necessary. We can have a contract transaction\n> fully-signed but only known to one peer, with a possibly-different\n> transaction transaction fully-signed and only known to the other peer.\n>\n> Obviously for the CoinSwap to work both contract transactions must have\n> the same hash-time-locked contract, but they can differ in other ways.\n>\n> == Building block 2: collateral payments ==\n>\n> The riskless theft attempt problem happens because the previous owner of\n> the coins knows the fully-signed contract transaction and can broadcast\n> it at no cost to themselves. So to solve the problem we add a cost.\n>\n> There is a 2of2 multisig made up of Bob's and Charlie's keys. The\n> associated contract transaction known to Bob must now also have one of\n> Bob's single-sig inputs. The outputs are such that some of the money\n> from Bob's input now ends up in the HTLC output. The result is that\n> after the CoinSwap if Bob broadcasts his contract transaction but fails\n> to take the money from the HTLC output, then Bob will have lost money.\n\nJust to be clear:\n\n* B is the one who originally funded the HTLC, and owns the timelock.\n* C is the one who will accept the HTLC, and owns the hashlock.\n\n> I'm calling this idea collateral payments, by analogy with collateral\n> used for loans. A collateral is someone valuable a debtor puts on the\n> table, and if they don't repay the loan then they lose the collateral\n> (presumably the creditor sells it to repay the loan).\n>\n> Here is a diagram of the contract transaction known to Bob:\n>\n> multisig (B+C) [I btc]---> (B+timelock_B OR C+hash) [I+K-M~ btc]\n>\n>     collateral(B)  [J btc]     (Bob)                    [J-K btc]\n>\n>\n> where:\n> I = CoinSwap amount\n> J = Value of Bob's collateral input\n> K = Value that Bob loses if he broadcasts his contract tx but doesnt\n> get the money\n> M~ = miner fee (random variable)\n>\n> The value K is something that can be set by the protocol, and made high\n> enough so that doing a riskless theft attempt is not worth it. Probably\n> the value of K will be quite small because the odds of a riskless\n> payment attempt succeeding is very small (assuming the makers all use\n> multiple redundant watchtowers). Mostly likely K will be smaller than\n> M~, so if the collateral is lost to Bob then the miners will the ones to\n> gain, rather than Charlie.\n\nThis seems a great solution!\n\nSince B is the one offering HTLCs, the taker of a CoinSwap sequence can be B as well.\nThis means, the taker has to have *some* collateral input, of at least value K, that it cannot swap (because if it tried to swap that amount, it would be unable to provide a collateral as well).\n\nHow much does C need to know about the B collateralized contract transaction?\nAt the minimum, it has to know the output pays out to the correct contract, so it seems to me it has to know the entire B collateralized contract transaction, meaning it learns another input of B (\"collateral(B)\") that is not otherwise involved in the CoinSwap.\nThis is important, again, if B is a taker, as it means an unrelated input of B is now learned by C as having the same ownership as B.\n\nA fresh maker that is given its starting funds in a single UTXO needs to split up its funds to make at least one collateral input it can use.\n\nOf note is that the B output also serves as a point for CPFPing this transaction, thus only one version of the B collateralized contract transaction needs to be made, and the B collateralized contract transaction can be at or close to the minimum relay feerate and later CPFPed.\n\nIn terms of onchain analysis heuristics, it looks like the B output is change, while the B+C contract output is the send-out, I think, for most cases.\nIn case of a protocol abort, this heuristic is misled, since both outputs become owned by B due to the protocol abort.\nIn case of a protocol completion, this heuristic is accurate, since the B+C contract output will be claimed by C, but we do not expect this transaction to be confirmed onchain after protocol completion anyway (it effectively donates K to C or miners), so this is fine.\n\n> The other contract transaction, known only to Charlie, does not contain\n> a collateral input or collateral value (K), because Charlie can't do a\n> riskless theft attempt to Bob.\n\nBecause it has a single output only, the C contract transaction needs to have RBFed versions.\n\n> If Bob ever spends his collateral input in another transaction, then his\n> contract transaction will become invalid. However Bob will only be\n> harming himself, so he'll never do this.\n\nAt least until B gets its own incoming funds in the swap, at which point the collateral input can be used for other purposes (and effectively \"releases\" the lease of B on that output).\n\nSince C knows the collateral input (it has to, in order to verify the B collateralized contract transaction is correct), it can monitor the collateral input for spendedness, and stop watching for the B collateralized contract transaction in its watchtower(s) if the collateral input is deeply spent.\nThe B collateralized contract transaction is invalidated if the collateral input is spent, and then only C can spend the funding outpoint at that point, so it can remove that from the watchtower.\nThis can be significant if C is using a for-pay watchtower that supports deletion of watches, which I believe is planned for watchtowers as well, and reduces the operating cost of C.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Chris Belcher",
                "date": "2020-09-03T10:50:57",
                "message_text_only": "Hello ZmnSCPxj,\n\nOn 03/09/2020 10:45, ZmnSCPxj wrote:\n> Good morning Chris,\n> \n>> A big downside is that it really ruins the property of allowing coins to\n>> remain unspent indefinitely. That has privacy implications: if a coin\n>> remains unspent for longer than 2 weeks (or another short locktime) then\n>> for sure the transaction was not a CoinSwap, and so the anonymity set of\n>> the CoinSwap system would be far smaller For this reason I'm pretty\n>> desperate to solve the vulnerability without losing the coins remaining\n>> unspent indefinitely feature.\n> \n> Ah, right.... accept no small privacy leaks!\n\nI'd argue its not even a small leak. A huge amount of coins remain\nunspent for weeks, months and years, and it would be great to add them\nto our CoinSwap anonymity set. And also have them benefit from\nCoinSwap's anonymity set even if they didn't use CoinSwap.\n\n> This seems a great solution!\n> \n> Since B is the one offering HTLCs, the taker of a CoinSwap sequence can be B as well.\n> This means, the taker has to have *some* collateral input, of at least value K, that it cannot swap (because if it tried to swap that amount, it would be unable to provide a collateral as well).\n> \n> How much does C need to know about the B collateralized contract transaction?\n> At the minimum, it has to know the output pays out to the correct contract, so it seems to me it has to know the entire B collateralized contract transaction, meaning it learns another input of B (\"collateral(B)\") that is not otherwise involved in the CoinSwap.\n> This is important, again, if B is a taker, as it means an unrelated input of B is now learned by C as having the same ownership as B.\n\nYes, in fact that's why in my example I talk about a CoinSwap between\ntwo makers Bob and Charlie. Makers can be reasonably expected to own\nmultiple UTXOs, but takers cannot. As you say because collateral\npayments breaks the ability of takers to sweep their entire wallet\nthrough CoinSwap.\n\nHappily, I think takers themselves don't need to use collateral\npayments. Here's an argument to why:\n\nRiskless theft attempts by the taker who no longer controls the coins\nactually isnt riskless or costless: Because it reduces the privacy of\nthe previously-owned coins. If a taker genuinely wanted good privacy\n(Which, after all, they're paying for via miner fees and CoinSwap fees)\nthen they would benefit if the coins they no longer own remain unspent\nfor a long time, because it increases their anonymity set by making them\nhide among a greater crowd of coins which also don't get spent for a\nlong time.\nAssuming that all peers, especially makers, deploy multiple redundant\nwatchtowers then we can assume the success rate of such a theft attempt\nis very low. Because of the very low payoff, and privacy benefit of\nleaving coins unspent, then it can be argued that taker software which\nattempts such theft will never get popular.\n\nOf course this privacy argument only applies to takers, and if the\nCoinSwap contract is between two makers as part of a multi-transaction\nCoinSwap then it doesn't apply. So a maker-to-maker CoinSwap must use\ncollateral payments.\n\n== Leak of first hop ==\nCollateral inputs only applying to maker-maker CoinSwaps adds an\nadditional information leak, which is that makers can now tell whether\ntheir previous peer was a taker or maker, based on whether they used a\ncollateral input or not.\n\nThis should be okay because the first maker doesn't know the final\ndestination of the coins. This is similar to Tor, where this information\nis already leaked, for example when the user connects to a Tor bridge.\nThe operator of the Tor bridge knows that everyone connecting to it is\nnot a Tor relay node but an actual user. The operator of the tor bridge\nstill has no idea where the user's internet traffic goes. Our situation\nis actually better than Tor, because in Tor the final relay always knows\nthat they are an exit node, while the final maker in a CoinSwap might\nnot know that.\n\nAlso, if the taker does happen to own an extra UTXO, they may choose to\nuse a collateral input anyway, just to pretend that they're a maker.\n\n\nRegards\nCB"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-09-03T23:39:02",
                "message_text_only": "Good morning Chris,\n\n\n> > This seems a great solution!\n> > Since B is the one offering HTLCs, the taker of a CoinSwap sequence can be B as well.\n> > This means, the taker has to have some collateral input, of at least value K, that it cannot swap (because if it tried to swap that amount, it would be unable to provide a collateral as well).\n> > How much does C need to know about the B collateralized contract transaction?\n> > At the minimum, it has to know the output pays out to the correct contract, so it seems to me it has to know the entire B collateralized contract transaction, meaning it learns another input of B (\"collateral(B)\") that is not otherwise involved in the CoinSwap.\n> > This is important, again, if B is a taker, as it means an unrelated input of B is now learned by C as having the same ownership as B.\n>\n> Yes, in fact that's why in my example I talk about a CoinSwap between\n> two makers Bob and Charlie. Makers can be reasonably expected to own\n> multiple UTXOs, but takers cannot. As you say because collateral\n> payments breaks the ability of takers to sweep their entire wallet\n> through CoinSwap.\n>\n> Happily, I think takers themselves don't need to use collateral\n> payments. Here's an argument to why:\n>\n> Riskless theft attempts by the taker who no longer controls the coins\n> actually isnt riskless or costless: Because it reduces the privacy of\n> the previously-owned coins. If a taker genuinely wanted good privacy\n> (Which, after all, they're paying for via miner fees and CoinSwap fees)\n> then they would benefit if the coins they no longer own remain unspent\n> for a long time, because it increases their anonymity set by making them\n> hide among a greater crowd of coins which also don't get spent for a\n> long time.\n\nHmmm.\n\nThe attack can only be mounted after protocol completion.\nThus, at that point, makers have made money, and takers have paid.\nAnd taker is now in possession of a coin unlinked with its original coin, which is what it paid for.\n\nHowever, if the taker considers the maker fee it has already paid as a sunk cost, then it would still be rational of them to mount this attack (sunk costs should be ignored).\n>From this point-of-view, it is possible to do so with only a *subsequent* potential gain, and still no downside.\n\nFor example, suppose the taker has already performed an \"honest\" CoinSwap.\nThen, it is now in possession of a UTXO that is not linked with its income stream.\nIt can then perform another CoinSwap, and *then* perform the attack.\nThis reveals that the UTXO it provided is involved in a CoinSwap due to publication of the contract transaction, which is not a loss in this case since the UTXO it put in was not linked to its income stream already, via a previous non-attacked CoinSwap.\n\nA taker might rationally consider doing riskless costless theft with its already-delinked coins if it assesses that some maker is not sufficiently online and with insufficient watchtowers (both operating expenditures!) that it has some probability of success times amount it has to seed the theft, versus the fee of that maker plus miner fees.\n\nIn response, a maker that is forced to accept a sweeping taker will raise its fee, so as to disincentivize this attack using already-delinked coins.\n\nHmmm.\n\nIn addition, post-Scriptless-Script, assuming relative-locktime-use is \"normalized\" as proposed in https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-January/002412.html , then the \"contract transaction\" and its timelock-path-transaction look exactly the same as ordinary (P2SH-)P2WPKH single-input-single-output transactions, thus in that case the taker does ***not*** lose any privacy.\nThis removes whatever protection you can get from contract transaction blackmail.\n\n--\n\nThe above suggests to me that you still want the collateralized contract transaction from the taker as well.\n\nA sweeping taker can split its funds in half, swapping one half (and using the remainder for collateral input), then after that swap, using the already-swapped coins for the collateral input of the remaining unswapped coins.\nThis leaks information: you are now linking a post-mix coin with a pre-mix coin, not onchain (if you do not mount an attack, which you probably will not) but you *do* reveal this information to the maker (one input is from the funding tx that is pre-mix, the collateral input is from the post-mix coin).\n\nThe only protection here is that the maker is unaware of the fact that your input coin is pre-mix and your collateral input is post-mix, so it can be hard for a maker to *use* this information.\n\n\nHowever, it might be possible to prevent the maker from learning the collateral input at all.\n\nIf my understanding of BIP-143 is correct, inputs are hashed separately (`hashPrevouts`) from outputs (`hashOutputs`).\nBob can provide the `hashPrevouts` as an opaque hash, while providing a decommitment of `hashOutputs` to show that the outputs of the collateralized contract transaction are correct, which is all that Charlie really needs to know.\n\nBob is incentivized to provide the correct `hashPrevouts`, because if it provides an incorrect `hashPrevouts` it cannot get a signature for a transaction it can use in case of a protocol abort, thus potentially losing its money in case of a protocol abort.\nConversely, Charlie does not care *where* Bob gets the funds that goes into its contract output come from, it only cares that the Bob collateralized contract output is I+K.\nIt loses nothing to sign that transaction, and it would prefer that transaction since its own contract output is only I.\n\nThis solution is mildly \"unclean\" as it depends on the details of the sighash algorithm, though, and is not proposed seriously.\nHopefully nobody will change the sighash algorithm anytime soon.........\n\nIn addition, it complicates reusing Lightning watchtowers.\nLightning watchtowers currently trigger on txid (i.e. it would have triggered on the txid of the B collateralized contract tx), but watching this needs to trigger on the spend of a txo, since it is not possible to prove that a specific `hashPrevouts` etc. goes with a specific txid without revealing the whole tx (which is precisely what we are trying to avoid), as both are hashes.\nWatchtowers may need to be entrusted with privkeys, or need to wait for `SIGHASH_ANYPREVOUT` so that the exact txid of the B collateralized contract tx does not need to be fixed at signing time, thus this solution is undesirable as well.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-09-05T02:45:00",
                "message_text_only": "Good morning Chris, and probably also Lightningers,\n\n> However, it might be possible to prevent the maker from learning the collateral input at all.\n>\n> If my understanding of BIP-143 is correct, inputs are hashed separately (`hashPrevouts`) from outputs (`hashOutputs`).\n> Bob can provide the `hashPrevouts` as an opaque hash, while providing a decommitment of `hashOutputs` to show that the outputs of the collateralized contract transaction are correct, which is all that Charlie really needs to know.\n>\n> Bob is incentivized to provide the correct `hashPrevouts`, because if it provides an incorrect `hashPrevouts` it cannot get a signature for a transaction it can use in case of a protocol abort, thus potentially losing its money in case of a protocol abort.\n> Conversely, Charlie does not care where Bob gets the funds that goes into its contract output come from, it only cares that the Bob collateralized contract output is I+K.\n> It loses nothing to sign that transaction, and it would prefer that transaction since its own contract output is only I.\n>\n> This solution is mildly \"unclean\" as it depends on the details of the sighash algorithm, though, and is not proposed seriously.\n> Hopefully nobody will change the sighash algorithm anytime soon.........\n>\n> In addition, it complicates reusing Lightning watchtowers.\n> Lightning watchtowers currently trigger on txid (i.e. it would have triggered on the txid of the B collateralized contract tx), but watching this needs to trigger on the spend of a txo, since it is not possible to prove that a specific `hashPrevouts` etc. goes with a specific txid without revealing the whole tx (which is precisely what we are trying to avoid), as both are hashes.\n> Watchtowers may need to be entrusted with privkeys, or need to wait for `SIGHASH_ANYPREVOUT` so that the exact txid of the B collateralized contract tx does not need to be fixed at signing time, thus this solution is undesirable as well.\n\nOn the other hand, when considering Decker-Russell-Osuntokun, the `(halftxid, encrypted_blob)` approach to watchtowers simply does not work.\nWatchtowers are simpler in Decker-Russell-Osuntoku if and only if the watchtower knows the funding outpoint, therefore knows which channel it is watching *before* an attack on the channel occurs, and is less private.\n\nI have argued before that we should instead use `(sighash[0:15], encrypted_blob)` rather than `(txid[0:15], encrypted_blob)`.\nThis makes Decker-Russell-Osuntokun blobs indistinguishable from Poon-Dryja blobs, and the watchtower is not even made aware what the commitment type of the channel is until an actual attack occurs.\n\nIf watchtowers use `(sighash[0:15], encrypted_blob)` instead, the proposal to hide the collateral input behind `hashPrevouts` would be workable, as Charlie knows the entire sighash of the B collateralized contract transaction even if it does not know the txid.\nThis also does not reveal the funding outpoint, or whether it is watching a Poon-Dryja channel, a Decker-Russell-Osuntokun channel, or a CoinSwap.\n\n--\n\nEven if we propose that CoinSwap makers should run their own watchtowers rather than hire a public watchtower, it's safer for a CoinSwap maker to have watchtowers that are unaware of exactly *what* they are watching.\nIf the watchtowers are aware of the funding outputs they are watching, then every additional watchtower a maker creates increases the attack surface on the privacy of the maker, as the funding outputs becoming known allows the maker hodlings to be derived.\n\nIf watchtowers only get a partial sighash, then the information that they contain are not sufficient by themselves to determine what coins are owned by the maker, thus every additional watchtower is no longer a potential attack vector on the privacy of the maker.\n\nSo this is off-topic, but anyway, we should probably move to using `sighash[0:15]` instead of `txid[0:15]` for watchtowers.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-09-05T01:07:15",
                "message_text_only": "Hi Chris,\n\nI forgot to underscore that contract transaction output must be grieved by\nat least a CSV of 1. Otherwise, a malicious counterparty can occupy with\ngarbage both the timelock-or-preimage output and its own anchor output thus\nblocking you to use the bumping capability of your own anchor ouput.\n\nA part of this, I think it works.\n\n> Another possible fix for both vulnerabilities is to separate the\n> timelock and hashlock cases into two separate transactions as described\n> by ZmnSCPxj in a recent email to this list. This comes at the cost of\n> breaking private key handover allowing coins to remain unspent\nindefinitely.\n\nThis works too assuming these second-stage transactions aren't malleable at\nall (e.g SIGASH_SINGLE). Other ways you can increase their feerate/absolute\nfee and you're back to the initial situation.\n\nBeyond note also that anchors-on-second-stage are more risky here, as\notherwise your counterparty can again attach a low-feerate child. In case\nof concurrent broadcast (assuming you haven't achieved to claim the output\nbefore timelock expiration due to network outage/mempool-congestion) you\nmight not see your counterparty version. I.e, your local mempool has the\ntimelock tx and the rest of the network the hashlock and your CPFP bump\nwon't propagate as being an orphan.\n\nSo you're left with a RBF-range, which is mostly okay minus a theoretical\nconcern : a party guessing the odds to lose the balance are high can\nbroadcast/send out-of-band the highest-fee bound to miners thus\nincentivizing them to censor a honest, low-fee  preimage tx. A\n\"nothing-at-stake-for-genuinely-evil-counterparty\" issue.\n\n> Another possible fix for the second attack, is to encumber the output\n> with a `1 OP_CSV` which stops that output being spent while unconfirmed.\n> This seems to be the simplest way if your aim is to only fix the second\n> attack.\n\nYes you don't package fee malleability so an honest party can always\nunilaterally bump the feerate and override concurrent bids.\n\n\nThat said, I would lean towards anchors and thus unileratel fee bumping.\nFeerate interactivity among a multi-party protocol should be seen as an\noracle to leak the full-node of a participant. By sending a range of\nconflicting transactions with different feerates to a set of network\nmempools I could theoretically observe variations in the protocol feerate\nannounced.\n\nI would recommend you to have a look on this paper, if it's not done yet :\nhttps://arxiv.org/pdf/2007.00764.pdf, the first one analyzing privacy\nholistically across Bitcoin layers.\n\nCheers,\n\nAntoine\n\nLe sam. 29 ao\u00fbt 2020 \u00e0 18:03, Chris Belcher <belcher at riseup.net> a \u00e9crit :\n\n> Hello Antoine,\n>\n> Thanks for the very useful insights.\n>\n> It seems having just one contract transaction which includes anchor\n> outputs in the style already used by Lightning is one way to fix both\n> these vulnerabilities.\n>\n> For the first attack, the other side cannot burn the entire balance\n> because they only have access to the small amount of satoshi of the\n> anchor output, and to add miner fees they must add their own inputs. So\n> they'd burn their own coins to miner fees, not the coins in the contract.\n>\n> For the second attack, the other side cannot do transaction pinning\n> because there is only one contract transaction, and all the protections\n> already developed for use with Lightning apply here as well, such as\n> CPFP carve out.\n>\n>\n> Another possible fix for both vulnerabilities is to separate the\n> timelock and hashlock cases into two separate transactions as described\n> by ZmnSCPxj in a recent email to this list. This comes at the cost of\n> breaking private key handover allowing coins to remain unspent\n> indefinitely.\n>\n> Another possible fix for the second attack, is to encumber the output\n> with a `1 OP_CSV` which stops that output being spent while unconfirmed.\n> This seems to be the simplest way if your aim is to only fix the second\n> attack.\n>\n>\n> These are all the possible fixes I can think of.\n>\n> Regards\n> Chris\n>\n> On 24/08/2020 20:30, Antoine Riard wrote:\n> > Hello Chris,\n> >\n> > I think you might have vulnerability issues with the current design.\n> >\n> > With regards to the fee model for contract transactions, AFAICT timely\n> > confirmation is a fund safety matter for an intermediate hop. Between the\n> > offchain preimage reveal phase and the offchain private key handover\n> phase,\n> > the next hop can broadcast your outgoing contract transactions, thus\n> > forcing you to claim quickly backward as you can't assume previous hop\n> will\n> > honestly cooperate to achieve the private key handover. This means that\n> > your range of pre-signed RBF-transactions must theoretically have for fee\n> > upper bound the maximum of the contested balance, as game-theory side,\n> it's\n> > rational to you to burn your balance instead of letting your counterparty\n> > claim it after timelock expiration, in face of mempool congestion. Where\n> > the issue dwells is that this fee is pre-committed and not cancelled when\n> > the balance change of ownership by the outgoing hop learning the preimage\n> > of the haslock output. Thus the previous hop is free to broadcast the\n> > highest-fee RBF-transactions and burn your balance, as for him, his\n> balance\n> > is now encoded in the output of the contract transactions on the previous\n> > link, for which he knows the preimage.\n> >\n> > Note, I think this is independent of picking up either relative or\n> absolute\n> > timelocks as what matters is the block delta between two links. Of course\n> > you can increase this delta to be week-lengthy and thus decrease the need\n> > for a compelling fee but a) you may force quickly close with contract\n> > transactions if the private key handover doesn't happen soon, you don't\n> > want to be caught by surprise by congestion so you would close far behind\n> > delta period expiration like half of it, and b) you increase the\n> time-value\n> > of makers funds in case of faulty hop, thus logically increasing the\n> maker\n> > fee and making the cost of the system higher in average. I guess a better\n> > solution would be to use dual-anchor outputs has spec'ed out by\n> Lightning,\n> > it lets the party who has a balance at stake unilaterally increase\n> feerate\n> > with a CPFP. The CPFP is obviously a higher blockchain cost but a) it's a\n> > safety mechanism for a worst-case scenario, 99% of the time they won't be\n> > committed, b) you might use this CPFP to aggregate change outputs or\n> other\n> > opportunistically side-usage.\n> >\n> > With regards to the preimage release phase, I think you might have a\n> > pinning scenario. The victim would be an intermediate hop, targeted by a\n> > malicious taker. The preimage isn't revealed offchain to this victim\n> hop. A\n> > low-feerate version of the outgoing contract transaction is broadcast and\n> > not going to confirm, assuming a bit of congestion. As preimage is known,\n> > the malicious taker can directly attach a high-fee, low-feerate child\n> > transaction and thus prevent any replacement of the pinned parent by a\n> > honest broadcast of a high-fee RBF-transaction under BIP 125 rules. At\n> the\n> > same time, the malicious taker broadcasts the contract tx on the previous\n> > link and gets it confirmed. At relative timelock expiration, malicious\n> > taker claims back the funds. When the pinned transaction spending the\n> > outgoing link gets evicted (either by replacing child by a higher feerate\n> > or waiting for mempool expiration after 2 weeks), taker gets it confirmed\n> > this time and claims output through hashlock. Given the relative timelock\n> > blocking the victim, there is not even a race.\n> >\n> > I guess restraining the contract transaction to one and only one version\n> > would overcome this attack. A honest intermediate hop, as soon as seeing\n> a\n> > relative timelock triggered backward would immediately broadcast the\n> > outgoing link contract tx or if it's already in network mempools\n> broadcast\n> > a higher-feerate child. As you don't have valid multiple contract\n> > transactions, an attacker can't obstruct you to propagate the correct\n> > child, as you are not blind about the parent txid.\n> >\n> > Lastly, one downside of using relative timelocks, in case of one\n> downstream\n> > link failure, it forces every other upstream hops to go onchain to\n> protect\n> > against this kind of pinning scenario. And this would be a privacy\n> > breakdown, as a maker would be able to provoke one, thus constraining\n> every\n> > upstream hops to go onchain with the same hash and revealing the CoinSwap\n> > route.\n> >\n> > Let me know if I reviewed the correct transactions circuit model or\n> > misunderstood associated semantic. I might be completely wrong, coming\n> from\n> > a LN perspective.\n> >\n> > Cheers,\n> > Antoine\n> >\n> > Le mar. 11 ao\u00fbt 2020 \u00e0 13:06, Chris Belcher via bitcoin-dev <\n> > bitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n> >\n> >> I'm currently working on implementing CoinSwap (see my other email\n> >> \"Design for a CoinSwap implementation for massively improving Bitcoin\n> >> privacy and fungibility\").\n> >>\n> >> CoinSwaps are special because they look just like regular bitcoin\n> >> transactions, so they improve the privacy even for people who do not use\n> >> them. Once CoinSwap is deployed, anyone attempting surveillance of\n> >> bitcoin transactions will be forced to ask themselves the question: how\n> >> do we know this transaction wasn't a CoinSwap?\n> >>\n> >> This email contains a detailed design of the first protocol version. It\n> >> makes use of the building blocks of multi-transaction CoinSwaps, routed\n> >> CoinSwaps, liquidity market, private key handover, and fidelity bonds.\n> >> It does not include PayJoin-with-CoinSwap, but that's in the plan to be\n> >> added later.\n> >>\n> >> == Routed CoinSwap ==\n> >>\n> >> Diagram of CoinSwaps in the route:\n> >>\n> >>     Alice ====> Bob ====> Charlie ====> Alice\n> >>\n> >> Where (====>) means one CoinSwap. Alice gives coins to Bob, who gives\n> >> coins to Charlie, who gives coins to Alice. Alice is the market taker\n> >> and she starts with the hash preimage. She chooses the CoinSwap amount\n> >> and chooses who the makers will be.\n> >>\n> >> This design has one market taker and two market makers in its route, but\n> >> it can easily be extended to any number of makers.\n> >>\n> >> == Multiple transactions ==\n> >>\n> >> Each single CoinSwap is made up of multiple transactions to avoid amount\n> >> correlation\n> >>\n> >>           (a0 BTC) --->     (b0 BTC) --->         (c0 BTC) --->\n> >>     Alice (a1 BTC) ---> Bob (b1 BTC) ---> Charlie (c1 BTC) ---> Alice\n> >>           (a2 BTC) --->     (b2 BTC) --->         (c2 BTC) --->\n> >>\n> >> The arrow (--->) represent funding transactions. The money gets paid to\n> >> a 2-of-2 multisig but after the CoinSwap protocol and private key\n> >> handover is done they will be controlled by the next party in the route.\n> >>\n> >> This example has 6 regular-sized transactions which use approximately\n> >> the same amount of block space as a single JoinMarket coinjoin with 6\n> >> parties (1 taker, 5 makers). Yet the privacy provided by this one\n> >> CoinSwap would be far far greater. It would not have to be repeated in\n> >> the way that Equal-Output CoinJoins must be.\n> >>\n> >> == Direct connections to Alice ===\n> >>\n> >> Only Alice, the taker, knows the entire route, Bob and Charlie just know\n> >> their previous and next transactions. Bob and Charlie do not have direct\n> >> connections with each other, only with Alice.\n> >>\n> >> Diagram of Tor connections:\n> >>\n> >>     Bob      Charlie\n> >>      |       /\n> >>      |      /\n> >>      |     /\n> >>       Alice\n> >>\n> >> When Bob and Charlie communicate, they are actually sending and\n> >> receiving messages via Alice who relays them to Charlie or Bob. This\n> >> helps hide whether the previous or next counterparty in a CoinSwap route\n> >> is a maker or taker.\n> >>\n> >> This doesn't have security issues even in the final steps where private\n> >> keys are handed over, because those private keys are always for 2-of-2\n> >> multisig and so on their own are never enough to steal money.\n> >>\n> >>\n> >> === Miner fees ===\n> >>\n> >> Makers have no incentive to pay any miner fees. They only do\n> >> transactions which earn them an income and are willing to wait a very\n> >> long time for that to happen. By contrast takers want to create\n> >> transactions far more urgently. In JoinMarket we coded a protocol where\n> >> the maker could contribute to miner fees, but the market price offered\n> >> of that trended towards zero. So the reality is that takers will pay all\n> >> the miner fees. Also because makers don't know the taker's time\n> >> preference they don't know how much they should pay in miner fees.\n> >>\n> >> The taker will have to set limits on how large the maker's transactions\n> >> are, otherwise makers could abuse this by having the taker consolidate\n> >> maker's UTXOs for free.\n> >>\n> >> == Funding transaction definitions ==\n> >>\n> >> Funding transactions are those which pay into the 2-of-2 multisig\n> >> addresses.\n> >>\n> >> Definitions:\n> >> I = initial coinswap amount sent by Alice = a0 + a1 + a2\n> >> (WA, WB, WC) = Total value of UTXOs being spent by Alice, Bob, Charlie\n> >>                respectively. Could be called \"wallet Alice\", \"wallet\n> >>                Bob\", etc\n> >> (B, C) = Coinswap fees paid by Alice and earned by Bob and Charlie.\n> >> (M1, M2, M3) = Miner fees of the first, second, third, etc sets of\n> >>                funding transactions. Alice will choose what these are\n> >>                since she's paying.\n> >> multisig(A+B) = A 2of2 multisig output with private keys held by A and B\n> >>\n> >> The value in square parentheses refers to the bitcoin amount.\n> >>\n> >> Alice funding txes\n> >>   [WA btc] ---> multisig (Alice+Bob) [I btc]\n> >>                 change [WA-M1-I btc]\n> >> Bob funding txes\n> >>   [WB btc] ---> multisig (Bob+Charlie) [I-M2-B btc]\n> >>                 change [WB-I+B btc]\n> >> Charlie funding txes\n> >>   [WC btc] ---> multisig (Charlie+Alice) [(I-M2-B)-M3-C btc]\n> >>                 change [WC-(I-M2-B)+C btc]\n> >>\n> >> Here we've drawn these transactions as single transactions, but they are\n> >> actually multiple transactions where the outputs add up some value (e.g.\n> >> add up to I in Alice's transactions.)\n> >>\n> >> === Table of balances before and after a successful CoinSwap ===\n> >>\n> >> If a CoinSwap is successful then all the multisig outputs in the funding\n> >> transactions will become controlled unilaterally by one party. We can\n> >> calculate how the balances of each party change.\n> >>\n> >> Party   | Before | After\n> >> --------|--------|-------------------------------------------\n> >> Alice   | WA     | WA-M1-I + (I-M2-B)-M3-C  = WA-M1-M2-M3-B-C\n> >> Bob     | WB     | WB-I+B + I               = WB+B\n> >> Charlie | WC     | WC-(I-M2-B)+C + I-M2-B   = WC+C\n> >>\n> >> After a successful coinswap, we see Alice's balance goes down by the\n> >> miner fees and the coinswap fees. Bob's and Charlie's balance goes up by\n> >> their coinswap fees.\n> >>\n> >> == Contract transaction definitions ==\n> >>\n> >> Contract transactions are those which may spend from the 2-of-2 multisig\n> >> outputs, they transfer the coins into a contract where the coins can be\n> >> spent either by waiting for a timeout or providing a hash preimage\n> >> value. Ideally contract transactions will never be broadcast but their\n> >> existence keeps all parties honest.\n> >>\n> >> M~ is miner fees, which we treat as a random variable, and ultimately\n> >> set by whichever pre-signed RBF tx get mined. When we talk about _the_\n> >> contract tx, we actually mean perhaps 20-30 transactions which only\n> >> differ by the miner fee and have RBF enabled, so they can be broadcasted\n> >> in sequence to get the contract transaction mined regardless of the\n> >> demand for block space.\n> >>\n> >> (Alice+timelock_A OR Bob+hash) = Is an output which can be spent\n> >>                                  either with Alice's private key\n> >>                                  after waiting for a relative\n> >>                                  timelock_A, or by Bob's private key by\n> >>                                  revealing a hash preimage value\n> >>\n> >> Alice contract tx:\n> >>     multisig (Alice+Bob) ---> (Alice+timelock_A OR Bob+hash)\n> >>     [I btc]                   [I-M~ btc]\n> >> Bob contract tx:\n> >>     multisig (Bob+Charlie) ---> (Bob+timelock_B OR Charlie+hash)\n> >>     [I-M2-B btc]                [I-M2-B-M~ btc]\n> >> Charlie contract tx:\n> >>     multisig (Charlie+Alice)  ---> (Charlie+timelock_C OR Alice+hash)\n> >>     [(I-M2-B)-M3-C btc]            [(I-M2-B)-M3-C-M~ btc]\n> >>\n> >>\n> >> === Table of balances before/after CoinSwap using contracts transactions\n> >> ===\n> >>\n> >> In this case the parties had to get their money back by broadcasting and\n> >> mining the contract transactions and waiting for timeouts.\n> >>\n> >> Party   | Before | After\n> >> --------|--------|--------------------------------------------\n> >> Alice   | WA     | WA-M1-I + I-M~                   = WA-M1-M~\n> >> Bob     | WB     | WB-I+B + I-M2-B-M~               = WB-M2-M~\n> >> Charlie | WC     | WC-(I-M2-B)+C + (I-M2-B)-M3-C-M~ = WC-M3-M~\n> >>\n> >> In the timeout failure case, every party pays for their own miner fees.\n> >> And nobody earns or spends any coinswap fees. So even for a market maker\n> >> its possible for their wallet balance to go down sometimes, although as\n> >> we shall see there are anti-DOS features which make this unlikely to\n> >> happen often.\n> >>\n> >> A possible attack by a malicious Alice is that she chooses M1 to be very\n> >> low (e.g. 1 sat/vbyte) and sets M2 and M3 to be very high (e.g. 1000\n> >> sat/vb) and then intentionally aborts, forcing the makers to lose much\n> >> more money in miner fees than the attacker. The attack can be used to\n> >> waste away Bob's and Charlie's coins on miner fees at little cost to the\n> >> malicious taker Alice. So to defend against this attack Bob and Charlie\n> >> must refuse to sign a contract transaction if the corresponding funding\n> >> transaction pays miner fees greater than Alice's funding transaction.\n> >>\n> >>\n> >> There can also be a failure case where each party gets their money using\n> >> hash preimage values instead of timeouts. Note that each party has to\n> >> sweep the output before the timeout expires, so that will cost an\n> >> additional miner fee M~.\n> >>\n> >> Party   | Before | After\n> >> --------|--------|------------------------------------------------------\n> >> Alice   | WA     | WA-M1-I + (I-M2-B)-M3-C-M~ - M~ = WA-M1-M2-M3-B-C-2M~\n> >> Bob     | WB     | WB-I+B + I-M~ - M~              = WB+B-2M~\n> >> Charlie | WC     | WC-(I-M2-B)+C + I-M2-B-M~ - M~  = WC+C-2M~\n> >>\n> >> In this situation the makers Bob and Charlie earn their CoinSwap fees,\n> >> but they pay an additional miner fee twice. Alice pays for all the\n> >> funding transaction miner fees, and the CoinSwap fees, and two\n> >> additional miner fees. And she had her privacy damaged because the\n> >> entire world saw on the blockchain the contract script.\n> >>\n> >> Using the timelock path is like a refund, everyone's coin just comes\n> >> back to them. Using the preimage is like the CoinSwap transaction\n> >> happened, with the coins being sent ahead one hop. Again note that if\n> >> the preimage is used then coinswap fees are paid.\n> >>\n> >> === Staggered timelocks ===\n> >>\n> >> The timelocks are staggered so that if Alice uses the preimage to take\n> >> coins then the right people will also learn the preimage and have enough\n> >> time to be able to get their coins back too. Alice starts with knowledge\n> >> of the hash preimage so she must have a longest timelock.\n> >>\n> >> == EC tweak to reduce one round trip ==\n> >>\n> >> When two parties are agreeing on a 2-of-2 multisig address, they need to\n> >> agree on their public keys. We can avoid one round trip by using the EC\n> >> tweak trick.\n> >>\n> >> When Alice, the taker, downloads the entire offer book for the liquidity\n> >> market, the offers will also contain a EC public key. Alice can tweak\n> >> this to generate a brand new public key for which the maker knows the\n> >> private key. This public key will be one of the keys in the 2-of-2\n> >> multisig. This feature removes one round trip from the protocol.\n> >>\n> >>     q = EC privkey generated by maker\n> >>     Q = q.G = EC pubkey published by maker\n> >>\n> >>     p = nonce generated by taker\n> >>     P = p.G = nonce point calculated by taker\n> >>\n> >>     R = Q + P = pubkey used in bitcoin transaction\n> >>       = (q + p).G\n> >>\n> >> Taker sends unsigned transaction which pays to multisig using pubkey Q,\n> >> and also sends nonce p. The maker can use nonce p to calculate (q + p)\n> >> which is the private key of pubkey R.\n> >>\n> >> Taker doesnt know the privkey because they are unable to find q because\n> >> of the ECDLP.\n> >>\n> >> Any eavesdropper can see the nonce p and easily calculate the point R\n> >> too but Tor communication is encrypted so this isnt a concern.\n> >>\n> >> None of the makers in the route know each other's Q values, so Alice the\n> >> taker will generate a nonce p on their behalf and send it over. I\n> >> believe this cant be used for any kind of attack, because the signing\n> >> maker will always check that the nonce results in the public key\n> >> included in the transaction they're signing, and they'll never sign a\n> >> transaction not in their interests.\n> >>\n> >>\n> >> == Protocol ==\n> >>\n> >> This section is the most important part of this document.\n> >>\n> >> Definitions:\n> >> fund = all funding txes (remember in this multi-tx protocol there can be\n> >>        multiple txes which together make up the funding)\n> >> A htlc = all htlc contract txes (fully signed) belonging to party A\n> >> A unsign htcl = all unsigned htlc contract txes belonging to party A\n> >>                 including the nonce point p used to calculate the\n> >>                 maker's pubkey.\n> >> p = nonce point p used in the tweak EC protocol for calculating the\n> >>     maker's pubkey\n> >> A htlc B/2 = Bob's signature for the 2of2 multisig of the Alice htlc\n> >>              contract tx\n> >> privA(A+B) = private key generated by Alice in the output\n> >>              multisig (Alice+Bob)\n> >>\n> >>\n> >>  | Alice           | Bob             | Charlie         |\n> >>  |=================|=================|=================|\n> >> 0. A unsign htlc ---->               |                 |\n> >> 1.               <---- A htlc B/2    |                 |\n> >> 2. ***** BROADCAST AND MINE ALICE FUNDING TXES ******  |\n> >> 3. A fund+htlc+p ---->               |                 |\n> >> 4.                 | B unsign htlc ---->               |\n> >> 5.                 |               <---- B htlc C/2    |\n> >> 6. ******* BROADCAST AND MINE BOB FUNDING TXES ******* |\n> >> 7.                 | B fund+htlc+p ---->               |\n> >> 8.               <---------------------- C unsign htlc |\n> >> 9.    C htlc A/2 ---------------------->               |\n> >> A. ***** BROADCAST AND MINE CHARLIE FUNDING TXES ***** |\n> >> B.               <---------------------- C fund+htlc+p |\n> >> C. hash preimage ---------------------->               |\n> >> D. hash preimage ---->               |                 |\n> >> E.    privA(A+B) ---->               |                 |\n> >> F.                 |    privB(B+C) ---->               |\n> >> G.               <---------------------- privC(C+A)    |\n> >>\n> >> == Protocol notes ==\n> >> 0-2 are the steps which setup Alice's funding tx and her contract tx for\n> >>     possible refund\n> >> 4-5 same as 0-2 but for Bob\n> >> 8-9 same as 0-2 but for Charlie\n> >> 3,7 is proof to the next party that the previous party has already\n> >>     committed miner fees to getting a transaction mined, and therefore\n> >>     this isnt a DOS attack. The step also reveals the fully-signed\n> >>     contract transaction which the party can use to get their money back\n> >>     with a preimage.\n> >> C-G is revealing the hash preimage to all, and handing over the private\n> >>     keys\n> >>\n> >>\n> >> == Analysis of aborts ==\n> >>\n> >> We will now discuss aborts, which happen when one party halts the\n> >> protocol and doesnt continue. Perhaps they had a power cut, their\n> >> internet broke, or they're a malicious attacker wanting to waste time\n> >> and money. The other party may try to reestablish a connection for some\n> >> time, but eventually must give up.\n> >>\n> >> Number refers to the step number where the abort happened\n> >> e.g. step 1 means that the party aborted instead of the action happening\n> >> on protocol step 1.\n> >>\n> >> The party name refers to what that party does\n> >> e.g. Party1: aborts, Party2/Party3: does a thing in reaction\n> >>\n> >> 0. Alice: aborts. Bob/Charlie: do nothing, they havent lost any time or\n> >>    money\n> >> 1. Bob: aborts. Alice: lost no time or money, try with another Bob.\n> >>    Charlie: do nothing\n> >> 2-3. same as 0.\n> >> 4. Bob: aborts. Charlie: do nothing. Alice: broadcasts her contract tx\n> >>    and waits for the timeout, loses time and money on miner fees, she'll\n> >>    never coinswap with Bob's fidelity bond again.\n> >> 5. Charlie: aborts. Alice/Bob: lose nothing, find another Charlie to\n> >>    coinswap with.\n> >> 6. same as 4.\n> >> 7. similar to 4 but Alice MIGHT not blacklist Bob's fidelity bond,\n> >>    because Bob will also have to broadcast his contract tx and will also\n> >>    lose time and money.\n> >> 8. Charlie: aborts. Bob: broadcast his contract transaction and wait for\n> >>    the timeout to get his money back, also broadcast Alice's contract\n> >>    transaction in retaliation. Alice: waits for the timeout on her htlc\n> >>    tx that Bob broadcasted, will never do a coinswap with Charlie's\n> >>    fidelity bond again.\n> >> 9. Alice: aborts. Charlie: do nothing, no money or time lost. Bob:\n> >>    broadcast bob contract tx and wait for timeout to get money back,\n> >>    comforted by the knowledge that when Alice comes back online she'll\n> >>    have to do the same thing and waste the same amount of time and\n> >>    money.\n> >> A-B. same as 8.\n> >> C-E. Alice: aborts. Bob/Charlie: all broadcast their contract txes and\n> >>      wait for the timeout to get their money back, or if Charlie knows\n> >>      the preimage he uses it to get the money immediately, which Bob can\n> >>      read from the blockchain and also use.\n> >> F. Bob: aborts. Alice: broadcast Charlie htlc tx and use preimage to get\n> >>    money immediately, Alice blacklists Bob's fidelity bond. Charlie:\n> >>    broadcast Bob htlc and use preimage to get money immediately.\n> >> G. Charlie: aborts. Alice: broadcast Charlie htlc and use preimage to\n> >>    get money immediately, Alice blacklists Charlie's fidelity bond. Bob:\n> >>    does nothing, already has his privkey.\n> >>\n> >> ==== Retaliation as DOS-resistance ====\n> >>\n> >> In some situations (e.g. step 8.) if one maker in the coinswap route is\n> >> the victim of a DOS they will retaliate by DOSing the previous maker in\n> >> the route. This may seem unnecessary and unfair (after all why waste\n> >> even more time and block space) but is actually the best way to resist\n> >> DOS because it produces a concrete cost every time a DOS happens.\n> >>\n> >>\n> >> == Analysis of deviations ==\n> >>\n> >> This section discusses what happens if one party deviates from the\n> >> protocol by doing something else, for example broadcasting a htlc\n> >> contract tx when they shouldnt have.\n> >>\n> >> The party name refers to what that party does, followed by other party's\n> >> reactions to it.\n> >> e.g. Party1: does a thing, Party2/Party3: does a thing in reaction\n> >>\n> >> If multiple deviations are possible in a step then they are numbered\n> >> e.g. A1 A2 A2 etc\n> >>\n> >>\n> >> 0-2. Alice/Bob/Charlie: nothing else is possible except following the\n> >>      protocol or aborting\n> >> 3. Alice: broadcasts one or more of the A htlc txes. Bob/Charlie/Dennis:\n> >>    do nothing, they havent lost any time or money.\n> >> 4-6. Bob/Charlie: nothing else is possible except following the protocol\n> >>      or aborting.\n> >> 7. Bob: broadcasts one or more of the B htlc txes, Alice: broadcasts all\n> >>    her own A htlc txes and waits for the timeout to get her money back.\n> >>    Charlie: do nothing\n> >> 8. Charlie: nothing else is possible except following the protocol or\n> >>    aborting.\n> >> 9. Alice: broadcasts one or more of the A htlc txes. Bob: broadcasts all\n> >>    his own A htlc txes and waits for the timeout.\n> >> A. same as 8.\n> >> B. Charlie: broadcasts one or more of the C htlc txes, Alice/Bob:\n> >>    broadcasts all their own htlc txes and waits for the timeout to get\n> >>    their money back.\n> >> C-E1. Alice: broadcasts all of C htlc txes and uses her knowledge of the\n> >>       preimage hash to take the money immediately. Charlie: broadcasts\n> >>       all of B htlc txes and reading the hash value from the blockchain,\n> >>       uses it to take the money from B htlc immediately. Bob: broadcasts\n> >>       all of A htlc txes, and reading hash from the blockchain, uses it\n> >>       to take the money from A htlc immediately.\n> >> C-E2. Alice: broadcast her own A htlc txes, and after a timeout take the\n> >>       money. Bob: broadcast his own B htlc txes and after the timeout\n> >>       take their money. Charlie: broadcast his own C htlc txes and after\n> >>       the timeout take their money.\n> >> F1. Bob: broadcast one or more of A htcl txes and use the hash preimage\n> >>     to get the money immediately. He already knows both privkeys of the\n> >>     multisig so this is pointless and just damages privacy and wastes\n> >>     miner fees. Alice: blacklist Bob's fidelity bond.\n> >> F2. Bob: broadcast one or more of the C htlc txes. Charlie: use preimage\n> >>     to get his money immediately. Bob's actions were pointless. Alice:\n> >>     cant tell whether Bob or Charlie actually broadcasted, so blacklist\n> >>     both fidelity bonds.\n> >> G1. Charlie: broadcast one or more of B htcl txes and use the hash\n> >>     preimage to get the money immediately. He already knows both\n> >>     privkeys of the multisig so this is pointless and just damages\n> >>     privacy and wastes miner fees. Alice: cant tell whether Bob or\n> >>     Charlie actually broadcasted, so blacklist both fidelity bonds.\n> >> G2. Charlie: broadcast one or more of the A htlc txes. Alice: broadcast\n> >>     the remaining A htlc txes and use preimage to get her money\n> >>     immediately. Charlies's actions were pointless. Alice: blacklist\n> >>     Charlie's fidelity bond.\n> >>\n> >> The multisig outputs of the funding transactions can stay unspent\n> >> indefinitely. However the parties must always be watching the network\n> >> and ready to respond with their own sweep using a preimage. This is\n> >> because the other party still possesses a fully-signed contract tx. The\n> >> parties respond in the same way as in steps C-E1, F2 and G2. Alice's\n> >> reaction of blacklisting both fidelity bonds might not be the right way,\n> >> because one maker could use it to get another one blacklisted (as well\n> >> as themselves).\n> >>\n> >>\n> >> == Conclusion ==\n> >>\n> >> This document describes the first version of the protocol which\n> >> implements multi-transaction Coinswap, routed Coinswap, fidelity bonds,\n> >> a liquidity market and private key handover. I describe the protocol and\n> >> also analyze aborts of the protocols and deviations from the protocol.\n> >>\n> >> _______________________________________________\n> >> bitcoin-dev mailing list\n> >> bitcoin-dev at lists.linuxfoundation.org\n> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >>\n> >\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200904/620ce615/attachment-0001.html>"
            },
            {
                "author": "seid Mohammed",
                "date": "2020-09-06T03:06:52",
                "message_text_only": "subscribe pls https://www.youtube.com/channel/UCcRPSO-n2HgolBFKzW3re4Q\n\nOn Saturday, September 5, 2020, Antoine Riard via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Chris,\n>\n> I forgot to underscore that contract transaction output must be grieved by\n> at least a CSV of 1. Otherwise, a malicious counterparty can occupy with\n> garbage both the timelock-or-preimage output and its own anchor output thus\n> blocking you to use the bumping capability of your own anchor ouput.\n>\n> A part of this, I think it works.\n>\n> > Another possible fix for both vulnerabilities is to separate the\n> > timelock and hashlock cases into two separate transactions as described\n> > by ZmnSCPxj in a recent email to this list. This comes at the cost of\n> > breaking private key handover allowing coins to remain unspent\n> indefinitely.\n>\n> This works too assuming these second-stage transactions aren't malleable\n> at all (e.g SIGASH_SINGLE). Other ways you can increase their\n> feerate/absolute fee and you're back to the initial situation.\n>\n> Beyond note also that anchors-on-second-stage are more risky here, as\n> otherwise your counterparty can again attach a low-feerate child. In case\n> of concurrent broadcast (assuming you haven't achieved to claim the output\n> before timelock expiration due to network outage/mempool-congestion) you\n> might not see your counterparty version. I.e, your local mempool has the\n> timelock tx and the rest of the network the hashlock and your CPFP bump\n> won't propagate as being an orphan.\n>\n> So you're left with a RBF-range, which is mostly okay minus a theoretical\n> concern : a party guessing the odds to lose the balance are high can\n> broadcast/send out-of-band the highest-fee bound to miners thus\n> incentivizing them to censor a honest, low-fee  preimage tx. A\n> \"nothing-at-stake-for-genuinely-evil-counterparty\" issue.\n>\n> > Another possible fix for the second attack, is to encumber the output\n> > with a `1 OP_CSV` which stops that output being spent while unconfirmed.\n> > This seems to be the simplest way if your aim is to only fix the second\n> > attack.\n>\n> Yes you don't package fee malleability so an honest party can always\n> unilaterally bump the feerate and override concurrent bids.\n>\n>\n> That said, I would lean towards anchors and thus unileratel fee bumping.\n> Feerate interactivity among a multi-party protocol should be seen as an\n> oracle to leak the full-node of a participant. By sending a range of\n> conflicting transactions with different feerates to a set of network\n> mempools I could theoretically observe variations in the protocol feerate\n> announced.\n>\n> I would recommend you to have a look on this paper, if it's not done yet :\n> https://arxiv.org/pdf/2007.00764.pdf, the first one analyzing privacy\n> holistically across Bitcoin layers.\n>\n> Cheers,\n>\n> Antoine\n>\n> Le sam. 29 ao\u00fbt 2020 \u00e0 18:03, Chris Belcher <belcher at riseup.net> a \u00e9crit :\n>\n>> Hello Antoine,\n>>\n>> Thanks for the very useful insights.\n>>\n>> It seems having just one contract transaction which includes anchor\n>> outputs in the style already used by Lightning is one way to fix both\n>> these vulnerabilities.\n>>\n>> For the first attack, the other side cannot burn the entire balance\n>> because they only have access to the small amount of satoshi of the\n>> anchor output, and to add miner fees they must add their own inputs. So\n>> they'd burn their own coins to miner fees, not the coins in the contract.\n>>\n>> For the second attack, the other side cannot do transaction pinning\n>> because there is only one contract transaction, and all the protections\n>> already developed for use with Lightning apply here as well, such as\n>> CPFP carve out.\n>>\n>>\n>> Another possible fix for both vulnerabilities is to separate the\n>> timelock and hashlock cases into two separate transactions as described\n>> by ZmnSCPxj in a recent email to this list. This comes at the cost of\n>> breaking private key handover allowing coins to remain unspent\n>> indefinitely.\n>>\n>> Another possible fix for the second attack, is to encumber the output\n>> with a `1 OP_CSV` which stops that output being spent while unconfirmed.\n>> This seems to be the simplest way if your aim is to only fix the second\n>> attack.\n>>\n>>\n>> These are all the possible fixes I can think of.\n>>\n>> Regards\n>> Chris\n>>\n>> On 24/08/2020 20:30, Antoine Riard wrote:\n>> > Hello Chris,\n>> >\n>> > I think you might have vulnerability issues with the current design.\n>> >\n>> > With regards to the fee model for contract transactions, AFAICT timely\n>> > confirmation is a fund safety matter for an intermediate hop. Between\n>> the\n>> > offchain preimage reveal phase and the offchain private key handover\n>> phase,\n>> > the next hop can broadcast your outgoing contract transactions, thus\n>> > forcing you to claim quickly backward as you can't assume previous hop\n>> will\n>> > honestly cooperate to achieve the private key handover. This means that\n>> > your range of pre-signed RBF-transactions must theoretically have for\n>> fee\n>> > upper bound the maximum of the contested balance, as game-theory side,\n>> it's\n>> > rational to you to burn your balance instead of letting your\n>> counterparty\n>> > claim it after timelock expiration, in face of mempool congestion. Where\n>> > the issue dwells is that this fee is pre-committed and not cancelled\n>> when\n>> > the balance change of ownership by the outgoing hop learning the\n>> preimage\n>> > of the haslock output. Thus the previous hop is free to broadcast the\n>> > highest-fee RBF-transactions and burn your balance, as for him, his\n>> balance\n>> > is now encoded in the output of the contract transactions on the\n>> previous\n>> > link, for which he knows the preimage.\n>> >\n>> > Note, I think this is independent of picking up either relative or\n>> absolute\n>> > timelocks as what matters is the block delta between two links. Of\n>> course\n>> > you can increase this delta to be week-lengthy and thus decrease the\n>> need\n>> > for a compelling fee but a) you may force quickly close with contract\n>> > transactions if the private key handover doesn't happen soon, you don't\n>> > want to be caught by surprise by congestion so you would close far\n>> behind\n>> > delta period expiration like half of it, and b) you increase the\n>> time-value\n>> > of makers funds in case of faulty hop, thus logically increasing the\n>> maker\n>> > fee and making the cost of the system higher in average. I guess a\n>> better\n>> > solution would be to use dual-anchor outputs has spec'ed out by\n>> Lightning,\n>> > it lets the party who has a balance at stake unilaterally increase\n>> feerate\n>> > with a CPFP. The CPFP is obviously a higher blockchain cost but a) it's\n>> a\n>> > safety mechanism for a worst-case scenario, 99% of the time they won't\n>> be\n>> > committed, b) you might use this CPFP to aggregate change outputs or\n>> other\n>> > opportunistically side-usage.\n>> >\n>> > With regards to the preimage release phase, I think you might have a\n>> > pinning scenario. The victim would be an intermediate hop, targeted by a\n>> > malicious taker. The preimage isn't revealed offchain to this victim\n>> hop. A\n>> > low-feerate version of the outgoing contract transaction is broadcast\n>> and\n>> > not going to confirm, assuming a bit of congestion. As preimage is\n>> known,\n>> > the malicious taker can directly attach a high-fee, low-feerate child\n>> > transaction and thus prevent any replacement of the pinned parent by a\n>> > honest broadcast of a high-fee RBF-transaction under BIP 125 rules. At\n>> the\n>> > same time, the malicious taker broadcasts the contract tx on the\n>> previous\n>> > link and gets it confirmed. At relative timelock expiration, malicious\n>> > taker claims back the funds. When the pinned transaction spending the\n>> > outgoing link gets evicted (either by replacing child by a higher\n>> feerate\n>> > or waiting for mempool expiration after 2 weeks), taker gets it\n>> confirmed\n>> > this time and claims output through hashlock. Given the relative\n>> timelock\n>> > blocking the victim, there is not even a race.\n>> >\n>> > I guess restraining the contract transaction to one and only one version\n>> > would overcome this attack. A honest intermediate hop, as soon as\n>> seeing a\n>> > relative timelock triggered backward would immediately broadcast the\n>> > outgoing link contract tx or if it's already in network mempools\n>> broadcast\n>> > a higher-feerate child. As you don't have valid multiple contract\n>> > transactions, an attacker can't obstruct you to propagate the correct\n>> > child, as you are not blind about the parent txid.\n>> >\n>> > Lastly, one downside of using relative timelocks, in case of one\n>> downstream\n>> > link failure, it forces every other upstream hops to go onchain to\n>> protect\n>> > against this kind of pinning scenario. And this would be a privacy\n>> > breakdown, as a maker would be able to provoke one, thus constraining\n>> every\n>> > upstream hops to go onchain with the same hash and revealing the\n>> CoinSwap\n>> > route.\n>> >\n>> > Let me know if I reviewed the correct transactions circuit model or\n>> > misunderstood associated semantic. I might be completely wrong, coming\n>> from\n>> > a LN perspective.\n>> >\n>> > Cheers,\n>> > Antoine\n>> >\n>> > Le mar. 11 ao\u00fbt 2020 \u00e0 13:06, Chris Belcher via bitcoin-dev <\n>> > bitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n>> >\n>> >> I'm currently working on implementing CoinSwap (see my other email\n>> >> \"Design for a CoinSwap implementation for massively improving Bitcoin\n>> >> privacy and fungibility\").\n>> >>\n>> >> CoinSwaps are special because they look just like regular bitcoin\n>> >> transactions, so they improve the privacy even for people who do not\n>> use\n>> >> them. Once CoinSwap is deployed, anyone attempting surveillance of\n>> >> bitcoin transactions will be forced to ask themselves the question: how\n>> >> do we know this transaction wasn't a CoinSwap?\n>> >>\n>> >> This email contains a detailed design of the first protocol version. It\n>> >> makes use of the building blocks of multi-transaction CoinSwaps, routed\n>> >> CoinSwaps, liquidity market, private key handover, and fidelity bonds.\n>> >> It does not include PayJoin-with-CoinSwap, but that's in the plan to be\n>> >> added later.\n>> >>\n>> >> == Routed CoinSwap ==\n>> >>\n>> >> Diagram of CoinSwaps in the route:\n>> >>\n>> >>     Alice ====> Bob ====> Charlie ====> Alice\n>> >>\n>> >> Where (====>) means one CoinSwap. Alice gives coins to Bob, who gives\n>> >> coins to Charlie, who gives coins to Alice. Alice is the market taker\n>> >> and she starts with the hash preimage. She chooses the CoinSwap amount\n>> >> and chooses who the makers will be.\n>> >>\n>> >> This design has one market taker and two market makers in its route,\n>> but\n>> >> it can easily be extended to any number of makers.\n>> >>\n>> >> == Multiple transactions ==\n>> >>\n>> >> Each single CoinSwap is made up of multiple transactions to avoid\n>> amount\n>> >> correlation\n>> >>\n>> >>           (a0 BTC) --->     (b0 BTC) --->         (c0 BTC) --->\n>> >>     Alice (a1 BTC) ---> Bob (b1 BTC) ---> Charlie (c1 BTC) ---> Alice\n>> >>           (a2 BTC) --->     (b2 BTC) --->         (c2 BTC) --->\n>> >>\n>> >> The arrow (--->) represent funding transactions. The money gets paid to\n>> >> a 2-of-2 multisig but after the CoinSwap protocol and private key\n>> >> handover is done they will be controlled by the next party in the\n>> route.\n>> >>\n>> >> This example has 6 regular-sized transactions which use approximately\n>> >> the same amount of block space as a single JoinMarket coinjoin with 6\n>> >> parties (1 taker, 5 makers). Yet the privacy provided by this one\n>> >> CoinSwap would be far far greater. It would not have to be repeated in\n>> >> the way that Equal-Output CoinJoins must be.\n>> >>\n>> >> == Direct connections to Alice ===\n>> >>\n>> >> Only Alice, the taker, knows the entire route, Bob and Charlie just\n>> know\n>> >> their previous and next transactions. Bob and Charlie do not have\n>> direct\n>> >> connections with each other, only with Alice.\n>> >>\n>> >> Diagram of Tor connections:\n>> >>\n>> >>     Bob      Charlie\n>> >>      |       /\n>> >>      |      /\n>> >>      |     /\n>> >>       Alice\n>> >>\n>> >> When Bob and Charlie communicate, they are actually sending and\n>> >> receiving messages via Alice who relays them to Charlie or Bob. This\n>> >> helps hide whether the previous or next counterparty in a CoinSwap\n>> route\n>> >> is a maker or taker.\n>> >>\n>> >> This doesn't have security issues even in the final steps where private\n>> >> keys are handed over, because those private keys are always for 2-of-2\n>> >> multisig and so on their own are never enough to steal money.\n>> >>\n>> >>\n>> >> === Miner fees ===\n>> >>\n>> >> Makers have no incentive to pay any miner fees. They only do\n>> >> transactions which earn them an income and are willing to wait a very\n>> >> long time for that to happen. By contrast takers want to create\n>> >> transactions far more urgently. In JoinMarket we coded a protocol where\n>> >> the maker could contribute to miner fees, but the market price offered\n>> >> of that trended towards zero. So the reality is that takers will pay\n>> all\n>> >> the miner fees. Also because makers don't know the taker's time\n>> >> preference they don't know how much they should pay in miner fees.\n>> >>\n>> >> The taker will have to set limits on how large the maker's transactions\n>> >> are, otherwise makers could abuse this by having the taker consolidate\n>> >> maker's UTXOs for free.\n>> >>\n>> >> == Funding transaction definitions ==\n>> >>\n>> >> Funding transactions are those which pay into the 2-of-2 multisig\n>> >> addresses.\n>> >>\n>> >> Definitions:\n>> >> I = initial coinswap amount sent by Alice = a0 + a1 + a2\n>> >> (WA, WB, WC) = Total value of UTXOs being spent by Alice, Bob, Charlie\n>> >>                respectively. Could be called \"wallet Alice\", \"wallet\n>> >>                Bob\", etc\n>> >> (B, C) = Coinswap fees paid by Alice and earned by Bob and Charlie.\n>> >> (M1, M2, M3) = Miner fees of the first, second, third, etc sets of\n>> >>                funding transactions. Alice will choose what these are\n>> >>                since she's paying.\n>> >> multisig(A+B) = A 2of2 multisig output with private keys held by A and\n>> B\n>> >>\n>> >> The value in square parentheses refers to the bitcoin amount.\n>> >>\n>> >> Alice funding txes\n>> >>   [WA btc] ---> multisig (Alice+Bob) [I btc]\n>> >>                 change [WA-M1-I btc]\n>> >> Bob funding txes\n>> >>   [WB btc] ---> multisig (Bob+Charlie) [I-M2-B btc]\n>> >>                 change [WB-I+B btc]\n>> >> Charlie funding txes\n>> >>   [WC btc] ---> multisig (Charlie+Alice) [(I-M2-B)-M3-C btc]\n>> >>                 change [WC-(I-M2-B)+C btc]\n>> >>\n>> >> Here we've drawn these transactions as single transactions, but they\n>> are\n>> >> actually multiple transactions where the outputs add up some value\n>> (e.g.\n>> >> add up to I in Alice's transactions.)\n>> >>\n>> >> === Table of balances before and after a successful CoinSwap ===\n>> >>\n>> >> If a CoinSwap is successful then all the multisig outputs in the\n>> funding\n>> >> transactions will become controlled unilaterally by one party. We can\n>> >> calculate how the balances of each party change.\n>> >>\n>> >> Party   | Before | After\n>> >> --------|--------|-------------------------------------------\n>> >> Alice   | WA     | WA-M1-I + (I-M2-B)-M3-C  = WA-M1-M2-M3-B-C\n>> >> Bob     | WB     | WB-I+B + I               = WB+B\n>> >> Charlie | WC     | WC-(I-M2-B)+C + I-M2-B   = WC+C\n>> >>\n>> >> After a successful coinswap, we see Alice's balance goes down by the\n>> >> miner fees and the coinswap fees. Bob's and Charlie's balance goes up\n>> by\n>> >> their coinswap fees.\n>> >>\n>> >> == Contract transaction definitions ==\n>> >>\n>> >> Contract transactions are those which may spend from the 2-of-2\n>> multisig\n>> >> outputs, they transfer the coins into a contract where the coins can be\n>> >> spent either by waiting for a timeout or providing a hash preimage\n>> >> value. Ideally contract transactions will never be broadcast but their\n>> >> existence keeps all parties honest.\n>> >>\n>> >> M~ is miner fees, which we treat as a random variable, and ultimately\n>> >> set by whichever pre-signed RBF tx get mined. When we talk about _the_\n>> >> contract tx, we actually mean perhaps 20-30 transactions which only\n>> >> differ by the miner fee and have RBF enabled, so they can be\n>> broadcasted\n>> >> in sequence to get the contract transaction mined regardless of the\n>> >> demand for block space.\n>> >>\n>> >> (Alice+timelock_A OR Bob+hash) = Is an output which can be spent\n>> >>                                  either with Alice's private key\n>> >>                                  after waiting for a relative\n>> >>                                  timelock_A, or by Bob's private key by\n>> >>                                  revealing a hash preimage value\n>> >>\n>> >> Alice contract tx:\n>> >>     multisig (Alice+Bob) ---> (Alice+timelock_A OR Bob+hash)\n>> >>     [I btc]                   [I-M~ btc]\n>> >> Bob contract tx:\n>> >>     multisig (Bob+Charlie) ---> (Bob+timelock_B OR Charlie+hash)\n>> >>     [I-M2-B btc]                [I-M2-B-M~ btc]\n>> >> Charlie contract tx:\n>> >>     multisig (Charlie+Alice)  ---> (Charlie+timelock_C OR Alice+hash)\n>> >>     [(I-M2-B)-M3-C btc]            [(I-M2-B)-M3-C-M~ btc]\n>> >>\n>> >>\n>> >> === Table of balances before/after CoinSwap using contracts\n>> transactions\n>> >> ===\n>> >>\n>> >> In this case the parties had to get their money back by broadcasting\n>> and\n>> >> mining the contract transactions and waiting for timeouts.\n>> >>\n>> >> Party   | Before | After\n>> >> --------|--------|--------------------------------------------\n>> >> Alice   | WA     | WA-M1-I + I-M~                   = WA-M1-M~\n>> >> Bob     | WB     | WB-I+B + I-M2-B-M~               = WB-M2-M~\n>> >> Charlie | WC     | WC-(I-M2-B)+C + (I-M2-B)-M3-C-M~ = WC-M3-M~\n>> >>\n>> >> In the timeout failure case, every party pays for their own miner fees.\n>> >> And nobody earns or spends any coinswap fees. So even for a market\n>> maker\n>> >> its possible for their wallet balance to go down sometimes, although as\n>> >> we shall see there are anti-DOS features which make this unlikely to\n>> >> happen often.\n>> >>\n>> >> A possible attack by a malicious Alice is that she chooses M1 to be\n>> very\n>> >> low (e.g. 1 sat/vbyte) and sets M2 and M3 to be very high (e.g. 1000\n>> >> sat/vb) and then intentionally aborts, forcing the makers to lose much\n>> >> more money in miner fees than the attacker. The attack can be used to\n>> >> waste away Bob's and Charlie's coins on miner fees at little cost to\n>> the\n>> >> malicious taker Alice. So to defend against this attack Bob and Charlie\n>> >> must refuse to sign a contract transaction if the corresponding funding\n>> >> transaction pays miner fees greater than Alice's funding transaction.\n>> >>\n>> >>\n>> >> There can also be a failure case where each party gets their money\n>> using\n>> >> hash preimage values instead of timeouts. Note that each party has to\n>> >> sweep the output before the timeout expires, so that will cost an\n>> >> additional miner fee M~.\n>> >>\n>> >> Party   | Before | After\n>> >> --------|--------|------------------------------------------\n>> ------------\n>> >> Alice   | WA     | WA-M1-I + (I-M2-B)-M3-C-M~ - M~ =\n>> WA-M1-M2-M3-B-C-2M~\n>> >> Bob     | WB     | WB-I+B + I-M~ - M~              = WB+B-2M~\n>> >> Charlie | WC     | WC-(I-M2-B)+C + I-M2-B-M~ - M~  = WC+C-2M~\n>> >>\n>> >> In this situation the makers Bob and Charlie earn their CoinSwap fees,\n>> >> but they pay an additional miner fee twice. Alice pays for all the\n>> >> funding transaction miner fees, and the CoinSwap fees, and two\n>> >> additional miner fees. And she had her privacy damaged because the\n>> >> entire world saw on the blockchain the contract script.\n>> >>\n>> >> Using the timelock path is like a refund, everyone's coin just comes\n>> >> back to them. Using the preimage is like the CoinSwap transaction\n>> >> happened, with the coins being sent ahead one hop. Again note that if\n>> >> the preimage is used then coinswap fees are paid.\n>> >>\n>> >> === Staggered timelocks ===\n>> >>\n>> >> The timelocks are staggered so that if Alice uses the preimage to take\n>> >> coins then the right people will also learn the preimage and have\n>> enough\n>> >> time to be able to get their coins back too. Alice starts with\n>> knowledge\n>> >> of the hash preimage so she must have a longest timelock.\n>> >>\n>> >> == EC tweak to reduce one round trip ==\n>> >>\n>> >> When two parties are agreeing on a 2-of-2 multisig address, they need\n>> to\n>> >> agree on their public keys. We can avoid one round trip by using the EC\n>> >> tweak trick.\n>> >>\n>> >> When Alice, the taker, downloads the entire offer book for the\n>> liquidity\n>> >> market, the offers will also contain a EC public key. Alice can tweak\n>> >> this to generate a brand new public key for which the maker knows the\n>> >> private key. This public key will be one of the keys in the 2-of-2\n>> >> multisig. This feature removes one round trip from the protocol.\n>> >>\n>> >>     q = EC privkey generated by maker\n>> >>     Q = q.G = EC pubkey published by maker\n>> >>\n>> >>     p = nonce generated by taker\n>> >>     P = p.G = nonce point calculated by taker\n>> >>\n>> >>     R = Q + P = pubkey used in bitcoin transaction\n>> >>       = (q + p).G\n>> >>\n>> >> Taker sends unsigned transaction which pays to multisig using pubkey Q,\n>> >> and also sends nonce p. The maker can use nonce p to calculate (q + p)\n>> >> which is the private key of pubkey R.\n>> >>\n>> >> Taker doesnt know the privkey because they are unable to find q because\n>> >> of the ECDLP.\n>> >>\n>> >> Any eavesdropper can see the nonce p and easily calculate the point R\n>> >> too but Tor communication is encrypted so this isnt a concern.\n>> >>\n>> >> None of the makers in the route know each other's Q values, so Alice\n>> the\n>> >> taker will generate a nonce p on their behalf and send it over. I\n>> >> believe this cant be used for any kind of attack, because the signing\n>> >> maker will always check that the nonce results in the public key\n>> >> included in the transaction they're signing, and they'll never sign a\n>> >> transaction not in their interests.\n>> >>\n>> >>\n>> >> == Protocol ==\n>> >>\n>> >> This section is the most important part of this document.\n>> >>\n>> >> Definitions:\n>> >> fund = all funding txes (remember in this multi-tx protocol there can\n>> be\n>> >>        multiple txes which together make up the funding)\n>> >> A htlc = all htlc contract txes (fully signed) belonging to party A\n>> >> A unsign htcl = all unsigned htlc contract txes belonging to party A\n>> >>                 including the nonce point p used to calculate the\n>> >>                 maker's pubkey.\n>> >> p = nonce point p used in the tweak EC protocol for calculating the\n>> >>     maker's pubkey\n>> >> A htlc B/2 = Bob's signature for the 2of2 multisig of the Alice htlc\n>> >>              contract tx\n>> >> privA(A+B) = private key generated by Alice in the output\n>> >>              multisig (Alice+Bob)\n>> >>\n>> >>\n>> >>  | Alice           | Bob             | Charlie         |\n>> >>  |=================|=================|=================|\n>> >> 0. A unsign htlc ---->               |                 |\n>> >> 1.               <---- A htlc B/2    |                 |\n>> >> 2. ***** BROADCAST AND MINE ALICE FUNDING TXES ******  |\n>> >> 3. A fund+htlc+p ---->               |                 |\n>> >> 4.                 | B unsign htlc ---->               |\n>> >> 5.                 |               <---- B htlc C/2    |\n>> >> 6. ******* BROADCAST AND MINE BOB FUNDING TXES ******* |\n>> >> 7.                 | B fund+htlc+p ---->               |\n>> >> 8.               <---------------------- C unsign htlc |\n>> >> 9.    C htlc A/2 ---------------------->               |\n>> >> A. ***** BROADCAST AND MINE CHARLIE FUNDING TXES ***** |\n>> >> B.               <---------------------- C fund+htlc+p |\n>> >> C. hash preimage ---------------------->               |\n>> >> D. hash preimage ---->               |                 |\n>> >> E.    privA(A+B) ---->               |                 |\n>> >> F.                 |    privB(B+C) ---->               |\n>> >> G.               <---------------------- privC(C+A)    |\n>> >>\n>> >> == Protocol notes ==\n>> >> 0-2 are the steps which setup Alice's funding tx and her contract tx\n>> for\n>> >>     possible refund\n>> >> 4-5 same as 0-2 but for Bob\n>> >> 8-9 same as 0-2 but for Charlie\n>> >> 3,7 is proof to the next party that the previous party has already\n>> >>     committed miner fees to getting a transaction mined, and therefore\n>> >>     this isnt a DOS attack. The step also reveals the fully-signed\n>> >>     contract transaction which the party can use to get their money\n>> back\n>> >>     with a preimage.\n>> >> C-G is revealing the hash preimage to all, and handing over the private\n>> >>     keys\n>> >>\n>> >>\n>> >> == Analysis of aborts ==\n>> >>\n>> >> We will now discuss aborts, which happen when one party halts the\n>> >> protocol and doesnt continue. Perhaps they had a power cut, their\n>> >> internet broke, or they're a malicious attacker wanting to waste time\n>> >> and money. The other party may try to reestablish a connection for some\n>> >> time, but eventually must give up.\n>> >>\n>> >> Number refers to the step number where the abort happened\n>> >> e.g. step 1 means that the party aborted instead of the action\n>> happening\n>> >> on protocol step 1.\n>> >>\n>> >> The party name refers to what that party does\n>> >> e.g. Party1: aborts, Party2/Party3: does a thing in reaction\n>> >>\n>> >> 0. Alice: aborts. Bob/Charlie: do nothing, they havent lost any time or\n>> >>    money\n>> >> 1. Bob: aborts. Alice: lost no time or money, try with another Bob.\n>> >>    Charlie: do nothing\n>> >> 2-3. same as 0.\n>> >> 4. Bob: aborts. Charlie: do nothing. Alice: broadcasts her contract tx\n>> >>    and waits for the timeout, loses time and money on miner fees,\n>> she'll\n>> >>    never coinswap with Bob's fidelity bond again.\n>> >> 5. Charlie: aborts. Alice/Bob: lose nothing, find another Charlie to\n>> >>    coinswap with.\n>> >> 6. same as 4.\n>> >> 7. similar to 4 but Alice MIGHT not blacklist Bob's fidelity bond,\n>> >>    because Bob will also have to broadcast his contract tx and will\n>> also\n>> >>    lose time and money.\n>> >> 8. Charlie: aborts. Bob: broadcast his contract transaction and wait\n>> for\n>> >>    the timeout to get his money back, also broadcast Alice's contract\n>> >>    transaction in retaliation. Alice: waits for the timeout on her htlc\n>> >>    tx that Bob broadcasted, will never do a coinswap with Charlie's\n>> >>    fidelity bond again.\n>> >> 9. Alice: aborts. Charlie: do nothing, no money or time lost. Bob:\n>> >>    broadcast bob contract tx and wait for timeout to get money back,\n>> >>    comforted by the knowledge that when Alice comes back online she'll\n>> >>    have to do the same thing and waste the same amount of time and\n>> >>    money.\n>> >> A-B. same as 8.\n>> >> C-E. Alice: aborts. Bob/Charlie: all broadcast their contract txes and\n>> >>      wait for the timeout to get their money back, or if Charlie knows\n>> >>      the preimage he uses it to get the money immediately, which Bob\n>> can\n>> >>      read from the blockchain and also use.\n>> >> F. Bob: aborts. Alice: broadcast Charlie htlc tx and use preimage to\n>> get\n>> >>    money immediately, Alice blacklists Bob's fidelity bond. Charlie:\n>> >>    broadcast Bob htlc and use preimage to get money immediately.\n>> >> G. Charlie: aborts. Alice: broadcast Charlie htlc and use preimage to\n>> >>    get money immediately, Alice blacklists Charlie's fidelity bond.\n>> Bob:\n>> >>    does nothing, already has his privkey.\n>> >>\n>> >> ==== Retaliation as DOS-resistance ====\n>> >>\n>> >> In some situations (e.g. step 8.) if one maker in the coinswap route is\n>> >> the victim of a DOS they will retaliate by DOSing the previous maker in\n>> >> the route. This may seem unnecessary and unfair (after all why waste\n>> >> even more time and block space) but is actually the best way to resist\n>> >> DOS because it produces a concrete cost every time a DOS happens.\n>> >>\n>> >>\n>> >> == Analysis of deviations ==\n>> >>\n>> >> This section discusses what happens if one party deviates from the\n>> >> protocol by doing something else, for example broadcasting a htlc\n>> >> contract tx when they shouldnt have.\n>> >>\n>> >> The party name refers to what that party does, followed by other\n>> party's\n>> >> reactions to it.\n>> >> e.g. Party1: does a thing, Party2/Party3: does a thing in reaction\n>> >>\n>> >> If multiple deviations are possible in a step then they are numbered\n>> >> e.g. A1 A2 A2 etc\n>> >>\n>> >>\n>> >> 0-2. Alice/Bob/Charlie: nothing else is possible except following the\n>> >>      protocol or aborting\n>> >> 3. Alice: broadcasts one or more of the A htlc txes.\n>> Bob/Charlie/Dennis:\n>> >>    do nothing, they havent lost any time or money.\n>> >> 4-6. Bob/Charlie: nothing else is possible except following the\n>> protocol\n>> >>      or aborting.\n>> >> 7. Bob: broadcasts one or more of the B htlc txes, Alice: broadcasts\n>> all\n>> >>    her own A htlc txes and waits for the timeout to get her money back.\n>> >>    Charlie: do nothing\n>> >> 8. Charlie: nothing else is possible except following the protocol or\n>> >>    aborting.\n>> >> 9. Alice: broadcasts one or more of the A htlc txes. Bob: broadcasts\n>> all\n>> >>    his own A htlc txes and waits for the timeout.\n>> >> A. same as 8.\n>> >> B. Charlie: broadcasts one or more of the C htlc txes, Alice/Bob:\n>> >>    broadcasts all their own htlc txes and waits for the timeout to get\n>> >>    their money back.\n>> >> C-E1. Alice: broadcasts all of C htlc txes and uses her knowledge of\n>> the\n>> >>       preimage hash to take the money immediately. Charlie: broadcasts\n>> >>       all of B htlc txes and reading the hash value from the\n>> blockchain,\n>> >>       uses it to take the money from B htlc immediately. Bob:\n>> broadcasts\n>> >>       all of A htlc txes, and reading hash from the blockchain, uses it\n>> >>       to take the money from A htlc immediately.\n>> >> C-E2. Alice: broadcast her own A htlc txes, and after a timeout take\n>> the\n>> >>       money. Bob: broadcast his own B htlc txes and after the timeout\n>> >>       take their money. Charlie: broadcast his own C htlc txes and\n>> after\n>> >>       the timeout take their money.\n>> >> F1. Bob: broadcast one or more of A htcl txes and use the hash preimage\n>> >>     to get the money immediately. He already knows both privkeys of the\n>> >>     multisig so this is pointless and just damages privacy and wastes\n>> >>     miner fees. Alice: blacklist Bob's fidelity bond.\n>> >> F2. Bob: broadcast one or more of the C htlc txes. Charlie: use\n>> preimage\n>> >>     to get his money immediately. Bob's actions were pointless. Alice:\n>> >>     cant tell whether Bob or Charlie actually broadcasted, so blacklist\n>> >>     both fidelity bonds.\n>> >> G1. Charlie: broadcast one or more of B htcl txes and use the hash\n>> >>     preimage to get the money immediately. He already knows both\n>> >>     privkeys of the multisig so this is pointless and just damages\n>> >>     privacy and wastes miner fees. Alice: cant tell whether Bob or\n>> >>     Charlie actually broadcasted, so blacklist both fidelity bonds.\n>> >> G2. Charlie: broadcast one or more of the A htlc txes. Alice: broadcast\n>> >>     the remaining A htlc txes and use preimage to get her money\n>> >>     immediately. Charlies's actions were pointless. Alice: blacklist\n>> >>     Charlie's fidelity bond.\n>> >>\n>> >> The multisig outputs of the funding transactions can stay unspent\n>> >> indefinitely. However the parties must always be watching the network\n>> >> and ready to respond with their own sweep using a preimage. This is\n>> >> because the other party still possesses a fully-signed contract tx. The\n>> >> parties respond in the same way as in steps C-E1, F2 and G2. Alice's\n>> >> reaction of blacklisting both fidelity bonds might not be the right\n>> way,\n>> >> because one maker could use it to get another one blacklisted (as well\n>> >> as themselves).\n>> >>\n>> >>\n>> >> == Conclusion ==\n>> >>\n>> >> This document describes the first version of the protocol which\n>> >> implements multi-transaction Coinswap, routed Coinswap, fidelity bonds,\n>> >> a liquidity market and private key handover. I describe the protocol\n>> and\n>> >> also analyze aborts of the protocols and deviations from the protocol.\n>> >>\n>> >> _______________________________________________\n>> >> bitcoin-dev mailing list\n>> >> bitcoin-dev at lists.linuxfoundation.org\n>> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> >>\n>> >\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200906/ad8795aa/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-09-05T01:10:36",
                "message_text_only": "Hi Zeeman,\n\nI think one of the general problems for any participant in an\ninterdependent chain of contracts like Lightning or CoinSwap is to avoid a\ndisequilibrium in its local HTLC ledger. Concretely sending forward more\nthan you receive backward. W.r.t, timelocks delta aim to enforce order of\nevents, namely that a forward contract must be terminated before any\nbackward contract to avoid a discrepancy in settlement. Order of events can\nbe enforced by a) absolute timelocks and thus linearized on the same scale\nby blockchain ticks or b) by a counterparty to two relative-time locked\ncontracts which observe the broadcast of the backward transaction and thus\nmanually trigger the kickoff of forward timelock by broadcasting the\ncorresponding transaction.\n\nWith this rough model in mind, pinning an absolute or relative timelocked\ntransaction produce the same effect, i.e breaking contracts settlement\norder.\n\n> This can be arranged by having one side offer partial signatures for the\ntransaction of the other, and once completing the signature, not sharing it\nwith the other until we are ready to actually broadcast the transaction of\nour own volition.\n> There is no transaction that both participants hold in completely-signed\nform\n\nI don't think that's different from the current model where you have either\na valid HTLC-timeout or HTLC-Sucess tx to solve a HTLC output but never\nfull witness material to build both ?\n\nI see a theoretical issue with RBF-range, if you're likely to lose the\nbalance, you can broadcast your highest-RBF version thus incentivizing\nminers to censor counterparty claim tx. Kind of a \"nothing at stake\" issue.\nAs of today, you have to take this fee out of your pocket if you want to\nincentivize miners to act so, not promising a fee from an ongoing disputed\nbalance.\n\n> Private key turnover is still useful even in an absolute-timelock world.\n\nThe way I understand the either-HTLC-or-private-key-turnover construction\nin CoinSwap is for the HTLC to serve as a security backup in case the\ncooperative key turnover fails. Lightning don't have this model as you\ndon't switch funding transaction ownership.\n\n> To reduce this risk, A can instead first swap A->B->A, then when that\ncompletes, A->C->A.\nThis limits its funding lockup to 1 week.\n\nOkay I think I understand your point. So by intermediating the chain with\nthe taker you ensure that in case of previous hop failure, taker funds are\nonly timelocked for the delta of this faulting hop not the whole route. But\nstill not anchoring onchain the next route segment means that any moment\nthe next maker can exit from the proposed position ?\n\nThat's interesting, so a) you require all takers to lock their funds\nonchain before initiating the whole routing and you will pay more in\nservice fees or b) you only lock them step by step but you increase risk of\nnext hop default and thus latency. Roughly.\n\nIt might be an interesting construction to explore on its own, minus the\ndownside of producing weird spend patterns due to next hop maker bidding\nwith another party.\n\nCheers,\n\nAntoine\n\nLe lun. 24 ao\u00fbt 2020 \u00e0 23:16, ZmnSCPxj <ZmnSCPxj at protonmail.com> a \u00e9crit :\n\n>\n> Good morning Antoine,\n>\n>\n> > Note, I think this is independent of picking up either relative or\n> absolute timelocks as what matters is the block delta between two links.\n>\n> I believe it is quite dependent on relative locktimes.\n> Relative locktimes *require* a contract transaction to kick off the\n> relative locktime period.\n> On the other hand, with Scriptless Script (which we know how to do with\n> 2p-ECDSA only, i.e. doable pre-Taproot), absolute locktimes do not need a\n> contract transaction.\n>\n> With absolute locktimes + Scriptless SCript, in a single onchain PTLC, one\n> participant holds a completely-signed timelock transaction while the other\n> participant holds a completely-signed pointlock transaction.\n> This can be arranged by having one side offer partial signatures for the\n> transaction of the other, and once completing the signature, not sharing it\n> with the other until we are ready to actually broadcast the transaction of\n> our own volition.\n> There is no transaction that both participants hold in completely-signed\n> form.\n>\n> This should remove most of the shenanigans possible, and makes the 30xRBF\n> safe for any range of fees.\n> I think.\n>\n> Since for each PTLC a participant holds only its \"own\" transaction, it is\n> possible for a participant to define its range of fees for the RBF versions\n> of the transaction it owns, without negotiation with the other participant.\n> Since the fee involved is deducted from its own transaction, each\n> participant can define this range of RBFed fees and impose it on the\n> partial signatures it gets from the other participant.\n>\n> --\n>\n> Private key turnover is still useful even in an absolute-timelock world.\n>\n> If we need to bump up the block delta between links, it might be\n> impractical to have the total delta of a multi-hop swap be too long at the\n> taker.\n>\n> As a concrete example, suppose A is a taker who wants to route over makers\n> B and C.\n> However, B and C require a CLTV delta of 1 week.\n>\n> If A wants to route \"directly\" A->B->C->A, then if something bad happens,\n> it could be looking at having its funds locked for two weeks.\n>\n> To reduce this risk, A can instead first swap A->B->A, then when that\n> completes, A->C->A.\n> This limits its funding lockup to 1 week.\n>\n> Private key turnover is useful since as soon as the A->B->A swap\n> completes, it can directly fund the A->C->A swap from the B-side funding\n> transaction of the A->B->A swap.\n>\n>          |   A->B->A         |    A->C->A           |\n>          :                   :                      :\n>       A -:->funding A&B--> B :                      :\n>          :                   :                      :\n>       B -:->funding A&B -----:--> funding A&C --> C :\n>          :                   :                      :\n>          :                   :C-> funding A&C ------:-> to-cold  A -->\n>          :                   :                      :\n>\n> This increases the number of transactions by 1 per swap beyond the first,\n> compared to a direct routing A->B->C->A, but this may be worth it for A if\n> the timelocks involved are too big for A.\n>\n> With 2p-ECDSA, a funding A&C looks exactly the same as a to-cold A, so B\n> is unable to reliably determine if it is the last hop in the route.\n>\n> Without private key turnover, A would have:\n>\n>                       **NO** private key turnover!\n>\n>          |   A->B->A         |    A->C->A                      |\n>          :                   :                                 :\n>       A -:->funding A&B--> B :                                 :\n>          :                   :                                 :\n>       B -:->funding A&B -----:--> claim A -> funding A&C --> C :\n>          :                   :                                 :\n>          :                   :           C-> funding A&C ------:->\n> to-cold  A -->\n>          :                   :                                 :\n>\n> So if timelock-deltas are possibly-high (to reduce the probability of the\n> MAD-HTLC argument, and other attacks, succeeding), takers might prefer to\n> route by completing one swap first before starting the next one, and\n> private key turnover is useful by reducing blockspace required by each hop.\n>\n> For reference, this is how it looks like with a single A->B->C->A swap\n> with private key turnover:\n>\n>          |   A->B->C->A      |\n>          :                   :\n>       A -:->funding A&B--> B :\n>          :                   :\n>       B -:->funding B&C -> C :\n>          :                   :\n>       C -:->funding A&C -----:-> to-cold A -->\n>          :                   :\n>\n> This is still smaller than in the A->B->A, A->C->A with private key\n> turnover, by one funding tx per hop.\n> However, A risks a much higher timelock (twice the timelock).\n> Thus, A might prefer a lower timelock in exchange for paying for an\n> additional transaction.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200904/7184e416/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-09-05T02:29:18",
                "message_text_only": "Good morning Antoine,\n\n\n> > This can be arranged by having one side offer partial signatures for the transaction of the other, and once completing the signature, not sharing it with the other until we are ready to actually broadcast the transaction of our own volition.\n> > There is no transaction that both participants hold in completely-signed form\n>\n> I don't think that's different from the current model where you have either a valid HTLC-timeout or HTLC-Sucess tx to solve a HTLC output but never full witness material to build both ?\n\nIt is different in that the current (actually, now *previous*) model looks like this:\n\n\n    funding out ->  contract tx -->  HTLC-timeout\n                                         OR\n                                     HTLC-success\n\n\nWhereas what I am describing looks like this:\n\n    funding out ->  HTLC-timeout\n                        OR\n                    HTLC-success\n\nThe attack being described has to do with the fact that, after private key turnover (i.e. after hash-lock resolution), the contract tx can be used to at least annoy the supposed new owner of the funding out, since the contract tx deducts fees from its input to pay for itself.\nAnd at the end of the swap (after private key turnover) the one who funded the funding outpoint (and swapped its control for this outpoint already, for a different outpoint) can at least try to broadcast the contract tx for a *chance* that the HTLC-timeout becomes valid and it can steal the coin even after taking the swapped coin on the other side of the swap.\n\n\nChris recently described a different technique, which has different contract txes, with the contract tx held by the offerrer of the HTLC (who can otherwise later annoy the acceptor of the HTLC once the HTLC has been hash-resolved) costing the offerrer of the HTLC some coins if it is published after swap completion.\n\n\n> > To reduce this risk, A can instead first swap A->B->A, then when that completes, A->C->A.\n> This limits its funding lockup to 1 week.\n>\n> Okay I think I understand your point. So by intermediating the chain with the taker you ensure that in case of previous hop failure, taker funds are only timelocked for the delta of this faulting hop not the whole route. But still not anchoring onchain the next route segment means that any moment the next maker can exit from the proposed position ?\n>\n> That's interesting, so a) you require all takers to lock their funds onchain before initiating the whole routing and you will pay more in service fees or b) you only lock them step by step but you increase risk of next hop default and thus latency. Roughly.\n> \u00a0\n> It might be an interesting construction to explore on its own, minus the downside of producing weird spend patterns due to next hop maker bidding with another party.\n>\n\nCorrect, a taker can pay higher fees for lots of smaller swaps that reduce its lockup risk, or pay less (with similar privacy bought) but with greater total lockup risk.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Detailed protocol design for routed multi-transaction CoinSwap",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Chris Belcher",
                "seid Mohammed",
                "ZmnSCPxj",
                "Antoine Riard"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 107527
        }
    },
    {
        "title": "[bitcoin-dev] BIP OP_CHECKTEMPLATEVERIFY",
        "thread_messages": [
            {
                "author": "Dmitry Petukhov",
                "date": "2020-09-03T14:42:23",
                "message_text_only": "Just had an idea that an an \"inverse timelock\" can be made\nalmost-certainly automatic: a revocation UTXO shall become\nanyone-can-spend after a timeout, and bear some non-dust amount.\n\nBefore the timelock expiration, it shall be spendable only along with\nthe covenant-locked 'main' UTXO (via a signature or mutual covenant)\n\nThis way, after a timeout expires, a multitude of entities will be\nincentivized to spend this UTXO, because this would be free money for\nthem. It will probably be spend by a miner, as they can always replace\nthe spending transaction with their own and claim the amount.\n\nAfter the revocation UTXO is spent, the covenant path that commits to\nhaving it in the inputs will be unspendable, and this would effectively\nconstitute an \"inverse timelock\".\n\n\u0412 Fri, 14 Feb 2020 11:16:26 -0800\nJeremy <jlrubin at mit.edu> wrote:\n\n> Hi Dmitry,\n> \n> I don't think that this is fundamentally introducing new behavior, but\n> let's take a closer look.\n> \n> We can talk about the issue you bring up purely in terms of a\n> hypothetical \"OP_CHECKINPUTOUTPOINTVERIFY\" and\n> \"OP_CHECKINPUTSCRIPTVERIFY\" (CIOV, CISV) with obvious implied by name\n> semantics, as a separate construct from CTV itself. Such opcodes\n> would be strictly more powerful/flexible than what CTV is enabling.\n> \n> Using these opcodes I can make an output that can *only* be spent with\n> another output -- e.g.,\n> \n> <s> <n> OP_CISV OP_DROP <pk> OP_CHECKSIGVERIFY\n> <h, i> <n> OP_CIOV OP_DROP <pk> OP_CHECKSIGVERIFY\n> \n> Let's look at CISV first:\n> \n> 1) Assume that <s> is from the same owner as PK\n> 2) Assume that <s> is from a different owner than PK\n> \n> In case 1, the wallet can create or recreate the appropriate output as\n> needed if it gets spent/stuck\n> \n> In case 2, the wallet can get \"frozen\" in a reorg until a signer on\n> <s> re-spends.\n> \n> \n> For CIOV:\n> \n> 1) Assume that <h, i> exists in the chain somewhere\n> 2) Assume that <h, i> exists in the mempool somewhere\n> 3) Assume that <h, i> does not exist (or, is provably non-creatable\n> -- h = txid(x) | x.IsValid() == false)\n> \n> In case 2, this is just a fancy op-return.\n> \n> Case 1 degrades into case 2 in the event of a reorg.\n> \n> In Case 2, if the output <h, i> is spent in another transaction, our\n> script becomes provably unspendable (unless a second reorg).\n> \n> Otherwise, it is possible to mine a block with our transaction.\n> \n> \n> Compare the above to normal transactions:\n> \n> 1) If a reorg occurs, and someone double-spends, your transaction gets\n> cancelled.\n> 2) You can re-sign your UTXO onto a different transaction\n> \n> However, if you have deleted your key (e.g. using a pre-signing HSM),\n> or your transaction was using a multi-sig with an uncooperating\n> party, you will have an output that may be effectively burned.\n> \n> These issues are -- as with CTV -- not present in the single input\n> use case.\n> \n> Thus I argue that CTV -- whose semantics are less powerful/flexible\n> than CISV/CIOV -- aren't introducing something that's not already\n> present when doing protocols involving more than one input.\n> \n> Further, on CTV \"monotonic authorization\":\n> \n> Generally we want Bitcoin Scripts to have the property that once a\n> condition is reached, it is 'permanently' a true case. E.g., showing\n> a hash preimage to C x, H(x) == C. This can't change with the weather\n> or anything else. Even things like timelocks -- although not obvious\n> at first glance -- have this property. They express logic that says\n> \"given the chain is at this height, ...\". This means that on any\n> chain at such a height the txn is valid. CISV/CIOV semantics also\n> fall in line with this description. It says, \"given such an input U,\n> ...\". If that input is realizable one time, it is provably realizable\n> across reorgs. However, that doesn't mean someone couldn't interrupt\n> U from being created. But generally, with Reorg + Double spend, or\n> Reorg > 100 blocks (potentially destroying CB reward), all bets are\n> off as to the replay-ability of transactions.\n> \n> I want to also point out that this \"revocation\" property -- to the\n> extent it is something new that can't already be emulated with\n> pre-signeds or RBF -- is entirely opt-in as far as CTV is concerned.\n> You have to specify that an output can only be spent with another,\n> most wallets shouldn't do that, and it can't \"infect\" other wallets\n> to an extent more than spending from any recently confirmed output\n> exposes you to more reorg risk.\n> \n> *In sum, we do not need to worry about this for CTV.*\n> \n> \n> Lastly, I want to note that revocation is part of what CTV is\n> designed to do (absent reorgs). It allows us to prune spending\n> conditions by playing a transaction forward.\n> \n> E.g., spending conditions {Alice & Bob, Preimage(H(X)) + Eve,\n> CTV({Alice & Bob}, 1 day)}\n> \n> Expresses that Eve has 1 day to reveal the preimage to H(X), otherwise\n> Alice and Bob can take the coin back by removing Eve's HTLC path.\n> What's cool about this revocation v.s. just {Alice & Bob,\n> Preimage(H(X)) + Eve} is that Alice and Bob don't need to coordinate\n> a multisig to revoke Eve.\n> \n> \n> \n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n> \n> \n> On Fri, Feb 14, 2020 at 3:17 AM Dmitry Petukhov <dp at simplexum.com>\n> wrote:\n> \n> > I decided to take this thread back on-list because I beleive that\n> > the 'revocation utxo' feature enabled by OP_CTV commiting to\n> > scriptSig may have wider implications that can slightly change the\n> > behavior of Bitcoin as a system, and some might not expect such\n> > changes or might not find them desireable (although there is\n> > already a case for such behaviour with RBF).\n> >\n> > There is a principle that some find valuable: \"During reorgs of\n> > depth less than 100, it is always possible to eventually replay\n> > transactions from the old branch into the new branch as long as no\n> > double spends are attempted\" (quoted from Russel O'Connor from the\n> > discussion about 'revocation utxo' on Elements Slack channel).\n> >\n> > As far as I can tell, this principle can be violated with the use of\n> > RBF: \"(tx) that was included in branch A and then RBF-ed (tx') in\n> > branch B and then branch A wins -> children of (tx') can't be\n> > replayed\"\n> >\n> > Some may hold an opinion that introducing new rules that violate\n> > that principle should be done with caution.\n> >\n> > The 'revocation utxo' feature enabled by OP_CTV essentially\n> > introduces a manually triggered 'inverse timelock' -  normal\n> > timelocks make tx invalid until certain point in time, and inverse\n> > timelock make tx invalid _after_ certain point in time, in this\n> > case by spending an unrelated UTXO.\n> >\n> > In a reorg, one branch can have that UTXO spent before the OP_CTV\n> > transaction that depends on it is included in the block, and the\n> > OP_CTV transaction and its children can't be replayed.\n> >\n> > This is the same issue as an 'automatic inverse timelock' that could\n> > be enforced by the structure of the transaction itself, if there was\n> > appropriate mechanism, with the difference that 'revocation utxo' is\n> > manually triggered.\n> >\n> > The absense of 'automatic inverse timelock' mechanism in Bitcoin\n> > hints that it was not seen as desireable historically. I was not\n> > able to find the relevant discussions, though.\n> >\n> > I would like to add that the behaviour enabled by inverse timelocks\n> > could be useable in various schemes with covenants, like the vaults\n> > with access revocable by spending the 'revocation utxo', or in the\n> > trustless lending schemes where the covenant scripts can enforce\n> > different amounts of interest paid to lender based on the point in\n> > time when the loan is returned - the obsolete script paths (with\n> > smaller interest paid) can be disabled by inverse timelock.\n> >\n> > \u0412 Fri, 13 Dec 2019 23:37:19 -0800\n> > Jeremy <jlrubin at mit.edu> wrote:\n> >  \n> > > That's a cool use case. I've thought previously about an\n> > > OP_CHECKINPUT, as a separate extension. Will need to think about\n> > > if your construction introduces a hash cycle (unless\n> > > SIGHASH_ALL|SIGHASH_ANYONECANPAY is used it seems likely).\n> > >\n> > > Also re signatures I think it's definitely possible to pick a\n> > > (signature, message) pair and generate a pk from it, but in\n> > > general the Bitcoin message commits to the pk so forging isn't\n> > > possible.\n> > >\n> > > On Fri, Dec 13, 2019, 11:25 PM Dmitry Petukhov <dp at simplexum.com>\n> > > wrote:\n> > >  \n> > > > Another idea for smart vaults:\n> > > >\n> > > > The ability to commit to scriptSig of a non-segwit input could\n> > > > be used for on-chain control of spending authorization\n> > > > (revoking the spending authorization), where CTV ensures that\n> > > > certain input is present in the transaction.\n> > > >\n> > > > scriptSig of that input can contain a signature that commits to\n> > > > certain prevout. Unless it is possible to forge an identical\n> > > > signature (and I don't know how strong are guarantees of that),\n> > > > such an input can only be valid if that prevout was not spent.\n> > > >\n> > > > Thus spending such prevout makes it impossible to spend the\n> > > > input with CTV that commits to such scriptSig, in effect\n> > > > revoking an ability to spend this input via CTV path, and\n> > > > alternate spending paths should be used (like, another taproot\n> > > > branch)\n> > > >\n> > > >\n> > > > \u0412 Fri, 13 Dec 2019 15:06:59 -0800\n> > > > Jeremy via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n> > > > \u043f\u0438\u0448\u0435\u0442:  \n> > > > > I've prepared a draft of the changes noted above (some small\n> > > > > additional modifications on the StandardTemplateHash\n> > > > > described in the BIP), but have not yet updated the main\n> > > > > branches for the BIP to leave time for any further feedback.\n> > > > >\n> > > > > See below:\n> > > > >\n> > > > > BIP:\n> > > > > https://github.com/JeremyRubin/bips/blob/ctv-v2/bip-ctv.mediawiki\n> > > > > Implementation:\n> > > > > https://github.com/JeremyRubin/bitcoin/tree/checktemplateverify-v2\n> > > > >\n> > > > > Thank you for your feedback,\n> > > > >\n> > > > > Jeremy\n> > > > > --\n> > > > > @JeremyRubin <https://twitter.com/JeremyRubin>\n> > > > > <https://twitter.com/JeremyRubin>  \n> > > >\n> > > >  \n> >\n> >"
            },
            {
                "author": "Jeremy",
                "date": "2020-09-03T17:34:15",
                "message_text_only": "CTV does not enable this afaiu because it does not commit to the inputs\n(otherwise there's a hash cycle for predicting the output's TXID.\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Thu, Sep 3, 2020 at 7:39 AM Dmitry Petukhov <dp at simplexum.com> wrote:\n\n> Just had an idea that an an \"inverse timelock\" can be made\n> almost-certainly automatic: a revocation UTXO shall become\n> anyone-can-spend after a timeout, and bear some non-dust amount.\n>\n> Before the timelock expiration, it shall be spendable only along with\n> the covenant-locked 'main' UTXO (via a signature or mutual covenant)\n>\n> This way, after a timeout expires, a multitude of entities will be\n> incentivized to spend this UTXO, because this would be free money for\n> them. It will probably be spend by a miner, as they can always replace\n> the spending transaction with their own and claim the amount.\n>\n> After the revocation UTXO is spent, the covenant path that commits to\n> having it in the inputs will be unspendable, and this would effectively\n> constitute an \"inverse timelock\".\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200903/0ff301bc/attachment.html>"
            },
            {
                "author": "Jeremy",
                "date": "2020-09-03T17:47:35",
                "message_text_only": "It's also not something that's trivial to set up in any scheme because you\nhave to have an ordering around when you set up the tx intended to be the\ninverse lock before you create the tx using it.\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Thu, Sep 3, 2020 at 10:34 AM Jeremy <jlrubin at mit.edu> wrote:\n\n> CTV does not enable this afaiu because it does not commit to the inputs\n> (otherwise there's a hash cycle for predicting the output's TXID.\n>\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n>\n>\n> On Thu, Sep 3, 2020 at 7:39 AM Dmitry Petukhov <dp at simplexum.com> wrote:\n>\n>> Just had an idea that an an \"inverse timelock\" can be made\n>> almost-certainly automatic: a revocation UTXO shall become\n>> anyone-can-spend after a timeout, and bear some non-dust amount.\n>>\n>> Before the timelock expiration, it shall be spendable only along with\n>> the covenant-locked 'main' UTXO (via a signature or mutual covenant)\n>>\n>> This way, after a timeout expires, a multitude of entities will be\n>> incentivized to spend this UTXO, because this would be free money for\n>> them. It will probably be spend by a miner, as they can always replace\n>> the spending transaction with their own and claim the amount.\n>>\n>> After the revocation UTXO is spent, the covenant path that commits to\n>> having it in the inputs will be unspendable, and this would effectively\n>> constitute an \"inverse timelock\".\n>>\n>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200903/4f912173/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP OP_CHECKTEMPLATEVERIFY",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy",
                "Dmitry Petukhov"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 13224
        }
    },
    {
        "title": "[bitcoin-dev] CVE-2018-17145: Bitcoin Inventory Out-of-Memory Denial-of-Service Attack",
        "thread_messages": [
            {
                "author": "Braydon Fuller",
                "date": "2020-09-09T13:28:38",
                "message_text_only": "Hi everyone:\n\nWe would like to share a paper and website for CVE-2018-17145 that was\nfound in mid-2018.\n\nThere was an easily exploitable uncontrolled memory resource consumption\ndenial-of-service vulnerability that existed in the peer-to-peer network\ncode of three implementations of Bitcoin and several alternative chains.\n\nFor more details please see:\nhttps://invdos.net/\n\nFor the paper:\nhttps://invdos.net/paper/CVE-2018-17145.pdf\n\nBest,\nBraydon Fuller"
            }
        ],
        "thread_summary": {
            "title": "CVE-2018-17145: Bitcoin Inventory Out-of-Memory Denial-of-Service Attack",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Braydon Fuller"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 455
        }
    },
    {
        "title": "[bitcoin-dev] Statechain coinswap: assigning blame for failure in a two-stage transfer protocol.",
        "thread_messages": [
            {
                "author": "Tom Trevethan",
                "date": "2020-09-13T22:14:50",
                "message_text_only": "We are designing an off-chain coin-swap protocol that will work with the\nstatechain implementation we are developing (\nhttps://github.com/commerceblock/mercury). The general idea is that coins\ndeposited with a statechain entity (statecoins) can be transacted\npeer-to-peer off-chain in a way that the statechain entity (SCE) is\ntrusted, but the statecoins always remain in the custody of the owners. A\nstatecoin swapping service would enable owners to mix their coins with\nother users, giving the same privacy benefits of on-chain CoinSwap\nprotocols, but by being off-chain statecoin swaps would be much faster and\ncheaper.\n\nThe swapping service (conductor) would not have custody of the statecoins\nat any point. The aim is to have the conductor coordinate the swap amongst\na group of statecoins (i.e. determine the which statecoin should be sent to\nwhich new random owner in the group) without being able to learn the link\nbetween owners and their provided addresses. To do this we will use a blind\nsignature scheme in a similar way to the zerolink protocol.\n\nHere is a high-level description of how this blinding can operate - with\nthe aim that the conductor does learn how the ownership of individual coins\nhas changed.\nFor example, imagine 4 individuals (A,B,C and D) who own equal value\nstatecoins utxo1, utxo2, utxo3 and utxo4 respectively. They want to swap\nownership privately, trusting the conductor/SCE to enforce atomicity. In\nother words, the conductor will randomly assign each statecoin to one of\nthe owners (the mix), but will not be able to gain knowledge of that\nassignment.\n1. A,B,C and D signal their participation by signing the swap_token (which\nhas details of the swap) with the proof-key of their input coin. (A\nstatecoin address is formed of a concatenation of the proof key and backup\naddress).\n2. Each of A,B,C and D then generate a new statecoin address (where they\nwhat to receive the swapped coin), which they blind (encrypt) and sign with\nthe proof key of their input coin: add1, add2, add3 and add4 and send to\nthe conductor.\n3. The conductor authenticates each signature and then signs each payload\n(i.e. the blinded destination addresses) with a blinded signature scheme\nand returns these signatures to A,B,C and D.\n4. Each of A,B,C and D then reconnects over TOR with a new identity.\n5. Each of A,B,C and D then send their unblinded destination address with\nthe conductor signature to the conductor (the conductor now knows that\nthese 4 addresses belong to A,B,C and D, but not which ones map to each\ninput.)\n6. The conductor randomly assigns each address to one of utxo1, utxo2,\nutxo3 and utxo4 (e.g. utxo1:add3, utxo2:add1, utxo3:add4 and utxo4:add2)\nand requests each participant to initiate the transfer to the given\naddress.\n7. Each participant then finalises each transfer - if any transfer fails\n(due to a participant disappearing or acting maliciously) then all\ntransfers are reverted - here atomicity is guaranteed by the SCE.\n\nThe interesting problem we have with this protocol is how to assign blame\nin the case that one or more participants in the swap causes it to fail, so\nthat the corresponding statecoins can be penalized (prevented from\nparticipating in further swaps for some timeout) to make any DoS attack\ncostly. In the case of an on-chain coinjoin, this is easy: whoever didn't\nsign their input is to blame. However, in our statechain system a statecoin\ntransfer is a two stage process (to update the private key shares): the\nsender performs an operation with the SCE (transfer_sender) and then sends\nan encrypted value to the receiver, who then performs the second operation\nwith the SCE (transfer_reciever) which updates the UTXO private key shares\nfor the new owner (\nhttps://github.com/commerceblock/mercury/blob/master/doc/statechains.md for\nmore details). If the second stage fails (i.e. the values used for the key\nupdate protocol are wrong) this could be due to either the sender sending a\nbad/manipulated value to the receiver, or the receiver using bad values in\nthe second operation with the SCE. Essentially, either the sender or the\nreceiver can cause the transfer to fail, and it is not possible to\ndetermine which one is malicious without revealing the encrypted value sent\nbetween the sender and receiver (which must be kept secret from the SCE).\n\nAll this means that if a multi-party coinswap fails, we will know which\nstatecoin was involved in the failure, but we cannot determine whether the\nsender or receiver of that coin caused the failure. One potential solution\nto this is to have each sender generate a zero knowledge proof that the\nencrypted value sent to the receiver is correct/valid (see last section in\nhttps://github.com/commerceblock/mercury/blob/master/doc/swaps.md for more\ndetails) which can be used to assign blame in a failure. This proof could\nbe generated and verified using a zkSNARK/zkSTARK framework, but this is\nnot trivial to implement and would likely add significant computational\nburden to user wallets to generate proofs - so we would like to avoid this\nif possible, and we are trying to come up with a simpler solution.\n\nAny comments on the above are welcome, and happy to provide more details if\nanyone is interested.\n\nCheers,\n\nTom\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200913/22a2f536/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-09-16T01:04:29",
                "message_text_only": "Good morning Tom,\n\n\n> Here is a high-level description of how this blinding can operate - with the aim that the conductor does learn how the ownership of individual coins has changed.\n> For example, imagine 4 individuals (A,B,C and D) who own equal value statecoins utxo1, utxo2, utxo3 and utxo4 respectively. They want to swap ownership privately, trusting the conductor/SCE to enforce atomicity. In other words, the conductor will randomly assign each statecoin to one of the owners (the mix), but will not be able to gain knowledge of that assignment.\n> 1. A,B,C and D signal their participation by signing the swap_token (which has details of the swap) with the proof-key of their input coin. (A statecoin address is formed of a concatenation of the proof key and backup address).\n> 2. Each of A,B,C and D then generate a new statecoin address (where they what to receive the swapped coin), which they blind (encrypt) and sign with the proof key of their input coin: add1, add2, add3 and add4 and send to the conductor.\n> 3. The conductor authenticates each signature and then signs each payload (i.e. the blinded destination addresses) with a blinded signature scheme and returns these signatures to A,B,C and D.\n> 4. Each of A,B,C and D then reconnects over TOR with a new identity.\n> 5. Each of A,B,C and D then send their unblinded destination address with the conductor signature to the conductor (the conductor now knows that these 4 addresses belong to A,B,C and D, but not which ones map to each input.)\n> 6. The conductor randomly assigns each address to one of utxo1, utxo2, utxo3 and utxo4 (e.g. utxo1:add3, utxo2:add1, utxo3:add4 and utxo4:add2) and requests each participant to initiate the transfer to the given address.\n> 7. Each participant then finalises each transfer - if any transfer fails (due to a participant disappearing or acting maliciously) then all transfers are reverted - here atomicity is guaranteed by the SCE.\n\nOkay, I suppose this is much too high-level a view, and I have no idea what you mean by \"statecoin\" exactly.\n\nLet me try to fill in the details and correct me if I am wrong okay?\n\nI imagine that the `add1` etc. are implemented as 2-of-2 between the purported owner and the tr\\*sted signing module.\nThe owner of that address can easily create this knowing only the pubkey of the tr\\*sted signing module.\n\nThe initial `utxo1`... are also in similar 2-of-2s.\n\n(they cannot be unilateral control, since then a participant can broadcast a replacement transaction, even without RBF, almost directly to miners.)\n\nSo when the coordinator talks to Alice, who owns `utxo1` and destination `addr1`, it provides partially-signed transactions of `utxo#:addr#`.\nAlice then checks that its `addr1` is on one of those transactions, with the correct amount, then provides a signature for the `utxo1:addr#` transaction.\n\nHowever, then the coordinator, who happens to be in cahoots with Bob, Charlie, and Dave, simply broadcasts that transaction without soliciting the `utxo#:addr1` transaction.\n\nSo it seems to me that this requires tr\\*st that the coordinator is not going to collude with other participants.\nThis is strictly worse than say Wasabi, where the coordinator colluding with other participants only allows the coordinator to break privacy, not outright steal funds.\n\nIt seems to me that the trust-minimized CoinSwap plan by belcher_ is superior to this, with reduced scope for theft.\nThe plan by belcher_ is potentially compatible with using watchtowers that can be used for both CoinSwap and Lightning as well (if we design it well) with the watchtower potentially not even learning whether it is watching a CoinSwap or a Lightning channel.\n\nThough of course I could be misunderstanding the scheme itself.\nIs my understanding correct?\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Tom Trevethan",
                "date": "2020-09-21T00:54:47",
                "message_text_only": "Hi ZmnSCPxj,\n\nThanks for the reply.\n\n> Okay, I suppose this is much too high-level a view, and I have no idea\nwhat you mean by \"statecoin\" exactly.\n\nSorry, most of the protocol details are in the links, but terminology\nshould be made clearer. A \"statecoin\" is a UTXO that is a 2-of-2 between\nthe owner and SE (the tr*sted signing server) i.e. can be transferred\noff-chain.\n\nAlso, should have been clear that `addr1` is the 'statecoin address' which\nis different from the on-chain address (the shared public key the bitcoin\nis paid to). The on-chain address does not change, whereas\nthe 'statecoin address' changes with each new owner and is used to\nauthenticate owners to the SE and act as proof of ownership on\nthe statechain - it is not related to the onchain address/pubkey and\ncontrolled by the owner only.\n\n> So it seems to me that this requires tr\\*st that the coordinator is not\ngoing to collude with other participants.\n\nThis is correct. The SE also must be trusted to not actively defraud users.\nThe main advantage of this scheme is that assuming the SE can be trusted,\nit is strictly non-custodial.\n\n> This is strictly worse than say Wasabi, where the coordinator colluding\nwith other participants only allows the coordinator to break privacy, not\noutright steal funds.\n> It seems to me that the trust-minimized CoinSwap plan by belcher_ is\nsuperior to this, with reduced scope for theft.\n\nThis is true if the overriding aim is trust minimisation, but not if the\naim is speed and cost while staying non-custodial. Off-chain SE\ntransactions are near instant and orders of magnitude cheaper than\non-chain. Probably best thought of as a non-custodial centralised mixer.\n\nTom\n\nOn Wed, Sep 16, 2020 at 2:04 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Tom,\n>\n>\n> > Here is a high-level description of how this blinding can operate - with\n> the aim that the conductor does learn how the ownership of individual coins\n> has changed.\n> > For example, imagine 4 individuals (A,B,C and D) who own equal value\n> statecoins utxo1, utxo2, utxo3 and utxo4 respectively. They want to swap\n> ownership privately, trusting the conductor/SCE to enforce atomicity. In\n> other words, the conductor will randomly assign each statecoin to one of\n> the owners (the mix), but will not be able to gain knowledge of that\n> assignment.\n> > 1. A,B,C and D signal their participation by signing the swap_token\n> (which has details of the swap) with the proof-key of their input coin. (A\n> statecoin address is formed of a concatenation of the proof key and backup\n> address).\n> > 2. Each of A,B,C and D then generate a new statecoin address (where they\n> what to receive the swapped coin), which they blind (encrypt) and sign with\n> the proof key of their input coin: add1, add2, add3 and add4 and send to\n> the conductor.\n> > 3. The conductor authenticates each signature and then signs each\n> payload (i.e. the blinded destination addresses) with a blinded signature\n> scheme and returns these signatures to A,B,C and D.\n> > 4. Each of A,B,C and D then reconnects over TOR with a new identity.\n> > 5. Each of A,B,C and D then send their unblinded destination address\n> with the conductor signature to the conductor (the conductor now knows that\n> these 4 addresses belong to A,B,C and D, but not which ones map to each\n> input.)\n> > 6. The conductor randomly assigns each address to one of utxo1, utxo2,\n> utxo3 and utxo4 (e.g. utxo1:add3, utxo2:add1, utxo3:add4 and utxo4:add2)\n> and requests each participant to initiate the transfer to the given address.\n> > 7. Each participant then finalises each transfer - if any transfer fails\n> (due to a participant disappearing or acting maliciously) then all\n> transfers are reverted - here atomicity is guaranteed by the SCE.\n>\n> Okay, I suppose this is much too high-level a view, and I have no idea\n> what you mean by \"statecoin\" exactly.\n>\n> Let me try to fill in the details and correct me if I am wrong okay?\n>\n> I imagine that the `add1` etc. are implemented as 2-of-2 between the\n> purported owner and the tr\\*sted signing module.\n> The owner of that address can easily create this knowing only the pubkey\n> of the tr\\*sted signing module.\n>\n> The initial `utxo1`... are also in similar 2-of-2s.\n>\n> (they cannot be unilateral control, since then a participant can broadcast\n> a replacement transaction, even without RBF, almost directly to miners.)\n>\n> So when the coordinator talks to Alice, who owns `utxo1` and destination\n> `addr1`, it provides partially-signed transactions of `utxo#:addr#`.\n> Alice then checks that its `addr1` is on one of those transactions, with\n> the correct amount, then provides a signature for the `utxo1:addr#`\n> transaction.\n>\n> However, then the coordinator, who happens to be in cahoots with Bob,\n> Charlie, and Dave, simply broadcasts that transaction without soliciting\n> the `utxo#:addr1` transaction.\n>\n> So it seems to me that this requires tr\\*st that the coordinator is not\n> going to collude with other participants.\n> This is strictly worse than say Wasabi, where the coordinator colluding\n> with other participants only allows the coordinator to break privacy, not\n> outright steal funds.\n>\n> It seems to me that the trust-minimized CoinSwap plan by belcher_ is\n> superior to this, with reduced scope for theft.\n> The plan by belcher_ is potentially compatible with using watchtowers that\n> can be used for both CoinSwap and Lightning as well (if we design it well)\n> with the watchtower potentially not even learning whether it is watching a\n> CoinSwap or a Lightning channel.\n>\n> Though of course I could be misunderstanding the scheme itself.\n> Is my understanding correct?\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200921/bdccafb6/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-09-21T01:14:29",
                "message_text_only": "Good morning Tom,\n\n> Hi ZmnSCPxj,\n>\n> Thanks for the reply.\u00a0\n>\n> > Okay, I suppose this is much too high-level a view, and I have no idea what you mean by \"statecoin\" exactly.\n>\n> Sorry, most of the protocol details are in the links, but terminology should be made clearer. A\u00a0\"statecoin\" is a UTXO that is a 2-of-2 between the owner and SE (the tr*sted signing server) i.e. can be transferred off-chain.\u00a0\n>\n> Also, should have been clear that `addr1` is the 'statecoin\u00a0address' which is different from the on-chain address (the shared public key the bitcoin is paid to). The on-chain address does not change, whereas the\u00a0'statecoin\u00a0address' changes with each new owner and is used to authenticate owners to the SE and act as proof of ownership on the\u00a0statechain - it is not related to the onchain address/pubkey and controlled by the owner only.\u00a0\n>\n> > So it seems to me that this requires tr\\*st that the coordinator is not going to collude with other participants.\n>\n> This is correct. The SE also must be trusted to not actively defraud users. The main advantage of this scheme is that assuming the SE can be trusted, it is strictly non-custodial.\u00a0\n>\n> > This is strictly worse than say Wasabi, where the coordinator colluding with other participants only allows the coordinator to break privacy, not outright steal funds.\n> > It seems to me that the trust-minimized CoinSwap plan by belcher_ is superior to this, with reduced scope for theft.\n>\n> This is true if the overriding aim is trust minimisation, but not if the aim is speed and cost while staying\u00a0non-custodial. Off-chain SE transactions are near instant and orders of magnitude cheaper than on-chain. Probably best thought of as a non-custodial centralised mixer.\u00a0\n\n\nI think the entire point of non-custodiality ***is*** trust minimization.\n\nThe main objection against custodiality is that someone else can prevent you from spending the coin.\nIf I have to tr\\*st the SE to not steal the funds, is it *really* non-custodial, when after a swap, a corrupted SE can, in collusion with other participants, take control of the coin and prevent me from spending it as I wish?\n\nSo I think touting \"non-custodial\" is relatively pointless if tr\\*st is not minimized.\n\n(I am aware there is an update mechanism, either Decker-Russell-Osuntokun or Decker-Wattenhofer, that is anchored off he onchain transaction output, but anyone who can recover the raw keys for signing the funding transaction output --- such as a previous participant and a corrupt SE --- can very easily bypass the mechanism.)\n\nFor example, in my previous description of [implementing investment aggregation](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-July/018055.html), while I admit you need tr\\*st in the business owners who you are investing in, it does not require tr\\*st in the aggregator, due to the n-of-n, which cannot be reconstructed by the aggregator and all other participants without you.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Tom Trevethan",
                "date": "2020-09-21T21:52:28",
                "message_text_only": "Hi ZmnSCPxj,\n\n> I think the entire point of non-custodiality ***is*** trust minimization.\n\nThere are also legal and regulatory implications. It is much easier for a\nservice to operate without requiring its users to be KYCed if it is\nnon-custodial and funds cannot be frozen/seized.\n\n> The main objection against custodiality is that someone else can prevent\nyou from spending the coin.\n> If I have to tr\\*st the SE to not steal the funds, is it *really*\nnon-custodial, when after a swap, a corrupted SE can, in collusion with\nother participants, take control of the coin and prevent me from spending\nit as I wish?\n\nI would argue that it is non-custodial if the SE performs the protocol as\nspecified (i.e. securely deleting expired key shares). If users do trust\nthat it is doing this, then they don't need to worry about the SE being\nshut down or even hacked - assuming the SE has deleted *old* keys (in the\npast) then there is no way the current owner can have their funds stolen -\nthis is a sort of 'forward security' that makes the protocol much more\nsecure than a fully custodial one which stores the full key(s) at all times\n(and I would argue therefore has higher trust requirements). The SE cannot\ndecide or be compelled to seize any specific coin without conspiring in\nadvance to: 1. Keep the expired key shares and 2. Collude with a previous\nowner of that coin. We have designed a scheme to ensure secure deletion of\nshares using HSMs, and are exploring the possibility of using remote\nattestation to prove key share deletion on the HSM to users.\n\nThese are different properties compared to a federated sidechain, which\nwhile lowering trust requirements with an m-of-n peg, remains custodial (if\nthe m-of-n collude at any point they can steal ALL the money, and if (n -\nm + 1) are shut down/disappear then the money is gone forever). However, in\nthe same way as a federated sidechain, users retain a verifiable proof of\ntheir unique ownership of a coin and must sign a peg-out transaction to\nwithdraw on-chain. The publication of this peg-out transaction is proof\nthat the current owner authenticated the on-chain spend, and so any absence\nof this is a signal that the SE should not be trusted.\n\nCheers,\n\nTom\n\nOn Mon, Sep 21, 2020 at 2:14 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Tom,\n>\n> > Hi ZmnSCPxj,\n> >\n> > Thanks for the reply.\n> >\n> > > Okay, I suppose this is much too high-level a view, and I have no idea\n> what you mean by \"statecoin\" exactly.\n> >\n> > Sorry, most of the protocol details are in the links, but terminology\n> should be made clearer. A \"statecoin\" is a UTXO that is a 2-of-2 between\n> the owner and SE (the tr*sted signing server) i.e. can be transferred\n> off-chain.\n> >\n> > Also, should have been clear that `addr1` is the 'statecoin address'\n> which is different from the on-chain address (the shared public key the\n> bitcoin is paid to). The on-chain address does not change, whereas\n> the 'statecoin address' changes with each new owner and is used to\n> authenticate owners to the SE and act as proof of ownership on\n> the statechain - it is not related to the onchain address/pubkey and\n> controlled by the owner only.\n> >\n> > > So it seems to me that this requires tr\\*st that the coordinator is\n> not going to collude with other participants.\n> >\n> > This is correct. The SE also must be trusted to not actively defraud\n> users. The main advantage of this scheme is that assuming the SE can be\n> trusted, it is strictly non-custodial.\n> >\n> > > This is strictly worse than say Wasabi, where the coordinator\n> colluding with other participants only allows the coordinator to break\n> privacy, not outright steal funds.\n> > > It seems to me that the trust-minimized CoinSwap plan by belcher_ is\n> superior to this, with reduced scope for theft.\n> >\n> > This is true if the overriding aim is trust minimisation, but not if the\n> aim is speed and cost while staying non-custodial. Off-chain SE\n> transactions are near instant and orders of magnitude cheaper than\n> on-chain. Probably best thought of as a non-custodial centralised mixer.\n>\n>\n> I think the entire point of non-custodiality ***is*** trust minimization.\n>\n> The main objection against custodiality is that someone else can prevent\n> you from spending the coin.\n> If I have to tr\\*st the SE to not steal the funds, is it *really*\n> non-custodial, when after a swap, a corrupted SE can, in collusion with\n> other participants, take control of the coin and prevent me from spending\n> it as I wish?\n>\n> So I think touting \"non-custodial\" is relatively pointless if tr\\*st is\n> not minimized.\n>\n> (I am aware there is an update mechanism, either Decker-Russell-Osuntokun\n> or Decker-Wattenhofer, that is anchored off he onchain transaction output,\n> but anyone who can recover the raw keys for signing the funding transaction\n> output --- such as a previous participant and a corrupt SE --- can very\n> easily bypass the mechanism.)\n>\n> For example, in my previous description of [implementing investment\n> aggregation](\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-July/018055.html),\n> while I admit you need tr\\*st in the business owners who you are investing\n> in, it does not require tr\\*st in the aggregator, due to the n-of-n, which\n> cannot be reconstructed by the aggregator and all other participants\n> without you.\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200921/5d3538a2/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-09-22T01:00:43",
                "message_text_only": "Good morning Tom,\n\n> Hi ZmnSCPxj,\n>\n> >\u00a0I think the entire point of non-custodiality ***is*** trust minimization.\n>\n> There are also legal and regulatory implications. It is much easier for a service to operate without requiring its users to be KYCed if it is non-custodial and funds cannot be frozen/seized.\u00a0\n\nComplying with the letter of the law without complying to its spirit seems rather hair-splitting to me.\n\nIdeally, a law regarding any financial mechanisms would judge based on how much control the purported owner has over the actual coin and what risks it would entail for them, and protect citizens against risk of damage to their finances, not focus on whether storage is \"custodial\" or not.\n\nSo I still suggest that, for purposes of technical discussion, we should avoid the term \"custodial\" and instead consider technical risks.\n\n>\n> > The main objection against custodiality is that someone else can prevent you from spending the coin.\n> > If I have to tr\\*st the SE to not steal the funds, is it *really* non-custodial, when after a swap, a corrupted SE can, in collusion with other participants, take control of the coin and prevent me from spending it as I wish?\n>\n> I would argue that it is non-custodial if the SE performs the protocol as specified (i.e. securely deleting expired key shares).\n\nThe SE can run in a virtual environment that monitors deletion events and records them.\nSuch a virtual environment could be set up by a rootkit that has been installed on the SE hardware.\nThus, even if the SE is honest, corruption of the hardware it is running on can allow recovery of old privkeys and violation of the tr\\*st assumption.\n\nCompare this to, for example, TumbleBit or Wasabi.\nIn those cases, even if the service providing the mixing is corrupted by a rootkit on the hardware running the honest service software in a virtual environment and monitoring all its internal state and communications, they cannot lead to loss of funds even with cooperation of previous participants.\nThey can at most be forced into denial-of-service, but not outright theft of coins.\n\nThus, I believe this solution is inferior to these older solutions, at least in terms of financial security.\n\nI admit the new solution is superior blockspace-wise, if you consider multiple mixing rounds.\nHowever, multiple mixing rounds under this solution have increased exposure to the risk of theft noted above, and thus it would be better, risk-wise, to immediately withdraw after every round, and potentially seek other SEs (to reduce risks arising from a particular SE being corrupted), thus obviating the blockspace savings.\n\n\nThe above remain true regardless of what definition of \"custodial\" you have.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Tom Trevethan",
                "date": "2020-09-22T15:32:06",
                "message_text_only": "Hi ZmnSCPxj,\n\n> The SE can run in a virtual environment that monitors deletion events and\nrecords them.\n> Such a virtual environment could be set up by a rootkit that has been\ninstalled on the SE hardware.\n> Thus, even if the SE is honest, corruption of the hardware it is running\non can allow recovery of old privkeys and violation of the tr\\*st\nassumption.\n\nThis is true, but this threat can be mitigated with secured infrastructure\nand the use of hardware security modules/trusted execution environments\nthat enable secure (and potentially attestable) deletion.\n\n> Compare this to, for example, TumbleBit or Wasabi.\n> In those cases, even if the service providing the mixing is corrupted by\na rootkit on the hardware running the honest service software in a virtual\nenvironment and monitoring all its internal state and communications, they\ncannot lead to loss of funds even with cooperation of previous participants.\n>They can at most be forced into denial-of-service, but not outright theft\nof coins.\n\nYes, I agree. But on the other side of the scale is a comparison with\ncentralised mixing services, which remain extremely popular.\n\n> I admit the new solution is superior blockspace-wise, if you consider\nmultiple mixing rounds.\n\nThe aim of the solution is to replicate the UX (in terms of speed) of a\ncompletely centralised mixer (i.e. where the server(s) explicitly holds the\nfull key(s) to the deposits being swapped) but in a way that makes theft\nmore difficult (requiring collusion with previous owners), has an in-built\nmechanism for users to get back their funds if the service is shut\ndown/blown-up, provides users with proof of ownership/theft, and with the\nsame privacy guarantees as the above mentioned trust-minimised protocols.\n\nCheers,\n\nTom\n\nOn Tue, Sep 22, 2020 at 2:00 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Tom,\n>\n> > Hi ZmnSCPxj,\n> >\n> > > I think the entire point of non-custodiality ***is*** trust\n> minimization.\n> >\n> > There are also legal and regulatory implications. It is much easier for\n> a service to operate without requiring its users to be KYCed if it is\n> non-custodial and funds cannot be frozen/seized.\n>\n> Complying with the letter of the law without complying to its spirit seems\n> rather hair-splitting to me.\n>\n> Ideally, a law regarding any financial mechanisms would judge based on how\n> much control the purported owner has over the actual coin and what risks it\n> would entail for them, and protect citizens against risk of damage to their\n> finances, not focus on whether storage is \"custodial\" or not.\n>\n> So I still suggest that, for purposes of technical discussion, we should\n> avoid the term \"custodial\" and instead consider technical risks.\n>\n> >\n> > > The main objection against custodiality is that someone else can\n> prevent you from spending the coin.\n> > > If I have to tr\\*st the SE to not steal the funds, is it *really*\n> non-custodial, when after a swap, a corrupted SE can, in collusion with\n> other participants, take control of the coin and prevent me from spending\n> it as I wish?\n> >\n> > I would argue that it is non-custodial if the SE performs the protocol\n> as specified (i.e. securely deleting expired key shares).\n>\n> The SE can run in a virtual environment that monitors deletion events and\n> records them.\n> Such a virtual environment could be set up by a rootkit that has been\n> installed on the SE hardware.\n> Thus, even if the SE is honest, corruption of the hardware it is running\n> on can allow recovery of old privkeys and violation of the tr\\*st\n> assumption.\n>\n> Compare this to, for example, TumbleBit or Wasabi.\n> In those cases, even if the service providing the mixing is corrupted by a\n> rootkit on the hardware running the honest service software in a virtual\n> environment and monitoring all its internal state and communications, they\n> cannot lead to loss of funds even with cooperation of previous participants.\n> They can at most be forced into denial-of-service, but not outright theft\n> of coins.\n>\n> Thus, I believe this solution is inferior to these older solutions, at\n> least in terms of financial security.\n>\n> I admit the new solution is superior blockspace-wise, if you consider\n> multiple mixing rounds.\n> However, multiple mixing rounds under this solution have increased\n> exposure to the risk of theft noted above, and thus it would be better,\n> risk-wise, to immediately withdraw after every round, and potentially seek\n> other SEs (to reduce risks arising from a particular SE being corrupted),\n> thus obviating the blockspace savings.\n>\n>\n> The above remain true regardless of what definition of \"custodial\" you\n> have.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200922/5c979a42/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-09-24T00:19:48",
                "message_text_only": "Good morning Tom,\n\n> Hi ZmnSCPxj,\n>\n> > The SE can run in a virtual environment that monitors deletion events and records them.\n> > Such a virtual environment could be set up by a rootkit that has been installed on the SE hardware.\n> > Thus, even if the SE is honest, corruption of the hardware it is running on can allow recovery of old privkeys and violation of the tr\\*st assumption.\n>\n> This is true, but this threat can be mitigated with secured infrastructure and the use of hardware security modules/trusted execution environments that enable secure (and potentially attestable) deletion.\u00a0\n>\n> > Compare this to, for example, TumbleBit or Wasabi.\n> > In those cases, even if the service providing the mixing is corrupted by a rootkit on the hardware running the honest service software in a virtual environment and monitoring all its internal state and communications, they cannot lead to loss of funds even with cooperation of previous participants.\n> >They can at most be forced into denial-of-service, but not outright theft of coins.\n>\n> Yes, I agree. But on the other side of the scale is a comparison with centralised mixing services, which remain extremely popular.\u00a0\n>\n> > I admit the new solution is superior blockspace-wise, if you consider multiple mixing rounds.\u00a0\n>\n> The aim of the solution is to replicate the UX (in terms of speed) of a completely centralised mixer (i.e. where the server(s) explicitly holds the full key(s) to the deposits being swapped) but in a way that makes theft more difficult (requiring collusion\u00a0with previous owners), has an in-built mechanism for users to get back their funds if the service is shut down/blown-up, provides users with proof of ownership/theft, and with the same privacy guarantees as the above mentioned trust-minimised protocols.\u00a0\n\nI believe the slowness of TumbleBit and Wasabi have less to do with security than with gathering enough participants to get a reasonable anonymity set.\n\nIf the statechain entity itself does not participate and put up funds that its clients can acquire quickly, than a similar waiting period would be necessary anyway to gather enough participants to make the swapping worthwhile.\nThis would then fail your goal of speed.\n\nIf the statechain entity *does* act as a participant, then a client could acquire a new coin fairly quickly (as the statechain entity would be a \"participant of last resort\" with which it could swap right now), but the \"previous participant\" in that case would be the statechain entity itself, making its ability to outright steal funds absolutely certain, and thus not much better than a mixer that provides \"put money in this address, I will send you money in your address\" service.\n(unless I can do a cut-and-choose on the hardware, i.e. buy multiple instances and reverse-engineer all except a randomly-selected one to check for hardware defects that may allow extraction of privkeys, and then use the hardware that remains, I do not think the security of TEEs/HSMs is at all high.\nAnd the TEE/HSM would be directly possessed by the statechain entity and not me, presumably I as client of the statechain entity cannot audit that, so ---)\n\nIf you are going to have a maker-taker model, where takers spend money to get immediate swaps for the time that makers spend waiting, then I suggest that the SwapMarket plan by Chris Belcher would only require some number of confirmations of various transactions to get superior security, which would be a better tradeoff than what statechains provide.\n\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Karl",
                "date": "2020-09-21T22:18:44",
                "message_text_only": "Coinswap has been a struggling goal for many years now.  Consider that\nbitshares' dexbot just recently lost their funding.\n\nPlease make your projects usable before you announce you are working on\nthem, to keep your work safe from distraction or harm.\n\nOn Sun, Sep 13, 2020, 7:11 PM Tom Trevethan via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> We are designing an off-chain coin-swap protocol that will work with the\n> statechain implementation we are developing (\n> https://github.com/commerceblock/mercury). The general idea is that coins\n> deposited with a statechain entity (statecoins) can be transacted\n> peer-to-peer off-chain in a way that the statechain entity (SCE) is\n> trusted, but the statecoins always remain in the custody of the owners. A\n> statecoin swapping service would enable owners to mix their coins with\n> other users, giving the same privacy benefits of on-chain CoinSwap\n> protocols, but by being off-chain statecoin swaps would be much faster and\n> cheaper.\n>\n> The swapping service (conductor) would not have custody of the statecoins\n> at any point. The aim is to have the conductor coordinate the swap amongst\n> a group of statecoins (i.e. determine the which statecoin should be sent to\n> which new random owner in the group) without being able to learn the link\n> between owners and their provided addresses. To do this we will use a blind\n> signature scheme in a similar way to the zerolink protocol.\n>\n> Here is a high-level description of how this blinding can operate - with\n> the aim that the conductor does learn how the ownership of individual coins\n> has changed.\n> For example, imagine 4 individuals (A,B,C and D) who own equal value\n> statecoins utxo1, utxo2, utxo3 and utxo4 respectively. They want to swap\n> ownership privately, trusting the conductor/SCE to enforce atomicity. In\n> other words, the conductor will randomly assign each statecoin to one of\n> the owners (the mix), but will not be able to gain knowledge of that\n> assignment.\n> 1. A,B,C and D signal their participation by signing the swap_token (which\n> has details of the swap) with the proof-key of their input coin. (A\n> statecoin address is formed of a concatenation of the proof key and backup\n> address).\n> 2. Each of A,B,C and D then generate a new statecoin address (where they\n> what to receive the swapped coin), which they blind (encrypt) and sign with\n> the proof key of their input coin: add1, add2, add3 and add4 and send to\n> the conductor.\n> 3. The conductor authenticates each signature and then signs each payload\n> (i.e. the blinded destination addresses) with a blinded signature scheme\n> and returns these signatures to A,B,C and D.\n> 4. Each of A,B,C and D then reconnects over TOR with a new identity.\n> 5. Each of A,B,C and D then send their unblinded destination address with\n> the conductor signature to the conductor (the conductor now knows that\n> these 4 addresses belong to A,B,C and D, but not which ones map to each\n> input.)\n> 6. The conductor randomly assigns each address to one of utxo1, utxo2,\n> utxo3 and utxo4 (e.g. utxo1:add3, utxo2:add1, utxo3:add4 and utxo4:add2)\n> and requests each participant to initiate the transfer to the given\n> address.\n> 7. Each participant then finalises each transfer - if any transfer fails\n> (due to a participant disappearing or acting maliciously) then all\n> transfers are reverted - here atomicity is guaranteed by the SCE.\n>\n> The interesting problem we have with this protocol is how to assign blame\n> in the case that one or more participants in the swap causes it to fail, so\n> that the corresponding statecoins can be penalized (prevented from\n> participating in further swaps for some timeout) to make any DoS attack\n> costly. In the case of an on-chain coinjoin, this is easy: whoever didn't\n> sign their input is to blame. However, in our statechain system a statecoin\n> transfer is a two stage process (to update the private key shares): the\n> sender performs an operation with the SCE (transfer_sender) and then sends\n> an encrypted value to the receiver, who then performs the second operation\n> with the SCE (transfer_reciever) which updates the UTXO private key shares\n> for the new owner (\n> https://github.com/commerceblock/mercury/blob/master/doc/statechains.md\n> for more details). If the second stage fails (i.e. the values used for the\n> key update protocol are wrong) this could be due to either the sender\n> sending a bad/manipulated value to the receiver, or the receiver using bad\n> values in the second operation with the SCE. Essentially, either the sender\n> or the receiver can cause the transfer to fail, and it is not possible to\n> determine which one is malicious without revealing the encrypted value sent\n> between the sender and receiver (which must be kept secret from the SCE).\n>\n> All this means that if a multi-party coinswap fails, we will know which\n> statecoin was involved in the failure, but we cannot determine whether the\n> sender or receiver of that coin caused the failure. One potential solution\n> to this is to have each sender generate a zero knowledge proof that the\n> encrypted value sent to the receiver is correct/valid (see last section in\n> https://github.com/commerceblock/mercury/blob/master/doc/swaps.md for\n> more details) which can be used to assign blame in a failure. This proof\n> could be generated and verified using a zkSNARK/zkSTARK framework, but this\n> is not trivial to implement and would likely add significant computational\n> burden to user wallets to generate proofs - so we would like to avoid this\n> if possible, and we are trying to come up with a simpler solution.\n>\n> Any comments on the above are welcome, and happy to provide more details\n> if anyone is interested.\n>\n> Cheers,\n>\n> Tom\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200921/f02fefb0/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Statechain coinswap: assigning blame for failure in a two-stage transfer protocol.",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Tom Trevethan",
                "Karl"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 40909
        }
    },
    {
        "title": "[bitcoin-dev] Default Signet, Custom Signets and Resetting Testnet",
        "thread_messages": [
            {
                "author": "Matt Corallo",
                "date": "2020-09-14T02:11:32",
                "message_text_only": "[resent with correct source, sorry Michael, stupid Apple]\n\nYes, a \u201cdefault\u201d signet that regularly reorgs a block or two all the time and is \u201ccompatible\u201d with testnet but a faster \nblock target (eg so that it is trivial to mine but still has PoW) and freshly-seeded genesis would be a massive step-up \nin testing usability across the space.\n\nI don\u2019t have strong feelings about the multisig policy, but probably something that is at least marginally robust (ie \n2-of-N) and allows valid blocks to select the next block\u2019s signers for key rollovers is probably close enough.\n\nThere are various folks with operational experience in the community, so let\u2019s not run stuff on DO/AWS/etc, please.\n\nMatt\n\nOn 8/29/20 6:14 AM, Michael Folkson via bitcoin-dev wrote:\n> Hi all\n> \n> Signet has been announced and discussed previously on the mailing list so I won't repeat what Signet is and its motivation.\n> \n> (For more background we recently had a Socratic Seminar with Kalle Alm and AJ Towns on Signet. Transcript, reading list \n> and video are available.)\n> \n> https://diyhpl.us/wiki/transcripts/london-bitcoin-devs/2020-08-19-socratic-seminar-signet/ \n> <https://diyhpl.us/wiki/transcripts/london-bitcoin-devs/2020-08-19-socratic-seminar-signet/>\n> \n> The first (of multiple) Signet PR 18267 in Bitcoin Core is at an advanced stage\u00a0of review and certainly additional code \n> review and testing of that PR is encouraged.\n> \n> https://github.com/bitcoin/bitcoin/pull/18267 <https://github.com/bitcoin/bitcoin/pull/18267>\n> \n> However there are some meta questions around Signet(s) that are best discussed outside of the Bitcoin Core repo and it \n> would be good to ensure everyone's testing needs are being met. I will put forward my initial thoughts on some of these \n> questions. These thoughts seem to be aligned with Kalle's and AJ's initial views but they have not reviewed this post \n> and they can chime in if they feel I am misrepresenting their perspectives.\n> \n> 1) Should there be one \"default\" Signet that we use for specific purpose(s) or should we \"let a thousand ships sail\"?\n> \n> To be clear there will be multiple custom Signets. Even if we wanted to prevent them we couldn't. But is there an \n> argument for having a \"default\" Signet with a network effect? A Signet that a large proportion of the community is drawn \n> to using with tooling and support? I would say yes. Especially if we see Signet as a staging ground for testing proposed \n> soft fork(s). Otherwise there will be lots of splintered Signet networks all with different combinations of proposed \n> soft forks enabled and no network effect around a particular Signet. I think this would be bewildering for say Taproot \n> testers to have to choose between Person A's Signet with Taproot enabled and Person B's Signet with Taproot enabled. For \n> this to work there would have to be a formal understanding of at what stage a proposed soft fork should be enabled on \n> \"default\" Signet. It would have to be at a sufficiently mature stage (e.g. BIP number allocated, BIP drafted and under \n> review, PR open in Bitcoin Core repo under review etc) but early enough so that it can be tested on Signet well in \n> advance of being considered for activation on mainnet. This does present challenges if soft forks are enabled on Signet \n> and then change/get updated. However there are approaches that AJ in particular is working on to deal with this, one of \n> which I have described below.\n> \n> https://bitcoin.stackexchange.com/questions/98642/can-we-experiment-on-signet-with-multiple-proposed-soft-forks-whilst-maintaining \n> <https://bitcoin.stackexchange.com/questions/98642/can-we-experiment-on-signet-with-multiple-proposed-soft-forks-whilst-maintaining>\n> \n> 2) Assuming there is a \"default\" Signet how many people and who should have keys to sign each new \"default\" Signet \n> block? If one of these keys is lost or stolen should we reset Signet? Should we plan to reset \"default\" Signet at \n> regular intervals anyway (say every two years)?\n> \n> Currently it is a 1-of-2 multisig with Kalle Alm and AJ Towns having keys. It was suggested on IRC that there should be \n> at least one additional key present in the EU/US timezone\u00a0so blocks can continue to be mined during an Asia-Pacific \n> outage. (Kalle and AJ are both in the Asia-Pacific region). Kalle believes we should keep Signet running indefinitely \n> unless we encounter specific problems and personally I think this makes sense.\n> \n> https://github.com/bitcoin/bitcoin/issues/19787#issuecomment-679160691 \n> <https://github.com/bitcoin/bitcoin/issues/19787#issuecomment-679160691>\n> \n> 3) Kalle has also experienced concern from some in the community that testnet will somehow be replaced by Signet. This \n> is not the case. As long as someone out there is mining testnet blocks testnet will continue. However, there is the \n> question of whether testnet needs to be reset. It was last reset in 2012 and there are differing accounts on \n> whether\u00a0this is presenting a problem for users of testnet. Assuming Signet is successful there will be less testing on \n> testnet but what testing use cases will still prefer testnet? It has been argued that testnet should be a large chain to \n> stress test certain IBD, P2P scenarios in which case it may be the case that we don't want to reset testnet. All other \n> testing use cases would not be impacted by the downsides of a large chain as they would gravitate towards Signet regardless.\n> \n> https://bitcoin.stackexchange.com/questions/98579/will-there-be-a-testnet4-or-do-we-not-need-a-testnet-reset-once-we-have-signet/ \n> <https://bitcoin.stackexchange.com/questions/98579/will-there-be-a-testnet4-or-do-we-not-need-a-testnet-reset-once-we-have-signet/>\n> \n> If you have thoughts, feedback, questions it would be great to hear them. Certainly we should seek to make sure \n> everybody's testing needs are being considered.\n> \n> There is a closed issue on the Bitcoin Core repo if you seek to review some of the prior conversation. Ideally though we \n> would have discussion that isn't directly impacting Bitcoin Core here on the mailing list or on IRC rather than in the \n> Bitcoin Core repo.\n> \n> https://github.com/bitcoin/bitcoin/issues/19787 <https://github.com/bitcoin/bitcoin/issues/19787>\n> \n> Thanks\n> Michael\n> \n> -- \n> Michael Folkson\n> Email: michaelfolkson at gmail.com <mailto:michaelfolkson at gmail.com>\n> Keybase: michaelfolkson\n> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            }
        ],
        "thread_summary": {
            "title": "Default Signet, Custom Signets and Resetting Testnet",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Matt Corallo"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 6669
        }
    },
    {
        "title": "[bitcoin-dev] A Replacement for RBF and CPFP: Non-Destructive TXID Dependencies for Fee Sponsoring",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2020-09-19T00:51:39",
                "message_text_only": "Hi Bitcoin Devs,\n\n\nI'd like to share with you a draft proposal for a mechanism to replace\nCPFP and RBF for\nincreasing fees on transactions in the mempool that should be more\nrobust against attacks.\n\nA reference implementation demonstrating these rules is available\n[here](https://github.com/bitcoin/bitcoin/compare/master...JeremyRubin:subsidy-tx)\nfor those who\nprefer to not read specs.\n\nShould the mailing list formatting be bungled, it is also available as\na gist [here](https://gist.github.com/JeremyRubin/92a9fc4c6531817f66c2934282e71fdf).\n\nNon-Destructive TXID Dependencies for Fee Sponsoring\n====================================================\n\nThis BIP proposes a general purpose mechanism for expressing\nnon-destructive (i.e., not requiring\nthe spending of a coin) dependencies on specific transactions being in\nthe same block that can be\nused to sponsor fees of remote transactions.\n\nMotivation\n==========\n\nThe mempool has a variety of protections and guards in place to ensure\nthat miners are economic and\nto protect the network from denial of service.\n\nThe rough surface of these policies has some unintended consequences\nfor second layer protocol\ndevelopers. Applications are either vulnerable to attacks (such as\ntransaction pinning) or must go\nthrough great amounts of careful protocol engineering to guard against\nknown mempool attacks.\n\nThis is insufficient because if new attacks are found, there is\nlimited ability to deploy fixes for\nthem against deployed contract instances (such as open lightning\nchannels). What is required is a\nfully abstracted primitive that requires no special structure from an\nunderlying transaction in\norder to increase fees to confirm the transactions.\n\nConsensus Specification\n=======================\n\nIf a transaction's last output's scripPubKey is of the form OP_VER\nfollowed by n*32 bytes, where\nn>1, it is interpreted as a vector of TXIDs (Sponsor Vector). The\nSponsor Vector TXIDs  must also be\nin the block the transaction is validated in, with no restriction on\norder or on specifying a TXID\nmore than once. This can be accomplished simply with the following patch:\n\n\n```diff\n+\n+    // Extract all required fee dependencies\n+    std::unordered_set<uint256, SaltedTxidHasher> dependencies;\n+\n+    const bool dependencies_enabled = VersionBitsState(pindex->pprev,\nchainparams.GetConsensus(),\nConsensus::DeploymentPos::DEPLOYMENT_TXID_DEPENDENCY,\nversionbitscache) == ThresholdState::ACTIVE;\n+    if (dependencies_enabled) {\n+        for (const auto& tx : block.vtx) {\n+            // dependency output is if the last output of a txn is\nOP_VER followed by a sequence of 32*n\n+            // bytes\n+            // vout.back() must exist because it is checked in CheckBlock\n+            const CScript& dependencies_script = tx->vout.back().scriptPubKey;\n+            // empty scripts are valid, so be sure we have at least one byte\n+            if (dependencies_script.size() && dependencies_script[0]\n== OP_VER) {\n+                const size_t size = dependencies_script.size() - 1;\n+                if (size % 32 == 0 && size > 0) {\n+                    for (auto start = dependencies_script.begin() +1,\nstop = start + 32; start < dependencies_script.end(); start = stop,\nstop += 32) {\n+                        uint256 txid;\n+                        std::copy(start, stop, txid.begin());\n+                        dependencies.emplace(txid);\n+                    }\n+                }\n+                // No rules applied otherwise, open for future upgrades\n+            }\n+        }\n+        if (dependencies.size() > block.vtx.size()) {\n+            return\nstate.Invalid(BlockValidationResult::BLOCK_CONSENSUS,\n\"bad-dependencies-too-many-target-txid\");\n+        }\n+    }\n+\n     for (unsigned int i = 0; i < block.vtx.size(); i++)\n     {\n         const CTransaction &tx = *(block.vtx[i]);\n+        if (!dependencies.empty()) {\n+            dependencies.erase(tx.GetHash());\n+        }\n\n         nInputs += tx.vin.size();\n\n@@ -2190,6 +2308,9 @@ bool CChainState::ConnectBlock(const CBlock&\nblock, BlockValidationState& state,\n         }\n         UpdateCoins(tx, view, i == 0 ? undoDummy :\nblockundo.vtxundo.back(), pindex->nHeight);\n     }\n+    if (!dependencies.empty()) {\n+        return state.Invalid(BlockValidationResult::BLOCK_CONSENSUS,\n\"bad-dependency-missing-target-txid\");\n+    }\n```\n\n### Design Motivation\nThe final output of a transaction is an unambiguous location to attach\nmetadata to a transaction\nsuch that the data is available for transaction validation. This data\ncould be committed to anywhere,\nwith added implementation complexity, or in the case of Taproot\nannexes, incompatibility with\nnon-Taproot addresses (although this is not a concern for sponsoring a\ntransaction that does not use\nTaproot).\n\nA bare scriptPubKey prefixed with OP_VER is defined to be invalid in\nany context, and is trivially\nprovably unspendable and therefore pruneable.\n\nIf there is another convenient place to put the TXID vector, that's fine too.\n\nAs the output type is non-standard, unupgraded nodes will by default\nnot include Transactions\ncontaining them in the mempool, limiting risk of an upgrade via this mechanism.\n\nPolicy Specification\n====================\n\nThe mechanism proposed above is a general specification for\ninter-transaction dependencies.\n\nIn this BIP, we only care to ensure a subset of behavior sufficient to\nreplace CPFP and RBF for fee\nbumping.\n\nThus we restrict the mempool policy such that:\n\n1. No Transaction with a Sponsor Vector may have any child spends; and\n1. No Transaction with a Sponsor Vector may have any unconfirmed parents; and\n1. The Sponsor Vector must have exactly 1 entry; and\n1. The Sponsor Vector's entry must be present in the mempool; and\n1. Every Transaction may have exactly 1 sponsor in the mempool; except\n1. Transactions with a Sponsor Vector may not be sponsored.\n\n\nThe mempool treats ancestors and descendants limits as follows:\n\n1. Sponsors are counted as children transactions for descendants; but\n1. Sponsoring transactions are exempted from any limits saturated at\nthe time of submission.\n\nThis ensures that within a given package, every child transaction may\nhave a sponsor, but that the\nmempool prefers to not accept new true children while there are\nparents that can be cleared.\n\nTo prevent garbage sponsors, we also require that:\n\n1. The Sponsor's feerate must be greater than the Sponsored's ancestor fee rate\n\nWe allow one Sponsor to replace another subject to normal replacement\npolicies, they are treated as\nconflicts.\n\n\n### Design Motivation\n\nThere are a few other ways to use OP_VER sponsors that are not\nincluded. For instance, one could\nmake child chains that are only valid if their parent is in the same\nblock (this is incompatible\nwith CTV, exercise left to reader). These use cases are in a sense\nincidental to the motivation\nof this mechanism, and add a lot of implementation complexity.\n\nWhat is wanted is a minimal mechanism that allows arbitrary\nunconnected third parties to attach\nfees to an arbitrary transaction. The set of rules given tightly\nbounds how much extra work the\nmempool might have to do to account for the new sponsors in the worst\ncase, while providing a \"it\nalways works\" API for end users that is not subject to traditional\nissues around pinning.\n\nEventually, rational miners may wish to permit multiple sponsor\ntargets, or multiple sponsoring\ntransactions, but they are not required for the mechanism to work.\nThis is a benefit of the\nminimality of the consensus rule, it is compatible with future policy\nshould it be implemented.\n\n\n#### Attack Analysis of new Policy\n\nIn the worst case the new policy can lead to a 1/2 reduction in the\nnumber of children allowed\n(e.g., if there are 13 children submitted, then 12 sponsors, the 25\nchild limit will saturate\nbefore) and a 2x increase in the maximum children (e.g., if there are\n25 children submitted, and\nthen each are sponsored). Importantly, even in the latter attack\nscenario, the DoS surface is not\ngreat because the sponsor transactions have no children nor parents.\n\n#### Package Relay/Orphan Pool\n\nFuture policy work might be able to insert sponsors into a special\nsponsor pool with an eviction\npolicy that would enable sponsors to be queried and tracked for\ntransactions that have too low fee\nto enter the mempool in the first place. This is treated as a separate\nconcern, as any strides on\npackage relay generally should be able to support sponsors trivially.\n\nReference Implementation\n========================\nA reference implementation demonstrating these rules is available\n[here](https://github.com/bitcoin/bitcoin/compare/master...JeremyRubin:subsidy-tx).\nThis is a best\neffort implementation, but has not been carefully audited for\ncorrectness and likely diverges from\nthis document in ways that should either be reflected in this document\nor amended in the code.\n\n\nBest,\n\nJeremy\n\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200918/5e8e4a42/attachment.html>"
            },
            {
                "author": "Cory Fields",
                "date": "2020-09-19T01:39:16",
                "message_text_only": "Conceptually this is so simple and explicit it almost seems like an obvious\nprimitive.\n\nGlossing over some of the design/policy decisions...\n\nI wonder what the real-world privacy implications are due to the\ndependencies now being encoded on-chain rather than requiring some effort\nto watch the mempool?\n\nCory\n\nOn Fri, Sep 18, 2020, 20:52 Jeremy via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Bitcoin Devs,\n>\n>\n> I'd like to share with you a draft proposal for a mechanism to replace CPFP and RBF for\n> increasing fees on transactions in the mempool that should be more robust against attacks.\n>\n> A reference implementation demonstrating these rules is available\n> [here](https://github.com/bitcoin/bitcoin/compare/master...JeremyRubin:subsidy-tx) for those who\n> prefer to not read specs.\n>\n> Should the mailing list formatting be bungled, it is also available as a gist [here](https://gist.github.com/JeremyRubin/92a9fc4c6531817f66c2934282e71fdf).\n>\n> Non-Destructive TXID Dependencies for Fee Sponsoring\n> ====================================================\n>\n> This BIP proposes a general purpose mechanism for expressing non-destructive (i.e., not requiring\n> the spending of a coin) dependencies on specific transactions being in the same block that can be\n> used to sponsor fees of remote transactions.\n>\n> Motivation\n> ==========\n>\n> The mempool has a variety of protections and guards in place to ensure that miners are economic and\n> to protect the network from denial of service.\n>\n> The rough surface of these policies has some unintended consequences for second layer protocol\n> developers. Applications are either vulnerable to attacks (such as transaction pinning) or must go\n> through great amounts of careful protocol engineering to guard against known mempool attacks.\n>\n> This is insufficient because if new attacks are found, there is limited ability to deploy fixes for\n> them against deployed contract instances (such as open lightning channels). What is required is a\n> fully abstracted primitive that requires no special structure from an underlying transaction in\n> order to increase fees to confirm the transactions.\n>\n> Consensus Specification\n> =======================\n>\n> If a transaction's last output's scripPubKey is of the form OP_VER followed by n*32 bytes, where\n> n>1, it is interpreted as a vector of TXIDs (Sponsor Vector). The Sponsor Vector TXIDs  must also be\n> in the block the transaction is validated in, with no restriction on order or on specifying a TXID\n> more than once. This can be accomplished simply with the following patch:\n>\n>\n> ```diff\n> +\n> +    // Extract all required fee dependencies\n> +    std::unordered_set<uint256, SaltedTxidHasher> dependencies;\n> +\n> +    const bool dependencies_enabled = VersionBitsState(pindex->pprev, chainparams.GetConsensus(), Consensus::DeploymentPos::DEPLOYMENT_TXID_DEPENDENCY, versionbitscache) == ThresholdState::ACTIVE;\n> +    if (dependencies_enabled) {\n> +        for (const auto& tx : block.vtx) {\n> +            // dependency output is if the last output of a txn is OP_VER followed by a sequence of 32*n\n> +            // bytes\n> +            // vout.back() must exist because it is checked in CheckBlock\n> +            const CScript& dependencies_script = tx->vout.back().scriptPubKey;\n> +            // empty scripts are valid, so be sure we have at least one byte\n> +            if (dependencies_script.size() && dependencies_script[0] == OP_VER) {\n> +                const size_t size = dependencies_script.size() - 1;\n> +                if (size % 32 == 0 && size > 0) {\n> +                    for (auto start = dependencies_script.begin() +1, stop = start + 32; start < dependencies_script.end(); start = stop, stop += 32) {\n> +                        uint256 txid;\n> +                        std::copy(start, stop, txid.begin());\n> +                        dependencies.emplace(txid);\n> +                    }\n> +                }\n> +                // No rules applied otherwise, open for future upgrades\n> +            }\n> +        }\n> +        if (dependencies.size() > block.vtx.size()) {\n> +            return state.Invalid(BlockValidationResult::BLOCK_CONSENSUS, \"bad-dependencies-too-many-target-txid\");\n> +        }\n> +    }\n> +\n>      for (unsigned int i = 0; i < block.vtx.size(); i++)\n>      {\n>          const CTransaction &tx = *(block.vtx[i]);\n> +        if (!dependencies.empty()) {\n> +            dependencies.erase(tx.GetHash());\n> +        }\n>\n>          nInputs += tx.vin.size();\n>\n> @@ -2190,6 +2308,9 @@ bool CChainState::ConnectBlock(const CBlock& block, BlockValidationState& state,\n>          }\n>          UpdateCoins(tx, view, i == 0 ? undoDummy : blockundo.vtxundo.back(), pindex->nHeight);\n>      }\n> +    if (!dependencies.empty()) {\n> +        return state.Invalid(BlockValidationResult::BLOCK_CONSENSUS, \"bad-dependency-missing-target-txid\");\n> +    }\n> ```\n>\n> ### Design Motivation\n> The final output of a transaction is an unambiguous location to attach metadata to a transaction\n> such that the data is available for transaction validation. This data could be committed to anywhere,\n> with added implementation complexity, or in the case of Taproot annexes, incompatibility with\n> non-Taproot addresses (although this is not a concern for sponsoring a transaction that does not use\n> Taproot).\n>\n> A bare scriptPubKey prefixed with OP_VER is defined to be invalid in any context, and is trivially\n> provably unspendable and therefore pruneable.\n>\n> If there is another convenient place to put the TXID vector, that's fine too.\n>\n> As the output type is non-standard, unupgraded nodes will by default not include Transactions\n> containing them in the mempool, limiting risk of an upgrade via this mechanism.\n>\n> Policy Specification\n> ====================\n>\n> The mechanism proposed above is a general specification for inter-transaction dependencies.\n>\n> In this BIP, we only care to ensure a subset of behavior sufficient to replace CPFP and RBF for fee\n> bumping.\n>\n> Thus we restrict the mempool policy such that:\n>\n> 1. No Transaction with a Sponsor Vector may have any child spends; and\n> 1. No Transaction with a Sponsor Vector may have any unconfirmed parents; and\n> 1. The Sponsor Vector must have exactly 1 entry; and\n> 1. The Sponsor Vector's entry must be present in the mempool; and\n> 1. Every Transaction may have exactly 1 sponsor in the mempool; except\n> 1. Transactions with a Sponsor Vector may not be sponsored.\n>\n>\n> The mempool treats ancestors and descendants limits as follows:\n>\n> 1. Sponsors are counted as children transactions for descendants; but\n> 1. Sponsoring transactions are exempted from any limits saturated at the time of submission.\n>\n> This ensures that within a given package, every child transaction may have a sponsor, but that the\n> mempool prefers to not accept new true children while there are parents that can be cleared.\n>\n> To prevent garbage sponsors, we also require that:\n>\n> 1. The Sponsor's feerate must be greater than the Sponsored's ancestor fee rate\n>\n> We allow one Sponsor to replace another subject to normal replacement policies, they are treated as\n> conflicts.\n>\n>\n> ### Design Motivation\n>\n> There are a few other ways to use OP_VER sponsors that are not included. For instance, one could\n> make child chains that are only valid if their parent is in the same block (this is incompatible\n> with CTV, exercise left to reader). These use cases are in a sense incidental to the motivation\n> of this mechanism, and add a lot of implementation complexity.\n>\n> What is wanted is a minimal mechanism that allows arbitrary unconnected third parties to attach\n> fees to an arbitrary transaction. The set of rules given tightly bounds how much extra work the\n> mempool might have to do to account for the new sponsors in the worst case, while providing a \"it\n> always works\" API for end users that is not subject to traditional issues around pinning.\n>\n> Eventually, rational miners may wish to permit multiple sponsor targets, or multiple sponsoring\n> transactions, but they are not required for the mechanism to work. This is a benefit of the\n> minimality of the consensus rule, it is compatible with future policy should it be implemented.\n>\n>\n> #### Attack Analysis of new Policy\n>\n> In the worst case the new policy can lead to a 1/2 reduction in the number of children allowed\n> (e.g., if there are 13 children submitted, then 12 sponsors, the 25 child limit will saturate\n> before) and a 2x increase in the maximum children (e.g., if there are 25 children submitted, and\n> then each are sponsored). Importantly, even in the latter attack scenario, the DoS surface is not\n> great because the sponsor transactions have no children nor parents.\n>\n> #### Package Relay/Orphan Pool\n>\n> Future policy work might be able to insert sponsors into a special sponsor pool with an eviction\n> policy that would enable sponsors to be queried and tracked for transactions that have too low fee\n> to enter the mempool in the first place. This is treated as a separate concern, as any strides on\n> package relay generally should be able to support sponsors trivially.\n>\n> Reference Implementation\n> ========================\n> A reference implementation demonstrating these rules is available\n> [here](https://github.com/bitcoin/bitcoin/compare/master...JeremyRubin:subsidy-tx). This is a best\n> effort implementation, but has not been carefully audited for correctness and likely diverges from\n> this document in ways that should either be reflected in this document or amended in the code.\n>\n>\n> Best,\n>\n> Jeremy\n>\n>\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200918/c7e52557/attachment-0001.html>"
            },
            {
                "author": "Jeremy",
                "date": "2020-09-19T16:16:25",
                "message_text_only": "Hi Cory!\n\nThanks for taking a look. CC nopara as I think your questions are the same.\n\nI think there are a few reason we won't see functionally worse privacy:\n\n1. RBF/CPFP may require the use of an external to the original transaction\nto pay sufficient fee.\n2. RBF/CPFP may leak which address was the change and which was the payment.\n\nIn addition, I think there is a benefit in that:\n\n1. RBF/CPFP requires access to the keys in the same 'security zone' as the\npayment you made (e.g., if it's a multi-sig to multi-sig requires m of N to\ncpfp/or RBF, whereas sponsors could be anyone).\n2. Sponsors can be a fully separate arbitrary wallet.\n3. You can continually coinjoin the funds in your fee-paying wallet without\ntainting your main funds.\n4. You can keep those funds in a lightning channel and pay your fees via\nloop outs.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200919/d5b8bdac/attachment.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2020-09-19T13:37:16",
                "message_text_only": "On Fri, Sep 18, 2020 at 05:51:39PM -0700, Jeremy via bitcoin-dev wrote:\n> I'd like to share with you a draft proposal for a mechanism to replace\n> CPFP and RBF for increasing fees on transactions in the mempool that\n> should be more robust against attacks.\n\nInteresting idea!  This is going to take a while to think about, but I\nhave one immediate question:\n\n> To prevent garbage sponsors, we also require that:\n> \n> 1. The Sponsor's feerate must be greater than the Sponsored's ancestor fee rate\n> \n> We allow one Sponsor to replace another subject to normal replacement\n> policies, they are treated as conflicts.\n\nIs this in the reference implementation?  I don't see it and I'm\nconfused by this text.  I think it could mean either:\n\n1. Sponsor Tx A can be replaced by Sponsor Tx B if A and B have at least\n   one input in common (which is part of the \"normal replacement policies\")\n\n2. A can be replaced by B even if they don't have any inputs in common\n   as long as they do have a Sponsor Vector in common (while otherwise\n   using the \"normal replacement policies\").\n\nIn the first case, I think Mallory can prevent Bob from\nsponsor-fee-bumping (sponsor-bumping?) his transaction by submitting a\nsponsor before he does; since Bob has no control over Mallory's inputs,\nhe can't replace Mallory's sponsor tx.\n\nIn the second case, I think Mallory can use an existing pinning\ntechnique to make it expensive for Bob to fee bump.  The normal\nreplacement policies require a replacement to pay an absolute higher fee\nthan the original transaction, so Mallory can create a 100,000 vbyte\ntransaction with a single-vector sponsor at the end pointing to Bob's\ntransaction.  This sponsor transaction pays the same feerate as Bob's\ntransaction---let's say 50 nBTC/vbyte, so 5 mBTC total fee.  In order\nfor Bob to replace Mallory's sponsor transaction with his own sponsor\ntransaction, Bob needs to pay the incremental relay feerate (10\nnBTC/vbyte) more, so 6 mBTC total ($66 at $11k/BTC).\n\nThanks,\n\n-Dave\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200919/b6c53712/attachment.sig>"
            },
            {
                "author": "nopara73",
                "date": "2020-09-19T15:01:07",
                "message_text_only": "Wouldn't this enable a passive adversary listening the mempool to associate\nunrelated TXO clusters to the same user?\n\nOn Sat, Sep 19, 2020, 15:38 David A. Harding via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Fri, Sep 18, 2020 at 05:51:39PM -0700, Jeremy via bitcoin-dev wrote:\n> > I'd like to share with you a draft proposal for a mechanism to replace\n> > CPFP and RBF for increasing fees on transactions in the mempool that\n> > should be more robust against attacks.\n>\n> Interesting idea!  This is going to take a while to think about, but I\n> have one immediate question:\n>\n> > To prevent garbage sponsors, we also require that:\n> >\n> > 1. The Sponsor's feerate must be greater than the Sponsored's ancestor\n> fee rate\n> >\n> > We allow one Sponsor to replace another subject to normal replacement\n> > policies, they are treated as conflicts.\n>\n> Is this in the reference implementation?  I don't see it and I'm\n> confused by this text.  I think it could mean either:\n>\n> 1. Sponsor Tx A can be replaced by Sponsor Tx B if A and B have at least\n>    one input in common (which is part of the \"normal replacement policies\")\n>\n> 2. A can be replaced by B even if they don't have any inputs in common\n>    as long as they do have a Sponsor Vector in common (while otherwise\n>    using the \"normal replacement policies\").\n>\n> In the first case, I think Mallory can prevent Bob from\n> sponsor-fee-bumping (sponsor-bumping?) his transaction by submitting a\n> sponsor before he does; since Bob has no control over Mallory's inputs,\n> he can't replace Mallory's sponsor tx.\n>\n> In the second case, I think Mallory can use an existing pinning\n> technique to make it expensive for Bob to fee bump.  The normal\n> replacement policies require a replacement to pay an absolute higher fee\n> than the original transaction, so Mallory can create a 100,000 vbyte\n> transaction with a single-vector sponsor at the end pointing to Bob's\n> transaction.  This sponsor transaction pays the same feerate as Bob's\n> transaction---let's say 50 nBTC/vbyte, so 5 mBTC total fee.  In order\n> for Bob to replace Mallory's sponsor transaction with his own sponsor\n> transaction, Bob needs to pay the incremental relay feerate (10\n> nBTC/vbyte) more, so 6 mBTC total ($66 at $11k/BTC).\n>\n> Thanks,\n>\n> -Dave\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200919/ea5778cf/attachment.html>"
            },
            {
                "author": "Jeremy",
                "date": "2020-09-19T16:30:56",
                "message_text_only": "Hi David!\n\nThanks for taking a look, and great question.\n\n> Is this in the reference implementation?\n\nIt is indeed in the reference implementation. Please see\nhttps://github.com/bitcoin/bitcoin/compare/master...JeremyRubin:subsidy-tx#diff-24efdb00bfbe56b140fb006b562cc70bR741-R743\n\nThere is no requirement that there be any input in common, just that the\nsponsor vectors are identical (keep in mind that we limit our sponsor\nvector by policy to 1 element, because, as you rightfully point out,\nmultiple sponsors is more complex to implement).\n\n\n> In the second case, I think Mallory can use an existing pinning\n> technique to make it expensive for Bob to fee bump.  The normal\n> replacement policies require a replacement to pay an absolute higher fee\n> than the original transaction, so Mallory can create a 100,000 vbyte\n> transaction with a single-vector sponsor at the end pointing to Bob's\n> transaction.  This sponsor transaction pays the same feerate as Bob's\n> transaction---let's say 50 nBTC/vbyte, so 5 mBTC total fee.  In order\n> for Bob to replace Mallory's sponsor transaction with his own sponsor\n> transaction, Bob needs to pay the incremental relay feerate (10\n> nBTC/vbyte) more, so 6 mBTC total ($66 at $11k/BTC).\n\nYup, I was aware of this limitation but I'm not sure how practical it is as\nan attack because it's quite expensive for the attacker. But there are a\nfew simple policies that can eliminate it:\n\n1) A Sponsoring TX never needs to be more than, say, 2 inputs and 2\noutputs. Restricting this via policy would help, or more flexibly limiting\nthe total size of a sponsoring paying transaction to 1000 bytes.\n2) Make A Sponsoring TX not need to pay more absolute fee, just needs to\nincrease the feerate (perhaps with a constant relay fee bump to prevent\nspam).\n\nI think 1) is simpler and should allow full use of the sponsor mechanism\nwhile preventing this class of issue mostly.\n\nWhat do you think?\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200919/f57991f4/attachment-0001.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2020-09-19T17:24:17",
                "message_text_only": "On Sat, Sep 19, 2020 at 09:30:56AM -0700, Jeremy wrote:\n> Yup, I was aware of this limitation but I'm not sure how practical it is as\n> an attack because it's quite expensive for the attacker. \n\nIt's cheap if:\n\n1. You were planning to consolidate all those UTXOs at roughly that\n   feerate anyway.\n\n2. After you no longer need your pinning transaction in the mempool, you\n   make an out-of-band arrangement with a pool to mine a small\n   conflicting transaction.\n\n> But there are a few simple policies that can eliminate it:\n> \n> 1) A Sponsoring TX never needs to be more than, say, 2 inputs and 2\n> outputs. Restricting this via policy would help, or more flexibly\n> limiting the total size of a sponsoring transaction to 1000 bytes.\n\nI think that works (as policy).\n\n> 2) Make A Sponsoring TX not need to pay more absolute fee, just needs to\n> increase the feerate (perhaps with a constant relay fee bump to prevent\n> spam).\n\nI think it'd be hard to find a constant relay fee bump amount that was\nhigh enough to prevent abuse but low enough not to unduly hinder\nlegitimate users.\n\n> I think 1) is simpler and should allow full use of the sponsor mechanism\n> while preventing this class of issue mostly.\n\nAgreed.\n\nThanks,\n\n-Dave\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200919/15f5bf2c/attachment.sig>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-09-19T18:39:41",
                "message_text_only": "Hi Jeremy,\n\nThis is a really interesting proposal to widen the scope of fee mechanisms.\n\nFirst, a wider point on what this proposal brings with regards to pinning,\nto the best of my knowledge.\n\nA pinning may have different vectors by exploiting a) mempools limits (e.g\ndescendants) or b) mempools absolute-fee/feerate/conflicts logic. The lack\nof a global mempool means you can creatively combine them to provoke\nmempools-partitions [0]\n\nAs far as I understand this proposal, it aims to solve the class a) of\npinnings by allowing fee-bumping with a new definition of dependencies. I'm\nnot sure it achieves to do  so as the Sponsor Vector TXIDs being committed\nin the Sponsoree signature hash means the Sponsor feerate is part of this\ncommitment and can't be unilaterally adjusted to actual mempool-congestion.\n\nAfter broadcasting the Sponsor/Sponsoree pair, mempools feerate may\nincrease again and thus obsoleting the previous fee-bump. Or you need a\nSponsor Vector for every blockspace feerate, in the worst-case bound by the\nvalue of the Sponsoree funds.\n\nFurther, I would say this proposal won't solve class b) of pinnings for\nmulti-party time-sensitive protocols without further modifications. E.g in\na LN-channel, assuming the commitment transaction is the Sponsoree, Alice\nthe honest party can't increase Sponsor feerate by mal eating its outputs\nwithout breaking the sponsoring dependency. And thus evict a Bob's\nmalicious pin across network mempools.\n\nI think a further softfork proposal with regards to sighash malleability is\nneeded to achieve the security semantic for Lightning type of protocols.\nRoughly, a SIGHASH_IOVECTOR allows N-inputs to commit to N-outputs, thus\ncommitting to all the balance/HTLC outputs minus the last output Vector,\nnon-interactively malleable by channel participants. This would be a form\nof transaction finalization delegation, allowing Alice to direct the\nSponsor vector to a good-feerate adjusted transaction.\n\nNote, I may have misunderstood completely the proposal as the feerate\nobserved might be the Sponsor _package_ one and each party could have a\npair of outputs to spend from to non-interactively increase the Sponsoree.\nThough sounds like re-introducing the limits issues...\n\nThat said, see following review points.\n\n> This is insufficient because if new attacks are found, there is\n> limited ability to deploy fixes for\n> them against deployed contract instances (such as open lightning\n> channels). What is required is a\n> fully abstracted primitive that requires no special structure from an\n> underlying transaction in\n> order to increase fees to confirm the transactions.\n\nThis is really true, in case of vulnerability discovered mass closing of\nthe channel would be in itself a concern as it would congest mempools and\nopen to looter behaviors [1]. Though I don't think a special structure can\nclaim covering every potential source of vulnerability for  off-chain\nprotocols as some of them might be tx-relay based (e.g reject-filters for\nsegwit txn).\n\nFurther, a \"fully abstracted primitive\" is loosely defined, one could argue\nthat anchor outputs don't require special structure from an underlying\ntransaction (i.e on the order of outputs ?).\n\n>  where\nn>1, it is interpreted as a vector of TXIDs (Sponsor Vector).\n\nn >=1 ? I think you can have at least one vector and this is matching the\ncode\n\n> If there is another convenient place to put the TXID vector, that's fine\ntoo.\n\nYou might use the per-input future Taproot annex, and even apply a witness\ndiscount as this mechanism could be argued to be less blockspace expensive\nthan a CPFP for the same semantic.\n\nAn alternative could be a new transaction field like a new `stxid` :\n\n`[nVersion][marker][flag][txins][txouts][witness][nLockTime][nSponsor][nVersion][n*STXID]`\n\nIt would be cheaper as you likely save the output amount size and OP_VER.\nAnd you don't have to subtract a dust output + 1 from the other output\namount to make sure the Sponsor output meets dust propagation requirements.\n\nThough it's more demanding on the tx-relay layer (new serialization and\ntransaction identifier) and new a version bump of the signature digest algo\nto avoid a third-party malleating the per-transaction sponsor field\n\n> To prevent garbage sponsors, we also require that:\n\nDoes the reverse hold ? Garbage Sponsoree by breaking the dependency and\ndouble-spending the utxo spent by the Sponsor and thus decreasing\nSponsoree's feerate to mempool bottom. AFAIK you can't do this with CPFP.\n\n> rational miners may wish to permit multiple sponsor\n> targets, or multiple sponsoring\n> transactions,\n\nI'm not sure if your policy sktech prevents multiple\n1-Sponsor-to-N-Sponsoree. Such a scheme would have some edges. A mempool\nmight receive Sponsoree in different order than evaluated by original\nsender and thus allocate the Sponsor feerate to the less-urgent Sponsoree.\n\n> This is treated as a separate\n> concern, as any strides on\n> package relay generally should be able to support sponsors trivially.\n\nThis is one more reason to carefully version package relay, beyond the\ntransaction package complexity, you now have a new type of graph dependency\nto scope. What we should be worried about is network mempools partitions\nbetween different mechanisms of incompatible package relay if we implement\none.\n\nOverall, a missing point which is making this proposal compelling is the\nfact that you may have one 1-Sponsor-for-N-Sponsoree which is a far reduced\ncost compared to N-Parent-1-CPFP as the CPFP must include an input for each\nbumped parent. Here you only have the Sponsor output. Thus observing\ninput_size > output_size, this proposal is better for multi-transactions\nbumping (but not for N=1 as you have to bear the input spending of the\nSponsor).\n\nAntoine\n\n[0] Within LN-context, for class b) see\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2020-June/002758.html\n\n[1] See the recent Dynamic Commitments proposal to ponder this concern\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2020-July/002763.html\n\nLe ven. 18 sept. 2020 \u00e0 20:52, Jeremy via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n> Hi Bitcoin Devs,\n>\n>\n> I'd like to share with you a draft proposal for a mechanism to replace CPFP and RBF for\n> increasing fees on transactions in the mempool that should be more robust against attacks.\n>\n> A reference implementation demonstrating these rules is available\n> [here](https://github.com/bitcoin/bitcoin/compare/master...JeremyRubin:subsidy-tx) for those who\n> prefer to not read specs.\n>\n> Should the mailing list formatting be bungled, it is also available as a gist [here](https://gist.github.com/JeremyRubin/92a9fc4c6531817f66c2934282e71fdf).\n>\n> Non-Destructive TXID Dependencies for Fee Sponsoring\n> ====================================================\n>\n> This BIP proposes a general purpose mechanism for expressing non-destructive (i.e., not requiring\n> the spending of a coin) dependencies on specific transactions being in the same block that can be\n> used to sponsor fees of remote transactions.\n>\n> Motivation\n> ==========\n>\n> The mempool has a variety of protections and guards in place to ensure that miners are economic and\n> to protect the network from denial of service.\n>\n> The rough surface of these policies has some unintended consequences for second layer protocol\n> developers. Applications are either vulnerable to attacks (such as transaction pinning) or must go\n> through great amounts of careful protocol engineering to guard against known mempool attacks.\n>\n> This is insufficient because if new attacks are found, there is limited ability to deploy fixes for\n> them against deployed contract instances (such as open lightning channels). What is required is a\n> fully abstracted primitive that requires no special structure from an underlying transaction in\n> order to increase fees to confirm the transactions.\n>\n> Consensus Specification\n> =======================\n>\n> If a transaction's last output's scripPubKey is of the form OP_VER followed by n*32 bytes, where\n> n>1, it is interpreted as a vector of TXIDs (Sponsor Vector). The Sponsor Vector TXIDs  must also be\n> in the block the transaction is validated in, with no restriction on order or on specifying a TXID\n> more than once. This can be accomplished simply with the following patch:\n>\n>\n> ```diff\n> +\n> +    // Extract all required fee dependencies\n> +    std::unordered_set<uint256, SaltedTxidHasher> dependencies;\n> +\n> +    const bool dependencies_enabled = VersionBitsState(pindex->pprev, chainparams.GetConsensus(), Consensus::DeploymentPos::DEPLOYMENT_TXID_DEPENDENCY, versionbitscache) == ThresholdState::ACTIVE;\n> +    if (dependencies_enabled) {\n> +        for (const auto& tx : block.vtx) {\n> +            // dependency output is if the last output of a txn is OP_VER followed by a sequence of 32*n\n> +            // bytes\n> +            // vout.back() must exist because it is checked in CheckBlock\n> +            const CScript& dependencies_script = tx->vout.back().scriptPubKey;\n> +            // empty scripts are valid, so be sure we have at least one byte\n> +            if (dependencies_script.size() && dependencies_script[0] == OP_VER) {\n> +                const size_t size = dependencies_script.size() - 1;\n> +                if (size % 32 == 0 && size > 0) {\n> +                    for (auto start = dependencies_script.begin() +1, stop = start + 32; start < dependencies_script.end(); start = stop, stop += 32) {\n> +                        uint256 txid;\n> +                        std::copy(start, stop, txid.begin());\n> +                        dependencies.emplace(txid);\n> +                    }\n> +                }\n> +                // No rules applied otherwise, open for future upgrades\n> +            }\n> +        }\n> +        if (dependencies.size() > block.vtx.size()) {\n> +            return state.Invalid(BlockValidationResult::BLOCK_CONSENSUS, \"bad-dependencies-too-many-target-txid\");\n> +        }\n> +    }\n> +\n>      for (unsigned int i = 0; i < block.vtx.size(); i++)\n>      {\n>          const CTransaction &tx = *(block.vtx[i]);\n> +        if (!dependencies.empty()) {\n> +            dependencies.erase(tx.GetHash());\n> +        }\n>\n>          nInputs += tx.vin.size();\n>\n> @@ -2190,6 +2308,9 @@ bool CChainState::ConnectBlock(const CBlock& block, BlockValidationState& state,\n>          }\n>          UpdateCoins(tx, view, i == 0 ? undoDummy : blockundo.vtxundo.back(), pindex->nHeight);\n>      }\n> +    if (!dependencies.empty()) {\n> +        return state.Invalid(BlockValidationResult::BLOCK_CONSENSUS, \"bad-dependency-missing-target-txid\");\n> +    }\n> ```\n>\n> ### Design Motivation\n> The final output of a transaction is an unambiguous location to attach metadata to a transaction\n> such that the data is available for transaction validation. This data could be committed to anywhere,\n> with added implementation complexity, or in the case of Taproot annexes, incompatibility with\n> non-Taproot addresses (although this is not a concern for sponsoring a transaction that does not use\n> Taproot).\n>\n> A bare scriptPubKey prefixed with OP_VER is defined to be invalid in any context, and is trivially\n> provably unspendable and therefore pruneable.\n>\n> If there is another convenient place to put the TXID vector, that's fine too.\n>\n> As the output type is non-standard, unupgraded nodes will by default not include Transactions\n> containing them in the mempool, limiting risk of an upgrade via this mechanism.\n>\n> Policy Specification\n> ====================\n>\n> The mechanism proposed above is a general specification for inter-transaction dependencies.\n>\n> In this BIP, we only care to ensure a subset of behavior sufficient to replace CPFP and RBF for fee\n> bumping.\n>\n> Thus we restrict the mempool policy such that:\n>\n> 1. No Transaction with a Sponsor Vector may have any child spends; and\n> 1. No Transaction with a Sponsor Vector may have any unconfirmed parents; and\n> 1. The Sponsor Vector must have exactly 1 entry; and\n> 1. The Sponsor Vector's entry must be present in the mempool; and\n> 1. Every Transaction may have exactly 1 sponsor in the mempool; except\n> 1. Transactions with a Sponsor Vector may not be sponsored.\n>\n>\n> The mempool treats ancestors and descendants limits as follows:\n>\n> 1. Sponsors are counted as children transactions for descendants; but\n> 1. Sponsoring transactions are exempted from any limits saturated at the time of submission.\n>\n> This ensures that within a given package, every child transaction may have a sponsor, but that the\n> mempool prefers to not accept new true children while there are parents that can be cleared.\n>\n> To prevent garbage sponsors, we also require that:\n>\n> 1. The Sponsor's feerate must be greater than the Sponsored's ancestor fee rate\n>\n> We allow one Sponsor to replace another subject to normal replacement policies, they are treated as\n> conflicts.\n>\n>\n> ### Design Motivation\n>\n> There are a few other ways to use OP_VER sponsors that are not included. For instance, one could\n> make child chains that are only valid if their parent is in the same block (this is incompatible\n> with CTV, exercise left to reader). These use cases are in a sense incidental to the motivation\n> of this mechanism, and add a lot of implementation complexity.\n>\n> What is wanted is a minimal mechanism that allows arbitrary unconnected third parties to attach\n> fees to an arbitrary transaction. The set of rules given tightly bounds how much extra work the\n> mempool might have to do to account for the new sponsors in the worst case, while providing a \"it\n> always works\" API for end users that is not subject to traditional issues around pinning.\n>\n> Eventually, rational miners may wish to permit multiple sponsor targets, or multiple sponsoring\n> transactions, but they are not required for the mechanism to work. This is a benefit of the\n> minimality of the consensus rule, it is compatible with future policy should it be implemented.\n>\n>\n> #### Attack Analysis of new Policy\n>\n> In the worst case the new policy can lead to a 1/2 reduction in the number of children allowed\n> (e.g., if there are 13 children submitted, then 12 sponsors, the 25 child limit will saturate\n> before) and a 2x increase in the maximum children (e.g., if there are 25 children submitted, and\n> then each are sponsored). Importantly, even in the latter attack scenario, the DoS surface is not\n> great because the sponsor transactions have no children nor parents.\n>\n> #### Package Relay/Orphan Pool\n>\n> Future policy work might be able to insert sponsors into a special sponsor pool with an eviction\n> policy that would enable sponsors to be queried and tracked for transactions that have too low fee\n> to enter the mempool in the first place. This is treated as a separate concern, as any strides on\n> package relay generally should be able to support sponsors trivially.\n>\n> Reference Implementation\n> ========================\n> A reference implementation demonstrating these rules is available\n> [here](https://github.com/bitcoin/bitcoin/compare/master...JeremyRubin:subsidy-tx). This is a best\n> effort implementation, but has not been carefully audited for correctness and likely diverges from\n> this document in ways that should either be reflected in this document or amended in the code.\n>\n>\n> Best,\n>\n> Jeremy\n>\n>\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200919/6e143592/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-09-19T19:13:56",
                "message_text_only": "EDIT: I misunderstood the emplacement of the sponsor vector, please\ndisregard previous review :( Beyond where the convenient place should live,\nwhich is still accurate I think.\n\n> The\n> Sponsor Vector TXIDs  must also be\n> in the block the transaction is validated in, with no restriction on\n> order or on specifying a TXID\n> more than once.\n\n\nLe sam. 19 sept. 2020 \u00e0 14:39, Antoine Riard <antoine.riard at gmail.com> a\n\u00e9crit :\n\n> Hi Jeremy,\n>\n> This is a really interesting proposal to widen the scope of fee\n> mechanisms.\n>\n> First, a wider point on what this proposal brings with regards to pinning,\n> to the best of my knowledge.\n>\n> A pinning may have different vectors by exploiting a) mempools limits (e.g\n> descendants) or b) mempools absolute-fee/feerate/conflicts logic. The lack\n> of a global mempool means you can creatively combine them to provoke\n> mempools-partitions [0]\n>\n> As far as I understand this proposal, it aims to solve the class a) of\n> pinnings by allowing fee-bumping with a new definition of dependencies. I'm\n> not sure it achieves to do  so as the Sponsor Vector TXIDs being committed\n> in the Sponsoree signature hash means the Sponsor feerate is part of this\n> commitment and can't be unilaterally adjusted to actual mempool-congestion.\n>\n> After broadcasting the Sponsor/Sponsoree pair, mempools feerate may\n> increase again and thus obsoleting the previous fee-bump. Or you need a\n> Sponsor Vector for every blockspace feerate, in the worst-case bound by the\n> value of the Sponsoree funds.\n>\n> Further, I would say this proposal won't solve class b) of pinnings for\n> multi-party time-sensitive protocols without further modifications. E.g in\n> a LN-channel, assuming the commitment transaction is the Sponsoree, Alice\n> the honest party can't increase Sponsor feerate by mal eating its outputs\n> without breaking the sponsoring dependency. And thus evict a Bob's\n> malicious pin across network mempools.\n>\n> I think a further softfork proposal with regards to sighash malleability\n> is needed to achieve the security semantic for Lightning type of protocols.\n> Roughly, a SIGHASH_IOVECTOR allows N-inputs to commit to N-outputs, thus\n> committing to all the balance/HTLC outputs minus the last output Vector,\n> non-interactively malleable by channel participants. This would be a form\n> of transaction finalization delegation, allowing Alice to direct the\n> Sponsor vector to a good-feerate adjusted transaction.\n>\n> Note, I may have misunderstood completely the proposal as the feerate\n> observed might be the Sponsor _package_ one and each party could have a\n> pair of outputs to spend from to non-interactively increase the Sponsoree.\n> Though sounds like re-introducing the limits issues...\n>\n> That said, see following review points.\n>\n> > This is insufficient because if new attacks are found, there is\n> > limited ability to deploy fixes for\n> > them against deployed contract instances (such as open lightning\n> > channels). What is required is a\n> > fully abstracted primitive that requires no special structure from an\n> > underlying transaction in\n> > order to increase fees to confirm the transactions.\n>\n> This is really true, in case of vulnerability discovered mass closing of\n> the channel would be in itself a concern as it would congest mempools and\n> open to looter behaviors [1]. Though I don't think a special structure can\n> claim covering every potential source of vulnerability for  off-chain\n> protocols as some of them might be tx-relay based (e.g reject-filters for\n> segwit txn).\n>\n> Further, a \"fully abstracted primitive\" is loosely defined, one could\n> argue that anchor outputs don't require special structure from an\n> underlying transaction (i.e on the order of outputs ?).\n>\n> >  where\n> n>1, it is interpreted as a vector of TXIDs (Sponsor Vector).\n>\n> n >=1 ? I think you can have at least one vector and this is matching the\n> code\n>\n> > If there is another convenient place to put the TXID vector, that's fine\n> too.\n>\n> You might use the per-input future Taproot annex, and even apply a witness\n> discount as this mechanism could be argued to be less blockspace expensive\n> than a CPFP for the same semantic.\n>\n> An alternative could be a new transaction field like a new `stxid` :\n>\n>\n> `[nVersion][marker][flag][txins][txouts][witness][nLockTime][nSponsor][nVersion][n*STXID]`\n>\n> It would be cheaper as you likely save the output amount size and OP_VER.\n> And you don't have to subtract a dust output + 1 from the other output\n> amount to make sure the Sponsor output meets dust propagation requirements.\n>\n> Though it's more demanding on the tx-relay layer (new serialization and\n> transaction identifier) and new a version bump of the signature digest algo\n> to avoid a third-party malleating the per-transaction sponsor field\n>\n> > To prevent garbage sponsors, we also require that:\n>\n> Does the reverse hold ? Garbage Sponsoree by breaking the dependency and\n> double-spending the utxo spent by the Sponsor and thus decreasing\n> Sponsoree's feerate to mempool bottom. AFAIK you can't do this with CPFP.\n>\n> > rational miners may wish to permit multiple sponsor\n> > targets, or multiple sponsoring\n> > transactions,\n>\n> I'm not sure if your policy sktech prevents multiple\n> 1-Sponsor-to-N-Sponsoree. Such a scheme would have some edges. A mempool\n> might receive Sponsoree in different order than evaluated by original\n> sender and thus allocate the Sponsor feerate to the less-urgent Sponsoree.\n>\n> > This is treated as a separate\n> > concern, as any strides on\n> > package relay generally should be able to support sponsors trivially.\n>\n> This is one more reason to carefully version package relay, beyond the\n> transaction package complexity, you now have a new type of graph dependency\n> to scope. What we should be worried about is network mempools partitions\n> between different mechanisms of incompatible package relay if we implement\n> one.\n>\n> Overall, a missing point which is making this proposal compelling is the\n> fact that you may have one 1-Sponsor-for-N-Sponsoree which is a far reduced\n> cost compared to N-Parent-1-CPFP as the CPFP must include an input for each\n> bumped parent. Here you only have the Sponsor output. Thus observing\n> input_size > output_size, this proposal is better for multi-transactions\n> bumping (but not for N=1 as you have to bear the input spending of the\n> Sponsor).\n>\n> Antoine\n>\n> [0] Within LN-context, for class b) see\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-June/002758.html\n>\n> [1] See the recent Dynamic Commitments proposal to ponder this concern\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-July/002763.html\n>\n> Le ven. 18 sept. 2020 \u00e0 20:52, Jeremy via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n>\n>> Hi Bitcoin Devs,\n>>\n>>\n>> I'd like to share with you a draft proposal for a mechanism to replace CPFP and RBF for\n>> increasing fees on transactions in the mempool that should be more robust against attacks.\n>>\n>> A reference implementation demonstrating these rules is available\n>> [here](https://github.com/bitcoin/bitcoin/compare/master...JeremyRubin:subsidy-tx) for those who\n>> prefer to not read specs.\n>>\n>> Should the mailing list formatting be bungled, it is also available as a gist [here](https://gist.github.com/JeremyRubin/92a9fc4c6531817f66c2934282e71fdf).\n>>\n>> Non-Destructive TXID Dependencies for Fee Sponsoring\n>> ====================================================\n>>\n>> This BIP proposes a general purpose mechanism for expressing non-destructive (i.e., not requiring\n>> the spending of a coin) dependencies on specific transactions being in the same block that can be\n>> used to sponsor fees of remote transactions.\n>>\n>> Motivation\n>> ==========\n>>\n>> The mempool has a variety of protections and guards in place to ensure that miners are economic and\n>> to protect the network from denial of service.\n>>\n>> The rough surface of these policies has some unintended consequences for second layer protocol\n>> developers. Applications are either vulnerable to attacks (such as transaction pinning) or must go\n>> through great amounts of careful protocol engineering to guard against known mempool attacks.\n>>\n>> This is insufficient because if new attacks are found, there is limited ability to deploy fixes for\n>> them against deployed contract instances (such as open lightning channels). What is required is a\n>> fully abstracted primitive that requires no special structure from an underlying transaction in\n>> order to increase fees to confirm the transactions.\n>>\n>> Consensus Specification\n>> =======================\n>>\n>> If a transaction's last output's scripPubKey is of the form OP_VER followed by n*32 bytes, where\n>> n>1, it is interpreted as a vector of TXIDs (Sponsor Vector). The Sponsor Vector TXIDs  must also be\n>> in the block the transaction is validated in, with no restriction on order or on specifying a TXID\n>> more than once. This can be accomplished simply with the following patch:\n>>\n>>\n>> ```diff\n>> +\n>> +    // Extract all required fee dependencies\n>> +    std::unordered_set<uint256, SaltedTxidHasher> dependencies;\n>> +\n>> +    const bool dependencies_enabled = VersionBitsState(pindex->pprev, chainparams.GetConsensus(), Consensus::DeploymentPos::DEPLOYMENT_TXID_DEPENDENCY, versionbitscache) == ThresholdState::ACTIVE;\n>> +    if (dependencies_enabled) {\n>> +        for (const auto& tx : block.vtx) {\n>> +            // dependency output is if the last output of a txn is OP_VER followed by a sequence of 32*n\n>> +            // bytes\n>> +            // vout.back() must exist because it is checked in CheckBlock\n>> +            const CScript& dependencies_script = tx->vout.back().scriptPubKey;\n>> +            // empty scripts are valid, so be sure we have at least one byte\n>> +            if (dependencies_script.size() && dependencies_script[0] == OP_VER) {\n>> +                const size_t size = dependencies_script.size() - 1;\n>> +                if (size % 32 == 0 && size > 0) {\n>> +                    for (auto start = dependencies_script.begin() +1, stop = start + 32; start < dependencies_script.end(); start = stop, stop += 32) {\n>> +                        uint256 txid;\n>> +                        std::copy(start, stop, txid.begin());\n>> +                        dependencies.emplace(txid);\n>> +                    }\n>> +                }\n>> +                // No rules applied otherwise, open for future upgrades\n>> +            }\n>> +        }\n>> +        if (dependencies.size() > block.vtx.size()) {\n>> +            return state.Invalid(BlockValidationResult::BLOCK_CONSENSUS, \"bad-dependencies-too-many-target-txid\");\n>> +        }\n>> +    }\n>> +\n>>      for (unsigned int i = 0; i < block.vtx.size(); i++)\n>>      {\n>>          const CTransaction &tx = *(block.vtx[i]);\n>> +        if (!dependencies.empty()) {\n>> +            dependencies.erase(tx.GetHash());\n>> +        }\n>>\n>>          nInputs += tx.vin.size();\n>>\n>> @@ -2190,6 +2308,9 @@ bool CChainState::ConnectBlock(const CBlock& block, BlockValidationState& state,\n>>          }\n>>          UpdateCoins(tx, view, i == 0 ? undoDummy : blockundo.vtxundo.back(), pindex->nHeight);\n>>      }\n>> +    if (!dependencies.empty()) {\n>> +        return state.Invalid(BlockValidationResult::BLOCK_CONSENSUS, \"bad-dependency-missing-target-txid\");\n>> +    }\n>> ```\n>>\n>> ### Design Motivation\n>> The final output of a transaction is an unambiguous location to attach metadata to a transaction\n>> such that the data is available for transaction validation. This data could be committed to anywhere,\n>> with added implementation complexity, or in the case of Taproot annexes, incompatibility with\n>> non-Taproot addresses (although this is not a concern for sponsoring a transaction that does not use\n>> Taproot).\n>>\n>> A bare scriptPubKey prefixed with OP_VER is defined to be invalid in any context, and is trivially\n>> provably unspendable and therefore pruneable.\n>>\n>> If there is another convenient place to put the TXID vector, that's fine too.\n>>\n>> As the output type is non-standard, unupgraded nodes will by default not include Transactions\n>> containing them in the mempool, limiting risk of an upgrade via this mechanism.\n>>\n>> Policy Specification\n>> ====================\n>>\n>> The mechanism proposed above is a general specification for inter-transaction dependencies.\n>>\n>> In this BIP, we only care to ensure a subset of behavior sufficient to replace CPFP and RBF for fee\n>> bumping.\n>>\n>> Thus we restrict the mempool policy such that:\n>>\n>> 1. No Transaction with a Sponsor Vector may have any child spends; and\n>> 1. No Transaction with a Sponsor Vector may have any unconfirmed parents; and\n>> 1. The Sponsor Vector must have exactly 1 entry; and\n>> 1. The Sponsor Vector's entry must be present in the mempool; and\n>> 1. Every Transaction may have exactly 1 sponsor in the mempool; except\n>> 1. Transactions with a Sponsor Vector may not be sponsored.\n>>\n>>\n>> The mempool treats ancestors and descendants limits as follows:\n>>\n>> 1. Sponsors are counted as children transactions for descendants; but\n>> 1. Sponsoring transactions are exempted from any limits saturated at the time of submission.\n>>\n>> This ensures that within a given package, every child transaction may have a sponsor, but that the\n>> mempool prefers to not accept new true children while there are parents that can be cleared.\n>>\n>> To prevent garbage sponsors, we also require that:\n>>\n>> 1. The Sponsor's feerate must be greater than the Sponsored's ancestor fee rate\n>>\n>> We allow one Sponsor to replace another subject to normal replacement policies, they are treated as\n>> conflicts.\n>>\n>>\n>> ### Design Motivation\n>>\n>> There are a few other ways to use OP_VER sponsors that are not included. For instance, one could\n>> make child chains that are only valid if their parent is in the same block (this is incompatible\n>> with CTV, exercise left to reader). These use cases are in a sense incidental to the motivation\n>> of this mechanism, and add a lot of implementation complexity.\n>>\n>> What is wanted is a minimal mechanism that allows arbitrary unconnected third parties to attach\n>> fees to an arbitrary transaction. The set of rules given tightly bounds how much extra work the\n>> mempool might have to do to account for the new sponsors in the worst case, while providing a \"it\n>> always works\" API for end users that is not subject to traditional issues around pinning.\n>>\n>> Eventually, rational miners may wish to permit multiple sponsor targets, or multiple sponsoring\n>> transactions, but they are not required for the mechanism to work. This is a benefit of the\n>> minimality of the consensus rule, it is compatible with future policy should it be implemented.\n>>\n>>\n>> #### Attack Analysis of new Policy\n>>\n>> In the worst case the new policy can lead to a 1/2 reduction in the number of children allowed\n>> (e.g., if there are 13 children submitted, then 12 sponsors, the 25 child limit will saturate\n>> before) and a 2x increase in the maximum children (e.g., if there are 25 children submitted, and\n>> then each are sponsored). Importantly, even in the latter attack scenario, the DoS surface is not\n>> great because the sponsor transactions have no children nor parents.\n>>\n>> #### Package Relay/Orphan Pool\n>>\n>> Future policy work might be able to insert sponsors into a special sponsor pool with an eviction\n>> policy that would enable sponsors to be queried and tracked for transactions that have too low fee\n>> to enter the mempool in the first place. This is treated as a separate concern, as any strides on\n>> package relay generally should be able to support sponsors trivially.\n>>\n>> Reference Implementation\n>> ========================\n>> A reference implementation demonstrating these rules is available\n>> [here](https://github.com/bitcoin/bitcoin/compare/master...JeremyRubin:subsidy-tx). This is a best\n>> effort implementation, but has not been carefully audited for correctness and likely diverges from\n>> this document in ways that should either be reflected in this document or amended in the code.\n>>\n>>\n>> Best,\n>>\n>> Jeremy\n>>\n>>\n>>\n>> --\n>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>> <https://twitter.com/JeremyRubin>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200919/7b4110fb/attachment-0001.html>"
            },
            {
                "author": "Jeremy",
                "date": "2020-09-19T19:46:25",
                "message_text_only": "Antoine,\n\nYes I think you're a bit confused on where the actual sponsor vector is. If\nyou have a transaction chain A->B->C and a sponsor S_A, S_A commits to txid\nA and A is unaware of S.\n\n\nW.r.t your other points, I fully agree that the 1-to-N sponsored case is\nvery compelling. The consensus rules are clear that sponsor commitments are\nnon-rival, so there's no issue with allowing as many sponsors as possible\nand including them in aggregate. E.g., if S_A and S'_A both sponsor A with\nfeerate(S*) > feerate(A), there's no reason not to include all of them in a\nblock. The only issue is denial of service in the mempool. In the future,\nit would definitely be desirable to figure out rules that allow mempools to\ntrack both multiple sponsors and multiple sponsor targets. But in the\ninterest of KISS, the current policy rules are designed to be minimally\ninvasive and maximally functional.\n\nIn terms of location for the sponsor vector, I'm relatively indifferent.\nThe annex is a possible location, but it's a bit odd as we really only need\nto allow one such vector per tx, not one per input, and one per input would\nenable some new use cases (maybe good, maybe bad). Further, being in the\nwitness space would mean that if two parties create a 2 input transaction\nwith a desired sponsor vector they would both need to specify it as you\ncan't sign another input's witness data. I wholeheartedly agree with the\nsentiment though; there could be a more efficient place to put this data,\nbut nothing jumps out to me as both efficient and simple in implementation\n(a new tx-level field sounds like a lot of complexity).\n\n\n> n >=1 ? I think you can have at least one vector and this is matching the\ncode\n\nyes, this has been fixed in the gist (cred to Dmitry Petukhov for pointing\nit out first), but is correct in the code. Thank you for your careful\nreading.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200919/109d1531/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-09-20T23:10:23",
                "message_text_only": "Right, I was off the shot. Thanks for the explanation.\n\nAs you mentioned, if the goal of the sponsor mechanism is to let any party\ndrive a state N's first tx to completion, you still have the issue of\nconcurrent states being pinned and thus non-observable for sponsoring by an\nhonest party.\n\nE.g, Bob can broadcast a thousand of revoked LN states and pin them with\nlow-feerate sponsors such as these malicious packages absolute fee are\nhigher than the honest state N. Alice can't fee-sponsor\nthem as we can assume she hasn't a global view of network mempools. Due to\nthe proposed policy rule \"The Sponsor Vector's entry must be present in the\nmempool\", Alice's sponsors won't propagate. Even amending this rule, we\ncan't assume Alice has a thousand of sponsoring utxos to avoid conflict\nbetween her own broadcast.\n\nOf course, offchain protocols designers can limit a participant's\ncapability to construct a pinning package by constraining its malleability\nand thus to always have a compelling feerate. E.g in Lightning you can bind\nthe size of a commitment transaction by refusing relayed HTLCs and thus\nhave less HTLC outputs. This security increase comes at the price of less\nprotocol flexibility, e.g reducing payments throughput.\n\nFurther, a malicious counterparty can still take advantage of\nmempool-congestion spikes. Even if the pinning package has a compelling\nfeerate, high enough to bounce off a honest broadcast, there is no\nguarantee it stays such. Just after the pinning, congestion can increase\nand bury it for long-enough until a timelock expires.\n\nIf we want to solve the hard cases of pinning, I still think mempool\nacceptance of a whole package only on the merits of feerate is the easiest\nsolution to reason on.\n\nLe sam. 19 sept. 2020 \u00e0 15:46, Jeremy <jlrubin at mit.edu> a \u00e9crit :\n\n> Antoine,\n>\n> Yes I think you're a bit confused on where the actual sponsor vector is.\n> If you have a transaction chain A->B->C and a sponsor S_A, S_A commits to\n> txid A and A is unaware of S.\n>\n>\n> W.r.t your other points, I fully agree that the 1-to-N sponsored case is\n> very compelling. The consensus rules are clear that sponsor commitments are\n> non-rival, so there's no issue with allowing as many sponsors as possible\n> and including them in aggregate. E.g., if S_A and S'_A both sponsor A with\n> feerate(S*) > feerate(A), there's no reason not to include all of them in a\n> block. The only issue is denial of service in the mempool. In the future,\n> it would definitely be desirable to figure out rules that allow mempools to\n> track both multiple sponsors and multiple sponsor targets. But in the\n> interest of KISS, the current policy rules are designed to be minimally\n> invasive and maximally functional.\n>\n> In terms of location for the sponsor vector, I'm relatively indifferent.\n> The annex is a possible location, but it's a bit odd as we really only need\n> to allow one such vector per tx, not one per input, and one per input would\n> enable some new use cases (maybe good, maybe bad). Further, being in the\n> witness space would mean that if two parties create a 2 input transaction\n> with a desired sponsor vector they would both need to specify it as you\n> can't sign another input's witness data. I wholeheartedly agree with the\n> sentiment though; there could be a more efficient place to put this data,\n> but nothing jumps out to me as both efficient and simple in implementation\n> (a new tx-level field sounds like a lot of complexity).\n>\n>\n> > n >=1 ? I think you can have at least one vector and this is matching\n> the code\n>\n> yes, this has been fixed in the gist (cred to Dmitry Petukhov for pointing\n> it out first), but is correct in the code. Thank you for your careful\n> reading.\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200920/d9355f8d/attachment-0001.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2020-09-21T14:52:21",
                "message_text_only": "On Sun, Sep 20, 2020 at 07:10:23PM -0400, Antoine Riard via bitcoin-dev wrote:\n> As you mentioned, if the goal of the sponsor mechanism is to let any party\n> drive a state N's first tx to completion, you still have the issue of\n> concurrent states being pinned and thus non-observable for sponsoring by an\n> honest party.\n> \n> E.g, Bob can broadcast a thousand of revoked LN states and pin them with\n> low-feerate sponsors such as these malicious packages absolute fee are\n> higher than the honest state N. Alice can't fee-sponsor\n> them as we can assume she hasn't a global view of network mempools. Due to\n> the proposed policy rule \"The Sponsor Vector's entry must be present in the\n> mempool\", Alice's sponsors won't propagate. \n\nWould it make sense that, instead of sponsor vectors\npointing to txids, they point to input outpoints?  E.g.:\n\n1. Alice and Bob open a channel with funding transaction 0123...cdef,\n   output 0.\n\n2. After a bunch of state updates, Alice unilaterally broadcasts a\n   commitment transaction, which has a minimal fee.\n\n3. Bob doesn't immediately care whether or not Alice tried to close the\n   channel in the latest state---he just wants the commitment\n   transaction confirmed so that he either gets his money directly or he\n   can send any necessary penalty transactions.  So Bob broadcasts a\n   sponsor transaction with a vector of 0123...cdef:0\n\n4. Miners can include that sponsor transaction in any block that has a\n   transaction with an input of 0123...cdef:0.  Otherwise the sponsor\n   transaction is consensus invalid.\n\n(Note: alternatively, sponsor vectors could point to either txids OR\ninput outpoints.  This complicates the serialization of the vector but\nseems otherwise fine to me.)\n\n> If we want to solve the hard cases of pinning, I still think mempool\n> acceptance of a whole package only on the merits of feerate is the easiest\n> solution to reason on.\n\nI don't think package relay based only on feerate solves RBF transaction\npinning (and maybe also doesn't solve ancestor/dependent limit pinning).\nThough, certainly, package relay has the major advantage over this\nproposal (IMO) in that it doesn't require any consensus changes.\nPackage relay is also very nice for fixing other protocol rough edges\nthat are needed anyway.\n\n-Dave\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200921/b0f831cf/attachment.sig>"
            },
            {
                "author": "Jeremy",
                "date": "2020-09-21T16:27:09",
                "message_text_only": "Responses Inline:\n\nWould it make sense that, instead of sponsor vectors\n> pointing to txids, they point to input outpoints?  E.g.:\n>\n> 1. Alice and Bob open a channel with funding transaction 0123...cdef,\n>    output 0.\n>\n> 2. After a bunch of state updates, Alice unilaterally broadcasts a\n>    commitment transaction, which has a minimal fee.\n>\n> 3. Bob doesn't immediately care whether or not Alice tried to close the\n>    channel in the latest state---he just wants the commitment\n>    transaction confirmed so that he either gets his money directly or he\n>    can send any necessary penalty transactions.  So Bob broadcasts a\n>    sponsor transaction with a vector of 0123...cdef:0\n>\n> 4. Miners can include that sponsor transaction in any block that has a\n>    transaction with an input of 0123...cdef:0.  Otherwise the sponsor\n>    transaction is consensus invalid.\n>\n> (Note: alternatively, sponsor vectors could point to either txids OR\n> input outpoints.  This complicates the serialization of the vector but\n> seems otherwise fine to me.)\n>\n\n*This seems like a fine suggestion and I think addresses Antoine's issue.*\n\n\n*I think there are likely some cases where you do want TXID and not Output\n(e.g., if you *\n\n*are sponsoring a payment to your locktime'd cold storage wallet (no CPFP)\nfrom an untrusted third party (no RBF), they can grift you into paying for\nan unrelated payment). This isn't a concern when the root utxo is multisig\n& you are a participant.*\n\n*The serialization to support both, while slightly more complicated, can be\ndone in a manner that permits future extensibility as well if there are\nother modes people require.*\n\n\n\n>\n> > If we want to solve the hard cases of pinning, I still think mempool\n> > acceptance of a whole package only on the merits of feerate is the\n> easiest\n> > solution to reason on.\n>\n> I don't think package relay based only on feerate solves RBF transaction\n> pinning (and maybe also doesn't solve ancestor/dependent limit pinning).\n> Though, certainly, package relay has the major advantage over this\n> proposal (IMO) in that it doesn't require any consensus changes.\n> Package relay is also very nice for fixing other protocol rough edges\n> that are needed anyway.\n>\n> -Dave\n>\n\n*I think it's important to keep in mind this is not a rival to package\nrelay; I think you also want package relay in addition to this, as they\nsolve different but related problems.*\n\n\n*Where you might be able to simplify package relay with sponsors is by\ndoing a sponsor-only package relay, which is always limited to 2\ntransactions, 1 sponsor, 1 sponsoree. This would not have some of the\nchallenges with arbitrary-package package-relay, and would (at least from a\nux perspective) allow users to successfully get parents with insufficient\nfee into the mempool.*\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200921/8f18e1c5/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-09-21T23:40:44",
                "message_text_only": "I think this is a worthy idea as the funding outpoint of any off-chain\nprotocols is an invariant known by participants. Thus by sponsoring an\noutpoint you're requiring from network mempools to increase the feerate of\nthe package locally known without assuming about the concrete state as any\nof them confirming is moving protocol forward.\n\nThat said, a malicious counterparty can still broadcast a heavy-weighted\ntransaction such as an honest party, devoid of knowledge of this weight,\nwon't attach a sponsor with a fee high enough to timely confirm the\nsponsoree. This counterparty capability is a function of package\nmalleability allowed by the off-chain protocol.\n\nThus an honest party has to overshoot your bump as a default setting. Now\nthis is a new concern as such a mechanism can be used as a fee-burning one\nby your counterparty. I believe we want a fee-burning equilibrium for any\npinning solution, Mallet shouldn't force Alice to overpay in fee more than\nMallet is ready to feerate-bid in network mempools.\n\n> I don't think package relay based only on feerate solves RBF transaction\n> pinning (and maybe also doesn't solve ancestor/dependent limit pinning).\n\nYes I agree with this. There are some really nasty cases of pinning where\nan adversary with knowledge of the tx-relay topology can block your\ncompelling feerate bids (sponsors/package relay/anchor whatever) from\npropagating by leveraging conflicts and RBF logic.\n\nOutbound tx-relay peers rotation which makes the tx-relay topology harder\nto observe could help.\n\nAntoine\n\nLe lun. 21 sept. 2020 \u00e0 12:27, Jeremy <jlrubin at mit.edu> a \u00e9crit :\n\n> Responses Inline:\n>\n> Would it make sense that, instead of sponsor vectors\n>> pointing to txids, they point to input outpoints?  E.g.:\n>>\n>> 1. Alice and Bob open a channel with funding transaction 0123...cdef,\n>>    output 0.\n>>\n>> 2. After a bunch of state updates, Alice unilaterally broadcasts a\n>>    commitment transaction, which has a minimal fee.\n>>\n>> 3. Bob doesn't immediately care whether or not Alice tried to close the\n>>    channel in the latest state---he just wants the commitment\n>>    transaction confirmed so that he either gets his money directly or he\n>>    can send any necessary penalty transactions.  So Bob broadcasts a\n>>    sponsor transaction with a vector of 0123...cdef:0\n>>\n>> 4. Miners can include that sponsor transaction in any block that has a\n>>    transaction with an input of 0123...cdef:0.  Otherwise the sponsor\n>>    transaction is consensus invalid.\n>>\n>> (Note: alternatively, sponsor vectors could point to either txids OR\n>> input outpoints.  This complicates the serialization of the vector but\n>> seems otherwise fine to me.)\n>>\n>\n> *This seems like a fine suggestion and I think addresses Antoine's issue.*\n>\n>\n> *I think there are likely some cases where you do want TXID and not Output\n> (e.g., if you *\n>\n> *are sponsoring a payment to your locktime'd cold storage wallet (no CPFP)\n> from an untrusted third party (no RBF), they can grift you into paying for\n> an unrelated payment). This isn't a concern when the root utxo is multisig\n> & you are a participant.*\n>\n> *The serialization to support both, while slightly more complicated, can\n> be done in a manner that permits future extensibility as well if there are\n> other modes people require.*\n>\n>\n>\n>>\n>> > If we want to solve the hard cases of pinning, I still think mempool\n>> > acceptance of a whole package only on the merits of feerate is the\n>> easiest\n>> > solution to reason on.\n>>\n>> I don't think package relay based only on feerate solves RBF transaction\n>> pinning (and maybe also doesn't solve ancestor/dependent limit pinning).\n>> Though, certainly, package relay has the major advantage over this\n>> proposal (IMO) in that it doesn't require any consensus changes.\n>> Package relay is also very nice for fixing other protocol rough edges\n>> that are needed anyway.\n>>\n>> -Dave\n>>\n>\n> *I think it's important to keep in mind this is not a rival to package\n> relay; I think you also want package relay in addition to this, as they\n> solve different but related problems.*\n>\n>\n> *Where you might be able to simplify package relay with sponsors is by\n> doing a sponsor-only package relay, which is always limited to 2\n> transactions, 1 sponsor, 1 sponsoree. This would not have some of the\n> challenges with arbitrary-package package-relay, and would (at least from a\n> ux perspective) allow users to successfully get parents with insufficient\n> fee into the mempool.*\n>\n>\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200921/f9e25128/attachment-0001.html>"
            },
            {
                "author": "Suhas Daftuar",
                "date": "2020-09-22T18:05:13",
                "message_text_only": "Hi,\n\nI think the topic of how to improve transaction relay policy and fee\nbumping is an important one that needs to be worked on, so I'm glad\nthis is a topic of discussion.  However I am pretty skeptical of this\nconsensus change proposal:\n\nThe Sponsor Vector TXIDs must also be in the block the transaction is\n> validated in, with no restriction on order or on specifying a TXID more\n> than once.\n\n\nThat means that if a transaction is confirmed in a block without its\nsponsor, the sponsor is no longer valid.  This breaks a design principle\nthat has been discussed many times over the years, which is that once a\nvalid transaction is created, it should not become invalid later on unless\nthe inputs are double-spent.  This principle has some logical consequences\nthat we've come to accept, such as transaction chains being valid across\nsmall reorgs in the absence of malicious (double-spend) behavior.\n\nI think that this principle is a useful one and that there should be a high\nbar for doing away with it.  And it seems to me that this proposal doesn't\nclear that bar -- the fee bumping improvement that this proposal aims at is\nreally coming from the policy change, rather than the consensus change. But\nif policy changes are the direction we're going to solve these problems, we\ncould instead just propose new policy rules for the existing types of\ntransaction chaining that we have, rather than couple them to a new\ntransaction type.\n\nMy understanding of the main benefit of this approach is that this allows\n3rd parties to participate in fee bumping.  But that behavior strikes me as\nalso problematic, because it introduces the possibility of 3rd party\ngriefing, to the extent that sponsor transactions in any way limit chains\nof transactions that would be otherwise permitted.  If Alice sends Bob some\ncoins, and Alice and Bob are both honest and cooperating, Mallory shouldn't\nbe able to interfere with their low-feerate transaction by (eg) pinning it\nwith a large transaction that \"sponsors\" it (ie a large transaction that is\njust above the feerate of the parent, which prevents additional child\ntransactions and makes it more expensive to RBF).\n\nThis last issue of pinning could be improved in this proposal by requiring\nthat a sponsor transaction bring the effective feerate of its package up to\nsomething which should be confirmed soon (rather than just being a higher\nfeerate than the tx it is sponsoring).  However, we could also carve out a\npolicy rule just like that today, without any consensus changes needed, to\nhelp with pinning (which is probably a good idea!  I think this would be\nuseful work).  So I don't think that approaches in that direction would be\nunique to this proposal.\n\nWe allow one Sponsor to replace another subject to normal replacement\n> policies, they are treated as conflicts.\n\n\nThis policy rule of allowing sponsor transactions to RBF each other also\nseems problematic; that means that if Alice is paying Bob in a transaction\nthat is also sponsoring some other transaction (perhaps from Alice to\nsomeone else), then Mallory can cause the transaction going to Bob to\nbecome invalid by RBF bumping it and sponsoring the parent transaction\nherself?  Allowing 3rd parties to interfere with transactions between\nothers seems like a complex and undesirable design to introduce.\n\nIn summary: this proposal seems like a CPFP replacement, requiring many\npolicy rules along with a consensus change to be worked out to get right; I\nthink we could achieve largely the same effect by improving the current\npolicy rules to make CPFP work better without a consensus change.  And\nwhile what is unique about this proposal is that it allows for 3rd parties\nto attach themselves to the transaction graph of other parties, I think\nthat is a complex interaction to introduce and has negative side effects as\nwell.\n\n\n\nOn Mon, Sep 21, 2020 at 12:27 PM Jeremy via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Responses Inline:\n>\n> Would it make sense that, instead of sponsor vectors\n>> pointing to txids, they point to input outpoints?  E.g.:\n>>\n>> 1. Alice and Bob open a channel with funding transaction 0123...cdef,\n>>    output 0.\n>>\n>> 2. After a bunch of state updates, Alice unilaterally broadcasts a\n>>    commitment transaction, which has a minimal fee.\n>>\n>> 3. Bob doesn't immediately care whether or not Alice tried to close the\n>>    channel in the latest state---he just wants the commitment\n>>    transaction confirmed so that he either gets his money directly or he\n>>    can send any necessary penalty transactions.  So Bob broadcasts a\n>>    sponsor transaction with a vector of 0123...cdef:0\n>>\n>> 4. Miners can include that sponsor transaction in any block that has a\n>>    transaction with an input of 0123...cdef:0.  Otherwise the sponsor\n>>    transaction is consensus invalid.\n>>\n>> (Note: alternatively, sponsor vectors could point to either txids OR\n>> input outpoints.  This complicates the serialization of the vector but\n>> seems otherwise fine to me.)\n>>\n>\n> *This seems like a fine suggestion and I think addresses Antoine's issue.*\n>\n>\n> *I think there are likely some cases where you do want TXID and not Output\n> (e.g., if you *\n>\n> *are sponsoring a payment to your locktime'd cold storage wallet (no CPFP)\n> from an untrusted third party (no RBF), they can grift you into paying for\n> an unrelated payment). This isn't a concern when the root utxo is multisig\n> & you are a participant.*\n>\n> *The serialization to support both, while slightly more complicated, can\n> be done in a manner that permits future extensibility as well if there are\n> other modes people require.*\n>\n>\n>\n>>\n>> > If we want to solve the hard cases of pinning, I still think mempool\n>> > acceptance of a whole package only on the merits of feerate is the\n>> easiest\n>> > solution to reason on.\n>>\n>> I don't think package relay based only on feerate solves RBF transaction\n>> pinning (and maybe also doesn't solve ancestor/dependent limit pinning).\n>> Though, certainly, package relay has the major advantage over this\n>> proposal (IMO) in that it doesn't require any consensus changes.\n>> Package relay is also very nice for fixing other protocol rough edges\n>> that are needed anyway.\n>>\n>> -Dave\n>>\n>\n> *I think it's important to keep in mind this is not a rival to package\n> relay; I think you also want package relay in addition to this, as they\n> solve different but related problems.*\n>\n>\n> *Where you might be able to simplify package relay with sponsors is by\n> doing a sponsor-only package relay, which is always limited to 2\n> transactions, 1 sponsor, 1 sponsoree. This would not have some of the\n> challenges with arbitrary-package package-relay, and would (at least from a\n> ux perspective) allow users to successfully get parents with insufficient\n> fee into the mempool.*\n>\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200922/56a6fd2c/attachment-0001.html>"
            },
            {
                "author": "Jeremy",
                "date": "2020-09-23T22:10:22",
                "message_text_only": "Hi Suhas,\n\nThanks for your thoughtful response!\n\nOverall I'll boil down my thoughts to the following:\n\nIf we can eventually come up with something clever at the user+policy layer\nto emulate a sponsor like mechanism, I would still greatly prefer to expose\nthat sort of functionality directly and in a fully-abstracted usable way\nfor the minimum amount of mempool attack risk in 2nd layer protocols, even\nat the expense of some base layer complexity. It's better to pay a security\nsensitive engineering cost once, than to have to pay it repeatedly and\nperhaps insufficiently.\n\nSpecific responses inline below:\n\nBest,\n\nJeremy\n\n>> The Sponsor Vector TXIDs must also be in the block the transaction is\nvalidated in, with no restriction on order or on specifying a TXID more\nthan once.\n> That means that if a transaction is confirmed in a block without its\nsponsor, the sponsor is no longer valid.  This breaks a design principle\nthat has been discussed many times over the years, which is that once a\nvalid transaction is created, it should not become invalid later on unless\nthe inputs are double-spent.  This principle has some logical consequences\nthat we've come to accept, such as transaction chains being valid across\nsmall reorgs in the absence of malicious (double-spend) behavior.\n\n*Certainly, this property is strictly broken by this proposal. It does not\nbreak the weaker property that the transactions can be reorged onto another\nchain, however (like OP_GETBLOCKHASH or similar would), which is important\nto note. It's also important to note this property is not preserved against\nreorgs longer than 100 blocks.*\n\n> I think that this principle is a useful one and that there should be a\nhigh bar for doing away with it.  And it seems to me that this proposal\ndoesn't clear that bar -- the fee bumping improvement that this proposal\naims at is really coming from the policy change, rather than the consensus\nchange.\n\n*I think this is possibly correct.*\n\n*IMO the ability to implement the policy changes is purely derived from the\nconsensus changes. The consensus changes add a way of third parties to a\ntransaction to specify economic interest in the resolution of a\ntransaction. This requires a consensus change to work generically and\nwithout forethought.*\n\n\n*It's possible that with specific planning or opt-in, you can make\nsomething roughly equivalent. But such a design might also consume more\nbandwidth on-chain as you would likely have to e.g. always include a CPFP\nhook output.*\n\n\n> But if policy changes are the direction we're going to solve these\nproblems, we could instead just propose new policy rules for the existing\ntypes of transaction chaining that we have, rather than couple them to a\nnew transaction type.\n>\n> My understanding of the main benefit of this approach is that this allows\n3rd parties to participate in fee bumping.  But that behavior strikes me as\nalso problematic, because it introduces the possibility of 3rd party\ngriefing, to the extent that sponsor transactions in any way limit chains\nof transactions that would be otherwise permitted.  If Alice sends Bob some\ncoins, and Alice and Bob are both honest and cooperating, Mallory shouldn't\nbe able to interfere with their low-feerate transaction by (eg) pinning it\nwith a large transaction that \"sponsors\" it (ie a large transaction that is\njust above the feerate of the parent, which prevents additional child\ntransactions and makes it more expensive to RBF).\n\n*It's possible to modify my implementation of the policy such that there is\nno ability to interfere with the otherwise permitted limits, it just\nrequires a little bit more work to always discount sponsors on the\ndescendant counting.*\n\n\n*W.r.t. griefing, the proposed amendment to limit sponsors to 1000 bytes\nminimizes this concern. Further, pinning in this context is mainly an issue\nif Alice and Bob are intending to RBF a transaction, at a policy level we\ncould make Sponsoring require that the transaction be RBF opted-out (or\nsponsor opted in). *\n\n\n> This last issue of pinning could be improved in this proposal by\nrequiring that a sponsor transaction bring the effective feerate of its\npackage up to something which should be confirmed soon (rather than just\nbeing a higher feerate than the tx it is sponsoring).  However, we could\nalso carve out a policy rule just like that today, without any consensus\nchanges needed, to help with pinning (which is probably a good idea!  I\nthink this would be useful work).  So I don't think that approaches in that\ndirection would be unique to this proposal.\n\n*I agree this is useful work and something that Ranked indexes would help\nwith if I understand them correctly, and can be worked on independently of\nSponsors. Overall I am skeptical that we want to accept any child if it\nputs something into an upper percentile as we still need to mind our DoS\nbudgets (which the sponsors implementation keeps a tight bound on). *\n\n\n>> We allow one Sponsor to replace another subject to normal replacement\npolicies, they are treated as conflicts.\n> This policy rule of allowing sponsor transactions to RBF each other also\nseems problematic; that means that if Alice is paying Bob in a transaction\nthat is also sponsoring some other transaction (perhaps from Alice to\nsomeone else), then Mallory can cause the transaction going to Bob to\nbecome invalid by RBF bumping it and sponsoring the parent transaction\nherself?  Allowing 3rd parties to interfere with transactions between\nothers seems like a complex and undesirable design to introduce.\n\n*If you'll note in the BIP draft text and implementation recursive\nsponsoring is not permitted by policy for this reason. Sponsors may not\nsponsor a transaction that is sponsoring another transaction, and a further\nrestriction that sponsors may not have any children.*\n\n\n> In summary: this proposal seems like a CPFP replacement, requiring many\npolicy rules along with a consensus change to be worked out to get right; I\nthink we could achieve largely the same effect by improving the current\npolicy rules to make CPFP work better without a consensus change.  And\nwhile what is unique about this proposal is that it allows for 3rd parties\nto attach themselves to the transaction graph of other parties, I think\nthat is a complex interaction to introduce and has negative side effects as\nwell.\n\n\n*This is where I most significantly disagree. Some thoughts below on why a\nconsensus change is likely required for this and why the sponsors mechanism\nmay not be that invasive (if done right) on the way we currently understand\nthe transaction graph.*\n\n\n*1)*\n*The main issue with CPFP like mechanisms is that they require an\nomniscient like behavior around how to coordinate.*\n\n\n*Given the complexity of CPFP, it's not possible to ever abstract its use\nfrom the contract protocol you are implementing. It always requires deep\nintegration into any protocol as a mechanism, and many bespoke protocols\nfor game theoretically ensuring you can pay fees is much more brittle than\none higher-order composable mechanism (which is what sponsors aims to\nachieve, but may fall short on in current incarnation).*\n\n\n*Further, CPFP based protocols can be wasteful, requiring at least one CPFP\nhook/anchor output per participant always. These CPFP hooks need a mempool\nCPFP exemption (so that you don't get pinned by a sibling), which will have\nto apply recursively in case your payment protocol is not at the base of a\ntransaction chain (as can happen within a multiparty channel factory). Thus\nCPFP as a mechanism inherently suffers from chain bloat issues and it\ncomposes poorly when used recursively.*\n\n\n*I think it will be essentially impossible to generically handle CPFP based\non transaction graph anchors both from a protocol implementers side and\nfrom a mempool policy side. And in the event that a new attack is\ndiscovered, a mechanism that works with fewer assumptions about the setup\nof your protocol should be more robust, or at least fixable. Whereas with a\npure CPFP transaction graph based design, once you are pinned, it may be\nimpossible to externally correct the incentives. *\n\n\n\n\n*2)*\n*Third parties can already -- trustfully -- insert themselves into\nanother's transaction chain by bribing mining pools to escalate priority of\na transaction. These out-of-band fees are somewhat inevitable, so if your\nprotocol is not robust against 3rd party feerate boosting you may have\nlarger issues.*\n\n*3)*\n*Because we already do not handle 100 block reorgs with the replayability\nproperty, one fine change to the BIP would be to enforce a 100 block\nmaturing period on sponsor transactions outputs after confirmation. This\nmight make usage a little bit more unwieldy, but then it would not have the\nissue on small reorg validity.* *I believe this could be safely done* *only\nvia policy and not consensus, as if someone wants to double spend a\ntransaction in a reorg they can, but it's fine either way.*\n\n*4)*\n\n*It's not particularly important that a transaction be in the same block\nonce sponsored, it could also be in the last 100 blocks (the opposite of\nproposed change 3). The main benefit to having same-block resolution is\nthat you never pay for something that would have gone in anyways, but this\nmechanism could actually be generically useful if you are operating a\nbusiness and need to make reorg safe payments contingent on funds received\ninto cold-storage. This implies a new rolling index of txids, which has\nsome overhead, but combined with appropriate mempool policy (e.g., a 200\nblock txid index in consensus and only a 100 block index available by\nmempool policy) would ensure that most reorgs could be handled cleanly.*\n\n\n*5)*\n*The behavior of sponsors is already emulable in a transaction graph. A\nmore complicated construction is possible that's a more accurate emulation,\nbut a simple version is as follows:*\n\n\n*if you were to require:*\n\n*A) All non-sponsor transactions include a single CPFP anchor output/CPFP\nhook with an OP_TRUE as the last output*\n\n*B) Miners sweep all OP_TRUE outputs at the end of the block to an\nOP_RETURN.*\n\n\n*Then it would be possible for third parties to be a sponsor by spending\nthat OP_TRUE output.*\n\n*With a couple modifications (happy to discuss off-list, they end up being\naggregately more complicated than the sponsors mechanism) this can also\npermit multiple sponsors in the same block.*\n\n*Because it's possible to convert sponsors mechanism into this transaction\ngraph (and back again), I don't see a sponsors mechanism as breaking any\nstrong inherent property of the transaction graph, it's merely an\noptimization of a pattern that could be implemented without breaking the\nproperty.*\n\n*Therefore I am unconcerned with the impact that a sponsors-like mechanism\nhas on the properties of the transaction graph itself.*\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200923/0546c978/attachment-0001.html>"
            },
            {
                "author": "Dmitry Petukhov",
                "date": "2020-09-24T04:22:56",
                "message_text_only": "\u0412 Wed, 23 Sep 2020 15:10:22 -0700\nJeremy via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> It's not particularly important that a transaction be in the same\n> block once sponsored, it could also be in the last 100 blocks (the\n> opposite of proposed change 3).\n\nThis will in effect enable \"inverse timelock\" mechanism for up to 100\nblocks for sponsor transactions: broadcast a transaction A, and\nthen make a pre-signed sponsor transaction B that sponsors A.\n\nTransaction B will become invalid after 100 blocks due to this rule.\n\nIf you put a timelock on B to make it valid after 50 blocks,\nthen it will be valid between block 50 and 100 after A is confirmed."
            },
            {
                "author": "ArmchairCryptologist",
                "date": "2020-09-22T06:24:40",
                "message_text_only": "Not sure if I'm missing something, but I'm curious if (how) this will work if the sponsored transaction's feerate is so low that it has been largely evicted from mempools due to fee pressure, and is too low to be widely accepted when re-broadcast? It seems to me that the following requirement\n\n>1. The Sponsor Vector's entry must be present in the mempool\n\nmeans that you enter a catch-22 where the sponsor transaction cannot be broadcast because the sponsored transaction is not in the mempool, and the sponsored transaction cannot be (re-)broadcast because the fee is too low. This requirement might therefore need to be revised.\n\nThere is of course no global mempool, but RBF by its nature would still work in this case, by replacing the transaction if it exists and inserting it if it does not.\n\n--AC\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200922/789c3ab8/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-09-22T13:52:55",
                "message_text_only": "Hello AC,\n\nYes that's a real issue. In the context of multi-party protocols, you may\npre-signed transactions with the feerate of _today_ and then only going to\nbe broadcast later with a feerate of _tomorrow_.\nIn that case the pre-signed feerate may be so low that the transaction\nwon't even propagate across network mempools with a local minimal feerate\nhigher.\n\nThat's why you want to be sure that the feerate of your  package of\ntransactions (either sponsor+sponsoree or parent+CPFP) is going to be\nevaluated as a whole to decide acceptance of each element of the package.\n\nAntoine\n\n\nLe mar. 22 sept. 2020 \u00e0 03:28, ArmchairCryptologist via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n> Not sure if I'm missing something, but I'm curious if (how) this will work\n> if the sponsored transaction's feerate is so low that it has been largely\n> evicted from mempools due to fee pressure, and is too low to be widely\n> accepted when re-broadcast? It seems to me that the following requirement\n>\n> >1. The Sponsor Vector's entry must be present in the mempool\n>\n> means that you enter a catch-22 where the sponsor transaction cannot be\n> broadcast because the sponsored transaction is not in the mempool, and the\n> sponsored transaction cannot be (re-)broadcast because the fee is too low.\n> This requirement might therefore need to be revised.\n>\n> There is of course no global mempool, but RBF by its nature would still\n> work in this case, by replacing the transaction if it exists and inserting\n> it if it does not.\n>\n> --AC\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200922/4705ef4b/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "A Replacement for RBF and CPFP: Non-Destructive TXID Dependencies for Fee Sponsoring",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy",
                "Antoine Riard",
                "David A. Harding",
                "Suhas Daftuar",
                "ArmchairCryptologist",
                "Dmitry Petukhov",
                "nopara73",
                "Cory Fields"
            ],
            "messages_count": 19,
            "total_messages_chars_count": 99286
        }
    },
    {
        "title": "[bitcoin-dev] Taproot (and graftroot) complexity",
        "thread_messages": [
            {
                "author": "Jay Berg",
                "date": "2020-09-19T08:46:12",
                "message_text_only": "> At the time you create a utxo, provided you don't reuse keys, all taproot\n> spends are indistinguishable. At the time you spend a taproot utxo,\n\ndoes reusing keys act differently in taproot than with Pay-to-PubKey-Hash? Or is it the same deal.. same pubkey creates same address?\n\nQuestion: does the security/privacy implications change when reusing pubkeys with taproot?\n\nty\njay\n\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200919/ef372454/attachment.html>"
            },
            {
                "author": "Jay Berg",
                "date": "2020-09-19T07:13:40",
                "message_text_only": "> At the time you create a utxo, provided you don't reuse keys, all taproot\n> spends are indistinguishable. At the time you spend a taproot utxo,\n\ndoes reusing keys act differently in taproot than with Pay-to-PubKey-Hash? Or is it the same deal.. same pubkey creates same address? \n\nQuestion is: is the security/privacy implications worse when reusing pubkeys with taproot? \n\nty\njay"
            },
            {
                "author": "Jay Berg",
                "date": "2020-09-19T12:52:51",
                "message_text_only": "Newb here..  don\u2019t know if \"in-reply-to\" header is misbehaving. \n\nBut this is the OP thread:  \n\n[bitcoin-dev] Taproot (and graftroot) complexity\nAnthony Towns aj at erisian.com.au\nMon Feb 10 00:20:11 UTC 2020\n\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-February/017622.html\n\n<a href=\"mailto:bitcoin-dev%40lists.linuxfoundation.org?Subject=Re:%20Re%3A%20%5Bbitcoin-dev%5D%20Taproot%20%28and%20graftroot%29%20complexity&In-Reply-To=%3C20200210002011.lelhcdmjejmoh6xv%40erisian.com.au%3E\" title=\"[bitcoin-dev] Taproot (and graftroot) complexity\">aj at erisian.com.au\n </a>\n\n\ufeffOn 9/19/20, 5:35 AM, \"bitcoin-dev on behalf of Jay Berg via bitcoin-dev\" <bitcoin-dev-bounces at lists.linuxfoundation.org on behalf of bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n    \n    > At the time you create a utxo, provided you don't reuse keys, all taproot\n    > spends are indistinguishable. At the time you spend a taproot utxo,\n    \n    does reusing keys act differently in taproot than with Pay-to-PubKey-Hash? Or is it the same deal.. same pubkey creates same address? \n    \n    Question is: is the security/privacy implications worse when reusing pubkeys with taproot? \n    \n    ty\n    jay  \n    \n    _______________________________________________\n    bitcoin-dev mailing list\n    bitcoin-dev at lists.linuxfoundation.org\n    https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Lloyd Fournier",
                "date": "2020-09-20T03:23:28",
                "message_text_only": "Hi Jay,\n\nI don't think there's much of a difference in security or privacy.\nThe advice to avoid key-reuse remains the same and for the same reasons.\n\nLL\n\n\nOn Sat, Sep 19, 2020 at 11:08 PM Jay Berg via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Newb here..  don\u2019t know if \"in-reply-to\" header is misbehaving.\n>\n> But this is the OP thread:\n>\n> [bitcoin-dev] Taproot (and graftroot) complexity\n> Anthony Towns aj at erisian.com.au\n> Mon Feb 10 00:20:11 UTC 2020\n>\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-February/017622.html\n>\n> <a href=\"mailto:bitcoin-dev%40lists.linuxfoundation.org?Subject=Re:%20Re%3A%20%5Bbitcoin-dev%5D%20Taproot%20%28and%20graftroot%29%20complexity&In-Reply-To=%3C20200210002011.lelhcdmjejmoh6xv%40erisian.com.au%3E\" title=\"[bitcoin-dev] Taproot (and graftroot) complexity\">aj at erisian.com.au\n>  </a>\n>\n> \ufeffOn 9/19/20, 5:35 AM, \"bitcoin-dev on behalf of Jay Berg via bitcoin-dev\" <bitcoin-dev-bounces at lists.linuxfoundation.org on behalf of bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>\n>     > At the time you create a utxo, provided you don't reuse keys, all taproot\n>     > spends are indistinguishable. At the time you spend a taproot utxo,\n>\n>     does reusing keys act differently in taproot than with Pay-to-PubKey-Hash? Or is it the same deal.. same pubkey creates same address?\n>\n>     Question is: is the security/privacy implications worse when reusing pubkeys with taproot?\n>\n>     ty\n>     jay\n>\n>     _______________________________________________\n>     bitcoin-dev mailing list\n>     bitcoin-dev at lists.linuxfoundation.org\n>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            }
        ],
        "thread_summary": {
            "title": "Taproot (and graftroot) complexity",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Lloyd Fournier",
                "Jay Berg"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 4222
        }
    },
    {
        "title": "[bitcoin-dev] Suggestion: Solve year 2106 problem by taking timestamps mod 2^32",
        "thread_messages": [
            {
                "author": "yanmaani at cock.li",
                "date": "2020-09-19T12:36:47",
                "message_text_only": "Currently, Bitcoin's timestamp rules are as follows:\n\n1. The block timestamp may not be lower than the median of the last 11 \nblocks'\n2. The block timestamp may not be greater than the current time plus two \nhours\n3. The block timestamp may not be greater than 2^32 (Sun, 07 Feb 2106 \n06:28:16 +0000)\n\nThus, Bitcoin will \"die\" on or about 2106-02-07, when there is no \ntimestamp below 2^32 that exceeds the median of the last 11 blocks.\n\nIf the rules were changed to the following, this problem would be \nsolved:\n\n1. The block timestamp plus k*2^32 may not be lower than the median of \nthe last 11 blocks'\n2. The block timestamp plus k*2^32 may not be greater than the current \ntime plus two hours\n3. k is an integer, whose value must be the same for the calculations of \nRule 1 and Rule 2\n\nThis would cause a hardfork in the year 2106, which is approximately \n85.5 years from now, by which time 95% of nodes would hopefully have \nupdated.\n\nAnother proposed solution is 64-bit timestamps. They would break \ncompatibility with other software that has specific expectations of \nheader fields, like ASICs' firmware. They would also cause a hardfork \nbefore the date of timestamp overflow. I thus believe them to be a less \nappropriate solution.\n\nWhat do you think of this idea? Is it worth a BIP?"
            }
        ],
        "thread_summary": {
            "title": "Suggestion: Solve year 2106 problem by taking timestamps mod 2^32",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "yanmaani at cock.li"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1293
        }
    },
    {
        "title": "[bitcoin-dev] Floating-Point Nakamoto Consensus",
        "thread_messages": [
            {
                "author": "Mike Brooks",
                "date": "2020-09-24T19:40:46",
                "message_text_only": "Hey Everyone,\n\n A lot of work has gone into this paper, and the current revision has been\nwell received and there is a lot of excitement on this side to be sharing\nit with you today. There are so few people that truly understand this\ntopic, but we are all pulling in the same direction to make Bitcoin better\nand it shows.  It is wildly underrated that future proofing was never\nreally a consideration in the initial design - but here we are a decade\nlater with amazing solutions like SegWit which gives us a real\nfuture-proofing framework.  The fact that future-proofing was added to\nBitcoin with a softfork gives me goosebumps. I'd just like to take the time\nto thank the people who worked on SegWit and it is an appreciation that\ncomes up in conversation of how difficult and necessary that process\nwas, and this appreciation may not be vocalized to the great people who\nworked on it. The fact that Bitcoin keeps improving and is able to respond\nto new threats is nothing short of amazing - thank you everyone for a great\nproject.\n\nThis current proposal really has nothing to do with SegWit - but it is an\nupdate that will make the network a little better for the future, and we\nhope you enjoy the paper.\n\nPDF:\nhttps://github.com/in-st/Floating-Point-Nakamoto-Consensus/blob/master/Floating-Point%20Nakamoto%20Consensus.pdf\n\nPull Request:\nhttps://github.com/bitcoin/bitcoin/pull/19665/files\n\n---\n\n\nFloating-Point Nakamoto Consensus\n\nAbstract \u2014 It has been shown that Nakamoto Consensus is very useful in the\nformation of long-term global agreement \u2014 and has issues with short-term\ndisagreement which can lead to re-organization (\u201cor-org\u201d) of the\nblockchain.  A malicious miner with knowledge of a specific kind of\ndenial-of-service (DoS) vulnerability can gain an unfair advantage in the\ncurrent Bitcoin network, and can be used to undermine the security\nguarantees that developers rely upon.  Floating-Point Nakamoto consensu\nmakes it more expensive to replace an already mined block vs. creation of a\nnew block, and by resolving ambiguity of competition solutions it helps\nachieve global consumers more quickly.  A floating-point fitness test\nstrongly incentivises the correct network behavior, and prevents\ndisagreement from ever forming in the first place.\nIntroduction\n\nThe Bitcoin protocol was created to provide a decentralized consensus on a\nfully distributed p2p network.  A problem arises when more than one\nproof-of-work is presented as the next solution block in the blockchain.\nTwo solutions of the same height are seen as authoritative equals which is\nthe basis of a growing disagreement. A node will adopt the first solution\nseen, as both solutions propagate across the network a race condition of\ndisagreement is formed. This race condition can be controlled by byzentiene\nfault injection commonly referred to as an \u201ceclipsing\u201d attack.  When two\nsegments of the network disagree it creates a moment of weakness in which\nless than 51% of the network\u2019s computational resources are required to keep\nthe network balanced against itself.\nNakamoto Consensus\n\nNakamoto Consensus is the process of proving computational resources in\norder to determine eligibility to participate in the decision making\nprocess.  If the outcome of an election were based on one node (or\none-IP-address-one-vote), then representation could be subverted by anyone\nable to allocate many IPs. A consensus is only formed when the prevailing\ndecision has the greatest proof-of-work effort invested in it. In order for\na Nakamoto Consensus to operate, the network must ensure that incentives\nare aligned such that the resources needed to subvert a proof-of-work based\nconsensus outweigh the resources gained through its exploitation. In this\nconsensus model, the proof-of-work requirements for the creation of the\nnext valid solution has the exact same cost as replacing the current\nsolution. There is no penalty for dishonesty, and this has worked well in\npractice because the majority of the nodes on the network are honest and\ntransparent, which is a substantial barrier for a single dishonest node to\novercome.\n\nA minimal network peer-to-peer structure is required to support Nakamoto\nConesus, and for our purposes this is entirely decentralized. Messages are\nbroadcast on a best-effort basis, and nodes can leave and rejoin the\nnetwork at will, accepting the longest proof-of-work chain as proof of what\nhappened while they were gone.  This design makes no guarantees that the\npeers connected do not misrepresent the network or so called \u201cdishonest\nnodes.\u201d Without a central authority or central view - all peers depend on\nthe data provided by neighboring peers - therefore a dishonest node can\ncontinue until a peer is able to make contact an honest node.\nSecurity\n\nIn this threat model let us assume a malicious miner possesses knowledge of\nan unpatched DoS vulnerability (\u201c0-day\u201d) which will strictly prevent honest\nnodes from communicating to new members of the network - a so-called \u201ctotal\neclipse.\u201d  The kind of DoS vulnerability needed to conduct an eclipse does\nnot need to consume all CPU or computaitly ability of target nodes - but\nrather prevent target nodes from forming new connections that would\nundermine the eclipsing effect. These kinds of DoS vulnerabilities are\nsomewhat less substional than actually knocking a powerful-mining node\noffline.  This class of attacks are valuable to an adversary because in\norder for an honest node to prove that a dishonest node is lying - they\nwould need to form a connection to a segment of the network that isn\u2019t\nentirely suppressed. Let us assume a defense-in-depth strategy and plan on\nthis kind of failure.\n\nLet us now consider that the C++ Bitcoind has a finite number of worker\nthreads and a finite number of connections that can be serviced by these\nworkers.  When a rude client occupies all connections - then a pidgin-hole\nprinciple comes into play. If a network's maximum capacity for connection\nhandlers \u2018k\u2019, is the sum of all available worker threads for all nodes in\nthe network, establishing \u2018k+1\u2019 connections by the pidgin-hole principle\nwill prevent any new connections from being formed by honest nodes -\nthereby creating a perfect eclipse for any new miners joining the network\nwould only be able to form connections with dishonest nodes.\n\nNow let\u2019s assume a dishonest node is modified in two ways - it increases\nthe maximum connection handles to hundreds of thousands instead of the\ncurrent value which is about 10. Then this node is modified to ignore any\nsolution blocks found by honest nodes - thus forcing the dishonest side of\nthe network to keep searching for a competitive-solution to split the\nnetwork in two sides that disagree about which tip of the chain to use.\nAny new solution propagates through nodes one hop at a time. This\npropagation can be predicted and shaped by dishonest non-voting nodes that\nare being used to pass messages for honest nodes.\n\nAt this point an attacker can expedite the transmission of one solution,\nwhile slowing another. If ever a competing proof-of-work is broadcasted to\nthe network, the adversary will use their network influence to split\nknowledge of the proof-of-work as close to \u00bd as possible. If the network\neclipse is perfect then an adversary can leverage an eigen-vector of\ncomputational effort to keep the disagreement in balance for as long as it\nis needed. No mechanism is stopping the attacker from adding additional\ncomputation resources or adjusting the eclipsing effect to make sure the\nsystem is in balance.   As long as two sides of the network are perfectly\nin disagreement and generating new blocks - the attacker has intentionally\ncreated a hard-fork against the will of the network architects and\noperators. The disagreement needs to be kept open until the adversary\u2019s\ntransactions have been validated on the honest chain - at which point the\nattacker will add more nodes to the dishonest chain to make sure it is the\nultimate winner - thus replacing out the honest chain with the one\ngenerated by dishonest miners.\n\nThis attack is convenient from the adversary\u2019s perspective,  Bitcoin being\na broadcast network advertises the IP addresses of all active nodes - and\nShodan and the internet scanning project can find all passive nodes\nresponding on TCP 8333.  This should illuminate all honest nodes on the\nnetwork, and even honest nodes that are trying to obscure themselves by not\nannouncing their presence.  This means that the attacker doesn\u2019t need to\nknow exactly which node is used by a targeted exchange - if the attacker\nhas subdued all nodes then the targeted exchange must be operating a node\nwithin this set of targeted honest nodes.\n\nDuring a split in the blockchain, each side of the network will honor a\nseparate merkel-tree formation and therefore a separate ledger of\ntransactions. An adversary will then broadcast currency deposits to public\nexchanges, but only on the weaker side, leaving the stronger side with no\ntransaction from the adversary. Any exchange that confirms one of these\ndeposits is relying upon nodes that have been entirely eclipsed so that\nthey cannot see the competing chain - at this point anyone looking to\nconfirm a transaction is vulnerable to a double-spend. With this currency\ndeposited on a chain that will become ephemeral, the attacker can wire out\nthe account balance on a different blockchain - such as Tether which is an\nerc20 token on the Ethereum network which would be unaffected by this\nattack.  When the weaker chain collapses, the transaction that the exchange\nacted upon is no longer codified in Bitcoin blockchain's global ledger, and\nwill be replaced with a version of the that did not contain these deposits.\n\nNakamoto Consensus holds no guarantees that it\u2019s process is deterministic.\nIn the short term, we can observe that the Nakamoto Consensus is\nempirically non-deterministic which is evident by re-organizations (re-org)\nas a method of resolving disagreements within the network.   During a\nreorganization a blockchain network is at its weakest point, and a 51%\nattack to take the network becomes unnecessary. An adversary who can\neclipse honest hosts on the network can use this as a means of byzantine\nfault-injection to disrupt the normal flow of messages on the network which\ncreates disagreement between miners.\n\nDeFi (Decentralized Finance) and smart-contract obligations depend on\nnetwork stability and determinism.  Failure to pay contracts, such as what\nhappened on \u201cblack thursday\u201d resulted in secured loans accidentally falling\ninto redemption.  The transactions used by a smart contract are intended to\nbe completed quickly and the outcome is irreversible.  However, if the\nblockchain network has split then a contract may fire and have it\u2019s\nside-effects execute only to have the transaction on the ledger to be\nreplaced.  Another example is that a hard-fork might cause the payer of a\nsmart contract to default - as the transaction that they broadcasted ended\nup being on the weaker chain that lost. Some smart contracts, such as\ncollateral backed loans have a redemption clause which would force the\nborrower on the loan to lose their deposit entirely.\n\nWith two sides of the network balanced against each other - an attacker has\nsplit the blockchain and this hard-fork can last for as long as the\nattacker is able to exert the computational power to ensure that\nproof-of-work blocks are regularly found on both sides of the network.  The\namount of resources needed to balance the network against itself is far\nless than a 51% attack - thereby undermining the security guarantees needed\nfor a decentralized untrusted payment network to function.  An adversary\nwith a sufficiently large network of dishonest bots could use this to take\na tally of which miners are participating in which side of the network\nsplit. This will create an attacker-controlled hard fork of the network\nwith two mutually exclusive merkle trees. Whereby the duration of this\nsplit is arbitrary, and the decision in which chain to collapse is up to\nthe individual with the most IP address, not the most computation.\n\nIn Satoshi Nakamoto\u2019s original paper it was stated that the electorate\nshould be represented by computational effort in the form of a\nproof-of-work, and only these nodes can participate in the consues\nprocess.  However, the electorate can be misled by non-voting nodes which\ncan reshape the network to benefit an individual adversary.\nChain Fitness\n\nAny solution to byzantine fault-injection or the intentional formation of\ndisagreements must be fully decentralized. A blockchain is allowed to split\nbecause there is ambiguity in the Nakamoto proof-of-work, which creates the\nenvironment for a race-condition to form. To resolve this, Floating-Point\nNakamoto Consensus makes it increasingly more expensive to replace the\ncurrent winning block. This added cost comes from a method of disagreement\nresolution where not every solution block is the same value, and a more-fit\nsolution is always chosen over a weaker solution. Any adversary attempting\nto have a weaker chain to win out would have to overcome a kind of\nrelay-race, whereby the winning team\u2019s strength is carried forward and the\nloser will have to work harder and harder to maintain the disagreement.  In\nmost cases Floating-Point Nakamoto Consensus will prevent a re-org\nblockchain from ever going past a single block thereby expediting the\nformation of a global consensus.  Floating-Point Nakamoto Consensus cements\nthe lead of the winner and to greatly incentivize the network to adopt the\ndominant chain no matter how many valid solutions are advertised, or what\norder they arrive.\n\nThe first step in Floating-Point Nakamoto Consensus is that all nodes in\nthe network should continue to conduct traditional Nakamoto Consensus and\nthe formation of new blocks is dictated by the same zero-prefix\nproof-of-work requirements.  If at any point there are two solution blocks\nadvertised for the same height - then a floating-point fitness value is\ncalculated and the solution with the higher fitness value is the winner\nwhich is then propagated to all neighbors. Any time two solutions are\nadvertised then a re-org is inevitable and it is in the best interest of\nall miners to adopt the most-fit block, failing to do so risks wasting\nresources on a mining of a block that would be discarded.  To make sure\nthat incentives are aligned, any zero-prefix proof of work could be the\nnext solution, but now in order to replace the current winning solution an\nadversary would need a zero-prefix block that is also more fit that the\ncurrent solution - which is much more computationally expensive to produce.\n\nAny changes to the current tip of the blockchain must be avoided as much as\npossible. To avoid thrashing between two or more competitive solutions,\neach replacement can only be done if it is more fit, thereby proving that\nit has an increased expense.  If at any point two solutions of the same\nheight are found it means that eventually some node will have to replace\ntheir tip - and it is better to have it done as quickly as possible so that\nconsensus is maintained.\n\nIn order to have a purely decentralized solution, this kind of agreement\nmust be empirically derived from the existing proof-of-work so that it is\nuniversally and identically verifiable by all nodes on the network.\nAdditionally, this fitness-test evaluation needs to ensure that no two\ncompeting solutions can be numerically equivalent.\n\nLet us suppose that two or more valid solutions will be proposed for the\nsame block.  To weigh the value of a given solution, let's consider a\nsolution for block 639254, in which the following hash was proposed:\n\n    00000000000000000008e33faa94d30cc73aa4fd819e58ce55970e7db82e10f8\n\nThere are 19 zeros, and the remaining hash in base 16 starts with 9e3 and\nends with f8.  This can value can be represented in floating point as:\n\n    19.847052573336114130069196154809453027792121882588614904\n\nTo simplify further lets give this block a single whole number to represent\none complete solution, and use a rounded floating-point value to represent\nsome fraction of additional work exerted by the miner.\n\n   1.847\n\nNow let us suppose that a few minutes later another solution is advertised\nto the network shown in base16 below:\n\n    000000000000000000028285ed9bd2c774136af8e8b90ca1bbb0caa36544fbc2\n\nThe solution above also has 19 prefixed zeros, and is being broadcast for\nthe same blockheight value of 639254 - and a fitness score of 1.282.  With\nNakamoto Consensus both of these solutions would be equivalent and a given\nnode would adopt the one that it received first.  In Floating-Post Nakamoto\nConsensus, we compare the fitness scores and keep the highest.  In this\ncase no matter what happens - some nodes will have to change their tip and\na fitness test makes sure this happens immediately.\n\nWith both solutions circulating in the network - any node who has received\nboth proof-of-works should know 1.847 is the current highest value, and\nshouldn\u2019t need to validate any lower-valued solution.  In fact this fitness\nvalue has a high degree of confidence that it won\u2019t be unseated by a larger\nvalue - being able to produce a proof-of-work with 19 0\u2019s and a decimal\ncomponent greater than 0.847 is non-trivial.  As time passes any nodes that\nreceived a proof-of-work with a value 1.204 - their view of the network\nshould erode as these nodes adopt the 1.847 version of the blockchain.\n\nAll nodes are incentivized to support the solution with the highest fitness\nvalue - irregardless of which order these proof-of-work were validated.\nMiners are incentivized to support the dominant chain which helps preserve\nthe global consensus.\n\nLet us assume that the underlying cryptographic hash-function used to\ngenerate a proof-of-work is an ideal primitive, and therefore a node cannot\nforce the outcome of the non-zero component of their proof-of-work.\nAdditionally if we assume an ideal cipher then the fitness of all possible\nsolutions is gaussian-random. With these assumptions then on average a new\nsolution would split the keyspace of remaining solutions in half.  Given\nthat the work needed to form a  new block remains a constant at 19 blocks\nfor this period - it is cheaper to produce a N+1 block that has any\nfloating point value as this is guaranteed to be adopted by all nodes if it\nis the first solution.  To leverage a chain replacement on nodes conducting\nFloating-Point Nakamoto Consensus a malicious miner would have to expend\nsignificantly more resources.\n\nEach successive n+1 solution variant of the same block-height must\ntherefore on average consume half of the remaining finite keyspace.\nResulting in a the n+1 value not only needed to overcome the 19 zero\nprefix, but also the non-zero fitness test.   It is possible for an\nadversary to waste their time making a 19 where n+1 was not greater, at\nwhich point the entire network will have had a chance to move on with the\nnext solution.  With inductive reasoning, we can see that a demissiniong\nkeyspace increases the amount of work needed to find a solution that also\nmeets this new criteria.\n\nNow let us assume a heavily-fragmented network where some nodes have gotten\none or both of the solutions.  In the case of nodes that received the\nproof-of-work solution with a fitness of 1.847, they will be happily mining\non this version of the blockchain. The nodes that have gotten both 1.847\nand .240 will still be mining for the 1.847 domainite version, ensuring a\ndominant chain.  However, we must assume some parts of the network never\ngot the message about 1.847 proof of work, and instead continued to mine\nusing a value of 1.240 as the previous block.   Now, let\u2019s say this group\nof isolated miners manages to present a new conflicting proof-of-work\nsolution for 639255:\n\n     000000000000000000058d8ebeb076584bb5853c80111bc06b5ada35463091a6\n\nThe above base16 block has a fitness score of 1.532  The fitness value for\nthe previous block 639254 is added together:\n\n     2.772 = 1.240 + 1.532\n\nIn this specific case, no other solution has been broadcast for block\nheight 639255 - putting the weaker branch in the lead.  If the weaker\nbranch is sufficiently lucky, and finds a solution before the dominant\nbranch then this solution will have a higher overall fitness score, and\nthis solution will propagate as it has the higher value.  This is also\nimportant for transactions on the network as they benefit from using the\nmost recently formed block - which will have the highest local fitness\nscore at the time of its discovery.  At this junction, the weaker branch\nhas an opportunity to prevail enterally thus ending the split.\n\nNow let us return to the DoS threat model and explore the worst-case\nscenario created by byzantine fault injection. Let us assume that both the\nweaker group and the dominant group have produced competing proof-of-work\nsolutions for blocks 639254 and 639255 respectively.  Let\u2019s assume that the\ndominant group that went with the 1.847 fitness score - also produces a\nsolution with a similar fitness value and advertises the following solution\nto the network:\n\n0000000000000000000455207e375bf1dac0d483a7442239f1ef2c70d050c113\n\n19.414973649464574877549198290879237036867705594421756179\n\nor\n\n3.262 = 1.847 + 1.415\n\nA total of 3.262 is still dominant over the lesser 2.772 - in order to\novercome this - the 2nd winning block needs to make up for all of the\nlosses in the previous block.  In this scenario, in order for the weaker\nchain to supplant the dominant chain it must overcome a -0.49 point\ndeficit. In traditional Nakamoto Consensus the nodes would see both forks\nas authoritative equals which creates a divide in mining capacity while two\ngroups of miners search for the next block.  In Floating-Point Nakamoto\nConsensus any nodes receiving both forks, would prefer to mine on the chain\nwith an overall fitness score of +3.262 - making it even harder for the\nweaker chain to find miners to compete in any future disagreement, thereby\neroding support for the weaker chain. This kind of comparison requires an\nempirical method for determining fitness by miners following the same same\nsystem of rules will insure a self-fulfilled outcome.  After all nodes\nadopt the dominant chain normal Nakamoto Consuess can resume without having\nto take into consideration block fitness. This example shows how\ndisagreement can be resolved more quickly if the network has a mechanism to\nresolve ambiguity and de-incentivise dissent.\nSoft Fork\n\nBlockchain networks that would like to improve the consensus generation\nmethod by adding a fitness test should be able to do so using a \u201cSoft Fork\u201d\notherwise known as a compatible software update.  By contrast a \u201cHard-Fork\u201d\nis a separate incompatible network that does not form the same consensus.\nFloating-Point Nakamoto Consensus can be implemented as a soft-fork because\nboth patched, and non-patched nodes can co-exist and non-patched nodes will\nbenefit from a kind of herd immunity in overall network stability.  This is\nbecause once a small number of nodes start following the same rules then\nthey will become the deciding factor in which chain is chosen.  Clients\nthat are using only traditional Nakamoto Consensus will still agree with\nnew clients over the total chain length. Miners that adopt the new strategy\nearly, will be less likely to lose out on mining invalid solutions.\nConclusion\n\nFloating-Point Nakamoto consensus allows the network to form a consensus\nmore quickly by avoiding ambiguity allowing for determinism to take hold.\nBitcoin has become an essential utility, and attacks against our networks\nmust be avoided and adapting, patching and protecting the network is a\nconstant effort. An organized attack against a cryptocurrency network will\nundermine the guarantees that blockchain developers are depending on.\n\nAny blockchain using Nakamoto Consensus can be modified to use a fitness\nconstraint such as the one used by a Floating-Point Nakamoto Consensus.  An\nexample implementation has been written and submitted as a PR to the\nbitcoin core which is free to be adapted by other networks.\n\n\n\n\n\nA complete implementation of Floating-Point Nakamoto consensus is in the\nfollowing pull request:\n\nhttps://github.com/bitcoin/bitcoin/pull/19665/files\n\nPaper:\n\nhttps://github.com/in-st/Floating-Point-Nakamoto-Consensus\n\nhttps://in.st.capital\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200924/e9b8884f/attachment-0001.html>"
            },
            {
                "author": "bitcoin ml",
                "date": "2020-09-25T15:18:17",
                "message_text_only": "Hi,\n\nThis is a pretty big departure from cumulative POW.\n\nCould you explain to me what you see happening if a node with this patch \nand no history starts to sync, and some random node gives it a block \nwith a better fitness test for say height 250,000? No other solution \nwill have a better fitness test at that height, so from my understanding \nits going to stop syncing. How about even later - say this proposal is \nactivated at block 750,000. At 850,000, someone decides it'd be fun to \npublish a new block 800,000 with a better fitness test. What happens the \n50,000 blocks?\n\nI can imagine the miners not being particularly happy about it - their \npreviously 50:50 chance (well, sort of, it's based on resources- \nconnectivity, validation overheads, etc) their tied block would succeed, \nvs the situation with this change - blocks that are inherently more or \nless valid than others.\n\nI think these days people are more focused on improving defences at the \nnetworking layer than in the consensus layer - especially when it \naffects mining incentives. I don't see how people will take this \nseriously - especially when you regard how often consensus changes are \nmade to _fix_ something as opposed to add something new.\n\nBest regards,\n\nThomas\n\nOn 9/24/20 8:40 PM, Mike Brooks via bitcoin-dev wrote:\n> \u00a0 Hey Everyone,\n>\n> \u00a0A lot of work has gone into this paper, and the current revision has \n> been well received and there is a lot of excitement on this side to\u00a0be \n> sharing it with you today. There are so few people that truly \n> understand this topic, but we are all pulling in the same direction to \n> make Bitcoin better and it shows.\u00a0 It is wildly underrated that future \n> proofing was never really a consideration\u00a0in the initial\u00a0design - but \n> here we are a decade later with amazing solutions like SegWit \n> which\u00a0gives us a real future-proofing framework.\u00a0 The fact that \n> future-proofing was added to Bitcoin with a softfork gives me \n> goosebumps.\u00a0I'd just like to take the time to thank the people who \n> worked on SegWit and it is an appreciation\u00a0that comes up in \n> conversation of how difficult and necessary that process was,\u00a0and this \n> appreciation may not be vocalized to the great people who worked on \n> it. The fact that Bitcoin keeps improving and is able to respond to \n> new threats is nothing short of amazing - thank you everyone for a \n> great project.\n>\n> This current proposal really has nothing to do with\u00a0SegWit - but it is \n> an update that will make the network a little better for the future, \n> and we hope you enjoy the paper.\n>\n> PDF:\n> https://github.com/in-st/Floating-Point-Nakamoto-Consensus/blob/master/Floating-Point%20Nakamoto%20Consensus.pdf\n> Pull Request:\n> https://github.com/bitcoin/bitcoin/pull/19665/files\n>\n> ---\n>\n>\n> Floating-Point Nakamoto Consensus\n>\n>\n> Abstract \u2014 It has been shown that Nakamoto Consensus is very useful in \n> the formation of long-term global agreement \u2014 and has issues with \n> short-term disagreement which can lead to re-organization (\u201cor-org\u201d) \n> of the blockchain.\u00a0 A malicious miner with knowledge of a specific \n> kind of denial-of-service (DoS) vulnerability can gain an unfair \n> advantage in the current Bitcoin network, and can be used to undermine \n> the security guarantees that developers rely upon.\u00a0 Floating-Point \n> Nakamoto consensu makes it more expensive to replace an already mined \n> block vs. creation of a new block, and by resolving ambiguity of \n> competition solutions it helps achieve global consumers more quickly.\u00a0 \n> A floating-point fitness test strongly incentivises the correct \n> network behavior, and prevents disagreement from ever forming in the \n> first place.\n>\n>\n>         Introduction\n>\n> The Bitcoin protocol was created to provide a decentralized consensus \n> on a fully distributed p2p network.\u00a0 A problem arises when more than \n> one proof-of-work is presented as the next solution block in the \n> blockchain.\u00a0 Two solutions of the same height are seen as \n> authoritative equals which is the basis of a growing disagreement. A \n> node will adopt the first solution seen, as both solutions propagate \n> across the network a race condition of disagreement is formed. This \n> race condition can be controlled by byzentiene fault injection \n> commonly referred to as an \u201ceclipsing\u201d attack.\u00a0 When two segments of \n> the network disagree it creates a moment of weakness in which less \n> than 51% of the network\u2019s computational resources are required to keep \n> the network balanced against itself.\n>\n>\n>         Nakamoto Consensus\n>\n> Nakamoto Consensus is the process of proving computational resources \n> in order to determine eligibility to participate in the decision \n> making process.\u00a0 If the outcome of an election were based on one node \n> (or one-IP-address-one-vote), then representation could be subverted \n> by anyone able to allocate many IPs. A consensus is only formed when \n> the prevailing decision has the greatest proof-of-work effort invested \n> in it. In order for a Nakamoto Consensus to operate, the network must \n> ensure that incentives are aligned such that the resources needed to \n> subvert a proof-of-work based consensus outweigh the resources gained \n> through its exploitation. In this consensus model, the proof-of-work \n> requirements for the creation of the next valid solution has the exact \n> same cost as replacing the current solution. There is no penalty for \n> dishonesty, and this has worked well in practice because the majority \n> of the nodes on the network are honest and transparent, which is a \n> substantial barrier for a single dishonest node to overcome.\n>\n>\n> A minimal network peer-to-peer structure is required to support \n> Nakamoto Conesus, and for our purposes this is entirely decentralized. \n> Messages are broadcast on a best-effort basis, and nodes can leave and \n> rejoin the network at will, accepting the longest proof-of-work chain \n> as proof of what happened while they were gone.\u00a0 This design makes no \n> guarantees that the peers connected do not misrepresent the network or \n> so called \u201cdishonest nodes.\u201d Without a central authority or central \n> view - all peers depend on the data provided by neighboring peers - \n> therefore a dishonest node can continue until a peer is able to make \n> contact an honest node.\n>\n>\n>         Security\n>\n> In this threat model let us assume a malicious miner possesses \n> knowledge of an unpatched DoS vulnerability (\u201c0-day\u201d) which will \n> strictly prevent honest nodes from communicating to new members of the \n> network - a so-called \u201ctotal eclipse.\u201d\u00a0 The kind of DoS vulnerability \n> needed to conduct an eclipse does not need to consume all CPU or \n> computaitly ability of target nodes - but rather prevent target nodes \n> from forming new connections that would undermine the eclipsing \n> effect. These kinds of DoS vulnerabilities are somewhat less \n> substional than actually knocking a powerful-mining node offline.\u00a0 \n> This class of attacks are valuable to an adversary because in order \n> for an honest node to prove that a dishonest node is lying - they \n> would need to form a connection to a segment of the network that isn\u2019t \n> entirely suppressed. Let us assume a defense-in-depth strategy and \n> plan on this kind of failure.\n>\n>\n> Let us now consider that the C++ Bitcoind has a finite number of \n> worker threads and a finite number of connections that can be serviced \n> by these workers.\u00a0 When a rude client occupies all connections - then \n> a pidgin-hole principle comes into play. If a network's maximum \n> capacity for connection handlers \u2018k\u2019, is the sum of all available \n> worker threads for all nodes in the network, establishing \u2018k+1\u2019 \n> connections by the pidgin-hole principle will prevent any new \n> connections from being formed by honest nodes - thereby creating a \n> perfect eclipse for any new miners joining the network would only be \n> able to form connections with dishonest nodes.\n>\n>\n> Now let\u2019s assume a dishonest node is modified in two ways - it \n> increases the maximum connection handles to hundreds of thousands \n> instead of the current value which is about 10. Then this node is \n> modified to ignore any solution blocks found by honest nodes - thus \n> forcing the dishonest side of the network to keep searching for a \n> competitive-solution to split the network in two sides that disagree \n> about which tip of the chain to use.\u00a0 Any new solution propagates \n> through nodes one hop at a time. This propagation can be predicted and \n> shaped by dishonest non-voting nodes that are being used to pass \n> messages for honest nodes.\n>\n>\n> At this point an attacker can expedite the transmission of one \n> solution, while slowing another. If ever a competing proof-of-work is \n> broadcasted to the network, the adversary will use their network \n> influence to split knowledge of the proof-of-work as close to \u00bd as \n> possible. If the network eclipse is perfect then an adversary can \n> leverage an eigen-vector of computational effort to keep the \n> disagreement in balance for as long as it is needed. No mechanism is \n> stopping the attacker from adding additional computation resources or \n> adjusting the eclipsing effect to make sure the system is in balance. \n> \u00a0 As long as two sides of the network are perfectly in disagreement \n> and generating new blocks - the attacker has intentionally created a \n> hard-fork against the will of the network architects and operators. \n> The disagreement needs to be kept open until the adversary\u2019s \n> transactions have been validated on the honest chain - at which point \n> the attacker will add more nodes to the dishonest chain to make sure \n> it is the ultimate winner - thus replacing out the honest chain with \n> the one generated by dishonest miners.\n>\n>\n> This attack is convenient from the adversary\u2019s perspective,\u00a0 Bitcoin \n> being a broadcast network advertises the IP addresses of all active \n> nodes - and Shodan and the internet scanning project can find all \n> passive nodes responding on TCP 8333.\u00a0 This should illuminate all \n> honest nodes on the network, and even honest nodes that are trying to \n> obscure themselves by not announcing their presence.\u00a0 This means that \n> the attacker doesn\u2019t need to know exactly which node is used by a \n> targeted exchange - if the attacker has subdued all nodes then the \n> targeted exchange must be operating a node within this set of targeted \n> honest nodes.\n>\n>\n> During a split in the blockchain, each side of the network will honor \n> a separate merkel-tree formation and therefore a separate ledger of \n> transactions. An adversary will then broadcast currency deposits to \n> public exchanges, but only on the weaker side, leaving the stronger \n> side with no transaction from the adversary. Any exchange that \n> confirms one of these deposits is relying upon nodes that have been \n> entirely eclipsed so that they cannot see the competing chain - at \n> this point anyone looking to confirm a transaction is vulnerable to a \n> double-spend. With this currency deposited on a chain that will become \n> ephemeral, the attacker can wire out the account balance on a \n> different blockchain - such as Tether which is an erc20 token on the \n> Ethereum network which would be unaffected by this attack.\u00a0 When the \n> weaker chain collapses, the transaction that the exchange acted upon \n> is no longer codified in Bitcoin blockchain's global ledger, and will \n> be replaced with a version of the that did not contain these deposits.\n>\n>\n> Nakamoto Consensus holds no guarantees that it\u2019s process is \n> deterministic.\u00a0 In the short term, we can observe that the Nakamoto \n> Consensus is empirically non-deterministic which is evident by \n> re-organizations (re-org) as a method of resolving disagreements \n> within the network. \u00a0 During a reorganization a blockchain network is \n> at its weakest point, and a 51% attack to take the network becomes \n> unnecessary. An adversary who can eclipse honest hosts on the network \n> can use this as a means of byzantine fault-injection to disrupt the \n> normal flow of messages on the network which creates disagreement \n> between miners.\n>\n>\n> DeFi (Decentralized Finance) and smart-contract obligations depend on \n> network stability and determinism.\u00a0 Failure to pay contracts, such as \n> what happened on \u201cblack thursday\u201d resulted in secured loans \n> accidentally falling into redemption.\u00a0 The transactions used by a \n> smart contract are intended to be completed quickly and the outcome is \n> irreversible.\u00a0 However, if the blockchain network has split then a \n> contract may fire and have it\u2019s side-effects execute only to have the \n> transaction on the ledger to be replaced.\u00a0 Another example is that a \n> hard-fork might cause the payer of a smart contract to default - as \n> the transaction that they broadcasted ended up being on the weaker \n> chain that lost. Some smart contracts, such as collateral backed loans \n> have a redemption clause which would force the borrower on the loan to \n> lose their deposit entirely.\n>\n>\n> With two sides of the network balanced against each other - an \n> attacker has split the blockchain and this hard-fork can last for as \n> long as the attacker is able to exert the computational power to \n> ensure that proof-of-work blocks are regularly found on both sides of \n> the network.\u00a0 The amount of resources needed to balance the network \n> against itself is far less than a 51% attack - thereby undermining the \n> security guarantees needed for a decentralized untrusted payment \n> network to function.\u00a0 An adversary with a sufficiently large network \n> of dishonest bots could use this to take a tally of which miners are \n> participating in which side of the network split. This will create an \n> attacker-controlled hard fork of the network with two mutually \n> exclusive merkle trees. Whereby the duration of this split is \n> arbitrary, and the decision in which chain to collapse is up to the \n> individual with the most IP address, not the most computation.\n>\n>\n> In Satoshi Nakamoto\u2019s original paper it was stated that the electorate \n> should be represented by computational effort in the form of a \n> proof-of-work, and only these nodes can participate in the consues \n> process.\u00a0 However, the electorate can be misled by non-voting nodes \n> which can reshape the network to benefit an individual adversary.\n>\n>\n>         Chain Fitness\n>\n> Any solution to byzantine fault-injection or the intentional formation \n> of disagreements must be fully decentralized. A blockchain is allowed \n> to split because there is ambiguity in the Nakamoto proof-of-work, \n> which creates the environment for a race-condition to form. To resolve \n> this, Floating-Point Nakamoto Consensus makes it increasingly more \n> expensive to replace the current winning block. This added cost comes \n> from a method of disagreement resolution where not every solution \n> block is the same value, and a more-fit solution is always chosen over \n> a weaker solution. Any adversary attempting to have a weaker chain to \n> win out would have to overcome a kind of relay-race, whereby the \n> winning team\u2019s strength is carried forward and the loser will have to \n> work harder and harder to maintain the disagreement.\u00a0 In most cases \n> Floating-Point Nakamoto Consensus will prevent a re-org blockchain \n> from ever going past a single block thereby expediting the formation \n> of a global consensus.\u00a0 Floating-Point Nakamoto Consensus cements the \n> lead of the winner and to greatly incentivize the network to adopt the \n> dominant chain no matter how many valid solutions are advertised, or \n> what order they arrive.\n>\n>\n> The first step in Floating-Point Nakamoto Consensus is that all nodes \n> in the network should continue to conduct traditional Nakamoto \n> Consensus and the formation of new blocks is dictated by the same \n> zero-prefix proof-of-work requirements.\u00a0 If at any point there are two \n> solution blocks advertised for the same height - then a floating-point \n> fitness value is calculated and the solution with the higher fitness \n> value is the winner which is then propagated to all neighbors. Any \n> time two solutions are advertised then a re-org is inevitable and it \n> is in the best interest of all miners to adopt the most-fit block, \n> failing to do so risks wasting resources on a mining of a block that \n> would be discarded.\u00a0 To make sure that incentives are aligned, any \n> zero-prefix proof of work could be the next solution, but now in order \n> to replace the current winning solution an adversary would need a \n> zero-prefix block that is also more fit that the current solution - \n> which is much more computationally expensive to produce.\n>\n> Any changes to the current tip of the blockchain must be avoided as \n> much as possible. To avoid thrashing between two or more competitive \n> solutions, each replacement can only be done if it is more fit, \n> thereby proving that it has an increased expense.\u00a0 If at any point two \n> solutions of the same height are found it means that eventually some \n> node will have to replace their tip - and it is better to have it done \n> as quickly as possible so that consensus is maintained.\n>\n>\n> In order to have a purely decentralized solution, this kind of \n> agreement must be empirically derived from the existing proof-of-work \n> so that it is universally and identically verifiable by all nodes on \n> the network.\u00a0 Additionally, this fitness-test evaluation needs to \n> ensure that no two competing solutions can be numerically equivalent.\n>\n>\n> Let us suppose that two or more valid solutions will be proposed for \n> the same block.\u00a0 To weigh the value of a given solution, let's \n> consider a solution for block 639254, in which the following hash was \n> proposed:\n>\n> \u00a0\u00a0\u00a0\u00a000000000000000000008e33faa94d30cc73aa4fd819e58ce55970e7db82e10f8\n>\n>\n> There are 19 zeros, and the remaining hash in base 16 starts with 9e3 \n> and ends with f8.\u00a0 This can value can be represented in floating point as:\n>\n> \u00a0\u00a0\u00a0\u00a019.847052573336114130069196154809453027792121882588614904\n>\n>\n> To simplify further lets give this block a single whole number to \n> represent one complete solution, and use a rounded floating-point \n> value to represent some fraction of additional work exerted by the miner.\n>\n> \u00a0\u00a0\u00a01.847\n>\n>\n> Now let us suppose that a few minutes later another solution is \n> advertised to the network shown in base16 below:\n>\n> \u00a0\u00a0\u00a0\u00a0000000000000000000028285ed9bd2c774136af8e8b90ca1bbb0caa36544fbc2\n>\n>\n> The solution above also has 19 prefixed zeros, and is being broadcast \n> for the same blockheight value of 639254 - and a fitness score of \n> 1.282.\u00a0 With Nakamoto Consensus both of these solutions would be \n> equivalent and a given node would adopt the one that it received \n> first.\u00a0 In Floating-Post Nakamoto Consensus, we compare the fitness \n> scores and keep the highest.\u00a0 In this case no matter what happens - \n> some nodes will have to change their tip and a fitness test makes sure \n> this happens immediately.\n>\n>\n> With both solutions circulating in the network - any node who has \n> received both proof-of-works should know 1.847 is the current highest \n> value, and shouldn\u2019t need to validate any lower-valued solution.\u00a0 In \n> fact this fitness value has a high degree of confidence that it won\u2019t \n> be unseated by a larger value - being able to produce a proof-of-work \n> with 19 0\u2019s and a decimal component greater than 0.847 is \n> non-trivial.\u00a0 As time passes any nodes that received a proof-of-work \n> with a value 1.204 - their view of the network should erode as these \n> nodes adopt the 1.847 version of the blockchain.\n>\n> All nodes are incentivized to support the solution with the highest \n> fitness value - irregardless of which order these proof-of-work were \n> validated. Miners are incentivized to support the dominant chain which \n> helps preserve the global consensus.\n>\n>\n> Let us assume that the underlying cryptographic hash-function used to \n> generate a proof-of-work is an ideal primitive, and therefore a node \n> cannot force the outcome of the non-zero component of their \n> proof-of-work.\u00a0 Additionally if we assume an ideal cipher then the \n> fitness of all possible solutions is gaussian-random. With these \n> assumptions then on average a new solution would split the keyspace of \n> remaining solutions in half.\u00a0 Given that the work needed to form a\u00a0 \n> new block remains a constant at 19 blocks for this period - it is \n> cheaper to produce a N+1 block that has any floating point value as \n> this is guaranteed to be adopted by all nodes if it is the first \n> solution.\u00a0 To leverage a chain replacement on nodes conducting \n> Floating-Point Nakamoto Consensus a malicious miner would have to \n> expend significantly more resources.\n>\n>\n> Each successive n+1 solution variant of the same block-height must \n> therefore on average consume half of the remaining finite keyspace. \n> Resulting in a the n+1 value not only needed to overcome the 19 zero \n> prefix, but also the non-zero fitness test. \u00a0 It is possible for an \n> adversary to waste their time making a 19 where n+1 was not greater, \n> at which point the entire network will have had a chance to move on \n> with the next solution.\u00a0 With inductive reasoning, we can see that a \n> demissiniong keyspace increases the amount of work needed to find a \n> solution that also meets this new criteria.\n>\n>\n> Now let us assume a heavily-fragmented network where some nodes have \n> gotten one or both of the solutions.\u00a0 In the case of nodes that \n> received the proof-of-work solution with a fitness of 1.847, they will \n> be happily mining on this version of the blockchain. The nodes that \n> have gotten both 1.847 and .240 will still be mining for the 1.847 \n> domainite version, ensuring a dominant chain.\u00a0 However, we must assume \n> some parts of the network never got the message about 1.847 proof of \n> work, and instead continued to mine using a value of 1.240 as the \n> previous block. \u00a0 Now, let\u2019s say this group of isolated miners manages \n> to present a new conflicting proof-of-work solution for 639255:\n>\n>\n> \u00a0\u00a0\u00a0\u00a0\u00a0000000000000000000058d8ebeb076584bb5853c80111bc06b5ada35463091a6\n>\n>\n> The above base16 block has a fitness score of 1.532\u00a0 The fitness value \n> for the previous block 639254 is added together:\n>\n>\n> \u00a0\u00a0\u00a0\u00a0\u00a02.772 = 1.240 + 1.532\n>\n>\n> In this specific case, no other solution has been broadcast for block \n> height 639255 - putting the weaker branch in the lead.\u00a0 If the weaker \n> branch is sufficiently lucky, and finds a solution before the dominant \n> branch then this solution will have a higher overall fitness score, \n> and this solution will propagate as it has the higher value.\u00a0 This is \n> also important for transactions on the network as they benefit from \n> using the most recently formed block - which will have the highest \n> local fitness score at the time of its discovery.\u00a0 At this junction, \n> the weaker branch has an opportunity to prevail enterally thus ending \n> the split.\n>\n>\n> Now let us return to the DoS threat model and explore the worst-case \n> scenario created by byzantine fault injection. Let us assume that both \n> the weaker group and the dominant group have produced competing \n> proof-of-work solutions for blocks 639254 and 639255 respectively.\u00a0 \n> Let\u2019s assume that the dominant group that went with the 1.847 fitness \n> score - also produces a solution with a similar fitness value and \n> advertises the following solution to the network:\n>\n>\n> 0000000000000000000455207e375bf1dac0d483a7442239f1ef2c70d050c113\n>\n> 19.414973649464574877549198290879237036867705594421756179\n>\n> or\n>\n> 3.262 = 1.847 + 1.415\n>\n>\n> A total of 3.262 is still dominant over the lesser 2.772 - in order to \n> overcome this - the 2nd winning block needs to make up for all of the \n> losses in the previous block.\u00a0 In this scenario, in order for the \n> weaker chain to supplant the dominant chain it must overcome a -0.49 \n> point deficit. In traditional Nakamoto Consensus the nodes would see \n> both forks as authoritative equals which creates a divide in mining \n> capacity while two groups of miners search for the next block.\u00a0 In \n> Floating-Point Nakamoto Consensus any nodes receiving both forks, \n> would prefer to mine on the chain with an overall fitness score of \n> +3.262 - making it even harder for the weaker chain to find miners to \n> compete in any future disagreement, thereby eroding support for the \n> weaker chain. This kind of comparison requires an empirical method for \n> determining fitness by miners following the same same system of rules \n> will insure a self-fulfilled outcome.\u00a0 After all nodes adopt the \n> dominant chain normal Nakamoto Consuess can resume without having to \n> take into consideration block fitness. This example shows how \n> disagreement can be resolved more quickly if the network has a \n> mechanism to resolve ambiguity and de-incentivise dissent.\n>\n>\n>         Soft Fork\n>\n> Blockchain networks that would like to improve the consensus \n> generation method by adding a fitness test should be able to do so \n> using a \u201cSoft Fork\u201d otherwise known as a compatible software update.\u00a0 \n> By contrast a \u201cHard-Fork\u201d is a separate incompatible network that does \n> not form the same consensus.\u00a0 Floating-Point Nakamoto Consensus can be \n> implemented as a soft-fork because both patched, and non-patched nodes \n> can co-exist and non-patched nodes will benefit from a kind of herd \n> immunity in overall network stability.\u00a0 This is because once a small \n> number of nodes start following the same rules then they will become \n> the deciding factor in which chain is chosen.\u00a0 Clients that are using \n> only traditional Nakamoto Consensus will still agree with new clients \n> over the total chain length. Miners that adopt the new strategy early, \n> will be less likely to lose out on mining invalid solutions.\n>\n>\n>         Conclusion\n>\n> Floating-Point Nakamoto consensus allows the network to form a \n> consensus more quickly by avoiding ambiguity allowing for determinism \n> to take hold. Bitcoin has become an essential utility, and attacks \n> against our networks must be avoided and adapting, patching and \n> protecting the network is a constant effort. An organized attack \n> against a cryptocurrency network will undermine the guarantees that \n> blockchain developers are depending on.\n>\n>\n> Any blockchain using Nakamoto Consensus can be modified to use a \n> fitness constraint such as the one used by a Floating-Point Nakamoto \n> Consensus.\u00a0 An example implementation has been written and submitted \n> as a PR to the bitcoin core which is free to be adapted by other networks.\n>\n>\n>\n>\n>\n>\n> A complete implementation of Floating-Point Nakamoto consensus is in \n> the following pull request:\n>\n> https://github.com/bitcoin/bitcoin/pull/19665/files\n>\n>\n> Paper:\n>\n> https://github.com/in-st/Floating-Point-Nakamoto-Consensus\n>\n> https://in.st.capital <https://in.st.capital/>\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200925/13c1a92e/attachment-0001.html>"
            },
            {
                "author": "Mike Brooks",
                "date": "2020-09-25T16:04:11",
                "message_text_only": "Hey Thomas,\n\nA fitness value is only additive for the length of the disagreement, and\nonly used to solve disagreements of the same height.  This isn't as large\nof a departure as you are expecting.  For 50,000 blocks of agreement, then\nno floating point value is calculated.\n\nAll the best,\nMike\n\nOn Fri, Sep 25, 2020 at 8:57 AM bitcoin ml via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi,\n>\n> This is a pretty big departure from cumulative POW.\n>\n> Could you explain to me what you see happening if a node with this patch\n> and no history starts to sync, and some random node gives it a block with a\n> better fitness test for say height 250,000? No other solution will have a\n> better fitness test at that height, so from my understanding its going to\n> stop syncing. How about even later - say this proposal is activated at\n> block 750,000. At 850,000, someone decides it'd be fun to publish a new\n> block 800,000 with a better fitness test. What happens the 50,000 blocks?\n>\n> I can imagine the miners not being particularly happy about it - their\n> previously 50:50 chance (well, sort of, it's based on resources-\n> connectivity, validation overheads, etc) their tied block would succeed, vs\n> the situation with this change - blocks that are inherently more or less\n> valid than others.\n>\n> I think these days people are more focused on improving defences at the\n> networking layer than in the consensus layer - especially when it affects\n> mining incentives. I don't see how people will take this seriously -\n> especially when you regard how often consensus changes are made to _fix_\n> something as opposed to add something new.\n>\n> Best regards,\n>\n> Thomas\n> On 9/24/20 8:40 PM, Mike Brooks via bitcoin-dev wrote:\n>\n>   Hey Everyone,\n>\n>  A lot of work has gone into this paper, and the current revision has been\n> well received and there is a lot of excitement on this side to be sharing\n> it with you today. There are so few people that truly understand this\n> topic, but we are all pulling in the same direction to make Bitcoin better\n> and it shows.  It is wildly underrated that future proofing was never\n> really a consideration in the initial design - but here we are a decade\n> later with amazing solutions like SegWit which gives us a real\n> future-proofing framework.  The fact that future-proofing was added to\n> Bitcoin with a softfork gives me goosebumps. I'd just like to take the time\n> to thank the people who worked on SegWit and it is an appreciation that\n> comes up in conversation of how difficult and necessary that process\n> was, and this appreciation may not be vocalized to the great people who\n> worked on it. The fact that Bitcoin keeps improving and is able to respond\n> to new threats is nothing short of amazing - thank you everyone for a great\n> project.\n>\n> This current proposal really has nothing to do with SegWit - but it is an\n> update that will make the network a little better for the future, and we\n> hope you enjoy the paper.\n>\n> PDF:\n>\n> https://github.com/in-st/Floating-Point-Nakamoto-Consensus/blob/master/Floating-Point%20Nakamoto%20Consensus.pdf\n>\n> Pull Request:\n> https://github.com/bitcoin/bitcoin/pull/19665/files\n>\n> ---\n>\n>\n> Floating-Point Nakamoto Consensus\n>\n> Abstract \u2014 It has been shown that Nakamoto Consensus is very useful in\n> the formation of long-term global agreement \u2014 and has issues with\n> short-term disagreement which can lead to re-organization (\u201cor-org\u201d) of the\n> blockchain.  A malicious miner with knowledge of a specific kind of\n> denial-of-service (DoS) vulnerability can gain an unfair advantage in the\n> current Bitcoin network, and can be used to undermine the security\n> guarantees that developers rely upon.  Floating-Point Nakamoto consensu\n> makes it more expensive to replace an already mined block vs. creation of a\n> new block, and by resolving ambiguity of competition solutions it helps\n> achieve global consumers more quickly.  A floating-point fitness test\n> strongly incentivises the correct network behavior, and prevents\n> disagreement from ever forming in the first place.\n> Introduction\n>\n> The Bitcoin protocol was created to provide a decentralized consensus on a\n> fully distributed p2p network.  A problem arises when more than one\n> proof-of-work is presented as the next solution block in the blockchain.\n> Two solutions of the same height are seen as authoritative equals which is\n> the basis of a growing disagreement. A node will adopt the first solution\n> seen, as both solutions propagate across the network a race condition of\n> disagreement is formed. This race condition can be controlled by byzentiene\n> fault injection commonly referred to as an \u201ceclipsing\u201d attack.  When two\n> segments of the network disagree it creates a moment of weakness in which\n> less than 51% of the network\u2019s computational resources are required to keep\n> the network balanced against itself.\n> Nakamoto Consensus\n>\n> Nakamoto Consensus is the process of proving computational resources in\n> order to determine eligibility to participate in the decision making\n> process.  If the outcome of an election were based on one node (or\n> one-IP-address-one-vote), then representation could be subverted by anyone\n> able to allocate many IPs. A consensus is only formed when the prevailing\n> decision has the greatest proof-of-work effort invested in it. In order for\n> a Nakamoto Consensus to operate, the network must ensure that incentives\n> are aligned such that the resources needed to subvert a proof-of-work based\n> consensus outweigh the resources gained through its exploitation. In this\n> consensus model, the proof-of-work requirements for the creation of the\n> next valid solution has the exact same cost as replacing the current\n> solution. There is no penalty for dishonesty, and this has worked well in\n> practice because the majority of the nodes on the network are honest and\n> transparent, which is a substantial barrier for a single dishonest node to\n> overcome.\n>\n> A minimal network peer-to-peer structure is required to support Nakamoto\n> Conesus, and for our purposes this is entirely decentralized. Messages are\n> broadcast on a best-effort basis, and nodes can leave and rejoin the\n> network at will, accepting the longest proof-of-work chain as proof of what\n> happened while they were gone.  This design makes no guarantees that the\n> peers connected do not misrepresent the network or so called \u201cdishonest\n> nodes.\u201d Without a central authority or central view - all peers depend on\n> the data provided by neighboring peers - therefore a dishonest node can\n> continue until a peer is able to make contact an honest node.\n> Security\n>\n> In this threat model let us assume a malicious miner possesses knowledge\n> of an unpatched DoS vulnerability (\u201c0-day\u201d) which will strictly prevent\n> honest nodes from communicating to new members of the network - a so-called\n> \u201ctotal eclipse.\u201d  The kind of DoS vulnerability needed to conduct an\n> eclipse does not need to consume all CPU or computaitly ability of target\n> nodes - but rather prevent target nodes from forming new connections that\n> would undermine the eclipsing effect. These kinds of DoS vulnerabilities\n> are somewhat less substional than actually knocking a powerful-mining node\n> offline.  This class of attacks are valuable to an adversary because in\n> order for an honest node to prove that a dishonest node is lying - they\n> would need to form a connection to a segment of the network that isn\u2019t\n> entirely suppressed. Let us assume a defense-in-depth strategy and plan on\n> this kind of failure.\n>\n> Let us now consider that the C++ Bitcoind has a finite number of worker\n> threads and a finite number of connections that can be serviced by these\n> workers.  When a rude client occupies all connections - then a pidgin-hole\n> principle comes into play. If a network's maximum capacity for connection\n> handlers \u2018k\u2019, is the sum of all available worker threads for all nodes in\n> the network, establishing \u2018k+1\u2019 connections by the pidgin-hole principle\n> will prevent any new connections from being formed by honest nodes -\n> thereby creating a perfect eclipse for any new miners joining the network\n> would only be able to form connections with dishonest nodes.\n>\n> Now let\u2019s assume a dishonest node is modified in two ways - it increases\n> the maximum connection handles to hundreds of thousands instead of the\n> current value which is about 10. Then this node is modified to ignore any\n> solution blocks found by honest nodes - thus forcing the dishonest side of\n> the network to keep searching for a competitive-solution to split the\n> network in two sides that disagree about which tip of the chain to use.\n> Any new solution propagates through nodes one hop at a time. This\n> propagation can be predicted and shaped by dishonest non-voting nodes that\n> are being used to pass messages for honest nodes.\n>\n> At this point an attacker can expedite the transmission of one solution,\n> while slowing another. If ever a competing proof-of-work is broadcasted to\n> the network, the adversary will use their network influence to split\n> knowledge of the proof-of-work as close to \u00bd as possible. If the network\n> eclipse is perfect then an adversary can leverage an eigen-vector of\n> computational effort to keep the disagreement in balance for as long as it\n> is needed. No mechanism is stopping the attacker from adding additional\n> computation resources or adjusting the eclipsing effect to make sure the\n> system is in balance.   As long as two sides of the network are perfectly\n> in disagreement and generating new blocks - the attacker has intentionally\n> created a hard-fork against the will of the network architects and\n> operators. The disagreement needs to be kept open until the adversary\u2019s\n> transactions have been validated on the honest chain - at which point the\n> attacker will add more nodes to the dishonest chain to make sure it is the\n> ultimate winner - thus replacing out the honest chain with the one\n> generated by dishonest miners.\n>\n> This attack is convenient from the adversary\u2019s perspective,  Bitcoin being\n> a broadcast network advertises the IP addresses of all active nodes - and\n> Shodan and the internet scanning project can find all passive nodes\n> responding on TCP 8333.  This should illuminate all honest nodes on the\n> network, and even honest nodes that are trying to obscure themselves by not\n> announcing their presence.  This means that the attacker doesn\u2019t need to\n> know exactly which node is used by a targeted exchange - if the attacker\n> has subdued all nodes then the targeted exchange must be operating a node\n> within this set of targeted honest nodes.\n>\n> During a split in the blockchain, each side of the network will honor a\n> separate merkel-tree formation and therefore a separate ledger of\n> transactions. An adversary will then broadcast currency deposits to public\n> exchanges, but only on the weaker side, leaving the stronger side with no\n> transaction from the adversary. Any exchange that confirms one of these\n> deposits is relying upon nodes that have been entirely eclipsed so that\n> they cannot see the competing chain - at this point anyone looking to\n> confirm a transaction is vulnerable to a double-spend. With this currency\n> deposited on a chain that will become ephemeral, the attacker can wire out\n> the account balance on a different blockchain - such as Tether which is an\n> erc20 token on the Ethereum network which would be unaffected by this\n> attack.  When the weaker chain collapses, the transaction that the exchange\n> acted upon is no longer codified in Bitcoin blockchain's global ledger, and\n> will be replaced with a version of the that did not contain these deposits.\n>\n> Nakamoto Consensus holds no guarantees that it\u2019s process is\n> deterministic.  In the short term, we can observe that the Nakamoto\n> Consensus is empirically non-deterministic which is evident by\n> re-organizations (re-org) as a method of resolving disagreements within the\n> network.   During a reorganization a blockchain network is at its weakest\n> point, and a 51% attack to take the network becomes unnecessary. An\n> adversary who can eclipse honest hosts on the network can use this as a\n> means of byzantine fault-injection to disrupt the normal flow of messages\n> on the network which creates disagreement between miners.\n>\n> DeFi (Decentralized Finance) and smart-contract obligations depend on\n> network stability and determinism.  Failure to pay contracts, such as what\n> happened on \u201cblack thursday\u201d resulted in secured loans accidentally falling\n> into redemption.  The transactions used by a smart contract are intended to\n> be completed quickly and the outcome is irreversible.  However, if the\n> blockchain network has split then a contract may fire and have it\u2019s\n> side-effects execute only to have the transaction on the ledger to be\n> replaced.  Another example is that a hard-fork might cause the payer of a\n> smart contract to default - as the transaction that they broadcasted ended\n> up being on the weaker chain that lost. Some smart contracts, such as\n> collateral backed loans have a redemption clause which would force the\n> borrower on the loan to lose their deposit entirely.\n>\n> With two sides of the network balanced against each other - an attacker\n> has split the blockchain and this hard-fork can last for as long as the\n> attacker is able to exert the computational power to ensure that\n> proof-of-work blocks are regularly found on both sides of the network.  The\n> amount of resources needed to balance the network against itself is far\n> less than a 51% attack - thereby undermining the security guarantees needed\n> for a decentralized untrusted payment network to function.  An adversary\n> with a sufficiently large network of dishonest bots could use this to take\n> a tally of which miners are participating in which side of the network\n> split. This will create an attacker-controlled hard fork of the network\n> with two mutually exclusive merkle trees. Whereby the duration of this\n> split is arbitrary, and the decision in which chain to collapse is up to\n> the individual with the most IP address, not the most computation.\n>\n> In Satoshi Nakamoto\u2019s original paper it was stated that the electorate\n> should be represented by computational effort in the form of a\n> proof-of-work, and only these nodes can participate in the consues\n> process.  However, the electorate can be misled by non-voting nodes which\n> can reshape the network to benefit an individual adversary.\n> Chain Fitness\n>\n> Any solution to byzantine fault-injection or the intentional formation of\n> disagreements must be fully decentralized. A blockchain is allowed to split\n> because there is ambiguity in the Nakamoto proof-of-work, which creates the\n> environment for a race-condition to form. To resolve this, Floating-Point\n> Nakamoto Consensus makes it increasingly more expensive to replace the\n> current winning block. This added cost comes from a method of disagreement\n> resolution where not every solution block is the same value, and a more-fit\n> solution is always chosen over a weaker solution. Any adversary attempting\n> to have a weaker chain to win out would have to overcome a kind of\n> relay-race, whereby the winning team\u2019s strength is carried forward and the\n> loser will have to work harder and harder to maintain the disagreement.  In\n> most cases Floating-Point Nakamoto Consensus will prevent a re-org\n> blockchain from ever going past a single block thereby expediting the\n> formation of a global consensus.  Floating-Point Nakamoto Consensus cements\n> the lead of the winner and to greatly incentivize the network to adopt the\n> dominant chain no matter how many valid solutions are advertised, or what\n> order they arrive.\n>\n> The first step in Floating-Point Nakamoto Consensus is that all nodes in\n> the network should continue to conduct traditional Nakamoto Consensus and\n> the formation of new blocks is dictated by the same zero-prefix\n> proof-of-work requirements.  If at any point there are two solution blocks\n> advertised for the same height - then a floating-point fitness value is\n> calculated and the solution with the higher fitness value is the winner\n> which is then propagated to all neighbors. Any time two solutions are\n> advertised then a re-org is inevitable and it is in the best interest of\n> all miners to adopt the most-fit block, failing to do so risks wasting\n> resources on a mining of a block that would be discarded.  To make sure\n> that incentives are aligned, any zero-prefix proof of work could be the\n> next solution, but now in order to replace the current winning solution an\n> adversary would need a zero-prefix block that is also more fit that the\n> current solution - which is much more computationally expensive to produce.\n>\n> Any changes to the current tip of the blockchain must be avoided as much\n> as possible. To avoid thrashing between two or more competitive solutions,\n> each replacement can only be done if it is more fit, thereby proving that\n> it has an increased expense.  If at any point two solutions of the same\n> height are found it means that eventually some node will have to replace\n> their tip - and it is better to have it done as quickly as possible so that\n> consensus is maintained.\n>\n> In order to have a purely decentralized solution, this kind of agreement\n> must be empirically derived from the existing proof-of-work so that it is\n> universally and identically verifiable by all nodes on the network.\n> Additionally, this fitness-test evaluation needs to ensure that no two\n> competing solutions can be numerically equivalent.\n>\n> Let us suppose that two or more valid solutions will be proposed for the\n> same block.  To weigh the value of a given solution, let's consider a\n> solution for block 639254, in which the following hash was proposed:\n>\n>     00000000000000000008e33faa94d30cc73aa4fd819e58ce55970e7db82e10f8\n>\n> There are 19 zeros, and the remaining hash in base 16 starts with 9e3 and\n> ends with f8.  This can value can be represented in floating point as:\n>\n>     19.847052573336114130069196154809453027792121882588614904\n>\n> To simplify further lets give this block a single whole number to\n> represent one complete solution, and use a rounded floating-point value to\n> represent some fraction of additional work exerted by the miner.\n>\n>    1.847\n>\n> Now let us suppose that a few minutes later another solution is advertised\n> to the network shown in base16 below:\n>\n>     000000000000000000028285ed9bd2c774136af8e8b90ca1bbb0caa36544fbc2\n>\n> The solution above also has 19 prefixed zeros, and is being broadcast for\n> the same blockheight value of 639254 - and a fitness score of 1.282.  With\n> Nakamoto Consensus both of these solutions would be equivalent and a given\n> node would adopt the one that it received first.  In Floating-Post Nakamoto\n> Consensus, we compare the fitness scores and keep the highest.  In this\n> case no matter what happens - some nodes will have to change their tip and\n> a fitness test makes sure this happens immediately.\n>\n> With both solutions circulating in the network - any node who has received\n> both proof-of-works should know 1.847 is the current highest value, and\n> shouldn\u2019t need to validate any lower-valued solution.  In fact this fitness\n> value has a high degree of confidence that it won\u2019t be unseated by a larger\n> value - being able to produce a proof-of-work with 19 0\u2019s and a decimal\n> component greater than 0.847 is non-trivial.  As time passes any nodes that\n> received a proof-of-work with a value 1.204 - their view of the network\n> should erode as these nodes adopt the 1.847 version of the blockchain.\n>\n> All nodes are incentivized to support the solution with the highest\n> fitness value - irregardless of which order these proof-of-work were\n> validated. Miners are incentivized to support the dominant chain which\n> helps preserve the global consensus.\n>\n> Let us assume that the underlying cryptographic hash-function used to\n> generate a proof-of-work is an ideal primitive, and therefore a node cannot\n> force the outcome of the non-zero component of their proof-of-work.\n> Additionally if we assume an ideal cipher then the fitness of all possible\n> solutions is gaussian-random. With these assumptions then on average a new\n> solution would split the keyspace of remaining solutions in half.  Given\n> that the work needed to form a  new block remains a constant at 19 blocks\n> for this period - it is cheaper to produce a N+1 block that has any\n> floating point value as this is guaranteed to be adopted by all nodes if it\n> is the first solution.  To leverage a chain replacement on nodes conducting\n> Floating-Point Nakamoto Consensus a malicious miner would have to expend\n> significantly more resources.\n>\n> Each successive n+1 solution variant of the same block-height must\n> therefore on average consume half of the remaining finite keyspace.\n> Resulting in a the n+1 value not only needed to overcome the 19 zero\n> prefix, but also the non-zero fitness test.   It is possible for an\n> adversary to waste their time making a 19 where n+1 was not greater, at\n> which point the entire network will have had a chance to move on with the\n> next solution.  With inductive reasoning, we can see that a demissiniong\n> keyspace increases the amount of work needed to find a solution that also\n> meets this new criteria.\n>\n> Now let us assume a heavily-fragmented network where some nodes have\n> gotten one or both of the solutions.  In the case of nodes that received\n> the proof-of-work solution with a fitness of 1.847, they will be happily\n> mining on this version of the blockchain. The nodes that have gotten both\n> 1.847 and .240 will still be mining for the 1.847 domainite version,\n> ensuring a dominant chain.  However, we must assume some parts of the\n> network never got the message about 1.847 proof of work, and instead\n> continued to mine using a value of 1.240 as the previous block.   Now,\n> let\u2019s say this group of isolated miners manages to present a new\n> conflicting proof-of-work solution for 639255:\n>\n>      000000000000000000058d8ebeb076584bb5853c80111bc06b5ada35463091a6\n>\n> The above base16 block has a fitness score of 1.532  The fitness value for\n> the previous block 639254 is added together:\n>\n>      2.772 = 1.240 + 1.532\n>\n> In this specific case, no other solution has been broadcast for block\n> height 639255 - putting the weaker branch in the lead.  If the weaker\n> branch is sufficiently lucky, and finds a solution before the dominant\n> branch then this solution will have a higher overall fitness score, and\n> this solution will propagate as it has the higher value.  This is also\n> important for transactions on the network as they benefit from using the\n> most recently formed block - which will have the highest local fitness\n> score at the time of its discovery.  At this junction, the weaker branch\n> has an opportunity to prevail enterally thus ending the split.\n>\n> Now let us return to the DoS threat model and explore the worst-case\n> scenario created by byzantine fault injection. Let us assume that both the\n> weaker group and the dominant group have produced competing proof-of-work\n> solutions for blocks 639254 and 639255 respectively.  Let\u2019s assume that the\n> dominant group that went with the 1.847 fitness score - also produces a\n> solution with a similar fitness value and advertises the following solution\n> to the network:\n>\n> 0000000000000000000455207e375bf1dac0d483a7442239f1ef2c70d050c113\n>\n> 19.414973649464574877549198290879237036867705594421756179\n>\n> or\n>\n> 3.262 = 1.847 + 1.415\n>\n> A total of 3.262 is still dominant over the lesser 2.772 - in order to\n> overcome this - the 2nd winning block needs to make up for all of the\n> losses in the previous block.  In this scenario, in order for the weaker\n> chain to supplant the dominant chain it must overcome a -0.49 point\n> deficit. In traditional Nakamoto Consensus the nodes would see both forks\n> as authoritative equals which creates a divide in mining capacity while two\n> groups of miners search for the next block.  In Floating-Point Nakamoto\n> Consensus any nodes receiving both forks, would prefer to mine on the chain\n> with an overall fitness score of +3.262 - making it even harder for the\n> weaker chain to find miners to compete in any future disagreement, thereby\n> eroding support for the weaker chain. This kind of comparison requires an\n> empirical method for determining fitness by miners following the same same\n> system of rules will insure a self-fulfilled outcome.  After all nodes\n> adopt the dominant chain normal Nakamoto Consuess can resume without having\n> to take into consideration block fitness. This example shows how\n> disagreement can be resolved more quickly if the network has a mechanism to\n> resolve ambiguity and de-incentivise dissent.\n> Soft Fork\n>\n> Blockchain networks that would like to improve the consensus generation\n> method by adding a fitness test should be able to do so using a \u201cSoft Fork\u201d\n> otherwise known as a compatible software update.  By contrast a \u201cHard-Fork\u201d\n> is a separate incompatible network that does not form the same consensus.\n> Floating-Point Nakamoto Consensus can be implemented as a soft-fork because\n> both patched, and non-patched nodes can co-exist and non-patched nodes will\n> benefit from a kind of herd immunity in overall network stability.  This is\n> because once a small number of nodes start following the same rules then\n> they will become the deciding factor in which chain is chosen.  Clients\n> that are using only traditional Nakamoto Consensus will still agree with\n> new clients over the total chain length. Miners that adopt the new strategy\n> early, will be less likely to lose out on mining invalid solutions.\n> Conclusion\n>\n> Floating-Point Nakamoto consensus allows the network to form a consensus\n> more quickly by avoiding ambiguity allowing for determinism to take hold.\n> Bitcoin has become an essential utility, and attacks against our networks\n> must be avoided and adapting, patching and protecting the network is a\n> constant effort. An organized attack against a cryptocurrency network will\n> undermine the guarantees that blockchain developers are depending on.\n>\n> Any blockchain using Nakamoto Consensus can be modified to use a fitness\n> constraint such as the one used by a Floating-Point Nakamoto Consensus.  An\n> example implementation has been written and submitted as a PR to the\n> bitcoin core which is free to be adapted by other networks.\n>\n>\n>\n>\n>\n> A complete implementation of Floating-Point Nakamoto consensus is in the\n> following pull request:\n>\n> https://github.com/bitcoin/bitcoin/pull/19665/files\n>\n> Paper:\n>\n> https://github.com/in-st/Floating-Point-Nakamoto-Consensus\n>\n> https://in.st.capital\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing listbitcoin-dev at lists.linuxfoundation.orghttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200925/cf4f40e6/attachment-0001.html>"
            },
            {
                "author": "Jeremy",
                "date": "2020-09-25T16:33:14",
                "message_text_only": "If I understand correctly, this is purely a policy level decision to accept\nfirst-seen or a secondary deterministic test, but the most-work chain is\nstill always better than a \"more fit\" but less work chain.\n\nIn any case, I'm skeptical of the properties of this change. First-seen has\na nice property that once you receive a block, you have a substantially\nreduced incentive to try to orphan it because the rest of the network is\ngoing to work on building on that block. With fitness, I have a 50% shot if\nI mine a block of mine being accepted, so floating point would have the\neffect of destabilizing consensus convergence at the tip.\n\nI could see using a fitness rule like this be useful if you see both blocks\nwithin some very small window, e.g., 10 seconds, as it could decrease\npartition risk if it's likely the orphan was mined within close range of\nthe other.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200925/ca799f49/attachment.html>"
            },
            {
                "author": "Mike Brooks",
                "date": "2020-09-25T17:35:36",
                "message_text_only": "Hey Jeremy,\n\nThanks for your response, but I think you misunderstood a crucial feature\n-  with a fitness test you have a 100% chance of a new block from being\naccepted, and only a 50% or less chance for replacing a block which has\nalready been mined.   This is all about keeping incentives moving forward.\n\n\"First seen\" was easy to implement, but has a few undesirable attributes.\n One of the big problems is that I don't think it is fair to allow for a\nminer to ignore a solution block and still have an unpenalized opportunity\nto replace it - this is very much possible with the first scene and an\neclipse of the network to dictate which solution will be seen first by\naffected nodes.   Making it more expensive to replace hard work instead of\ncontributing to new work is a useful feature for stability.  Eclipsing\nallows the attacker to make sure that one solution will be seen before\nanother - but this race condition is resolved uniformly if we have a\nfitness test.\n\nBut let's dig into this topic more.  What would actually lead to\n\"thrashing\" or unnecessary replacement of the tip?  A malicious miner who\nhas observed the creation of a new block and intends to replace it - would\nhave to exceed the work needed to generate a new block - and crucially will\nhave less time to perform this task than the entire network as whole.\nFitness introduces a neat boundary, whereby it is always cheaper to make a\nnew block than replace the existing block - which means it would take at\nleast a 51% attack to overcome this attribute.   That being said, without\nthis feature - less than 51% is needed when you have miners that will work\nfor you for free.\n\n-Mike\n\n\n\nOn Fri, Sep 25, 2020 at 9:33 AM Jeremy via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> If I understand correctly, this is purely a policy level decision to\n> accept first-seen or a secondary deterministic test, but the most-work\n> chain is still always better than a \"more fit\" but less work chain.\n>\n> In any case, I'm skeptical of the properties of this change. First-seen\n> has a nice property that once you receive a block, you have a substantially\n> reduced incentive to try to orphan it because the rest of the network is\n> going to work on building on that block. With fitness, I have a 50% shot if\n> I mine a block of mine being accepted, so floating point would have the\n> effect of destabilizing consensus convergence at the tip.\n>\n> I could see using a fitness rule like this be useful if you see both\n> blocks within some very small window, e.g., 10 seconds, as it could\n> decrease partition risk if it's likely the orphan was mined within close\n> range of the other.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200925/973ca305/attachment.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2020-09-26T10:11:23",
                "message_text_only": "On Fri, Sep 25, 2020 at 10:35:36AM -0700, Mike Brooks via bitcoin-dev wrote:\n> -  with a fitness test you have a 100% chance of a new block from being\n> accepted, and only a 50% or less chance for replacing a block which has\n> already been mined.   This is all about keeping incentives moving forward.\n\nFYI, I think this topic has been discussed on the list before (in\nresponse to the selfish mining paper).  See this proposal:\n\n  https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2013-November/003583.html\n\nOf its responses, I thought these two stood out in particular:\n\n  https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2013-November/003584.html\n  https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2013-November/003588.html\n\nI think there may be some related contemporary discussion from\nBitcoinTalk as well; here's a post that's not directly related to the\nidea of using hash values but which does describe some of the challenges\nin replacing first seen as the tip disambiguation method.  There may be\nother useful posts in that thread---I didn't take the time to skim all\n11 pages.\n\n  https://bitcointalk.org/index.php?topic=324413.msg3476697#msg3476697\n\n-Dave\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200926/f62b4394/attachment.sig>"
            },
            {
                "author": "Mike Brooks",
                "date": "2020-09-26T11:09:23",
                "message_text_only": "Very interesting find - there are similarities here, but this is hardly\nidentical.\n\n>\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2013-November/003584.html\n\nI am largely in agreement with Quinn (from 2013) - simply using the lowest\nblock value was a bad idea because the value cannot be carried forward to\nresolve disagreements greater than N+1. Simply picking a lower value in big\nedian is a nieve approach to disagreement resolution that would result in\ntrashing. I thought of this before writing the paper, and then thought\nbetter of it.\n\nThe zero-prefix component can be thought of driving a lower numeric value\nin big-edian which is the verifiable proof-of-work we know to expect.  The\nremaining value could be minimized or maximized in any edeness - so long as\nit is consistent - but more importantly the winner needs to be ahead of the\nrace for the next block, and we need to add a mechanism by which to make it\nmore expencive to replace an existing block than producing a new block -\nall three components solve the issue at hand, cutting one of these out\nisn't a complete answer.\n\nAs to Quinn's point - I don't think it should be random.  The miner's\nchoice of picking the most fit soluton means the any future children of the\nwinning solution will also be further ahead.  \"Survival of the fittest\"\nblock -  The winners have the home field advantage of being in the lead for\nthe next round - and any miners that disagree are fools to start from a\nstarting line that is further behind.\n\nThe difference between the 2013 post and FPNC is the alignment of\nincentives.\n\n-Mike\n\n\nOn Sat, Sep 26, 2020, 3:12 AM David A. Harding <dave at dtrt.org> wrote:\n\n> On Fri, Sep 25, 2020 at 10:35:36AM -0700, Mike Brooks via bitcoin-dev\n> wrote:\n> > -  with a fitness test you have a 100% chance of a new block from being\n> > accepted, and only a 50% or less chance for replacing a block which has\n> > already been mined.   This is all about keeping incentives moving\n> forward.\n>\n> FYI, I think this topic has been discussed on the list before (in\n> response to the selfish mining paper).  See this proposal:\n>\n>\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2013-November/003583.html\n>\n> Of its responses, I thought these two stood out in particular:\n>\n>\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2013-November/003584.html\n>\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2013-November/003588.html\n>\n> I think there may be some related contemporary discussion from\n> BitcoinTalk as well; here's a post that's not directly related to the\n> idea of using hash values but which does describe some of the challenges\n> in replacing first seen as the tip disambiguation method.  There may be\n> other useful posts in that thread---I didn't take the time to skim all\n> 11 pages.\n>\n>   https://bitcointalk.org/index.php?topic=324413.msg3476697#msg3476697\n>\n> -Dave\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200926/cf39ae2d/attachment-0001.html>"
            },
            {
                "author": "Franck Royer",
                "date": "2020-09-29T01:51:03",
                "message_text_only": "On Fri, 25 Sep 2020 at 22:09, Mike Brooks via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n[snip]\n\n> The solution above also has 19 prefixed zeros, and is being broadcast for\n> the same blockheight value of 639254 - and a fitness score of 1.282.  With\n> Nakamoto Consensus both of these solutions would be equivalent and a given\n> node would adopt the one that it received first.  In Floating-Post Nakamoto\n> Consensus, we compare the fitness scores and keep the highest.  In this\n> case no matter what happens - some nodes will have to change their tip and\n> a fitness test makes sure this happens immediately.\n>\n\nHi Mike,\n\nAny reason why you decided to consider the higher value the \"fittest\" one\ninstead of keeping in line with the difficulty algorithm where smallest\nvalues, prefixed with more zeroes, are considered more valuable/difficult?\n\nAlso, can you elaborate if anything special would happen if the competitive\nchains were created around a difficulty adjustment?\n\nCheers, Franck\n\n[snip]\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200929/0ab39abc/attachment.html>"
            },
            {
                "author": "Mike Brooks",
                "date": "2020-09-29T16:00:12",
                "message_text_only": "Hey Frank,\n\nFirstly, I must commend you on two very good questions.\n\nThe reason why I chose to maximize the value is because I approached this\nas an optimization problem to be solved with a genetic algorithm, and it\nfit with my internal model of a kind of relay race that moves forward\nfaster. When confronted with the paradox of one side of the solution being\nminimized and the other being maximized I thought to myself that a paradox\nleading to determinism was beautiful... But it doesn't have to be this way.\n\nPart 2 of your question - what about the inevitable march of difficulty?\nAnd here is where how we quantify fitness starts to matter.  Your right to\npoint this out condition, maximizing the non-zero value means that re-org\nduring an epoch won't optimize for having a trailing zero, which is a\nconflict that I see now must be avoided.\n\nThe solution is to always choose the smallest, and the summation of all\ncontestant chains must also be minimized. This approach would then be\ncompatible with an Epoch - so much so that it would not impeed the use of a\ncontinuous difficulty function that pegs a solution at a range of non-zero\nvalues which would avoid a discrete cliff by requiring a whole extra zero.\nWe need not be a victim of an early implementation - a continuous\ndifficulty function would add stability to the network and this is worth\nunlocking.\n\nWith added determinism and a continuous epoch, the network will be a lot\nmore stable.  At this point very little is stopping us from speeding up\nblock creation times. PoS networks are proving that conformations can be a\nminute or less - why not allow for a block formation time that is 6 or 12\ntimes faster than the current target and have 1/6th (or 1/12th) of the\nsubsidy to keep an identical inflation target.\n\n\u2026 The really interesting part is the doors that this patch opens. Bitcoin\nis the best network, we have the most miners and we as developers have the\nopportunity to build an even better system - all with incremental\nsoft-forks - which is so exciting.\n\nWhat I am proposing is a patch that is ~100 lines of code and is fully\ncompatible with the current Bitcoin network - because I am running a node\nwith my changes on the network, and the more miners who adopt my patch the\nmore lucky we will become.\n\nThank you everyone,\n\nMike\n\n\nOn Mon, Sep 28, 2020, 7:18 PM Franck Royer via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> On Fri, 25 Sep 2020 at 22:09, Mike Brooks via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> [snip]\n>\n>> The solution above also has 19 prefixed zeros, and is being broadcast for\n>> the same blockheight value of 639254 - and a fitness score of 1.282.  With\n>> Nakamoto Consensus both of these solutions would be equivalent and a given\n>> node would adopt the one that it received first.  In Floating-Post Nakamoto\n>> Consensus, we compare the fitness scores and keep the highest.  In this\n>> case no matter what happens - some nodes will have to change their tip and\n>> a fitness test makes sure this happens immediately.\n>>\n>\n> Hi Mike,\n>\n> Any reason why you decided to consider the higher value the \"fittest\" one\n> instead of keeping in line with the difficulty algorithm where smallest\n> values, prefixed with more zeroes, are considered more valuable/difficult?\n>\n> Also, can you elaborate if anything special would happen if the\n> competitive chains were created around a difficulty adjustment?\n>\n> Cheers, Franck\n>\n> [snip]\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200929/bfc7b2ee/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-09-30T06:31:41",
                "message_text_only": ">\u00a0 At this point very little is stopping us from speeding up block creation times. PoS networks are proving that conformations can be a minute or less - why not allow for a block formation time that is 6 or 12 times faster than the current target and have 1/6th (or 1/12th) of the subsidy to keep an identical inflation target.\n\nWhat?\n\nThat is surprising information to me.\n\nMy understanding is that speeding up block creation times is highly risky due to increasing the tendency to \"race\" in mining.\n\nThe average time to propagate to all miners should be negligible to the average inter-block time.\nEfforts like compact blocks and FIBRE already work at the very edges of our capability to keep the propagation time negligible.\n\nIndeed, looking forward, part of my plans for Earth-based civilization involves sending out hapless humans into space and forcing them to survive there, thus the inter-block time may need to be *increased* in consideration of interplanetary communications times, otherwise Bitcoin would dangerously centralize around Earth, potentially leading to the Universal Century and awesome giant robot battles.\n\n(Hmmm, on the one hand, centralizing around Earth is dangerous, on the other hand, giant robots, hmmm)\n\n\"PoS\" networks mean nothing, as most of them are not global in the scale that Bitcoin is, and all of them have a very different block discovery model from proof-of-work.\nIn particular, I believe there is no \"racing\" involved in most PoS schemes in practice.\n\n>\n> \u2026 The really interesting part is the doors that this patch opens. Bitcoin is the best network, we have the most miners and we as developers have the opportunity to build an even better system - all with incremental soft-forks - which is so exciting.\n\nChanging inter-block times is not possible as a softfork, unless you are planning to (ab)use the timewarp bug, which I believe was proposed by maaku7 before.\nMy understanding is that the preferred approach would be to close the timewarp bug, in which case increasing the block rate would not be doable as a softfork anymore.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Mike Brooks",
                "date": "2020-09-30T06:37:47",
                "message_text_only": "ZmnSCPxj,\n\nNo, it would be better to use parachains for Mars.\n\n-Mike Brooks\n\nOn Tue, Sep 29, 2020, 11:31 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n>\n> >  At this point very little is stopping us from speeding up block\n> creation times. PoS networks are proving that conformations can be a minute\n> or less - why not allow for a block formation time that is 6 or 12 times\n> faster than the current target and have 1/6th (or 1/12th) of the subsidy to\n> keep an identical inflation target.\n>\n> What?\n>\n> That is surprising information to me.\n>\n> My understanding is that speeding up block creation times is highly risky\n> due to increasing the tendency to \"race\" in mining.\n>\n> The average time to propagate to all miners should be negligible to the\n> average inter-block time.\n> Efforts like compact blocks and FIBRE already work at the very edges of\n> our capability to keep the propagation time negligible.\n>\n> Indeed, looking forward, part of my plans for Earth-based civilization\n> involves sending out hapless humans into space and forcing them to survive\n> there, thus the inter-block time may need to be *increased* in\n> consideration of interplanetary communications times, otherwise Bitcoin\n> would dangerously centralize around Earth, potentially leading to the\n> Universal Century and awesome giant robot battles.\n>\n> (Hmmm, on the one hand, centralizing around Earth is dangerous, on the\n> other hand, giant robots, hmmm)\n>\n> \"PoS\" networks mean nothing, as most of them are not global in the scale\n> that Bitcoin is, and all of them have a very different block discovery\n> model from proof-of-work.\n> In particular, I believe there is no \"racing\" involved in most PoS schemes\n> in practice.\n>\n> >\n> > \u2026 The really interesting part is the doors that this patch opens.\n> Bitcoin is the best network, we have the most miners and we as developers\n> have the opportunity to build an even better system - all with incremental\n> soft-forks - which is so exciting.\n>\n> Changing inter-block times is not possible as a softfork, unless you are\n> planning to (ab)use the timewarp bug, which I believe was proposed by\n> maaku7 before.\n> My understanding is that the preferred approach would be to close the\n> timewarp bug, in which case increasing the block rate would not be doable\n> as a softfork anymore.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200929/99703402/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-09-30T23:44:59",
                "message_text_only": "Good morning Mike,\n\nAn observation to be made is that the current \"first seen\" is more incentive-compatible than floating-point Nakamoto consensus.\n\nIf a miner A mines a block at height N, then obviously the first block it has seen is that block.\n\nIf due to propagation delays on the network, another miner B mines an alternative block (let us say with more fitness score, regardless of the details of the fitness metric you use) at height N, miner A has no incentive to reject its own version of that block and mine on top of the miner B alternative version, even if floating-point Nakamoto consensus is deployed by most nodes.\n\nEven if the rest of the mining network is now mining on top of the miner B version, if miner A chances on another new block at N+1 built on top of its own version of block N, then it would still win both blocks and earn the block subsidy and fees of two blocks.\nAnd since block height, as I understand it, trumps over floating-point Nakamoto consensus, the B version will be reorganized out anyway in that case.\nIf miner A had switched to mining on top of the miner B block, then if it won another block at height N+1, it would have lost the block subsidy+fees of the lower-scoring miner A block at height N.\n\n\nThus, floating-point Nakamoto consensus is not incentive-compatible, so I doubt it would have any kind of adoption.\n\n\nThe problems with stability you mention can be fixed, fairly trivially, by simply waiting for 3 confirmations rather than just 1 confirmation.\n\n\nIn a relativistic universe, information cannot propagate faster than light-speed, and thus there will always be a communications network delay in propagating data.\nAs I see it, floating-point Nakamoto consensus cannot fix this issue, as it cannot change underlying laws of the universe.\n\nIf your goal is \"stability\" of some kind, then there is still always a possibility that two miners on opposite sides of the Earth will create blocks at the same height outside of the light cones of each other.\nIn a relativistic universe, this cannot be eliminated unless all miners occupy the same physical location, i.e. have centralized in the same mining hardware.\n\nOne of those two blocks created will, with high probability, have a lower score, and thus any nodes in the light cone of the miner of the lower-scored block will still experience a reorg, as they will first see one block, then switch to the higher-scored block when it arrives to them.\n\nThus, floating-point Nakamoto consensus cannot provide complete stability of the network, still, as the universe we operate in does not have instantaneous information transfer.\n\nA wise designer of automated systems will ***still*** wait for 3 confirmations before doing anything, and by then, the effects of floating-point Nakamoto consensus will be literally a thing of the past.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Mike Brooks",
                "date": "2020-09-30T23:53:25",
                "message_text_only": "ZmnSCPxj,\n\nThe growing tare in growing disagreement continues to divide mining\ncapacity while the network waits for formation of future blocks - you'll\nnever get to complete consensus unless three is a way to avoid ambiguity\nin disagreement, which you have not addressed.  The topic of my discussion\nis an exploitable condition, your three block plan does not add up.\n\nI wrote the exploit before I wrote the paper. It is telling that still no\none here has refenced the threat model, which is the largest section of the\nentire 8 page paper.  The security came before the introduction of FPNC\nbecause security fundamentals is what drives the necessity for the solution.\n\nThe text you are reading right now was delivered using the mailing list\nmanager Majordomo2, which I shelled in 2011\n<http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2011-0049> and got a\nseverity metric and an alert in the DHS newsletter. Correct me if I am\nwrong, but I bet that just of my exploits has probably popped more shells\n<https://www.theregister.com/2010/05/11/phpnuke_infection_purged/> than\neveryone on this thread combined.   Cryptography?  Sure, I'll brag about\nthe time I hacked Square Inc. This is actually my current favorite crypto\nexploit \u2014 it was the time I used DKIM signature-malleability to conduct a\nreplay-attack that allowed an adversary to replay another user's\ntransactions an unlimited number of times. After receiving a normal payment\nfrom another Square user you could empty their account.  This was reported\nethically and it was a mutual joy to work with such a great team.  Now it\nis not just impact, but I am also getting the feeling that I have collected\nmore CVEs, all this is to say that I'm not new to difficult vendors.\n\nTo be blunt; some of you on this thread are behaving like a virgin reading\na trashy love novel and failing to see the point \u2014 Just because you aren't\nexcited, doesn't mean that it isn't hot.\n\nThe exploit described in this paper was delivered to the Bitcoin-core\nsecurity team on August 4 at 9:36 PM PST.  The industry standard of 90 days\ngives you until November 2nd. Now clearly, we need more time. However, if\nthe consensus is a rejection, then there shouldn't be any concerns with a\nsensible 90-day disclosure policy.\n\nRegards,\nMike Brooks\n\nOn Wed, Sep 30, 2020, 4:45 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Mike,\n>\n> An observation to be made is that the current \"first seen\" is more\n> incentive-compatible than floating-point Nakamoto consensus.\n>\n> If a miner A mines a block at height N, then obviously the first block it\n> has seen is that block.\n>\n> If due to propagation delays on the network, another miner B mines an\n> alternative block (let us say with more fitness score, regardless of the\n> details of the fitness metric you use) at height N, miner A has no\n> incentive to reject its own version of that block and mine on top of the\n> miner B alternative version, even if floating-point Nakamoto consensus is\n> deployed by most nodes.\n>\n> Even if the rest of the mining network is now mining on top of the miner B\n> version, if miner A chances on another new block at N+1 built on top of its\n> own version of block N, then it would still win both blocks and earn the\n> block subsidy and fees of two blocks.\n> And since block height, as I understand it, trumps over floating-point\n> Nakamoto consensus, the B version will be reorganized out anyway in that\n> case.\n> If miner A had switched to mining on top of the miner B block, then if it\n> won another block at height N+1, it would have lost the block subsidy+fees\n> of the lower-scoring miner A block at height N.\n>\n>\n> Thus, floating-point Nakamoto consensus is not incentive-compatible, so I\n> doubt it would have any kind of adoption.\n>\n>\n> The problems with stability you mention can be fixed, fairly trivially, by\n> simply waiting for 3 confirmations rather than just 1 confirmation.\n>\n>\n> In a relativistic universe, information cannot propagate faster than\n> light-speed, and thus there will always be a communications network delay\n> in propagating data.\n> As I see it, floating-point Nakamoto consensus cannot fix this issue, as\n> it cannot change underlying laws of the universe.\n>\n> If your goal is \"stability\" of some kind, then there is still always a\n> possibility that two miners on opposite sides of the Earth will create\n> blocks at the same height outside of the light cones of each other.\n> In a relativistic universe, this cannot be eliminated unless all miners\n> occupy the same physical location, i.e. have centralized in the same mining\n> hardware.\n>\n> One of those two blocks created will, with high probability, have a lower\n> score, and thus any nodes in the light cone of the miner of the\n> lower-scored block will still experience a reorg, as they will first see\n> one block, then switch to the higher-scored block when it arrives to them.\n>\n> Thus, floating-point Nakamoto consensus cannot provide complete stability\n> of the network, still, as the universe we operate in does not have\n> instantaneous information transfer.\n>\n> A wise designer of automated systems will ***still*** wait for 3\n> confirmations before doing anything, and by then, the effects of\n> floating-point Nakamoto consensus will be literally a thing of the past.\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200930/a718e8a2/attachment-0001.html>"
            },
            {
                "author": "LORD HIS EXCELLENCY JAMES HRMH",
                "date": "2020-09-29T03:10:36",
                "message_text_only": "Good Afternoon,\n\nRe: [bitcoin-dev] Floating-Point Nakamoto Consensus\n\nI note that the discussion thread for this proposal has previously received HARD_NAK\n\nI note in the whitepaper the following basic introduction of need:\n>As a result anode will simply adopt the first solution seen, creating a kind of race condition.\n\nThe said race condition, it is not noted, is 'self-resolving' with the network adopting the longest chain with the highest proof of work as any contentious tip is built on. This is the proper reason for waiting for two confirmations for a transaction as a minimum proof of its inclusion in the blockchain (without fraud), and for waiting for six confirmations before considering that a transaction is 'final'.\n\nI take it that your work is intended to allow the network to decide immediately without waiting for a chain to be further extended, in that case, the solution should be as noted elsewhere to accept the higher proof of work with the greater precision proof. When comparing two competing blocks there is an indirect reference to a higher proof of work due to the greater precision in the block hash, although the answer could have been arrived with fewer attempts. As it is, the total proof of work is not directly calculated but is evaluated as the chain with more blocks being the chain with more proof-of-work, whereas in the cases two blocks are received as alternates extending the same chain tip there is currently no method of comparison to determine which of the blocks, and the correct tip is not chosen without further proof-of-work to extend a tip. Resolving this reduces the network expense of reorganisation in ordinary conditions but in the case of a network-split resolves nothing.\n\nKING JAMES HRMH\nGreat British Empire\n\nRegards,\nThe Australian\nLORD HIS EXCELLENCY JAMES HRMH (& HMRH)\nof Hougun Manor & Glencoe & British Empire\nMR. Damian A. James Williamson\nWills\n\net al.\n\n\nWilltech\nwww.willtech.com.au\nwww.go-overt.com\nand other projects\n\nearn.com/willtech\nlinkedin.com/in/damianwilliamson\n\n\nm. 0487135719\nf. 61261470192\n\n\n----\n________________________________\nFrom: bitcoin-dev <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Mike Brooks via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Friday, 25 September 2020 5:40 AM\nTo: bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSubject: [bitcoin-dev] Floating-Point Nakamoto Consensus\n\n  Hey Everyone,\n\n A lot of work has gone into this paper, and the current revision has been well received and there is a lot of excitement on this side to be sharing it with you today. There are so few people that truly understand this topic, but we are all pulling in the same direction to make Bitcoin better and it shows.  It is wildly underrated that future proofing was never really a consideration in the initial design - but here we are a decade later with amazing solutions like SegWit which gives us a real future-proofing framework.  The fact that future-proofing was added to Bitcoin with a softfork gives me goosebumps. I'd just like to take the time to thank the people who worked on SegWit and it is an appreciation that comes up in conversation of how difficult and necessary that process was, and this appreciation may not be vocalized to the great people who worked on it. The fact that Bitcoin keeps improving and is able to respond to new threats is nothing short of amazing - thank you everyone for a great project.\n\nThis current proposal really has nothing to do with SegWit - but it is an update that will make the network a little better for the future, and we hope you enjoy the paper.\n\nPDF:\nhttps://github.com/in-st/Floating-Point-Nakamoto-Consensus/blob/master/Floating-Point%20Nakamoto%20Consensus.pdf\n\nPull Request:\nhttps://github.com/bitcoin/bitcoin/pull/19665/files\n\n---\n\n\n\nFloating-Point Nakamoto Consensus\n\n\nAbstract \u2014 It has been shown that Nakamoto Consensus is very useful in the formation of long-term global agreement \u2014 and has issues with short-term disagreement which can lead to re-organization (\u201cor-org\u201d) of the blockchain.  A malicious miner with knowledge of a specific kind of denial-of-service (DoS) vulnerability can gain an unfair advantage in the current Bitcoin network, and can be used to undermine the security guarantees that developers rely upon.  Floating-Point Nakamoto consensu makes it more expensive to replace an already mined block vs. creation of a new block, and by resolving ambiguity of competition solutions it helps achieve global consumers more quickly.  A floating-point fitness test strongly incentivises the correct network behavior, and prevents disagreement from ever forming in the first place.\n\nIntroduction\n\nThe Bitcoin protocol was created to provide a decentralized consensus on a fully distributed p2p network.  A problem arises when more than one proof-of-work is presented as the next solution block in the blockchain.  Two solutions of the same height are seen as authoritative equals which is the basis of a growing disagreement. A node will adopt the first solution seen, as both solutions propagate across the network a race condition of disagreement is formed. This race condition can be controlled by byzentiene fault injection commonly referred to as an \u201ceclipsing\u201d attack.  When two segments of the network disagree it creates a moment of weakness in which less than 51% of the network\u2019s computational resources are required to keep the network balanced against itself.\n\nNakamoto Consensus\n\nNakamoto Consensus is the process of proving computational resources in order to determine eligibility to participate in the decision making process.  If the outcome of an election were based on one node (or one-IP-address-one-vote), then representation could be subverted by anyone able to allocate many IPs. A consensus is only formed when the prevailing decision has the greatest proof-of-work effort invested in it. In order for a Nakamoto Consensus to operate, the network must ensure that incentives are aligned such that the resources needed to subvert a proof-of-work based consensus outweigh the resources gained through its exploitation. In this consensus model, the proof-of-work requirements for the creation of the next valid solution has the exact same cost as replacing the current solution. There is no penalty for dishonesty, and this has worked well in practice because the majority of the nodes on the network are honest and transparent, which is a substantial barrier for a single dishonest node to overcome.\n\n\nA minimal network peer-to-peer structure is required to support Nakamoto Conesus, and for our purposes this is entirely decentralized. Messages are broadcast on a best-effort basis, and nodes can leave and rejoin the network at will, accepting the longest proof-of-work chain as proof of what happened while they were gone.  This design makes no guarantees that the peers connected do not misrepresent the network or so called \u201cdishonest nodes.\u201d Without a central authority or central view - all peers depend on the data provided by neighboring peers - therefore a dishonest node can continue until a peer is able to make contact an honest node.\n\nSecurity\n\nIn this threat model let us assume a malicious miner possesses knowledge of an unpatched DoS vulnerability (\u201c0-day\u201d) which will strictly prevent honest nodes from communicating to new members of the network - a so-called \u201ctotal eclipse.\u201d  The kind of DoS vulnerability needed to conduct an eclipse does not need to consume all CPU or computaitly ability of target nodes - but rather prevent target nodes from forming new connections that would undermine the eclipsing effect. These kinds of DoS vulnerabilities are somewhat less substional than actually knocking a powerful-mining node offline.  This class of attacks are valuable to an adversary because in order for an honest node to prove that a dishonest node is lying - they would need to form a connection to a segment of the network that isn\u2019t entirely suppressed. Let us assume a defense-in-depth strategy and plan on this kind of failure.\n\n\nLet us now consider that the C++ Bitcoind has a finite number of worker threads and a finite number of connections that can be serviced by these workers.  When a rude client occupies all connections - then a pidgin-hole principle comes into play. If a network's maximum capacity for connection handlers \u2018k\u2019, is the sum of all available worker threads for all nodes in the network, establishing \u2018k+1\u2019 connections by the pidgin-hole principle will prevent any new connections from being formed by honest nodes - thereby creating a perfect eclipse for any new miners joining the network would only be able to form connections with dishonest nodes.\n\n\nNow let\u2019s assume a dishonest node is modified in two ways - it increases the maximum connection handles to hundreds of thousands instead of the current value which is about 10. Then this node is modified to ignore any solution blocks found by honest nodes - thus forcing the dishonest side of the network to keep searching for a competitive-solution to split the network in two sides that disagree about which tip of the chain to use.  Any new solution propagates through nodes one hop at a time. This propagation can be predicted and shaped by dishonest non-voting nodes that are being used to pass messages for honest nodes.\n\n\nAt this point an attacker can expedite the transmission of one solution, while slowing another. If ever a competing proof-of-work is broadcasted to the network, the adversary will use their network influence to split knowledge of the proof-of-work as close to \u00bd as possible. If the network eclipse is perfect then an adversary can leverage an eigen-vector of computational effort to keep the disagreement in balance for as long as it is needed. No mechanism is stopping the attacker from adding additional computation resources or adjusting the eclipsing effect to make sure the system is in balance.   As long as two sides of the network are perfectly in disagreement and generating new blocks - the attacker has intentionally created a hard-fork against the will of the network architects and operators. The disagreement needs to be kept open until the adversary\u2019s transactions have been validated on the honest chain - at which point the attacker will add more nodes to the dishonest chain to make sure it is the ultimate winner - thus replacing out the honest chain with the one generated by dishonest miners.\n\n\nThis attack is convenient from the adversary\u2019s perspective,  Bitcoin being a broadcast network advertises the IP addresses of all active nodes - and Shodan and the internet scanning project can find all passive nodes responding on TCP 8333.  This should illuminate all honest nodes on the network, and even honest nodes that are trying to obscure themselves by not announcing their presence.  This means that the attacker doesn\u2019t need to know exactly which node is used by a targeted exchange - if the attacker has subdued all nodes then the targeted exchange must be operating a node within this set of targeted honest nodes.\n\n\nDuring a split in the blockchain, each side of the network will honor a separate merkel-tree formation and therefore a separate ledger of transactions. An adversary will then broadcast currency deposits to public exchanges, but only on the weaker side, leaving the stronger side with no transaction from the adversary. Any exchange that confirms one of these deposits is relying upon nodes that have been entirely eclipsed so that they cannot see the competing chain - at this point anyone looking to confirm a transaction is vulnerable to a double-spend. With this currency deposited on a chain that will become ephemeral, the attacker can wire out the account balance on a different blockchain - such as Tether which is an erc20 token on the Ethereum network which would be unaffected by this attack.  When the weaker chain collapses, the transaction that the exchange acted upon is no longer codified in Bitcoin blockchain's global ledger, and will be replaced with a version of the that did not contain these deposits.\n\n\nNakamoto Consensus holds no guarantees that it\u2019s process is deterministic.  In the short term, we can observe that the Nakamoto Consensus is empirically non-deterministic which is evident by re-organizations (re-org) as a method of resolving disagreements within the network.   During a reorganization a blockchain network is at its weakest point, and a 51% attack to take the network becomes unnecessary. An adversary who can eclipse honest hosts on the network can use this as a means of byzantine fault-injection to disrupt the normal flow of messages on the network which creates disagreement between miners.\n\n\nDeFi (Decentralized Finance) and smart-contract obligations depend on network stability and determinism.  Failure to pay contracts, such as what happened on \u201cblack thursday\u201d resulted in secured loans accidentally falling into redemption.  The transactions used by a smart contract are intended to be completed quickly and the outcome is irreversible.  However, if the blockchain network has split then a contract may fire and have it\u2019s side-effects execute only to have the transaction on the ledger to be replaced.  Another example is that a hard-fork might cause the payer of a smart contract to default - as the transaction that they broadcasted ended up being on the weaker chain that lost. Some smart contracts, such as collateral backed loans have a redemption clause which would force the borrower on the loan to lose their deposit entirely.\n\n\nWith two sides of the network balanced against each other - an attacker has split the blockchain and this hard-fork can last for as long as the attacker is able to exert the computational power to ensure that proof-of-work blocks are regularly found on both sides of the network.  The amount of resources needed to balance the network against itself is far less than a 51% attack - thereby undermining the security guarantees needed for a decentralized untrusted payment network to function.  An adversary with a sufficiently large network of dishonest bots could use this to take a tally of which miners are participating in which side of the network split. This will create an attacker-controlled hard fork of the network with two mutually exclusive merkle trees. Whereby the duration of this split is arbitrary, and the decision in which chain to collapse is up to the individual with the most IP address, not the most computation.\n\n\nIn Satoshi Nakamoto\u2019s original paper it was stated that the electorate should be represented by computational effort in the form of a proof-of-work, and only these nodes can participate in the consues process.  However, the electorate can be misled by non-voting nodes which can reshape the network to benefit an individual adversary.\n\nChain Fitness\n\nAny solution to byzantine fault-injection or the intentional formation of disagreements must be fully decentralized. A blockchain is allowed to split because there is ambiguity in the Nakamoto proof-of-work, which creates the environment for a race-condition to form. To resolve this, Floating-Point Nakamoto Consensus makes it increasingly more expensive to replace the current winning block. This added cost comes from a method of disagreement resolution where not every solution block is the same value, and a more-fit solution is always chosen over a weaker solution. Any adversary attempting to have a weaker chain to win out would have to overcome a kind of relay-race, whereby the winning team\u2019s strength is carried forward and the loser will have to work harder and harder to maintain the disagreement.  In most cases Floating-Point Nakamoto Consensus will prevent a re-org blockchain from ever going past a single block thereby expediting the formation of a global consensus.  Floating-Point Nakamoto Consensus cements the lead of the winner and to greatly incentivize the network to adopt the dominant chain no matter how many valid solutions are advertised, or what order they arrive.\n\n\nThe first step in Floating-Point Nakamoto Consensus is that all nodes in the network should continue to conduct traditional Nakamoto Consensus and the formation of new blocks is dictated by the same zero-prefix proof-of-work requirements.  If at any point there are two solution blocks advertised for the same height - then a floating-point fitness value is calculated and the solution with the higher fitness value is the winner which is then propagated to all neighbors. Any time two solutions are advertised then a re-org is inevitable and it is in the best interest of all miners to adopt the most-fit block, failing to do so risks wasting resources on a mining of a block that would be discarded.  To make sure that incentives are aligned, any zero-prefix proof of work could be the next solution, but now in order to replace the current winning solution an adversary would need a zero-prefix block that is also more fit that the current solution - which is much more computationally expensive to produce.\n\nAny changes to the current tip of the blockchain must be avoided as much as possible. To avoid thrashing between two or more competitive solutions, each replacement can only be done if it is more fit, thereby proving that it has an increased expense.  If at any point two solutions of the same height are found it means that eventually some node will have to replace their tip - and it is better to have it done as quickly as possible so that consensus is maintained.\n\n\nIn order to have a purely decentralized solution, this kind of agreement must be empirically derived from the existing proof-of-work so that it is universally and identically verifiable by all nodes on the network.  Additionally, this fitness-test evaluation needs to ensure that no two competing solutions can be numerically equivalent.\n\n\nLet us suppose that two or more valid solutions will be proposed for the same block.  To weigh the value of a given solution, let's consider a solution for block 639254, in which the following hash was proposed:\n\n    00000000000000000008e33faa94d30cc73aa4fd819e58ce55970e7db82e10f8\n\n\nThere are 19 zeros, and the remaining hash in base 16 starts with 9e3 and ends with f8.  This can value can be represented in floating point as:\n\n    19.847052573336114130069196154809453027792121882588614904\n\n\nTo simplify further lets give this block a single whole number to represent one complete solution, and use a rounded floating-point value to represent some fraction of additional work exerted by the miner.\n\n   1.847\n\n\nNow let us suppose that a few minutes later another solution is advertised to the network shown in base16 below:\n\n    000000000000000000028285ed9bd2c774136af8e8b90ca1bbb0caa36544fbc2\n\n\nThe solution above also has 19 prefixed zeros, and is being broadcast for the same blockheight value of 639254 - and a fitness score of 1.282.  With Nakamoto Consensus both of these solutions would be equivalent and a given node would adopt the one that it received first.  In Floating-Post Nakamoto Consensus, we compare the fitness scores and keep the highest.  In this case no matter what happens - some nodes will have to change their tip and a fitness test makes sure this happens immediately.\n\n\nWith both solutions circulating in the network - any node who has received both proof-of-works should know 1.847 is the current highest value, and shouldn\u2019t need to validate any lower-valued solution.  In fact this fitness value has a high degree of confidence that it won\u2019t be unseated by a larger value - being able to produce a proof-of-work with 19 0\u2019s and a decimal component greater than 0.847 is non-trivial.  As time passes any nodes that received a proof-of-work with a value 1.204 - their view of the network should erode as these nodes adopt the 1.847 version of the blockchain.\n\nAll nodes are incentivized to support the solution with the highest fitness value - irregardless of which order these proof-of-work were validated. Miners are incentivized to support the dominant chain which helps preserve the global consensus.\n\n\nLet us assume that the underlying cryptographic hash-function used to generate a proof-of-work is an ideal primitive, and therefore a node cannot force the outcome of the non-zero component of their proof-of-work.  Additionally if we assume an ideal cipher then the fitness of all possible solutions is gaussian-random. With these assumptions then on average a new solution would split the keyspace of remaining solutions in half.  Given that the work needed to form a  new block remains a constant at 19 blocks for this period - it is cheaper to produce a N+1 block that has any floating point value as this is guaranteed to be adopted by all nodes if it is the first solution.  To leverage a chain replacement on nodes conducting Floating-Point Nakamoto Consensus a malicious miner would have to expend significantly more resources.\n\n\nEach successive n+1 solution variant of the same block-height must therefore on average consume half of the remaining finite keyspace. Resulting in a the n+1 value not only needed to overcome the 19 zero prefix, but also the non-zero fitness test.   It is possible for an adversary to waste their time making a 19 where n+1 was not greater, at which point the entire network will have had a chance to move on with the next solution.  With inductive reasoning, we can see that a demissiniong keyspace increases the amount of work needed to find a solution that also meets this new criteria.\n\n\nNow let us assume a heavily-fragmented network where some nodes have gotten one or both of the solutions.  In the case of nodes that received the proof-of-work solution with a fitness of 1.847, they will be happily mining on this version of the blockchain. The nodes that have gotten both 1.847 and .240 will still be mining for the 1.847 domainite version, ensuring a dominant chain.  However, we must assume some parts of the network never got the message about 1.847 proof of work, and instead continued to mine using a value of 1.240 as the previous block.   Now, let\u2019s say this group of isolated miners manages to present a new conflicting proof-of-work solution for 639255:\n\n\n     000000000000000000058d8ebeb076584bb5853c80111bc06b5ada35463091a6\n\n\nThe above base16 block has a fitness score of 1.532  The fitness value for the previous block 639254 is added together:\n\n\n     2.772 = 1.240 + 1.532\n\n\nIn this specific case, no other solution has been broadcast for block height 639255 - putting the weaker branch in the lead.  If the weaker branch is sufficiently lucky, and finds a solution before the dominant branch then this solution will have a higher overall fitness score, and this solution will propagate as it has the higher value.  This is also important for transactions on the network as they benefit from using the most recently formed block - which will have the highest local fitness score at the time of its discovery.  At this junction, the weaker branch has an opportunity to prevail enterally thus ending the split.\n\n\nNow let us return to the DoS threat model and explore the worst-case scenario created by byzantine fault injection. Let us assume that both the weaker group and the dominant group have produced competing proof-of-work solutions for blocks 639254 and 639255 respectively.  Let\u2019s assume that the dominant group that went with the 1.847 fitness score - also produces a solution with a similar fitness value and advertises the following solution to the network:\n\n\n0000000000000000000455207e375bf1dac0d483a7442239f1ef2c70d050c113\n\n19.414973649464574877549198290879237036867705594421756179\n\nor\n\n3.262 = 1.847 + 1.415\n\n\nA total of 3.262 is still dominant over the lesser 2.772 - in order to overcome this - the 2nd winning block needs to make up for all of the losses in the previous block.  In this scenario, in order for the weaker chain to supplant the dominant chain it must overcome a -0.49 point deficit. In traditional Nakamoto Consensus the nodes would see both forks as authoritative equals which creates a divide in mining capacity while two groups of miners search for the next block.  In Floating-Point Nakamoto Consensus any nodes receiving both forks, would prefer to mine on the chain with an overall fitness score of +3.262 - making it even harder for the weaker chain to find miners to compete in any future disagreement, thereby eroding support for the weaker chain. This kind of comparison requires an empirical method for determining fitness by miners following the same same system of rules will insure a self-fulfilled outcome.  After all nodes adopt the dominant chain normal Nakamoto Consuess can resume without having to take into consideration block fitness. This example shows how disagreement can be resolved more quickly if the network has a mechanism to resolve ambiguity and de-incentivise dissent.\n\nSoft Fork\n\nBlockchain networks that would like to improve the consensus generation method by adding a fitness test should be able to do so using a \u201cSoft Fork\u201d otherwise known as a compatible software update.  By contrast a \u201cHard-Fork\u201d is a separate incompatible network that does not form the same consensus.  Floating-Point Nakamoto Consensus can be implemented as a soft-fork because both patched, and non-patched nodes can co-exist and non-patched nodes will benefit from a kind of herd immunity in overall network stability.  This is because once a small number of nodes start following the same rules then they will become the deciding factor in which chain is chosen.  Clients that are using only traditional Nakamoto Consensus will still agree with new clients over the total chain length. Miners that adopt the new strategy early, will be less likely to lose out on mining invalid solutions.\n\nConclusion\n\nFloating-Point Nakamoto consensus allows the network to form a consensus more quickly by avoiding ambiguity allowing for determinism to take hold. Bitcoin has become an essential utility, and attacks against our networks must be avoided and adapting, patching and protecting the network is a constant effort. An organized attack against a cryptocurrency network will undermine the guarantees that blockchain developers are depending on.\n\n\nAny blockchain using Nakamoto Consensus can be modified to use a fitness constraint such as the one used by a Floating-Point Nakamoto Consensus.  An example implementation has been written and submitted as a PR to the bitcoin core which is free to be adapted by other networks.\n\n\n\n\n\n\nA complete implementation of Floating-Point Nakamoto consensus is in the following pull request:\n\nhttps://github.com/bitcoin/bitcoin/pull/19665/files\n\n\nPaper:\n\nhttps://github.com/in-st/Floating-Point-Nakamoto-Consensus\n\nhttps://in.st.capital<https://in.st.capital/>\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200929/1603874c/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Floating-Point Nakamoto Consensus",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Mike Brooks",
                "Jeremy",
                "LORD HIS EXCELLENCY JAMES HRMH",
                "David A. Harding",
                "bitcoin ml",
                "Franck Royer",
                "ZmnSCPxj"
            ],
            "messages_count": 14,
            "total_messages_chars_count": 132980
        }
    },
    {
        "title": "[bitcoin-dev] Floating-Point Nakamoto Consensus (bitcoin ml)",
        "thread_messages": [
            {
                "author": "John Tromp",
                "date": "2020-09-25T17:23:46",
                "message_text_only": "Re: Floating-Point Nakamoto Consensus (bitcoin ml)\n>\n\n> This is a pretty big departure from cumulative POW.\n\nIt's still cumulative. But instead of cumulating network difficulty,\nthey cumulate log_2(solution difficulty).\n\nSo if two solutions are found simultaneously, and one has a hash\nthat's only half of the other, then that will have twice the solution\ndifficulty and thus contribute 1 more the cumulate log_2(solution\ndifficulty).\n\n> Could you explain to me what you see happening if a node with this patch\n> and no history starts to sync, and some random node gives it a block\n> with a better fitness test for say height 250,000? No other solution\n> will have a better fitness test at that height, so from my understanding\n> its going to stop syncing. How about even later - say this proposal is\n> activated at block 750,000. At 850,000, someone decides it'd be fun to\n> publish a new block 800,000 with a better fitness test. What happens the\n> 50,000 blocks?\n\nNothing happens in these cases, as the new blocks are still far behind\nthe tip in cumulative score (they just have higher score at their\nheight).\n\nregards,\n-John"
            }
        ],
        "thread_summary": {
            "title": "Floating-Point Nakamoto Consensus (bitcoin ml)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "John Tromp"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1128
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin-s v0.4.0 release",
        "thread_messages": [
            {
                "author": "Chris Stewart",
                "date": "2020-09-28T17:32:08",
                "message_text_only": "Hi all,\n\nWe just released v0.4.0 of bitcoin-s.\n\nMajor features include\n\n- Wallet overhaul to support all common script types\n- Sqlite and postgres database support for all projects\n- Improved robustness of the neutrino node\n- BIP340 Schnorr Signatures implemented in Java (Bouncy Castle)\n- Wallet rescans with block filters\n- Testkit contains all new features so you can re-use our code to test\nyour bitcoin applications\n\nSee the release notes here:\n\nhttps://github.com/bitcoin-s/bitcoin-s/releases/tag/v0.4.0\n\nor our 'Getting Started' section on our website\n\nhttps://bitcoin-s.org/docs/next/getting-started\n\n-Chris\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200928/f9f6eef4/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin-s v0.4.0 release",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Chris Stewart"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 798
        }
    },
    {
        "title": "[bitcoin-dev] Is BIP32's chain code needed?",
        "thread_messages": [
            {
                "author": "Leonardo Comandini",
                "date": "2020-09-29T17:34:28",
                "message_text_only": "Hi all,\n\nBIP32 [1] says: \"In order to prevent these from depending solely on the key\nitself, we extend both private and public keys first with an extra 256 bits\nof\nentropy. This extension, called the chain code...\".\n\nMy argument is that the chain code is not needed.\nTo support such claim, I'll show a schematic of BIP32 operations to be\ncompared\nwith an alternative proposal and discuss the differences.\n\nI have two main questions:\n- Is this claim false?\n- Has anyone shared this idea before?\n\n## BIP32 schematic\n\nLet `G` be the secp256k1 generator.\nLet `i` be the child index.\nLet `(p, P=pG)` and `(p_i, P_i=p_iG)` be the parent and i-th child keypairs\nrespectively.\nLet `c` and `c_i` be the corresponding chain codes.\nLet `h1, h2, h3, h4` be hash functions so that the formulae below match the\ndefinitions given in BIP32 [2].\nDefine private and public child derivation as follow:\n\n    p_i(p, c, i) = (i < 2^31)  p + h1(c, pG, i)\n                   (i >= 2^31) p + h2(c, p, i)\n\n    c_i(p, c, i) = (i < 2^31)  h3(c, pG, i)\n                   (i >= 2^31) h4(c, p, i)\n\n    P_i(P, c, i) = (i < 2^31)  P + h1(c, P, i)G\n                   (i >= 2^31) not possible\n\n    c_i(P, c, i) = (i < 2^31)  h3(c, P, i)\n                   (i >= 2^31) not possible\n\nThe above formula for unhardened public derivation resembles a\npay-to-contract\n[3] scheme.\n\n## Alternative proposal\n\nLet `h` be an adequately strong hash function which converts its output to\ninteger.\nConsider the following derivation scheme:\n\n    p_i(p, i) = (i < 2^31)  p + h(pG, i)\n                (i >= 2^31) h(p, i)\n\n    P_i(P, i) = (i < 2^31)  P + h(P, i)G\n                (i >= 2^31) not possible\n\nWhich is basically the above one without the chaincode.\n\n## Considerations\n\nI claim that this has the same properties as BIP32 [4]:\n- The problem of finding `p` given `p_i, i` relies on brute-forcing `h` in\nthe\n  same way the analogous problem relies on brute-forcing `h2` in BIP32.\n- The problem of determining whether `{p_i, i}_i=1..n` are derived from a\ncommon\n  parent `p` relies on brute-forcing `h` in the same way the analogous\nproblem\n  relies on brute-forcing `h2` in BIP32.\n- Given `i < 2^31, p_i, P`, an attacker can find `p`. This is analogous to\n  BIP32, where the parent extended pubkey is needed (`P, c`). One could\nargue\n  that `c` is never published on the blockchain, while `P` may be. On the\nother\n  hand most wallets either use hardened derivation (so the attack does not\nwork)\n  or derive scriptpubkeys from keys at the same depth (so the parent key is\n  never published on the blockchain).\n  Anyway, if the parent public key is kept as secret as BIP32 extended keys\nare,\n  then the situation is analogous to BIP32's.\n\n_If_ these claims are correct, the proposed derivation scheme has two main\nadvantages:\n\n1) Shorter backups for public and private derivable keys\n\nBackups are especially relevant for output descriptors. For instance, when\nusing\na NofM multisig, each participant must backup M-1 exteneded public keys and\nits\nextended private key, which can be included in an output descriptor. Using\nthe\nproposed derivation reduces the backup size by `~M*32` bytes.\n\n2) User-friendly backup for child keys\n\nMost wallets use user-friendly backups, such as BIP39 [5] mnemonics. They\nmap\n16-32 bytes of entropy to 12-24 words. However BIP32 exteneded keys are at\nleast\n64(65) bytes (key and chain code), so they cannot be mapped back to a\nmnemonic.\n\nA common wallet setup is (`->` one-way derivation, `<->` two-way mapping):\n\n    entropy (16-32 bytes) <-> user-friendly backup\n      -> BIP32 extended key (64-65 bytes)\n         -> BIP32 extended child keys (64-65 bytes)\n\nWith the proposed derivation, it would be possible to have:\n\n    derivable private key (32 bytes) <-> user-friendly backup\n      -> derivable public key (33 bytes) <-> user-friendly backup\n      -> derivable child keys (32-33 bytes) <-> user-friendly backup\n\nThis would allow having mnemonics for subaccount keys.\n\n## References\n\n[1] https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki\n\n[2] h1, h2, h3 and h4 can be defined as follows\n\n    Ip(c, p, i) = (i >= 2^31) HMAC-SHA512(c, 0x00 || ser256(p) || ser32(i))\n                  (i < 2^31)  HMAC-SHA512(c, pG || ser32(i))\n\n    IP(c, P, i) = (i >= 2^31) not possible\n                  (i < 2^31)  HMAC-SHA512(c, P || ser32(i))\n\n    h1(c, P, i) = parse256(IP(c, P, i)[:32])\n    h2(c, p, i) = parse256(Ip(c, p, i)[:32])\n    h3(c, P, i) = IP(c, P, i)[32:]\n    h4(c, p, i) = Ip(c, p, i)[32:]\n\n[3] https://blockstream.com/sidechains.pdf Appendix A\n\n[4] https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki#security\n\n[5] https://github.com/bitcoin/bips/blob/master/bip-0039.mediawiki\n\n\n-- \nLeonardo\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20200929/a9a3fd5f/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Is BIP32's chain code needed?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Leonardo Comandini"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4896
        }
    }
]