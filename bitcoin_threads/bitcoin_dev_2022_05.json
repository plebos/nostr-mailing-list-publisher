[
    {
        "title": "[bitcoin-dev] What to do when contentious soft fork activations are attempted",
        "thread_messages": [
            {
                "author": "alicexbt",
                "date": "2022-05-01T01:20:22",
                "message_text_only": "Hi Michael,\n\n> Maybe the whole thing worked as designed. Some users identified what was going on, well known Bitcoin educators such as Andreas Antonopoulos, Jimmy Song etc brought additional attention to the dangers, a URSF movement started to gain momentum and those attempting a contentious soft fork activation backed off. (Disappointingly Bitcoin Optech didn't cover my previous posts to this mailing list [1](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-October/019535.html), [2](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019728.html), [3](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020235.html) highlighting the dangers many months ago or recent posts. Normally Optech is very high signal.)\n\nSome users have been misled and there is nothing great being achieved by doing this on social media. Andreas is clueless about BIP 119 and other covenant proposals. He is spreading misinformation and some of the URSF enthusiasts do not understand what are they even opposing or going to run with risks involved.\n\nAnswering the subject of this email: \"What to do when contentious soft forks activations are attempted?\"\n\n- Do not consider something contentious because someone said it on mailing list\n- Do not spread misinformation\n- Read all posts in detail with different opinions\n- Avoid personal attacks\n- Look at the technical details, code etc. and comment on things that could be improved\n\n/dev/fd0\n\nSent with [ProtonMail](https://protonmail.com/) secure email.\n------- Original Message -------\nOn Saturday, April 30th, 2022 at 3:23 PM, Michael Folkson via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:\n\n> I\u2019ve been in two minds on whether to completely move on to other topics or to formulate some thoughts on the recent attempt to activate a contentious soft fork. In the interests of those of us who have wasted days/weeks/months of our time on this (with no personal upside) and who don\u2019t want to repeat this exercise again I thought I should at least raise the issue for discussion of what should be done differently if this is tried again in future.\n>\n> This could be Jeremy with OP_CTV at a later point (assuming it is still contentious) or anyone who wants to pick up a single opcode that is not yet activated on Bitcoin and try to get miners to signal for it bypassing technical concerns from many developers, bypassing Bitcoin Core and bypassing users.\n>\n> Maybe the whole thing worked as designed. Some users identified what was going on, well known Bitcoin educators such as Andreas Antonopoulos, Jimmy Song etc brought additional attention to the dangers, a URSF movement started to gain momentum and those attempting a contentious soft fork activation backed off. (Disappointingly Bitcoin Optech didn't cover my previous posts to this mailing list [1](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-October/019535.html), [2](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019728.html), [3](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020235.html) highlighting the dangers many months ago or recent posts. Normally Optech is very high signal.)\n>\n> Alternatively this was the first time a contentious soft fork activation was attempted, we were all woefully unprepared for it and none of us knew what we were doing.\n>\n> I\u2019m unsure on the above. I\u2019d be interested to hear thoughts. What I am sure of is that it is totally unacceptable for one individual to bring the entire Bitcoin network to the brink of a chain split. There has to be a personal cost to that individual dissuading them from trying it again otherwise they\u2019re motivated to try it again every week/month. Perhaps the personal cost that the community is now prepared if that individual tries it again is sufficient. I\u2019m not sure. Obviously Bitcoin is a permissionless network, Bitcoin Core and other open source projects are easily forked and no authority (I\u2019m certainly no authority) can stop things like this happening again.\n>\n> I\u2019ll follow the responses if people have thoughts (I won't be responding to the instigators of this contentious soft fork activation attempt) but other than that I\u2019d like to move on to other things than contentious soft fork activations. Thanks to those who have expressed concerns publicly (too many to name, Bob McElrath was often wording arguments better than I could) and who were willing to engage with the URSF conversation. If an individual can go directly to miners to get soft forks activated bypassing technical concerns from many developers, bypassing Bitcoin Core and bypassing users Bitcoin is fundamentally broken. The reason I still have hope that it isn't is that during a period of general apathy some people were willing to stand up and actively resist it.\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> Keybase: michaelfolkson\n> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220501/8aa2a818/attachment-0001.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2022-05-01T12:47:54",
                "message_text_only": "On Sun, May 1, 2022, 09:22 alicexbt via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Michael,\n>\n> Maybe the whole thing worked as designed. Some users identified what was\n> going on, well known Bitcoin educators such as Andreas Antonopoulos, Jimmy\n> Song etc brought additional attention to the dangers, a URSF movement\n> started to gain momentum and those attempting a contentious soft fork\n> activation backed off. (Disappointingly Bitcoin Optech didn't cover my\n> previous posts to this mailing list 1\n> <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-October/019535.html>,\n> 2\n> <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019728.html>,\n> 3\n> <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020235.html>\n> highlighting the dangers many months ago or recent posts. Normally Optech\n> is very high signal.)\n>\n>\n> Some users have been misled and there is nothing great being achieved by\n> doing this on social media. Andreas is clueless about BIP 119 and other\n> covenant proposals. He is spreading misinformation and some of the URSF\n> enthusiasts do not understand what are they even opposing or going to run\n> with risks involved.\n>\nClueless and spreading disinformation, you say? What misinformation, could\nyou explain?\n\n\n> - Avoid personal attacks\n>\nCould accusing someone of apreading misinformation without prove and\ncalling him clueless be considered a personal attack?\nWhat do we do with hypocrites and liars?\nPeople who knowingly lie to push their own agenda, how do we protect\nagainst those?\n\n\n> /dev/fd0\n>\n> Sent with ProtonMail <https://protonmail.com/> secure email.\n>\n> ------- Original Message -------\n> On Saturday, April 30th, 2022 at 3:23 PM, Michael Folkson via bitcoin-dev\n> bitcoin-dev at lists.linuxfoundation.org wrote:\n>\n>\n> I\u2019ve been in two minds on whether to completely move on to other topics or\n> to formulate some thoughts on the recent attempt to activate a contentious\n> soft fork. In the interests of those of us who have wasted\n> days/weeks/months of our time on this (with no personal upside) and who\n> don\u2019t want to repeat this exercise again I thought I should at least raise\n> the issue for discussion of what should be done differently if this is\n> tried again in future.\n>\n> This could be Jeremy with OP_CTV at a later point (assuming it is still\n> contentious) or anyone who wants to pick up a single opcode that is not yet\n> activated on Bitcoin and try to get miners to signal for it bypassing\n> technical concerns from many developers, bypassing Bitcoin Core and\n> bypassing users.\n>\n> Maybe the whole thing worked as designed. Some users identified what was\n> going on, well known Bitcoin educators such as Andreas Antonopoulos, Jimmy\n> Song etc brought additional attention to the dangers, a URSF movement\n> started to gain momentum and those attempting a contentious soft fork\n> activation backed off. (Disappointingly Bitcoin Optech didn't cover my\n> previous posts to this mailing list 1\n> <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-October/019535.html>,\n> 2\n> <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019728.html>,\n> 3\n> <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020235.html>\n> highlighting the dangers many months ago or recent posts. Normally Optech\n> is very high signal.)\n>\n> Alternatively this was the first time a contentious soft fork activation\n> was attempted, we were all woefully unprepared for it and none of us knew\n> what we were doing.\n>\n> I\u2019m unsure on the above. I\u2019d be interested to hear thoughts. What I am\n> sure of is that it is totally unacceptable for one individual to bring the\n> entire Bitcoin network to the brink of a chain split. There has to be a\n> personal cost to that individual dissuading them from trying it again\n> otherwise they\u2019re motivated to try it again every week/month. Perhaps the\n> personal cost that the community is now prepared if that individual tries\n> it again is sufficient. I\u2019m not sure. Obviously Bitcoin is a permissionless\n> network, Bitcoin Core and other open source projects are easily forked and\n> no authority (I\u2019m certainly no authority) can stop things like this\n> happening again.\n>\n> I\u2019ll follow the responses if people have thoughts (I won't be responding\n> to the instigators of this contentious soft fork activation attempt) but\n> other than that I\u2019d like to move on to other things than contentious soft\n> fork activations. Thanks to those who have expressed concerns publicly (too\n> many to name, Bob McElrath was often wording arguments better than I could)\n> and who were willing to engage with the URSF conversation. If an individual\n> can go directly to miners to get soft forks activated bypassing technical\n> concerns from many developers, bypassing Bitcoin Core and bypassing users\n> Bitcoin is fundamentally broken. The reason I still have hope that it isn't\n> is that during a period of general apathy some people were willing to stand\n> up and actively resist it.\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> Keybase: michaelfolkson\n> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220501/4d78ed9f/attachment-0001.html>"
            },
            {
                "author": "Ryan Grant",
                "date": "2022-05-03T14:36:15",
                "message_text_only": "On Sun, May 1, 2022 at 8:49 PM Jorge Tim\u00f3n via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> On Sun, May 1, 2022, 09:22 alicexbt via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>> [...] Andreas is clueless about BIP 119 and other covenant\n>> proposals.  He is spreading misinformation and [...]\n\n> Clueless and spreading disinformation, you say?  What\n> misinformation, could you explain?\n\nFirst, OP_CTV covenants cannot restrict any address that the sender\ndoes not control.  OP_CTV just delivers auditable presigned\ntransactions.  That's it!  OP_CTV's primary design constraint is to\nNOT empower new ways to do blacklists (which are already possible\nusing unwanted-multisig).  That's not a statement about what Bitcoin\nshould ultimately become, but rather what Bitcoin is likely ready for.\nMuch like Bitcoin's design, the simplest possible covenant solution\nwas chosen, so that it would be \"dirt simple\" to audit that the code\ndoes only what it should, and no more.\n\nAndreas used a few words of indecision to make excuses for not\ncode-reviewing BIP119 or the pull request, while using a lot of words\ntalking about: how dangerous any change is; conservative consensus\nprocess; and GovCoin blacklists.  This gave the strong impression that\nthe change was dangerous and could easily lead to the creation of\nblacklists enforced by L1 consensus itself (rather than enforced by\nother signers in a sidechain or unwanted-multisig).\n\nAndreas also didn't look into the reason that the proposed client was\nsafe and would not cause a chain split.  Speedy Trials by themselves\ndon't risk chain splits, they poll.  There was no UASF in the planned\nexecutable.  Some devs hate ST because it puts the initiative in\nminer's hands to gauge **user support and readiness** - which those\ndevs feel the miners have no reason to be good at - but that expires\nspeedily.  If everyone loved the change and the trial was about to\npass, except ornery users - who we love when UASF is needed, of\ncourse - were going to cause a chain split of their own to block it,\nthen ST offers miners the capability to - very quickly, faster than a\nrelease can be pushed out - change their signaling to again prevent a\nchain split.\n\nRussell O'Connor wrote the definitive explanation for how ST arose in\nthe consensus process and how it was designed to make everyone\nunhappy.  It's a great explanation of what we went through last year.\n\n  https://r6.ca/blog/20210615T191422Z.html\n\n    \"On Building Consensus and Speedy Trial\"\n\n    on | 2021-06-15T19:14:22Z\n    by | Russell O'Connor\n\nAndreas also didn't look for a non-attack reason for a separate binary\nrelease.  (Here I feel like I should be naming a lot of devs as well,\nhmm.)  Let's go back to O'Connor, who reminds us of a faction from the\nlast consensus change:\n\n  > The \"devs-do-not-decide\" faction's concern is regarding the\n  > appearance of Bitcoin developers deciding the rules of Bitcoin.\n  > [...]  This faction would be fine with users building their own\n  > alternative client for forced activation, or a configuration flag\n  > for enabling some kind of forced activation that is not enabled by\n  > default.\n\nMaintainers of the repository and \"Big Name\" devs have very personal\nreasons to take this stance.  Meanwhile, devs who want to form an\nopinion on some given matter but who do not want to do their own code\nreviews typically look to Big Name code reviewers for guidance, in a\n\"Consensus Beauty Contest\" [note_kbc].  Contrast this with everyone\nwho restricts their opinion-formation to their own review of the code;\nthey are \"Doing Consensus Right\", rather than being stuck in the\nBeauty Contest.  Now, if a \"devs-do-not-decide\" dev wrote some code,\nthey implicitly reviewed their own code, right?  But!  If they did not\nwrite that code, then they **must avoid it** ...in proportion to how\nmuch it affects consensus.  According to this theory of Bitcoin's\nconsensus, we would **expect** Big Names to be partly missing from the\nOP_CTV code reviews.  This confuses people who are used to playing the\nConsensus Beauty Contest.\n\n  [note_kbc:] for another game about what everybody else thinks,\n    see Keynesian beauty contest:\n      https://en.wikipedia.org/wiki/Keynesian_beauty_contest\n\n    (The connection is funny to me because we all have to individually\n    play this game when deciding what money is, and in so doing pay a\n    last homage to Keynes, during our multi-generational exit from his\n    eponymous economics of manipulated interest rates.)\n\nJimmy Song, in a video best fitting the advocacy referred to by\nMichael (who did not give any specific link), claims that the OP_CTV\nreview process is \"routing around\" some Big Names.  Jimmy is seemingly\nunaware that some Big Names are explicitly not participating in\nguiding what Bitcoin's consensus should be, and that some are even\nusing strategic ambiguity to do so.  With the context above, we have a\nmuch less nefarious interpretation of motive for releasing a\nbinary - one that is part of the consensus process.\n\n  https://www.youtube.com/watch?v=i5VNiiCYnIg\n    \"Bitcoin Brief - BIP119, Mexico CBDC & Bitcoin's Role in Russia vs\n    Ukraine!\"\n    on | Apr 25, 2022\n\n    (mark 1:13:52.0) Jimmy Song\n    (mark 1:18:00.0) \"routing around\"\n\nAn alternative client must, by necessity, offer both its consensus\nfeature and its activation.  Releasing an alternative client is not a\ndecision made from impatience and disrespect.  It\u2019s the result of\nasking everyone, getting literal non-responses, and intuiting that the\nlandscape has changed, so something on this path must be different\nfrom last time.  While the alternative client route surprised me when\nI heard about it, I cannot say that I personally knew of any other way\nto advance what has clearly been a blocked discussion, and so I did\nnot disassociate myself from the effort.  People do not understand how\nblocked up consensus is, and no dev has verbalized a better solution\nfor maintainers than strategic ambiguity, which is most confusing when\nit is delivering only silence.\n\nThe typical alternative offered by other devs is, \"Wait.\"  Well, this\n\"Wait\" has almost always meant \"Never.\"  Take a look at CSFS and APO.\nThey've been waiting, but for what?  What's the bug that BIP authors\ncan't fix?  Where's the concrete pull request?  Who is going to anoint\nthem as done?  OP_CTV has made its rite of passage and transcended\nthese questions.  Its only competition is whether something better can\nbe imagined, but those arguments need to explain why learning from a\ngood opcode in the meantime is worth waiting years to work through new\nsafety concerns.  If any of this matters, then timing matters, too.\nOP_CTV is sitting at the front of the bus.\n\nPersonally, I suspect that the \"something better\" crowd wants\nrecursive covenants, yet recognizes the argument is difficult and\nwould have put it off in a sense of misplaced priorities, but we'll\nfind out soon.  If there were some kind of assurance that could be\noffered, something that would result in a less contentious soft fork,\ninstead of stonewalling resistance that makes all soft forks more\ncontentious, then a later \"epsilon\" upgrade to covenants would be\neasier instead of harder.  This is because everyone who believes that\nrecursive covenants are not a new threat to Bitcoin could argue\ntowards a common purpose and resolve that in a binding consensus\nagreement.  One such binding mechanism could be parties committing\nmatched coins locked under a future opcode, although this would be an\nextreme departure from typical development and incur massive risk to\nthe parties if for other reasons phase two of the initiative fails.\nIt's too bad the game theory isn't simpler.\n\nFinally, Andreas summarized the conservatism in his position as\nbasically, \"If you want scripting and contracts, go buy ETH.\"  Which\nis offensive to everyone trying to make bitcoins more protective of\nindividual freedom and thus more valuable; whether you're working on\nscaling and privacy, the Lightning Network, Discreet Log Contracts,\nCoinPool covenants, self-custody vault covenants, building out Taproot\ncapabilities, or working on other infrastructure.  What a clueless\nshitcoiner!\n\n  https://www.youtube.com/watch?v=vAE5fOZ2Luw\n\n    \"BIP119, EU regulatory attack, El Salvador, and much more in Q&A\n    with aantonop (April 2022)\"\n\n    on | Apr 24, 2022\n    by | aantonop\n\n    (mark 30:34.0) \"if you want to do smart contracts...\"\n\nThe path to redemption in the Bitcoin community is to unequivocally\nhelp Bitcoin.\n\nJeremy wasn't always Bitcoin-only, but his efforts have been sincere\nand he works in the concrete realm where anyone can judge how pure his\ncontributions are.  Even if OP_CTV is never activated, or if no\ncovenant opcode is ever activated, Bitcoin is much more secure due to\nthe critical bug fixes that Jeremy has already seen merged just\nplanning ahead for a mempool that could handle dependent transactions.\nBitcoin was never under attack or at risk of harm from Jeremy's\nactions to advance the covenants discussion.\n\nAndreas is welcome to research technical merits better before\ncommunicating, and to discover how a vision of powerful contract\ncovenants - in the most decentralized money that exists - can affect\npeople's freedom.  In so doing, join us."
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2022-05-06T17:17:28",
                "message_text_only": "On Tue, May 3, 2022 at 4:36 PM Ryan Grant <bitcoin-dev at rgrant.org> wrote:\n\n> On Sun, May 1, 2022 at 8:49 PM Jorge Tim\u00f3n via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > On Sun, May 1, 2022, 09:22 alicexbt via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> >> [...] Andreas is clueless about BIP 119 and other covenant\n> >> proposals.  He is spreading misinformation and [...]\n>\n> > Clueless and spreading disinformation, you say?  What\n> > misinformation, could you explain?\n>\n> First, OP_CTV covenants cannot restrict any address that the sender\n> does not control.  OP_CTV just delivers auditable presigned\n> transactions.  That's it!  OP_CTV's primary design constraint is to\n> NOT empower new ways to do blacklists (which are already possible\n> using unwanted-multisig).  That's not a statement about what Bitcoin\n> should ultimately become, but rather what Bitcoin is likely ready for.\n> Much like Bitcoin's design, the simplest possible covenant solution\n> was chosen, so that it would be \"dirt simple\" to audit that the code\n> does only what it should, and no more.\n>\n> Andreas used a few words of indecision to make excuses for not\n> code-reviewing BIP119 or the pull request, while using a lot of words\n> talking about: how dangerous any change is; conservative consensus\n> process; and GovCoin blacklists.  This gave the strong impression that\n> the change was dangerous and could easily lead to the creation of\n> blacklists enforced by L1 consensus itself (rather than enforced by\n> other signers in a sidechain or unwanted-multisig).\n>\n> Andreas also didn't look into the reason that the proposed client was\n> safe and would not cause a chain split.  Speedy Trials by themselves\n> don't risk chain splits, they poll.  There was no UASF in the planned\n> executable.  Some devs hate ST because it puts the initiative in\n> miner's hands to gauge **user support and readiness** - which those\n> devs feel the miners have no reason to be good at - but that expires\n> speedily.  If everyone loved the change and the trial was about to\n> pass, except ornery users - who we love when UASF is needed, of\n> course - were going to cause a chain split of their own to block it,\n> then ST offers miners the capability to - very quickly, faster than a\n> release can be pushed out - change their signaling to again prevent a\n> chain split.\n>\n\nI don't think that's enough of a reason to justify you calling andreas\n\"clueless\". I'm sure whatever andreas said, he said it with the best\nintentions.\nRemember:\n\n- Avoid personal attacks\n\nAccusing andreas of being clueless is spreading misinformation.\n\nRussell O'Connor wrote the definitive explanation for how ST arose in\n> the consensus process and how it was designed to make everyone\n> unhappy.  It's a great explanation of what we went through last year.\n>\n>   https://r6.ca/blog/20210615T191422Z.html\n>\n>     \"On Building Consensus and Speedy Trial\"\n>\n>     on | 2021-06-15T19:14:22Z\n>     by | Russell O'Connor\n>\n\nThat's a lot of text, are you sure he said in there he designed speedy\ntrial to make everyone unhappy?\nWell, if we're still talking about it, that proves that it failed at its\nown design criterion of failing fast.\nBut if you think my judgement about speedy trial (sorry, we discussed it\nfor so long that I forgot the BIP number, it wasn't eight, I remember that)\nand I locked my mind in about speedy trial too soon and without giving\nanyone a chance to coordinate about my personal signaling of the\nproposal...I guess I can give you a grace period of 6 months to upgrade\nyour own mind about it and accept my judgment about it, so that concern\nabout my criticism on the proposal is addressed.\nThere may be a couple of people trying to create dissent about this opinion\nof mine. But once all concerns are addressed...\n\nAndreas also didn't look for a non-attack reason for a separate binary\n> release.  (Here I feel like I should be naming a lot of devs as well,\n> hmm.)  Let's go back to O'Connor, who reminds us of a faction from the\n> last consensus change:\n>\n>   > The \"devs-do-not-decide\" faction's concern is regarding the\n>   > appearance of Bitcoin developers deciding the rules of Bitcoin.\n>   > [...]  This faction would be fine with users building their own\n>   > alternative client for forced activation, or a configuration flag\n>   > for enabling some kind of forced activation that is not enabled by\n>   > default.\n>\n\nYeah, I know, both speedy trial and CTV could be perceived as developers\ntrying to dictate rules.\nI guess that criticism against bip8 can be applied from now on to any\nproposal forever. what a great precedent.\nIt's not always that software designers should focus on making everyone\nunhappy (like any other kind of designer, I guess), but some times it's\npotential perceptions from vaguely defined groups that should be at the\nheart of your design decisions.\n\n\n> Maintainers of the repository and \"Big Name\" devs have very personal\n> reasons to take this stance.  Meanwhile, devs who want to form an\n> opinion on some given matter but who do not want to do their own code\n> reviews typically look to Big Name code reviewers for guidance, in a\n> \"Consensus Beauty Contest\" [note_kbc].  Contrast this with everyone\n> who restricts their opinion-formation to their own review of the code;\n> they are \"Doing Consensus Right\", rather than being stuck in the\n> Beauty Contest.  Now, if a \"devs-do-not-decide\" dev wrote some code,\n> they implicitly reviewed their own code, right?  But!  If they did not\n> write that code, then they **must avoid it** ...in proportion to how\n> much it affects consensus.  According to this theory of Bitcoin's\n> consensus, we would **expect** Big Names to be partly missing from the\n> OP_CTV code reviews.  This confuses people who are used to playing the\n> Consensus Beauty Contest.\n>\n>   [note_kbc:] for another game about what everybody else thinks,\n>     see Keynesian beauty contest:\n>       https://en.wikipedia.org/wiki/Keynesian_beauty_contest\n>\n>     (The connection is funny to me because we all have to individually\n>     play this game when deciding what money is, and in so doing pay a\n>     last homage to Keynes, during our multi-generational exit from his\n>     eponymous economics of manipulated interest rates.)\n>\n> Jimmy Song, in a video best fitting the advocacy referred to by\n> Michael (who did not give any specific link), claims that the OP_CTV\n> review process is \"routing around\" some Big Names.  Jimmy is seemingly\n> unaware that some Big Names are explicitly not participating in\n> guiding what Bitcoin's consensus should be, and that some are even\n> using strategic ambiguity to do so.  With the context above, we have a\n> much less nefarious interpretation of motive for releasing a\n> binary - one that is part of the consensus process.\n>\n>   https://www.youtube.com/watch?v=i5VNiiCYnIg\n>     \"Bitcoin Brief - BIP119, Mexico CBDC & Bitcoin's Role in Russia vs\n>     Ukraine!\"\n>     on | Apr 25, 2022\n>\n>     (mark 1:13:52.0) Jimmy Song\n>     (mark 1:18:00.0) \"routing around\"\n>\n> An alternative client must, by necessity, offer both its consensus\n> feature and its activation.  Releasing an alternative client is not a\n> decision made from impatience and disrespect.  It\u2019s the result of\n> asking everyone, getting literal non-responses, and intuiting that the\n> landscape has changed, so something on this path must be different\n> from last time.  While the alternative client route surprised me when\n> I heard about it, I cannot say that I personally knew of any other way\n> to advance what has clearly been a blocked discussion, and so I did\n> not disassociate myself from the effort.  People do not understand how\n> blocked up consensus is, and no dev has verbalized a better solution\n> for maintainers than strategic ambiguity, which is most confusing when\n> it is delivering only silence.\n>\n\nI don't know about beauty contest or big names.\nBut if you want to speak in those terms...\nIf there was a beauty contest for activation proposals and I was part of\nthe jury, BIP8 would win.\nI was once in love with bip9, but, no offense, she is getting old.\nAnd regarding speedy trial, whatever its bip was...sorry, I was trying to\nfollow your analogy, but some times my instinct tells me not to make\ncertain jokes about the lord of the rings in certain contexts.\nAs it turns out, not everyone likes the lord of the rings, or beauty\ncontests.\n\n\n> The typical alternative offered by other devs is, \"Wait.\"  Well, this\n> \"Wait\" has almost always meant \"Never.\"  Take a look at CSFS and APO.\n> They've been waiting, but for what?  What's the bug that BIP authors\n> can't fix?  Where's the concrete pull request?  Who is going to anoint\n> them as done?  OP_CTV has made its rite of passage and transcended\n> these questions.  Its only competition is whether something better can\n> be imagined, but those arguments need to explain why learning from a\n> good opcode in the meantime is worth waiting years to work through new\n> safety concerns.  If any of this matters, then timing matters, too.\n> OP_CTV is sitting at the front of the bus\n>\n\nSpeedy covenants (I will write an email explaining the proposal and asking\nfor a bip number) is I think a superior covenant prooposal in terms of not\nwaiting. Minor activation details aside, it has been implemented for longer\nthan OP_CTV, and discussed for longer too.\nI know what you're thinking: but that would be a hardfork and necromancy.\nNo, it wouldn't, well, at least not the hardfork part. Can we undo a\nsoftfork with another softfork?\nWell, I don't know if always, but some times, in practice, yes we can.\nI will explain how in the coming \"speedy covenants\".\n\n\n> Personally, I suspect that the \"something better\" crowd wants\n> recursive covenants, yet recognizes the argument is difficult and\n> would have put it off in a sense of misplaced priorities, but we'll\n> find out soon.  If there were some kind of assurance that could be\n> offered, something that would result in a less contentious soft fork,\n> instead of stonewalling resistance that makes all soft forks more\n> contentious, then a later \"epsilon\" upgrade to covenants would be\n> easier instead of harder.  This is because everyone who believes that\n> recursive covenants are not a new threat to Bitcoin could argue\n> towards a common purpose and resolve that in a binding consensus\n> agreement.  One such binding mechanism could be parties committing\n> matched coins locked under a future opcode, although this would be an\n> extreme departure from typical development and incur massive risk to\n> the parties if for other reasons phase two of the initiative fails.\n> It's too bad the game theory isn't simpler.\n>\n\nLet's not allow perfection to be the enemy of the good sutff, or something\nlike that.\nHopefully speedy covenants will solve all the latest tensions around.\nAnd OP_CTV can always be implemented afterwards if it is more optimal under\nsome criteria.\n\nFinally, Andreas summarized the conservatism in his position as\n> basically, \"If you want scripting and contracts, go buy ETH.\"  Which\n> is offensive to everyone trying to make bitcoins more protective of\n> individual freedom and thus more valuable; whether you're working on\n> scaling and privacy, the Lightning Network, Discreet Log Contracts,\n> CoinPool covenants, self-custody vault covenants, building out Taproot\n> capabilities, or working on other infrastructure.  What a clueless\n> shitcoiner!\n>\n>   https://www.youtube.com/watch?v=vAE5fOZ2Luw\n>\n>     \"BIP119, EU regulatory attack, El Salvador, and much more in Q&A\n>     with aantonop (April 2022)\"\n>\n>     on | Apr 24, 2022\n>     by | aantonop\n>\n>     (mark 30:34.0) \"if you want to do smart contracts...\"\n>\n> The path to redemption in the Bitcoin community is to unequivocally\n> help Bitcoin.\n>\n\nThe path to redemption for whom?\n\n\n> Jeremy wasn't always Bitcoin-only, but his efforts have been sincere\n> and he works in the concrete realm where anyone can judge how pure his\n> contributions are.  Even if OP_CTV is never activated, or if no\n> covenant opcode is ever activated, Bitcoin is much more secure due to\n> the critical bug fixes that Jeremy has already seen merged just\n> planning ahead for a mempool that could handle dependent transactions.\n> Bitcoin was never under attack or at risk of harm from Jeremy's\n> actions to advance the covenants discussion.\n>\n> Andreas is welcome to research technical merits better before\n> communicating, and to discover how a vision of powerful contract\n> covenants - in the most decentralized money that exists - can affect\n> people's freedom.  In so doing, join us.\n>\n\nyeah, jeremy is welcomed to understand bip8 and the analysis behind it.\nHe just needs to be open minded and not worry about \"perceptions\" for a few\nminutes, so I don't think he will be able to, sadly.\nBut let's not personally attack andreas for his opinions.\nThe only reason you don't like bip8 is because you're ignorant about it and\nyou haven't reviewed it enough.\njoin bip8, join us. do it for freedom.\n\nSpeaking less specifically of ctv, SC or other covenants proposals, but\nmore generally about covenants...\nWhat are your thoughts on \"visacoin\" (described on the technical bitcoin\nforums) in the context of covenants?\n\nAnyway, I should be working on a covenants proposal older than ctv myself.\nInstead of just talking and criticizing what others have done.\nYou have a point there.\n\nJappy Janukka\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220506/d69f650c/attachment-0001.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2022-05-06T18:23:51",
                "message_text_only": "On Fri, May 6, 2022 at 2:01 PM Jorge Tim\u00f3n via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> Russell O'Connor wrote the definitive explanation for how ST arose in\n>> the consensus process and how it was designed to make everyone\n>> unhappy.  It's a great explanation of what we went through last year.\n>>\n>>   https://r6.ca/blog/20210615T191422Z.html\n>>\n>>     \"On Building Consensus and Speedy Trial\"\n>>\n>>     on | 2021-06-15T19:14:22Z\n>>     by | Russell O'Connor\n>>\n>\n> That's a lot of text, are you sure he said in there he designed speedy\n> trial to make everyone unhappy?\n> Well, if we're still talking about it, that proves that it failed at its\n> own design criterion of failing fast.\n>\n\nQuoting from https://r6.ca/blog/20210615T191422Z.html:\n\n> Speedy Trial\u2019s design is not based on any sort of activation philosophy\nabout failing fast.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220506/7b1fba52/attachment.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2022-05-06T22:44:24",
                "message_text_only": "So, to be clear, you didn't design speedy trial \"to make everyone unhappy\"\nas Ryan claims, no?\nThat's a really strange claim on his part.\nWhen the grace period for slower activation after lock in was added, I\ndon't think it was added to make me or people like me who dislike that\nproposal unhappy. On the contrary, I think the goal was precisely to\naddress some of our concerns.\nBut it doesn't address them all, as I've tried to explain other times.\nI truly think you wanted to make everyone happy with speedy trial, but you\ndidn't do it, sorry.\nI know it' not a lack of capacity because you did impressive and genius\nthings like simplicity.\nBut despite your best intentions and your great capacity, I still think\nspeedy trial is a very bad proposal because you got the analysis wrong.\nLet me reiterate that this is not attack against you, but only against one\nof your ideas.\nSorry if I sounded sarcastic, but I was trying to be sarcastic with ryan,\nnot with you.\n\n\nOn Fri, May 6, 2022 at 8:24 PM Russell O'Connor via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Fri, May 6, 2022 at 2:01 PM Jorge Tim\u00f3n via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>>\n>> Russell O'Connor wrote the definitive explanation for how ST arose in\n>>> the consensus process and how it was designed to make everyone\n>>> unhappy.  It's a great explanation of what we went through last year.\n>>>\n>>>   https://r6.ca/blog/20210615T191422Z.html\n>>>\n>>>     \"On Building Consensus and Speedy Trial\"\n>>>\n>>>     on | 2021-06-15T19:14:22Z\n>>>     by | Russell O'Connor\n>>>\n>>\n>> That's a lot of text, are you sure he said in there he designed speedy\n>> trial to make everyone unhappy?\n>> Well, if we're still talking about it, that proves that it failed at its\n>> own design criterion of failing fast.\n>>\n>\n> Quoting from https://r6.ca/blog/20210615T191422Z.html:\n>\n> > Speedy Trial\u2019s design is not based on any sort of activation philosophy\n> about failing fast.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220507/fb08a129/attachment-0001.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-05-01T19:14:29",
                "message_text_only": "+1 alicexbt\n\nWe of course want knowledgeable bitcoiners who aren't knowledgeable about a\ncertain proposal to be skeptical. But what we don't want is for that\nnatural skepticism-from-ignorance to be interpreted as opposition, or\nreally a strong signal of any kind. Any thoughts from ignorance, whether\nself-aware or not, should be given small weight. It seems the vast majority\nof push back has been this kind of skepticism from ignorance. And to a\ncertain degree I think we want to give time for understanding to those who\nhave not participated in the first, second, third, etc round of discussion\non a proposal. It may not be reasonable to say \"you had the last 2 years of\ntime to voice your concern\".\n\nNow that CTV is being taken seriously as a proposal, we probably should\ngive the community who is finally taking a serious look at it time to\nunderstand, get their questions answered, and come to terms with it. This\nis not to say that CTV as a technology or proposal has been rushed, or has\nnot had enough work put into it, but rather that the community as a whole\nhas not paid enough attention to it for long enough.\n\nThe wrong approach is: \"how do I yell more loudly next time I see something\nI'm uncomfortable with?\" The right approach is to educate those who aren't\neducated on the proposal and gather consensus on what people think when\nthey understand enough about it to contribute to that consensus. If you\ncare about consensus, you should respect the consensus process and be ok\nwith consensus being not your preferred outcome. If you don't care about\nconsensus, then you're basically attacking the bitcoin community.\n\nOn Sun, May 1, 2022 at 3:22 AM alicexbt via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Michael,\n>\n> Maybe the whole thing worked as designed. Some users identified what was\n> going on, well known Bitcoin educators such as Andreas Antonopoulos, Jimmy\n> Song etc brought additional attention to the dangers, a URSF movement\n> started to gain momentum and those attempting a contentious soft fork\n> activation backed off. (Disappointingly Bitcoin Optech didn't cover my\n> previous posts to this mailing list 1\n> <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-October/019535.html>,\n> 2\n> <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019728.html>,\n> 3\n> <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020235.html>\n> highlighting the dangers many months ago or recent posts. Normally Optech\n> is very high signal.)\n>\n>\n> Some users have been misled and there is nothing great being achieved by\n> doing this on social media. Andreas is clueless about BIP 119 and other\n> covenant proposals. He is spreading misinformation and some of the URSF\n> enthusiasts do not understand what are they even opposing or going to run\n> with risks involved.\n>\n>\n> Answering the subject of this email: \"What to do when contentious soft\n> forks activations are attempted?\"\n>\n> - Do not consider something contentious because someone said it on mailing\n> list\n> - Do not spread misinformation\n> - Read all posts in detail with different opinions\n> - Avoid personal attacks\n> - Look at the technical details, code etc. and comment on things that\n> could be improved\n>\n>\n>\n> /dev/fd0\n>\n> Sent with ProtonMail <https://protonmail.com/> secure email.\n>\n> ------- Original Message -------\n> On Saturday, April 30th, 2022 at 3:23 PM, Michael Folkson via bitcoin-dev\n> bitcoin-dev at lists.linuxfoundation.org wrote:\n>\n>\n> I\u2019ve been in two minds on whether to completely move on to other topics or\n> to formulate some thoughts on the recent attempt to activate a contentious\n> soft fork. In the interests of those of us who have wasted\n> days/weeks/months of our time on this (with no personal upside) and who\n> don\u2019t want to repeat this exercise again I thought I should at least raise\n> the issue for discussion of what should be done differently if this is\n> tried again in future.\n>\n> This could be Jeremy with OP_CTV at a later point (assuming it is still\n> contentious) or anyone who wants to pick up a single opcode that is not yet\n> activated on Bitcoin and try to get miners to signal for it bypassing\n> technical concerns from many developers, bypassing Bitcoin Core and\n> bypassing users.\n>\n> Maybe the whole thing worked as designed. Some users identified what was\n> going on, well known Bitcoin educators such as Andreas Antonopoulos, Jimmy\n> Song etc brought additional attention to the dangers, a URSF movement\n> started to gain momentum and those attempting a contentious soft fork\n> activation backed off. (Disappointingly Bitcoin Optech didn't cover my\n> previous posts to this mailing list 1\n> <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-October/019535.html>,\n> 2\n> <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019728.html>,\n> 3\n> <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020235.html>\n> highlighting the dangers many months ago or recent posts. Normally Optech\n> is very high signal.)\n>\n> Alternatively this was the first time a contentious soft fork activation\n> was attempted, we were all woefully unprepared for it and none of us knew\n> what we were doing.\n>\n> I\u2019m unsure on the above. I\u2019d be interested to hear thoughts. What I am\n> sure of is that it is totally unacceptable for one individual to bring the\n> entire Bitcoin network to the brink of a chain split. There has to be a\n> personal cost to that individual dissuading them from trying it again\n> otherwise they\u2019re motivated to try it again every week/month. Perhaps the\n> personal cost that the community is now prepared if that individual tries\n> it again is sufficient. I\u2019m not sure. Obviously Bitcoin is a permissionless\n> network, Bitcoin Core and other open source projects are easily forked and\n> no authority (I\u2019m certainly no authority) can stop things like this\n> happening again.\n>\n> I\u2019ll follow the responses if people have thoughts (I won't be responding\n> to the instigators of this contentious soft fork activation attempt) but\n> other than that I\u2019d like to move on to other things than contentious soft\n> fork activations. Thanks to those who have expressed concerns publicly (too\n> many to name, Bob McElrath was often wording arguments better than I could)\n> and who were willing to engage with the URSF conversation. If an individual\n> can go directly to miners to get soft forks activated bypassing technical\n> concerns from many developers, bypassing Bitcoin Core and bypassing users\n> Bitcoin is fundamentally broken. The reason I still have hope that it isn't\n> is that during a period of general apathy some people were willing to stand\n> up and actively resist it.\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> Keybase: michaelfolkson\n> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220501/7158d8ed/attachment.html>"
            },
            {
                "author": "John Tromp",
                "date": "2022-05-06T19:58:44",
                "message_text_only": "On Fri, 6 May 2022 7:17PM Jorge Tim?n wrote\n> But let's not personally attack andreas for his opinions.\n> The only reason you don't like bip8 is because you're ignorant about it and\n> you haven't reviewed it enough.\n\nCan you see the irony in equating \"clueless about BIP119\" with a\npersonal attack and then calling Jeremy ignorant about BIP8?\n\n-John"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2022-05-07T01:57:39",
                "message_text_only": "It is quite ironic that yeah, it is quite ironic that the people who are\nconstantly basing their arguments on personal attack are also the ones who\ncomplain the most about personal attacks. That's exactly the irony I was\ntrying to convey.\nJust like some people claim that the only people against bip119 are people\nignorant about bip119, I can also claim that everyone against bip8 doesn't\nreally understand it, can't I?\nThe same people who spread the misinformation that bip8 \"would be perceived\nby most users as developers trying to dictate changes\" are now complaining\nabout people spreading misinformation about their own proposals. I\npersonally find it as ironic as it can get.\nI'm glad I'm not the only one who noticed how ironic the whole situation is.\nHow often are the people claiming to be concerned about misinformation\nprecisely the ones who spread the most misinformation?\nVery ironic indeed.\n\nOn Fri, May 6, 2022 at 10:07 PM John Tromp via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Fri, 6 May 2022 7:17PM Jorge Tim?n wrote\n> > But let's not personally attack andreas for his opinions.\n> > The only reason you don't like bip8 is because you're ignorant about it\n> and\n> > you haven't reviewed it enough.\n>\n> Can you see the irony in equating \"clueless about BIP119\" with a\n> personal attack and then calling Jeremy ignorant about BIP8?\n>\n> -John\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220507/421e13dc/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "What to do when contentious soft fork activations are attempted",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Ryan Grant",
                "Russell O'Connor",
                "alicexbt",
                "Jorge Tim\u00f3n",
                "John Tromp",
                "Billy Tetrud"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 46418
        }
    },
    {
        "title": "[bitcoin-dev] BIP proposal: Timelocked address fidelity bond for BIP39 seeds",
        "thread_messages": [
            {
                "author": "Chris Belcher",
                "date": "2022-05-01T08:57:25",
                "message_text_only": "See \nhttps://gist.github.com/chris-belcher/7257763cedcc014de2cd4239857cd36e \nfor the latest version of this BIP.\n\n<pre>\n   BIP: TBD. Preferably a two-digit number to match the bip44, bip49, \nbip84, bip86 family of bips\n   Layer: Applications\n   Title: Derivation scheme for storing timelocked address fidelity \nbonds in BIP39 phrases\n   Author: Chris Belcher <belcher at riseup dot net>\n   Status: Draft\n   Type: Standards Track\n   Comments-Summary: No comments yet.\n   Created: 2022-04-01\n   License: CC0-1.0\n</pre>\n\n== Abstract ==\n\nThis BIP defines the derivation scheme for BIP39 seed phrases which \ncreate timelocked addresses used for creating fidelity bonds. It also \ndefines how to sign fidelity bond certificates, which are needed when \nusing fidelity bonds that are stored offline.\n\n== Motivation ==\n\nFidelity bonds are used to resist sybil attacks in certain decentralized \nanonymous protocols. They are created by locking up bitcoins using the \n`OP_CHECKLOCKTIMEVERIFY` opcode.\n\nIt would be useful to have a common derivation scheme so that users of \nwallet software can have a backup of their fidelity bonds by storing \nonly the BIP39 seed phrase and a reference to this BIP. Importantly the \nuser does not need to backup any timelock values.\n\nWe largely use the same approach used in BIPs 49, 84 and 86 for ease of \nimplementation.\n\nThis standard is already implemented and deployed in JoinMarket. As most \nchanges would requires a protocol change of a live system, there is \nlimited scope for changing this standard in review. This BIP is more \nabout documenting something which already exists, warts and all.\n\n== Background ==\n\n=== Fidelity bonds ===\n\nA fidelity bond is a mechanism where bitcoin value is deliberately \nsacrificed to make a cryptographic identity expensive to obtain. A way \nto create a fidelity bond is to lock up bitcoins by sending them to a \ntimelocked address. The valuable thing being sacrificed is the \ntime-value-of-money.\n\nThe sacrifice must be done in a way that can be proven to a third party. \nThis proof can be made by showing the UTXO outpoint, the address \nredeemscript and a signature which signs a message using the private key \ncorresponding to the public key in the redeemscript.\n\nThe sacrificed value is an objective measurement that can't be faked and \nwhich can be verified by anybody (just like, for example PoW mining). \nSybil attacks can be made very expensive by forcing a hypothetical sybil \nattacker to lock up many bitcoins for a long time. JoinMarket implements \nfidelity bonds for protection from sybil attackers. At the time of \nwriting over 600 BTC in total have been locked up with some for many \nyears. Their UTXOs and signatures have been advertised to the world as \nproof. We can calculate that for a sybil attacker to succeed in unmixing \nall the CoinJoins, they would have to lock up over 100k BTC for several \nyears.\n\n=== Fidelity bonds in cold storage ===\n\nIt would be useful to be able to keep the private keys of timelocked \naddresses in cold storage. This would allow the sybil resistance of a \nsystem to increase without hot wallet risk. For this reason there is an \nintermediate keypair called the certificate.\n\n     UTXO key ---signs---> certificate ---signs---> endpoint (e.g. IRC \nnickname or tor .onion hostname)\n\nThe certificate keypair can be kept online and used to prove ownership \nof the fidelity bond. Even if the hot wallet private keys are stolen, \nthe coins in the timelocked address will still be safe, although the \nthief will be able to impersonate the fidelity bond until the expiry.\n\n=== Fixed timelock values ===\n\nIt would be useful for the user to avoid having to keep a record of the \ntimelocks in the time-locked addresses. So only a limited small set of \ntimelocks are defined by this BIP. This way the user must only store \ntheir seed phrase, and knowledge that they have coins stored using this \nBIP standard. The user doesn't need to remember or store any dates.\n\n\n== Specifications ==\n\nThis BIP defines the two needed steps to derive multiple deterministic \naddresses based on a [[bip-0032.mediawiki|BIP 32]] master private key. \nIt also defines the format of the certificate can be signed by the \ndeterministic address key.\n\n=== Public key derivation ===\n\nTo derive a public key from the root account, this BIP uses a similar \naccount-structure as defined in BIP [[bip-0084.mediawiki|44]] but with \n<tt>change</tt> set to <tt>2</tt>.\n\n<pre>\nm / 84' / 0' / 0' / 2 / index\n</pre>\n\nA key derived with this derivation path pattern will be referred to as \n<tt>derived_key</tt> further\nin this document.\n\nFor <tt>index</tt>, addresses are numbered from 0 in a sequentially \nincreasing manner, but index does not increase forever like in other \nsimilar standards. The index only goes up to <tt>959</tt> inclusive. \nOnly 960 addresses can be derived for a given BIP32 master key. \nFurthermore there is no concept of a gap limit, instead wallets must \nalways generate all 960 addresses and check all of them if they have a \nbalance and history.\n\n=== Timelock derivation ===\n\nThe timelock used in the time-locked address is derived from the \n<tt>index</tt>. The timelock is a unix time. It is always the first of \nthe month at midnight. The <tt>index</tt> counts upwards the months from \nJanuary 2020, ending in December 2099. At 12 months per year for 80 \nyears this totals 960 timelocks. Note that care must be taken with the \nyear 2038 problem on 32-bit systems.\n\n<pre>\nyear = 2020 + index // 12\nmonth = 1 + index % 12\n</pre>\n\n\n=== Address derivation ===\n\nTo derive the address from the above calculated public key and timelock, \nwe create a <tt>redeemScript</tt> which locks the funds until the \n<tt>timelock</tt>, and then checks the signature of the \n<tt>derived_key</tt>. The <tt>redeemScript</tt> is hashed with SHA256 to \nproduce a 32-byte hash value that forms the <tt>scriptPubKey</tt> of the \nP2WSH address.\n\n     redeemScript: <timelock> OP_CHECKLOCKTIMEVERIFY OP_DROP \n<derived_key> OP_CHECKSIG\n     witness:      <signature> <pubkey>\n     scriptSig:    (empty)\n     scriptPubKey: 0 <32-byte-hash>\n                   (0x0020{32-byte-hash})\n\n=== Certificate message derivation ===\n\nTo create a certificate needed for using fidelity bonds in cold storage, \nanother application external to this standard will create a ECDSA \nkeypair. The public key of this keypair and an integer called the \n`expiry` will be used to create a certificate message.\n\nThe certificate message is defined as:\n\n    'fidelity-bond-cert|' + cert_pubkey + '|' + cert_expiry\n\nwhere + denotes concatenation. `cert_pubkey` is encoded as a hex string, \nand `cert_expiry` is encoded as an ascii string of the integer.\n\nThis certificate message is then prepended with the string `\\x18Bitcoin \nSigned Message:\\n` and a byte denoting the length of the certificate \nmessage. The whole thing is then signed with the private key of the \n<tt>derived_key</tt>. This part is identical to the \"Sign Message\" \nfunction which many wallets already implement.\n\nAlmost all wallets implementing this standard can use their \nalready-existing \"Sign Message\" function to sign the certificate \nmessage. As the certificate message itself is always an ascii string, \nthe wallet may not need to specially implement this section at all but \njust rely on users copypasting their certificate message into the \nalready-existing \"Sign Message\" user interface. This works as long as \nthe wallet knows how to use the private key of the timelocked address \nfor signing messages.\n\nIt is most important for wallet implementions of this standard to \nsupport creating the certificate signature. Verifying the certificate \nsignature is less important.\n\n\n== Test vectors ==\n\n<pre>\nmnemonic = abandon abandon abandon abandon abandon abandon abandon \nabandon abandon abandon abandon about\nrootpriv = \nxprv9s21ZrQH143K3GJpoapnV8SFfukcVBSfeCficPSGfubmSFDxo1kuHnLisriDvSnRRuL2Qrg5ggqHKNVpxR86QEC8w35uxmGoggxtQTPvfUu\nrootpub  = \nxpub661MyMwAqRbcFkPHucMnrGNzDwb6teAX1RbKQmqtEF8kK3Z7LZ59qafCjB9eCRLiTVG3uxBxgKvRgbubRhqSKXnGGb1aoaqLrpMBDrVxga8\n\n// First timelocked address = m/84'/0'/0'/2/0\nderived private_key = L2tQBEdhC48YLeEWNg3e4msk94iKfyVa9hdfzRwUERabZ53TfH3d\nderived public_key  = \n02a1b09f93073c63f205086440898141c0c3c6d24f69a18db608224bcf143fa011\nunix locktime       = 1577836800\nstring locktime     = 2020-01-01 00:00:00\nredeemscript        = \n0400e10b5eb1752102a1b09f93073c63f205086440898141c0c3c6d24f69a18db608224bcf143fa011ac\nscriptPubKey        = \n0020bdee9515359fc9df912318523b4cd22f1c0b5410232dc943be73f9f4f07e39ad\naddress             = \nbc1qhhhf29f4nlyalyfrrpfrknxj9uwqk4qsyvkujsa7w0ulfur78xkspsqn84\n\n// Test certificate using first timelocked address\n// Note that as signatures contains a random nonce, it might not be \nexactly the same when your code generates it\n// p2pkh address is the p2pkh address corresponding to the derived \npublic key, it can be used to verify the message\n//  signature in any wallet that supports Verify Message.\n// As mentioned before, it is more important for implementors of this \nstandard to support signing such messages, not verifying them\nMessage       = \nfidelity-bond-cert|020000000000000000000000000000000000000000000000000000000000000001|375\nAddress       = \nbc1qhhhf29f4nlyalyfrrpfrknxj9uwqk4qsyvkujsa7w0ulfur78xkspsqn84\np2pkh address = 16vmiGpY1rEaYnpGgtG7FZgr2uFCpeDgV6\nSignature     = \nH2b/90XcKnIU/D1nSCPhk8OcxrHebMCr4Ok2d2yDnbKDTSThNsNKA64CT4v2kt+xA1JmGRG/dMnUUH1kKqCVSHo=\n\n// 2nd timelocked address = m/84'/0'/0'/2/1\nderived private_key = KxctaFBzetyc9KXeUr6jxESCZiCEXRuwnQMw7h7hroP6MqnWN6Pf\nderived public_key  = \n02599f6db8b33265a44200fef0be79c927398ed0b46c6a82fa6ddaa5be2714002d\nunix locktime       = 1580515200\nstring locktime     = 2020-02-01 00:00:00\nredeemscript        = \n0480bf345eb1752102599f6db8b33265a44200fef0be79c927398ed0b46c6a82fa6ddaa5be2714002dac\nscriptPubKey        = \n0020b8f898643991608524ed04e0c6779f632a57f1ffa3a3a306cd81432c5533e9ae\naddress             = \nbc1qhrufsepej9sg2f8dqnsvvaulvv490u0l5w36xpkds9pjc4fnaxhq7pcm4h\n\n// timelocked address after the year 2038 problem = m/84'/0'/0'/2/240\nderived private_key = L3SYqae23ZoDDcyEA8rRBK83h1MDqxaDG57imMc9FUx1J8o9anQe\nderived public_key  = \n03ec8067418537bbb52d5d3e64e2868e67635c33cfeadeb9a46199f89ebfaab226\nunix locktime       = 2208988800\nstring locktime     = 2040-01-01 00:00:00\nredeemscript        = \n05807eaa8300b1752103ec8067418537bbb52d5d3e64e2868e67635c33cfeadeb9a46199f89ebfaab226ac\nscriptPubKey        = \n0020e7de0ad2720ae1d6cc9b6ad91af57eb74646762cf594c91c18f6d5e7a873635a\naddress             = \nbc1qul0q45njptsadnymdtv34at7karyva3v7k2vj8qc7m2702rnvddq0z20u5\n\n// last timelocked address = m/84'/0'/0'/2/959\nderived private_key = L5Z9DDMnj5RZMyyPiQLCvN48Xt7GGmev6cjvJXD8uz5EqiY8trNJ\nderived public_key  = \n0308c5751121b1ae5c973cdc7071312f6fc10ab864262f0cbd8134f056166e50f3\nunix locktime       = 4099766400\nstring locktime     = 2099-12-01 00:00:00\nredeemscript        = \n0580785df400b175210308c5751121b1ae5c973cdc7071312f6fc10ab864262f0cbd8134f056166e50f3ac\nscriptPubKey        = \n0020803268e042008737cf439748cbb5a4449e311da9aa64ae3ac56d84d059654f85\naddress             = \nbc1qsqex3czzqzrn0n6rjayvhddygj0rz8df4fj2uwk9dkzdqkt9f7zs5c493u\n</pre>\n\nCode generating these test vectors can be found here: \nhttps://github.com/chris-belcher/timelocked-addresses-fidelity-bond-bip-testvectors\n\n==Reference==\n\n* \n[[https://gist.github.com/chris-belcher/18ea0e6acdb885a2bfbdee43dcd6b5af/|Design \nfor improving JoinMarket's resistance to sybil attacks using fidelity \nbonds]]\n* \n[[https://github.com/JoinMarket-Org/joinmarket-clientserver/blob/master/docs/fidelity-bonds.md|JoinMarket \nfidelity bonds doc page]]\n* [[bip-0065.mediawiki|BIP86 - OP_CHECKLOCKTIMEVERIFY]]\n* [[bip-0032.mediawiki|BIP32 - Hierarchical Deterministic Wallets]]\n* [[bip-0044.mediawiki|BIP44 - Multi-Account Hierarchy for Deterministic \nWallets]]\n* [[bip-0049.mediawiki|BIP49 - Derivation scheme for \nP2WPKH-nested-in-P2SH based accounts]]\n* [[bip-0084.mediawiki|BIP84 - Derivation scheme for P2WPKH based accounts]]\n* [[bip-0086.mediawiki|BIP86 - Key Derivation for Single Key P2TR Outputs]]"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-01T09:43:39",
                "message_text_only": "Good morning Chris,\n\nExcellent BIP!\n\n>From a quick read-over, it seems to me that the fidelity bond does not commit to any particular scheme or application.\nThis means (as I understand it) that the same fidelity bond can be used to prove existence across multiple applications.\nI am uncertain whether this is potentially abusable or not.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Chris Belcher",
                "date": "2022-05-01T10:01:49",
                "message_text_only": "Hello ZmnSCPxj,\n\nThis is an intended feature. I'm thinking that the same fidelity bond \ncan be used to running a JoinMarket maker as well as a Teleport \n(Coinswap) maker.\n\nI don't believe it's abusable. It would be a problem if the same \nfidelity bond is used by two makers in the _same_ application, but \nJoinMarket takers are already coded to check for this, and Teleport \ntakers will soon as well. Using the same bond across different \napplications is fine.\n\nBest,\nCB\n\nOn 01/05/2022 10:43, ZmnSCPxj wrote:\n> Good morning Chris,\n> \n> Excellent BIP!\n> \n>>From a quick read-over, it seems to me that the fidelity bond does not commit to any particular scheme or application.\n> This means (as I understand it) that the same fidelity bond can be used to prove existence across multiple applications.\n> I am uncertain whether this is potentially abusable or not.\n> \n> \n> Regards,\n> ZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-01T11:41:50",
                "message_text_only": "Good morning again Chris,\n\nI wonder if there would be an incentive to *rent* out a fidelity bond, i.e. I am interested in application A, you are interested in application B, and you rent my fidelity bond for application B.\nWe can use a pay-for-signature protocol now that Taproot is available, so that the signature for the certificate for your usage of application B can only be completed if I reveal a secret via a signature on another Taproot UTXO that gets me the rent for the fidelity bond.\n\nI do not know if this would count as \"abuse\" or just plain \"economic sensibility\".\nBut a time may come where people just offer fidelity bonds for lease without actually caring about the actual applications it is being used *for*.\nIf the point is simply to make it costly to show your existence, whether you pay for the fidelity bond by renting it, or by acquiring your own Bitcoins and foregoing the ability to utilize it for some amount of time (which should cost closely to renting the fidelity bond from a provider), should probably not matter economically.\n\nYou mention that JoinMarket clients now check for fidelity bonds not being used across multiple makers, how is this done exactly, and does the technique not deserve a section in this BIP?\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Chris Belcher",
                "date": "2022-05-02T09:23:50",
                "message_text_only": "Hello ZmnSCPxj,\n\nRenting out fidelity bonds is an interesting idea. It might happen in \nthe situation where a hodler wants to generate yield but doesn't want \nthe hassle of running a full node and yield generator. A big downside of \nit is that the yield generator income is random while the rent paid is a \nfixed cost, so there's a chance that the income won't cover the rent.\n\nJoinMarket takers since the start have checked that a fidelity bond \ndoesn't appear twice. The technique doesn't deserve a section in the BIP \nbecause this BIP is only about specifying the wallets that hold fidelity \nbond UTXOs for makers, not takers which receive fidelity bond messages.\n\nIn JoinMarket this is done in this code here:\nhttps://github.com/JoinMarket-Org/joinmarket-clientserver/blob/6b05f65260a487cd22f175ba64d499fbe8122530/jmclient/jmclient/taker.py#L1020-L1021\n\nBest,\nCB\n\nOn 01/05/2022 12:41, ZmnSCPxj wrote:\n> Good morning again Chris,\n> \n> I wonder if there would be an incentive to *rent* out a fidelity bond, i.e. I am interested in application A, you are interested in application B, and you rent my fidelity bond for application B.\n> We can use a pay-for-signature protocol now that Taproot is available, so that the signature for the certificate for your usage of application B can only be completed if I reveal a secret via a signature on another Taproot UTXO that gets me the rent for the fidelity bond.\n> \n> I do not know if this would count as \"abuse\" or just plain \"economic sensibility\".\n> But a time may come where people just offer fidelity bonds for lease without actually caring about the actual applications it is being used *for*.\n> If the point is simply to make it costly to show your existence, whether you pay for the fidelity bond by renting it, or by acquiring your own Bitcoins and foregoing the ability to utilize it for some amount of time (which should cost closely to renting the fidelity bond from a provider), should probably not matter economically.\n> \n> You mention that JoinMarket clients now check for fidelity bonds not being used across multiple makers, how is this done exactly, and does the technique not deserve a section in this BIP?\n> \n> Regards,\n> ZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-03T05:26:46",
                "message_text_only": "Good morning Chris,\n\n> Hello ZmnSCPxj,\n>\n> Renting out fidelity bonds is an interesting idea. It might happen in\n> the situation where a hodler wants to generate yield but doesn't want\n> the hassle of running a full node and yield generator. A big downside of\n> it is that the yield generator income is random while the rent paid is a\n> fixed cost, so there's a chance that the income won't cover the rent.\n\nThe fact that *renting* is at all possible suggests to me that the following situation *could* arise:\n\n* A market of lessors arises.\n* A surveillor creates multiple identities.\n* Each fake identity rents separately from multiple lessors.\n* Surveillor gets privacy data by paying out rent money to the lessor market.\n\nIn defiads, I and Tamas pretty much concluded that rental would happen inevitably.\nOne could say that defiads was a kind of fidelity bond system.\nOur solution for defiads was to prioritize propagating advertisements (roughly equivalent to the certificates in your system, I think) with larger bonded values * min(bonded_time, 1 year).\nHowever, do note that we did not intend defiads to be used for privacy-sensitive applications like JoinMarket/Teleport.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Chris Belcher",
                "date": "2022-05-03T18:03:12",
                "message_text_only": "Hello ZmnSCPxj,\n\nSuch a system will have to be publicly advertised, in the same way we \nsee centralized cryptocurrency staking shops buying ads all over the \nplace. That's how they'll make retail hodlers aware that renting out \nyour coins in this way is possible. If JoinMarket/Teleport users notice \nsuch ads appearing then we could change the taker code to remove the \nintermediate certificate keypair, and have the fidelity bond UTXO key \nsign the endpoint (IRC nickname or onion hostname) directly. This \nremoves the possibility of fidelity bonds in cold storage. It would have \nto be done for privacy, and it wouldn't be too bad. Right now there's no \ncold storage solution for fidelity bonds yet JoinMarket has about 600 \nbitcoins locked up and advertised, which must be all on hot wallets.\n\nBest,\nCB\n\nOn 03/05/2022 06:26, ZmnSCPxj wrote:\n> Good morning Chris,\n> \n>> Hello ZmnSCPxj,\n>>\n>> Renting out fidelity bonds is an interesting idea. It might happen in\n>> the situation where a hodler wants to generate yield but doesn't want\n>> the hassle of running a full node and yield generator. A big downside of\n>> it is that the yield generator income is random while the rent paid is a\n>> fixed cost, so there's a chance that the income won't cover the rent.\n> \n> The fact that *renting* is at all possible suggests to me that the following situation *could* arise:\n> \n> * A market of lessors arises.\n> * A surveillor creates multiple identities.\n> * Each fake identity rents separately from multiple lessors.\n> * Surveillor gets privacy data by paying out rent money to the lessor market.\n> \n> In defiads, I and Tamas pretty much concluded that rental would happen inevitably.\n> One could say that defiads was a kind of fidelity bond system.\n> Our solution for defiads was to prioritize propagating advertisements (roughly equivalent to the certificates in your system, I think) with larger bonded values * min(bonded_time, 1 year).\n> However, do note that we did not intend defiads to be used for privacy-sensitive applications like JoinMarket/Teleport.\n> \n> \n> Regards,\n> ZmnSCPxj"
            },
            {
                "author": "Eric Voskuil",
                "date": "2022-05-03T18:26:52",
                "message_text_only": "It looks like you are talking about lending where the principal return is guaranteed by covenant at maturity. This make the net present value of the loan zero.\n\ne\n\n> On May 3, 2022, at 11:03, Chris Belcher via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> \ufeffHello ZmnSCPxj,\n> \n> Such a system will have to be publicly advertised, in the same way we see centralized cryptocurrency staking shops buying ads all over the place. That's how they'll make retail hodlers aware that renting out your coins in this way is possible. If JoinMarket/Teleport users notice such ads appearing then we could change the taker code to remove the intermediate certificate keypair, and have the fidelity bond UTXO key sign the endpoint (IRC nickname or onion hostname) directly. This removes the possibility of fidelity bonds in cold storage. It would have to be done for privacy, and it wouldn't be too bad. Right now there's no cold storage solution for fidelity bonds yet JoinMarket has about 600 bitcoins locked up and advertised, which must be all on hot wallets.\n> \n> Best,\n> CB\n> \n>> On 03/05/2022 06:26, ZmnSCPxj wrote:\n>> Good morning Chris,\n>>> Hello ZmnSCPxj,\n>>> \n>>> Renting out fidelity bonds is an interesting idea. It might happen in\n>>> the situation where a hodler wants to generate yield but doesn't want\n>>> the hassle of running a full node and yield generator. A big downside of\n>>> it is that the yield generator income is random while the rent paid is a\n>>> fixed cost, so there's a chance that the income won't cover the rent.\n>> The fact that *renting* is at all possible suggests to me that the following situation *could* arise:\n>> * A market of lessors arises.\n>> * A surveillor creates multiple identities.\n>> * Each fake identity rents separately from multiple lessors.\n>> * Surveillor gets privacy data by paying out rent money to the lessor market.\n>> In defiads, I and Tamas pretty much concluded that rental would happen inevitably.\n>> One could say that defiads was a kind of fidelity bond system.\n>> Our solution for defiads was to prioritize propagating advertisements (roughly equivalent to the certificates in your system, I think) with larger bonded values * min(bonded_time, 1 year).\n>> However, do note that we did not intend defiads to be used for privacy-sensitive applications like JoinMarket/Teleport.\n>> Regards,\n>> ZmnSCPxj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-04T02:37:10",
                "message_text_only": "Good morning e,\n\n\n> It looks like you are talking about lending where the principal return is guaranteed by covenant at maturity. This make the net present value of the loan zero.\n\nI am talking about lending where:\n\n* Lessor pays landlord X satoshis in rent.\n* Landlord provides use of the fidelity bond coin (value Y) for N blocks.\n* Landlord gets the entire fidelity bond amount (Y) back.\n\nThus, the landlord gets X + Y satoshis, earning X satoshis, at the cost of having Y satoshis locked for N blocks.\n\nSo I do not understand why the value of this, to the landlord, would be 0.\nCompare to a simple HODL strategy, where I lock Y satoshis for N blocks and get Y satoshi back.\nOr are you saying that a simple HODL strategy is of negative value and that \"zero value\" is the point where you actively invest all your savings?\nOr are you saying that HODL strategy is of some value since it still allows you to spend funds freely in the N blocks you are HODLing them, and the option to spend is of value, while dedfinitely locking the value Y for N blocks is equal to the value X of the rent paid (and thus net zero value)?\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "eric at voskuil.org",
                "date": "2022-05-04T04:04:10",
                "message_text_only": "Good evening ZmnSCPxj,\n\nFor the sake of simplicity, I'll use the terms lender (Landlord), borrower (Lessor), interest (X), principal (Y), period (N) and maturity (height after N).\n\nThe lender in your scenario \"provides use\" of the principal, and is paid interest in exchange. This is of course the nature of lending, as a period without one's capital incurs an opportunity cost that must be offset (by interest).\n\nThe borrower's \"use\" of the principal is what is being overlooked. To generate income from capital one must produce something and sell it. Production requires both capital and time. Borrowing the principle for the period allows the borrower to produce goods, sell them, and return the \"profit\" as interest to the lender. Use implies that the borrower is spending the principle - trading it with others. Eventually any number of others end up holding the principle. At maturity, the coin is returned to the lender (by covenant). At that point, all people the borrower traded with are bag holders. Knowledge of this scam results in an imputed net present zero value for the borrowed principal.\n\nWhile the lack of usability is a cost to the lender, it is not a benefit to the borrower. The lender incurs no risk, and will obtain no reward - as the loan is of no value. Failure to deploy capital is an opportunity cost, and locking it up is not deployment.\n\nNow, even if we accept the generous (economically irrational) assumption that money must increase in price (i.e. trades from more goods) over any given period, we are still left with the observation that the presumed appreciation would accrue to the lender absent lending, making it pointless.\n\ne\n\n> -----Original Message-----\n> From: ZmnSCPxj <ZmnSCPxj at protonmail.com>\n> Sent: Tuesday, May 3, 2022 7:37 PM\n> To: Eric Voskuil <eric at voskuil.org>\n> Cc: Chris Belcher <belcher at riseup.net>; Bitcoin Protocol Discussion <bitcoin-\n> dev at lists.linuxfoundation.org>\n> Subject: Re: [bitcoin-dev] BIP proposal: Timelocked address fidelity bond for\n> BIP39 seeds\n> \n> Good morning e,\n> \n> \n> > It looks like you are talking about lending where the principal return is\n> guaranteed by covenant at maturity. This make the net present value of the\n> loan zero.\n> \n> I am talking about lending where:\n> \n> * Lessor pays landlord X satoshis in rent.\n> * Landlord provides use of the fidelity bond coin (value Y) for N blocks.\n> * Landlord gets the entire fidelity bond amount (Y) back.\n> \n> Thus, the landlord gets X + Y satoshis, earning X satoshis, at the cost of having Y\n> satoshis locked for N blocks.\n> \n> So I do not understand why the value of this, to the landlord, would be 0.\n> Compare to a simple HODL strategy, where I lock Y satoshis for N blocks and\n> get Y satoshi back.\n> Or are you saying that a simple HODL strategy is of negative value and that\n> \"zero value\" is the point where you actively invest all your savings?\n> Or are you saying that HODL strategy is of some value since it still allows you\n> to spend funds freely in the N blocks you are HODLing them, and the option to\n> spend is of value, while dedfinitely locking the value Y for N blocks is equal to\n> the value X of the rent paid (and thus net zero value)?\n> \n> Regards,\n> ZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-04T04:19:25",
                "message_text_only": "Good morning e,\n\n> Good evening ZmnSCPxj,\n>\n> For the sake of simplicity, I'll use the terms lender (Landlord), borrower (Lessor), interest (X), principal (Y), period (N) and maturity (height after N).\n>\n> The lender in your scenario \"provides use\" of the principal, and is paid interest in exchange. This is of course the nature of lending, as a period without one's capital incurs an opportunity cost that must be offset (by interest).\n>\n> The borrower's \"use\" of the principal is what is being overlooked. To generate income from capital one must produce something and sell it. Production requires both capital and time. Borrowing the principle for the period allows the borrower to produce goods, sell them, and return the \"profit\" as interest to the lender. Use implies that the borrower is spending the principle - trading it with others. Eventually any number of others end up holding the principle. At maturity, the coin is returned to the lender (by covenant). At that point, all people the borrower traded with are bag holders. Knowledge of this scam results in an imputed net present zero value for the borrowed principal.\n\nBut in this scheme, the principal is not being used as money, but as a billboard for an advertisement.\nThus, the bitcoins are not being used as money due to the use of the fidelity bond to back a \"you can totally trust me I am not a bot!!\" assertion.\nThis is not the same as your scenario --- the funds are never transferred, instead, a different use of the locked funds is invented.\n\nAs a better analogy: I am borrowing a piece of gold, smelting it down to make a nice shiny advertisement \"I am totally not a bot!!\", then at the end of the lease period, re-smelting it back and returning to you the same gold piece (with the exact same atoms constituting it), plus an interest from my business, which gained customers because of the shiny gold advertisement claiming \"I am totally not a bot!!\".\n\nThat you use the same piece of gold for money does not preclude me using the gold for something else of economic value, like making a nice shiny advertisement, so I think your analysis fails there.\nOtherwise, your analysis is on point, but analyses something else entirely.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "eric at voskuil.org",
                "date": "2022-05-18T03:06:29",
                "message_text_only": "Good evening ZmnSCPxj,\n\nSorry for the long delay...\n\n> Good morning e,\n> \n> > Good evening ZmnSCPxj,\n> >\n> > For the sake of simplicity, I'll use the terms lender (Landlord), borrower\n> > (Lessor), interest (X), principal (Y), period (N) and maturity (height after N).\n> >\n> > The lender in your scenario \"provides use\" of the principal, and is paid\n> > interest in exchange. This is of course the nature of lending, as a period\n> > without one's capital incurs an opportunity cost that must be offset (by\n> > interest).\n> >\n> > The borrower's \"use\" of the principal is what is being overlooked. To\n> > generate income from capital one must produce something and sell it.\n> > Production requires both capital and time. Borrowing the principle for the\n> > period allows the borrower to produce goods, sell them, and return the\n> > \"profit\" as interest to the lender. Use implies that the borrower is spending\n> > the principle - trading it with others. Eventually any number of others end up\n> > holding the principle. At maturity, the coin is returned to the lender (by\n> > covenant). At that point, all people the borrower traded with are bag holders.\n> > Knowledge of this scam results in an imputed net present zero value for the\n> > borrowed principal.\n> \n> But in this scheme, the principal is not being used as money, but as a billboard\n> for an advertisement.\n>\n> Thus, the bitcoins are not being used as money due to the use of the fidelity\n> bond to back a \"you can totally trust me I am not a bot!!\" assertion.\n> This is not the same as your scenario --- the funds are never transferred,\n> instead, a different use of the locked funds is invented.\n> \n> As a better analogy: I am borrowing a piece of gold, smelting it down to make\n> a nice shiny advertisement \"I am totally not a bot!!\", then at the end of the\n> lease period, re-smelting it back and returning to you the same gold piece\n> (with the exact same atoms constituting it), plus an interest from my business,\n> which gained customers because of the shiny gold advertisement claiming \"I\n> am totally not a bot!!\".\n> \n> That you use the same piece of gold for money does not preclude me using\n> the gold for something else of economic value, like making a nice shiny\n> advertisement, so I think your analysis fails there.\n> Otherwise, your analysis is on point, but analyses something else entirely.\n\nOk, so you are suggesting the renting of someone else's proof of \"burn\" (opportunity cost) to prove your necessary expense - the financial equivalent of your own burn. Reading through the thread, it looks like you are suggesting this as a way the cost of the burn might be diluted across multiple uses, based on the obscuration of the identity. And therefore identity (or at least global uniqueness) enters the equation. Sounds like a reasonable concern to me.\n\nIt appears that the term \"fidelity bond\" is generally accepted, though I find this an unnecessarily misleading analogy. A bond is a loan (capital at risk), and a fidelity bond is also capital at risk (to provide assurance of some behavior). Proof of burn/work, such as Hash Cash (and Bitcoin), is merely demonstration of a prior expense. But in those cases, the expense is provably associated. As you have pointed out, if the burn is not associated with the specific use, it can be reused, diluting the demonstrated expense to an unprovable degree.\n\nI can see how you come to refer to selling the PoB as \"lending\" it, because the covenant on the underlying coin is time constrained. But nothing is actually lent here. The \"advertisement\" created by the covenant (and its presumed exclusivity) is sold. This is also entirely consistent with the idea that a loan implies capital at risk. While this is nothing more than a terminology nit, the use of \"fidelity bond\" and the subsequent description of \"renting\" (the fidelity bond) both led me down another path (Tamas' proposal for risk free lending under covenant, which we discussed here years ago).\n\nIn any case, I tend to agree with your other posts on the subject. For the burn to be provably non-dilutable it must be a cost provably associated to the scenario which relies upon the cost. This provides the global uniqueness constraint (under cryptographic assumptions of difficulty).\n\nBest,\ne\n\n> Regards,\n> ZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-18T06:29:23",
                "message_text_only": "Good morning e,\n\n> Good evening ZmnSCPxj,\n>\n> Sorry for the long delay...\n\nThank you very much for responding.\n\n>\n> > Good morning e,\n> >\n> > > Good evening ZmnSCPxj,\n> > >\n> > > For the sake of simplicity, I'll use the terms lender (Landlord), borrower\n> > > (Lessor), interest (X), principal (Y), period (N) and maturity (height after N).\n> > >\n> > > The lender in your scenario \"provides use\" of the principal, and is paid\n> > > interest in exchange. This is of course the nature of lending, as a period\n> > > without one's capital incurs an opportunity cost that must be offset (by\n> > > interest).\n> > >\n> > > The borrower's \"use\" of the principal is what is being overlooked. To\n> > > generate income from capital one must produce something and sell it.\n> > > Production requires both capital and time. Borrowing the principle for the\n> > > period allows the borrower to produce goods, sell them, and return the\n> > > \"profit\" as interest to the lender. Use implies that the borrower is spending\n> > > the principle - trading it with others. Eventually any number of others end up\n> > > holding the principle. At maturity, the coin is returned to the lender (by\n> > > covenant). At that point, all people the borrower traded with are bag holders.\n> > > Knowledge of this scam results in an imputed net present zero value for the\n> > > borrowed principal.\n> >\n> > But in this scheme, the principal is not being used as money, but as a billboard\n> > for an advertisement.\n> >\n> > Thus, the bitcoins are not being used as money due to the use of the fidelity\n> > bond to back a \"you can totally trust me I am not a bot!!\" assertion.\n> > This is not the same as your scenario --- the funds are never transferred,\n> > instead, a different use of the locked funds is invented.\n> >\n> > As a better analogy: I am borrowing a piece of gold, smelting it down to make\n> > a nice shiny advertisement \"I am totally not a bot!!\", then at the end of the\n> > lease period, re-smelting it back and returning to you the same gold piece\n> > (with the exact same atoms constituting it), plus an interest from my business,\n> > which gained customers because of the shiny gold advertisement claiming \"I\n> > am totally not a bot!!\".\n> >\n> > That you use the same piece of gold for money does not preclude me using\n> > the gold for something else of economic value, like making a nice shiny\n> > advertisement, so I think your analysis fails there.\n> > Otherwise, your analysis is on point, but analyses something else entirely.\n>\n>\n> Ok, so you are suggesting the renting of someone else's proof of \"burn\" (opportunity cost) to prove your necessary expense - the financial equivalent of your own burn. Reading through the thread, it looks like you are suggesting this as a way the cost of the burn might be diluted across multiple uses, based on the obscuration of the identity. And therefore identity (or at least global uniqueness) enters the equation. Sounds like a reasonable concern to me.\n>\n> It appears that the term \"fidelity bond\" is generally accepted, though I find this an unnecessarily misleading analogy. A bond is a loan (capital at risk), and a fidelity bond is also capital at risk (to provide assurance of some behavior). Proof of burn/work, such as Hash Cash (and Bitcoin), is merely demonstration of a prior expense. But in those cases, the expense is provably associated. As you have pointed out, if the burn is not associated with the specific use, it can be reused, diluting the demonstrated expense to an unprovable degree.\n\nIndeed, that is why defiads used the term \"advertisement\" and not \"fidelity bond\".\nOne could say that defiads was a much-too-ambitious precursor of this proposed scheme.\n\n> I can see how you come to refer to selling the PoB as \"lending\" it, because the covenant on the underlying coin is time constrained. But nothing is actually lent here. The \"advertisement\" created by the covenant (and its presumed exclusivity) is sold. This is also entirely consistent with the idea that a loan implies capital at risk. While this is nothing more than a terminology nit, the use of \"fidelity bond\" and the subsequent description of \"renting\" (the fidelity bond) both led me down another path (Tamas' proposal for risk free lending under covenant, which we discussed here years ago).\n\nYes, that is why Tamas switched to defiads, as I had convinced him that it would be similar enough without actually being a covenant scam like you described.\n\n> In any case, I tend to agree with your other posts on the subject. For the burn to be provably non-dilutable it must be a cost provably associated to the scenario which relies upon the cost. This provides the global uniqueness constraint (under cryptographic assumptions of difficulty).\n\nIndeed.\nI suspect the only reason it is not *yet* a problem with existing JoinMarket and Teleport is simply that no convenient software currently exists which allows the same bond to be used by both, thus making it safe in practice but not in theory.\nBut the theory implies that if somebody does make such software, effectively both systems will become joined as effectively only a single identity exists in both systems.\nThis may not be a problem either since the intent is that Teleport will obsolete JoinMarket someday, but if other applications start using the same scheme without requiring a commitment to a specific application, this may also effectively render Teleport less useful as well.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "AdamISZ",
                "date": "2022-05-21T21:36:06",
                "message_text_only": "> > > As a better analogy: I am borrowing a piece of gold, smelting it down to make\n> > > a nice shiny advertisement \"I am totally not a bot!!\", then at the end of the\n> > > lease period, re-smelting it back and returning to you the same gold piece\n> > > (with the exact same atoms constituting it), plus an interest from my business,\n> > > which gained customers because of the shiny gold advertisement claiming \"I\n> > > am totally not a bot!!\".\n> > >\n> > > That you use the same piece of gold for money does not preclude me using\n> > > the gold for something else of economic value, like making a nice shiny\n> > > advertisement, so I think your analysis fails there.\n> > > Otherwise, your analysis is on point, but analyses something else entirely.\n\nBack to this analogy, I think it's imprecise in a way that's important to not overlook: you cannot re-use the same gold atoms in two different advertisements. Use of a fidelity bond, being basically a signature, is completely 'non-rivalrous' as I think the economists say.\n\n> Yes, that is why Tamas switched to defiads, as I had convinced him that it would be similar enough without actually being a covenant scam like you described.\n>\n> > In any case, I tend to agree with your other posts on the subject. For the burn to be provably non-dilutable it must be a cost provably associated to the scenario which relies upon the cost. This provides the global uniqueness constraint (under cryptographic assumptions of difficulty).\n>\n>\n> Indeed.\n> I suspect the only reason it is not yet a problem with existing JoinMarket and Teleport is simply that no convenient software currently exists which allows the same bond to be used by both, thus making it safe in practice but not in theory.\n> But the theory implies that if somebody does make such software, effectively both systems will become joined as effectively only a single identity exists in both systems.\n> This may not be a problem either since the intent is that Teleport will obsolete JoinMarket someday, but if other applications start using the same scheme without requiring a commitment to a specific application, this may also effectively render Teleport less useful as well.\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n\nSo, general comment: it seems like both you and Eric agree with my uncertain intuition up-thread and therefore do we all agree that the correct solution (to whatever extent there is one) is something like domain separation tags, as we discussed earlier? It's still a matter of social consensus: if appending \"JM\" to the end of a certificate signature is intended to mean that this fidelity bond can only be used in Joinmarket and not anywhere else, well we can only as individual users demand that (i.e. *I* might not accept it in Teleport, but what if Fred down the street does? It's not enough for me to rely on my own criteria!), and more subtly, it makes sense only if we all have an unambiguous definition of what Joinmarket *is* - ironically it is precisely the thing brought most into question by the achievement of real decentralization in a system.\n\nCheers,\nwaxwing/AdamISZ"
            },
            {
                "author": "AdamISZ",
                "date": "2022-05-10T12:31:00",
                "message_text_only": "------- Original Message -------\nOn Sunday, May 1st, 2022 at 11:01, Chris Belcher via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n\n> Hello ZmnSCPxj,\n>\n> This is an intended feature. I'm thinking that the same fidelity bond\n> can be used to running a JoinMarket maker as well as a Teleport\n> (Coinswap) maker.\n>\n> I don't believe it's abusable. It would be a problem if the same\n> fidelity bond is used by two makers in the same application, but\n> JoinMarket takers are already coded to check for this, and Teleport\n> takers will soon as well. Using the same bond across different\n> applications is fine.\n>\n> Best,\n> CB\n>\n\nHi Chris, Zmn, list,\nI've noodled about this a few times in the past (especially when trying to figure out an LSAG style ring sig based FB for privacy, but that does not seem workable), and I can't decide the right perspective on it.\n\nA user sacrifices X amount of time-value-of-money (henceforth TVOM) by committing in Joinmarket with FB1. He then uses the same FB1 in Teleport, let's say. If he gets benefit Y from using FB1 in Joinmarket, and benefit Z in Teleport, then presumably he'll only do it if (probabilistically) he thinks Y+Z > X.\n\nBut as an assessor of FB1 in Joinmarket, I don't know if it's also being used for Teleport, and more importantly, if it's being used somewhere else I'm not even aware of. Now I'm not an economist I admit, so I might not be intuit-ing this situation right, but it fees to me like the right answer is \"It's fine for a closed system, but not an open one.\" (i.e. if the set of possible usages is not something that all participants have fixed in advance, then there is an effective Sybilling problem, like I'm, as an assessor, thinking that sacrificed value 100 is there, whereas actually it's only 15, or whatever.)\n\nAs I mentioned in https://github.com/JoinMarket-Org/joinmarket-clientserver/issues/993#issuecomment-1110784059 , I did wonder about domain separation tags because of this, and as I vaguely alluded to there, I'm really not sure about it.\n\nIf it was me I'd want to include domain separation via part of the signed message, since I don't see how it hurts? For scenarios where reuse is fine, reuse can still happen.\n\nCheers,\nwaxwing/AdamISZ"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-10T16:54:31",
                "message_text_only": "Good morning waxwing,\n\n> ------- Original Message -------\n> On Sunday, May 1st, 2022 at 11:01, Chris Belcher via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:\n>\n> > Hello ZmnSCPxj,\n> > This is an intended feature. I'm thinking that the same fidelity bond\n> > can be used to running a JoinMarket maker as well as a Teleport\n> > (Coinswap) maker.\n> > I don't believe it's abusable. It would be a problem if the same\n> > fidelity bond is used by two makers in the same application, but\n> > JoinMarket takers are already coded to check for this, and Teleport\n> > takers will soon as well. Using the same bond across different\n> > applications is fine.\n> > Best,\n> > CB\n>\n> Hi Chris, Zmn, list,\n> I've noodled about this a few times in the past (especially when trying to figure out an LSAG style ring sig based FB for privacy, but that does not seem workable), and I can't decide the right perspective on it.\n>\n> A user sacrifices X amount of time-value-of-money (henceforth TVOM) by committing in Joinmarket with FB1. He then uses the same FB1 in Teleport, let's say. If he gets benefit Y from using FB1 in Joinmarket, and benefit Z in Teleport, then presumably he'll only do it if (probabilistically) he thinks Y+Z > X.\n>\n> But as an assessor of FB1 in Joinmarket, I don't know if it's also being used for Teleport, and more importantly, if it's being used somewhere else I'm not even aware of. Now I'm not an economist I admit, so I might not be intuit-ing this situation right, but it fees to me like the right answer is \"It's fine for a closed system, but not an open one.\" (i.e. if the set of possible usages is not something that all participants have fixed in advance, then there is an effective Sybilling problem, like I'm, as an assessor, thinking that sacrificed value 100 is there, whereas actually it's only 15, or whatever.)\n>\n> As I mentioned in https://github.com/JoinMarket-Org/joinmarket-clientserver/issues/993#issuecomment-1110784059 , I did wonder about domain separation tags because of this, and as I vaguely alluded to there, I'm really not sure about it.\n>\n> If it was me I'd want to include domain separation via part of the signed message, since I don't see how it hurts? For scenarios where reuse is fine, reuse can still happen.\n\nAh, yes, now I remember.\nI discussed this with Tamas as well in the past and that is why we concluded that in defiads, each UTXO can host at most one advertisement at any one time.\nIn the case of defiads there would be a sequence counter where a higher-sequenced advertisement would replace lower-sequenced advertisement, so you could update, but at any one time, for a defiads node, only one advertisement per UTXO could be used.\nThis assumed that there would be a defiads network with good gossip propagation so our thinking at the time was that a higher-sequenced advertisement would quickly replace lower-sequenced ones on the network.\nBut it is simpler if such replacement would not be needed, and you could then commit to the advertisement directly on the UTXO via a tweak.\n\nEach advertisement would also have a specific application ID that it applied to, and applications on top of defiads would ask the local defiads node to give it the ads that match a specific application ID, so a UTXO could only be used for one application at a time.\nThis would be equivalent to domain separation tags that waxwing mentions.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "AdamISZ",
                "date": "2022-05-10T19:03:16",
                "message_text_only": "------- Original Message -------\nOn Tuesday, May 10th, 2022 at 17:54, ZmnSCPxj via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n\n> Good morning waxwing,\n<snip>\n>\n> Ah, yes, now I remember.\n> I discussed this with Tamas as well in the past and that is why we concluded that in defiads, each UTXO can host at most one advertisement at any one time.\n> In the case of defiads there would be a sequence counter where a higher-sequenced advertisement would replace lower-sequenced advertisement, so you could update, but at any one time, for a defiads node, only one advertisement per UTXO could be used.\n> This assumed that there would be a defiads network with good gossip propagation so our thinking at the time was that a higher-sequenced advertisement would quickly replace lower-sequenced ones on the network.\n> But it is simpler if such replacement would not be needed, and you could then commit to the advertisement directly on the UTXO via a tweak.\n>\n> Each advertisement would also have a specific application ID that it applied to, and applications on top of defiads would ask the local defiads node to give it the ads that match a specific application ID, so a UTXO could only be used for one application at a time.\n> This would be equivalent to domain separation tags that waxwing mentions.\n>\n> Regards,\n> ZmnSCPxj\n>\n\nI suppose ultimately this brings up the question of the scope of this BIP. The abstract points out that the BIP contains both a definition of address derivation, but also how to sign fidelity bond certificates.\n\nMy feeling is that the latter might be better not included? I note that the 'Motivation' section gives motivation for standardisation of derivation (this includes things like time schedule), but not the second area - certificate signing. I think the second area is much more tricky, but much more to the point is, isn't it the case that that second area, can be interpreted without consensus between wallet developers? So say you were a hardware wallet provider, or a \"node in a box\" provider - your customers want you to provide the ability move funds around, including e.g. moving funds out of an old Joinmarket wallet (in which say there is a now expired timelock address utxo) by just entering its BIP39 seed. If this BIP addresses that, it should be enough.\n\nI don't doubt that there's gains to be had from a broader community discussing and agreeing the details of how to create a fidelity bond certificate, but it's a separate, and more difficult, task.\n\nCheers,\nwaxwing/AdamISZ"
            },
            {
                "author": "AdamISZ",
                "date": "2022-05-10T19:28:05",
                "message_text_only": "> I suppose ultimately this brings up the question of the scope of this BIP. The abstract points out that the BIP contains both a definition of address derivation, but also how to sign fidelity bond certificates.\n>\n> My feeling is that the latter might be better not included? I note that the 'Motivation' section gives motivation for standardisation of derivation (this includes things like time schedule), but not the second area - certificate signing. I think the second area is much more tricky, but much more to the point is, isn't it the case that that second area, can be interpreted without consensus between wallet developers? So say you were a hardware wallet provider, or a \"node in a box\" provider - your customers want you to provide the ability move funds around, including e.g. moving funds out of an old Joinmarket wallet (in which say there is a now expired timelock address utxo) by just entering its BIP39 seed. If this BIP addresses that, it should be enough.\n>\n> I don't doubt that there's gains to be had from a broader community discussing and agreeing the details of how to create a fidelity bond certificate, but it's a separate, and more difficult, task.\n>\n> Cheers,\n> waxwing/AdamISZ\n\nFurther to that last point, as the BIP draft currently says:\n\n\" Almost all wallets implementing this standard can use their\nalready-existing \"Sign Message\" function to sign the certificate\nmessage. As the certificate message itself is always an ascii string,\nthe wallet may not need to specially implement this section at all but\njust rely on users copypasting their certificate message into the\nalready-existing \"Sign Message\" user interface. This works as long as\nthe wallet knows how to use the private key of the timelocked address\nfor signing messages.\"\n\nSo, isn't that an argument that we don't need to specify the certificate message format here?\n\nOn the other hand, I can hardly disagree that it's worth presenting a kind of 'default' way of doing it. But I fear it is not at all simple to decide what a secure, general format should be (as per the discussion we started having here about domain separation tags).\n\nCheers,\nwaxwing/AdamISZ"
            },
            {
                "author": "Chris Belcher",
                "date": "2022-05-13T10:02:20",
                "message_text_only": "Hello waxwing,\n\n > A user sacrifices X amount of time-value-of-money (henceforth TVOM) \nby committing in Joinmarket with FB1. He then uses the same FB1 in \nTeleport, let's say. If he gets benefit Y from using FB1 in Joinmarket, \nand benefit Z in Teleport, then presumably he'll only do it if \n(probabilistically) he thinks Y+Z > X.\n\n > But as an assessor of FB1 in Joinmarket, I don't know if it's also \nbeing used for Teleport, and more importantly, if it's being used \nsomewhere else I'm not even aware of. Now I'm not an economist I admit, \nso I might not be intuit-ing this situation right, but it fees to me \nlike the right answer is \"It's fine for a closed system, but not an open \none.\" (i.e. if the set of possible usages is not something that all \nparticipants have fixed in advance, then there is an effective Sybilling \nproblem, like I'm, as an assessor, thinking that sacrificed value 100 is \nthere, whereas actually it's only 15, or whatever.)\n\n\nI don't entirely agree with this. The value of the sacrifice doesn't \nchange if the fidelity bond owner starts using it for Teleport as well \nas Joinmarket. The sacrifice is still 100. Even if the owner doesn't run \nany maker at all the sacrifice would still be 100, because it only \ndepends on the bitcoin value and locktime. In your equation Y+Z > X, \nusing a fidelity bond for more applications increases the \nleft-hand-side, while the right-hand-side X remains the same. As \nprotection from a sybil attack is calculated using only X, it makes no \ndifference what Y and Z are, the takers can still always calculate that \n\"to sybil attack the coinjoin I'm about to make, it costs A btc locked \nup for B time\".\n\nRegarding fidelity bonds being used for both, I expect that most \nfidelity bond owners will use their bonds with both Joinmarket and \nTeleport, to not do that is just leaving money on the table.\n\nIf an attacker locks up the 100k btc or whatever the requirement is now, \nand actually does a successful sybil attack against Joinmarket, then \nthey could at the same time do a successful sybil attack against \nteleport with little added cost. So both markets form a single fidelity \nbond ecosystem. This is a similar situation to merge-mining bitcoin with \nan altcoin that also uses SHA256^2 for proof of work. The two or more \ncoins form one mining ecosystem. This results in the users of the small \naltcoin benefiting from having their transactions protected by bitcoin's \nmassive hashrate. In this analogy the new small Teleport system can very \nquickly benefit from the large amount of fidelity bonds already used in \nJoinmarket.\n\nYes the hypothetical attacker can attack all systems at once, but the \ndefenders can defend all systems at once (and we can say not just that \nthey \"can\" do it, but that they \"will\" do it, or else they leave money \non the table). The mathematics which gives a huge advantage to the \ndefender still applies.\n\n----\n\nYou've convinced me that specifying the exact form of the fidelity bond \ncertificate is a bad idea. I'll leave it more general, saying just that \nwallets should be able to do SignMessage using the timelocked privkey. \nAnd I'll leave the example signature in the test vectors.\n\nI've made edits to this effect on the gist:\nhttps://gist.github.com/chris-belcher/7257763cedcc014de2cd4239857cd36e/revisions#diff-4f1f364f340b78bdfe9dca2ff50784bd312d49be220e5e5c2e4675447f79c6e8\n\nIt's worth noting that even if the certificate message is different \nacross the two systems, a fidelity bond owner can still create two \nsignatures over two different messages (e.g. \n\"fidelity-bond-cert|<pubkey>|<expiry>\" and \n\"fidelity-bond-cert-teleport|<pubkey>|<expiry>\")."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-13T12:44:14",
                "message_text_only": "Good morning Chris,\n\n> Hello waxwing,\n>\n> > A user sacrifices X amount of time-value-of-money (henceforth TVOM)\n>\n> by committing in Joinmarket with FB1. He then uses the same FB1 in\n> Teleport, let's say. If he gets benefit Y from using FB1 in Joinmarket,\n> and benefit Z in Teleport, then presumably he'll only do it if\n> (probabilistically) he thinks Y+Z > X.\n>\n> > But as an assessor of FB1 in Joinmarket, I don't know if it's also\n>\n> being used for Teleport, and more importantly, if it's being used\n> somewhere else I'm not even aware of. Now I'm not an economist I admit,\n> so I might not be intuit-ing this situation right, but it fees to me\n> like the right answer is \"It's fine for a closed system, but not an open\n> one.\" (i.e. if the set of possible usages is not something that all\n> participants have fixed in advance, then there is an effective Sybilling\n> problem, like I'm, as an assessor, thinking that sacrificed value 100 is\n> there, whereas actually it's only 15, or whatever.)\n>\n>\n> I don't entirely agree with this. The value of the sacrifice doesn't\n> change if the fidelity bond owner starts using it for Teleport as well\n> as Joinmarket. The sacrifice is still 100. Even if the owner doesn't run\n> any maker at all the sacrifice would still be 100, because it only\n> depends on the bitcoin value and locktime. In your equation Y+Z > X,\n>\n> using a fidelity bond for more applications increases the\n> left-hand-side, while the right-hand-side X remains the same. As\n> protection from a sybil attack is calculated using only X, it makes no\n> difference what Y and Z are, the takers can still always calculate that\n> \"to sybil attack the coinjoin I'm about to make, it costs A btc locked\n> up for B time\".\n\nI think another perspective here is that a maker with a single fidelity bond between both Teleport and Joinmarket has a single identity in both systems.\n\nRecall that not only makers can be secretly surveillors, but takers can also be secretly surveillors.\n\nIdeally, the maker should not tie its identity in one system to its identity in another system, as that degrades the privacy of the maker as well.\n\nAnd the privacy of the maker is the basis of the privacy of its takers.\nIt is the privacy of the coins the maker offers, that is being purchased by the takers.\n\n\nA taker can be a surveillor as well, and because the identity between JoinMarket and Teleport is tied via the single shared fidelity bond, a taker can perform partial-protocol attacks (i.e. aborting at the last step) to identify UTXOs of particular makers.\nAnd it can perform attacks on both systems to identify the ownership of maker coins in both systems.\n\nSince the coins in one system are tied to that system, this increases the information available to the surveillor: it is now able to associate coins in JoinMarket with coins in Teleport, via the shared fidelity bond identity.\nIt would be acceptable for both systems to share an identity if coins were shared between the JoinMarket and Teleport maker clients, but at that point they would arguably be a single system, not two separate systems, and that is what you should work towards.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Chris Belcher",
                "date": "2022-05-15T09:13:39",
                "message_text_only": "Hello ZmnSCPxj,\n\nYou say \"A taker can be a surveillor as well\", as though that's simple \nand easy to achieve. In reality there are many defenses against that.\n\nDefending against the attack of a malicious taker aborting at the last \nstep is the purpose of the podle commitments which joinmarket has \nimplemented since 2016. This was in response to this attack actually \ntaking place. Another important point is that this attack cant happen \nsecretly, it is very obvious to everyone operating a maker that it \nhappens. The podle defense means that an attacker doing this will \nconstantly have to spend money on miner fees to create new UTXOs. Here's \na writeup with links to other blog posts about the whole thing: \nhttps://gist.github.com/chris-belcher/00255ecfe1bc4984fcf7c65e25aa8b4b\n\nAs well as podle as mitigation, the multiple mixdepths in the joinmarket \nwallet also helps a lot because it's not trivial for an attacker to \nactually learn all the UTXOs in all 5 mixdepths, which is necessary for \nthe attack to work.\n\nMitigation in Teleport works in a slightly different way: takers can \nonly see UTXOs or transactions belonging to the maker once they have \nalready gotten their own transaction confirmed. So if they were to abort \nthe protocol early they would not only have spent miner fees but also \nwaste their own time waiting for the OP_CSV timeout.\n\nIt's worth remembering that the fidelity bond UTXOs are not linked to \nany resulting coinjoin or coinswaps on-chain.\n\nYes linking the two identities (joinmarket maker and teleport maker) \ntogether slightly degrades privacy, but that has to be balanced against \nthe privacy loss of leaving both systems open to sybil attacks. Without \nfidelity bonds the two systems can be sybil attacked just by using about \nfive-figures USD, and the attack can get these coins back at any time \nwhen they're finished.\n\nRegards\nCB\n\nOn 13/05/2022 13:44, ZmnSCPxj wrote:\n> Good morning Chris,\n> \n>> Hello waxwing,\n>>\n>>> A user sacrifices X amount of time-value-of-money (henceforth TVOM)\n>>\n>> by committing in Joinmarket with FB1. He then uses the same FB1 in\n>> Teleport, let's say. If he gets benefit Y from using FB1 in Joinmarket,\n>> and benefit Z in Teleport, then presumably he'll only do it if\n>> (probabilistically) he thinks Y+Z > X.\n>>\n>>> But as an assessor of FB1 in Joinmarket, I don't know if it's also\n>>\n>> being used for Teleport, and more importantly, if it's being used\n>> somewhere else I'm not even aware of. Now I'm not an economist I admit,\n>> so I might not be intuit-ing this situation right, but it fees to me\n>> like the right answer is \"It's fine for a closed system, but not an open\n>> one.\" (i.e. if the set of possible usages is not something that all\n>> participants have fixed in advance, then there is an effective Sybilling\n>> problem, like I'm, as an assessor, thinking that sacrificed value 100 is\n>> there, whereas actually it's only 15, or whatever.)\n>>\n>>\n>> I don't entirely agree with this. The value of the sacrifice doesn't\n>> change if the fidelity bond owner starts using it for Teleport as well\n>> as Joinmarket. The sacrifice is still 100. Even if the owner doesn't run\n>> any maker at all the sacrifice would still be 100, because it only\n>> depends on the bitcoin value and locktime. In your equation Y+Z > X,\n>>\n>> using a fidelity bond for more applications increases the\n>> left-hand-side, while the right-hand-side X remains the same. As\n>> protection from a sybil attack is calculated using only X, it makes no\n>> difference what Y and Z are, the takers can still always calculate that\n>> \"to sybil attack the coinjoin I'm about to make, it costs A btc locked\n>> up for B time\".\n> \n> I think another perspective here is that a maker with a single fidelity bond between both Teleport and Joinmarket has a single identity in both systems.\n> \n> Recall that not only makers can be secretly surveillors, but takers can also be secretly surveillors.\n> \n> Ideally, the maker should not tie its identity in one system to its identity in another system, as that degrades the privacy of the maker as well.\n> \n> And the privacy of the maker is the basis of the privacy of its takers.\n> It is the privacy of the coins the maker offers, that is being purchased by the takers.\n> \n> \n> A taker can be a surveillor as well, and because the identity between JoinMarket and Teleport is tied via the single shared fidelity bond, a taker can perform partial-protocol attacks (i.e. aborting at the last step) to identify UTXOs of particular makers.\n> And it can perform attacks on both systems to identify the ownership of maker coins in both systems.\n> \n> Since the coins in one system are tied to that system, this increases the information available to the surveillor: it is now able to associate coins in JoinMarket with coins in Teleport, via the shared fidelity bond identity.\n> It would be acceptable for both systems to share an identity if coins were shared between the JoinMarket and Teleport maker clients, but at that point they would arguably be a single system, not two separate systems, and that is what you should work towards.\n> \n> \n> Regards,\n> ZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-16T00:00:16",
                "message_text_only": "Good morning Chris,\n\n\n> Yes linking the two identities (joinmarket maker and teleport maker)\n> together slightly degrades privacy, but that has to be balanced against\n> the privacy loss of leaving both systems open to sybil attacks. Without\n> fidelity bonds the two systems can be sybil attacked just by using about\n> five-figures USD, and the attack can get these coins back at any time\n> when they're finished.\n\nI am not saying \"do not use fidelity bonds at all\", I am saying \"maybe we should disallow a fidelity bond used in JoinMarket from being used in Teleport and vice versa\".\n\n\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "BIP proposal: Timelocked address fidelity bond for BIP39 seeds",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Chris Belcher",
                "Eric Voskuil",
                "eric at voskuil.org",
                "ZmnSCPxj",
                "AdamISZ"
            ],
            "messages_count": 22,
            "total_messages_chars_count": 65102
        }
    },
    {
        "title": "[bitcoin-dev] ANYPREVOUT in place of CTV",
        "thread_messages": [
            {
                "author": "Nadav Ivgi",
                "date": "2022-05-01T14:25:42",
                "message_text_only": "> via `sha_sequences`\n\nSince you cannot expect txid stability with >1 inputs either way[0], it\nshould be sufficient to commit just to the current input's\nnSequence/scriptSig to get txid stability for single input transactions. I\nchatted with Jeremy about this and he appears to agree.\n\nNot committing to the nSequence of other inputs gives them the freedom to\nset it independently, so for example you can spend a CSV-encumbered output\nalongside the covenant. And there seems to be no downside to doing this [1].\n\nAPO/APOAS already commits to the nSequence of the current input. And since\nAPO is Taproot-only, the scriptSig of the covenant input is guarrnated to\nbe empty, so it is also already committed to in a way.\n\nHowever, without committing to all the nSequences which implicitly commits\nto the number of inputs, the number has to be committed separately.\n\nSo my suggestion is to explicitly commit to the number of inputs, instead\nof commiting to `sha_sequences`.\n\nCheers\nshesek\n\n[0] the additional input(s) will be third-party malleable, since their\nprevouts can be replaced with an entirely different txid:vout\n[1] BIP 119's rationale for committing to the nSequences is txid\nmalleability:\nhttps://github.com/bitcoin/bips/blob/master/bip-0119.mediawiki#committing-to-the-sequences-hash\n\n\n\nOn Sat, Apr 30, 2022 at 11:09 AM Nadav Ivgi <nadav at shesek.info> wrote:\n\n> Hi darosior,\n>\n> It's interesting to note that APOAS|SINGLE (with the ANYONECANPAY\n> behaviour and without covering the spent input index) has some interesting\n> uses for cases where the covenant only needs to restrict a single output\n> (so useful for e.g. vaults or spacechains, but not for batch channels or\n> congestion control).\n>\n> For example in the vault use-case, it makes it possible to bump fees on\n> the unvault tx by adding more inputs and a change output, as well as\n> unvault multiple vaulted outputs in a single transaction.\n>\n> For spacechains, it makes it possible to add the spaceblock hash OP_RETURN\n> and pay fees directly in the tx chain, instead of having to use an\n> additional tx to prepare an output that gets spent in the tx chain  (see\n> the diagram in [0]).\n>\n> > via `sha_sequences` and maybe also `sha_amounts`\n>\n> CTV does not commit to the input amounts. This has some practical\n> implications:\n>\n> 1. If it is committed, sending an even slightly incorrect amount will make\n> the covenant-encumbered spend path unusable.\n>\n> With CTV, sending a slightly lower amount results in slightly lower fees,\n> while any extra gets spent/burned on fees. The covenant spend path only\n> becomes unusable if the amount is too low to cover for the outputs (+relay\n> fee for it to also be standard).\n>\n> 2. The ability to allow for additional inputs with unknown amounts makes\n> it possible to fee-bump the covenant spending transaction (with whole utxos\n> and no change). You can have one tapleaf for spending the covenant output\n> alone, and another one for attaching an extra fee input to it.\n>\n> This also makes it possible to resolve the under-payment issue described\n> in (1), by adding an input that covers the original intended amount.\n>\n> So my suggestion would be to either not cover `sha_amounts` in the msg\n> hash, or to make it optional behind a flag.\n>\n> shesek\n>\n> [0] https://github.com/fiatjaf/simple-ctv-spacechain\n>\n> On Fri, Apr 22, 2022 at 2:23 PM darosior via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> I would like to know people's sentiment about doing (a very slightly\n>> tweaked version of) BIP118 in place of\n>> (or before doing) BIP119.\n>>\n>> SIGHASH_ANYPREVOUT and its precedent iterations have been discussed for\n>> over 6 years. It presents proven and\n>> implemented usecases, that are demanded and (please someone correct me if\n>> i'm wrong) more widely accepted than\n>> CTV's.\n>>\n>> SIGHASH_ANYPREVOUTANYSCRIPT, if its \"ANYONECANPAY\" behaviour is made\n>> optional [0], can emulate CTV just fine.\n>> Sure then you can't have bare or Segwit v0 CTV, and it's a bit more\n>> expensive to use. But we can consider CTV\n>> an optimization of APO-AS covenants.\n>>\n>> CTV advocates have been presenting vaults as the flagship usecase.\n>> Although as someone who've been trying to\n>> implement practical vaults for the past 2 years i doubt CTV is necessary\n>> nor sufficient for this (but still\n>> useful!), using APO-AS covers it. And it's not a couple dozen more\n>> virtual bytes that are going to matter for\n>> a potential vault user.\n>>\n>> If after some time all of us who are currently dubious about CTV's stated\n>> usecases are proven wrong by onchain\n>> usage of a less efficient construction to achieve the same goal, we could\n>> roll-out CTV as an optimization.  In\n>> the meantime others will have been able to deploy new applications\n>> leveraging ANYPREVOUT (Eltoo, blind\n>> statechains, etc..[1]).\n>>\n>>\n>> Given the interest in, and demand for, both simple covenants and better\n>> offchain protocols it seems to me that\n>> BIP118 is a soft fork candidate that could benefit more (if not most of)\n>> Bitcoin users.\n>> Actually i'd also be interested in knowing if people would oppose the\n>> APO-AS part of BIP118, since it enables\n>> CTV's features, for the same reason they'd oppose BIP119.\n>>\n>>\n>> [0] That is, to not commit to the other inputs of the transaction (via\n>> `sha_sequences` and maybe also\n>> `sha_amounts`). Cf\n>> https://github.com/bitcoin/bips/blob/master/bip-0118.mediawiki#signature-message\n>> .\n>>\n>> [1] https://anyprevout.xyz/ \"Use Cases\" section\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220501/515b1504/attachment.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-05-01T23:35:08",
                "message_text_only": ">   If a QC is able overnight to spend a large fraction of the supply, your\ncoins in your super non-QC vulnerable-bare-CTV-covenant (that would\neventually become vulnerable when trying to use it) are worthless.[1]\n\nI know this has been debated to death, but I really don't think this\nargument is very convincing. First of all, why are we assuming that if for\nexample, \"satoshi's hoard\" of 5+ million bitcoins was stolen, that it would\nmean bitcoin becomes worthless? To me this is an absurd assumption to make.\nThe thief almost certainly wouldn't want to just destroy bitcoin. But even\nif they did and put it all up for sale overnight, yes it would tank\nbitcoin's price *temporarily*. But in the long run, this is less than 1/3\nof the supply, and it at worst could be considered monetary inflation of <\n30%, and so that's the amount that the price should take a hit of: less\nthan 30%. Plenty of fiat currencies have survived worse.\n\nSecond of all, its incredibly unlikely that someone is suddenly going to be\nable to do QC so well that they jump straight to being able to find \"a\nlarge fraction\" of the private keys out there, or enough private keys to\nmake up a large fraction of the supply. Its far more likely that the first\nquantum computers that are able to derive *any* private keys will still\ntake a long time (weeks? months?) to do one. If you have your bitcoins in a\nsegwit address, you know that they can't be stolen by a quantum computer.\nYou can sit back calmly, and figure out what to do next. By contrast, if\nyour life savings is in a taproot address, you have to drop everything with\nyour underwear on fire and recklessly move that stuff ASAP. Chances for\nhasty mistakes is high.\n\nBut lets say someone *does* jump to being able to derive 1 private key per\nminute (pretty darn fast if you ask me). It would currently take such a\nmachine 152 years to crack all the 80 million UTXOs in existence. By the\ntime there are practical quantum machines, it'll probably be at least\ndouble that many UTXOs. If it was trying to crack revealed private keys\nfrom mempool transactions, it could only really hit 10 out of 2000\ntransactions. Hashing the public key is I think is quite an effective\nprotection to a quantum computing attack in the vast majority of likely QC\nemergence scenarios. I honestly don't understand how someone could come to\na different conclusion.\n\nIt makes a lot of sense in a world where quantum computers are now a very\nreal thing, to store large amounts of bitcoin in a possibly slightly less\nefficient way in order to ensure that those funds can't be snatched in a QC\ndisaster scenario. I would be very interested to see a proposal to add the\noption of having a taproot address type that doesn't expose the bare public\nkey.\n\n\nOn Fri, Apr 29, 2022 at 6:53 AM Nadav Ivgi via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Correction: thinking about this some more, you can't actually expect to\n> have a stable txid if you allow additional inputs at all...\n>\n> So yes, amending BIP 118 to commit to sha_sequences (which indirectly also\n> commits to the number of inputs) as proposed in the OP should be sufficient\n> to get stable txids for single-input transactions.\n>\n> (I initially thought that APO has to cover some additional tx parts for\n> this, but it seems that it's really just the scriptSig which is guarrnated\n> to be empty if you have a single input that is known to be the taproot APO\n> spend.)\n>\n> So in overall, my (1) and (5) points are only applicable to\n> APO-as-currently-spec'd and not to the suggested APO revision.\n>\n> On Fri, Apr 29, 2022 at 1:21 PM Nadav Ivgi <nadav at shesek.info> wrote:\n>\n>> > This is *literally* what the post you are replying to is proposing to\n>> solve.\n>>\n>> I thought the changes mentioned in the OP (+ committing to the spent\n>> input index) only solves the half-spend problem, but not the stable txids\n>> one?\n>>\n>> There can be other inputs with a scriptSig, which doesn't get committed\n>> to in the APO hash. I guess this isn't too common, but there might be some\n>> cases where you would want to spend some (pre-selected) non-segwit inputs\n>> alongside your covenant, maybe for fees. With CTV you would pre-commit to\n>> the scriptSig which makes it non-malleable even if the script itself is.\n>>\n>> > Hmm? You can't have channel factories without Eltoo. (Well, you can in\n>> theory but good luck.)\n>> > Maybe you are refering to non-interactive channel creation?\n>>\n>> I was referring to what BIP 119 calls 'Batched Channel Creation' [0],\n>> which is a sort of a channel factory construction under a broader\n>> definition (and in fact was previously called that in the BIP [1]).\n>>\n>> > The case for stable txids is less strong if we have APO (and therefore\n>> Eltoo).\n>>\n>> There's merit in using these factory constructs for Poon-Dryja channels\n>> even if Eltoo was available.\n>> I don't foresee Eltoo taking over the penalty approach entirely, but\n>> rather the two living side by side.\n>>\n>> (It could theoretically be possible to use APO to open Poon-Dryja\n>> channels on top of unstable funding txids, but having stable txids makes\n>> this much more easily integratable with existing lightning implementations,\n>> without the invasive changes that unstable txids would bring.)\n>>\n>> > This has been addressed over and over and over again. If a QC is able\n>> overnight to spend a large fraction of\n>> > the supply, your coins in your super\n>> non-QC-vulnerable-bare-CTV-covenant (that would eventually become\n>> > vulnerable when trying to use it) are worthless.\n>>\n>> It might be the case that a sufficient fraction of supply does switch\n>> over to QC-protected outputs in time, with only some small minority that\n>> didn't actively switch over *and* with revealed bare pubkeys losing\n>> their funds, which wouldn't make BTC entirely worthless. It makes sense not\n>> to want to be in that minority, ideally without requiring further\n>> time-sensitive active action (esp if considering long-term deep cold\n>> storage for inheritance etc).\n>>\n>> (This of course assumes a safe post-QC mechanism to later spend these\n>> funds; IIUC there are some viable approaches for that using a two-step\n>> spending procedure, where you prove knowledge of the pubkey/script preimage\n>> while commiting to a future tx.)\n>>\n>> > Sorry for being sarcastic, but at this point it's not fair to use\n>> quantum-computer FUD to justify the\n>> > activation of CTV over APO, or encourage the use of legacy transactions\n>> over Taproot ones.\n>>\n>> Sorry if it came off as FUDing. I don't know enough to hold a strong\n>> opinion on whether the fear of QCs is justified or not. I know that many\n>> people on this list don't think so, but I also think that this fear is\n>> prevalent enough to warrant taking it into consideration (at least for\n>> features that target long-term SoV use cases; less so for features\n>> targeted at L2 MoE applications like lightning spacechains paypools etc).\n>>\n>> > you can also use the internal key optimization .. you can't have\n>> NUMS-ness then\n>>\n>> Right, which makes this unsuitable for the vaulting use case.\n>>\n>> > Also, it's not 33 extra vbytes vs CTV-in-segwitv0, but 33 extra *\n>> witness units* (8.25 vbytes).\n>>\n>> Ugh yes sorry about that! I realized after hitting send and meant to\n>> clarify that it should've been s/vbyte/WU/ in my next reply.\n>>\n>> > Are APO signatures more expensive to verify? .. the cost for the\n>> network of validating signatures already exists today\n>>\n>> Not compared to existing signature verifications, but compared to a\n>> CTV/TXHASH-like construction.\n>>\n>> Can anyone quantify how much of a difference this makes in practice?\n>>\n>> > i appreciate your reply and your efforts to explore the tradeoffs\n>> between the two approaches.\n>>\n>> Thank you, I appreciate your efforts on this too :-)\n>>\n>> shesek\n>>\n>> [0]\n>> https://github.com/bitcoin/bips/blob/master/bip-0119.mediawiki#Batched_Channel_Creation\n>> [1] https://github.com/bitcoin/bips/pull/1273\n>>\n>> On Fri, Apr 29, 2022 at 11:31 AM darosior <darosior at protonmail.com>\n>> wrote:\n>>\n>>> Hi Shesek,\n>>>\n>>> 1. The resulting txids are not stable.\n>>>\n>>>\n>>> This is *literally* what the post you are replying to is proposing to\n>>> solve.\n>>>\n>>>\n>>> This property could be important for some of the proposed CTV use-cases,\n>>> like channel factories.\n>>>\n>>>\n>>> Hmm? You can't have channel factories without Eltoo. (Well, you can in\n>>> theory but good luck.)\n>>> Maybe you are refering to non-interactive channel creation? The case for\n>>> stable txids is less strong if we\n>>> have APO (and therefore Eltoo). [0]\n>>>\n>>>\n>>> 2. APO will only be available on Taproot, which some people might prefer\n>>> to avoid for long-term multi-decade vault storage due to QC concerns. (also\n>>> see my previous post on this thread [0])\n>>>\n>>>\n>>> This has been addressed over and over and over again. If a QC is able\n>>> overnight to spend a large fraction of\n>>> the supply, your coins in your super non-QC-vulnerable-bare-CTV-covenant\n>>> (that would eventually become\n>>> vulnerable when trying to use it) are worthless.[1]\n>>>\n>>> Sorry for being sarcastic, but at this point it's not fair to use\n>>> quantum-computer FUD to justify the\n>>> activation of CTV over APO, or encourage the use of legacy transactions\n>>> over Taproot ones.\n>>>\n>>>\n>>> 3. Higher witness satisfaction cost of roughly 3x vbytes vs\n>>> CTV-in-Taproot (plus 33 extra vbytes vs CTV-in-segwitv0 *in the case of\n>>> a single CTV branch*, for the taproot control block. with more branches\n>>> CTV-in-taproot eventually becomes preferable).\n>>>\n>>>\n>>> Again, this is what my post discusses. Here are the arguments from my\n>>> post about why i don't think it's a big deal:\n>>>\n>>>     1. You can in this case see CTV as an optimization of (tweaked)\n>>> APOAS. A lot of us are doubtful about CTV\n>>>        usecases for real people. So much that it was even proposed to\n>>> temporarily activate it to see if it would\n>>>        ever have any real traction! [2]\n>>>        My point with this post was: what if we do (a slightly tweaked)\n>>> BIP118, that is otherwise useful. And\n>>>        if this use of covenants is really getting traction then we can\n>>> roll out an optimization in the form of\n>>>        CTV (or better covenants, as we'd have had more research put into\n>>> it by this time).\n>>>     2. CTV is mainly sold for its usage inside vaults. While i'm not\n>>> convinced, a few more vbytes should not\n>>>        matter for this usecase.\n>>>\n>>> Also, it's not 33 extra vbytes vs CTV-in-segwitv0, but 33 extra *\n>>> witness units* (8.25 vbytes).\n>>> Aside, you can also use the internal key optimization with APO. But i\n>>> don't think it's desirable just to save\n>>> 32 WU, as you can't have NUMS-ness then. [3]\n>>>\n>>>\n>>> 4. Higher network-wide full-node validation costs (checking a signature\n>>> is quite more expensive than hashing, and the hashing is done in both\n>>> cases).\n>>>\n>>>\n>>> Are APO signatures more expensive to verify? If not i don't think this\n>>> should be a reason to constrain us to a\n>>> much less useful construction, as the cost for the network of validating\n>>> signatures already exists today. Even\n>>> if it didn't, the tradeoff of cost/usefulness needs to be considered.\n>>>\n>>>\n>>> 5. As APO is currently spec'd, it would suffer from the half-spend\n>>> problem: if you have multiple outputs encumbered under an APO covenant that\n>>> requires the same tx sigmsg hash, it becomes possible to spend all of them\n>>> together as multiple inputs in a single transaction and burn the extra to\n>>> mining fees.\n>>>\n>>> If I'm not mistaken, I believe this makes the simple-apo-vault\n>>> implementation [1] vulnerable to spending multiple vaulted outputs of the\n>>> same denomination together and burning all but the first one. I asked the\n>>> author for a more definitive answer on twitter [2].\n>>>\n>>> Fixing this requires amending BIP 118 with some new sigmsg flags (making\n>>> the ANYONECANPAY behaviour optional, as mentioned in the OP).\n>>>\n>>>\n>>> Yes! And as i mentioned on Twitter also committing to the input index\n>>> which i forgot to add in the OP here.\n>>>\n>>>\n>>> While i don't think the specific points are valid, i appreciate your\n>>> reply and your efforts to explore the\n>>> tradeoffs between the two approaches.\n>>>\n>>> Thanks,\n>>> Antoine\n>>>\n>>> [0]\n>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019813.html\n>>> [1] https://bitcoin.stackexchange.com/a/91050/101498\n>>> [2]\n>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020242.html\n>>> [3]\n>>> https://twitter.com/darosior/status/1518979155362254849?s=20&t=mGkw7K8mcyQwdLImFvdebw\n>>>\n>>>\n>>> This is definitely possible but also means that APO as-is isn't a\n>>> CTV-replacement candidate, without first going through some more design and\n>>> review iterations.\n>>>\n>>> shesek\n>>>\n>>>\n>>> [0]\n>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020326.html\n>>> [1] https://github.com/darosior/simple-anyprevout-vault\n>>> [2] https://twitter.com/shesek/status/1519874493434544128\n>>>\n>>>\n>>>\n>>> On Fri, Apr 22, 2022 at 2:23 PM darosior via bitcoin-dev <\n>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> I would like to know people's sentiment about doing (a very slightly\n>>>> tweaked version of) BIP118 in place of\n>>>> (or before doing) BIP119.\n>>>>\n>>>> SIGHASH_ANYPREVOUT and its precedent iterations have been discussed for\n>>>> over 6 years. It presents proven and\n>>>> implemented usecases, that are demanded and (please someone correct me\n>>>> if i'm wrong) more widely accepted than\n>>>> CTV's.\n>>>>\n>>>> SIGHASH_ANYPREVOUTANYSCRIPT, if its \"ANYONECANPAY\" behaviour is made\n>>>> optional [0], can emulate CTV just fine.\n>>>> Sure then you can't have bare or Segwit v0 CTV, and it's a bit more\n>>>> expensive to use. But we can consider CTV\n>>>> an optimization of APO-AS covenants.\n>>>>\n>>>> CTV advocates have been presenting vaults as the flagship usecase.\n>>>> Although as someone who've been trying to\n>>>> implement practical vaults for the past 2 years i doubt CTV is\n>>>> necessary nor sufficient for this (but still\n>>>> useful!), using APO-AS covers it. And it's not a couple dozen more\n>>>> virtual bytes that are going to matter for\n>>>> a potential vault user.\n>>>>\n>>>> If after some time all of us who are currently dubious about CTV's\n>>>> stated usecases are proven wrong by onchain\n>>>> usage of a less efficient construction to achieve the same goal, we\n>>>> could roll-out CTV as an optimization. In\n>>>> the meantime others will have been able to deploy new applications\n>>>> leveraging ANYPREVOUT (Eltoo, blind\n>>>> statechains, etc..[1]).\n>>>>\n>>>>\n>>>> Given the interest in, and demand for, both simple covenants and better\n>>>> offchain protocols it seems to me that\n>>>> BIP118 is a soft fork candidate that could benefit more (if not most\n>>>> of) Bitcoin users.\n>>>> Actually i'd also be interested in knowing if people would oppose the\n>>>> APO-AS part of BIP118, since it enables\n>>>> CTV's features, for the same reason they'd oppose BIP119.\n>>>>\n>>>>\n>>>> [0] That is, to not commit to the other inputs of the transaction (via\n>>>> `sha_sequences` and maybe also\n>>>> `sha_amounts`). Cf\n>>>> https://github.com/bitcoin/bips/blob/master/bip-0118.mediawiki#signature-message\n>>>> .\n>>>>\n>>>> [1] https://anyprevout.xyz/ \"Use Cases\" section\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>\n>>>\n>>> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220501/8e6bc38d/attachment-0001.html>"
            },
            {
                "author": "darosior",
                "date": "2022-05-03T10:38:52",
                "message_text_only": "Hi Jacob,\n\nI think you are a bit confused about how CTV and (tweaked) APO covenants compare. Both would commit to the\nsame template, so one isn't \"safer\" than the other. Just more efficient in how it commits to the template.\nReplies on the specifics inline.\n\n> While I agree with the arguments in favour of (optional ANYONECANPAY) APOAS in lieu of CTV in the short-term (given the additional benefit of enabling Eltoo), there's a point to add in favour of CTV (or similar) in the long-term beyond as an optimisation.\n\nIn the long term, we'd hopefully have more powerful covenants to enable more interesting applications. At this\npoint CTV would be an optimisation for these covenant constructions instead of an APO one.\nMy request for feedback was more about the short term, where some are requesting the activation of CTV to\nstart playing with covenants before we settle on the way forward to more useful covenant. Not that i'm in\nfavour of it, but if it gains sufficient traction then i believe there is a case for instead doing a tweaked\nAPO that would optionally commit to the input index, nSequences, etc..[0] I think this addresses the technical\ndebt concerns of CTV once we have more interesting covenants, as no covenant can entirely emulate a signature\nhash type.\n\n> With APOAS-based covenants, the signature message algorithm is tied to both the covenant commitment and transaction validation. Coupling these things introduces a trade-off between safety and flexibility with covenant-based applications.\n\nWhat do you mean \"tied to the transaction validation\"? To me \"transaction validation\" is what a node does to\ncheck whether a block is valid, but you probably mean something else here.\nWith APOAS-based covenants, the signature message *is* the covenant commitment. I don't see how it is coupled\nto anything else. I also don't see how it could ever differ in safety or flexibility with another\nhashed-template approach (CTV) if the template is the same.\n\n> E.g. the maximally safe and restricted covenant commits to all inputs and outputs of the transaction (using SIGHASH ALL). However, a less restricted covenant commits to, for example, a single input and a single output (using ANYONECANPAY|SINGLE) but opens itself up to attacks making use of transaction malleability and signature replay.\n\nIndeed the APO approach is more flexible as sighash types may be combined. You can opt-in to more\nmalleability. I don't think it's a bad thing. Now, sure, the commitment may be replayed, but it's inherent to\nany commitment that doesn't commit to the prevout (whether it is CTV or APO, or any other type of templated\ncovenant that you'd place in the ScriptPubKey) otherwise you'd have a circular hash dependency.\nIf you are talking about the \"half spend\" by which two coins with the same covenant get spent in the same\ntransaction, then committing to the input index fixes this. Interestingly the instance you give *does* commit\nto the input index without any tweak to the current APO proposal.\n\n> If instead we separate the covenant commitment from the signatures to validate transactions (as with CTV and TXHASH + CHECKSIGFROMSTACK) then we by-pass this trade-off.\n\nCTV doesn't \"separate the signature and the commitment\", it doesn't need a signature. Sure one can be added to\nfurther restrict a spending path, but it isn't necessary since the transaction is pre-defined and can't be\nmalleated. It also sounds like you imply the APO covenant is using a \"real\" signature. It's not. The pubkey\nmay well be G. The signature is just a roundabout way to access the hash. So if you wanted to have, say, a\ncovenant only available to a participant you'd go the same way with either CTV or APO covenants:\n<covenant sig> <0x01 G> OP_CHECKSIGVERIFY <Alice pubkey> OP_CHECKSIG\n<tx hash> OP_CTV OP_VERIFY <Alice pubkey> OP_CHECKSIG\n\n> The flexibility of additional templates with new CTV versions or with the TXHASH primitive seems to me to enable significantly more utility for covenant-based applications.\n\nTXHASH would definitely enable more utility. Additional templates with new CTV versions would require a new\nsoft fork for new (hardcoded) usecases. But i'm not going to restart the conversation around the benefits of\nslightly more general covenant primitives [1]. :-)\n\nAntoine\n\n[0] See the OP for rationale[1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019813.html\n\n[0] Cf the OP for the rationale\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220503/3644bbb9/attachment.html>"
            },
            {
                "author": "Jeremy Rubin",
                "date": "2022-05-03T15:51:18",
                "message_text_only": "Antoine,\n\nOne high level reason to not prefer APO is that it gets 'dangerously close'\nto fully recursive covenants.\n\nE.g., just by tweaking APO to use a Schnorr signature without PK\ncommitment, Pubkey Recovery would be possible, and fully recursive\ncovenants could be done.\n\nShort of that type of modification, you can still do a \"trusted setup\" key\ndeletion covenant with APO and have a fully recursive covenant set up. E.g.\n\n<1 || N-N MuSig> APO\n\nwhere the N-N MuSig pregenerates a signature of a transaction that commits\nto an output with itself, e.g., using SIGHASH_SINGLE.\n\nBy itself, this is not super useful, but does create the type of thing that\npeople might worry about with a recursive covenant since after\ninitialization it is autonomous.\n\nOne use case for this might be, for example, a spacechain backbone that\ninfinitely iterates, so it isn't entirely useless.\n\nIf other opcodes are added, such as OP_IN_OUT_AMOUNT, then you can get all\nsorts of recursive covenant interesting stuff on top of that, since you\ncould pre-sign e.g. for a quanitzed vault a number of different\ndeposit/withdraw programs as well as increasing balances depending on\ntimeout waited.\n\n\nTherefore, I think reasonable people might discriminate the \"complexity\nclass\" of the design space available with just CTV v.s. APO.\n\nIn contrast, the approach of smaller independent steps:\n\n1) Adding CTV\n2) Adding CSFS (enables APO-like behavior, sufficient for Eltoo)\n3) Adding flags to CTV, similar to TXHASH, or just adding TXHASH (enables\nfull covenants)\n4) Ergonomic OPCodes for covenants like TLUV, EcTweak, MAST building, etc\n(enables efficient covenants)\n\nis a much more granular path where we are able to cleanly 'level up' into\neach covenant complexity class only if we deem it to be safe.\n\n<redacted>comment about timelines to produce a modified APO</redacted>\n\nBest,\n\nJeremy\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n\nOn Fri, Apr 22, 2022 at 4:23 AM darosior via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I would like to know people's sentiment about doing (a very slightly\n> tweaked version of) BIP118 in place of\n> (or before doing) BIP119.\n>\n> SIGHASH_ANYPREVOUT and its precedent iterations have been discussed for\n> over 6 years. It presents proven and\n> implemented usecases, that are demanded and (please someone correct me if\n> i'm wrong) more widely accepted than\n> CTV's.\n>\n> SIGHASH_ANYPREVOUTANYSCRIPT, if its \"ANYONECANPAY\" behaviour is made\n> optional [0], can emulate CTV just fine.\n> Sure then you can't have bare or Segwit v0 CTV, and it's a bit more\n> expensive to use. But we can consider CTV\n> an optimization of APO-AS covenants.\n>\n> CTV advocates have been presenting vaults as the flagship usecase.\n> Although as someone who've been trying to\n> implement practical vaults for the past 2 years i doubt CTV is necessary\n> nor sufficient for this (but still\n> useful!), using APO-AS covers it. And it's not a couple dozen more virtual\n> bytes that are going to matter for\n> a potential vault user.\n>\n> If after some time all of us who are currently dubious about CTV's stated\n> usecases are proven wrong by onchain\n> usage of a less efficient construction to achieve the same goal, we could\n> roll-out CTV as an optimization.  In\n> the meantime others will have been able to deploy new applications\n> leveraging ANYPREVOUT (Eltoo, blind\n> statechains, etc..[1]).\n>\n>\n> Given the interest in, and demand for, both simple covenants and better\n> offchain protocols it seems to me that\n> BIP118 is a soft fork candidate that could benefit more (if not most of)\n> Bitcoin users.\n> Actually i'd also be interested in knowing if people would oppose the\n> APO-AS part of BIP118, since it enables\n> CTV's features, for the same reason they'd oppose BIP119.\n>\n>\n> [0] That is, to not commit to the other inputs of the transaction (via\n> `sha_sequences` and maybe also\n> `sha_amounts`). Cf\n> https://github.com/bitcoin/bips/blob/master/bip-0118.mediawiki#signature-message\n> .\n>\n> [1] https://anyprevout.xyz/ \"Use Cases\" section\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220503/b53717e0/attachment-0001.html>"
            },
            {
                "author": "Swambo, Jacob",
                "date": "2022-05-03T16:40:22",
                "message_text_only": "Thanks Darosior for your response.\n\nI see now that APOAS (e.g. with ANYONECANPAY and/or SINGLE) and CTV (with less restrictive templates) fall prey to the same trade-off between flexibility and safety. So I retract my statement about that 'point in favour of OP_CTV'. It would be nice to by-pass the trade-off, but it seems to be unavoidable. That begs the question, why would we want to have a way to commit to less restrictive templates?\n\nFirstly, I posit that if a transaction does not allow RBF, then it would be very difficult for an attacker to repackage parts of the transaction into a malicious alternative and rebroadcast it before it reaches the mempool of the majority of nodes, who would then reject the malicious alternative.\n\nSecondly, some covenant-based applications aren't as critical as others, and it may well be acceptable to take the risk of using something like ANYONECANPAY|ALL even with RBF enabled.\n\nThird, in a trusted multi-party context you can safely make use of flexible signature messages. Let's say there are 3 people and a UTXO with the following locking script as a single leaf in the tapscript:\n\n<pk1> OP_CHECKSIG <pk2> OP_CHECKSIGADD <pk3> OP_CHECKSIGADD 2 OP_EQUAL <APOAS|SINGLE:signature_covenant_tx> <covenant_PK> OP_CHECKSIG\n\nAnd they produce this witness:\n\n<SINGLE:sig_1> <ALL:sig_2>\n\nThe second participant can, for example, add a change output before signing. <sig_1> is not sufficient and so can't be repackaged without the authorisation of participant 2.\n\n\nThe additional flexibility through composing APOAS with other SIGHASH modes, and the ability to re-bind covenant transactions to different UTXOs allows protocol designers to do more with APOAS covenants than with CTV covenants (as currently spec'd). I'm not yet convinced that BIP-118 is totally safe, but I think the debate recently is part of that maturation process and I'm glad for it.\n\n\nJacob Swambo\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220503/0dcb6bd3/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "ANYPREVOUT in place of CTV",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "darosior",
                "Nadav Ivgi",
                "Billy Tetrud",
                "Swambo, Jacob",
                "Jeremy Rubin"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 33060
        }
    },
    {
        "title": "[bitcoin-dev] Password-protected wallet on Taproot",
        "thread_messages": [
            {
                "author": "vjudeu at gazeta.pl",
                "date": "2022-05-01T16:18:40",
                "message_text_only": "It seems that Taproot allows us to protect each individual public key with a password. It could work in this way: we have some normal, Taproot-based public key, that is generated in a secure and random way, as it is today in Bitcoin Core wallet. Then, we can create another public key, just by taking password from the user, executing SHA-256 on that, and using it as a private key, so the second key will be just a brainwallet. Then, we can combine them in a Schnorr signature, forming 2-of-2 multisig, where the first key is totally random, and the second key is just a brainwallet that takes a password chosen by the user. By default, each key can be protected with the same password, used for the whole wallet, but it could be possible to choose different passwords for different addresses, if needed. Descriptors should handle that nicely, in the same way as they can be used to handle any other 2-of-2 multisig."
            },
            {
                "author": "Lloyd Fournier",
                "date": "2022-05-04T00:26:46",
                "message_text_only": "Hi Vjudeu,\n\nPerhaps this could make sense in some setting. e.g. instead of a hardware\ndevice which protects your secret key via pin you use a pinless device but\nyou create a strong password and use a proper password hash to create\nanother key and put them in a 2-of-2. But make sure you don't use sha256 to\nhash the password. Use a proper password hash. Keep in mind there's also\nbip39 passwords which do a similar but this does involve entering them into\nthe possibly malicious hardware device.\n\nCheers,\n\nLL\n\nOn Mon, 2 May 2022 at 03:56, vjudeu via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> It seems that Taproot allows us to protect each individual public key with\n> a password. It could work in this way: we have some normal, Taproot-based\n> public key, that is generated in a secure and random way, as it is today in\n> Bitcoin Core wallet. Then, we can create another public key, just by taking\n> password from the user, executing SHA-256 on that, and using it as a\n> private key, so the second key will be just a brainwallet. Then, we can\n> combine them in a Schnorr signature, forming 2-of-2 multisig, where the\n> first key is totally random, and the second key is just a brainwallet that\n> takes a password chosen by the user. By default, each key can be protected\n> with the same password, used for the whole wallet, but it could be possible\n> to choose different passwords for different addresses, if needed.\n> Descriptors should handle that nicely, in the same way as they can be used\n> to handle any other 2-of-2 multisig.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220504/f39b25f0/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Password-protected wallet on Taproot",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "vjudeu at gazeta.pl",
                "Lloyd Fournier"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 2844
        }
    },
    {
        "title": "[bitcoin-dev] Towards a means of measuring user support for Soft Forks",
        "thread_messages": [
            {
                "author": "Billy Tetrud",
                "date": "2022-05-01T22:41:44",
                "message_text_only": ">  if you are perfectly rational, you can certainly imagine a \"what if\"\nwhere your goal is different from your current goal and figure out what you\nwould do ***if*** that were your goal instead.\n\nI see what you're saying, and I'm a lot more on board with that. I still\nthink \"rational\" can't mean \"perfect\" - like \"perfectly rational\" is not\nthe same as \"you magically get to the optimal answer\". But I think my line\nof thinking on this is a lot more pedantic than my previous contention. But\nI will agree that for a given specific objective goal (that ignores other\ngoals), there is an objective set of answers that any logical person should\neventually be able to agree on. Of course, if there's any subjectivity in\nthe goal, then discussing the goal amongst two different people will really\nmean that each of them are discussing slightly different goals, which\nbreaks the premise. So really for alignment to happen, the goal in question\nneeds to be really specific in order to remove any significant\nsubjectivity.\n\n> better-than-human rationality\n\nI like to think of rationality in the following way. Any economic actor is\na being that has goals they want to maximize for, and tools at their\ndisposal to analyze and affect their world. A rational actor is one that\nattempts to use their tools to the best of their ability to maximize their\ngoals. Perhaps goals is a misleading word to use here, since it implies\nsomething that can be achieved, whereas I really mean a set of weighted\nmetrics that can hypothetically always be improved upon. But in any case, a\nhuman starts with goals built into their genetics, which in turn build\nthemselves into the structure of their body. The tools a human has is also\ntheir body and their brain. The brain is not a perfect tool, and neither is\nthe rest of the body. However, humans use what they have to make decisions\nand act on their world. The goals a human has evolve as they have\nexperiences in the world (which end up physically changing their brain). In\nthis sense, every human, and every possible actor really, must be a\nrational actor. They're all doing the best they can, even if the tools at\ntheir disposal are very suboptimal for maximizing their underlying goals.\nWhat more can you ask of a rational actor than to use the tools they have\nto achieve their goals?\n\nSo I don't think anyone is more or less \"rational\" than anyone else. They\njust have different goals and different levels of ability to maximize those\ngoals. In my definition above, the goals are completely arbitrary. They\ndon't have to be anything in particular. A person could have the goal of\nmaximizing the number of paper clips in the world, at all other costs. This\nwould almost certainly be \"bad\" for that person, and \"bad\" for the world,\nbut if that's really what their goals are, then that \"badness\" is a\nsubjectivity that you and I would be placing on that goal because our goals\nare completely different from it. To the being with that goal, it is a\ntotally perfect goal.\n\nThe idea that someone can be \"more rational\" than someone else kind of\nboils everything down to one dimension. In reality, everyone has their\ndifferent skills and proficiencies. In a futures market, you might be\nbetter at predicting the price of salmon, but you might be quite bad at\npredicting human population changes over time. Does this mean you're \"more\nrational\" about salmon but \"less rational\" about how human populations\nchange? I would say a better way to describe this is proficiency, rather\nthan rationality.\n\n</digression>\n\n> a future market\n\nA futures market for predictions is an interesting idea. I haven't really\nheard about such a thing really being done other than in little\nexperiments. Are you suggesting we use one to help make decisions about\nbitcoin? One issue is that the questions a futures market answers have to,\nlike my conclusion in the above paragraph, be completely objective. So a\nfutures market can't answer the question \"what's the best way to design\ncovenants?\" tho it could answer the question \"will CTV be activated by\n2024?\". But as a consequence, I don't think a future's market could help\nmuch in the formulation of appropriate goals for bitcoin. That would need\nto be hashed out by making a lot of different compromises amongst\neveryone's various subjective opinion's about what is best.\n\nAnd I think that's really what I'm suggesting here, is that we bitcoiners\ndiscuss what the objective goals of bitcoin should be, or at least what\nbounds on those goals there should be. And once we have these objective\ngoals, we can be aligned on how to appropriately solve them. It wouldn't\navoid the nashing of teeth needed to hash out the subjective parts of our\nopinions in getting to those goals, but it could avoid much nashing of\nteeth in the other half of the conversation: how to achieve the goals we\nhave reached consensus on.\n\nEg, should a goal of bitcoin be that 50% of the world's population should\nrequire spending no more than 1% of their income to be able to run a full\nnode? Were we to decide on something akin to that, it would at least be a\nquestion that has an objective truth value to it, even if we couldn't\nfeasibly confirm to 100% certainty whether we have achieved it, we could\nprobably confirm with some acceptable level of certainty below 100%.\n\n\n\nOn Sat, Apr 30, 2022 at 1:14 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Billy,\n>\n> > @Zman\n> > > if two people are perfectly rational and start from the same\n> information, they *will* agree\n> > I take issue with this. I view the word \"rational\" to mean basically\n> logical. Someone is rational if they advocate for things that are best for\n> them. Two humans are not the same people. They have different circumstances\n> and as a result different goals. Two actors with different goals will\n> inevitably have things they rationally and logically disagree about. There\n> is no universal rationality. Even an AI from outside space and time is\n> incredibly likely to experience at least some value drift from its peers.\n>\n> Note that \"the goal of this thing\" is part of the information where both\n> \"start from\" here.\n>\n> Even if you and I have different goals, if we both think about \"given this\n> goal, and these facts, is X the best solution available?\" we will both\n> agree, though our goals might not be the same as each other, or the same as\n> \"this goal\" is in the sentence.\n> What is material is simply that the laws of logic are universal and if you\n> include the goal itself as part of the question, you will reach the same\n> conclusion --- but refuse to act on it (and even oppose it) because the\n> goal is not your own goal.\n>\n> E.g. \"What is the best way to kill a person without getting caught?\" will\n> probably have us both come to the same broad conclusion, but I doubt either\n> of us has a goal or sub-goal to kill a person.\n> That is: if you are perfectly rational, you can certainly imagine a \"what\n> if\" where your goal is different from your current goal and figure out what\n> you would do ***if*** that were your goal instead.\n>\n> Is that better now?\n>\n> > > 3. Can we actually have the goals of all humans discussing this topic\n> all laid out, *accurately*?\n> > I think this would be a very useful exercise to do on a regular basis.\n> This conversation is a good example, but conversations like this are rare.\n> I tried to discuss some goals we might want bitcoin to have in a paper I\n> wrote about throughput bottlenecks. Coming to a consensus around goals, or\n> at very least identifying various competing groupings of goals would be\n> quite useful to streamline conversations and to more effectively share\n> ideas.\n>\n>\n> Using a future market has the attractive property that, since money is\n> often an instrumental sub-goal to achieve many of your REAL goals, you can\n> get reasonably good information on the goals of people without them having\n> to actually reveal their actual goals.\n> Also, irrationality on the market tends to be punished over time, and a\n> human who achieves better-than-human rationality can gain quite a lot of\n> funds on the market, thus automatically re-weighing their thoughts higher.\n>\n> However, persistent irrationalities embedded in the design of the human\n> mind will still be difficult to break (it is like a program attempting to\n> escape a virtual machine).\n> And an uninformed market is still going to behave pretty much randomly.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220501/c23d0f10/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Towards a means of measuring user support for Soft Forks",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Billy Tetrud"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 8629
        }
    },
    {
        "title": "[bitcoin-dev] Conjectures on solving the high interactivity issue in payment pools and channel factories",
        "thread_messages": [
            {
                "author": "Billy Tetrud",
                "date": "2022-05-01T22:53:13",
                "message_text_only": "Hi Antoine,\n\nVery interesting exploration. I think you're right that there are issues\nwith the kind of partitioning you're talking about. Lightning works because\nall participants sign all offchain states (barring data loss). If a\nparticipant can be excluded from needing to agree to a new state, there\nmust be an additional mechanism to ensure the relevant state for that\nparticipant isn't changed to their detriment.\n\nTo summarize my below email, the two techniques I can think for solving\nthis problem are:\n\nA. Create sub-pools when the whole group is live that can be used by the\nsub- pool participants later without the whole group's involvement. The\nwhole group is needed to change the whole group's state (eg close or open\nsub-pools), but sub-pool states don't need to involve the whole group.\nB. Have an always-online system empowered to sign only for group updates\nthat *do not* change the owner's balance in the group. This could be done\nwith a hardware-wallet like device, or could be done with some kind of new\nset of opcodes that can be used to verify that a particular transaction\nisn't to the owner's detriment.\n\nI had some thoughts that I think don't pan out, but here they are anyway:\n\nWhat if the pool state transaction (that returns everyone's money) has each\nparticipant sign the input + their personal output (eg with sighash flags)?\nThat way the transaction could have outputs swapped out by a subset of\nparticipants as needed. Some kind of eltoo mechanism could then ensure that\nthe latest transaction can override earlier transactions. As far as the\nnon-participating members are concerned, they don't care whether the newest\nstate is published or whether the newest state they participated in is\npublished - because their output is identical either way. However, I can\nsee that there might be problems related to separate groups of participants\ncreating conflicting transactions, ie A B & C create a partition like this,\nand so do D E & F, but they don't know about each other's state. If they\nhave some always-online coordination mechanism, this could be solved as\nlong as the participants aren't malicious. But it still leaves open the\npossibility that some participants could intentionally grief others by\nintentionally creating conflicting state transactions. Theoretically it\ncould be structured so that no funds could be directly stolen, but it seems\nunavoidable that some group of members could create a secret transaction\nthat when published makes the most recent honest state not minable.\n\nCome to think of it tho, this doesn't actually solve the double spending\nproblem. The fundamental issue is that if you have a subset of participants\ncreating partitions like this, without the involvement of the whole group,\nits impossible for any subset of participants to know for sure that there\nisn't a double-spending partition amongst another set of members of the\ngroup.\n\nOn-chain bitcoin transactions prevent double spending by ensuring that\neveryone knows what outputs have been spent. Payment channels prevent\ndouble spending by ensuring that everyone that's part of the channel knows\nwhat the current channel state is. Any 3rd layer probably needs this exact\nproperty: everyone involved must know the state. So you should be able to\ncreate a partition when the whole group is live, and thereafter the members\nof that partition can use that partition without involving the rest of the\ngroup. I think that pattern can work to any level of depth. After thinking\nabout this, I conjecture it might be a fundamental property of the double\nspending problem. All participants must be aware of the whole state\notherwise the double spending problem exists for those who aren't aware of\nthe whole state.\n\n> this is forcing the pool/factory user to share their key materials with\npotentially lower trusted entities, if they don't self-host the tower\ninstances.\n\nI had a conceptual idea a while back (that I can't find at the moment)\nabout offline lightning receiving. The concept is that each lightning node\nin a channel has two separate keys: a spending-key and a receiving-key. The\nspending-key must be used manually by the node owner to send payments,\nhowever the receiving-key can be given to an always-online service that can\nuse that key only to either receive funds (ie update the state to a more\nfavorable state).\n\nRight now with just a single-hot-key setup you need to trust your online\nsystem to only sign receiving transactions and would refuse to sign any\nproposed channel update not in the owner's favor. However, if the node was\ncompromised all bets are off - the entire channel balance could be stolen.\n\nYou could do this logic inside a hardware-wallet-like device that checks\nthe proposed updates and verifies the new state is favorable before\nsigning. This could go a long way to hardening lightning nodes against\npotential compromise.\n\nBut if we go a step further, what if we enable that logic of ensuring the\nstate is more favorable with an on-chain mechanism? This was where my idea\ngot a bit hand wavy, but I think it could theoretically be done. The\nreceiving-key would be able to sign receiving transactions that would only\nbe valid when the most recent state signed by the spending-key is also\nincluded in the script sig in some way. Some Script would then validate\nthat the receiving-key state being published is more favorable than the\nspending-key state in that transaction's outputs. You'd have a couple\nguarantees:\n\n1. The usual guarantee that if the presented last spending-key state is\nactually out of date, the transaction could be overridden by the newer\nstate in some way (eg eltoo style or punishment).\n2. The state being published can be no worse than the presented\nspending-key state. Yes, your channel partner could compromise your\nreceiving/routing node and then publish an out of date receiving-key\nchannel state that's based on the most-recent spending-key state, but it\nwould limit your losses to at most the amount of money you've received\nsince the last time you manually signed a channel state with your\nspending-key. Because the always-online system empowered to receive does\n*not* have the spending-key, anyone that compromises that node can't spend\nand the damage is limited.\n\nWhile less straight-forward than for receiving, in principle it seems like\nsomething similar could be done for routing (which would require presenting\nthe state of multiple channels, and so has some additional complexities\nthere I haven't worked out).\n\nThis kind of thing might be a way of working around interactivity\nrequirements of payment pools and the like. All participants still have to\nbe aware of the whole state (eg of the payment pool), but this awareness\ncan be delegated to a system you have limited trust in. Payment pool\nparticipants could delegate an always-online system empowered with a\nseparate key to sign payment pool updates that user's state isn't changed\nfor, allowing the payment pool to do its thing without exposing the user to\nhot-key vulnerabilities in that always-online system. Double spending is\nprevented because the user can access their always-online system to get the\nfull payment pool state.\n\nSo in short, while I think there may be no way to fundamentally not require\ninteractivity, there are workarounds that can limit how often full\ninteractivity is needed as well as ways to make it easier to provide that\nfull interactivity without compromising other aspects of each participant's\nsecurity.\n\nOn Thu, Apr 28, 2022 at 8:20 AM Antoine Riard via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi,\n>\n> This post recalls the noticeable interactivity issue encumbering payment\n> pools and channel factories in the context of a high number of\n> participants, describes how the problem can be understood and proposes few\n> solutions with diverse trust-minizations and efficiency assumptions. It is\n> intended to capture the theoretical bounds of the \"interactivity issue\",\n> where technical completeness of the solutions is exposed in future works.\n>\n> The post assumes a familiarity with the CoinPool paper concepts and\n> terminology [0].\n>\n> # The interactivity requirement grieving payment pools/channel factories\n>\n> Payment pools and channel factories are multi-party constructions enabling\n> to share the ownership of a single on-chain UTXO among many\n> off-chain/promised balances. Payment pool improves on the channel factory\n> construction fault-tolerance by reducing the number of balance outputs\n> disclosed  on-chain to a single one in case of unilateral user exits.\n>\n> However, those constructions require all the users to be online and\n> exchange rounds of signatures to update the balance distribution. Those\n> liveliness/interactivity requirements are increasing with the number of\n> users, as there are higher odds of *one* lazzy/buggy/offline user stalling\n> the pool/factory updates.\n>\n> In echo, the design of LN was envisioned for a network of\n> always-online/self-hosted participants, the early deployment of LN showed\n> the resort to delegated channel hosting solutions, relieving users from the\n> liveliness requirement. While the trust trade-offs of those solutions are\n> significant, they answer the reality of a world made of unreliable networks\n> and mobile devices.\n>\n> Minding that observation, the attractiveness of pools/factories might be\n> questioned.\n>\n> # The interactivity requirement palliatives and their limits\n>\n> Relatively straightforward solutions to lower the interactivity\n> requirement, or its encumbered costs, can be drawn out. Pools/factories\n> users could own (absolute) timelocked kick-out abilities to evict offline\n> users who are not present before expiration.\n>\n> E.g, let's say you have Alice, Bob, Caroll and Dave as pool participants.\n> Each of them owns a Withdraw transaction to exit their individual balances\n> at any time. Each user should have received the pre-signed components from\n> the others guaranteeing the unilateral ability to publish the Withdraw.\n>\n> A kick-out ability playable by any pool user could be provided by\n> generating a second set of Withdraw transactions, with the difference of\n> the nLocktime field setup to an absolute height T + X, where T is the\n> height at which the corresponding Update transaction is generated and X the\n> kick-out delay.  For this set of kick-out transactions, the complete\n> witnesses should be fully shared among Alice, Bob, Caroll and Dave. That\n> way, if Caroll is unresponsive to move the pool state forward after X, any\n> one of Alice, Bob or Dave can publish the Caroll kick-out Withdraw\n> transaction, and pursue operations without that unresponsive party.\n>\n> While decreasing the interactivity requirement to the timelock delay, this\n> solution is constraining the kicked user to fallback on-chain encumbering\n> the UTXO set with one more entry.\n>\n> Another solution could be to assume the widespread usage of node towers\n> among the pool participants. Those towers would host the full logic and key\n> state necessary to receive an update request and produce a user's approval\n> of it. As long as one tower instance is online per-user, the pool/factory\n> can move forward. Yet this is forcing the pool/factory user to share their\n> key materials with potentially lower trusted entities, if they don't\n> self-host the tower instances.\n>\n> Ideally, I think we would like a trust-minimized solution enabling\n> non-interactive, off-chain updates of the pool/factory, with no or minimal\n> consumption of blockspace.\n>\n> For the remainder of this post, only the pool use-case will be mentioned.\n> Though, I think the observations/implications can be extended to factories\n> as well.\n>\n> # Non-interactive Off-chain Pool Partitions\n>\n> If a pool update fails because of lack of online unanimity, a partition\n> request could be exchanged among the online subset of users (\"the\n> actives\"). They decide to partition the pool by introducing a new layer of\n> transactions gathering the promised/off-chain outputs of the actives. The\n> set of outputs belonging to the passive users remains unchanged.\n>\n> The actives spend their Withdraw transactions `user_balance` outputs back\n> to a new intermediate Update transaction. This \"intermediate\" Update\n> transaction is free to re-distribute the pool balances among the active\n> users. To guarantee the unilateral withdraw ability of a partitioned-up\n> balance, the private components of the partitioned Withdraw transactions\n> should be revealed among the set of active users.\n>\n> E.g, let's say you have Alice, Bob, Caroll and Dave as pool participants.\n> Pool is at state N, Bob and Dave are offline. Alice and Caroll agree to\n> partition the pool, each of them owns a Withdraw transaction\n> ready-to-be-attached on the Update transaction N. They generate a new\n> partitioning Update transaction with two inputs spending respectively\n> Alice's Withdraw transaction `user_balance` output and Caroll's Withdraw\n> transaction `user-balance` output. From this partitioning Update\n> transaction, two new second-layer Withdraw ones are issued.\n>\n> Alice and Caroll reveal to each other the private components of their\n> first-layer Withdraw transactions, allowing to publish the full branch :\n> first-layer Update transaction, first-layer Withdraw transactions,\n> second-layer partitioning Update transaction, second-layer partitioned\n> Withdraw transaction. At that step, I think the partitioning should be\n> complete.\n>\n> Quickly, a safety issue arises with pool partitioning. A participant of\n> the active set A could equivocate the partition state by signing another\n> spend of her Withdraw transaction allocating her balance to an Update\n> transaction of a \"covert\" set of active users B.\n>\n> This equivocation exists because there is no ordering of the off-chain\n> spend of the Withdraw transactions and any Withdraw transaction can be\n> freely spent by its owner. This issue appears as similar to solving the\n> double-spend problem.\n>\n> Equivocation is a different case than multiple *parallel* partitions,\n> where there is no intersection between the partitioned balances. The\n> parallel partitions are still rooting from the same Update transaction N. I\n> think the safety of parallel partitions is yet to be explored.\n>\n> # Current solutions to the double-spend problem : Bitcoin base-layer &\n> Lightning Network\n>\n> Of course, the double-spend issue is already addressed on the Bitcoin\n> base-layer due to nodes consensus convergence on the most-proof-of-work\n> accumulated valid chain of blocks. While reorg can happen, a UTXO cannot be\n> spent twice on the same chain. This security model can be said to be\n> prophylactic, i.e an invalid block cannot be applied to a node's state and\n> should be rejected.\n>\n> The double-spend issue is also solved in its own way in payment channels.\n> If a transaction is published, of which the correctness has been revoked\n> w.r.t negotiated, private channel state, the wronged channel users must\n> react in consequence. This security model can be said to be corrective,\n> states updates are applied first on the global ledger then eventually\n> corrected.\n>\n> A solution to the pool partition equivocation issue appears as either\n> based on a prophylactic one or a corrective security model.\n>\n> Let's examine first, a reactive security model similar to LN-Penalty. At\n> pool partition proposals, the owners of the partitioned-up Withdraw\n> transactions could reveal a revocation secret enabling correction in case\n> of wrongdoing (e.g single-show signatures). However, such off-chain\n> revocation can be committed towards multiple sets of honest \"active\" users.\n> Only one equivocating balance spend can succeed, letting the remaining set\n> of honest users still be deprived of their expected partitioned balances.\n>\n> E.g, let's say you have Alice, Bob, Caroll and Dave as pool participants.\n> Alice contacts Bob to form a first partition, then Caroll to form a second\n> one, then Dave to form a last one. If she is successful in that\n> equivocation trick, she can *triple*-spend her balance against any goods or\n> out-of-pool payments.\n>\n> Assuming the equivocation is discovered once realized, Bob, Caroll and\n> Dave are all left with a branch of transactions all including Alice's\n> Withdraw one. However only one branch can be fully published, as a Withdraw\n> transaction can be played only once following the pool semantic.\n> Game-theory-wise, Bob, Caroll and Dave have an interest to enter in a fee\n> race to be the first to confirm and earn the Alice balance spend.\n>\n> The equivocation is only bounded by the maximal number of equivocating\n> sets one can form, namely the number of pool users. However, correction can\n> only be limited to the equivocated balance. Therefore, it appears that\n> corrective security models in the context of multi-party are always\n> producing an economic disequilibrium.\n>\n> An extension of this corrective model could be to require off-pool\n> collaterals locked-up, against which the revocation secret would be\n> revealed at partition generation. However, this fix is limited to the\n> collateral liquidity available. One collateral balance should be guaranteed\n> for each potential victim, thus the collateral liquidity should be equal to\n> the number of pool users multiplied by the equivocatable balance amount.\n>\n> It sounds like a more economic-efficient security model of the pool\n> partitioning can be established with a prophylactic technique.\n>\n> # Trusted coordinator\n>\n> A genuine solution could be to rely on a coordinator collecting the\n> partition declaration and order them canonically. The pool partition\n> candidates can then fetch them and decide their partitions acceptance\n> decisions on that. Of course, the coordinator is trusted and can drop or\n> dissimulate any partition, thus enabling partitioned balance equivocation.\n>\n> # Trust-minimized : Partition Statements\n>\n> A pool partition invalidity can be defined by the existence of two\n> second-layer Update transactions at the same state number spending the same\n> Withdraw transaction balance output. Each Update transaction signature can\n> be considered as a \"partition statement\". A user wishing to join a\n> partition should ensure there is no conflicting partition statement before\n> applying the partition to her local state.\n>\n> The open question is from where the conflict should be observed. A\n> partition statement log could be envisioned and monitored by pool users\n> before to accept any partition.\n>\n> I think multiple partition statement publication spaces can be drawn out,\n> with different trust-minization trade-offs.\n>\n> # Publication space : Distributed Bulletin Boards\n>\n> The set of \"active\" pool users could host their own boards of partition\n> statements. They would coordinate on the statement order through a\n> consensus algorithm (e.g Raft). For redundancy, a user can have multiple\n> board instances. If a user falls offline, they can fetch the statement\n> order from the other users boards.\n>\n> However, while this solution distributes the trust across all the other\n> users, it's not safe in case of malicious user coalitions agreeing among\n> themselves to drop a partition statement. Therefore, a user catching up\n> online can be feeded with an incorrect view of the existing partitions, and\n> thus enter into an equivocated partition.\n>\n> # Publication space : On-chain Authoritative Board\n>\n> Another solution could be to designate an authoritative UTXO at pool\n> setup. This UTXO could be spent by any user of the pool set (1-of-N) to a\n> covenanted transaction sending back to a Taproot output with the same\n> internal key. The Merkelized tree tweaked could be modified by the spender\n> to stamp the partition statements as leaves hashes. The statement data is\n> not committed in the leaves itself and the storage can be delegated to\n> out-of-band archive servers.\n>\n> E.g, let's say you have Alice, Bob, Caroll and Dave as pool participants.\n> Alice and Bob decide to start a partition, they commit a hash of the\n> partitioning Update transaction as a Taproot tree leaf and they spend the\n> pool authoritative UTXO. They also send a copy of the Update transaction to\n> an archive server.\n>\n> At a later time, Alice proposes to Caroll to start a partition. Caroll\n> follows the chain of transactions forming the on-chain authoritative board,\n> she fetches the merkle branches and leaves data payload from an archive\n> server, verifying the authenticity of the branches and payload. As Alice\n> has already published a partition statement spending her Withdraw, Caroll\n> should refuse the partition proposal.\n>\n> Even if a pool user goes offline, she can recover the correct partition\n> statement logs, as it has been committed in the chain from the\n> authoritative UTXO. If the statement data is not available from servers,\n> the pool user should not engage in partitions.\n>\n> Assuming the spend confirms in every block, this solution enables\n> partitions every 10min. The cost can be shared across pool instances, if\n> the authoritative signers set is made of multiple pool instances signers\n> sets. A threshold signature scheme could be used to avoid interactivity\n> beyond the aggregated key setup. However, batching across pool instances\n> increases the set of data to verify by the partition candidate users, which\n> could be a grievance for bandwidth-constrained clients.\n>\n> # Fiability of the Publication of Partition Statements\n>\n> Whatever ends up being used as a partition statement log, there is still\n> the question of the incentives of pool users to publish the partition\n> statements. A malicious user could act in coalition with the equivocating\n> entity to retain the publication of her partition statement. Thus, an\n> honest user would only be aware of her own partition statement and accept\n> the partition proposal from the will-be equivocating entity.\n>\n> I think that leveraging covenants a revocation mechanism could be attached\n> on any equivocating branch of transactions, allowing in the above case a\n> single honest user to punish the publication. While a revocation mechanism\n> does not work in case of multiple defrauded users, I believe the existence\n> of a revocation mechanism makes the formation of malicious coalitions\n> unsafe for their conjurers.\n>\n> Indeed, any user entering in the coalition is not guaranteed to be blinded\n> to other equivocating branches generated by the partition initiator.\n> Therefore, the publication of a partition statement by everyone is\n> holistically optimal to discover any equivocating candidate among the pool\n> users.\n>\n> Further research should establish the soundness of the partition statement\n> publication game-theory.\n>\n> # Writing the Partition Statements to a new Consensus Data Structure\n>\n> To avoid a solution relying on game-theory, a new consensus data structure\n> could be introduced to register and order the partition statements. This\n> off-chain contract register could be a Merkle tree, where every leaf is a\n> pool balance identified by a key. This register would be established\n> on-chain at the same time the pool is set up.\n>\n> Every time the pool is partitioned, the tree leaves would be updated with\n> the partition statement committed to. Only one partition could be\n> registered per user by state number. The publication branch would be\n> invalid if it doesn't point back to the corresponding contract register\n> tree entries. When the first-layer pool Update transaction is replaced, the\n> tree should transition to a blank state too.\n>\n> Beyond the high cost of yet-another softfork to introduce such consensus\n> data structure, the size of the witness to write into the contract register\n> could be so significant that the economic attractiveness of pool\n> partitioning is decreased in consequence.\n>\n> If you have read so far, thank you. And curious if anyone has more ideas\n> or thoughts on  the high interactivity issue ?\n>\n> Thanks Gleb for the review.\n>\n> Cheers,\n> Antoine\n>\n> [0] https://coinpool.dev/\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220501/29523d35/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-05-10T00:38:36",
                "message_text_only": "Hi Billy,\n\nThanks for reading.\n\n> A. Create sub-pools when the whole group is live that can be used by the\n> sub- pool participants later without the whole group's involvement. The\n> whole group is needed to change the whole group's state (eg close or open\n> sub-pools), but sub-pool states don't need to involve the whole group.\n\nYes this could be a direction. Assume you have a fan-out transaction\nspending the Update transaction to a combination of sub-pools. I think you\nhave two problems arising.\n\nThe first one it's hard to predict in advance the subset of pool\nparticipants which will be inactive, and thus guaranteeing stale-free\nsub-pools. Further, it's also hard to predict in advance the liquidity\nneeds of the sub-pools. So I think this prediction of these two factors is\nunlikely to be correct, this statement getting more sound as the number of\npool participants increases.\n\nThe second one, this fan-out transaction could interfere with the\nconfirmation of the simple withdraw transactions, and thus the uplifted\nconstructions (e.g a LN channel). So there is an open question about the\n\"honest\" usage of the sub-pool states themselves.\n\n> B. Have an always-online system empowered to sign only for group updates\n> that *do not* change the owner's balance in the group. This could be done\n> with a hardware-wallet like device, or could be done with some kind of new\n> set of opcodes that can be used to verify that a particular transaction\n> isn't to the owner's detriment.\n\nSure, one could envision an accumulator committing directly to balances\ntoo. State transition would be allowed only if the non-involved users\nbalances are immutably preserved to, only the active users balances are\nmixed. I think the challenge is to find a compact accumulator with those\nproperties.\n\nAbout the \"hardware-wallet like device\"/\"towers\" solution, yes this is a\nknown technique to solve interactivity. Sadly, this can be a significant\nrequirement for a lot of users to run an additional always-online process.\nIt's more likely a lot of them will delegate this operation to third-party\nproviders, with the known reductions in terms of trust-minimizations.\n\n> Come to think of it tho, this doesn't actually solve the double spending\n> problem. The fundamental issue is that if you have a subset of\nparticipants\n> creating partitions like this, without the involvement of the whole group,\n> its impossible for any subset of participants to know for sure that there\n> isn't a double-spending partition amongst another set of members of the\n> group.\n\nYes, it seems we agree that equivocation opening the way to balance\ndouble-spend is the hard issue with partitioning multi-party constructions.\n\n> I had a conceptual idea a while back (that I can't find at the moment)\n> about offline lightning receiving. The concept is that each lightning node\n> in a channel has two separate keys: a spending-key and a receiving-key.\nThe\n> spending-key must be used manually by the node owner to send payments,\n> however the receiving-key can be given to an always-online service that\ncan\n> use that key only to either receive funds (ie update the state to a more\n> favorable state).\n\nHmmm, how could you prevent the always-online service from using the\nreceiving-key in \"spending\" mode if the balance stacked there becomes\nrelevant ?\n\n> You could do this logic inside a hardware-wallet-like device that checks\n> the proposed updates and verifies the new state is favorable before\n> signing. This could go a long way to hardening lightning nodes against\n> potential compromise.\n\nYes, see https://gitlab.com/lightning-signer/docs for wip in that direction.\n\n> This kind of thing might be a way of working around interactivity\n> requirements of payment pools and the like. All participants still have to\n> be aware of the whole state (eg of the payment pool), but this awareness\n> can be delegated to a system you have limited trust in. Payment pool\n> participants could delegate an always-online system empowered with a\n> separate key to sign payment pool updates that user's state isn't changed\n> for, allowing the payment pool to do its thing without exposing the user\nto\n> hot-key vulnerabilities in that always-online system. Double spending is\n> prevented because the user can access their always-online system to get\nthe\n> full payment pool state.\n\nWhile I would be curious to see such Script-based \"receiving-key\" only\nmechanism (maybe with IN_OUT_AMOUNT-style of covenant) I wonder if it would\nsolve equivocation fully. A malicious pool participant could still commit\nher off-chain balance in two partitions and send spends to the A&B hosting\n\"receiving-keys\" entities without them being aware of the conflict, in the\nlack of a reconciliation such as a publication space ? Or do you have\nanother thinking ?\n\nAntoine\n\nLe dim. 1 mai 2022 \u00e0 18:53, Billy Tetrud <billy.tetrud at gmail.com> a \u00e9crit :\n\n> Hi Antoine,\n>\n> Very interesting exploration. I think you're right that there are issues\n> with the kind of partitioning you're talking about. Lightning works because\n> all participants sign all offchain states (barring data loss). If a\n> participant can be excluded from needing to agree to a new state, there\n> must be an additional mechanism to ensure the relevant state for that\n> participant isn't changed to their detriment.\n>\n> To summarize my below email, the two techniques I can think for solving\n> this problem are:\n>\n> A. Create sub-pools when the whole group is live that can be used by the\n> sub- pool participants later without the whole group's involvement. The\n> whole group is needed to change the whole group's state (eg close or open\n> sub-pools), but sub-pool states don't need to involve the whole group.\n> B. Have an always-online system empowered to sign only for group updates\n> that *do not* change the owner's balance in the group. This could be done\n> with a hardware-wallet like device, or could be done with some kind of new\n> set of opcodes that can be used to verify that a particular transaction\n> isn't to the owner's detriment.\n>\n> I had some thoughts that I think don't pan out, but here they are anyway:\n>\n> What if the pool state transaction (that returns everyone's money) has\n> each participant sign the input + their personal output (eg with sighash\n> flags)? That way the transaction could have outputs swapped out by a subset\n> of participants as needed. Some kind of eltoo mechanism could then ensure\n> that the latest transaction can override earlier transactions. As far as\n> the non-participating members are concerned, they don't care whether the\n> newest state is published or whether the newest state they participated in\n> is published - because their output is identical either way. However, I can\n> see that there might be problems related to separate groups of participants\n> creating conflicting transactions, ie A B & C create a partition like this,\n> and so do D E & F, but they don't know about each other's state. If they\n> have some always-online coordination mechanism, this could be solved as\n> long as the participants aren't malicious. But it still leaves open the\n> possibility that some participants could intentionally grief others by\n> intentionally creating conflicting state transactions. Theoretically it\n> could be structured so that no funds could be directly stolen, but it seems\n> unavoidable that some group of members could create a secret transaction\n> that when published makes the most recent honest state not minable.\n>\n> Come to think of it tho, this doesn't actually solve the double spending\n> problem. The fundamental issue is that if you have a subset of participants\n> creating partitions like this, without the involvement of the whole group,\n> its impossible for any subset of participants to know for sure that there\n> isn't a double-spending partition amongst another set of members of the\n> group.\n>\n> On-chain bitcoin transactions prevent double spending by ensuring that\n> everyone knows what outputs have been spent. Payment channels prevent\n> double spending by ensuring that everyone that's part of the channel knows\n> what the current channel state is. Any 3rd layer probably needs this exact\n> property: everyone involved must know the state. So you should be able to\n> create a partition when the whole group is live, and thereafter the members\n> of that partition can use that partition without involving the rest of the\n> group. I think that pattern can work to any level of depth. After thinking\n> about this, I conjecture it might be a fundamental property of the double\n> spending problem. All participants must be aware of the whole state\n> otherwise the double spending problem exists for those who aren't aware of\n> the whole state.\n>\n> > this is forcing the pool/factory user to share their key materials with\n> potentially lower trusted entities, if they don't self-host the tower\n> instances.\n>\n> I had a conceptual idea a while back (that I can't find at the moment)\n> about offline lightning receiving. The concept is that each lightning node\n> in a channel has two separate keys: a spending-key and a receiving-key. The\n> spending-key must be used manually by the node owner to send payments,\n> however the receiving-key can be given to an always-online service that can\n> use that key only to either receive funds (ie update the state to a more\n> favorable state).\n>\n> Right now with just a single-hot-key setup you need to trust your online\n> system to only sign receiving transactions and would refuse to sign any\n> proposed channel update not in the owner's favor. However, if the node was\n> compromised all bets are off - the entire channel balance could be stolen.\n>\n> You could do this logic inside a hardware-wallet-like device that checks\n> the proposed updates and verifies the new state is favorable before\n> signing. This could go a long way to hardening lightning nodes against\n> potential compromise.\n>\n> But if we go a step further, what if we enable that logic of ensuring the\n> state is more favorable with an on-chain mechanism? This was where my idea\n> got a bit hand wavy, but I think it could theoretically be done. The\n> receiving-key would be able to sign receiving transactions that would only\n> be valid when the most recent state signed by the spending-key is also\n> included in the script sig in some way. Some Script would then validate\n> that the receiving-key state being published is more favorable than the\n> spending-key state in that transaction's outputs. You'd have a couple\n> guarantees:\n>\n> 1. The usual guarantee that if the presented last spending-key state is\n> actually out of date, the transaction could be overridden by the newer\n> state in some way (eg eltoo style or punishment).\n> 2. The state being published can be no worse than the presented\n> spending-key state. Yes, your channel partner could compromise your\n> receiving/routing node and then publish an out of date receiving-key\n> channel state that's based on the most-recent spending-key state, but it\n> would limit your losses to at most the amount of money you've received\n> since the last time you manually signed a channel state with your\n> spending-key. Because the always-online system empowered to receive does\n> *not* have the spending-key, anyone that compromises that node can't spend\n> and the damage is limited.\n>\n> While less straight-forward than for receiving, in principle it seems like\n> something similar could be done for routing (which would require presenting\n> the state of multiple channels, and so has some additional complexities\n> there I haven't worked out).\n>\n> This kind of thing might be a way of working around interactivity\n> requirements of payment pools and the like. All participants still have to\n> be aware of the whole state (eg of the payment pool), but this awareness\n> can be delegated to a system you have limited trust in. Payment pool\n> participants could delegate an always-online system empowered with a\n> separate key to sign payment pool updates that user's state isn't changed\n> for, allowing the payment pool to do its thing without exposing the user to\n> hot-key vulnerabilities in that always-online system. Double spending is\n> prevented because the user can access their always-online system to get the\n> full payment pool state.\n>\n> So in short, while I think there may be no way to fundamentally not\n> require interactivity, there are workarounds that can limit how often full\n> interactivity is needed as well as ways to make it easier to provide that\n> full interactivity without compromising other aspects of each participant's\n> security.\n>\n> On Thu, Apr 28, 2022 at 8:20 AM Antoine Riard via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi,\n>>\n>> This post recalls the noticeable interactivity issue encumbering payment\n>> pools and channel factories in the context of a high number of\n>> participants, describes how the problem can be understood and proposes few\n>> solutions with diverse trust-minizations and efficiency assumptions. It is\n>> intended to capture the theoretical bounds of the \"interactivity issue\",\n>> where technical completeness of the solutions is exposed in future works.\n>>\n>> The post assumes a familiarity with the CoinPool paper concepts and\n>> terminology [0].\n>>\n>> # The interactivity requirement grieving payment pools/channel factories\n>>\n>> Payment pools and channel factories are multi-party constructions\n>> enabling to share the ownership of a single on-chain UTXO among many\n>> off-chain/promised balances. Payment pool improves on the channel factory\n>> construction fault-tolerance by reducing the number of balance outputs\n>> disclosed  on-chain to a single one in case of unilateral user exits.\n>>\n>> However, those constructions require all the users to be online and\n>> exchange rounds of signatures to update the balance distribution. Those\n>> liveliness/interactivity requirements are increasing with the number of\n>> users, as there are higher odds of *one* lazzy/buggy/offline user stalling\n>> the pool/factory updates.\n>>\n>> In echo, the design of LN was envisioned for a network of\n>> always-online/self-hosted participants, the early deployment of LN showed\n>> the resort to delegated channel hosting solutions, relieving users from the\n>> liveliness requirement. While the trust trade-offs of those solutions are\n>> significant, they answer the reality of a world made of unreliable networks\n>> and mobile devices.\n>>\n>> Minding that observation, the attractiveness of pools/factories might be\n>> questioned.\n>>\n>> # The interactivity requirement palliatives and their limits\n>>\n>> Relatively straightforward solutions to lower the interactivity\n>> requirement, or its encumbered costs, can be drawn out. Pools/factories\n>> users could own (absolute) timelocked kick-out abilities to evict offline\n>> users who are not present before expiration.\n>>\n>> E.g, let's say you have Alice, Bob, Caroll and Dave as pool participants.\n>> Each of them owns a Withdraw transaction to exit their individual balances\n>> at any time. Each user should have received the pre-signed components from\n>> the others guaranteeing the unilateral ability to publish the Withdraw.\n>>\n>> A kick-out ability playable by any pool user could be provided by\n>> generating a second set of Withdraw transactions, with the difference of\n>> the nLocktime field setup to an absolute height T + X, where T is the\n>> height at which the corresponding Update transaction is generated and X the\n>> kick-out delay.  For this set of kick-out transactions, the complete\n>> witnesses should be fully shared among Alice, Bob, Caroll and Dave. That\n>> way, if Caroll is unresponsive to move the pool state forward after X, any\n>> one of Alice, Bob or Dave can publish the Caroll kick-out Withdraw\n>> transaction, and pursue operations without that unresponsive party.\n>>\n>> While decreasing the interactivity requirement to the timelock delay,\n>> this solution is constraining the kicked user to fallback on-chain\n>> encumbering the UTXO set with one more entry.\n>>\n>> Another solution could be to assume the widespread usage of node towers\n>> among the pool participants. Those towers would host the full logic and key\n>> state necessary to receive an update request and produce a user's approval\n>> of it. As long as one tower instance is online per-user, the pool/factory\n>> can move forward. Yet this is forcing the pool/factory user to share their\n>> key materials with potentially lower trusted entities, if they don't\n>> self-host the tower instances.\n>>\n>> Ideally, I think we would like a trust-minimized solution enabling\n>> non-interactive, off-chain updates of the pool/factory, with no or minimal\n>> consumption of blockspace.\n>>\n>> For the remainder of this post, only the pool use-case will be mentioned.\n>> Though, I think the observations/implications can be extended to factories\n>> as well.\n>>\n>> # Non-interactive Off-chain Pool Partitions\n>>\n>> If a pool update fails because of lack of online unanimity, a partition\n>> request could be exchanged among the online subset of users (\"the\n>> actives\"). They decide to partition the pool by introducing a new layer of\n>> transactions gathering the promised/off-chain outputs of the actives. The\n>> set of outputs belonging to the passive users remains unchanged.\n>>\n>> The actives spend their Withdraw transactions `user_balance` outputs back\n>> to a new intermediate Update transaction. This \"intermediate\" Update\n>> transaction is free to re-distribute the pool balances among the active\n>> users. To guarantee the unilateral withdraw ability of a partitioned-up\n>> balance, the private components of the partitioned Withdraw transactions\n>> should be revealed among the set of active users.\n>>\n>> E.g, let's say you have Alice, Bob, Caroll and Dave as pool participants.\n>> Pool is at state N, Bob and Dave are offline. Alice and Caroll agree to\n>> partition the pool, each of them owns a Withdraw transaction\n>> ready-to-be-attached on the Update transaction N. They generate a new\n>> partitioning Update transaction with two inputs spending respectively\n>> Alice's Withdraw transaction `user_balance` output and Caroll's Withdraw\n>> transaction `user-balance` output. From this partitioning Update\n>> transaction, two new second-layer Withdraw ones are issued.\n>>\n>> Alice and Caroll reveal to each other the private components of their\n>> first-layer Withdraw transactions, allowing to publish the full branch :\n>> first-layer Update transaction, first-layer Withdraw transactions,\n>> second-layer partitioning Update transaction, second-layer partitioned\n>> Withdraw transaction. At that step, I think the partitioning should be\n>> complete.\n>>\n>> Quickly, a safety issue arises with pool partitioning. A participant of\n>> the active set A could equivocate the partition state by signing another\n>> spend of her Withdraw transaction allocating her balance to an Update\n>> transaction of a \"covert\" set of active users B.\n>>\n>> This equivocation exists because there is no ordering of the off-chain\n>> spend of the Withdraw transactions and any Withdraw transaction can be\n>> freely spent by its owner. This issue appears as similar to solving the\n>> double-spend problem.\n>>\n>> Equivocation is a different case than multiple *parallel* partitions,\n>> where there is no intersection between the partitioned balances. The\n>> parallel partitions are still rooting from the same Update transaction N. I\n>> think the safety of parallel partitions is yet to be explored.\n>>\n>> # Current solutions to the double-spend problem : Bitcoin base-layer &\n>> Lightning Network\n>>\n>> Of course, the double-spend issue is already addressed on the Bitcoin\n>> base-layer due to nodes consensus convergence on the most-proof-of-work\n>> accumulated valid chain of blocks. While reorg can happen, a UTXO cannot be\n>> spent twice on the same chain. This security model can be said to be\n>> prophylactic, i.e an invalid block cannot be applied to a node's state and\n>> should be rejected.\n>>\n>> The double-spend issue is also solved in its own way in payment channels.\n>> If a transaction is published, of which the correctness has been revoked\n>> w.r.t negotiated, private channel state, the wronged channel users must\n>> react in consequence. This security model can be said to be corrective,\n>> states updates are applied first on the global ledger then eventually\n>> corrected.\n>>\n>> A solution to the pool partition equivocation issue appears as either\n>> based on a prophylactic one or a corrective security model.\n>>\n>> Let's examine first, a reactive security model similar to LN-Penalty. At\n>> pool partition proposals, the owners of the partitioned-up Withdraw\n>> transactions could reveal a revocation secret enabling correction in case\n>> of wrongdoing (e.g single-show signatures). However, such off-chain\n>> revocation can be committed towards multiple sets of honest \"active\" users.\n>> Only one equivocating balance spend can succeed, letting the remaining set\n>> of honest users still be deprived of their expected partitioned balances.\n>>\n>> E.g, let's say you have Alice, Bob, Caroll and Dave as pool participants.\n>> Alice contacts Bob to form a first partition, then Caroll to form a second\n>> one, then Dave to form a last one. If she is successful in that\n>> equivocation trick, she can *triple*-spend her balance against any goods or\n>> out-of-pool payments.\n>>\n>> Assuming the equivocation is discovered once realized, Bob, Caroll and\n>> Dave are all left with a branch of transactions all including Alice's\n>> Withdraw one. However only one branch can be fully published, as a Withdraw\n>> transaction can be played only once following the pool semantic.\n>> Game-theory-wise, Bob, Caroll and Dave have an interest to enter in a fee\n>> race to be the first to confirm and earn the Alice balance spend.\n>>\n>> The equivocation is only bounded by the maximal number of equivocating\n>> sets one can form, namely the number of pool users. However, correction can\n>> only be limited to the equivocated balance. Therefore, it appears that\n>> corrective security models in the context of multi-party are always\n>> producing an economic disequilibrium.\n>>\n>> An extension of this corrective model could be to require off-pool\n>> collaterals locked-up, against which the revocation secret would be\n>> revealed at partition generation. However, this fix is limited to the\n>> collateral liquidity available. One collateral balance should be guaranteed\n>> for each potential victim, thus the collateral liquidity should be equal to\n>> the number of pool users multiplied by the equivocatable balance amount.\n>>\n>> It sounds like a more economic-efficient security model of the pool\n>> partitioning can be established with a prophylactic technique.\n>>\n>> # Trusted coordinator\n>>\n>> A genuine solution could be to rely on a coordinator collecting the\n>> partition declaration and order them canonically. The pool partition\n>> candidates can then fetch them and decide their partitions acceptance\n>> decisions on that. Of course, the coordinator is trusted and can drop or\n>> dissimulate any partition, thus enabling partitioned balance equivocation.\n>>\n>> # Trust-minimized : Partition Statements\n>>\n>> A pool partition invalidity can be defined by the existence of two\n>> second-layer Update transactions at the same state number spending the same\n>> Withdraw transaction balance output. Each Update transaction signature can\n>> be considered as a \"partition statement\". A user wishing to join a\n>> partition should ensure there is no conflicting partition statement before\n>> applying the partition to her local state.\n>>\n>> The open question is from where the conflict should be observed. A\n>> partition statement log could be envisioned and monitored by pool users\n>> before to accept any partition.\n>>\n>> I think multiple partition statement publication spaces can be drawn out,\n>> with different trust-minization trade-offs.\n>>\n>> # Publication space : Distributed Bulletin Boards\n>>\n>> The set of \"active\" pool users could host their own boards of partition\n>> statements. They would coordinate on the statement order through a\n>> consensus algorithm (e.g Raft). For redundancy, a user can have multiple\n>> board instances. If a user falls offline, they can fetch the statement\n>> order from the other users boards.\n>>\n>> However, while this solution distributes the trust across all the other\n>> users, it's not safe in case of malicious user coalitions agreeing among\n>> themselves to drop a partition statement. Therefore, a user catching up\n>> online can be feeded with an incorrect view of the existing partitions, and\n>> thus enter into an equivocated partition.\n>>\n>> # Publication space : On-chain Authoritative Board\n>>\n>> Another solution could be to designate an authoritative UTXO at pool\n>> setup. This UTXO could be spent by any user of the pool set (1-of-N) to a\n>> covenanted transaction sending back to a Taproot output with the same\n>> internal key. The Merkelized tree tweaked could be modified by the spender\n>> to stamp the partition statements as leaves hashes. The statement data is\n>> not committed in the leaves itself and the storage can be delegated to\n>> out-of-band archive servers.\n>>\n>> E.g, let's say you have Alice, Bob, Caroll and Dave as pool participants.\n>> Alice and Bob decide to start a partition, they commit a hash of the\n>> partitioning Update transaction as a Taproot tree leaf and they spend the\n>> pool authoritative UTXO. They also send a copy of the Update transaction to\n>> an archive server.\n>>\n>> At a later time, Alice proposes to Caroll to start a partition. Caroll\n>> follows the chain of transactions forming the on-chain authoritative board,\n>> she fetches the merkle branches and leaves data payload from an archive\n>> server, verifying the authenticity of the branches and payload. As Alice\n>> has already published a partition statement spending her Withdraw, Caroll\n>> should refuse the partition proposal.\n>>\n>> Even if a pool user goes offline, she can recover the correct partition\n>> statement logs, as it has been committed in the chain from the\n>> authoritative UTXO. If the statement data is not available from servers,\n>> the pool user should not engage in partitions.\n>>\n>> Assuming the spend confirms in every block, this solution enables\n>> partitions every 10min. The cost can be shared across pool instances, if\n>> the authoritative signers set is made of multiple pool instances signers\n>> sets. A threshold signature scheme could be used to avoid interactivity\n>> beyond the aggregated key setup. However, batching across pool instances\n>> increases the set of data to verify by the partition candidate users, which\n>> could be a grievance for bandwidth-constrained clients.\n>>\n>> # Fiability of the Publication of Partition Statements\n>>\n>> Whatever ends up being used as a partition statement log, there is still\n>> the question of the incentives of pool users to publish the partition\n>> statements. A malicious user could act in coalition with the equivocating\n>> entity to retain the publication of her partition statement. Thus, an\n>> honest user would only be aware of her own partition statement and accept\n>> the partition proposal from the will-be equivocating entity.\n>>\n>> I think that leveraging covenants a revocation mechanism could be\n>> attached on any equivocating branch of transactions, allowing in the above\n>> case a single honest user to punish the publication. While a revocation\n>> mechanism does not work in case of multiple defrauded users, I believe the\n>> existence of a revocation mechanism makes the formation of malicious\n>> coalitions unsafe for their conjurers.\n>>\n>> Indeed, any user entering in the coalition is not guaranteed to be\n>> blinded to other equivocating branches generated by the partition\n>> initiator. Therefore, the publication of a partition statement by everyone\n>> is holistically optimal to discover any equivocating candidate among the\n>> pool users.\n>>\n>> Further research should establish the soundness of the partition\n>> statement publication game-theory.\n>>\n>> # Writing the Partition Statements to a new Consensus Data Structure\n>>\n>> To avoid a solution relying on game-theory, a new consensus data\n>> structure could be introduced to register and order the partition\n>> statements. This off-chain contract register could be a Merkle tree, where\n>> every leaf is a pool balance identified by a key. This register would be\n>> established on-chain at the same time the pool is set up.\n>>\n>> Every time the pool is partitioned, the tree leaves would be updated with\n>> the partition statement committed to. Only one partition could be\n>> registered per user by state number. The publication branch would be\n>> invalid if it doesn't point back to the corresponding contract register\n>> tree entries. When the first-layer pool Update transaction is replaced, the\n>> tree should transition to a blank state too.\n>>\n>> Beyond the high cost of yet-another softfork to introduce such consensus\n>> data structure, the size of the witness to write into the contract register\n>> could be so significant that the economic attractiveness of pool\n>> partitioning is decreased in consequence.\n>>\n>> If you have read so far, thank you. And curious if anyone has more ideas\n>> or thoughts on  the high interactivity issue ?\n>>\n>> Thanks Gleb for the review.\n>>\n>> Cheers,\n>> Antoine\n>>\n>> [0] https://coinpool.dev/\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220509/b1aa5fee/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-10T16:45:19",
                "message_text_only": "Good morning Billy,\n\n\n> Very interesting exploration. I think you're right that there are issues with the kind of partitioning you're talking about. Lightning works because all participants sign all\u00a0offchain states (barring data loss). If a participant can be excluded from needing to agree to a new state, there must be an additional mechanism to ensure the relevant state for that participant isn't changed to their detriment.\u00a0\n>\n> To summarize my below email, the two techniques I can think for solving this problem are:\n>\n> A. Create sub-pools when the whole group is live that can be used by the sub- pool\u00a0participants later without the whole group's involvement. The whole group is needed to change the whole group's state (eg close or open sub-pools), but sub-pool\u00a0states don't need to involve the whole group.\n\nIs this not just basically channel factories?\n\nTo reduce the disruption if any one pool participant is down, have each sub-pool have only 2 participants each.\nMore participants means that the probability that one of them is offline is higher, so you use the minimum number of participants in the sub-pool: 2.\nThis makes any arbitrary sub-pool more likely to be usable.\n\nBut a 2-participant pool is a channel.\nSo a large multiparticipant pool with sub-pools is just a channel factory for a bunch of channels.\n\nI like this idea because it has good tradeoffs, so channel factories ho.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-05-12T17:36:25",
                "message_text_only": "@Antoine\n>  it's also hard to predict in advance the liquidity needs of the\nsub-pools.\n\nDefinitely. Better than not being able to use the pool at all when\nsomeone's offline tho.\n\n> this fan-out transaction could interfere with the confirmation of the\nsimple withdraw transactions\n> So there is an open question about the \"honest\" usage of the sub-pool\nstates themselves.\n\nI don't follow this one. How would it interfere? How would it call into\nquestion the \"honesty\" of the sub-pools? Why would honesty matter? I would\nassume they can all be structured trustlessly.\n\n> one could envision an accumulator committing directly to balances too\n\nAre you suggesting that there would be some kind of opcode that operates on\nthis accumulator to shift around balances of some participants without\ndisturbing others? Sounds reasonable.\n\n> I think the challenge is to find a compact accumulator with those\nproperties.\n\nThe Merkle Sum Trees like are used in Taro sound like they could probably\nbe useful for that.\n\n> It's more likely a lot of them will delegate this operation to\nthird-party providers, with the known reductions in terms of\ntrust-minimizations.\n\nThere is of course that limitation. But a third party empowered only to\nkeep the pool functioning is much better than one given the ability to\nspend on your behalf without your confirmation. This would be a big\nimprovement despite there still being minor privacy downsides.\n\n> Hmmm, how could you prevent the always-online service from using the\nreceiving-key in \"spending\" mode if the balance stacked there becomes\nrelevant ?\n\nYou mean if your balance in the pool is 1000 sats and the service\nfacilitates receiving 100 sats, that service could then steal those 100\nsats? And you're asking how you could prevent that? Well first of all, if\nyou're in a channel, not only does your service need to want to steal your\nfunds, but your channel partner(s) must also sign for that as well - so\nthey both must be malicious for these funds to be stolen. I can't see a way\nto prevent that, but at least this situation prevents them from stealing\nyour whole 1100 sats, and can only steal 100 sats.\n\n>  see https://gitlab.com/lightning-signer/docs for wip in that direction.\n\nInteresting. I'm glad someone's been working on this kind of thing\n\n> A malicious pool participant could still commit her off-chain balance in\ntwo partitions and send spends to the A&B hosting \"receiving-keys\" entities\nwithout them being aware of the conflict, in the lack of a reconciliation\nsuch as a publication space ?\n\nActually, I was envisioning that the always-online services holding a\nreceive-only key would *all* be online. So all participants of the pool\nwould have a representative, either one with a spending key or with just a\nreceiving-key (which could also be used to simply sign pool state changes\nthat don't negatively affect the balance of the user they represent). So\nthere still would be agreement among all participants on pool state\nchanges.\n\nI kind of think if both techniques (sub-pools and limited-trust services)\nare used, it might be able to substantially increase the ability for a pool\nto operate effectively (ie substantially decrease the average downtime).\n\n@ZmnSCPxj\n> Is this not just basically channel factories?\n\nIt is.\n\n> To reduce the disruption if any one pool participant is down, have each\nsub-pool have only 2 participants each.\n\nYes. But the benefit of the pool over just having individual 2 person\nchannels is that you can change around the structure of the channels within\nthe pool without doing on-chain transactions. As Antoine mentioned, it may\noften not be predictable which 2-person channels would be beneficial in the\nfuture. So you want the pool to be as responsive as possible to the\nchanging needs of the pool.\n\n\n\nOn Tue, May 10, 2022 at 11:45 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Billy,\n>\n>\n> > Very interesting exploration. I think you're right that there are issues\n> with the kind of partitioning you're talking about. Lightning works because\n> all participants sign all offchain states (barring data loss). If a\n> participant can be excluded from needing to agree to a new state, there\n> must be an additional mechanism to ensure the relevant state for that\n> participant isn't changed to their detriment.\n> >\n> > To summarize my below email, the two techniques I can think for solving\n> this problem are:\n> >\n> > A. Create sub-pools when the whole group is live that can be used by the\n> sub- pool participants later without the whole group's involvement. The\n> whole group is needed to change the whole group's state (eg close or open\n> sub-pools), but sub-pool states don't need to involve the whole group.\n>\n> Is this not just basically channel factories?\n>\n> To reduce the disruption if any one pool participant is down, have each\n> sub-pool have only 2 participants each.\n> More participants means that the probability that one of them is offline\n> is higher, so you use the minimum number of participants in the sub-pool: 2.\n> This makes any arbitrary sub-pool more likely to be usable.\n>\n> But a 2-participant pool is a channel.\n> So a large multiparticipant pool with sub-pools is just a channel factory\n> for a bunch of channels.\n>\n> I like this idea because it has good tradeoffs, so channel factories ho.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220512/940da85e/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Conjectures on solving the high interactivity issue in payment pools and channel factories",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Billy Tetrud",
                "Antoine Riard"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 61260
        }
    },
    {
        "title": "[bitcoin-dev] Multiple ways to do bitcoin covenants",
        "thread_messages": [
            {
                "author": "Billy Tetrud",
                "date": "2022-05-01T23:02:55",
                "message_text_only": "I've been thinking about writing something about covenant proposals from\nthe viewpoint of wallet vaults specifically (mostly because that's the use\ncase I care most about).\n\nCTV is basically the minimal covenant opcode you can do that doesn't have\nmalleability. Everything else either introduces malleability, infinite\nrecursion, or has interactions with other proposed opcodes that could\nintroduce potentially undesirable effects like those.\n\nTXHASH+CSFS seems like on its own might enable pretty much\nidentical capabilities to CTV (including no malleability). But it can also\ndo other things (mostly because CSFS can do other things), which isn't\nnecessarily a bad thing, but its more stuff to be analyzed. TXHASH+CSFS in\nterms of wallet vaults seems to provide no benefits over CTV as far as I\ncan imagine.\n\nIt seems pretty clear that anything involving OP_CAT is out for the time\nbeing. There are so many things it can enable that it seems most people\naren't comfortable adding it at  the moment.\n\nAPO wallet vaults seem rather hacky, inefficient, and limited. Certainly\nnot easy to reason about. But this is somewhat a function of my limited\nunderstanding of them. Its not clear to me if anyone is actually suggesting\nthat we should use APO for covenants, but it doesn't feel like the right\napproach.\n\nTLUV + IN_OUT_AMOUNT can do infinitely recursive covenants. IN_OUT_AMOUNT\nwasn't very clearly specified that I know of, but its not a very robust way\nof ensuring the correct amount goes where you want. If TLUV requires a\nsingle input and a single output, IN_OUT_AMOUNT makes sense because you can\nsimply do opcode math to determine if the output is receiving enough coins\n(and not eg being all lost as fees). Maybe it could be extended to allow\nmultiple outputs, but extending it to allow for multiple inputs would be\ndifficult and you'd probably want a completely different mechanism for\nthat. If you're doing any math the script itself around amounts and fees,\nthis doesn't work well in any scenario where multiple inputs might send to\nthe same address, or be combined into the same output, since each input's\nscript can't interact.\n\nBut since TLUV at its most basic should be able to say \"remove the only\ntapleaf in this tree and replace it with this other tap tree\", it should be\nable to do pretty arbitrary covenants. It ideally should be paired up with\nsomething that has better control over how input amounts flow to outputs\nthan IN_OUT_AMOUNT allows (see the design considerations here\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/bip-constraindestination.md>).\n\n\nTLUV is built for evictions, but it seems its likely not really very good\nat that, as Zman mentioned in his post about OP_EVICT\n<https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-February/019926.html>\n(which is a covenant opcode that can't be used for wallet vaults, tho\nperhaps its characteristics can be used in a kind of TLUV2 opcode that does\nevictions better, but also can add tapleaves).\n\nOP_CHECKOUTPUTVERIFY <https://fc16.ifca.ai/bitcoin/papers/MES16.pdf> is\nanother interesting one. Also has a form that allows recursive covenants.\nIt also has similar awkwardness as TLUV + IN_OUT_AMOUNT around multi-input\ntransactions. It has the half-spend problem if two outputs are combined\nthat specify the same output index and script pattern. It also seems like a\nrather expensive opcode to use beyond very simple covenants, since the\nscripts basically has to be duplicated in the transaction specifying the\ncovenant and then again when the subsequent transaction is spent. Its not\nvery taproot friendly either: would you have to specify the entire taproot\nscript tree? Any similar opcode that requires specifying the exact\nscript(s) fundamentally can't take advantage taproot's ability to keep\nscripts private until that spend path is actually used.\n\nAs far as I can tell, few of these other covenant opcodes have even been\nconcretely specified, let alone analyzed enough to know whether they're\nworth pursuing. It seems like all but CTV (potentially TXHASH+CSFS) have\nsignificant flaws and would need reworking in order to fix them.\n\nI guess in short, I agree with you. Over these other ideas that have gotten\nsignificant attention, none really seem to be of high enough quality to be\nput into bitcoin in their current state.\n\n\n\n\nOn Thu, Apr 28, 2022 at 3:47 AM alicexbt via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> CTV and other covenant proposals, tradeoffs, and overlapping features are\n> among the topics being explored recently. I had some views and questions on\n> this subject.:\n>\n> a) Does bitcoin already have opcodes with overlapping features? Yes\n>\n> b) Can we have multiple ways with some overlapping features to do bitcoin\n> covenants with some tradeoffs? Yes\n> _\n> c) What are these tradeoffs if we compare CTV, APO, TLUV and TXHASH+CSFS?\n>\n> I am sure about a) because it was already answered in CTV chat by Jeremy\n> and sheshek. Example: CHECKSIG and CHECKSIGADD is redundant with OP_IF and\n> OP_ADD\n>\n> Not sure if we have \"consensus\" on b) but I don't see anything wrong with\n> it.\n>\n> For c) I would prefer CTV because:\n>\n> - Simpler\n> - Blockspace effient\n> - Can be used even without taproot\n>\n> Covering bare script, as in segwit v0, is necessary. Exposing a pubkey in\n> case of an EC break will be a disaster, and vaults imply very long lived\n> storage. Root CA offline certificates can often have shelf life measured in\n> decades. However, NSA has issued warnings, NIST has issued guidelines, and\n> executive order to prepare for the quantum shift. As a result, forcing\n> everyone into a quantum-unsafe position is unsustainable.\n>\n> Other developers might use a different way to do bitcoin covenant for\n> other reasons. Example: Russel O'Connor would prefer general OP_TXHASH\n> design\n>\n> /dev/fd0\n>\n> Sent with ProtonMail <https://protonmail.com/> secure email.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220501/84cd21d4/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Multiple ways to do bitcoin covenants",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Billy Tetrud"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 6307
        }
    },
    {
        "title": "[bitcoin-dev] Working Towards Consensus",
        "thread_messages": [
            {
                "author": "Jeremy Rubin",
                "date": "2022-05-02T02:43:29",
                "message_text_only": "Developers,\n\nThere is much to say about the events of the last two weeks and the\nresponse to them. I've been searching for the right words to share here,\nbut I think it best that short of a more thoughtful writeup I start with a\ntimely small step with the below comments.\n\nFirst, let me be clear: I am not advancing a Speedy Trial(ST) activation of\nBitcoin Improvement Proposal-119 (BIP-119) CheckTemplateVerify (CTV) at\nthis time.\n\nI'm skipping any discussion of the drama here. Most of you are interested\nin developing Bitcoin, not drama. Let's try to keep this thread focused on\nthe actual work. I'll make some limited comments on the drama in a separate\nthread, for those who care to hear from me on the subject directly.\n\nI believe that the disinformation spread around my post (\"7 Theses on a\nnext step for BIP-119\"[0]) created three main negative outcomes within the\nBitcoin community:\n\n1. Confusion about how Bitcoin's \"technical consensus\" works and how\nchanges are \"approved\".\n2. Fear about the safety of CTV and covenants more broadly.\n3. Misunderstandings around the properties of Speedy Trial, User Activated\nSoft Fork (UASF), User Resisted Soft Fork (URSF), Soft Forks, Hard Forks,\nand more.\n\nWhile I cannot take responsibility for the spread of the disinformation, I\ndo apologize to anyone dealing with it for the role my actions have had in\nleading to the current circumstance.\n\nI personally take some solace in knowing that the only way out of this is\nthrough it. The conversations happening now seem to have been more or less\ninevitable, this has brought them to the surface, and as a technical\ncommunity we are able to address them head on if -- as individuals and\ncollectively -- we choose to. And, viewed through a certain lens, these\nconversations represent incredibly important opportunities to participate\nin defining the future of Bitcoin that would not be happening otherwise.\nUltimately, I am grateful to live in a time where I am able to play a small\nrole in such an important process. This is the work.\n\nIn the coming months, I expect the discourse to be messy, but I think the\nwork is clear cut that we should undertake at least the following:\n\n1. Make great efforts to better document how Bitcoin's technical consensus\nprocess works today, how it can be improved, and how changes may be\nformally reviewed while still being unofficially advanced.\n2. Work diligently to address the concerns many in the community have\naround the negative potential of covenants and better explain the\ntrade-offs between levels of functionality.\n3. Renew conversations about activation and release mechanisms and\nre-examine our priors around why Speedy Trial may have been acceptable for\nTaproot, was not acceptable for BIP-119, but may not be optimal long\nterm[1], and work towards processes that better captures the Bitcoin\nnetwork's diverse interests and requirements.\n4. Work towards thoroughly systematizing knowledge around covenant\ntechnologies so that in the coming months we may work towards delivering a\ncoherent pathway for the Bitcoin technical community to evaluate and put up\nfor offer to the broader community an upgrade or set of upgrades to improve\nBitcoin's capabilities for self sovereignty, privacy, scalability, and\ndecentralization.\n\nThis may not be the easiest path to take, but I believe that this work is\ncritical to the future of Bitcoin. I welcome all reading this to share your\nthoughts with this list on how we might work towards consensus going\nforward, including any criticisms of my observations and recommendations\nabove. While I would expect nothing less than passionate debate when it\ncomes to Bitcoin, remember that at the end of the day we all largely share\na mission to make the world a freer place, even if we disagree about how we\nget there.\n\nYours truly,\n\nJeremy\n\n[0]: https://rubin.io/bitcoin/2022/04/17/next-steps-bip119/\n[1]: http://r6.ca/blog/20210615T191422Z.html I quite enjoyed Roconnor's\ndetailed post on Speedy Trial\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220501/9009e65d/attachment-0001.html>"
            },
            {
                "author": "John Carvalho",
                "date": "2022-05-02T08:37:29",
                "message_text_only": "Jeremy,\n\nThe path to consensus is to propose things that everyone needs. Demand\ncomes from the market, not the designers.\n\nDesigners (engineers) solve problems with designs, but when they speculate\nand lead the process, they create problems instead. Bitcoin is not a place\nfor speculative feature additions. Bitcoin cannot afford a culture of\nadditive features no one is asking for. Bitcoin thrives in a culture of\n\"NO.\" Rejection of change is Bitcoin's primary feature.\n\nThere is NO HOPE of EVER getting the majority of Bitcoin users to be able\nto grasp, audit, and meaningfully consent to complicated new features, nor\nto assess how they may interact with existing features in undesirable ways\nor affect Bitcoin's incentive structure. To ignore this is a selfish\negomania that too many devs succumb to. The public already trusts Core devs\nmore than they probably should, and it is unwise to lean on that trust.\n\nYou are of course welcome to try and research and document all of the\ndetails about how this plays out in practice, but you will fail to specify\na path to approval or any sort of clear governance structure for ensuring\nthat speculative features get into Bitcoin. You will seek and only see a\nbias that allows you to get what YOU want. Until you focus on what everyone\nwants, you will not reach consensus on anything.\n\nBitcoin changes should solve obvious problems and provide easy wins on\noptimization, security, and privacy. Seek simplicity and efficiency, not\ncomplication.\n\nWe have yet to saturate usage of the features we have added already in the\npast 5 years. Use those. It is becoming apparent over time that many\nfeatures can be accomplished off-chain, or without a blockchain, or by\nmerely anchoring into currently available bitcoin transaction types.\n\nThere is simply no urgency or problem that any of the proposed soft fork\nfeatures are trying to address. This includes APO, CTV, sidechain\nproposals, etc, etc.\n\nYour aggression to your purpose is the antithesis of consensus, as it\nindicates your incentives are external to it.\n\n--\nJohn Carvalho\nCEO, Synonym.to <http://synonym.to/>\n\n\nOn Mon, May 2, 2022 at 3:43 AM <\nbitcoin-dev-request at lists.linuxfoundation.org> wrote:\n\n> Send bitcoin-dev mailing list submissions to\n>         bitcoin-dev at lists.linuxfoundation.org\n>\n> To subscribe or unsubscribe via the World Wide Web, visit\n>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> or, via email, send a message with subject or body 'help' to\n>         bitcoin-dev-request at lists.linuxfoundation.org\n>\n> You can reach the person managing the list at\n>         bitcoin-dev-owner at lists.linuxfoundation.org\n>\n> When replying, please edit your Subject line so it is more specific\n> than \"Re: Contents of bitcoin-dev digest...\"\n>\n>\n> Today's Topics:\n>\n>    1. Re: What to do when contentious soft fork activations are\n>       attempted (Billy Tetrud)\n>    2. Working Towards Consensus (Jeremy Rubin)\n>\n>\n> ----------------------------------------------------------------------\n>\n> Message: 1\n> Date: Sun, 1 May 2022 14:14:29 -0500\n> From: Billy Tetrud <billy.tetrud at gmail.com>\n> To: alicexbt <alicexbt at protonmail.com>,  Bitcoin Protocol Discussion\n>         <bitcoin-dev at lists.linuxfoundation.org>\n> Subject: Re: [bitcoin-dev] What to do when contentious soft fork\n>         activations are attempted\n> Message-ID:\n>         <\n> CAGpPWDb-T4OB0NKv7O5k9yhDQJtmag1QLqM1jJN9fQMoNTPLug at mail.gmail.com>\n> Content-Type: text/plain; charset=\"utf-8\"\n>\n> +1 alicexbt\n>\n> We of course want knowledgeable bitcoiners who aren't knowledgeable about a\n> certain proposal to be skeptical. But what we don't want is for that\n> natural skepticism-from-ignorance to be interpreted as opposition, or\n> really a strong signal of any kind. Any thoughts from ignorance, whether\n> self-aware or not, should be given small weight. It seems the vast majority\n> of push back has been this kind of skepticism from ignorance. And to a\n> certain degree I think we want to give time for understanding to those who\n> have not participated in the first, second, third, etc round of discussion\n> on a proposal. It may not be reasonable to say \"you had the last 2 years of\n> time to voice your concern\".\n>\n> Now that CTV is being taken seriously as a proposal, we probably should\n> give the community who is finally taking a serious look at it time to\n> understand, get their questions answered, and come to terms with it. This\n> is not to say that CTV as a technology or proposal has been rushed, or has\n> not had enough work put into it, but rather that the community as a whole\n> has not paid enough attention to it for long enough.\n>\n> The wrong approach is: \"how do I yell more loudly next time I see something\n> I'm uncomfortable with?\" The right approach is to educate those who aren't\n> educated on the proposal and gather consensus on what people think when\n> they understand enough about it to contribute to that consensus. If you\n> care about consensus, you should respect the consensus process and be ok\n> with consensus being not your preferred outcome. If you don't care about\n> consensus, then you're basically attacking the bitcoin community.\n>\n> On Sun, May 1, 2022 at 3:22 AM alicexbt via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> > Hi Michael,\n> >\n> > Maybe the whole thing worked as designed. Some users identified what was\n> > going on, well known Bitcoin educators such as Andreas Antonopoulos,\n> Jimmy\n> > Song etc brought additional attention to the dangers, a URSF movement\n> > started to gain momentum and those attempting a contentious soft fork\n> > activation backed off. (Disappointingly Bitcoin Optech didn't cover my\n> > previous posts to this mailing list 1\n> > <\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-October/019535.html\n> >,\n> > 2\n> > <\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019728.html\n> >,\n> > 3\n> > <\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020235.html\n> >\n> > highlighting the dangers many months ago or recent posts. Normally Optech\n> > is very high signal.)\n> >\n> >\n> > Some users have been misled and there is nothing great being achieved by\n> > doing this on social media. Andreas is clueless about BIP 119 and other\n> > covenant proposals. He is spreading misinformation and some of the URSF\n> > enthusiasts do not understand what are they even opposing or going to run\n> > with risks involved.\n> >\n> >\n> > Answering the subject of this email: \"What to do when contentious soft\n> > forks activations are attempted?\"\n> >\n> > - Do not consider something contentious because someone said it on\n> mailing\n> > list\n> > - Do not spread misinformation\n> > - Read all posts in detail with different opinions\n> > - Avoid personal attacks\n> > - Look at the technical details, code etc. and comment on things that\n> > could be improved\n> >\n> >\n> >\n> > /dev/fd0\n> >\n> > Sent with ProtonMail <https://protonmail.com/> secure email.\n> >\n> > ------- Original Message -------\n> > On Saturday, April 30th, 2022 at 3:23 PM, Michael Folkson via bitcoin-dev\n> > bitcoin-dev at lists.linuxfoundation.org wrote:\n> >\n> >\n> > I?ve been in two minds on whether to completely move on to other topics\n> or\n> > to formulate some thoughts on the recent attempt to activate a\n> contentious\n> > soft fork. In the interests of those of us who have wasted\n> > days/weeks/months of our time on this (with no personal upside) and who\n> > don?t want to repeat this exercise again I thought I should at least\n> raise\n> > the issue for discussion of what should be done differently if this is\n> > tried again in future.\n> >\n> > This could be Jeremy with OP_CTV at a later point (assuming it is still\n> > contentious) or anyone who wants to pick up a single opcode that is not\n> yet\n> > activated on Bitcoin and try to get miners to signal for it bypassing\n> > technical concerns from many developers, bypassing Bitcoin Core and\n> > bypassing users.\n> >\n> > Maybe the whole thing worked as designed. Some users identified what was\n> > going on, well known Bitcoin educators such as Andreas Antonopoulos,\n> Jimmy\n> > Song etc brought additional attention to the dangers, a URSF movement\n> > started to gain momentum and those attempting a contentious soft fork\n> > activation backed off. (Disappointingly Bitcoin Optech didn't cover my\n> > previous posts to this mailing list 1\n> > <\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-October/019535.html\n> >,\n> > 2\n> > <\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019728.html\n> >,\n> > 3\n> > <\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020235.html\n> >\n> > highlighting the dangers many months ago or recent posts. Normally Optech\n> > is very high signal.)\n> >\n> > Alternatively this was the first time a contentious soft fork activation\n> > was attempted, we were all woefully unprepared for it and none of us knew\n> > what we were doing.\n> >\n> > I?m unsure on the above. I?d be interested to hear thoughts. What I am\n> > sure of is that it is totally unacceptable for one individual to bring\n> the\n> > entire Bitcoin network to the brink of a chain split. There has to be a\n> > personal cost to that individual dissuading them from trying it again\n> > otherwise they?re motivated to try it again every week/month. Perhaps the\n> > personal cost that the community is now prepared if that individual tries\n> > it again is sufficient. I?m not sure. Obviously Bitcoin is a\n> permissionless\n> > network, Bitcoin Core and other open source projects are easily forked\n> and\n> > no authority (I?m certainly no authority) can stop things like this\n> > happening again.\n> >\n> > I?ll follow the responses if people have thoughts (I won't be responding\n> > to the instigators of this contentious soft fork activation attempt) but\n> > other than that I?d like to move on to other things than contentious soft\n> > fork activations. Thanks to those who have expressed concerns publicly\n> (too\n> > many to name, Bob McElrath was often wording arguments better than I\n> could)\n> > and who were willing to engage with the URSF conversation. If an\n> individual\n> > can go directly to miners to get soft forks activated bypassing technical\n> > concerns from many developers, bypassing Bitcoin Core and bypassing users\n> > Bitcoin is fundamentally broken. The reason I still have hope that it\n> isn't\n> > is that during a period of general apathy some people were willing to\n> stand\n> > up and actively resist it.\n> >\n> > --\n> > Michael Folkson\n> > Email: michaelfolkson at protonmail.com\n> > Keybase: michaelfolkson\n> > PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n> -------------- next part --------------\n> An HTML attachment was scrubbed...\n> URL: <\n> http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220501/7158d8ed/attachment-0001.html\n> >\n>\n> ------------------------------\n>\n> Message: 2\n> Date: Sun, 1 May 2022 19:43:29 -0700\n> From: Jeremy Rubin <jeremy.l.rubin at gmail.com>\n> To: Bitcoin development mailing list\n>         <bitcoin-dev at lists.linuxfoundation.org>\n> Subject: [bitcoin-dev] Working Towards Consensus\n> Message-ID:\n>         <CAD5xwhhdEgADWwLwbjRKp-UFCw9hHjDsc-L=pkiwW=\n> bmhFqBNw at mail.gmail.com>\n> Content-Type: text/plain; charset=\"utf-8\"\n>\n> Developers,\n>\n> There is much to say about the events of the last two weeks and the\n> response to them. I've been searching for the right words to share here,\n> but I think it best that short of a more thoughtful writeup I start with a\n> timely small step with the below comments.\n>\n> First, let me be clear: I am not advancing a Speedy Trial(ST) activation of\n> Bitcoin Improvement Proposal-119 (BIP-119) CheckTemplateVerify (CTV) at\n> this time.\n>\n> I'm skipping any discussion of the drama here. Most of you are interested\n> in developing Bitcoin, not drama. Let's try to keep this thread focused on\n> the actual work. I'll make some limited comments on the drama in a separate\n> thread, for those who care to hear from me on the subject directly.\n>\n> I believe that the disinformation spread around my post (\"7 Theses on a\n> next step for BIP-119\"[0]) created three main negative outcomes within the\n> Bitcoin community:\n>\n> 1. Confusion about how Bitcoin's \"technical consensus\" works and how\n> changes are \"approved\".\n> 2. Fear about the safety of CTV and covenants more broadly.\n> 3. Misunderstandings around the properties of Speedy Trial, User Activated\n> Soft Fork (UASF), User Resisted Soft Fork (URSF), Soft Forks, Hard Forks,\n> and more.\n>\n> While I cannot take responsibility for the spread of the disinformation, I\n> do apologize to anyone dealing with it for the role my actions have had in\n> leading to the current circumstance.\n>\n> I personally take some solace in knowing that the only way out of this is\n> through it. The conversations happening now seem to have been more or less\n> inevitable, this has brought them to the surface, and as a technical\n> community we are able to address them head on if -- as individuals and\n> collectively -- we choose to. And, viewed through a certain lens, these\n> conversations represent incredibly important opportunities to participate\n> in defining the future of Bitcoin that would not be happening otherwise.\n> Ultimately, I am grateful to live in a time where I am able to play a small\n> role in such an important process. This is the work.\n>\n> In the coming months, I expect the discourse to be messy, but I think the\n> work is clear cut that we should undertake at least the following:\n>\n> 1. Make great efforts to better document how Bitcoin's technical consensus\n> process works today, how it can be improved, and how changes may be\n> formally reviewed while still being unofficially advanced.\n> 2. Work diligently to address the concerns many in the community have\n> around the negative potential of covenants and better explain the\n> trade-offs between levels of functionality.\n> 3. Renew conversations about activation and release mechanisms and\n> re-examine our priors around why Speedy Trial may have been acceptable for\n> Taproot, was not acceptable for BIP-119, but may not be optimal long\n> term[1], and work towards processes that better captures the Bitcoin\n> network's diverse interests and requirements.\n> 4. Work towards thoroughly systematizing knowledge around covenant\n> technologies so that in the coming months we may work towards delivering a\n> coherent pathway for the Bitcoin technical community to evaluate and put up\n> for offer to the broader community an upgrade or set of upgrades to improve\n> Bitcoin's capabilities for self sovereignty, privacy, scalability, and\n> decentralization.\n>\n> This may not be the easiest path to take, but I believe that this work is\n> critical to the future of Bitcoin. I welcome all reading this to share your\n> thoughts with this list on how we might work towards consensus going\n> forward, including any criticisms of my observations and recommendations\n> above. While I would expect nothing less than passionate debate when it\n> comes to Bitcoin, remember that at the end of the day we all largely share\n> a mission to make the world a freer place, even if we disagree about how we\n> get there.\n>\n> Yours truly,\n>\n> Jeremy\n>\n> [0]: https://rubin.io/bitcoin/2022/04/17/next-steps-bip119/\n> [1]: http://r6.ca/blog/20210615T191422Z.html I quite enjoyed Roconnor's\n> detailed post on Speedy Trial\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> -------------- next part --------------\n> An HTML attachment was scrubbed...\n> URL: <\n> http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220501/9009e65d/attachment.html\n> >\n>\n> ------------------------------\n>\n> Subject: Digest Footer\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n> ------------------------------\n>\n> End of bitcoin-dev Digest, Vol 84, Issue 4\n> ******************************************\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220502/82f69955/attachment-0001.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-05-03T00:04:45",
                "message_text_only": "John,\n\n> The path to consensus is to propose things that everyone needs.\n\nIf there's an insight here, it isn't clear what it is to me. As stated,\nthis is something I can only 100% disagree with. Its possible that\nliterally nothing about bitcoin is something that \"everyone needs\". Its\npretty clear that not \"everyone needs\" taproot. Its even questionable\nwhether \"everyone needs\" bitcoin. Are you really saying that no change\nshould be added to bitcoin unless it is something literally all bitcoin\nusers are currently asking for, or maybe just will want to use sometime\nsoon? The majority of bitcoin users don't even custody their own funds, so\npractically all features are something those users aren't using. If you\nwant to convince people of whatever argument you're making, you're going to\nhave to get a little more specific and rather less hyperbolic.\n\n> Designers (engineers) solve problems with designs, but when they\nspeculate and lead the process, they create problems instead.\n\nHow do you expect any improvement to ever happen to bitcoin if designers\ncan't design things unless end-users have asked for it. Every good product\ndesigner knows that users do not know how to design products. Users have\nproblems, designers create solutions. Companies that have implemented\nfeatures that users directly ask for end up with awful bloated confusing\nproducts. Surely this isn't what you're suggesting we do in bitcoin, right?\n\n> Seek simplicity and efficiency, not complication.\n\nThis is an extraordinarily ironic thing to say to Jeremy Rubin, who\ndesigned CTV with exactly that in mind. It is an incredibly simple opcode\nthat doesn't allow recursive covenants or various other things that people\nhave been worried about in the past about covenants. I'm 99% confident that\nthere is no simpler, more efficient, and less complicated covenant opcode\nthan CTV that can even possibly be designed. The only one on par is\nTXHASH+CSFS and that has more complex implications than CTV.\n\nThere are MANY people out there that would like more complex, more powerful\ncovenants. \"The market\" is  in fact demanding it. And yet because we must\nmove carefully in Bitcoin, CTV is a compromise that focuses on simplicity\nand incremental change rather than radical change.\n\nDo you really disagree that CTV was intended to be as simple as possible\nand achieves that goal?\n\n> There is simply no urgency or problem that any of the proposed soft fork\nfeatures are trying to address.\n\nThat is pretty subjective, and very debatable. But ignoring the\ndebatableness of it, why is urgency even necessary for an improvement to\nbitcoin? Should we wait until a problem is urgent to fix it? Or should we\nget ahead of it so we don't risk making hasty mistakes?\n\n> Your aggression to your purpose is the antithesis of consensus, as it\nindicates your incentives are external to it.\n\nThis is a personal attack John, and there have been too many of those\nlately. This is a completely unacceptable thing to say on this mailing\nlist. I ask that you take your words back and apologize. Please be more\nobjective and temper your strong emotions.\n\nYou know what is antithetical to consensus? People throwing around personal\nattacks, asserting that consensus is something without evidence, and\nfailing to acknowledge the many opinions out there that are different from\ntheirs. You write your email as if there's only one person in this world\nwho wants CTV. You know this isn't the case.\n\n\nOn Mon, May 2, 2022 at 3:56 AM John Carvalho via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Jeremy,\n>\n> The path to consensus is to propose things that everyone needs. Demand\n> comes from the market, not the designers.\n>\n> Designers (engineers) solve problems with designs, but when they speculate\n> and lead the process, they create problems instead. Bitcoin is not a place\n> for speculative feature additions. Bitcoin cannot afford a culture of\n> additive features no one is asking for. Bitcoin thrives in a culture of\n> \"NO.\" Rejection of change is Bitcoin's primary feature.\n>\n> There is NO HOPE of EVER getting the majority of Bitcoin users to be able\n> to grasp, audit, and meaningfully consent to complicated new features, nor\n> to assess how they may interact with existing features in undesirable ways\n> or affect Bitcoin's incentive structure. To ignore this is a selfish\n> egomania that too many devs succumb to. The public already trusts Core devs\n> more than they probably should, and it is unwise to lean on that trust.\n>\n> You are of course welcome to try and research and document all of the\n> details about how this plays out in practice, but you will fail to specify\n> a path to approval or any sort of clear governance structure for ensuring\n> that speculative features get into Bitcoin. You will seek and only see a\n> bias that allows you to get what YOU want. Until you focus on what everyone\n> wants, you will not reach consensus on anything.\n>\n> Bitcoin changes should solve obvious problems and provide easy wins on\n> optimization, security, and privacy. Seek simplicity and efficiency, not\n> complication.\n>\n> We have yet to saturate usage of the features we have added already in the\n> past 5 years. Use those. It is becoming apparent over time that many\n> features can be accomplished off-chain, or without a blockchain, or by\n> merely anchoring into currently available bitcoin transaction types.\n>\n> There is simply no urgency or problem that any of the proposed soft fork\n> features are trying to address. This includes APO, CTV, sidechain\n> proposals, etc, etc.\n>\n> Your aggression to your purpose is the antithesis of consensus, as it\n> indicates your incentives are external to it.\n>\n> --\n> John Carvalho\n> CEO, Synonym.to <http://synonym.to/>\n>\n>\n> On Mon, May 2, 2022 at 3:43 AM <\n> bitcoin-dev-request at lists.linuxfoundation.org> wrote:\n>\n>> Send bitcoin-dev mailing list submissions to\n>>         bitcoin-dev at lists.linuxfoundation.org\n>>\n>> To subscribe or unsubscribe via the World Wide Web, visit\n>>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> or, via email, send a message with subject or body 'help' to\n>>         bitcoin-dev-request at lists.linuxfoundation.org\n>>\n>> You can reach the person managing the list at\n>>         bitcoin-dev-owner at lists.linuxfoundation.org\n>>\n>> When replying, please edit your Subject line so it is more specific\n>> than \"Re: Contents of bitcoin-dev digest...\"\n>>\n>>\n>> Today's Topics:\n>>\n>>    1. Re: What to do when contentious soft fork activations are\n>>       attempted (Billy Tetrud)\n>>    2. Working Towards Consensus (Jeremy Rubin)\n>>\n>>\n>> ----------------------------------------------------------------------\n>>\n>> Message: 1\n>> Date: Sun, 1 May 2022 14:14:29 -0500\n>> From: Billy Tetrud <billy.tetrud at gmail.com>\n>> To: alicexbt <alicexbt at protonmail.com>,  Bitcoin Protocol Discussion\n>>         <bitcoin-dev at lists.linuxfoundation.org>\n>> Subject: Re: [bitcoin-dev] What to do when contentious soft fork\n>>         activations are attempted\n>> Message-ID:\n>>         <\n>> CAGpPWDb-T4OB0NKv7O5k9yhDQJtmag1QLqM1jJN9fQMoNTPLug at mail.gmail.com>\n>> Content-Type: text/plain; charset=\"utf-8\"\n>>\n>> +1 alicexbt\n>>\n>> We of course want knowledgeable bitcoiners who aren't knowledgeable about\n>> a\n>> certain proposal to be skeptical. But what we don't want is for that\n>> natural skepticism-from-ignorance to be interpreted as opposition, or\n>> really a strong signal of any kind. Any thoughts from ignorance, whether\n>> self-aware or not, should be given small weight. It seems the vast\n>> majority\n>> of push back has been this kind of skepticism from ignorance. And to a\n>> certain degree I think we want to give time for understanding to those who\n>> have not participated in the first, second, third, etc round of discussion\n>> on a proposal. It may not be reasonable to say \"you had the last 2 years\n>> of\n>> time to voice your concern\".\n>>\n>> Now that CTV is being taken seriously as a proposal, we probably should\n>> give the community who is finally taking a serious look at it time to\n>> understand, get their questions answered, and come to terms with it. This\n>> is not to say that CTV as a technology or proposal has been rushed, or has\n>> not had enough work put into it, but rather that the community as a whole\n>> has not paid enough attention to it for long enough.\n>>\n>> The wrong approach is: \"how do I yell more loudly next time I see\n>> something\n>> I'm uncomfortable with?\" The right approach is to educate those who aren't\n>> educated on the proposal and gather consensus on what people think when\n>> they understand enough about it to contribute to that consensus. If you\n>> care about consensus, you should respect the consensus process and be ok\n>> with consensus being not your preferred outcome. If you don't care about\n>> consensus, then you're basically attacking the bitcoin community.\n>>\n>> On Sun, May 1, 2022 at 3:22 AM alicexbt via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> > Hi Michael,\n>> >\n>> > Maybe the whole thing worked as designed. Some users identified what was\n>> > going on, well known Bitcoin educators such as Andreas Antonopoulos,\n>> Jimmy\n>> > Song etc brought additional attention to the dangers, a URSF movement\n>> > started to gain momentum and those attempting a contentious soft fork\n>> > activation backed off. (Disappointingly Bitcoin Optech didn't cover my\n>> > previous posts to this mailing list 1\n>> > <\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-October/019535.html\n>> >,\n>> > 2\n>> > <\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019728.html\n>> >,\n>> > 3\n>> > <\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020235.html\n>> >\n>> > highlighting the dangers many months ago or recent posts. Normally\n>> Optech\n>> > is very high signal.)\n>> >\n>> >\n>> > Some users have been misled and there is nothing great being achieved by\n>> > doing this on social media. Andreas is clueless about BIP 119 and other\n>> > covenant proposals. He is spreading misinformation and some of the URSF\n>> > enthusiasts do not understand what are they even opposing or going to\n>> run\n>> > with risks involved.\n>> >\n>> >\n>> > Answering the subject of this email: \"What to do when contentious soft\n>> > forks activations are attempted?\"\n>> >\n>> > - Do not consider something contentious because someone said it on\n>> mailing\n>> > list\n>> > - Do not spread misinformation\n>> > - Read all posts in detail with different opinions\n>> > - Avoid personal attacks\n>> > - Look at the technical details, code etc. and comment on things that\n>> > could be improved\n>> >\n>> >\n>> >\n>> > /dev/fd0\n>> >\n>> > Sent with ProtonMail <https://protonmail.com/> secure email.\n>> >\n>> > ------- Original Message -------\n>> > On Saturday, April 30th, 2022 at 3:23 PM, Michael Folkson via\n>> bitcoin-dev\n>> > bitcoin-dev at lists.linuxfoundation.org wrote:\n>> >\n>> >\n>> > I?ve been in two minds on whether to completely move on to other topics\n>> or\n>> > to formulate some thoughts on the recent attempt to activate a\n>> contentious\n>> > soft fork. In the interests of those of us who have wasted\n>> > days/weeks/months of our time on this (with no personal upside) and who\n>> > don?t want to repeat this exercise again I thought I should at least\n>> raise\n>> > the issue for discussion of what should be done differently if this is\n>> > tried again in future.\n>> >\n>> > This could be Jeremy with OP_CTV at a later point (assuming it is still\n>> > contentious) or anyone who wants to pick up a single opcode that is not\n>> yet\n>> > activated on Bitcoin and try to get miners to signal for it bypassing\n>> > technical concerns from many developers, bypassing Bitcoin Core and\n>> > bypassing users.\n>> >\n>> > Maybe the whole thing worked as designed. Some users identified what was\n>> > going on, well known Bitcoin educators such as Andreas Antonopoulos,\n>> Jimmy\n>> > Song etc brought additional attention to the dangers, a URSF movement\n>> > started to gain momentum and those attempting a contentious soft fork\n>> > activation backed off. (Disappointingly Bitcoin Optech didn't cover my\n>> > previous posts to this mailing list 1\n>> > <\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-October/019535.html\n>> >,\n>> > 2\n>> > <\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019728.html\n>> >,\n>> > 3\n>> > <\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020235.html\n>> >\n>> > highlighting the dangers many months ago or recent posts. Normally\n>> Optech\n>> > is very high signal.)\n>> >\n>> > Alternatively this was the first time a contentious soft fork activation\n>> > was attempted, we were all woefully unprepared for it and none of us\n>> knew\n>> > what we were doing.\n>> >\n>> > I?m unsure on the above. I?d be interested to hear thoughts. What I am\n>> > sure of is that it is totally unacceptable for one individual to bring\n>> the\n>> > entire Bitcoin network to the brink of a chain split. There has to be a\n>> > personal cost to that individual dissuading them from trying it again\n>> > otherwise they?re motivated to try it again every week/month. Perhaps\n>> the\n>> > personal cost that the community is now prepared if that individual\n>> tries\n>> > it again is sufficient. I?m not sure. Obviously Bitcoin is a\n>> permissionless\n>> > network, Bitcoin Core and other open source projects are easily forked\n>> and\n>> > no authority (I?m certainly no authority) can stop things like this\n>> > happening again.\n>> >\n>> > I?ll follow the responses if people have thoughts (I won't be responding\n>> > to the instigators of this contentious soft fork activation attempt) but\n>> > other than that I?d like to move on to other things than contentious\n>> soft\n>> > fork activations. Thanks to those who have expressed concerns publicly\n>> (too\n>> > many to name, Bob McElrath was often wording arguments better than I\n>> could)\n>> > and who were willing to engage with the URSF conversation. If an\n>> individual\n>> > can go directly to miners to get soft forks activated bypassing\n>> technical\n>> > concerns from many developers, bypassing Bitcoin Core and bypassing\n>> users\n>> > Bitcoin is fundamentally broken. The reason I still have hope that it\n>> isn't\n>> > is that during a period of general apathy some people were willing to\n>> stand\n>> > up and actively resist it.\n>> >\n>> > --\n>> > Michael Folkson\n>> > Email: michaelfolkson at protonmail.com\n>> > Keybase: michaelfolkson\n>> > PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>> >\n>> > _______________________________________________\n>> > bitcoin-dev mailing list\n>> > bitcoin-dev at lists.linuxfoundation.org\n>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> >\n>> -------------- next part --------------\n>> An HTML attachment was scrubbed...\n>> URL: <\n>> http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220501/7158d8ed/attachment-0001.html\n>> >\n>>\n>> ------------------------------\n>>\n>> Message: 2\n>> Date: Sun, 1 May 2022 19:43:29 -0700\n>> From: Jeremy Rubin <jeremy.l.rubin at gmail.com>\n>> To: Bitcoin development mailing list\n>>         <bitcoin-dev at lists.linuxfoundation.org>\n>> Subject: [bitcoin-dev] Working Towards Consensus\n>> Message-ID:\n>>         <CAD5xwhhdEgADWwLwbjRKp-UFCw9hHjDsc-L=pkiwW=\n>> bmhFqBNw at mail.gmail.com>\n>> Content-Type: text/plain; charset=\"utf-8\"\n>>\n>> Developers,\n>>\n>> There is much to say about the events of the last two weeks and the\n>> response to them. I've been searching for the right words to share here,\n>> but I think it best that short of a more thoughtful writeup I start with a\n>> timely small step with the below comments.\n>>\n>> First, let me be clear: I am not advancing a Speedy Trial(ST) activation\n>> of\n>> Bitcoin Improvement Proposal-119 (BIP-119) CheckTemplateVerify (CTV) at\n>> this time.\n>>\n>> I'm skipping any discussion of the drama here. Most of you are interested\n>> in developing Bitcoin, not drama. Let's try to keep this thread focused on\n>> the actual work. I'll make some limited comments on the drama in a\n>> separate\n>> thread, for those who care to hear from me on the subject directly.\n>>\n>> I believe that the disinformation spread around my post (\"7 Theses on a\n>> next step for BIP-119\"[0]) created three main negative outcomes within the\n>> Bitcoin community:\n>>\n>> 1. Confusion about how Bitcoin's \"technical consensus\" works and how\n>> changes are \"approved\".\n>> 2. Fear about the safety of CTV and covenants more broadly.\n>> 3. Misunderstandings around the properties of Speedy Trial, User Activated\n>> Soft Fork (UASF), User Resisted Soft Fork (URSF), Soft Forks, Hard Forks,\n>> and more.\n>>\n>> While I cannot take responsibility for the spread of the disinformation, I\n>> do apologize to anyone dealing with it for the role my actions have had in\n>> leading to the current circumstance.\n>>\n>> I personally take some solace in knowing that the only way out of this is\n>> through it. The conversations happening now seem to have been more or less\n>> inevitable, this has brought them to the surface, and as a technical\n>> community we are able to address them head on if -- as individuals and\n>> collectively -- we choose to. And, viewed through a certain lens, these\n>> conversations represent incredibly important opportunities to participate\n>> in defining the future of Bitcoin that would not be happening otherwise.\n>> Ultimately, I am grateful to live in a time where I am able to play a\n>> small\n>> role in such an important process. This is the work.\n>>\n>> In the coming months, I expect the discourse to be messy, but I think the\n>> work is clear cut that we should undertake at least the following:\n>>\n>> 1. Make great efforts to better document how Bitcoin's technical consensus\n>> process works today, how it can be improved, and how changes may be\n>> formally reviewed while still being unofficially advanced.\n>> 2. Work diligently to address the concerns many in the community have\n>> around the negative potential of covenants and better explain the\n>> trade-offs between levels of functionality.\n>> 3. Renew conversations about activation and release mechanisms and\n>> re-examine our priors around why Speedy Trial may have been acceptable for\n>> Taproot, was not acceptable for BIP-119, but may not be optimal long\n>> term[1], and work towards processes that better captures the Bitcoin\n>> network's diverse interests and requirements.\n>> 4. Work towards thoroughly systematizing knowledge around covenant\n>> technologies so that in the coming months we may work towards delivering a\n>> coherent pathway for the Bitcoin technical community to evaluate and put\n>> up\n>> for offer to the broader community an upgrade or set of upgrades to\n>> improve\n>> Bitcoin's capabilities for self sovereignty, privacy, scalability, and\n>> decentralization.\n>>\n>> This may not be the easiest path to take, but I believe that this work is\n>> critical to the future of Bitcoin. I welcome all reading this to share\n>> your\n>> thoughts with this list on how we might work towards consensus going\n>> forward, including any criticisms of my observations and recommendations\n>> above. While I would expect nothing less than passionate debate when it\n>> comes to Bitcoin, remember that at the end of the day we all largely share\n>> a mission to make the world a freer place, even if we disagree about how\n>> we\n>> get there.\n>>\n>> Yours truly,\n>>\n>> Jeremy\n>>\n>> [0]: https://rubin.io/bitcoin/2022/04/17/next-steps-bip119/\n>> [1]: http://r6.ca/blog/20210615T191422Z.html I quite enjoyed Roconnor's\n>> detailed post on Speedy Trial\n>>\n>> --\n>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>> -------------- next part --------------\n>> An HTML attachment was scrubbed...\n>> URL: <\n>> http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220501/9009e65d/attachment.html\n>> >\n>>\n>> ------------------------------\n>>\n>> Subject: Digest Footer\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>> ------------------------------\n>>\n>> End of bitcoin-dev Digest, Vol 84, Issue 4\n>> ******************************************\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220502/ee18ad51/attachment-0001.html>"
            },
            {
                "author": "John Carvalho",
                "date": "2022-05-03T05:24:23",
                "message_text_only": ">\n> > The path to consensus is to propose things that everyone needs.\n> If there's an insight here, it isn't clear what it is to me. As stated,\n> this is something I can only 100% disagree with. Its possible that\n> literally nothing about bitcoin is something that \"everyone needs\". Its\n> pretty clear that not \"everyone needs\" taproot. Its even questionable\n> whether \"everyone needs\" bitcoin. Are you really saying that no change\n> should be added to bitcoin unless it is something literally all bitcoin\n> users are currently asking for, or maybe just will want to use sometime\n> soon? The majority of bitcoin users don't even custody their own funds, so\n> practically all features are something those users aren't using. If you\n> want to convince people of whatever argument you're making, you're going to\n> have to get a little more specific and rather less hyperbolic.\n\n\nBilly, the insight is quite simple: it is easier to get everyone to agree\nwhen everyone has something to gain. Taproot getting activated is not proof\nof a sound consensus process, it is proof that most users are either\napathetic or trusting in the developers that initiated it being activated.\nThis is a dangerous dynamic to lean on. I'm not trying to convince anyone\nof anything, I'm trying to provide insight into Bitcoin's dynamics and\nqualities so as to save everyone some time. Take it or leave it, but I'm\nconfident about how things will play out within this model.\n\n> Designers (engineers) solve problems with designs, but when they\n> speculate and lead the process, they create problems instead.\n> How do you expect any improvement to ever happen to bitcoin if designers\n> can't design things unless end-users have asked for it. Every good product\n> designer knows that users do not know how to design products. Users have\n> problems, designers create solutions. Companies that have implemented\n> features that users directly ask for end up with awful bloated confusing\n> products. Surely this isn't what you're suggesting we do in bitcoin, right?\n\n\nI do not \"expect\" improvement by any other means than is typical in life:\ncompetition and adaptation in response to an adverse and changing\nenvironment. Designers can design whatever they please, they just need to\nunderstand the dynamics at play and the risks they are taking in that they\nare likely to waste their own time, and others, if they miss the mark on\nproviding for the greater good. Anyone can be a designer, like anyone can\nbe a Bitcoin user. Engineers are only special if their specialization\nallows them to solve a problem faster than someone else might. Why are you\ntalking about companies and bloat while I am speaking about being\nconservative?\n\n> Seek simplicity and efficiency, not complication.\n> This is an extraordinarily ironic thing to say to Jeremy Rubin, who\n> designed CTV with exactly that in mind. It is an incredibly simple opcode\n> that doesn't allow recursive covenants or various other things that people\n> have been worried about in the past about covenants. I'm 99% confident that\n> there is no simpler, more efficient, and less complicated covenant opcode\n> than CTV that can even possibly be designed. The only one on par is\n> TXHASH+CSFS and that has more complex implications than CTV.\n\n\nNo, you're ironic in thinking that adding complication to Bitcoin's base\nlayer is somehow a means of valuing simplicity. I don't know who you are,\nand since you and Jeremy have no reputation with me, I have no reason to\ncare about your \"99%\" confidence in something that I cannot distinguish\nfrom an attack and have no personal need for. This is how trust and\nincentives work!\n\nThere are MANY people out there that would like more complex, more powerful\n> covenants. \"The market\" is  in fact demanding it. And yet because we must\n> move carefully in Bitcoin, CTV is a compromise that focuses on simplicity\n> and incremental change rather than radical change. Do you really disagree\n> that CTV was intended to be as simple as possible and achieves that goal?\n\n\nSpeaking for myself, and likely the great majority of the market: \"Don't\nknow, don't care.\" Your self-ascribed ability to assess the market is\nobjectively overconfident because we all know there is no way to\nconfidently measure this market by polling or analysis, and that most of\nthis market does not even know CTV exists, and the portion that does know\nof CTV is barely competent enough to audit or bless it. That is just\nreality.\n\n> There is simply no urgency or problem that any of the proposed soft fork\n> features are trying to address.\n> That is pretty subjective, and very debatable. But ignoring the\n> debatableness of it, why is urgency even necessary for an improvement to\n> bitcoin? Should we wait until a problem is urgent to fix it? Or should we\n> get ahead of it so we don't risk making hasty mistakes?\n\n\nWhat is necessary is demand. All forms of scale and complexity come at a\ncost to Bitcoin users. That cost is only offset AFTER the feature has\nreached saturation of usage. Not even Segwit has achieved saturation yet.\nTaproot is dying on the vine so far. This is not a judgment of either\ndesign so much as an observation that we might be too aggressive in our\npace of feature speculation. If we keep piling on features, we have more\nchances of making a mistake, adding technical debt, and abstractly debasing\nusers. Complexity can yield centralization, we should be more careful.\n\n> Your aggression to your purpose is the antithesis of consensus, as it\n> indicates your incentives are external to it.\n> This is a personal attack John, and there have been too many of those\n> lately. This is a completely unacceptable thing to say on this mailing\n> list. I ask that you take your words back and apologize. Please be more\n> objective and temper your strong emotions.\n> You know what is antithetical to consensus? People throwing around\n> personal attacks, asserting that consensus is something without evidence,\n> and failing to acknowledge the many opinions out there that are different\n> from theirs. You write your email as if there's only one person in this\n> world who wants CTV. You know this isn't the case.\n\n\nCry harder. Jeremy is his own champion and my assessment that his\nincentives are external to consensus is based on analyzing the game and\ndynamics at play. It is evident to anyone capable of being objective, and\nyour being offended is not important to this topic. However many people in\nthe world that may want CTV, that number is surely less than 1% of the\nBitcoin user base.\n\n--\nJohn Carvalho\nCEO, Synonym.to <http://synonym.to/>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220503/fefee1ae/attachment.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-05-08T17:36:01",
                "message_text_only": ">  it is easier to get everyone to agree when everyone has something to gain\n\nThat's unquestionably true. It doesn't really sound like what you said\noriginally tho.\n\n> most users are either apathetic or trusting in the developers that\ninitiated it being activated. This is a dangerous dynamic to lean on\n\nI don't disagree.\n\n> I do not \"expect\" improvement by any other means than is typical in life:\ncompetition and adaptation in response to an adverse and changing\nenvironment.\n> Why are you talking about companies and bloat while I am speaking about\nbeing conservative?\n\nSounds like we agree then. However, when you said \"when [designers]\nspeculate and lead the process, they create problems instead\" I took that\nto mean that you think designers shouldn't lead the process. I think\ndesigners and engineers should lead the process, as you said, \"[when] their\nspecialization allows them to solve a problem faster than someone else\nmight.\"\n\n> thinking that adding complication to Bitcoin's base layer is somehow a\nmeans of valuing simplicity\n\nYou seem to be missing my point. I am certainly not saying the words you're\nputting in my mouth there. What I am saying is that a number of people have\nbeen calling covenants for a number of years before Jeremy created CTV, and\nall discussed proposals were more powerful and complex than CTV. I do think\nthat the design of CTV had a goal of simplicity, and I believe it achieved\nthat goal. If CTV were not proposed and developed, we would very likely\nhave seen a more complex covenant opcode on the table. I certainly would\nlike to see a more powerful covenant opcode myself.\n\n> I have no reason to care about your \"99%\" confidence in something\n\nI'm not asking you to care about my confidence. I'm asking to consider my\nlogic. Feel free to take any claims about my confidence as an aside.\n\n> Speaking for myself, and likely the great majority of the market\n\n... are you trying to speak for yourself, or are you trying to assert that\nyour opinion is the market majority opinion? If I may echo your opinion of\nme, I have no reason to care about your confidence that your opinion is\neveryone else's opinion as well. I'll take that as an aside ; )\n\n> Your self-ascribed ability to assess the market is objectively\noverconfident\n\nI'm not the one claiming to speak for the market ^ I'm only relaying the\nfact that the vast majority of folks I see on the dev mailing list who talk\nabout covenants, even occasionally, are in support of them generally, and\nit seems the majority of those people who generally support covenants, if\nnot the vast majority, support CTV. That's what I see. Feel free to not\nbelieve me, but the dev mailing list records are all there for you to\nverify.\n\n> That cost [of a change to bitcoin] is only offset AFTER the feature has\nreached saturation of usage.\n\nI think that's objectively false. Were it true, it would mean that every\nchange can only at best reach break-even, which would mean that no change\nis worth doing.\n\n> we might be too aggressive in our pace of feature speculation\n> If we keep piling on features...\n> Complexity can yield centralization, we should be more careful.\n\nAre you in the \"ossification now\" camp, John? Or perhaps, ossification\nsoon? I agree that the bar of quality should continually be raised for\nmaking changes to bitcoin, and ossification (or as near as possible) should\nbe the eventual goal. Perhaps we just disagree on how quickly to raise the\nbar.\n\n> However many people in the world that may want CTV, that number is surely\nless than 1% of the Bitcoin user base.\n\nI don't disagree that 1% isn't an unlikely number for the fraction of\nbitcoin users who currently want specifically CTV. However, I would guess\nthe percentage of users who hold something close to your opinion isn't much\ndifferent from that number. Measuring things like this as a percentage of\nthe total bitcoin userbase is kind of worthless.\n\n> Cry harder.\n> your being offended is not important to this topic\n\nPerhaps not, but its still no reason to act like an asshole, John. If you\nthink personal attacks, childish jeers, and angry dismissals will be\nconvincing to people who read this mailing list, you're sorely mistaken.\n\n\n\n\nOn Wed, May 4, 2022 at 8:01 AM LORD HIS EXCELLENCY JAMES HRMH <\nwilltech at live.com.au> wrote:\n\n> Good Afternoon,\n>\n> The basic principle of Bitcoin is operating the consensus fungibility. All\n> transactions are published on the public ledger. What is valuable is the\n> consensus as we have it, not what it may become from some proposal that may\n> harm fungibility. Without consensus Bitcoin is not what is valued by the\n> current consensus. Consensus is exactly why Bitcoin is fungible if that can\n> be made clear. That is why it is important to defend consensus.  We have\n> agreed Bitcoin has certain properties including being immutable,\n> transparent, published, distributed, trustless. Consensus provides we make\n> software to allow transfer of Bitcoin via ownership of a UTXO in a manner\n> in accordance with consensus. If we do not value Bitcoin to defend the\n> consensus we admin all kinds of features without purpose to complicate the\n> operation of a wallet for a standard user. Bitcoin and the consensus is all\n> about the standard user in order to be fungible. A valuable use-case does\n> not approve an enhancement. Most users will never be involved in the\n> consensus process and in the interest of  being fungible all developers and\n> the consensus must ensure their interest in a wallet being upgraded is in\n> their beneficial interest. Making a fidget toy that can do anything is not\n> useful until it can make the bed, cook breakfast, and pour the coffee, that\n> is, to do something useful that a user will want.\n>\n> One test of this is how many users will object if a feature is taken away.\n>\n> KING JAMES HRMH\n> Great British Empire\n>\n> Regards,\n> The Australian\n> LORD HIS EXCELLENCY JAMES HRMH (& HMRH)\n> of Hougun Manor & Glencoe & British Empire\n> MR. Damian A. James Williamson\n> Wills\n>\n> et al.\n>\n>\n> Willtech\n> www.willtech.com.au\n> www.go-overt.com\n> and other projects\n>\n> earn.com/willtech\n> linkedin.com/in/damianwilliamson\n>\n>\n> m. 0487135719\n> f. +61261470192\n>\n>\n> This email does not constitute a general advice. Please disregard this\n> email if misdelivered.\n> ------------------------------\n> *From:* bitcoin-dev <bitcoin-dev-bounces at lists.linuxfoundation.org> on\n> behalf of John Carvalho via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org>\n> *Sent:* Monday, 2 May 2022 6:37 PM\n> *To:* bitcoin-dev at lists.linuxfoundation.org <\n> bitcoin-dev at lists.linuxfoundation.org>\n> *Subject:* Re: [bitcoin-dev] Working Towards Consensus\n>\n> Jeremy,\n>\n> The path to consensus is to propose things that everyone needs. Demand\n> comes from the market, not the designers.\n>\n> Designers (engineers) solve problems with designs, but when they speculate\n> and lead the process, they create problems instead. Bitcoin is not a place\n> for speculative feature additions. Bitcoin cannot afford a culture of\n> additive features no one is asking for. Bitcoin thrives in a culture of\n> \"NO.\" Rejection of change is Bitcoin's primary feature.\n>\n> There is NO HOPE of EVER getting the majority of Bitcoin users to be able\n> to grasp, audit, and meaningfully consent to complicated new features, nor\n> to assess how they may interact with existing features in undesirable ways\n> or affect Bitcoin's incentive structure. To ignore this is a selfish\n> egomania that too many devs succumb to. The public already trusts Core devs\n> more than they probably should, and it is unwise to lean on that trust.\n>\n> You are of course welcome to try and research and document all of the\n> details about how this plays out in practice, but you will fail to specify\n> a path to approval or any sort of clear governance structure for ensuring\n> that speculative features get into Bitcoin. You will seek and only see a\n> bias that allows you to get what YOU want. Until you focus on what everyone\n> wants, you will not reach consensus on anything.\n>\n> Bitcoin changes should solve obvious problems and provide easy wins on\n> optimization, security, and privacy. Seek simplicity and efficiency, not\n> complication.\n>\n> We have yet to saturate usage of the features we have added already in the\n> past 5 years. Use those. It is becoming apparent over time that many\n> features can be accomplished off-chain, or without a blockchain, or by\n> merely anchoring into currently available bitcoin transaction types.\n>\n> There is simply no urgency or problem that any of the proposed soft fork\n> features are trying to address. This includes APO, CTV, sidechain\n> proposals, etc, etc.\n>\n> Your aggression to your purpose is the antithesis of consensus, as it\n> indicates your incentives are external to it.\n>\n> --\n> John Carvalho\n> CEO, Synonym.to <http://synonym.to/>\n>\n>\n> On Mon, May 2, 2022 at 3:43 AM <\n> bitcoin-dev-request at lists.linuxfoundation.org> wrote:\n>\n> Send bitcoin-dev mailing list submissions to\n>         bitcoin-dev at lists.linuxfoundation.org\n>\n> To subscribe or unsubscribe via the World Wide Web, visit\n>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> or, via email, send a message with subject or body 'help' to\n>         bitcoin-dev-request at lists.linuxfoundation.org\n>\n> You can reach the person managing the list at\n>         bitcoin-dev-owner at lists.linuxfoundation.org\n>\n> When replying, please edit your Subject line so it is more specific\n> than \"Re: Contents of bitcoin-dev digest...\"\n>\n>\n> Today's Topics:\n>\n>    1. Re: What to do when contentious soft fork activations are\n>       attempted (Billy Tetrud)\n>    2. Working Towards Consensus (Jeremy Rubin)\n>\n>\n> ----------------------------------------------------------------------\n>\n> Message: 1\n> Date: Sun, 1 May 2022 14:14:29 -0500\n> From: Billy Tetrud <billy.tetrud at gmail.com>\n> To: alicexbt <alicexbt at protonmail.com>,  Bitcoin Protocol Discussion\n>         <bitcoin-dev at lists.linuxfoundation.org>\n> Subject: Re: [bitcoin-dev] What to do when contentious soft fork\n>         activations are attempted\n> Message-ID:\n>         <\n> CAGpPWDb-T4OB0NKv7O5k9yhDQJtmag1QLqM1jJN9fQMoNTPLug at mail.gmail.com>\n> Content-Type: text/plain; charset=\"utf-8\"\n>\n> +1 alicexbt\n>\n> We of course want knowledgeable bitcoiners who aren't knowledgeable about a\n> certain proposal to be skeptical. But what we don't want is for that\n> natural skepticism-from-ignorance to be interpreted as opposition, or\n> really a strong signal of any kind. Any thoughts from ignorance, whether\n> self-aware or not, should be given small weight. It seems the vast majority\n> of push back has been this kind of skepticism from ignorance. And to a\n> certain degree I think we want to give time for understanding to those who\n> have not participated in the first, second, third, etc round of discussion\n> on a proposal. It may not be reasonable to say \"you had the last 2 years of\n> time to voice your concern\".\n>\n> Now that CTV is being taken seriously as a proposal, we probably should\n> give the community who is finally taking a serious look at it time to\n> understand, get their questions answered, and come to terms with it. This\n> is not to say that CTV as a technology or proposal has been rushed, or has\n> not had enough work put into it, but rather that the community as a whole\n> has not paid enough attention to it for long enough.\n>\n> The wrong approach is: \"how do I yell more loudly next time I see something\n> I'm uncomfortable with?\" The right approach is to educate those who aren't\n> educated on the proposal and gather consensus on what people think when\n> they understand enough about it to contribute to that consensus. If you\n> care about consensus, you should respect the consensus process and be ok\n> with consensus being not your preferred outcome. If you don't care about\n> consensus, then you're basically attacking the bitcoin community.\n>\n> On Sun, May 1, 2022 at 3:22 AM alicexbt via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> > Hi Michael,\n> >\n> > Maybe the whole thing worked as designed. Some users identified what was\n> > going on, well known Bitcoin educators such as Andreas Antonopoulos,\n> Jimmy\n> > Song etc brought additional attention to the dangers, a URSF movement\n> > started to gain momentum and those attempting a contentious soft fork\n> > activation backed off. (Disappointingly Bitcoin Optech didn't cover my\n> > previous posts to this mailing list 1\n> > <\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-October/019535.html\n> >,\n> > 2\n> > <\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019728.html\n> >,\n> > 3\n> > <\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020235.html\n> >\n> > highlighting the dangers many months ago or recent posts. Normally Optech\n> > is very high signal.)\n> >\n> >\n> > Some users have been misled and there is nothing great being achieved by\n> > doing this on social media. Andreas is clueless about BIP 119 and other\n> > covenant proposals. He is spreading misinformation and some of the URSF\n> > enthusiasts do not understand what are they even opposing or going to run\n> > with risks involved.\n> >\n> >\n> > Answering the subject of this email: \"What to do when contentious soft\n> > forks activations are attempted?\"\n> >\n> > - Do not consider something contentious because someone said it on\n> mailing\n> > list\n> > - Do not spread misinformation\n> > - Read all posts in detail with different opinions\n> > - Avoid personal attacks\n> > - Look at the technical details, code etc. and comment on things that\n> > could be improved\n> >\n> >\n> >\n> > /dev/fd0\n> >\n> > Sent with ProtonMail <https://protonmail.com/> secure email.\n> >\n> > ------- Original Message -------\n> > On Saturday, April 30th, 2022 at 3:23 PM, Michael Folkson via bitcoin-dev\n> > bitcoin-dev at lists.linuxfoundation.org wrote:\n> >\n> >\n> > I?ve been in two minds on whether to completely move on to other topics\n> or\n> > to formulate some thoughts on the recent attempt to activate a\n> contentious\n> > soft fork. In the interests of those of us who have wasted\n> > days/weeks/months of our time on this (with no personal upside) and who\n> > don?t want to repeat this exercise again I thought I should at least\n> raise\n> > the issue for discussion of what should be done differently if this is\n> > tried again in future.\n> >\n> > This could be Jeremy with OP_CTV at a later point (assuming it is still\n> > contentious) or anyone who wants to pick up a single opcode that is not\n> yet\n> > activated on Bitcoin and try to get miners to signal for it bypassing\n> > technical concerns from many developers, bypassing Bitcoin Core and\n> > bypassing users.\n> >\n> > Maybe the whole thing worked as designed. Some users identified what was\n> > going on, well known Bitcoin educators such as Andreas Antonopoulos,\n> Jimmy\n> > Song etc brought additional attention to the dangers, a URSF movement\n> > started to gain momentum and those attempting a contentious soft fork\n> > activation backed off. (Disappointingly Bitcoin Optech didn't cover my\n> > previous posts to this mailing list 1\n> > <\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-October/019535.html\n> >,\n> > 2\n> > <\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019728.html\n> >,\n> > 3\n> > <\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020235.html\n> >\n> > highlighting the dangers many months ago or recent posts. Normally Optech\n> > is very high signal.)\n> >\n> > Alternatively this was the first time a contentious soft fork activation\n> > was attempted, we were all woefully unprepared for it and none of us knew\n> > what we were doing.\n> >\n> > I?m unsure on the above. I?d be interested to hear thoughts. What I am\n> > sure of is that it is totally unacceptable for one individual to bring\n> the\n> > entire Bitcoin network to the brink of a chain split. There has to be a\n> > personal cost to that individual dissuading them from trying it again\n> > otherwise they?re motivated to try it again every week/month. Perhaps the\n> > personal cost that the community is now prepared if that individual tries\n> > it again is sufficient. I?m not sure. Obviously Bitcoin is a\n> permissionless\n> > network, Bitcoin Core and other open source projects are easily forked\n> and\n> > no authority (I?m certainly no authority) can stop things like this\n> > happening again.\n> >\n> > I?ll follow the responses if people have thoughts (I won't be responding\n> > to the instigators of this contentious soft fork activation attempt) but\n> > other than that I?d like to move on to other things than contentious soft\n> > fork activations. Thanks to those who have expressed concerns publicly\n> (too\n> > many to name, Bob McElrath was often wording arguments better than I\n> could)\n> > and who were willing to engage with the URSF conversation. If an\n> individual\n> > can go directly to miners to get soft forks activated bypassing technical\n> > concerns from many developers, bypassing Bitcoin Core and bypassing users\n> > Bitcoin is fundamentally broken. The reason I still have hope that it\n> isn't\n> > is that during a period of general apathy some people were willing to\n> stand\n> > up and actively resist it.\n> >\n> > --\n> > Michael Folkson\n> > Email: michaelfolkson at protonmail.com\n> > Keybase: michaelfolkson\n> > PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n> -------------- next part --------------\n> An HTML attachment was scrubbed...\n> URL: <\n> http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220501/7158d8ed/attachment-0001.html\n> >\n>\n> ------------------------------\n>\n> Message: 2\n> Date: Sun, 1 May 2022 19:43:29 -0700\n> From: Jeremy Rubin <jeremy.l.rubin at gmail.com>\n> To: Bitcoin development mailing list\n>         <bitcoin-dev at lists.linuxfoundation.org>\n> Subject: [bitcoin-dev] Working Towards Consensus\n> Message-ID:\n>         <CAD5xwhhdEgADWwLwbjRKp-UFCw9hHjDsc-L=pkiwW=\n> bmhFqBNw at mail.gmail.com>\n> Content-Type: text/plain; charset=\"utf-8\"\n>\n> Developers,\n>\n> There is much to say about the events of the last two weeks and the\n> response to them. I've been searching for the right words to share here,\n> but I think it best that short of a more thoughtful writeup I start with a\n> timely small step with the below comments.\n>\n> First, let me be clear: I am not advancing a Speedy Trial(ST) activation of\n> Bitcoin Improvement Proposal-119 (BIP-119) CheckTemplateVerify (CTV) at\n> this time.\n>\n> I'm skipping any discussion of the drama here. Most of you are interested\n> in developing Bitcoin, not drama. Let's try to keep this thread focused on\n> the actual work. I'll make some limited comments on the drama in a separate\n> thread, for those who care to hear from me on the subject directly.\n>\n> I believe that the disinformation spread around my post (\"7 Theses on a\n> next step for BIP-119\"[0]) created three main negative outcomes within the\n> Bitcoin community:\n>\n> 1. Confusion about how Bitcoin's \"technical consensus\" works and how\n> changes are \"approved\".\n> 2. Fear about the safety of CTV and covenants more broadly.\n> 3. Misunderstandings around the properties of Speedy Trial, User Activated\n> Soft Fork (UASF), User Resisted Soft Fork (URSF), Soft Forks, Hard Forks,\n> and more.\n>\n> While I cannot take responsibility for the spread of the disinformation, I\n> do apologize to anyone dealing with it for the role my actions have had in\n> leading to the current circumstance.\n>\n> I personally take some solace in knowing that the only way out of this is\n> through it. The conversations happening now seem to have been more or less\n> inevitable, this has brought them to the surface, and as a technical\n> community we are able to address them head on if -- as individuals and\n> collectively -- we choose to. And, viewed through a certain lens, these\n> conversations represent incredibly important opportunities to participate\n> in defining the future of Bitcoin that would not be happening otherwise.\n> Ultimately, I am grateful to live in a time where I am able to play a small\n> role in such an important process. This is the work.\n>\n> In the coming months, I expect the discourse to be messy, but I think the\n> work is clear cut that we should undertake at least the following:\n>\n> 1. Make great efforts to better document how Bitcoin's technical consensus\n> process works today, how it can be improved, and how changes may be\n> formally reviewed while still being unofficially advanced.\n> 2. Work diligently to address the concerns many in the community have\n> around the negative potential of covenants and better explain the\n> trade-offs between levels of functionality.\n> 3. Renew conversations about activation and release mechanisms and\n> re-examine our priors around why Speedy Trial may have been acceptable for\n> Taproot, was not acceptable for BIP-119, but may not be optimal long\n> term[1], and work towards processes that better captures the Bitcoin\n> network's diverse interests and requirements.\n> 4. Work towards thoroughly systematizing knowledge around covenant\n> technologies so that in the coming months we may work towards delivering a\n> coherent pathway for the Bitcoin technical community to evaluate and put up\n> for offer to the broader community an upgrade or set of upgrades to improve\n> Bitcoin's capabilities for self sovereignty, privacy, scalability, and\n> decentralization.\n>\n> This may not be the easiest path to take, but I believe that this work is\n> critical to the future of Bitcoin. I welcome all reading this to share your\n> thoughts with this list on how we might work towards consensus going\n> forward, including any criticisms of my observations and recommendations\n> above. While I would expect nothing less than passionate debate when it\n> comes to Bitcoin, remember that at the end of the day we all largely share\n> a mission to make the world a freer place, even if we disagree about how we\n> get there.\n>\n> Yours truly,\n>\n> Jeremy\n>\n> [0]: https://rubin.io/bitcoin/2022/04/17/next-steps-bip119/\n> [1]: http://r6.ca/blog/20210615T191422Z.html I quite enjoyed Roconnor's\n> detailed post on Speedy Trial\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> -------------- next part --------------\n> An HTML attachment was scrubbed...\n> URL: <\n> http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220501/9009e65d/attachment.html\n> >\n>\n> ------------------------------\n>\n> Subject: Digest Footer\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n> ------------------------------\n>\n> End of bitcoin-dev Digest, Vol 84, Issue 4\n> ******************************************\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220508/76fe3e01/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Working Towards Consensus",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Billy Tetrud",
                "Jeremy Rubin",
                "John Carvalho"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 71440
        }
    },
    {
        "title": "[bitcoin-dev] On The Drama",
        "thread_messages": [
            {
                "author": "Jeremy Rubin",
                "date": "2022-05-02T03:16:58",
                "message_text_only": "Developers,\n\nI know that some of you may be interested in hearing my perspective on what\nhappened and why. I still do not know exactly what happened and why.\nHowever, I can offer a brief explanation of what I perceived my main\nactions to be and the response to them:\n\n1. I published and shared to this list a blog post encouraging review on\nviability of having a Speedy Trial (ST) with signalling beginning around\n3.5 weeks (May 12th), in line with previously communicated materials.\n2. I held a regularly scheduled meeting to discuss the viability of an\nactivation attempt, \"The Agenda for the meeting will be an open discussion\non the possibility of activating CTV[CheckTemplateVerify] in 2022, why we\nmay or may not wish to do that, if we did want to do that what would need\nto be done, what the path might look like if we do not do that.\"\n3. If ST was deemed viable, I provided a pathway for sufficient review to\noccur and I also wrote User Resisted Soft Fork(URSF) software to be used\nsuch that miners are not unilaterally in control, as well as encouragement\nfor someone to author a User Activated Soft Fork(UASF) as a follow up if\nminers \"vetoed\".\n4. If ST was not viable, I gave encouragement to more thoroughly \"re-evaluate\nthe design of CTV against alternatives that would take more time to prepare\nengineering wise (e.g., more general covenants, small tweaks to CTV)\"\n5. I Made clear that CTV activation was \"not a must. All actors must decide\nif it\u2019s in their own rational self-interest to have the soft-fork proceed.\"\n6. I provided a review of rationale for why I thought this to be the right\nnext step for CTV, and for future soft forks to follow.\n\nSince I posted my blog, there have been a flurry of inaccurate claims\nlobbed at me across various platforms that I am trying to route around\nconsensus, force miners to do a ST, force users to accept a patch they\ndon't want, calls for me to face various repercussions, attacks on my\ncharacter, and more. Anyone is free to read the material I actually\ncommunicated myself and evaluate the claims of bad-faith being made. I\naccept responsibility that ultimately I may not have communicated these\nthings clearly enough.\n\nI've kept my word to listen to feedback on parameters before any release:\n\n- I've not released binaries for a ST CTV client in May, and won't be.\n- I've kept my promise not to run a UASF process.\n\nI hope you can believe me that I am not trying to do anything wanton to\nBitcoin. I am trying to do my best to accurately communicate my exact\nintentions and plans along the way, and learn from the ways I fell short.\n\nI cannot thank enough the (majority!) of individuals who understand this\nand have provided overwhelming amounts of personal support to me through\nthese last weeks. While I do not mistake that personal support for support\nof my views, I wanted to share the depth of support and appreciation that\nthe community has for the difficult tasks developers engage in. This isn't\nspecific to me; the community has immense respect for the sacrifices every\ndeveloper makes in choosing to work on Bitcoin. The hate may be loud and\npublic on the shallow surface, but the love and support runs deep.\n\nAt the same time, it has been eye opening for me to see the processes by\nwhich a kernel of disinformation blossoms into a panic across the Bitcoin\ncommunity. For any Bitcoin contributor who might engage in consensus\nprocesses: Agree or disagree with the quality of my actions, it's worth\nspending a little time to trace how the response to my proposal was\ninstigated so that you harden your own defenses against such disinformation\ncampaigns in the future. I encourage you to look closely at what various\n\"respected members of the community\" have lobbied for because they\nrepresent dangerous precedents for all Bitcoin developers. I've yet to\nfully form my thoughts around this.\n\nIf you do not think that my actions lived up with my perception of them,\nfeel free to give me, either publicly or privately, any feedback on how I\ncan do better going forward.\n\nWith respect to this thread, I'll read whatever you send, but I won't be\nreply-all'ing here as I view this as largely off-topic for this list,\nunless anyone feels strongly otherwise.\n\nBest,\n\nJeremy\n\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220501/6aecba60/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "On The Drama",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy Rubin"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4470
        }
    },
    {
        "title": "[bitcoin-dev] [Pre-BIP] Fee Accounts",
        "thread_messages": [
            {
                "author": "Jeremy Rubin",
                "date": "2022-05-02T15:59:49",
                "message_text_only": "Ok, got it. Won't waste anyone's time on terminology pedantism.\n\n\nThe model that I proposed above is simply what *any* correct timestamping\nservice must do. If OTS does not follow that model, then I suspect whatever\nOTS is, is provably incorrect or, in this context, unreliable, even when\nservers and clients are honest. Unreliable might mean different things to\ndifferent people, I'm happy to detail the types of unreliability issue that\narise if you do not conform to the model I presented above (of which,\nlinearizability is one way to address it, there are others that still\nimplement epoch based recommitting that could be conceptually sound without\nrequiring linearizability).\n\nDo you have any formal proof of what guarantees OTS provides against which\nthreat model? This is likely difficult to produce without a formal model of\nwhat OTS is, but perhaps you can give your best shot at producing one and\nwe can carry the conversation on productively from there.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220502/af0d2b92/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Fee Accounts",
            "categories": [
                "bitcoin-dev",
                "Pre-BIP"
            ],
            "authors": [
                "Jeremy Rubin"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1149
        }
    },
    {
        "title": "[bitcoin-dev] CTV Meeting #8 Reminder + Agenda (Tuesday, May 3rd, 12:00 PT / 7PM UTC)",
        "thread_messages": [
            {
                "author": "Jeremy Rubin",
                "date": "2022-05-02T16:24:30",
                "message_text_only": "Developers,\n\nA reminder that the regularly scheduled CTV Meeting is tomorrow at 12:00\nPacific Time in ##ctv-bip-review in Libera.\n\nIn terms of agenda, we'll keep it as an open forum for discussion guided by\nthe participants. Feel free to propose meeting topics in the IRC in advance\nof the meeting to aid in allocating time to things that you would like to\nhave discussed.\n\nBest,\n\nJeremy\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220502/7a4157b6/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "CTV Meeting #8 Reminder + Agenda (Tuesday, May 3rd, 12:00 PT / 7PM UTC)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy Rubin"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 621
        }
    },
    {
        "title": "[bitcoin-dev] Pay to signature hash as a covenant",
        "thread_messages": [
            {
                "author": "vjudeu at gazeta.pl",
                "date": "2022-05-03T07:37:20",
                "message_text_only": "Typical P2PK looks like that: \"<signature> <pubkey> OP_CHECKSIG\". In a typical scenario, we have \"<signature>\" in out input and \"<pubkey> OP_CHECKSIG\" in our output. I wonder if it is possible to use covenants right here and right now, with no consensus changes, just by requiring a specific signature. To start with, I am trying to play with P2PK and legacy signatures, but it may turn out, that doing such things with Schnorr signatures will be more flexible and will allow more use cases.\n\nThe simplest \"pay to signature\" script I can think of is: \"<signature> OP_SWAP OP_CHECKSIG\". Then, any user can provide just a \"<pubkey>\" in some input, as a part of a public key recovery. The problem with such scheme is that it is insecure. Another problem is that we should handle it carefully, because signatures are removed from outputs. However, we could replace it with some signature hash, then it will be untouched, for example: \"OP_TOALTSTACK OP_DUP OP_HASH160 <signatureHash> OP_EQUALVERIFY OP_FROMALTSTACK OP_CHECKSIG\".\n\nAnd then, signatures are more flexible than public keys, because we can use many different sighashes to decide, what kind of transaction is allowed and what should be rejected. Then, if we could use the right signature with correct sighashes, it could be possible to disable key recovery and require some specific public key, then that scheme could be safely used again. I still have no idea, how to complete that puzzle, but it seems to be possible to use that trick, to restrict destination address. Maybe I should wrap such things in some kind of multisig or somehow combine it with OP_CHECKSIGADD, any ideas?"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-03T09:35:31",
                "message_text_only": "Good morning vjudeu,\n\n> Typical P2PK looks like that: \"<signature> <pubkey> OP_CHECKSIG\". In a typical scenario, we have \"<signature>\" in out input and \"<pubkey> OP_CHECKSIG\" in our output. I wonder if it is possible to use covenants right here and right now, with no consensus changes, just by requiring a specific signature. To start with, I am trying to play with P2PK and legacy signatures, but it may turn out, that doing such things with Schnorr signatures will be more flexible and will allow more use cases.\n>\n>\n> The simplest \"pay to signature\" script I can think of is: \"<signature> OP_SWAP OP_CHECKSIG\". Then, any user can provide just a \"<pubkey>\" in some input, as a part of a public key recovery. The problem with such scheme is that it is insecure. Another problem is that we should handle it carefully, because signatures are removed from outputs. However, we could replace it with some signature hash, then it will be untouched, for example: \"OP_TOALTSTACK OP_DUP OP_HASH160 <signatureHash> OP_EQUALVERIFY OP_FROMALTSTACK OP_CHECKSIG\".\n>\n> And then, signatures are more flexible than public keys, because we can use many different sighashes to decide, what kind of transaction is allowed and what should be rejected. Then, if we could use the right signature with correct sighashes, it could be possible to disable key recovery and require some specific public key, then that scheme could be safely used again. I still have no idea, how to complete that puzzle, but it seems to be possible to use that trick, to restrict destination address. Maybe I should wrap such things in some kind of multisig or somehow combine it with OP_CHECKSIGADD, any ideas?\n\nYou can do the same thing with P2SH, P2WSH, and P2TR (in a Tapscript) as well.\n\nNote that it is generally known that you *can* use pre-signed transactions to implement vaults.\nUsually what we refer to by \"covenant\" is something like \"this output will definitely be constructed here\" without necessarily requiring a signature.\n\nHOWEVER, what you are proposing is not ***quite*** pre-signed transactions!\nInstead, you are (ab)using signatures in order to commit to particular sighashes.\n\nFirst, let me point out that you do not need to hash the signature and *then* use a raw `scriptPubKey`, which I should *also* point it is not going to pass `IsStandard` checks (and will not propagate on the mainnet network reliably, only on testnet).\nInstead, you can use P2WSH and *include* the signature outright in the `redeemScript`.\nSince the output `scriptPubKey` is really just the hash of the `redeemScript`, this is automatically a hash of a signature (plus a bunch of other bytes).\n\nSo your proposal boils down to using P2WSH and having a `redeemScript`:\n\n    redeemScript = <fixedSignature> <fixPubKey> OP_CHECKSIG\n\nWhy include the `fixPubKey` in the `redeemScript`?\nIn your scheme, you would provide the signature and pubkey in the `scriptSig` that spends the `scriptPubKey`.\nBut in a post-P2WSH world, `redeemScript` will also be provided in the `witness`, so you *also* provide both the signature and the pubkey, and both are hashed before appearing on the `scriptPubKey` --- which is exactly what you are proposing anyway.\n\nThe above pre-commits to a particular transaction, depending on the `SIGHASH` flags of the `fixedSignature`.\nOf note is that the `fixPubKey` can have a throwaway privkey, or even a ***publicly-shared*** privkey.\nEven if an alternate signature is created from  well-known privkey, the `redeemScript` will not allow any other signature to be accepted, it will only use the one that is hardcoded into the script.\nUsing a publicly-shared privkey would allow us to compute just the expected `sighash`. them derove the `fixedSignature` that should be in the `redeemScript`.\n\nIn particular, this scheme would work just as well for the \"congestion control\" application proposed for `OP_CTV`.\n`OP_CTV` still wins in raw WUs spent (just the 32-WU hash), but in the absence of `OP_CTV` because raisins, this would also work (but you reveal a 33-WU pubkey, and a 73-WU/64-WU signature, which is much larger).\nValidation speed is also better for `OP_CTV`, as it is just a hash, while this scheme uses signature validation in order to commit to a specific hash anyway (a waste of CPU time, since you could just check the hash directly instead of going through the rigmarole of a signature, but one which allows us to make non-recursive covenants with some similarities to `OP_CTV`).\n\nA purported `OP_CHECKSIGHASHVERIFY` which accepts a `SIGHASH` flag and a hash, and checks that the sighash of the transaction (as modified by the flags) is equal to the hash, would be more efficient, and would also not differ by much from `OP_CTV`.\n\nThis can be used in a specific branch of an `OP_IF` to allow, say, a cold privkey to override this branch, to start a vault construction.\n\nThe same technique should work with Tapscripts inside Taproot (but the `fixedPubKey` CANNOT be the same as the internal Taproot key!).\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "AdamISZ",
                "date": "2022-05-21T21:24:39",
                "message_text_only": "Sent with ProtonMail secure email.\n------- Original Message -------\nOn Tuesday, May 3rd, 2022 at 02:37, vjudeu via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n\n> Typical P2PK looks like that: \"<signature> <pubkey> OP_CHECKSIG\". In a typical scenario, we have \"<signature>\" in out input and \"<pubkey> OP_CHECKSIG\" in our output. I wonder if it is possible to use covenants right here and right now, with no consensus changes, just by requiring a specific signature. To start with, I am trying to play with P2PK and legacy signatures, but it may turn out, that doing such things with Schnorr signatures will be more flexible and will allow more use cases.\n>\n>\n> The simplest \"pay to signature\" script I can think of is: \"<signature> OP_SWAP OP_CHECKSIG\". Then, any user can provide just a \"<pubkey>\" in some input, as a part of a public key recovery. The problem with such scheme is that it is insecure. Another problem is that we should handle it carefully, because signatures are removed from outputs. However, we could replace it with some signature hash, then it will be untouched, for example: \"OP_TOALTSTACK OP_DUP OP_HASH160 <signatureHash> OP_EQUALVERIFY OP_FROMALTSTACK OP_CHECKSIG\".\n>\n\nDoesn't this suffer from the standard \"circular reference\" problem for covenants? To pay to a utxo U1, whose scriptpubkey is a (p2wsh wrapped, say) script of: sig, op_checksig, I must create that sig, using my chosen public key, and a message which is a (signature style) hashing of a tx TX1, where an/the input to TX1 is U1, and the txid of U1 'hashes over' that script, which includes the sig we're trying to create. You can't make a hash of data which includes that hash (unless the hash fn is broken ofc).\n\nI don't think that's affected by the later discussion here or in Zmn's response right?\n\nAlso a side detail which you might find useful in these ponderings: pubkey recovery is, as you know, possible in ECDSA but is not possible in BIP340 schnorr (which has key prefixing, i.e. the pubkey is included in the message hash binding, i.e. the e in s = k + ex), but is in the original Schnorr where only R(=kG), m are included in e. Easy to see why: from R, s and e(=H(R,m) .. easy to calculate) you can get P = (sG - R)* e^-1.\nBut in BIP340 Schnorr where (R, s) is published and e (=H(P, R, m)) is not, you cannot reconstruct e and so can only calculate e*P, which by DL assumption does not reveal P. Another way to put it is: if you made up a random R, s you wouldn't be able to find the right 'P' to put into e=H(P, R, m) so that the same P came out, and so that the sig actually verifies.\n\nCheers,\nwaxwing/AdamISZ"
            }
        ],
        "thread_summary": {
            "title": "Pay to signature hash as a covenant",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "vjudeu at gazeta.pl",
                "AdamISZ"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 9279
        }
    },
    {
        "title": "[bitcoin-dev] CoinPool should focus on different sighashes",
        "thread_messages": [
            {
                "author": "vjudeu at gazeta.pl",
                "date": "2022-05-03T09:15:36",
                "message_text_only": "It seems that the current consensus with Taproot is enough to implement CoinPool. There are no needed changes if we want to form a basic version of that protocol, so it probably should be done now (or at least started, even in some signet or testnet3). Later, if some features like SIGHASH_ANYPREVOUT (or the same with ANYSCRIPT) would be added, then it could be improved, just in the same way, as Lightning Network is moving from P2WSH to P2TR.\n\nTo start with, we assume there are six participants that are going to form a CoinPool. They start their journey by moving all of their coins to a 6-of-6 multisig channel. Nothing is signed, first we focus on making transactions, then we will sign them backwards to make it trustless.\n\n+------------------------------------------------+\n| Alice   3.51 -> ABCDEF (6-of-6 multisig) 19.94 |\n| Bob     0.90                                   |\n| Charlie 6.81                                   |\n| Daniel  7.29                                   |\n| Elaine  0.84                                   |\n| Frank   0.60                                   |\n+------------------------------------------------+\n\nThat first transaction is simple, we could sign it later with SIGHASH_ALL. But it seems we can handle it better: what about SIGHASH_ANYONECANPAY? Then, all outputs (so just one) will be signed, but anyone could attach another inputs if needed. Also, the first person could use SIGHASH_SINGLE | SIGHASH_ANYONECANPAY, but it is optional, and I assume we don't need any \"group leader\" or \"coordinator\", so anyone will just use SIGHASH_ANYONECANPAY, they will only switch destination and amount, to form a channel in a P2P way. Channel forming could work in a similar way as mempools in Bitcoin: all messages will fly, until there will be some agreement, and some group will collect all needed signatures. But for now, nothing is signed, so let's go to the next transaction.\n\nTo close that channel, a group should still exist, and just detach some participant. Closing the whole group is not an option, we want to encourage CoinPool formation, so we don't want to continuously open and close the whole channel. Let's assume that Alice wants to leave. That means, we should get a group of five participants and Alice, nothing more is needed:\n\n+-----------------------------------------------------------------+\n| ABCDEF (6-of-6 multisig) 19.94 -> BCDEF (5-of-5 multisig) 16.43 |\n|                                   Alice                    3.50 |\n+-----------------------------------------------------------------+\n\nWhen we talk about sighashes, that case is quite interesting. The group of five participants could use SIGHASH_SINGLE | SIGHASH_ANYONECANPAY, and just bind that to the first output. But Alice cannot use the same sighash, because then her funds could be stolen by miners. She can use SIGHASH_ANYONECANPAY, then all outputs will be protected by her signature. However, combining two different sighashes is not going to work well with Schnorr signatures. For that reason, we need two of them. So, the TapScript branch for that ABCDEF multisig could be: \"<pubkeyBCDEF> OP_CHECKSIGVERIFY <pubkeyAlice> OP_CHECKSIG\".\n\nAlso, this case is even more interesting: Alice could also use SIGHASH_SINGLE | SIGHASH_ANYONECANPAY in that ABCDEF multisig and spend by key, but then she needs some on-chain output. It could be anything, even some output she received from dust attack. Then, she could use SIGHASH_ANYONECANPAY on that dust output, just to protect her coins. The total transaction size will be roughly the same, but then she could hide the whole group under a single Schnorr signature.\n\nThe missing part here is of course SIGHASH_ANYPREVOUT, then less transactions are needed. But even without that, the basic protocol can be deployed here and now, the only overhead will be transaction storage, because we need to sign every possible transaction for closing the channel. Also, it will be larger in case where all participants are going to close the channel, then each detachment will be processed in a separate transaction.\n\nWhen it comes to handling costs, the cost of leaving the channel is paid by the detached person. That means, even if going through the least compressed path is possible, it would be costly for all participants trying to do that, so it should discourage them and encourage to play by the rules, and move all coins through N-of-N multisig.\n\nAlso, when we talk about covenants, it is in fact some kind of covenant. By having different sighashes for different signatures, we can easily restrict outputs to any scripts we want (and every participant can just collect other signatures, and later decide, where to send its own coins, so it is possible to pay someone directly, instead of first moving coins to some personal address, so there is one less transaction; tldr: another payment can be done during closing the channel).\n\nSo, my conclusion is that changing sighashes is far easier and more powerful than my previous idea of \"paying to signatures\", so I will probably focus on that instead."
            }
        ],
        "thread_summary": {
            "title": "CoinPool should focus on different sighashes",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "vjudeu at gazeta.pl"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 5065
        }
    },
    {
        "title": "[bitcoin-dev] Wallet policies for descriptor wallets",
        "thread_messages": [
            {
                "author": "Salvatore Ingala",
                "date": "2022-05-05T14:32:34",
                "message_text_only": "In the implementation work to implement descriptors and miniscript support\nin hardware wallets [a][b], I encountered a number of challenges. Some of\nthem are technical in nature (e.g. due to constraints of embedded\ndevelopment). Others are related to the attempts of shaping a good user\nexperience; with bitcoin reaching more people who are not tech-savvy,\nself-custody is only as secure as what those newcomers can use easily\nenough.\n\nThe main tool that I am using to address some of these challenges is a\nlayer that sits _on top_ of descriptors/miniscript, while staying very\nclose to it. Since there is nothing that is vendor-specific in the vast\nmajority of the approach I'm currently using, I tried to distill it here\nfor your comments, and will propose a BIP if this is deemed valuable.\n\nI called the language \"wallet policies\" (suggestions for a better name are\nwelcome). I believe an approach based on wallet policies can benefit all\nhardware wallets (stateless or not) that want to securely support complex\nscripts; moreover, wallet policies are close enough to descriptors that\ntheir integration should be extremely easy for any software wallet that is\ncurrently using descriptors.\n\n[a]: https://blog.ledger.com/bitcoin-2 - early demo\n[b]: https://blog.ledger.com/miniscript-is-coming - miniscript example\n\n\nSalvatore Ingala\n\n\n======================================================\n\nThis document starts with a discussion on the motivation for wallet\npolicies, followed by their formal definition, and some recommendations for\nimplementations.\n\n== Rationale ==\n\nOutput script descriptors [1] were introduced in bitcoin-core as a way to\nrepresent collections of output scripts. It is a very general and flexible\nlanguage, designed to catch all the possible use-cases of bitcoin wallets\n(that is, if you know the script and you have the necessary keys, it will\nbe possible to sign transactions with bitcoin-core's descriptor-based\nwallets).\n\nUnfortunately, descriptors are not a perfect match for the typical usage of\nhardware wallets. Most hardware wallets have the following limitations\ncompared to a general-purpose machine running bitcoin-core:\n\n- they are embedded devices with limited RAM and computational power;\n- they might not be able to import additional private keys (all the keys\nare generated from a single seed via [BIP-32](\nhttps://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki));\n- they might not have permanent storage (*stateless* hardware wallet\ndesign).\n\nMoreover, other limitations like the limited size of the screen might\naffect what design choices are available in practice. Therefore, minimizing\nthe size of the information shown on-screen is important for a good user\nexperience.\n\nA more native, compact representation of the wallet receive/change would\nalso benefit the UX of software wallets using descriptors to represent\nsoftware wallets using descriptors/miniscript for multisignature or other\ncomplex locking conditions.\n\n=== Security and UX concerns of scripts in hardware wallets ===\n\nFor a hardware wallet, allowing the usage of complex scripts presents\nchallenges in terms of both security and user experience.\n\n==== Security issues ====\n\nOne of the security properties that hardware wallets strive to guarantee is\nthe following: **as long as the user correctly verifies the information\nthat is shown on the hardware wallet's screen before approving, no action\ncan be performed without the user's consent**.\nThis must hold even in scenarios where the attacker has full control of the\nmachine that is connected to the hardware wallet, and can execute arbitrary\nrequests or tamper with the legitimate user's requests.\n\nTherefore, it is not at all trivial to allow complex scripts, especially if\nthey contain keys that belong to third parties.\nThe hardware wallet must guarantee that the user knows precisely *what*\n\"policy\" is being used to spend the funds, and that the \"unspent\" funds (if\nany) will be protected by the same policy. This makes it impossible for an\nattacker to surreptitiously modify the policy, therefore stealing or\nburning user's funds.\n\n==== UX issues ====\n\nWith miniscript (and taproot trees) allowing substantially more complex\nspending policies to be used, it becomes more challenging to make sure that\nthe user is able _in practice_ to verify the information on the screen.\nTherefore, there are two fundamental design goals to strive for:\n- Minimize the amount of information that is shown on screen - so that the\nuser can actually validate it.\n- Minimize the number of times the user has to validate such information.\n\nDesigning a secure protocol for the coordination of a descriptor wallet\namong distant parties is also a challenging problem that is out of scope in\nthis document. See BIP-129 [2] for an approach designed for multisignature\nwallets.\n\n=== Policy registration as a solution ===\n\nA solution to address the security concerns, and part of the UX concerns,\nis to have a *registration* flow for the wallet policy in the hardware\nwallet. The \"wallet policy\" must contain enough information to generate all\nthe relevant addresses/scripts, and for the hardware wallet to identify the\nkeys that it controls and that are needed to spend the funds sent to those\naddresses.\n\nBefore a new policy is used for the first time, the user will register a\n`wallet policy` into the hardware wallet. While the details of the process\nare out of scope in this document, the flow should be something similar to\nthe following:\n\n1) The software wallet initiates a _wallet policy registration_ on the\nhardware wallet; the information should include the wallet policy, but also\na unique *name* that identifies the policy.\n2) The hardware wallet shows the wallet policy to the user using the secure\nscreen.\n3) After inspecting the policy and comparing it with a trusted source (for\nexample a printed backup), the user approves the policy.\n4) If stateful, the hardware wallet persists the policy in its permanent\nmemory; if stateless, it returns a \"proof of registration\".\n\nThe details of how to create a proof of registration are out of scope for\nthis document; using a *message authentication codes* on a hash committing\nto the wallet policy, its name and any additional metadata is an effective\nsolution if correctly executed.\n\nOnce a policy is registered, the hardware wallet can perform the usual\noperations securely:\n- generating receive and change addresses;\n- showing addresses on the secure screen;\n- sign transactions spending from a wallet, while correctly identifying\nchange addresses and computing the transaction fees.\n\nBefore any of the actions mentioned above, the hardware wallet will\nretrieve the policy from its permanent storage if stateful; if stateless it\nwill validate the _proof of registration_ before using the wallet policy\nprovided by the client.\nOnce the previously registered policy is correctly identified and approved\nby the user (for example by its name), and *as long as the policy\nregistration was executed securely*, hardware wallets can provide a user\nexperience similar to the usual one for single-signature transactions.\n\n=== Avoiding blowup in descriptor size ===\n\nWhile reusing a pubkey in different branches of a miniscript is explicitly\nforbidden by miniscript (as it has certain negative security implications),\nit is still reasonable to reuse the same *xpub* in multiple places, albeit\nwith different final steps of derivation (so that the actual pubkeys that\nare used in the script are indeed different).\n\nFor example, using Taproot, a *3*-of-*5* multisignature wallet could use:\n- a key path with a 5-of-5 MuSig\n- a script tree with a tree of 10 different 3-of-3 MuSig2 scripts, that are\ngenerated, plus a leaf with a fallback *3*-of-*5* multisignature using\nplain multisignature (with `OP_CHECKSIGADD`).\n\nThis could look similar to:\n\n```\ntr(musig2(xpubA,xpubB,xpubC,xpubD,xpubE)/<0;1>/*), {\n  {\n    {\n      pk(musig2(xpubA,xpubB,xpubC)/<2;3>/*),\n      {\n        pk(musig2(xpubA,xpubB,xpubD)/<4;5>/*)\n        pk(musig2(xpubA,xpubB,xpubE)/<6;7>/*),\n      }\n    },\n    {\n      pk(musig2(xpubA,xpubC,xpubD)/<8;9>/*),\n      {\n        pk(musig2(xpubA,xpubC,xpubE)/<10;11>/*),\n        pk(musig2(xpubA,xpubD,xpubE)/<12;13>/*)\n      }\n    }\n  },\n  {\n    {\n      pk(musig2(xpubB,xpubC,xpubD)/<14;15>/*),\n      pk(musig2(xpubB,xpubC,xpubE)/<16;17>/*)\n    },\n    {\n      pk(musig2(xpubB,xpubD,xpubE)/<18;19>/*),\n      {\n        pk(musig2(xpubC,xpubD,xpubE)/<20;21>/*),\n        sortedmulti_a(3,\n          xpubA/<22;23>/*,\n          xpubB/<22;23>/*,\n          xpubC/<22;23>/*,\n          xpubD/<22;23>/*,\n          xpubE/<22;23>/*)\n      }\n    }\n  }\n})\n```\n\nNote that each root xpub appears 8 times. With xpubs being up to 118 bytes\nlong, the length of the full descriptor can get extremely long (the problem\ngets *exponentially* worse with larger multisignature schemes).\n\nReplacing the common part of the key with a short key placeholder and\nmoving the key expression separately helps to keep the size of the wallet\npolicy small, which is crucial to allow human inspection in the\nregistration flow.\n\n=== Restrictions on the supported descriptors ====\n\nThe policy language proposed in this document purposely targets only a\nstricter subset of the output descriptors language, and it attempts to\ngeneralize in the most natural way the approach that is already used for\nsingle-signature *accounts* (as described in BIP-44 [3], BIP-49 [4], BIP-84\n[5], or BIP-86 [6]), or in multisignature setups (see for example BIP-48\n[7] and BIP-87 [8]).\n\nUnlike the BIPs mentioned above, it is not tied to any specific script\ntemplate, as it applies to arbitrary scripts that can be represented with\ndescriptors and miniscript.\n\nSupporting only a reduced feature set when compared to output descriptors\nhelps in implementations (especially on hardware wallets), while attempting\nto capture all the common use cases. More features can be added in the\nfuture if motivated by real world necessity.\n\nBy keeping the structure of the wallet policy language very close to that\nof descriptors, it should be straightforward to:\n- write wallet policy parsers;\n- extract the descriptors defined by a wallet policy;\n- convert a pair of descriptors describing a wallet \"account\" used in\ncurrent implementations into the corresponding wallet policy.\n\n\n== Wallet policies ==\n\nThis section formally defines wallet policies, and how they relate to\noutput script descriptors.\n\n=== Formal definition ===\n\nA wallet policy is composed by a wallet descriptor template, together with\na vector of key information items.\n\n==== Wallet descriptor template ====\n\nA wallet descriptor template is a `SCRIPT` expression.\n\n`SCRIPT` expressions:\n- `sh(SCRIPT)` (top level only): P2SH embed the argument.\n- `wsh(SCRIPT)` (top level or inside `sh` only): P2WSH embed the argument.\n- `pkh(KP)` (not inside `tr`): P2PKH output for the given public key (use\n`addr` if you only know the pubkey hash).\n- `wpkh(KP)` (top level or inside `sh` only): P2WPKH output for the given\ncompressed pubkey.\n- `multi(k,KP_1,KP_2,...,KP_n)`: k-of-n multisig script.\n- `sortedmulti(k,KP_1,KP_2,...,KP_n)`: k-of-n multisig script with keys\nsorted lexicographically in the resulting script.\n- `tr(KP)` or `tr(KP,TREE)` (top level only): P2TR output with the\nspecified key as internal key, and optionally a tree of script paths.\n- any valid miniscript template (inside `wsh` or `tr` only).\n\n`TREE` expressions:\n- any `SCRIPT` expression\n- An open brace `{`, a `TREE` expression, a comma `,`, a `TREE` expression,\nand a closing brace `}`\n\nNote: \"miniscript templates\" are not formally defined in this version of\nthe document, but it is straightforward to adapt this approach.\n\n`KP` expressions (key placeholders) consist of\n- a single character `@`\n- followed by a non-negative decimal number, with no leading zeros (except\nfor `@0`).\n- possibly followed by either:\n  - the string  `/**`, or\n  - a string of the form `/<NUM;NUM>/*`, for two distinct decimal numbers\n`NUM` representing unhardened derivations\n\nThe `/**` in the placeholder template represents commonly used paths for\nreceive/change addresses, and is equivalent to `<0;1>`.\n\nThe placeholder `@i` for some number *i* represents the *i*-th key in the\nvector of key origin information (which must be of size at least *i* + 1,\nor the wallet policy is invalid).\n\n==== Key informations vector ====\n\nEach element of the key origin information vector is a `KEY` expression.\n\n- Optionally, key origin information, consisting of:\n  - An open bracket `[`\n  - Exactly 8 hex characters for the fingerprint of the master key from\nwhich this key is derived from (see [BIP32](\nhttps://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki) for details)\n  - Followed by zero or more `/NUM'` path elements to indicate hardened\nderivation steps between the fingerprint and the xpub that follows\n  - A closing bracket `]`\n- Followed by the actual key, which is either\n  - a hex-encoded pubkey, which is either\n    - inside `wpkh` and `wsh`, only compressed public keys are permitted\n(exactly 66 hex characters starting with `02` or `03`.\n    - inside `tr`, x-only pubkeys are also permitted (exactly 64 hex\ncharacters).\n  - a serialized extended public key (`xpub`) (as defined in [BIP 32](\nhttps://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki))\n\nThe placeholder `@i` for some number *i* represents the *i*-th key in the\nvector of key orIgin information (which must be of size at least *i* + 1,\nor the wallet policy is invalid).\n\nThe policy template is invalid if any placeholder `@i` has derivation steps\nwhile the corresponding `(i+1)`-th element of the keys vector is not an\nxpub.\n\n==== Additional rules ====\n\nThe wallet policy is invalid if any placeholder expression with additional\nderivation steps is used when the corresponding key information is not an\nxpub.\n\nThe key information vector *should* be ordered so that placeholder `@i`\nnever appear for the first time before an occurrence of `@j`  for some `j <\ni`; for example, the first placeholder is always `@0`, the next one is\n`@1`, etc.\n\n=== Descriptor derivation ===\n\n>From a wallet descriptor template (and the associated vector of key\ninformations), one can therefore obtain the 1-dimensional descriptor for\nreceive and change addresses by:\n\n- replacing each key placeholder with the corresponding key origin\ninformation;\n- replacing every `/**`  with `/0/*` for the receive descriptor, and `/1/*`\nfor the change descriptor;\n- replacing every `/<M,N>` with  `/M` for the receive descriptor, and `/N`\nfor the change descriptor.\n\nFor example, the wallet descriptor `pkh(@0/**)` with key information\n`[\"[d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL\"]`\nproduces the following two descriptors:\n\n- Receive descriptor:\n`pkh([d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL/0/*)`\n\n- Change descriptor:\n`pkh([d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL/1/*)`\n\n=== Implementation guidelines ===\n\nImplementations must not necessarily implement all of the possible wallet\npolicies defined by this standard, but it is recommended to clearly\ndocument any limitation.\n\nImplementations can add additional metadata that is stored together with\nthe wallet policy for the purpose of wallet policy registration and later\nusage. Metadata can be vendor-specific and is out of the scope of this\ndocument.\n\nAny implementation in a general-purpose software wallet allowing arbitrary\nscripts (or any scripts that involve external cosigners) should put great\ncare into a process for backing up a wallet policy. In fact, unlike typical\nsingle-signature scenarios, the seed alone is no longer enough to discover\nwallet policies with existing funds, and the loss of the backup is likely\nto lead to permanent loss of funds.\n\nAvoiding key reuse among different wallet accounts is also extremely\nimportant, but out of scope for this document.\n\n== Examples ==\n\nSome examples of wallet descriptor templates (vectors of keys omitted for\nsimplicity):\n- Template for a native segwit account:\n  wpkh(@0/**)\n- Template for a taproot BIP86 account:\n  tr(@0/**)\n- Template for a native segwit 2-of-3:\n  wsh(sortedmulti(2, at 0/**, at 1/**, at 2/**))\n- Template with miniscript for \"1 of 2 equally likely keys\":\n  wsh(or_b(pk(@0/**),s:pk(@1/**)))\n\nMore examples (esp. targeting miniscript on taproot) will be added in the\nfuture.\n\n== References ==\n\n* [1] - Output Script Descriptors:\nhttps://github.com/bitcoin/bitcoin/blob/master/doc/descriptors.md\n* [2] - BIP-129 (Bitcoin Secure Multisig Setup):\nhttps://github.com/bitcoin/bips/blob/master/bip-0129.mediawiki\n* [3] - BIP-44:\nhttps://github.com/bitcoin/bips/blob/master/bip-0044.mediawiki\n* [4] - BIP-49:\nhttps://github.com/bitcoin/bips/blob/master/bip-0049.mediawiki\n* [5] - BIP-84:\nhttps://github.com/bitcoin/bips/blob/master/bip-0084.mediawiki\n* [6] - BIP-86:\nhttps://github.com/bitcoin/bips/blob/master/bip-0086.mediawiki\n* [7] - BIP-48:\nhttps://github.com/bitcoin/bips/blob/master/bip-0048.mediawiki\n* [8] - BIP-87:\nhttps://github.com/bitcoin/bips/blob/master/bip-0087.mediawiki\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220505/946462e7/attachment-0001.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-05-08T17:41:07",
                "message_text_only": "I took a look at the spec for the wallet descriptor format, and I like the\nconcept of having placeholder variables for keys. It reduces the size of\nthe descriptor, makes it substantially easier for a human to\nread/verify, especially in the future when we have more complex\nscripts, and provides a nice format for a script template which can make it\neasier to verify that you're using the same script template as something\nelse (ie besides using different keys). I think the `/**` syntax is an\nimprovement over the current descriptor format, however it is a bit awkward\nand inflexible. My understanding is that some of this inflexibility comes\nfrom the goal of reducing memory usage, and I don't think I have a good\nenough handle on that part of things to usefully comment. I've put\nadditional comments and suggestions on the format in this github issue\n<https://github.com/LedgerHQ/app-bitcoin-new/issues/35>.\n\nI think it would be very useful to come to agreement on a more flexible\nformat that can support a much broader set of use cases, and can\npotentially be a widely supported standard. I understand low-ram devices\nmight have a much harder time using more flexible (and complex) formats.\n\n\n\n\n\n\n\nOn Thu, May 5, 2022 at 9:39 AM Salvatore Ingala via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> In the implementation work to implement descriptors and miniscript support\n> in hardware wallets [a][b], I encountered a number of challenges. Some of\n> them are technical in nature (e.g. due to constraints of embedded\n> development). Others are related to the attempts of shaping a good user\n> experience; with bitcoin reaching more people who are not tech-savvy,\n> self-custody is only as secure as what those newcomers can use easily\n> enough.\n>\n> The main tool that I am using to address some of these challenges is a\n> layer that sits _on top_ of descriptors/miniscript, while staying very\n> close to it. Since there is nothing that is vendor-specific in the vast\n> majority of the approach I'm currently using, I tried to distill it here\n> for your comments, and will propose a BIP if this is deemed valuable.\n>\n> I called the language \"wallet policies\" (suggestions for a better name are\n> welcome). I believe an approach based on wallet policies can benefit all\n> hardware wallets (stateless or not) that want to securely support complex\n> scripts; moreover, wallet policies are close enough to descriptors that\n> their integration should be extremely easy for any software wallet that is\n> currently using descriptors.\n>\n> [a]: https://blog.ledger.com/bitcoin-2 - early demo\n> [b]: https://blog.ledger.com/miniscript-is-coming - miniscript example\n>\n>\n> Salvatore Ingala\n>\n>\n> ======================================================\n>\n> This document starts with a discussion on the motivation for wallet\n> policies, followed by their formal definition, and some recommendations for\n> implementations.\n>\n> == Rationale ==\n>\n> Output script descriptors [1] were introduced in bitcoin-core as a way to\n> represent collections of output scripts. It is a very general and flexible\n> language, designed to catch all the possible use-cases of bitcoin wallets\n> (that is, if you know the script and you have the necessary keys, it will\n> be possible to sign transactions with bitcoin-core's descriptor-based\n> wallets).\n>\n> Unfortunately, descriptors are not a perfect match for the typical usage\n> of hardware wallets. Most hardware wallets have the following limitations\n> compared to a general-purpose machine running bitcoin-core:\n>\n> - they are embedded devices with limited RAM and computational power;\n> - they might not be able to import additional private keys (all the keys\n> are generated from a single seed via [BIP-32](\n> https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki));\n> - they might not have permanent storage (*stateless* hardware wallet\n> design).\n>\n> Moreover, other limitations like the limited size of the screen might\n> affect what design choices are available in practice. Therefore, minimizing\n> the size of the information shown on-screen is important for a good user\n> experience.\n>\n> A more native, compact representation of the wallet receive/change would\n> also benefit the UX of software wallets using descriptors to represent\n> software wallets using descriptors/miniscript for multisignature or other\n> complex locking conditions.\n>\n> === Security and UX concerns of scripts in hardware wallets ===\n>\n> For a hardware wallet, allowing the usage of complex scripts presents\n> challenges in terms of both security and user experience.\n>\n> ==== Security issues ====\n>\n> One of the security properties that hardware wallets strive to guarantee\n> is the following: **as long as the user correctly verifies the information\n> that is shown on the hardware wallet's screen before approving, no action\n> can be performed without the user's consent**.\n> This must hold even in scenarios where the attacker has full control of\n> the machine that is connected to the hardware wallet, and can execute\n> arbitrary requests or tamper with the legitimate user's requests.\n>\n> Therefore, it is not at all trivial to allow complex scripts, especially\n> if they contain keys that belong to third parties.\n> The hardware wallet must guarantee that the user knows precisely *what*\n> \"policy\" is being used to spend the funds, and that the \"unspent\" funds (if\n> any) will be protected by the same policy. This makes it impossible for an\n> attacker to surreptitiously modify the policy, therefore stealing or\n> burning user's funds.\n>\n> ==== UX issues ====\n>\n> With miniscript (and taproot trees) allowing substantially more complex\n> spending policies to be used, it becomes more challenging to make sure that\n> the user is able _in practice_ to verify the information on the screen.\n> Therefore, there are two fundamental design goals to strive for:\n> - Minimize the amount of information that is shown on screen - so that the\n> user can actually validate it.\n> - Minimize the number of times the user has to validate such information.\n>\n> Designing a secure protocol for the coordination of a descriptor wallet\n> among distant parties is also a challenging problem that is out of scope in\n> this document. See BIP-129 [2] for an approach designed for multisignature\n> wallets.\n>\n> === Policy registration as a solution ===\n>\n> A solution to address the security concerns, and part of the UX concerns,\n> is to have a *registration* flow for the wallet policy in the hardware\n> wallet. The \"wallet policy\" must contain enough information to generate all\n> the relevant addresses/scripts, and for the hardware wallet to identify the\n> keys that it controls and that are needed to spend the funds sent to those\n> addresses.\n>\n> Before a new policy is used for the first time, the user will register a\n> `wallet policy` into the hardware wallet. While the details of the process\n> are out of scope in this document, the flow should be something similar to\n> the following:\n>\n> 1) The software wallet initiates a _wallet policy registration_ on the\n> hardware wallet; the information should include the wallet policy, but also\n> a unique *name* that identifies the policy.\n> 2) The hardware wallet shows the wallet policy to the user using the\n> secure screen.\n> 3) After inspecting the policy and comparing it with a trusted source (for\n> example a printed backup), the user approves the policy.\n> 4) If stateful, the hardware wallet persists the policy in its permanent\n> memory; if stateless, it returns a \"proof of registration\".\n>\n> The details of how to create a proof of registration are out of scope for\n> this document; using a *message authentication codes* on a hash committing\n> to the wallet policy, its name and any additional metadata is an effective\n> solution if correctly executed.\n>\n> Once a policy is registered, the hardware wallet can perform the usual\n> operations securely:\n> - generating receive and change addresses;\n> - showing addresses on the secure screen;\n> - sign transactions spending from a wallet, while correctly identifying\n> change addresses and computing the transaction fees.\n>\n> Before any of the actions mentioned above, the hardware wallet will\n> retrieve the policy from its permanent storage if stateful; if stateless it\n> will validate the _proof of registration_ before using the wallet policy\n> provided by the client.\n> Once the previously registered policy is correctly identified and approved\n> by the user (for example by its name), and *as long as the policy\n> registration was executed securely*, hardware wallets can provide a user\n> experience similar to the usual one for single-signature transactions.\n>\n> === Avoiding blowup in descriptor size ===\n>\n> While reusing a pubkey in different branches of a miniscript is explicitly\n> forbidden by miniscript (as it has certain negative security implications),\n> it is still reasonable to reuse the same *xpub* in multiple places, albeit\n> with different final steps of derivation (so that the actual pubkeys that\n> are used in the script are indeed different).\n>\n> For example, using Taproot, a *3*-of-*5* multisignature wallet could use:\n> - a key path with a 5-of-5 MuSig\n> - a script tree with a tree of 10 different 3-of-3 MuSig2 scripts, that\n> are generated, plus a leaf with a fallback *3*-of-*5* multisignature using\n> plain multisignature (with `OP_CHECKSIGADD`).\n>\n> This could look similar to:\n>\n> ```\n> tr(musig2(xpubA,xpubB,xpubC,xpubD,xpubE)/<0;1>/*), {\n>   {\n>     {\n>       pk(musig2(xpubA,xpubB,xpubC)/<2;3>/*),\n>       {\n>         pk(musig2(xpubA,xpubB,xpubD)/<4;5>/*)\n>         pk(musig2(xpubA,xpubB,xpubE)/<6;7>/*),\n>       }\n>     },\n>     {\n>       pk(musig2(xpubA,xpubC,xpubD)/<8;9>/*),\n>       {\n>         pk(musig2(xpubA,xpubC,xpubE)/<10;11>/*),\n>         pk(musig2(xpubA,xpubD,xpubE)/<12;13>/*)\n>       }\n>     }\n>   },\n>   {\n>     {\n>       pk(musig2(xpubB,xpubC,xpubD)/<14;15>/*),\n>       pk(musig2(xpubB,xpubC,xpubE)/<16;17>/*)\n>     },\n>     {\n>       pk(musig2(xpubB,xpubD,xpubE)/<18;19>/*),\n>       {\n>         pk(musig2(xpubC,xpubD,xpubE)/<20;21>/*),\n>         sortedmulti_a(3,\n>           xpubA/<22;23>/*,\n>           xpubB/<22;23>/*,\n>           xpubC/<22;23>/*,\n>           xpubD/<22;23>/*,\n>           xpubE/<22;23>/*)\n>       }\n>     }\n>   }\n> })\n> ```\n>\n> Note that each root xpub appears 8 times. With xpubs being up to 118 bytes\n> long, the length of the full descriptor can get extremely long (the problem\n> gets *exponentially* worse with larger multisignature schemes).\n>\n> Replacing the common part of the key with a short key placeholder and\n> moving the key expression separately helps to keep the size of the wallet\n> policy small, which is crucial to allow human inspection in the\n> registration flow.\n>\n> === Restrictions on the supported descriptors ====\n>\n> The policy language proposed in this document purposely targets only a\n> stricter subset of the output descriptors language, and it attempts to\n> generalize in the most natural way the approach that is already used for\n> single-signature *accounts* (as described in BIP-44 [3], BIP-49 [4], BIP-84\n> [5], or BIP-86 [6]), or in multisignature setups (see for example BIP-48\n> [7] and BIP-87 [8]).\n>\n> Unlike the BIPs mentioned above, it is not tied to any specific script\n> template, as it applies to arbitrary scripts that can be represented with\n> descriptors and miniscript.\n>\n> Supporting only a reduced feature set when compared to output descriptors\n> helps in implementations (especially on hardware wallets), while attempting\n> to capture all the common use cases. More features can be added in the\n> future if motivated by real world necessity.\n>\n> By keeping the structure of the wallet policy language very close to that\n> of descriptors, it should be straightforward to:\n> - write wallet policy parsers;\n> - extract the descriptors defined by a wallet policy;\n> - convert a pair of descriptors describing a wallet \"account\" used in\n> current implementations into the corresponding wallet policy.\n>\n>\n> == Wallet policies ==\n>\n> This section formally defines wallet policies, and how they relate to\n> output script descriptors.\n>\n> === Formal definition ===\n>\n> A wallet policy is composed by a wallet descriptor template, together with\n> a vector of key information items.\n>\n> ==== Wallet descriptor template ====\n>\n> A wallet descriptor template is a `SCRIPT` expression.\n>\n> `SCRIPT` expressions:\n> - `sh(SCRIPT)` (top level only): P2SH embed the argument.\n> - `wsh(SCRIPT)` (top level or inside `sh` only): P2WSH embed the argument.\n> - `pkh(KP)` (not inside `tr`): P2PKH output for the given public key (use\n> `addr` if you only know the pubkey hash).\n> - `wpkh(KP)` (top level or inside `sh` only): P2WPKH output for the given\n> compressed pubkey.\n> - `multi(k,KP_1,KP_2,...,KP_n)`: k-of-n multisig script.\n> - `sortedmulti(k,KP_1,KP_2,...,KP_n)`: k-of-n multisig script with keys\n> sorted lexicographically in the resulting script.\n> - `tr(KP)` or `tr(KP,TREE)` (top level only): P2TR output with the\n> specified key as internal key, and optionally a tree of script paths.\n> - any valid miniscript template (inside `wsh` or `tr` only).\n>\n> `TREE` expressions:\n> - any `SCRIPT` expression\n> - An open brace `{`, a `TREE` expression, a comma `,`, a `TREE`\n> expression, and a closing brace `}`\n>\n> Note: \"miniscript templates\" are not formally defined in this version of\n> the document, but it is straightforward to adapt this approach.\n>\n> `KP` expressions (key placeholders) consist of\n> - a single character `@`\n> - followed by a non-negative decimal number, with no leading zeros (except\n> for `@0`).\n> - possibly followed by either:\n>   - the string  `/**`, or\n>   - a string of the form `/<NUM;NUM>/*`, for two distinct decimal numbers\n> `NUM` representing unhardened derivations\n>\n> The `/**` in the placeholder template represents commonly used paths for\n> receive/change addresses, and is equivalent to `<0;1>`.\n>\n> The placeholder `@i` for some number *i* represents the *i*-th key in the\n> vector of key origin information (which must be of size at least *i* + 1,\n> or the wallet policy is invalid).\n>\n> ==== Key informations vector ====\n>\n> Each element of the key origin information vector is a `KEY` expression.\n>\n> - Optionally, key origin information, consisting of:\n>   - An open bracket `[`\n>   - Exactly 8 hex characters for the fingerprint of the master key from\n> which this key is derived from (see [BIP32](\n> https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki) for\n> details)\n>   - Followed by zero or more `/NUM'` path elements to indicate hardened\n> derivation steps between the fingerprint and the xpub that follows\n>   - A closing bracket `]`\n> - Followed by the actual key, which is either\n>   - a hex-encoded pubkey, which is either\n>     - inside `wpkh` and `wsh`, only compressed public keys are permitted\n> (exactly 66 hex characters starting with `02` or `03`.\n>     - inside `tr`, x-only pubkeys are also permitted (exactly 64 hex\n> characters).\n>   - a serialized extended public key (`xpub`) (as defined in [BIP 32](\n> https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki))\n>\n> The placeholder `@i` for some number *i* represents the *i*-th key in the\n> vector of key orIgin information (which must be of size at least *i* + 1,\n> or the wallet policy is invalid).\n>\n> The policy template is invalid if any placeholder `@i` has derivation\n> steps while the corresponding `(i+1)`-th element of the keys vector is not\n> an xpub.\n>\n> ==== Additional rules ====\n>\n> The wallet policy is invalid if any placeholder expression with additional\n> derivation steps is used when the corresponding key information is not an\n> xpub.\n>\n> The key information vector *should* be ordered so that placeholder `@i`\n> never appear for the first time before an occurrence of `@j`  for some `j <\n> i`; for example, the first placeholder is always `@0`, the next one is\n> `@1`, etc.\n>\n> === Descriptor derivation ===\n>\n> From a wallet descriptor template (and the associated vector of key\n> informations), one can therefore obtain the 1-dimensional descriptor for\n> receive and change addresses by:\n>\n> - replacing each key placeholder with the corresponding key origin\n> information;\n> - replacing every `/**`  with `/0/*` for the receive descriptor, and\n> `/1/*` for the change descriptor;\n> - replacing every `/<M,N>` with  `/M` for the receive descriptor, and `/N`\n> for the change descriptor.\n>\n> For example, the wallet descriptor `pkh(@0/**)` with key information\n> `[\"[d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL\"]`\n> produces the following two descriptors:\n>\n> - Receive descriptor:\n> `pkh([d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL/0/*)`\n>\n> - Change descriptor:\n> `pkh([d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL/1/*)`\n>\n> === Implementation guidelines ===\n>\n> Implementations must not necessarily implement all of the possible wallet\n> policies defined by this standard, but it is recommended to clearly\n> document any limitation.\n>\n> Implementations can add additional metadata that is stored together with\n> the wallet policy for the purpose of wallet policy registration and later\n> usage. Metadata can be vendor-specific and is out of the scope of this\n> document.\n>\n> Any implementation in a general-purpose software wallet allowing arbitrary\n> scripts (or any scripts that involve external cosigners) should put great\n> care into a process for backing up a wallet policy. In fact, unlike typical\n> single-signature scenarios, the seed alone is no longer enough to discover\n> wallet policies with existing funds, and the loss of the backup is likely\n> to lead to permanent loss of funds.\n>\n> Avoiding key reuse among different wallet accounts is also extremely\n> important, but out of scope for this document.\n>\n> == Examples ==\n>\n> Some examples of wallet descriptor templates (vectors of keys omitted for\n> simplicity):\n> - Template for a native segwit account:\n>   wpkh(@0/**)\n> - Template for a taproot BIP86 account:\n>   tr(@0/**)\n> - Template for a native segwit 2-of-3:\n>   wsh(sortedmulti(2, at 0/**, at 1/**, at 2/**))\n> - Template with miniscript for \"1 of 2 equally likely keys\":\n>   wsh(or_b(pk(@0/**),s:pk(@1/**)))\n>\n> More examples (esp. targeting miniscript on taproot) will be added in the\n> future.\n>\n> == References ==\n>\n> * [1] - Output Script Descriptors:\n> https://github.com/bitcoin/bitcoin/blob/master/doc/descriptors.md\n> * [2] - BIP-129 (Bitcoin Secure Multisig Setup):\n> https://github.com/bitcoin/bips/blob/master/bip-0129.mediawiki\n> * [3] - BIP-44:\n> https://github.com/bitcoin/bips/blob/master/bip-0044.mediawiki\n> * [4] - BIP-49:\n> https://github.com/bitcoin/bips/blob/master/bip-0049.mediawiki\n> * [5] - BIP-84:\n> https://github.com/bitcoin/bips/blob/master/bip-0084.mediawiki\n> * [6] - BIP-86:\n> https://github.com/bitcoin/bips/blob/master/bip-0086.mediawiki\n> * [7] - BIP-48:\n> https://github.com/bitcoin/bips/blob/master/bip-0048.mediawiki\n> * [8] - BIP-87:\n> https://github.com/bitcoin/bips/blob/master/bip-0087.mediawiki\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220508/2f271848/attachment-0001.html>"
            },
            {
                "author": "darosior",
                "date": "2022-05-09T11:36:47",
                "message_text_only": "Thanks for taking the time to write up about the implementation of output descriptors on signing devices, and\nfor proposing a method to overcome encountered difficulties for the following implementers.\n\nI have some questions with regard to the modifications to the descriptor language required to make the\nregistration flow reasonable on a signing device.\n\nTo sum up, starting from the currently spec'd output descriptors [0] you need:\n1. The `<NUM;NUM>` optimization for the common usecase of using 2 descriptors at different derivation indices\n   for receive and change. [1]\n2. The `/**` optimization for the common usecase of `/<0;1>` for point 1).\n3. A new key expression `@i` referring to an index in a list of keys.\n\nThe first point was already discussed at great length [2]. Whether or not we agree using the derivation path\nfor change detection is a sane thing to do, most signing devices need to support this to not break\ncompatibility. I think the advantage boils down to not make the user write two almost-similar descriptors on\nits backup, since it doesn't necessarily help readibility for human verification.\n\nI'm not so sure about the second point. Is another deviation from the standard worth it just for saving 3\ncharacters?\nDisgressing, if we are to have a carve-out in the descriptor language for the common usecase of change/receive\nkeychains maybe your `/**` applies better than the proposed `/<NUM;NUM>` as the latter can open the door to\nfurther carve-out requests.\n\nFor the third point, it does indeed seem unrealistic to check both the keys and the descriptor at the same\ntime. Even just because of the screen size (if the width an xpub is, what, 3 times the width of your screen,\nby the time you finished verifying it you have forgotten the descriptor context in which this key was!). It\nbecomes harder as you get larger descriptors with Miniscript or Taproot, as you mentioned. Even the Miniscript\ncompiler at [3] supports key aliasing to workaround the inconvenience of long keys.\nHowever, why does it need to be a change to the descriptor language? It looks a lot like something that needs\nto be handled at the application level with key aliasing. The flow would be first to register known keys, and\nthen when registering a descriptor the keys would be replaced by their aliases for smoother verification. For\nstateless devices, the registration of keys could use the same flow you described for descriptors.\nIn the end it's just replacing the vector and indices with a mapping and label, which make it a *much* better\nUX (checking aliases vs looking up indices in a vector). For instance:\n    Key registration:\n        Alice: xpub6FLhTbeNidZkyC729yW6K6a5zuDxKUL8Q6oZm4XG2ov9PdxAyyDNEUm3jet8ENnvYsy6nCgsofN6FeVxakLDTdWGoxtmoYcu2exhqh9HjtV\n        Bob: xpub6CoUua86qHYdDmnQL7imGN3zUMpVjRT4uDtRxYvfFj2v8JRvsaaGtf9ggv9NiL8sx3rFh6po92WBChwb37gDGuuU2Qo7zi3ZKC9cLjAsdQw\n        Notary: xpub6DjUwtKmK7uqsd5p9w3eoJ4cjuML51nW85BTWuBaHEoxfmDGD3uPf6ZghsVeyuZUSuYEL4ajkVrfXzmotHHPtf6oBNYUQDSSBD4zUEiDoap\n\n    Descriptor registration (policy language for simpl.):\n        tr(NUMS,{\n            multi(2,Alice,Bob),\n            and(older(52560),and(Notary,Alice)),\n            and(older(52560),and(Notary,Bob))\n        })\n\nIn conclusion, if we were to have an optimization in the descriptor language for the common receive/change\nusecase, i don't think you need another \"wallet policy language\" than the existing output descriptors language\nwith key aliasing/registration?\n\n\nUnrelated question, since you mentioned `musig2` descriptors in this context. I thought Musig2 wasn't really\nfeasible for hardware signing devices, especially stateless ones. Do you think/know whether it is actually\npossible for a HW to take part in a Musig2?\n\n\nThanks,\nAntoine\n\n[0] https://github.com/bitcoin/bips/blob/master/bip-0380.mediawiki\n[1] https://github.com/bitcoin/bitcoin/pull/22838\n[2] https://github.com/bitcoin/bitcoin/issues/17190\n[3] https://bitcoin.sipa.be/miniscript/\n\n\n------- Original Message -------\nLe jeudi 5 mai 2022 \u00e0 4:32 PM, Salvatore Ingala via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n\n> In the implementation work to implement descriptors and miniscript support in hardware wallets [a][b], I encountered a number of challenges. Some of them are technical in nature (e.g. due to constraints of embedded development). Others are related to the attempts of shaping a good user experience; with bitcoin reaching more people who are not tech-savvy, self-custody is only as secure as what those newcomers can use easily enough.\n>\n> The main tool that I am using to address some of these challenges is a layer that sits _on top_ of descriptors/miniscript, while staying very close to it. Since there is nothing that is vendor-specific in the vast majority of the approach I'm currently using, I tried to distill it here for your comments, and will propose a BIP if this is deemed valuable.\n>\n> I called the language \"wallet policies\" (suggestions for a better name are welcome). I believe an approach based on wallet policies can benefit all hardware wallets (stateless or not) that want to securely support complex scripts; moreover, wallet policies are close enough to descriptors that their integration should be extremely easy for any software wallet that is currently using descriptors.\n>\n> [a]: https://blog.ledger.com/bitcoin-2 - early demo[b]: https://blog.ledger.com/miniscript-is-coming - miniscript example\n>\n> Salvatore Ingala\n>\n> ======================================================\n>\n> This document starts with a discussion on the motivation for wallet policies, followed by their formal definition, and some recommendations for implementations.\n> == Rationale ==\n> Output script descriptors [1] were introduced in bitcoin-core as a way to represent collections of output scripts. It is a very general and flexible language, designed to catch all the possible use-cases of bitcoin wallets (that is, if you know the script and you have the necessary keys, it will be possible to sign transactions with bitcoin-core's descriptor-based wallets).\n>\n> Unfortunately, descriptors are not a perfect match for the typical usage of hardware wallets. Most hardware wallets have the following limitations compared to a general-purpose machine running bitcoin-core:\n>\n> - they are embedded devices with limited RAM and computational power;\n> - they might not be able to import additional private keys (all the keys are generated from a single seed via [BIP-32](https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki));\n> - they might not have permanent storage (*stateless* hardware wallet design).\n>\n> Moreover, other limitations like the limited size of the screen might affect what design choices are available in practice. Therefore, minimizing the size of the information shown on-screen is important for a good user experience.\n>\n> A more native, compact representation of the wallet receive/change would also benefit the UX of software wallets using descriptors to represent software wallets using descriptors/miniscript for multisignature or other complex locking conditions.\n>\n> === Security and UX concerns of scripts in hardware wallets ===\n> For a hardware wallet, allowing the usage of complex scripts presents challenges in terms of both security and user experience.\n>\n> ==== Security issues ====\n> One of the security properties that hardware wallets strive to guarantee is the following: **as long as the user correctly verifies the information that is shown on the hardware wallet's screen before approving, no action can be performed without the user's consent**.\n> This must hold even in scenarios where the attacker has full control of the machine that is connected to the hardware wallet, and can execute arbitrary requests or tamper with the legitimate user's requests.\n>\n> Therefore, it is not at all trivial to allow complex scripts, especially if they contain keys that belong to third parties.\n> The hardware wallet must guarantee that the user knows precisely *what* \"policy\" is being used to spend the funds, and that the \"unspent\" funds (if any) will be protected by the same policy. This makes it impossible for an attacker to surreptitiously modify the policy, therefore stealing or burning user's funds.\n>\n> ==== UX issues ====\n> With miniscript (and taproot trees) allowing substantially more complex spending policies to be used, it becomes more challenging to make sure that the user is able _in practice_ to verify the information on the screen. Therefore, there are two fundamental design goals to strive for:\n> - Minimize the amount of information that is shown on screen - so that the user can actually validate it.\n> - Minimize the number of times the user has to validate such information.\n>\n> Designing a secure protocol for the coordination of a descriptor wallet among distant parties is also a challenging problem that is out of scope in this document. See BIP-129 [2] for an approach designed for multisignature wallets.\n>\n> === Policy registration as a solution ===\n> A solution to address the security concerns, and part of the UX concerns, is to have a *registration* flow for the wallet policy in the hardware wallet. The \"wallet policy\" must contain enough information to generate all the relevant addresses/scripts, and for the hardware wallet to identify the keys that it controls and that are needed to spend the funds sent to those addresses.\n>\n> Before a new policy is used for the first time, the user will register a `wallet policy` into the hardware wallet. While the details of the process are out of scope in this document, the flow should be something similar to the following:\n>\n> 1) The software wallet initiates a _wallet policy registration_ on the hardware wallet; the information should include the wallet policy, but also a unique *name* that identifies the policy.\n> 2) The hardware wallet shows the wallet policy to the user using the secure screen.\n> 3) After inspecting the policy and comparing it with a trusted source (for example a printed backup), the user approves the policy.\n> 4) If stateful, the hardware wallet persists the policy in its permanent memory; if stateless, it returns a \"proof of registration\".\n>\n> The details of how to create a proof of registration are out of scope for this document; using a *message authentication codes* on a hash committing to the wallet policy, its name and any additional metadata is an effective solution if correctly executed.\n>\n> Once a policy is registered, the hardware wallet can perform the usual operations securely:\n> - generating receive and change addresses;\n> - showing addresses on the secure screen;\n> - sign transactions spending from a wallet, while correctly identifying change addresses and computing the transaction fees.\n>\n> Before any of the actions mentioned above, the hardware wallet will retrieve the policy from its permanent storage if stateful; if stateless it will validate the _proof of registration_ before using the wallet policy provided by the client.\n> Once the previously registered policy is correctly identified and approved by the user (for example by its name), and *as long as the policy registration was executed securely*, hardware wallets can provide a user experience similar to the usual one for single-signature transactions.\n>\n> === Avoiding blowup in descriptor size ===\n> While reusing a pubkey in different branches of a miniscript is explicitly forbidden by miniscript (as it has certain negative security implications), it is still reasonable to reuse the same *xpub* in multiple places, albeit with different final steps of derivation (so that the actual pubkeys that are used in the script are indeed different).\n>\n> For example, using Taproot, a *3*-of-*5* multisignature wallet could use:\n> - a key path with a 5-of-5 MuSig\n> - a script tree with a tree of 10 different 3-of-3 MuSig2 scripts, that are generated, plus a leaf with a fallback *3*-of-*5* multisignature using plain multisignature (with `OP_CHECKSIGADD`).\n>\n> This could look similar to:\n>\n> ```\n> tr(musig2(xpubA,xpubB,xpubC,xpubD,xpubE)/<0;1>/*), {\n> {\n> {\n> pk(musig2(xpubA,xpubB,xpubC)/<2;3>/*),\n> {\n> pk(musig2(xpubA,xpubB,xpubD)/<4;5>/*)\n> pk(musig2(xpubA,xpubB,xpubE)/<6;7>/*),\n> }\n> },\n> {\n> pk(musig2(xpubA,xpubC,xpubD)/<8;9>/*),\n> {\n> pk(musig2(xpubA,xpubC,xpubE)/<10;11>/*),\n> pk(musig2(xpubA,xpubD,xpubE)/<12;13>/*)\n> }\n> }\n> },\n> {\n> {\n> pk(musig2(xpubB,xpubC,xpubD)/<14;15>/*),\n> pk(musig2(xpubB,xpubC,xpubE)/<16;17>/*)\n> },\n> {\n> pk(musig2(xpubB,xpubD,xpubE)/<18;19>/*),\n> {\n> pk(musig2(xpubC,xpubD,xpubE)/<20;21>/*),\n> sortedmulti_a(3,\n> xpubA/<22;23>/*,\n> xpubB/<22;23>/*,\n> xpubC/<22;23>/*,\n> xpubD/<22;23>/*,\n> xpubE/<22;23>/*)\n> }\n> }\n> }\n> })\n> ```\n>\n> Note that each root xpub appears 8 times. With xpubs being up to 118 bytes long, the length of the full descriptor can get extremely long (the problem gets *exponentially* worse with larger multisignature schemes).\n>\n> Replacing the common part of the key with a short key placeholder and moving the key expression separately helps to keep the size of the wallet policy small, which is crucial to allow human inspection in the registration flow.\n>\n> === Restrictions on the supported descriptors ====\n>\n> The policy language proposed in this document purposely targets only a stricter subset of the output descriptors language, and it attempts to generalize in the most natural way the approach that is already used for single-signature *accounts* (as described in BIP-44 [3], BIP-49 [4], BIP-84 [5], or BIP-86 [6]), or in multisignature setups (see for example BIP-48 [7] and BIP-87 [8]).\n> Unlike the BIPs mentioned above, it is not tied to any specific script template, as it applies to arbitrary scripts that can be represented with descriptors and miniscript.\n>\n> Supporting only a reduced feature set when compared to output descriptors helps in implementations (especially on hardware wallets), while attempting to capture all the common use cases. More features can be added in the future if motivated by real world necessity.\n>\n> By keeping the structure of the wallet policy language very close to that of descriptors, it should be straightforward to:\n> - write wallet policy parsers;\n> - extract the descriptors defined by a wallet policy;\n> - convert a pair of descriptors describing a wallet \"account\" used in current implementations into the corresponding wallet policy.\n>\n>\n> == Wallet policies ==\n> This section formally defines wallet policies, and how they relate to output script descriptors.\n> === Formal definition ===\n> A wallet policy is composed by a wallet descriptor template, together with a vector of key information items.\n>\n> ==== Wallet descriptor template ====\n>\n> A wallet descriptor template is a `SCRIPT` expression.\n>\n> `SCRIPT` expressions:\n> - `sh(SCRIPT)` (top level only): P2SH embed the argument.\n> - `wsh(SCRIPT)` (top level or inside `sh` only): P2WSH embed the argument.\n> - `pkh(KP)` (not inside `tr`): P2PKH output for the given public key (use `addr` if you only know the pubkey hash).\n> - `wpkh(KP)` (top level or inside `sh` only): P2WPKH output for the given compressed pubkey.\n> - `multi(k,KP_1,KP_2,...,KP_n)`: k-of-n multisig script.\n> - `sortedmulti(k,KP_1,KP_2,...,KP_n)`: k-of-n multisig script with keys sorted lexicographically in the resulting script.\n> - `tr(KP)` or `tr(KP,TREE)` (top level only): P2TR output with the specified key as internal key, and optionally a tree of script paths.- any valid miniscript template (inside `wsh` or `tr` only).\n> `TREE` expressions:\n> - any `SCRIPT` expression\n> - An open brace `{`, a `TREE` expression, a comma `,`, a `TREE` expression, and a closing brace `}`\n>\n> Note: \"miniscript templates\" are not formally defined in this version of the document, but it is straightforward to adapt this approach.\n>\n> `KP` expressions (key placeholders) consist of\n> - a single character `@`\n> - followed by a non-negative decimal number, with no leading zeros (except for `@0`).\n> - possibly followed by either:\n> - the string `/**`, or\n> - a string of the form `/<NUM;NUM>/*`, for two distinct decimal numbers `NUM` representing unhardened derivations\n>\n> The `/**` in the placeholder template represents commonly used paths for receive/change addresses, and is equivalent to `<0;1>`.\n>\n> The placeholder `@i` for some number *i* represents the *i*-th key in the vector of key origin information (which must be of size at least *i* + 1, or the wallet policy is invalid).\n>\n> ==== Key informations vector ====\n>\n> Each element of the key origin information vector is a `KEY` expression.\n>\n> - Optionally, key origin information, consisting of:\n> - An open bracket `[`\n> - Exactly 8 hex characters for the fingerprint of the master key from which this key is derived from (see [BIP32](https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki) for details)\n> - Followed by zero or more `/NUM'` path elements to indicate hardened derivation steps between the fingerprint and the xpub that follows\n> - A closing bracket `]`\n> - Followed by the actual key, which is either\n> - a hex-encoded pubkey, which is either\n> - inside `wpkh` and `wsh`, only compressed public keys are permitted (exactly 66 hex characters starting with `02` or `03`.\n> - inside `tr`, x-only pubkeys are also permitted (exactly 64 hex characters).\n> - a serialized extended public key (`xpub`) (as defined in [BIP 32](https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki))\n>\n> The placeholder `@i` for some number *i* represents the *i*-th key in the vector of key orIgin information (which must be of size at least *i* + 1, or the wallet policy is invalid).\n>\n> The policy template is invalid if any placeholder `@i` has derivation steps while the corresponding `(i+1)`-th element of the keys vector is not an xpub.\n>\n> ==== Additional rules ====\n> The wallet policy is invalid if any placeholder expression with additional derivation steps is used when the corresponding key information is not an xpub.\n>\n> The key information vector *should* be ordered so that placeholder `@i` never appear for the first time before an occurrence of `@j` for some `j < i`; for example, the first placeholder is always `@0`, the next one is `@1`, etc.\n>\n> === Descriptor derivation ===\n> From a wallet descriptor template (and the associated vector of key informations), one can therefore obtain the 1-dimensional descriptor for receive and change addresses by:\n>\n> - replacing each key placeholder with the corresponding key origin information;\n> - replacing every `/**` with `/0/*` for the receive descriptor, and `/1/*` for the change descriptor;\n> - replacing every `/<M,N>` with `/M` for the receive descriptor, and `/N` for the change descriptor.\n>\n> For example, the wallet descriptor `pkh(@0/**)` with key information `[\"[d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL\"]` produces the following two descriptors:\n>\n> - Receive descriptor: `pkh([d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL/0/*)`\n>\n> - Change descriptor: `pkh([d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL/1/*)`\n>\n> === Implementation guidelines ===\n> Implementations must not necessarily implement all of the possible wallet policies defined by this standard, but it is recommended to clearly document any limitation.\n>\n> Implementations can add additional metadata that is stored together with the wallet policy for the purpose of wallet policy registration and later usage. Metadata can be vendor-specific and is out of the scope of this document.\n>\n> Any implementation in a general-purpose software wallet allowing arbitrary scripts (or any scripts that involve external cosigners) should put great care into a process for backing up a wallet policy. In fact, unlike typical single-signature scenarios, the seed alone is no longer enough to discover wallet policies with existing funds, and the loss of the backup is likely to lead to permanent loss of funds.\n>\n> Avoiding key reuse among different wallet accounts is also extremely important, but out of scope for this document.\n>\n> == Examples ==\n>\n> Some examples of wallet descriptor templates (vectors of keys omitted for simplicity):- Template for a native segwit account:wpkh(@0/**)\n> - Template for a taproot BIP86 account:tr(@0/**)\n> - Template for a native segwit 2-of-3:wsh(sortedmulti(2, at 0/**, at 1/**, at 2/**))- Template with miniscript for \"1 of 2 equally likely keys\":wsh(or_b(pk(@0/**),s:pk(@1/**)))\n> More examples (esp. targeting miniscript on taproot) will be added in the future.\n> == References ==\n>\n> * [1] - Output Script Descriptors: https://github.com/bitcoin/bitcoin/blob/master/doc/descriptors.md* [2] - BIP-129 (Bitcoin Secure Multisig Setup): https://github.com/bitcoin/bips/blob/master/bip-0129.mediawiki\n> * [3] - BIP-44: https://github.com/bitcoin/bips/blob/master/bip-0044.mediawiki* [4] - BIP-49: https://github.com/bitcoin/bips/blob/master/bip-0049.mediawiki* [5] - BIP-84: https://github.com/bitcoin/bips/blob/master/bip-0084.mediawiki* [6] - BIP-86: https://github.com/bitcoin/bips/blob/master/bip-0086.mediawiki* [7] - BIP-48: https://github.com/bitcoin/bips/blob/master/bip-0048.mediawiki* [8] - BIP-87: https://github.com/bitcoin/bips/blob/master/bip-0087.mediawiki"
            },
            {
                "author": "Salvatore Ingala",
                "date": "2022-05-10T09:37:26",
                "message_text_only": "Hi Antoine and Billy,\n\nThank you for your comments and for looking into the proposal.\n\nOn Mon, 9 May 2022 at 12:36, darosior <darosior at protonmail.com> wrote:\n\n> 1. The `<NUM;NUM>` optimization for the common usecase of using 2\n> descriptors at different derivation indices\n>    for receive and change. [1]\n> 2. The `/**` optimization for the common usecase of `/<0;1>` for point 1).\n>\n> [...]\n>\n> I'm not so sure about the second point. Is another deviation from the\n> standard worth it just for saving 3\n> characters?\n>\n\nI agree with the concerns of both you and Billy on the `\\**` syntax, and it\nis certainly not a crucial part of the proposal, as it is arguably\nredundant once `\\<0;1>` is available.\nI have been using it since before the `\\<0;1>` syntax was proposed (afaik),\nand I thought I would leave it mostly for the sake of optimizing the UX in\nthe most common use cases. I think that\n\n    sh(sortedmulti(2, at 0/**, at 1/**, at 2/**))\n\nis quite a lot more readable (especially on a small screen) than\n\n    sh(sortedmulti(2, at 0/<0;1>/*, at 1/<0;1>/*, at 2/<0;1>/*))\n\nApart from the additional 5 characters *per placeholder*, there are a lot\nmore numbers to parse for the user.\n\nYet, I'm not too attached to the feature as it is probably not very useful\nin taptrees. For the future, I expect further improvements will come from\nthe hardware wallets analyzing the wallet policy and recognizing the\ncommonly used patterns. No reason to show the full taptree of a complex\n3-of-5 multisig setup \u2212 you can just say \"Taproot 3-of-5 multisig\". Show\nthe full taptree policy should be reserved for the 1% of advanced use-cases\nthat are not in the catalogue.\n\nSlightly off-topic, but my impression is that descriptors are outgrowing\ntheir original scope (probably the reason for sipa's comments[1] on the\nearly proposals for multiple derivation paths in one descriptor).\nI think there is a case to be made for keeping the language of descriptors\nlimited to represent either (1) a single output, or (2) a list of outputs\nwith the `/*` syntax; in this interpretation, the `/<m;n>` syntax would\nentirely be on a separate layer (the `combo` descriptor[2] would also be\nextraneous in this interpretation).\nI tried to design the policy wallet language in a way that is agnostic to\nthese details of descriptor specs (since I target a _subset_ of\ndescriptors, it will work either way).\n\nHowever, why does it need to be a change to the descriptor language? It\n> looks a lot like something that needs\n> to be handled at the application level with key aliasing.\n\n\nKey aliasing is not part of descriptors; therefore, \"descriptors with key\naliasing\" are still a language on top of descriptors.\n\nAdding key aliases will indeed be a great UX improvement, but in my opinion\nit is better built on top of wallet policies, rather than within the\nlanguage itself.\nNote that by separating the *wallet descriptor template* from the keys\nthemselves, such a feature is already facilitated. Moreover, wallet\npolicies separate the KEY expressions of descriptors into two semantically\nrelevant parts: only the xpub and its origin info goes into the \"vector of\nkey information\", while the receive/change part of the derivation is kept\nin the placeholder (therefore in the descriptor template). Adding\nrestrictions is also useful: `xpub/1/2/3/4/<0;1>/5/6/*` might be valid\nminiscript, but supporting this kind of thing would be (arguably)\nunreasonable and a lot more complicated for hardware wallets; therefore,\nplaceholders and key informations are a lot more limited in the wallet\npolicy language than their miniscript counterpart.\n\nWhile I understand that descriptors are designed with a maximum flexibility\nmindset, a minimized feature set is very valuable for hardware wallets, and\nI believe it can be done with little to no practical loss of use cases.\nRestrictions can be lifted in future versions when the need arises.\n\nI think to better suit the needs of both hardware and software wallets, you\nneed both the *extensions* and the *restrictions*. That's why I propose to\nkeep them separated, rather than suggesting changes to descriptors.\n\nUnrelated question, since you mentioned `musig2` descriptors in this\n> context. I thought Musig2 wasn't really\n> feasible for hardware signing devices, especially stateless ones. Do you\n> think/know whether it is actually\n> possible for a HW to take part in a Musig2?\n>\n\nI certainly have some more homework to do on musig2, and for this proposal\nI was only concerned with making sure the wallet policy language won't\nbreak with future upgrades to descriptors.\nYet, as far as I understand , the complications for hardware wallets are\n(1) possible lack of good quality randomness, and (2) need to keep state\nduring a signing session. Ledger signers have a hardware TRNG, and while\nthe design is generally stateless, there is flash memory that can be used\nto store the secret nonce during a signing session (or, more likely, a few\nparallel signing sessions). Therefore, I don't think there are technical\nblockers for musig2.\n\nSalvatore\n\n\n[1] https://github.com/bitcoin/bitcoin/issues/17190#issuecomment-543845642\n[2] https://github.com/bitcoin/bips/blob/master/bip-0384.mediawiki\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220510/98ebf626/attachment.html>"
            },
            {
                "author": "Salvatore Ingala",
                "date": "2022-05-17T08:44:53",
                "message_text_only": "Hi all,\n\nTL;DR: It is easy to convert from wallet policy to descriptors and back;\nimho aliases are better left out of descriptors in real world usage; some\nmore examples given.\n\nI received some very useful feedback on the wallet policy proposal (in this\nlist and outside); that also led me to realize that my initial post lacked\nsome clarity and more practical examples.\n\nThis post wants to:\n- clarify that extracting descriptors from the wallet policy is trivial;\n- argue that figuring out the wallet policy (template and list of keys\ninformation) from the descriptor is reasonably easy \u2212 automatable for sane\ndescriptors currently in use, and much more general ones as well;\n- give an idea of what the information shown on a hardware wallet screen\nwould look like (emphasizing compactness);\n- explain my point of view on \"descriptors with aliases\".\n\nThis gist demoes conversions from wallet policies to descriptors, and back:\nhttps://gist.github.com/bigspider/10df51401be3aa6120217c03c2836ffa\n\nNote that I would expect/hope software wallets to prefer working directly\nwith wallet policies \u2212 but it might help to have automated tools for the\nconversion, for interoperability with tools that do not adopt wallet\npolicies.\n\n(All the following examples use the `/**` notation as a shortcut for\n`/<0,1>/*`; this notation might be dropped without consequences on the rest\nof the proposal.)\n\nAll the keys in the example I'm proposing are followed by /**. It is\nunclear to me if hardware wallets should allow *registration* of wallet\npolicies with static keys (that is, without any range operator), as that\nwould incentivize key reuse. The specs still support it as there might be\nother use cases.\n\nThe policy for miniscript examples not using taproot was generated with the\nonline compiler: https://bitcoin.sipa.be/miniscript. Many examples are also\nborrowed from there.\n(To the best of my knowledge, there is no publicly released compiler for\nminiscript on taproot, yet)\n\nNote on aliases: it has been pointed out that many miniscript\nimplementations internally use aliases to refer to the keys. In my opinion,\naliases:\n- should be external to the descriptor language, as they bear no\nsignificance for the actual script(s) that the descriptor can produce\n- fail to distinguish which part of the KEY expression is part of the\n\"wallet description\", and which part is not\n\nBy clearly separating the key information in the vector (typically, an xpub\nwith key origin information) from the key placeholder expression (which\ntypically will have the `/**` or `/<0,1>/*` derivation step), wallet\npolicies semantically represent keys in a way that should be convenient to\nboth software wallets and hardware signers.\n\nAssociating recognizable names to the xpubs (and registering them on the\ndevice) is a good idea for future developments and can greatly improve the\nUX, both during wallet setup, or in recognizing outputs for repeated\npayments; it should be easy to build this feature on top of wallet policies.\n\n== Examples ==\n\nAll the examples show:\n- Miniscript policy: semantic spending rules, and optimization hints (can\nbe compiled to miniscript automatically)\n- Miniscript: the actual miniscript descriptor, compiles 1-to-1 to Bitcoin\nScript\n- Wallet template: the \"wallet descriptor template\"\n- Vector of keys: the list of key information (with key origin information)\n\nTogether, the wallet template and the vector of keys are the complet\n\"wallet policy\".\n\n=== Example 1: Either of two keys (equally likely) ===\n\nMiniscript policy: or(pk(key_0),pk(key_1))\nMiniscript:\n wsh(or_b([d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL/<0;1>/*),s:pk([12345678/44'/0'/0']xpub661MyMwAqRbcFW31YEwpkMuc5THy2PSt5bDMsktWQcFF8syAmRUapSCGu8ED9W6oDMSgv6Zz8idoc4a6mr8BDzTJY47LJhkJ8UB7WEGuduB/<0;1>/*)))\n\nDescriptor template:   wsh(or_b(pk(@0/**),s:pk(@1/**)))\nVector of keys: [\n\n\"[d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL\",\n\n\"[12345678/44'/0'/0']xpub661MyMwAqRbcFW31YEwpkMuc5THy2PSt5bDMsktWQcFF8syAmRUapSCGu8ED9W6oDMSgv6Zz8idoc4a6mr8BDzTJY47LJhkJ8UB7WEGuduB\"\n]\n\nIn all the following examples, I will replace the xpubs with aliases in the\nminiscript for brevity, and omit the corresponding vector of keys in the\nwallet policy.\n\nOf course, in comparing the \"information density\" (especially for UX\npurposes), it is important to take the full descriptor into account.\nIt is always to be assumed that the keys are xpubs, complete with key\norigin information if internal (that is, controlled by the software or\nhardware signer that the wallet policy is being with).\n\n=== Example 2: Either of two keys, but one is more likely ===\n\nMiniscript policy: or(99 at pk(key_likely),pk(key_unlikely))\nMiniscript:           wsh(or_d(pk(key_likely),pkh(key_unlikely)))\n\nDescriptor template: wsh(or_d(pk(@0/**),pkh(@1/**)))\nVector of keys:         <omitted>\n\n=== Example 3: A 3-of-3 that turns into a 2-of-3 after 90 days ===\n\nMiniscript policy: thresh(3,pk(key_0),pk(key_1),pk(key_2),older(12960))\nMiniscript:\n wsh(thresh(3,pk(key_0),s:pk(key_1),s:pk(key_2),sln:older(12960)))\n\nDescriptor template:\nwsh(thresh(3,pk(@0/**),s:pk(@1/**),s:pk(@2/**),sln:older(12960)))))\nVector of keys:         <omitted>\n\n=== Example 4: The BOLT #3 received HTLC policy ===\n\nMiniscript policy:\nandor(pk(key_remote),or_i(and_v(v:pkh(key_local),hash160(395e368b267d64945f30e4b71de1054f364c9473)),older(1008)),pk(key_revocation))\nMiniscript:\n wsh(andor(pk(key_remote),or_i(and_v(v:pkh(key_local),hash160(395e368b267d64945f30e4b71de1054f364c9473)),older(1008)),pk(key_revocation)))\n\nDescriptor template:\nwsh(andor(pk(@0/**),or_i(and_v(v:pkh(@1/**),hash160(395e368b267d64945f30e4b71de1054f364c9473)),older(1008)),pk(@2/**)))\nVector of keys:          <omitted>\n\n=== Example 5: Taproot complex script (2-of-2 with cold backup and\ntimelocked inheritance) ===\n\nThe likely path is a 2-of-2 of a hot_key and a cosigner_key (2FA-like\nservice). At any time, a cold_key can be used for signing, and after about\na year, a separate timelocked_key becomes active (for example, to a notary\nfor inheritance purposes).\nThe timelock is reset every time UTXOs are spent.\n\nMiniscript policy: or(99 at thresh(2,pk(hot_key),pk(cosigner_key)),1 at or(99 at pk\n(cold_key),1 at and(pk(timelocked_key),older(52596))))\nMiniscript:\n tr(cold_key,{and_v(v:pk(timelocked_key),older(52596)),multi_a(2,hot_key,cosigner_key)})\n\nDescriptor template:\ntr(@0/**,{and_v(v:pk(@1/**),older(52596)),multi_a(2, at 2/**, at 3/**)})\nVector of keys:          <omitted>\n\n=== Example 6: Taproot complex script with MuSig2 ===\n\nThe same policy as above, but we assume that the hot wallet and the\ncosigner are able to engage in the MuSig2 protocol.\nThis greatly exemplifies the practical advantage of MuSig2 with taproot in\nterms of both transaction cost and privacy.\n\nMiniscript policy: or(99 at musig2(hot_key,cosigner_key),1 at or(99 at pk\n(cold_key),1 at and(pk(timelocked_key),older(52596))))\nMiniscript:\n tr(musig2(hot_key,cosigner_key),{and_v(v:pk(timelocked_key),older(52596)),pk(cold_key)})\n\nDescriptor template:\ntr(musig2(@0, at 1)/**,{and_v(v:pk(@2/**),older(52596)),pk(@3/**)})\nVector of keys:         <omitted>. Note: the order of keys differs from the\nprevious example.\n\n\n\nSalvatore Ingala\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220517/94538dab/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Wallet policies for descriptor wallets",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Salvatore Ingala",
                "darosior",
                "Billy Tetrud"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 71642
        }
    },
    {
        "title": "[bitcoin-dev] Speedy covenants (OP_CAT2)",
        "thread_messages": [
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2022-05-06T22:30:01",
                "message_text_only": "OP_CAT was removed. If I remember correctly, some speculated that perhaps\nit was removed because it could allow covenants.\nI don't remember any technical concern about the OP besides enabling\ncovenants.\nBefore it was a common opinion that covenants shouldn't be enabled in\nbitcoin because, despite having good use case, there are some nasty attacks\nthat are enabled with them too. These days it seems the opinion of the\nbenefits being worth the dangers is quite generalized. Which is quite\nunderstandable given that more use cases have been thought since then.\n\nRe-enabling OP_CAT with the exact same OP would be a hardfork, but creating\na new OP_CAT2 that does the same would be a softfork.\nAs far a I know, this is the covenants proposal that has been implemented\nfor the longest time, if that's to be used as a selection criteria.\nAnd as always, this is not incompatible with deploying other convenant\nproposals later.\nPersonally I find the simplicity proposal the best one among all the\ncovenant proposals by far, including this one.\nBut I understand that despite the name, the proposal is harder to review\nand test than other proposals, for it wouldn't simply add covenants, but a\ncomplete new scripting language that is better in many senses.\nSpeedy covenants, on the other hand, is much simpler and has been\nimplemented for longer, so in principle, it should be easier to deploy in a\nspeedy manner.\n\nWhat are the main arguments against speedy covenants (aka op_cat2) and\nagainst deploying simplicity in bitcoin respectively?\n\nSorry if this was discussed before.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220507/2bd47223/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-07T03:06:23",
                "message_text_only": "Good morning Jorge,\n\n> OP_CAT was removed. If I remember correctly, some speculated that perhaps it was removed because it could allow covenants.I don't remember any technical concern about the OP besides enabling covenants.Before it was a common opinion that covenants shouldn't be enabled in bitcoin because, despite having good use case, there are some nasty attacks that are enabled with them too. These days it seems the opinion of the benefits being worth the dangers is quite generalized. Which is quite understandable given that more use cases have been thought since then.\n\nI think the more accurate reason for why it was removed is because the following SCRIPT of N size would lead to 2^N memory usage:\n\n    OP_1 OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT ...\n\nIn particular it was removed at about the same time as `OP_MUL`, which has similar behavior (consider that multiplying two 32-bit numbers results in a 64-bit number, similar to `OP_CAT`ting a vector to itself).\n\n`OP_CAT` was removed long before covenants were even expressed as a possibility.\n\nCovenants were first expressed as a possibility, I believe, during discussions around P2SH.\nBasically, at the time, the problem was this:\n\n* Some receivers wanted to use k-of-n multisignature for improved security.\n* The only way to implement this, pre-P2SH, was by putting in the `scriptPubKey` all the public keys.\n* The sender is the one paying for the size of the `scriptPubKey`.\n* It was considered unfair that the sender is paying for the security of the receiver.\n\nThus, `OP_EVAL` and the P2SH concept was conceived.\nInstead of the `scriptPubKey` containing the k-of-n multisignature, you create a separate script containing the public keys, then hash it, and the `scriptPubKey` would contain the hash of the script.\nBy symmetry with the P2PKH template:\n\n    OP_DUP OP_HASH160 <hash160(pubkey)> OP_EQUALVERIFY OP_CHECKSIG\n\nThe P2SH template would be:\n\n    OP_DUP OP_HASH160 <hash160(redeemScript)> OP_EQUALVERIFY OP_EVAL\n\n`OP_EVAL` would take the stack top vector and treat it as a Bitcoin SCRIPT.\n\nIt was then pointed out that `OP_EVAL` could be used to create recursive SCRIPTs by quining using `OP_CAT`.\n`OP_CAT` was already disabled by then, but people were talking about re-enabling it somehow by restricting the output size of `OP_CAT` to limit the O(2^N) behavior.\n\nThus, since then, `OP_CAT` has been associated with ***recursive*** covenants (and people are now reluctant to re-enable it even with a limit on its output size, because recursive covenants).\nIn particular, `OP_CAT` in combination with `OP_CHECKSIGFROMSTACK` and `OP_CHECKSIG`, you could get a deferred `OP_EVAL` and then use `OP_CAT` too to quine.\n\nBecause of those concerns, the modern P2SH is now \"just a template\" with an implicit `OP_EVAL` of the `redeemScript`, but without any `OP_EVAL` being actually enabled.\n\n(`OP_EVAL` cannot replace an `OP_NOP` in a softfork, but it is helpful to remember that P2SH was pretty much what codified the difference between softfork and hardfork, and the community at the time was small enough (or so it seemed) that a hardfork might not have been disruptive.)\n\n> Re-enabling OP_CAT with the exact same OP would be a hardfork, but creating a new OP_CAT2 that does the same would be a softfork.\n\nIf you are willing to work in Taproot the same OP-code can be enabled in a softfork by using a new Tapscript version.\n\nIf you worry about quantum-computing-break, a new SegWit version (which is more limited than Tapscript versions, unfortunately) can also be used, creating a new P2WSHv2 (or whatever version) that enables these opcodes.\n\n> As far a I know, this is the covenants proposal that has been implemented for the longest time, if that's to be used as a selection criteria.And as always, this is not incompatible with deploying other convenant proposals later.\n\nNo, it was `OP_EVAL`, not `OP_CAT`.\nIn particular if `OP_EVAL` was allowed in the `redeemScript` then it would enable covenants as well.\nIt was just pointed out that `OP_CAT` enables recursive covenenats in combination with `OP_EVAL`-in-`redeemScript`.\n\nIn particular, in combination with `OP_CAT`, `OP_EVAL` not only allows recursive covenants, but also recursion *within* a SCRIPT i.e. unbounded SCRIPT execution.\nThus, `OP_EVAL` is simply not going to fly, at all.\n\n> Personally I find the simplicity proposal the best one among all the covenant proposals by far, including this one.But I understand that despite the name, the proposal is harder to review and test than other proposals, for it wouldn't simply add covenants, but a complete new scripting language that is better in many senses.Speedy covenants, on the other hand, is much simpler and has been implemented for longer, so in principle, it should be easier to deploy in a speedy manner.\n>\n> What are the main arguments against speedy covenants (aka op_cat2) and against deploying simplicity in bitcoin respectively?\n> Sorry if this was discussed before.\n\n`OP_CAT`, by itself, does not implement any covenants --- instead, it creates recursive covenants when combined with almost all covenant opcodes.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "vjudeu at gazeta.pl",
                "date": "2022-05-07T03:52:48",
                "message_text_only": "> Re-enabling OP_CAT with the exact same OP would be a hardfork, but creating a new OP_CAT2 that does the same would be a softfork.\n\nWe have TapScript for that. OP_CAT is defined as OP_SUCCESS, it can be re-enabled in a soft-fork way. For now, OP_CAT in TapScript simply means \"anyone can move those coins\", so adding some restrictions is all we need to re-enable this opcode. Introducing OP_CAT2 is not needed at all, unless it will be totally different, but then it should not be named as OP_CAT2, but rather as OP_SOMETHING_ELSE, it depends how different it will be from OP_CAT.\n\n> OP_1 OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT ...\n\nSo we can use OP_SUBSTR instead. Maybe even OP_SPLIT will be enough, if data expansion is the only problem, then we can focus on getting it smaller. Or better, we could use OP_FIND that would return true/false answer if element A is a part of element B, when we do byte-to-byte comparison. In general, we can use many different string-based functions to do the same things, we can choose something that will not exponentially explode as OP_CAT.\n\n> It was considered unfair that the sender is paying for the security of the receiver.\n\nIt can be changed by using different sighashes, for example, it is possible to create a \"negative fee transaction\", where all transaction costs are paid by receiver. Using SIGHASH_SINGLE | SIGHASH_ANYONECANPAY with a higher amount in outputs than inputs is enough to do that, see testnet3 transaction 495d2007ae8b741c70c3d278c02ce03702223b9675e954ecabbb634c6cd5bf40.\n\nOn 2022-05-07 05:06:46 user ZmnSCPxj via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Good morning Jorge,\n\n> OP_CAT was removed. If I remember correctly, some speculated that perhaps it was removed because it could allow covenants.I don't remember any technical concern about the OP besides enabling covenants.Before it was a common opinion that covenants shouldn't be enabled in bitcoin because, despite having good use case, there are some nasty attacks that are enabled with them too. These days it seems the opinion of the benefits being worth the dangers is quite generalized. Which is quite understandable given that more use cases have been thought since then.\n\nI think the more accurate reason for why it was removed is because the following SCRIPT of N size would lead to 2^N memory usage:\n\n    OP_1 OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT ...\n\nIn particular it was removed at about the same time as `OP_MUL`, which has similar behavior (consider that multiplying two 32-bit numbers results in a 64-bit number, similar to `OP_CAT`ting a vector to itself).\n\n`OP_CAT` was removed long before covenants were even expressed as a possibility.\n\nCovenants were first expressed as a possibility, I believe, during discussions around P2SH.\nBasically, at the time, the problem was this:\n\n* Some receivers wanted to use k-of-n multisignature for improved security.\n* The only way to implement this, pre-P2SH, was by putting in the `scriptPubKey` all the public keys.\n* The sender is the one paying for the size of the `scriptPubKey`.\n* It was considered unfair that the sender is paying for the security of the receiver.\n\nThus, `OP_EVAL` and the P2SH concept was conceived.\nInstead of the `scriptPubKey` containing the k-of-n multisignature, you create a separate script containing the public keys, then hash it, and the `scriptPubKey` would contain the hash of the script.\nBy symmetry with the P2PKH template:\n\n    OP_DUP OP_HASH160 <hash160(pubkey)> OP_EQUALVERIFY OP_CHECKSIG\n\nThe P2SH template would be:\n\n    OP_DUP OP_HASH160 <hash160(redeemScript)> OP_EQUALVERIFY OP_EVAL\n\n`OP_EVAL` would take the stack top vector and treat it as a Bitcoin SCRIPT.\n\nIt was then pointed out that `OP_EVAL` could be used to create recursive SCRIPTs by quining using `OP_CAT`.\n`OP_CAT` was already disabled by then, but people were talking about re-enabling it somehow by restricting the output size of `OP_CAT` to limit the O(2^N) behavior.\n\nThus, since then, `OP_CAT` has been associated with ***recursive*** covenants (and people are now reluctant to re-enable it even with a limit on its output size, because recursive covenants).\nIn particular, `OP_CAT` in combination with `OP_CHECKSIGFROMSTACK` and `OP_CHECKSIG`, you could get a deferred `OP_EVAL` and then use `OP_CAT` too to quine.\n\nBecause of those concerns, the modern P2SH is now \"just a template\" with an implicit `OP_EVAL` of the `redeemScript`, but without any `OP_EVAL` being actually enabled.\n\n(`OP_EVAL` cannot replace an `OP_NOP` in a softfork, but it is helpful to remember that P2SH was pretty much what codified the difference between softfork and hardfork, and the community at the time was small enough (or so it seemed) that a hardfork might not have been disruptive.)\n\n> Re-enabling OP_CAT with the exact same OP would be a hardfork, but creating a new OP_CAT2 that does the same would be a softfork.\n\nIf you are willing to work in Taproot the same OP-code can be enabled in a softfork by using a new Tapscript version.\n\nIf you worry about quantum-computing-break, a new SegWit version (which is more limited than Tapscript versions, unfortunately) can also be used, creating a new P2WSHv2 (or whatever version) that enables these opcodes.\n\n> As far a I know, this is the covenants proposal that has been implemented for the longest time, if that's to be used as a selection criteria.And as always, this is not incompatible with deploying other convenant proposals later.\n\nNo, it was `OP_EVAL`, not `OP_CAT`.\nIn particular if `OP_EVAL` was allowed in the `redeemScript` then it would enable covenants as well.\nIt was just pointed out that `OP_CAT` enables recursive covenenats in combination with `OP_EVAL`-in-`redeemScript`.\n\nIn particular, in combination with `OP_CAT`, `OP_EVAL` not only allows recursive covenants, but also recursion *within* a SCRIPT i.e. unbounded SCRIPT execution.\nThus, `OP_EVAL` is simply not going to fly, at all.\n\n> Personally I find the simplicity proposal the best one among all the covenant proposals by far, including this one.But I understand that despite the name, the proposal is harder to review and test than other proposals, for it wouldn't simply add covenants, but a complete new scripting language that is better in many senses.Speedy covenants, on the other hand, is much simpler and has been implemented for longer, so in principle, it should be easier to deploy in a speedy manner.\n>\n> What are the main arguments against speedy covenants (aka op_cat2) and against deploying simplicity in bitcoin respectively?\n> Sorry if this was discussed before.\n\n`OP_CAT`, by itself, does not implement any covenants --- instead, it creates recursive covenants when combined with almost all covenant opcodes.\n\nRegards,\nZmnSCPxj\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2022-05-07T13:31:27",
                "message_text_only": "On Sat, May 7, 2022 at 5:52 AM <vjudeu at gazeta.pl> wrote:\n\n> > Re-enabling OP_CAT with the exact same OP would be a hardfork, but\n> creating a new OP_CAT2 that does the same would be a softfork.\n>\n> We have TapScript for that. OP_CAT is defined as OP_SUCCESS, it can be\n> re-enabled in a soft-fork way. For now, OP_CAT in TapScript simply means\n> \"anyone can move those coins\", so adding some restrictions is all we need\n> to re-enable this opcode. Introducing OP_CAT2 is not needed at all, unless\n> it will be totally different, but then it should not be named as OP_CAT2,\n> but rather as OP_SOMETHING_ELSE, it depends how different it will be from\n> OP_CAT.\n>\n\nOh, well, I didn't know any of that. I guess it could be a modification of\nOP_SUCCESS if it makes sense instead of a new opcode.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220507/6b3c1b24/attachment.html>"
            },
            {
                "author": "alicexbt",
                "date": "2022-05-11T15:25:31",
                "message_text_only": "Hi vjudeu,\n\n> It can be changed by using different sighashes, for example, it is possible to create a \"negative fee transaction\", where all transaction costs are paid by receiver. Using SIGHASH_SINGLE | SIGHASH_ANYONECANPAY with a higher amount in outputs than inputs is enough to do that, see testnet3 transaction 495d2007ae8b741c70c3d278c02ce03702223b9675e954ecabbb634c6cd5bf40.\n\nThis transaction has 2 inputs: 0.00074 tBTC and 0.00073 tBTC (0.00074 + 0.00073 = 0.00147) which is more than output amount 0.001 tBTC\n\n/dev/fd0\n\nSent with [ProtonMail](https://protonmail.com/) secure email.\n------- Original Message -------\nOn Saturday, May 7th, 2022 at 9:22 AM, vjudeu via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:\n\n>> Re-enabling OP_CAT with the exact same OP would be a hardfork, but creating a new OP_CAT2 that does the same would be a softfork.\n>\n> We have TapScript for that. OP_CAT is defined as OP_SUCCESS, it can be re-enabled in a soft-fork way. For now, OP_CAT in TapScript simply means \"anyone can move those coins\", so adding some restrictions is all we need to re-enable this opcode. Introducing OP_CAT2 is not needed at all, unless it will be totally different, but then it should not be named as OP_CAT2, but rather as OP_SOMETHING_ELSE, it depends how different it will be from OP_CAT.\n>\n>> OP_1 OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT ...\n>\n> So we can use OP_SUBSTR instead. Maybe even OP_SPLIT will be enough, if data expansion is the only problem, then we can focus on getting it smaller. Or better, we could use OP_FIND that would return true/false answer if element A is a part of element B, when we do byte-to-byte comparison. In general, we can use many different string-based functions to do the same things, we can choose something that will not exponentially explode as OP_CAT.\n>\n>> It was considered unfair that the sender is paying for the security of the receiver.\n>\n> It can be changed by using different sighashes, for example, it is possible to create a \"negative fee transaction\", where all transaction costs are paid by receiver. Using SIGHASH_SINGLE | SIGHASH_ANYONECANPAY with a higher amount in outputs than inputs is enough to do that, see testnet3 transaction 495d2007ae8b741c70c3d278c02ce03702223b9675e954ecabbb634c6cd5bf40.\n>\n> On 2022-05-07 05:06:46 user ZmnSCPxj via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:\n>\n>> Good morning Jorge,\n>\n>> OP_CAT was removed. If I remember correctly, some speculated that perhaps it was removed because it could allow covenants.I don't remember any technical concern about the OP besides enabling covenants.Before it was a common opinion that covenants shouldn't be enabled in bitcoin because, despite having good use case, there are some nasty attacks that are enabled with them too. These days it seems the opinion of the benefits being worth the dangers is quite generalized. Which is quite understandable given that more use cases have been thought since then.\n>\n> I think the more accurate reason for why it was removed is because the following SCRIPT of N size would lead to 2^N memory usage:\n>\n> OP_1 OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT ...\n>\n> In particular it was removed at about the same time as OP_MUL, which has similar behavior (consider that multiplying two 32-bit numbers results in a 64-bit number, similar to OP_CATting a vector to itself).\n>\n> OP_CAT was removed long before covenants were even expressed as a possibility.\n>\n> Covenants were first expressed as a possibility, I believe, during discussions around P2SH.\n> Basically, at the time, the problem was this:\n>\n> * Some receivers wanted to use k-of-n multisignature for improved security.\n> * The only way to implement this, pre-P2SH, was by putting in the scriptPubKey all the public keys.\n> * The sender is the one paying for the size of the scriptPubKey.\n> * It was considered unfair that the sender is paying for the security of the receiver.\n>\n> Thus, OP_EVAL and the P2SH concept was conceived.\n> Instead of the scriptPubKey containing the k-of-n multisignature, you create a separate script containing the public keys, then hash it, and the scriptPubKey would contain the hash of the script.\n> By symmetry with the P2PKH template:\n>\n> OP_DUP OP_HASH160 <hash160(pubkey)> OP_EQUALVERIFY OP_CHECKSIG\n>\n> The P2SH template would be:\n>\n> OP_DUP OP_HASH160 <hash160(redeemScript)> OP_EQUALVERIFY OP_EVAL\n>\n> OP_EVAL would take the stack top vector and treat it as a Bitcoin SCRIPT.\n>\n> It was then pointed out that OP_EVAL could be used to create recursive SCRIPTs by quining using OP_CAT.\n> OP_CAT was already disabled by then, but people were talking about re-enabling it somehow by restricting the output size of OP_CAT to limit the O(2^N) behavior.\n>\n> Thus, since then, OP_CAT has been associated with recursive covenants (and people are now reluctant to re-enable it even with a limit on its output size, because recursive covenants).\n> In particular, OP_CAT in combination with OP_CHECKSIGFROMSTACK and OP_CHECKSIG, you could get a deferred OP_EVAL and then use OP_CAT too to quine.\n>\n> Because of those concerns, the modern P2SH is now \"just a template\" with an implicit OP_EVAL of the redeemScript, but without any OP_EVAL being actually enabled.\n>\n> (OP_EVAL cannot replace an OP_NOP in a softfork, but it is helpful to remember that P2SH was pretty much what codified the difference between softfork and hardfork, and the community at the time was small enough (or so it seemed) that a hardfork might not have been disruptive.)\n>\n>> Re-enabling OP_CAT with the exact same OP would be a hardfork, but creating a new OP_CAT2 that does the same would be a softfork.\n>\n> If you are willing to work in Taproot the same OP-code can be enabled in a softfork by using a new Tapscript version.\n>\n> If you worry about quantum-computing-break, a new SegWit version (which is more limited than Tapscript versions, unfortunately) can also be used, creating a new P2WSHv2 (or whatever version) that enables these opcodes.\n>\n>> As far a I know, this is the covenants proposal that has been implemented for the longest time, if that's to be used as a selection criteria.And as always, this is not incompatible with deploying other convenant proposals later.\n>\n> No, it was OP_EVAL, not OP_CAT.\n> In particular if OP_EVAL was allowed in the redeemScript then it would enable covenants as well.\n> It was just pointed out that OP_CAT enables recursive covenenats in combination with OP_EVAL-in-redeemScript.\n>\n> In particular, in combination with OP_CAT, OP_EVAL not only allows recursive covenants, but also recursion within a SCRIPT i.e. unbounded SCRIPT execution.\n> Thus, OP_EVAL is simply not going to fly, at all.\n>\n>> Personally I find the simplicity proposal the best one among all the covenant proposals by far, including this one.But I understand that despite the name, the proposal is harder to review and test than other proposals, for it wouldn't simply add covenants, but a complete new scripting language that is better in many senses.Speedy covenants, on the other hand, is much simpler and has been implemented for longer, so in principle, it should be easier to deploy in a speedy manner.\n>>\n>> What are the main arguments against speedy covenants (aka op_cat2) and against deploying simplicity in bitcoin respectively?\n>> Sorry if this was discussed before.\n>\n> OP_CAT, by itself, does not implement any covenants --- instead, it creates recursive covenants when combined with almost all covenant opcodes.\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220511/40c774ba/attachment-0001.html>"
            },
            {
                "author": "vjudeu at gazeta.pl",
                "date": "2022-05-11T16:03:25",
                "message_text_only": "> This transaction has 2 inputs: 0.00074 tBTC and 0.00073 tBTC (0.00074 + 0.00073 = 0.00147) which is more than output amount 0.001 tBTC\n\nIt was created without the second input, see: https://bitcointalk.org/index.php?topic=5390103.msg59616324#msg59616324\nI didn't touch that later, the signatures are the same. Some user named coinlatte just completed it: https://bitcointalk.org/index.php?topic=5390103.msg60029953#msg60029953\n\n\nOn 2022-05-11 17:25:41 user alicexbt <alicexbt at protonmail.com> wrote:\n\nHi vjudeu,\n\nIt can be changed by using different sighashes, for example, it is possible to create a \"negative fee transaction\", where all transaction costs are paid by receiver. Using SIGHASH_SINGLE | SIGHASH_ANYONECANPAY with a higher amount in outputs than inputs is enough to do that, see testnet3 transaction 495d2007ae8b741c70c3d278c02ce03702223b9675e954ecabbb634c6cd5bf40.\n\n\nThis transaction has 2 inputs: 0.00074 tBTC and 0.00073 tBTC (0.00074 +\u00a00.00073 = 0.00147)\u00a0which is more than output amount 0.001 tBTC\n\n\n/dev/fd0\n\n\n\n\n\nSent with ProtonMail secure email.\n\n------- Original Message -------\nOn Saturday, May 7th, 2022 at 9:22 AM, vjudeu via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:\n\n\n\n\n\n\n\nRe-enabling OP_CAT with the exact same OP would be a hardfork, but creating a new OP_CAT2 that does the same would be a softfork.\n\nWe have TapScript for that. OP_CAT is defined as OP_SUCCESS, it can be re-enabled in a soft-fork way. For now, OP_CAT in TapScript simply means \"anyone can move those coins\", so adding some restrictions is all we need to re-enable this opcode. Introducing OP_CAT2 is not needed at all, unless it will be totally different, but then it should not be named as OP_CAT2, but rather as OP_SOMETHING_ELSE, it depends how different it will be from OP_CAT.\n\nOP_1 OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT ...\n\nSo we can use OP_SUBSTR instead. Maybe even OP_SPLIT will be enough, if data expansion is the only problem, then we can focus on getting it smaller. Or better, we could use OP_FIND that would return true/false answer if element A is a part of element B, when we do byte-to-byte comparison. In general, we can use many different string-based functions to do the same things, we can choose something that will not exponentially explode as OP_CAT.\n\nIt was considered unfair that the sender is paying for the security of the receiver.\n\nIt can be changed by using different sighashes, for example, it is possible to create a \"negative fee transaction\", where all transaction costs are paid by receiver. Using SIGHASH_SINGLE | SIGHASH_ANYONECANPAY with a higher amount in outputs than inputs is enough to do that, see testnet3 transaction 495d2007ae8b741c70c3d278c02ce03702223b9675e954ecabbb634c6cd5bf40.\n\nOn 2022-05-07 05:06:46 user ZmnSCPxj via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:\n\nGood morning Jorge,\n\nOP_CAT was removed. If I remember correctly, some speculated that perhaps it was removed because it could allow covenants.I don't remember any technical concern about the OP besides enabling covenants.Before it was a common opinion that covenants shouldn't be enabled in bitcoin because, despite having good use case, there are some nasty attacks that are enabled with them too. These days it seems the opinion of the benefits being worth the dangers is quite generalized. Which is quite understandable given that more use cases have been thought since then.\n\nI think the more accurate reason for why it was removed is because the following SCRIPT of N size would lead to 2^N memory usage:\n\nOP_1 OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT ...\n\nIn particular it was removed at about the same time as OP_MUL, which has similar behavior (consider that multiplying two 32-bit numbers results in a 64-bit number, similar to OP_CATting a vector to itself).\n\nOP_CAT was removed long before covenants were even expressed as a possibility.\n\nCovenants were first expressed as a possibility, I believe, during discussions around P2SH.\nBasically, at the time, the problem was this:\n\n* Some receivers wanted to use k-of-n multisignature for improved security.\n* The only way to implement this, pre-P2SH, was by putting in the scriptPubKey all the public keys.\n* The sender is the one paying for the size of the scriptPubKey.\n* It was considered unfair that the sender is paying for the security of the receiver.\n\nThus, OP_EVAL and the P2SH concept was conceived.\nInstead of the scriptPubKey containing the k-of-n multisignature, you create a separate script containing the public keys, then hash it, and the scriptPubKey would contain the hash of the script.\nBy symmetry with the P2PKH template:\n\nOP_DUP OP_HASH160 <hash160(pubkey)> OP_EQUALVERIFY OP_CHECKSIG\n\nThe P2SH template would be:\n\nOP_DUP OP_HASH160 <hash160(redeemScript)> OP_EQUALVERIFY OP_EVAL\n\nOP_EVAL would take the stack top vector and treat it as a Bitcoin SCRIPT.\n\nIt was then pointed out that OP_EVAL could be used to create recursive SCRIPTs by quining using OP_CAT.\nOP_CAT was already disabled by then, but people were talking about re-enabling it somehow by restricting the output size of OP_CAT to limit the O(2^N) behavior.\n\nThus, since then, OP_CAT has been associated with recursive covenants (and people are now reluctant to re-enable it even with a limit on its output size, because recursive covenants).\nIn particular, OP_CAT in combination with OP_CHECKSIGFROMSTACK and OP_CHECKSIG, you could get a deferred OP_EVAL and then use OP_CAT too to quine.\n\nBecause of those concerns, the modern P2SH is now \"just a template\" with an implicit OP_EVAL of the redeemScript, but without any OP_EVAL being actually enabled.\n\n(OP_EVAL cannot replace an OP_NOP in a softfork, but it is helpful to remember that P2SH was pretty much what codified the difference between softfork and hardfork, and the community at the time was small enough (or so it seemed) that a hardfork might not have been disruptive.)\n\nRe-enabling OP_CAT with the exact same OP would be a hardfork, but creating a new OP_CAT2 that does the same would be a softfork.\n\nIf you are willing to work in Taproot the same OP-code can be enabled in a softfork by using a new Tapscript version.\n\nIf you worry about quantum-computing-break, a new SegWit version (which is more limited than Tapscript versions, unfortunately) can also be used, creating a new P2WSHv2 (or whatever version) that enables these opcodes.\n\nAs far a I know, this is the covenants proposal that has been implemented for the longest time, if that's to be used as a selection criteria.And as always, this is not incompatible with deploying other convenant proposals later.\n\nNo, it was OP_EVAL, not OP_CAT.\nIn particular if OP_EVAL was allowed in the redeemScript then it would enable covenants as well.\nIt was just pointed out that OP_CAT enables recursive covenenats in combination with OP_EVAL-in-redeemScript.\n\nIn particular, in combination with OP_CAT, OP_EVAL not only allows recursive covenants, but also recursion within a SCRIPT i.e. unbounded SCRIPT execution.\nThus, OP_EVAL is simply not going to fly, at all.\n\nPersonally I find the simplicity proposal the best one among all the covenant proposals by far, including this one.But I understand that despite the name, the proposal is harder to review and test than other proposals, for it wouldn't simply add covenants, but a complete new scripting language that is better in many senses.Speedy covenants, on the other hand, is much simpler and has been implemented for longer, so in principle, it should be easier to deploy in a speedy manner.\n\nWhat are the main arguments against speedy covenants (aka op_cat2) and against deploying simplicity in bitcoin respectively?\nSorry if this was discussed before.\n\nOP_CAT, by itself, does not implement any covenants --- instead, it creates recursive covenants when combined with almost all covenant opcodes.\n\nRegards,\nZmnSCPxj\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2022-05-07T13:27:16",
                "message_text_only": "Thanks a lot for the many clarifications.\nYeah, I forgot it wasn't OP_CAT alone, but in combination with other things.\nI guess this wouldn't be a covenants proposal then.\nBut simplicity would enable covenants too indeed, no?\nOr did I get that wrong too?\n\nOn Sat, May 7, 2022 at 5:06 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Jorge,\n>\n> > OP_CAT was removed. If I remember correctly, some speculated that\n> perhaps it was removed because it could allow covenants.I don't remember\n> any technical concern about the OP besides enabling covenants.Before it was\n> a common opinion that covenants shouldn't be enabled in bitcoin because,\n> despite having good use case, there are some nasty attacks that are enabled\n> with them too. These days it seems the opinion of the benefits being worth\n> the dangers is quite generalized. Which is quite understandable given that\n> more use cases have been thought since then.\n>\n> I think the more accurate reason for why it was removed is because the\n> following SCRIPT of N size would lead to 2^N memory usage:\n>\n>     OP_1 OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP OP_CAT OP_DUP\n> OP_CAT OP_DUP OP_CAT ...\n>\n> In particular it was removed at about the same time as `OP_MUL`, which has\n> similar behavior (consider that multiplying two 32-bit numbers results in a\n> 64-bit number, similar to `OP_CAT`ting a vector to itself).\n>\n> `OP_CAT` was removed long before covenants were even expressed as a\n> possibility.\n>\n> Covenants were first expressed as a possibility, I believe, during\n> discussions around P2SH.\n> Basically, at the time, the problem was this:\n>\n> * Some receivers wanted to use k-of-n multisignature for improved security.\n> * The only way to implement this, pre-P2SH, was by putting in the\n> `scriptPubKey` all the public keys.\n> * The sender is the one paying for the size of the `scriptPubKey`.\n> * It was considered unfair that the sender is paying for the security of\n> the receiver.\n>\n> Thus, `OP_EVAL` and the P2SH concept was conceived.\n> Instead of the `scriptPubKey` containing the k-of-n multisignature, you\n> create a separate script containing the public keys, then hash it, and the\n> `scriptPubKey` would contain the hash of the script.\n> By symmetry with the P2PKH template:\n>\n>     OP_DUP OP_HASH160 <hash160(pubkey)> OP_EQUALVERIFY OP_CHECKSIG\n>\n> The P2SH template would be:\n>\n>     OP_DUP OP_HASH160 <hash160(redeemScript)> OP_EQUALVERIFY OP_EVAL\n>\n> `OP_EVAL` would take the stack top vector and treat it as a Bitcoin SCRIPT.\n>\n> It was then pointed out that `OP_EVAL` could be used to create recursive\n> SCRIPTs by quining using `OP_CAT`.\n> `OP_CAT` was already disabled by then, but people were talking about\n> re-enabling it somehow by restricting the output size of `OP_CAT` to limit\n> the O(2^N) behavior.\n>\n> Thus, since then, `OP_CAT` has been associated with ***recursive***\n> covenants (and people are now reluctant to re-enable it even with a limit\n> on its output size, because recursive covenants).\n> In particular, `OP_CAT` in combination with `OP_CHECKSIGFROMSTACK` and\n> `OP_CHECKSIG`, you could get a deferred `OP_EVAL` and then use `OP_CAT` too\n> to quine.\n>\n> Because of those concerns, the modern P2SH is now \"just a template\" with\n> an implicit `OP_EVAL` of the `redeemScript`, but without any `OP_EVAL`\n> being actually enabled.\n>\n> (`OP_EVAL` cannot replace an `OP_NOP` in a softfork, but it is helpful to\n> remember that P2SH was pretty much what codified the difference between\n> softfork and hardfork, and the community at the time was small enough (or\n> so it seemed) that a hardfork might not have been disruptive.)\n>\n> > Re-enabling OP_CAT with the exact same OP would be a hardfork, but\n> creating a new OP_CAT2 that does the same would be a softfork.\n>\n> If you are willing to work in Taproot the same OP-code can be enabled in a\n> softfork by using a new Tapscript version.\n>\n> If you worry about quantum-computing-break, a new SegWit version (which is\n> more limited than Tapscript versions, unfortunately) can also be used,\n> creating a new P2WSHv2 (or whatever version) that enables these opcodes.\n>\n> > As far a I know, this is the covenants proposal that has been\n> implemented for the longest time, if that's to be used as a selection\n> criteria.And as always, this is not incompatible with deploying other\n> convenant proposals later.\n>\n> No, it was `OP_EVAL`, not `OP_CAT`.\n> In particular if `OP_EVAL` was allowed in the `redeemScript` then it would\n> enable covenants as well.\n> It was just pointed out that `OP_CAT` enables recursive covenenats in\n> combination with `OP_EVAL`-in-`redeemScript`.\n>\n> In particular, in combination with `OP_CAT`, `OP_EVAL` not only allows\n> recursive covenants, but also recursion *within* a SCRIPT i.e. unbounded\n> SCRIPT execution.\n> Thus, `OP_EVAL` is simply not going to fly, at all.\n>\n> > Personally I find the simplicity proposal the best one among all the\n> covenant proposals by far, including this one.But I understand that despite\n> the name, the proposal is harder to review and test than other proposals,\n> for it wouldn't simply add covenants, but a complete new scripting language\n> that is better in many senses.Speedy covenants, on the other hand, is much\n> simpler and has been implemented for longer, so in principle, it should be\n> easier to deploy in a speedy manner.\n> >\n> > What are the main arguments against speedy covenants (aka op_cat2) and\n> against deploying simplicity in bitcoin respectively?\n> > Sorry if this was discussed before.\n>\n> `OP_CAT`, by itself, does not implement any covenants --- instead, it\n> creates recursive covenants when combined with almost all covenant opcodes.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220507/a95bab51/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-07T14:08:27",
                "message_text_only": "Good morning Jorge,\n\n> Thanks a lot for the many clarifications.\n> Yeah, I forgot it wasn't OP_CAT alone, but in combination with other things.\n> I guess this wouldn't be a covenants proposal then.\n> But simplicity would enable covenants too indeed, no?\n> Or did I get that wrong too?\n\nYes, it would enable covenants.\n\nHowever, it could also enable *recursive* covenants, depending on what introspection operations are actually implemented (though maybe not? Russell O'Connor should be the one that answers this).\n\nIt is helpful to delineate between non-recursive covenants from recursive covenants.\n\n* Even ***with*** `OP_CAT`, the following will enable non-recursive covenants without enabling recursive covenants:\n  * `OP_CTV`\n  * `SIGHASH_ANYPREVOUT`\n* With `OP_CAT`, the following would enable recursive covenants:\n  * `OP_EVAL`\n  * `OP_CHECKSIGFROMSTACK`\n  * `OP_TX`/`OP_TXHASH`\n  * ...possibly more.\n    * It is actually *easier* to *design* an opcode which inadvertently supports recursive covenants than to design one which avoids recursive covenants.\n\nRecursive covenants are very near to true Turing-completeness.\nWe want to avoid Turing-completeness due to the halting problem being unsolvable for Turing-complete languages.\nThat is, given just a program, we cannot determine for sure if for all possible inputs, it will terminate.\nIt is important in our context (Bitcoin) that any SCRIPT programs we write *must* terminate, or else we run the risk of a DoS on the network.\n\nA fair amount of this is theoretical crap, but if you want to split hairs, recursive covenants are *not* Turing-complete, but are instead total functional programming with codata.\n\nAs a very rough bastardization, a program written in a total functional programming language with codata will always assuredly terminate.\nHowever, the return value of a total functional programming language with codata can be another program.\nAn external program (written in a Turing-complete language) could then just keep invoking the interpreter of the total functional programming language with codata (taking the output program and running it, taking *its* output program and running it, ad infinitum, thus effectively able to loop indefinitely.\n\nTranslated to Bitcoin transactions, a recursive covenant system can force an output to be spent only if the output is spent on a transaction where one of the outputs is the same covenant (possibly with tweaks).\nThen an external program can keep passing the output program to the Bitcoin SCRIPT interpreter --- by building transactions that spend the previous output.\n\nThis behavior is still of concern.\nIt may be possible to attack the network by eroding its supply, by such a recursive covenant.\n\n--\n\nCommon reactions:\n\n* We can just limit the number of opcodes we can process and then fail it if it takes too many operations!\n  That way we can avoid DoS!\n  * Yes, this indeed drops it from Turing-complete to total, possibly total functional programming **without** codata.\n    But if it is possible to treat data as code, it may drop it \"total but with codata\" instead (i.e. recursive covenants).\n    But if you want to avoid recursive covenants while allowing recursive ones (i.e. equivalent to total without codata), may I suggest you instead look at `OP_CTV` and `SIGHASH_ANYPREVOUT`?\n\n* What is so wrong with total-with-codata anyway??\n  So what if the recursive covenant could potentially consume all Bitcoins, nobody will pay to it except as a novelty!!\n  If you want to burn your funds, 1BitcoinEater willingly accepts it!\n  * The burden of proof-of-safety is on the proposer, so if you have some proof that total-with-codata is safe, by construction, then sure, we can add opcodes that may enable recursive covenants, and add `OP_CAT` back in too.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-07T22:28:58",
                "message_text_only": "Good morning Jorge,\n\n> Thanks again.\n> I won't ask anything else about bitcoin, I guess, since it seems my questions are too \"misinforming\" for the list.\n> I also agreed with vjudeu, also too much misinformation on my part to agree with him, it seems.\n> I mean, I say that because it doesn't look like my emails are appearing on the mailing list:\n>\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-May/thread.html#start\n>\n> Do any of you now who moderates the mailing list? I would like to ask him what was wrong with my latest messages.\n\nCannot remember.\n\n> Can the censored messages me seen somewhere perhaps?\n\nhttps://lists.ozlabs.org/pipermail/bitcoin-dev-moderation/\n\nE.g.: https://lists.ozlabs.org/pipermail/bitcoin-dev-moderation/2022-May/000325.html\n\n> That way the moderation could be audited.\n>\n> This is quite worrying in my opinion.\n> But I'm biased, perhaps I deserve to be censored. It would still be nice to understand why, if you can help me.\n> Now I wonder if this is the first time I was censored or I was censored in bip8 discussions too, and who else was censored, when, why and by whom.\n> Perhaps I'm missing something about how the mailing list works and/or are giving this more importance than it has.\n\nSometimes the moderator is just busy living his or her life to moderate messages within 24 hours.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Nadav Ivgi",
                "date": "2022-05-08T02:03:25",
                "message_text_only": "On Sat, May 7, 2022 at 5:08 PM ZmnSCPxj via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n> * Even ***with*** `OP_CAT`, the following will enable non-recursive\ncovenants without enabling recursive covenants:\n>  * `OP_CTV`, ...\n> * With `OP_CAT`, the following would enable recursive covenants:\n>  * `OP_CHECKSIGFROMSTACK`, ...\n\nWhy does CTV+CAT not enable recursive covenants while CSFS+CAT does?\n\nCTV+CAT lets you similarly assert against the outputs and verify that they\nmatch some dynamically constructed script.\n\nIs it because CTV does not let you have a verified copy of the input's\nprevout scriptPubKey on the stack [0], while with OP_CSFS you can because\nthe signature hash covers it?\n\nBut you don't actually need this for recursion. Instead of having the user\nsupply the script in the witness stack and verifying it against the input\nto obtain the quine, the script can simply contain a copy of itself as an\ninitial push (minus this push). You can then reconstruct the full script\nquine using OP_CAT, as a PUSH(<script>) followed by the literal <script>.\n\nWhen I started experimenting with recursive covenants on liquid, I started\nwith the approach of verifying user-supplied witness data against the\ninput. It ended up being quite complex and verbose with taproot, because\nyou have to compute the tagged taptree hash from the tapscript and\nTWEAKVERIFY it against the prevout's taproot output key (which also\nrequires the internal key and parity flag, provided as two extra witness\nelements by the user).\n\nI then realized that it is much simpler to have the tapscript hold a copy\nof itself, that it's as safe and that it reduces the witness size cost\n(because you don't need to do the entire taproot dance to verify the\ntapscript), and switched to this approach.\n\nHere are two examples of recursive covenants using this approach that I\nplayed with (for liquid, rough sketches, very lightly tested and has some\nknown issues. the $label thing is a scriptwiz notation and can be ignored):\n\nhttps://gist.github.com/shesek/be910619b247ce5e1aedd84e9ba9db42 (auction)\nhttps://gist.github.com/shesek/ede9ca921a394580b23d301b8d84deea (listed\nprice sale with royalty)\n(And here's the second example written in Minsc:\nhttps://min.sc/next/#gist=e1c9914b4cb940137122d6d30972c25c)\n\nshesek\n\n[0] It does not cover it, and it cannot be done even by providing the full\nprev tx because the prevout txid is not covered either.\n\n\nOn Sat, May 7, 2022 at 5:08 PM ZmnSCPxj via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Jorge,\n>\n> > Thanks a lot for the many clarifications.\n> > Yeah, I forgot it wasn't OP_CAT alone, but in combination with other\n> things.\n> > I guess this wouldn't be a covenants proposal then.\n> > But simplicity would enable covenants too indeed, no?\n> > Or did I get that wrong too?\n>\n> Yes, it would enable covenants.\n>\n> However, it could also enable *recursive* covenants, depending on what\n> introspection operations are actually implemented (though maybe not?\n> Russell O'Connor should be the one that answers this).\n>\n> It is helpful to delineate between non-recursive covenants from recursive\n> covenants.\n>\n> * Even ***with*** `OP_CAT`, the following will enable non-recursive\n> covenants without enabling recursive covenants:\n>   * `OP_CTV`\n>   * `SIGHASH_ANYPREVOUT`\n> * With `OP_CAT`, the following would enable recursive covenants:\n>   * `OP_EVAL`\n>   * `OP_CHECKSIGFROMSTACK`\n>   * `OP_TX`/`OP_TXHASH`\n>   * ...possibly more.\n>     * It is actually *easier* to *design* an opcode which inadvertently\n> supports recursive covenants than to design one which avoids recursive\n> covenants.\n>\n> Recursive covenants are very near to true Turing-completeness.\n> We want to avoid Turing-completeness due to the halting problem being\n> unsolvable for Turing-complete languages.\n> That is, given just a program, we cannot determine for sure if for all\n> possible inputs, it will terminate.\n> It is important in our context (Bitcoin) that any SCRIPT programs we write\n> *must* terminate, or else we run the risk of a DoS on the network.\n>\n> A fair amount of this is theoretical crap, but if you want to split hairs,\n> recursive covenants are *not* Turing-complete, but are instead total\n> functional programming with codata.\n>\n> As a very rough bastardization, a program written in a total functional\n> programming language with codata will always assuredly terminate.\n> However, the return value of a total functional programming language with\n> codata can be another program.\n> An external program (written in a Turing-complete language) could then\n> just keep invoking the interpreter of the total functional programming\n> language with codata (taking the output program and running it, taking\n> *its* output program and running it, ad infinitum, thus effectively able to\n> loop indefinitely.\n>\n> Translated to Bitcoin transactions, a recursive covenant system can force\n> an output to be spent only if the output is spent on a transaction where\n> one of the outputs is the same covenant (possibly with tweaks).\n> Then an external program can keep passing the output program to the\n> Bitcoin SCRIPT interpreter --- by building transactions that spend the\n> previous output.\n>\n> This behavior is still of concern.\n> It may be possible to attack the network by eroding its supply, by such a\n> recursive covenant.\n>\n> --\n>\n> Common reactions:\n>\n> * We can just limit the number of opcodes we can process and then fail it\n> if it takes too many operations!\n>   That way we can avoid DoS!\n>   * Yes, this indeed drops it from Turing-complete to total, possibly\n> total functional programming **without** codata.\n>     But if it is possible to treat data as code, it may drop it \"total but\n> with codata\" instead (i.e. recursive covenants).\n>     But if you want to avoid recursive covenants while allowing recursive\n> ones (i.e. equivalent to total without codata), may I suggest you instead\n> look at `OP_CTV` and `SIGHASH_ANYPREVOUT`?\n>\n> * What is so wrong with total-with-codata anyway??\n>   So what if the recursive covenant could potentially consume all\n> Bitcoins, nobody will pay to it except as a novelty!!\n>   If you want to burn your funds, 1BitcoinEater willingly accepts it!\n>   * The burden of proof-of-safety is on the proposer, so if you have some\n> proof that total-with-codata is safe, by construction, then sure, we can\n> add opcodes that may enable recursive covenants, and add `OP_CAT` back in\n> too.\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220508/4b8325a8/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-08T02:19:57",
                "message_text_only": "Good morning shesek,\n\n> On Sat, May 7, 2022 at 5:08 PM ZmnSCPxj via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > * Even ***with*** `OP_CAT`, the following will enable non-recursive covenants without enabling recursive covenants:\n> >\u00a0 * `OP_CTV`, ...\n> > * With `OP_CAT`, the following would enable recursive covenants:\n> >\u00a0 * `OP_CHECKSIGFROMSTACK`, ...\n>\n> Why does CTV+CAT not enable recursive covenants while CSFS+CAT does?\n>\n> CTV+CAT lets you similarly assert against the outputs and verify that they match some dynamically constructed script.\n>\n> Is it because CTV does not let you have a verified copy of the input's prevout scriptPubKey on the stack [0], while with OP_CSFS you can because the signature hash covers it?\n>\n> But you don't actually need this for recursion. Instead of having the user supply the script in the witness stack and verifying it against the input to obtain the quine, the script can simply contain a copy of itself as an initial push (minus this push). You can then reconstruct the full script quine using OP_CAT, as a PUSH(<script>) followed by the literal <script>.\n\n    <OP_PUSH_length-of-script> OP_SWAP OP_DUP OP_CAT OP_CAT <rest of script...>\n\nHa, yes, looks like you are correct here.\n\n`OP_CAT` makes *all* covenant opcodes recursive, because you can always quine using `OP_CAT`.\n\nBy itself it does not make recursive covenants, but with probably any opcode it would.\n\nLooks like `OP_CAT` is not getting enabled until after we are reasonably sure that recursive covenants are not really unsafe.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "vjudeu at gazeta.pl",
                "date": "2022-05-11T10:57:01",
                "message_text_only": "> Looks like `OP_CAT` is not getting enabled until after we are reasonably sure that recursive covenants are not really unsafe.\n\nMaybe we should use OP_SUBSTR instead of OP_CAT. Or even better: OP_SPLIT. Then, we could have OP_SPLIT <n> <pos1> <pos2> ... <posN> that would split a string N times (so there will be N+1 pieces). Or we could have just OP_SPLIT <pos> to split one string into two. Or maybe OP_2SPLIT and OP_3SPLIT, just to split into two or three pieces (as we have OP_2DUP and OP_3DUP). I think OP_SUBSTR or OP_SPLIT is better than OP_CAT, because then things always get smaller and we can be always sure that we will have one byte as the smallest unit in our Script.\n\nOn 2022-05-08 04:20:19 user ZmnSCPxj via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Good morning shesek,\n\n> On Sat, May 7, 2022 at 5:08 PM ZmnSCPxj via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > * Even ***with*** `OP_CAT`, the following will enable non-recursive covenants without enabling recursive covenants:\n> >  * `OP_CTV`, ...\n> > * With `OP_CAT`, the following would enable recursive covenants:\n> >  * `OP_CHECKSIGFROMSTACK`, ...\n>\n> Why does CTV+CAT not enable recursive covenants while CSFS+CAT does?\n>\n> CTV+CAT lets you similarly assert against the outputs and verify that they match some dynamically constructed script.\n>\n> Is it because CTV does not let you have a verified copy of the input's prevout scriptPubKey on the stack [0], while with OP_CSFS you can because the signature hash covers it?\n>\n> But you don't actually need this for recursion. Instead of having the user supply the script in the witness stack and verifying it against the input to obtain the quine, the script can simply contain a copy of itself as an initial push (minus this push). You can then reconstruct the full script quine using OP_CAT, as a PUSH(<script>) followed by the literal <script>.\n\n    <OP_PUSH_length-of-script> OP_SWAP OP_DUP OP_CAT OP_CAT <rest of script...>\n\nHa, yes, looks like you are correct here.\n\n`OP_CAT` makes *all* covenant opcodes recursive, because you can always quine using `OP_CAT`.\n\nBy itself it does not make recursive covenants, but with probably any opcode it would.\n\nLooks like `OP_CAT` is not getting enabled until after we are reasonably sure that recursive covenants are not really unsafe.\n\nRegards,\nZmnSCPxj\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-11T11:42:10",
                "message_text_only": "Good morning vjudeu,\n\n\n> > Looks like `OP_CAT` is not getting enabled until after we are reasonably sure that recursive covenants are not really unsafe.\n>\n> Maybe we should use OP_SUBSTR instead of OP_CAT. Or even better: OP_SPLIT. Then, we could have OP_SPLIT <n> <pos1> <pos2> ... <posN> that would split a string N times (so there will be N+1 pieces). Or we could have just OP_SPLIT <pos> to split one string into two. Or maybe OP_2SPLIT and OP_3SPLIT, just to split into two or three pieces (as we have OP_2DUP and OP_3DUP). I think OP_SUBSTR or OP_SPLIT is better than OP_CAT, because then things always get smaller and we can be always sure that we will have one byte as the smallest unit in our Script.\n\nUnfortunately `OP_SUBSTR` can be used to synthesize an effective `OP_CAT`.\n\nInstead of passing in two items on the witness stack to be `OP_CAT`ted together, you instead pass in the two items to concatenate, and *then* the concatenation.\nThen you can synthesize a SCRIPT which checks that the supposed concatenation is indeed the two items to be concatenated.\n\nRecursive covenants DO NOT arise from the increasing amounts of memory the trivial `OP_DUP OP_CAT OP_DUP OP_CAT` repetition allocates.\n\nREMEMBER: `OP_CAT` BY ITSELF DOES NOT ENABLE COVENANTS, WHETHER RECURSIVE OR NOT.\n\nInstead, `OP_CAT` enable recursive covenants (which we are not certain are safe) because `OP_CAT` allows quining to be done.\nQuining is a technique to pass a SCRIPT with a copy of its code, so that it can then enforce that the output is passed to the exact same input SCRIPT.\n\n`OP_SUBSTR` allows a SCRIPT to validate that it is being passed a copy of itself and that the complete SCRIPT contains its copy as an `OP_PUSH` and the rest of the SCRIPT as actual code.\nThis is done by `OP_SUBSTR` the appropriate parts of the supposed complete SCRIPT and comparing them to a reference value we have access to (because our own SCRIPT was passed to us inside an `OP_PUSH`).\n\n   # Assume that the witness stack top is the concatenation of\n   #   `OP_PUSH`, the SCRIPT below, then the`SCRIPT below.\n   # Assume this SCRIPT is prepended with an OP_PUSH of our own code.\n   OP_TOALTSTACK # save our reference\n   OP_DUP 1 <scriptlength> OP_SUBSTR # Get the OP_PUSH argument\n   OP_FROMALTSTACK OP_DUP OP_TOALTSTACK # Get our reference\n   OP_EQUALVERIFY # check they are the same\n   OP_DUP <1 + scriptlength> <scriptlength> OP_SUBSTR # Get the SCRIPT body\n   OP_FROMALTSTACK # Get our reference\n   OP_EQUALVERIFY # check they are the same\n   # At this point, we have validated that the top of the witness stack\n   # is the quine of this SCRIPT.\n   # TODO: validate the `OP_PUSH` instruction, left as an exercise for the\n   # reader.\n\nThus, `OP_SUBSTR` is enough to enable quining and is enough to implement recursive covenants.\n\nWe cannot enable `OP_SUBSTR` either, unless we are reasonably sure that recursive covenants are safe.\n\n(FWIW recursive covenants are probably safe, as they are not in fact Turing-complete, they are a hair less powerful, equivalent to the total functional programming with codata.)\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Russell O'Connor",
                "date": "2022-05-11T19:41:16",
                "message_text_only": "On Wed, May 11, 2022 at 7:42 AM ZmnSCPxj via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> REMEMBER: `OP_CAT` BY ITSELF DOES NOT ENABLE COVENANTS, WHETHER RECURSIVE\n> OR NOT.\n>\n\nI think the state of the art has advanced to the point where we can say\n\"OP_CAT in tapscript enables non recursive covenants and it is unknown\nwhether OP_CAT can enable recursive covenants or not\".\n\nA. Poelstra in\nhttps://www.wpsoftware.net/andrew/blog/cat-and-schnorr-tricks-i.html show\nhow to use CAT to use the schnorr verification opcode to get the sighash\nvalue + 1 onto the stack, and then through some grinding and some more CAT,\nget the actual sighash value on the stack.  From there we can use SHA256 to\nget the signed transaction data onto the stack and apply introspect (using\nCAT) to build functionality similar to OP_CTV.\n\nThe missing bits for enabling recursive covenants comes down to needing to\ntransform a scriptpubkey into an taproot address, which involves some\ntweaking.  Poelstra has suggested that it might be possible to hijack the\nECDSA checksig operation from a parallel, legacy input, in order to perform\nthe calculations for this tweaking.  But as far as I know no one has yet\nbeen able to achieve this feat.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220511/50e8333f/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-12T03:07:45",
                "message_text_only": "Good morning Russell,\n\n> On Wed, May 11, 2022 at 7:42 AM ZmnSCPxj via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> > REMEMBER: `OP_CAT` BY ITSELF DOES NOT ENABLE COVENANTS, WHETHER RECURSIVE OR NOT.\n>\n>\n> I think the state of the art has advanced to the point where we can say \"OP_CAT in tapscript enables non recursive covenants and it is unknown whether OP_CAT can enable recursive covenants or not\".\n>\n> A. Poelstra in https://www.wpsoftware.net/andrew/blog/cat-and-schnorr-tricks-i.html show how to use CAT to use the schnorr verification opcode to get the sighash value + 1 onto the stack, and then through some grinding and some more CAT, get the actual sighash value on the stack. From there we can use SHA256 to get the signed transaction data onto the stack and apply introspect (using CAT) to build functionality similar to OP_CTV.\n>\n> The missing bits for enabling recursive covenants comes down to needing to transform a scriptpubkey into an taproot address, which involves some tweaking. Poelstra has suggested that it might be possible to hijack the ECDSA checksig operation from a parallel, legacy input, in order to perform the calculations for this tweaking. But as far as I know no one has yet been able to achieve this feat.\n\nHmm, I do not suppose it would have worked in ECDSA?\nSeems like this exploits linearity in the Schnorr.\nFor the ECDSA case it seems that the trick in that link leads to `s = e + G[x]` where `G[x]` is the x-coordinate of `G`.\n(I am not a mathist, so I probably am not making sense; in particular, there may be an operation to add two SECP256K1 scalars that I am not aware of)\n\nIn that case, since Schnorr was added later, I get away by a technicality, since it is not *just* `OP_CAT` which enabled this style of covenant, it was `OP_CAT` + BIP340 v(^^);;;;;\n\nAlso holy shit math is scary.\n\nSeems this also works with `OP_SUBSTR`, simply by inverting it into \"validate that the concatenation is correct\" rather than \"concatenate it ourselves\".\n\n\n\n\nSo really: are recursive covenants good or...?\nBecause if recursive covenants are good, what we should really work on is making them cheap (in CPU load/bandwidth load terms) and private, to avoid centralization and censoring.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Russell O'Connor",
                "date": "2022-05-12T10:48:44",
                "message_text_only": "On Wed, May 11, 2022 at 11:07 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Russell,\n>\n> > On Wed, May 11, 2022 at 7:42 AM ZmnSCPxj via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >\n> > > REMEMBER: `OP_CAT` BY ITSELF DOES NOT ENABLE COVENANTS, WHETHER\n> RECURSIVE OR NOT.\n> >\n> >\n> > I think the state of the art has advanced to the point where we can say\n> \"OP_CAT in tapscript enables non recursive covenants and it is unknown\n> whether OP_CAT can enable recursive covenants or not\".\n> >\n> > A. Poelstra in\n> https://www.wpsoftware.net/andrew/blog/cat-and-schnorr-tricks-i.html show\n> how to use CAT to use the schnorr verification opcode to get the sighash\n> value + 1 onto the stack, and then through some grinding and some more CAT,\n> get the actual sighash value on the stack. From there we can use SHA256 to\n> get the signed transaction data onto the stack and apply introspect (using\n> CAT) to build functionality similar to OP_CTV.\n> >\n> > The missing bits for enabling recursive covenants comes down to needing\n> to transform a scriptpubkey into an taproot address, which involves some\n> tweaking. Poelstra has suggested that it might be possible to hijack the\n> ECDSA checksig operation from a parallel, legacy input, in order to perform\n> the calculations for this tweaking. But as far as I know no one has yet\n> been able to achieve this feat.\n>\n> Hmm, I do not suppose it would have worked in ECDSA?\n> Seems like this exploits linearity in the Schnorr.\n> For the ECDSA case it seems that the trick in that link leads to `s = e +\n> G[x]` where `G[x]` is the x-coordinate of `G`.\n> (I am not a mathist, so I probably am not making sense; in particular,\n> there may be an operation to add two SECP256K1 scalars that I am not aware\n> of)\n>\n> In that case, since Schnorr was added later, I get away by a technicality,\n> since it is not *just* `OP_CAT` which enabled this style of covenant, it\n> was `OP_CAT` + BIP340 v(^^);;;;;\n>\n\nCorrect.\n\n\n> Also holy shit math is scary.\n>\n> Seems this also works with `OP_SUBSTR`, simply by inverting it into\n> \"validate that the concatenation is correct\" rather than \"concatenate it\n> ourselves\".\n>\n>\n>\n>\n> So really: are recursive covenants good or...?\n> Because if recursive covenants are good, what we should really work on is\n> making them cheap (in CPU load/bandwidth load terms) and private, to avoid\n> centralization and censoring.\n>\n\nMy view is that recursive covenants are inevitable.  It is nearly\nimpossible to have programmable money without it because it is so difficult\nto avoid.\n\nGiven that we cannot have programmable money without recursive covenants\nand given all the considerations already discussed regarding them, i.e. no\nworse than being compelled to co-sign transactions, and that user generated\naddresses won't be encumbered by a covenant unless they specifically\ngenerate it to be, I do think it makes sense to embrace them.\n\n\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220512/af1e5596/attachment-0001.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2022-05-13T21:43:47",
                "message_text_only": "On Thu, May 12, 2022 at 06:48:44AM -0400, Russell O'Connor via bitcoin-dev wrote:\n> On Wed, May 11, 2022 at 11:07 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n> > So really: are recursive covenants good or...?\n> My view is that recursive covenants are inevitable.  It is nearly\n> impossible to have programmable money without it because it is so difficult\n> to avoid.\n\nI think my answer is that yes they are good: they enable much more\npowerful contracting.\n\nOf course, like any cryptographic tool they can also be harmful to you if\nyou misuse them, and so before you use them yourself you should put in the\ntime to understand them well enough that you *don't* misuse them. Same as\nusing a kitchen knife, or riding a bicycle, or swimming. Can be natural\nto be scared at first, too.\n\n> Given that we cannot have programmable money without recursive covenants\n> and given all the considerations already discussed regarding them, i.e. no\n> worse than being compelled to co-sign transactions, and that user generated\n> addresses won't be encumbered by a covenant unless they specifically\n> generate it to be, I do think it makes sense to embrace them.\n\nI think that's really the easy way to be sure *you* aren't at risk\nfrom covenants: just follow the usual \"not your keys, not your coins\"\nphilosophy.\n\nThe way you currently generate an address from a private key already\nguarantees that *your* funds won't be encumbered by any covenants; all\nyou need to do is to keep doing that. And generating the full address\nyourself is already necessary with taproot: if you don't understand\nall the tapscript MAST paths, then even though you can spend the coin,\none of those paths you don't know about might already allow someone to\nsteal your funds. But if you generated the address, you (or at least your\nsoftware) will understand everything and not include anything dangerous,\nso your funds really are safu.\n\nIt may be that some people will refuse to send money to your address\nbecause they have some rule that says \"I'll only send money to people who\nencumber all their funds with covenant X\" and you didn't encumber your\naddress in that way -- but that just means they're refusing to pay you,\njust as people who say \"I'll only pay you off-chain via coinbase\" or\n\"I'll only pay you via SWIFT\" won't send funds to your bitcoin address.\n\nOther examples might include \"we only support segwit-v0 addresses not\ntaproot ones\", or \"you're on an OFAC sanctions list so I can't send\nto you or the government will put me in prison\" or \"my funds are in a\nmultisig with the government who won't pay to anyone who isn't also in\na multisig with them\".\n\nIt does mean you still need people with the moral fortitude to say \"no,\nif you can't pay me properly, we can't do business\" though.\n\nEven better: in so far as wallet software will just ignore any funds\nsent to addresses that they didn't generate themselves according to the\nrules you selected, you can already kind of outsource that policy to\nyour wallet. And covenants, recursive or otherwise, don't change that.\n\n\nFor any specific opcode proposal, I think you still want to consider\n\n 1) how much you can do with it\n 2) how efficient it is to validate (and thus how cheap it is to use)\n 3) how easy it is to make it do what you want\n 4) how helpful it is at preventing bugs\n 5) how clean and maintainable the validation code is\n\nI guess to me CTV and APO are weakest at (1); CAT/CSFS falls down on\n(3) and (4); OP_TX is probably weakest at (5) and maybe not as good as\nwe'd like at (3) and (4)?\n\nCheers,\naj"
            },
            {
                "author": "Russell O'Connor",
                "date": "2022-05-13T23:33:36",
                "message_text_only": "On Fri, May 13, 2022 at 5:43 PM Anthony Towns <aj at erisian.com.au> wrote:\n\n> For any specific opcode proposal, I think you still want to consider\n>\n>  1) how much you can do with it\n>  2) how efficient it is to validate (and thus how cheap it is to use)\n>  3) how easy it is to make it do what you want\n>  4) how helpful it is at preventing bugs\n>  5) how clean and maintainable the validation code is\n>\n> I guess to me CTV and APO are weakest at (1); CAT/CSFS falls down on\n> (3) and (4); OP_TX is probably weakest at (5) and maybe not as good as\n> we'd like at (3) and (4)?\n>\n\nFWIW, I think the rmain reasons to do CAT+CSFS is to validate oracle\nmessages and pubkey delegation.  The ability to covenants would be\nsecondary and would mostly serve to get us some real user data about what\nsort of covenants users find especially valuable.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220513/e19a4b5f/attachment.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2022-05-14T13:32:18",
                "message_text_only": ">\n>\n>\n> FWIW, I think the rmain reasons to do CAT+CSFS is to validate oracle\n> messages and pubkey delegation.  The ability to covenants would be\n> secondary and would mostly serve to get us some real user data about what\n> sort of covenants users find especially valuable.\n>\n\nI don't think this should be discounted.   I think it's worthwhile to\nwillingly include possibly less-than-awesome, but proven perfectly-safe\nopcodes, knowing we will have to validate them forever, even if new, cooler\nand more widely-used ones replace them years from now.\n\nI honestly don't think the development of the latter will happen without\nsome version of the former.\n\nPersonally I am satisfied:\n\n  - the safety of covenants, in general, is covered by how addresses are\ngenerated\n  - fears of forced forward-encumbrance are not any worse than can be\neasily done today\n  - ctv+apo, cat+csfs are fine, but we should pick ones that everyone\nthinks are \"good enough for everyone who cares about them\"\n  - they are not an undue burden on nodes in terms of\nvalidate-cpu-cycles-per-byte (have we proven this?)\n  - the complexity is low, code is easy to validate\n  - won't introduce DDOS attack vectors (also needs to be proven i think?)\n  - the game theory underpinning selfish miner support of the chain won't\nbe altered by causing a widespread use of on-chain leveraging instruments\n(shorting bitcoin on-chain would be dangerous, for example)\n\n\n\n\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220514/4d21bc38/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Speedy covenants (OP_CAT2)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Anthony Towns",
                "Nadav Ivgi",
                "ZmnSCPxj",
                "vjudeu at gazeta.pl",
                "alicexbt",
                "Jorge Tim\u00f3n",
                "Russell O'Connor",
                "Erik Aronesty"
            ],
            "messages_count": 19,
            "total_messages_chars_count": 69617
        }
    },
    {
        "title": "[bitcoin-dev] CTV BIP Meeting #8 Notes",
        "thread_messages": [
            {
                "author": "alicexbt",
                "date": "2022-05-07T02:40:36",
                "message_text_only": "Hi Bitcoin Developers,\n\nSummary for the last CTV meeting:\n\nTopics:\n\n1)APO version of the simple vault\n2)APO as alternative to CTV\n3)fiatjaf's CTV spacechain demo\n4)Compare CTV with other covenant proposals\n5)Recursive covenants\n6)Responding to FUD\n\n===================================================\nAPO version of the simple vault\n===================================================\n\n- It is vulnerable to the half-spend problem, where multiple vaulted outputs (of the same denomination) can be spent together, burning all but the first to fees. Fixing this requires amending APOAS to cover the current input index.\n- The unvault transaction is third-party malleable (it can have more inputs added to it). One practical implication is that you can't hand a list of the unvault txids to a watchtower, you have to tell them which outpoints to watch which is less privacy-preserving. Fixing this requires amending APOAS to cover the number of inputs.\nBoth of these issues are fixed by the BIP 118 changes suggested by darosior (although they still not officially spec'd afaik), which would basically make APO have a CTV-equivalent hash mode (minus scriptSig of other inputs)\n- simple-apo-vault could use APO-as-spec'd with SIGHASH_SINGLE|SIGHASH_ANYONECANPAY, which would solve the half-spend problem (but not malleability) and have some other interesting properties, like more natural dynamic fees (add inputs+change) and the ability spend multiple vaulted outputs together. This would, however, introduce a tx pinning attack vector and prevent rate-limited vaults.\n\n===================================================\nAPO as alternative to CTV\n===================================================\n\n- Current APO is unusable as a CTV alternative, (revised)APO seems to be as useful as CTV is (plus some extra flexibility from existing sighash flags)\n- Main drawbacks being the additional witness satisfaction cost, the network-side full-node validation costs of checking a signature instead of just a hash, and not being segwit0-compatible (meaning, among others, not quantumphobic-friendly)\n- Its about 3x for APO-in-taproot vs CTV-in-taproot. CTV-in-segwitv0 and CTV-in-bare-spk get you even more savings\n- APO is far from being ready, let alone (revised)APO\n- APOv2 would be both better for Eltoo and better for CTV, since you can use a trick to make the signatures smaller\n- \"layered commitments\" is essential for eltoo to be usable or not is unclear. AJ Towns thinks it is required while Christian Decker thinks it is not.\n\n===================================================\nfiatjaf's CTV spacechain demo\n===================================================\n\nhttps://github.com/fiatjaf/simple-ctv-spacechain\n\n===================================================\nCompare CTV with other covenant proposals\n===================================================\n\nUnlike crypto primitves (e.g., BLS vs Schnorr), there's not really actually a defined way to compare them. So one exercise of value would be if everyone tries to actually either agree to or come up with their own framework for comparing covenants.\n\nBilly Tetrud's email: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-May/020402.html\n\n- Prefers CTV for several reasons. Mainly because of being simple, documentation, code, tools, review and testing.\n- Everything else either introduces malleability, infinite recursion, or has interactions with other proposed opcodes that could introduce potentially undesirable effects like those.\n- Anything involving OP_CAT is out for the time being. There are so many things it can enable that it seems most people aren't comfortable adding it at the moment.\n- APO wallet vaults seem rather hacky, inefficient, and limited.\n- TLUV is built for evictions, TLUV + IN_OUT_AMOUNT and OP_CHECKOUTPUTVERIFY allows recursive covenants\n\n===================================================\nRecursive covenants\n===================================================\n\njamesob:\nI don't particularly understand the aversion to infinite recursion, which seems no different than the risk of potentially burning your coins. It's not like infinite recursion on bitcoin is some kind of DoS vector or poses execution overhead like an Ethereum VM bug might.\n\nrgrant:\ni think people who want recursion for cool stuff are worried that pedestrian stuff will prevent it.\n\njeremyrubin:\ni think people are afraid of weird shit happening, less so of recursion in particular\n\nhsjoberg:\n\"Recursive covenants\" is the boogie man\n\nshesek:\n\"recursion\" translates to \"complex black magic\" for nondevs' -- recursion is the new turing completeness\n\n===================================================\nResponding to FUD\n===================================================\n\n- It could be a good idea to include showing a way to do blacklists in the bug bounty offer\n- The potential concerns about recursive covenants have to clearly explained so they can be properly examined.\n- An article about CTV myths similar to segwit: : https://blog.blockstream.com/en-segwit-myths-debunked/\n- Some users think CTV might delay eltoo\n\nTL;DR\n\"The initial resistance came from the Speedy Trial proposal. Then later on rumors and FUD started spreading around regarding CTV and covenants.\"\n- hsjoberg\n\nhttps://gnusha.org/ctv-bip-review/2022-05-03.log\n\n/dev/fd0\n\nSent with [ProtonMail](https://protonmail.com/) secure email.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220507/52f50052/attachment-0001.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2022-05-07T13:22:49",
                "message_text_only": "I think people may be scared of potential attacks based on covenants. For\nexample, visacoin.\nBut there was a thread with ideas of possible attacks based on covenants.\nTo me the most scary one is visacoin, specially seeing what happened in\ncanada and other places lately and the general censorship in the west, the\nsupposed war on \"misinformation\" going on (really a war against truth imo,\nbut whatever) it's getting really scary. But perhaps someone else can be\nmore scared about a covenant to add demurrage fees to coins or something, I\ndon't know.\n\nhttps://bitcointalk.org/index.php?topic=278122\n\nFor example, what if Justin Castro, sorry, Justin Trudeu mandated a\nvisacoin covenant for all withdrawals from canadian exchanges?\nWhat if ursula von der mengele, sorry, von der leyen wants to do the same\nin europe?\nWhat if nina Nina Jankowicz decides visacoin covenants are the best way to\n\"stop misinformation\"?\n\nCovenants can enable many attacks on bitcoin, not just new cool features.\n\nNow, perhaps I am crazy for thinking there's a war against truth going on,\nI don't know.\nPerhaps most devs and bitcoin users love those lying politicians I\nmentioned.\nPerhaps I'm too biased because my political views. Or perhaps the people\nwho don't consider Justin a criminal against humanity are biased.\n\nI guess this goes beyond the scope of this mailing list though. Perhaps we\nshould go back to the bitcoin forums to discuss this kind of thing.\n\n\n\n\n\nOn Sat, May 7, 2022 at 10:54 AM alicexbt via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Bitcoin Developers,\n>\n> Summary for the last CTV meeting:\n>\n> Topics:\n>\n> 1)APO version of the simple vault\n> 2)APO as alternative to CTV\n> 3)fiatjaf's CTV spacechain demo\n> 4)Compare CTV with other covenant proposals\n> 5)Recursive covenants\n> 6)Responding to FUD\n>\n> ===================================================\n> APO version of the simple vault\n> ===================================================\n>\n> - It is vulnerable to the half-spend problem, where multiple vaulted\n> outputs (of the same denomination) can be spent together, burning all but\n> the first to fees. Fixing this requires amending APOAS to cover the current\n> input index.\n> - The unvault transaction is third-party malleable (it can have more\n> inputs added to it). One practical implication is that you can't hand a\n> list of the unvault txids to a watchtower, you have to tell them which\n> outpoints to watch which is less privacy-preserving. Fixing this requires\n> amending APOAS to cover the number of inputs.\n> Both of these issues are fixed by the BIP 118 changes suggested by\n> darosior (although they still not officially spec'd afaik), which would\n> basically make APO have a CTV-equivalent hash mode (minus scriptSig of\n> other inputs)\n> - simple-apo-vault could use APO-as-spec'd with\n> SIGHASH_SINGLE|SIGHASH_ANYONECANPAY, which would solve the half-spend\n> problem (but not malleability) and have some other interesting properties,\n> like more natural dynamic fees (add inputs+change) and the ability spend\n> multiple vaulted outputs together. This would, however, introduce a tx\n> pinning attack vector and prevent rate-limited vaults.\n>\n> ===================================================\n> APO as alternative to CTV\n> ===================================================\n>\n> - Current APO is unusable as a CTV alternative, (revised)APO seems to be\n> as useful as CTV is (plus some extra flexibility from existing sighash\n> flags)\n> - Main drawbacks being the additional witness satisfaction cost, the\n> network-side full-node validation costs of checking a signature instead of\n> just a hash, and not being segwit0-compatible (meaning, among others, not\n> quantumphobic-friendly)\n> - Its about 3x for APO-in-taproot vs CTV-in-taproot. CTV-in-segwitv0 and\n> CTV-in-bare-spk get you even more savings\n> - APO is far from being ready, let alone (revised)APO\n> - APOv2 would be both better for Eltoo and better for CTV, since you can\n> use a trick to make the signatures smaller\n> - \"layered commitments\" is essential for eltoo to be usable or not is\n> unclear. AJ Towns thinks it is required while Christian Decker thinks it is\n> not.\n>\n> ===================================================\n> fiatjaf's CTV spacechain demo\n> ===================================================\n>\n> https://github.com/fiatjaf/simple-ctv-spacechain\n>\n> ===================================================\n> Compare CTV with other covenant proposals\n> ===================================================\n>\n> Unlike crypto primitves (e.g., BLS vs Schnorr), there's not really\n> actually a defined way to compare them. So one exercise of value would be\n> if everyone tries to actually either agree to or come up with their own\n> framework for comparing covenants.\n>\n> Billy Tetrud's email:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-May/020402.html\n>\n> - Prefers CTV for several reasons. Mainly because of being simple,\n> documentation, code, tools, review and testing.\n> - Everything else either introduces malleability, infinite recursion, or\n> has interactions with other proposed opcodes that could introduce\n> potentially undesirable effects like those.\n> - Anything involving OP_CAT is out for the time being. There are so many\n> things it can enable that it seems most people aren't comfortable adding it\n> at the moment.\n> - APO wallet vaults seem rather hacky, inefficient, and limited.\n> - TLUV is built for evictions, TLUV + IN_OUT_AMOUNT and\n> OP_CHECKOUTPUTVERIFY allows recursive covenants\n>\n> ===================================================\n> Recursive covenants\n> ===================================================\n>\n> jamesob:\n> I don't particularly understand the aversion to infinite recursion, which\n> seems no different than the risk of potentially burning your coins. It's\n> not like infinite recursion on bitcoin is some kind of DoS vector or poses\n> execution overhead like an Ethereum VM bug might.\n>\n> rgrant:\n> i think people who want recursion for cool stuff are worried that\n> pedestrian stuff will prevent it.\n>\n> jeremyrubin:\n> i think people are afraid of weird shit happening, less so of recursion in\n> particular\n>\n> hsjoberg:\n> \"Recursive covenants\" is the boogie man\n>\n> shesek:\n> \"recursion\" translates to \"complex black magic\" for nondevs' -- recursion\n> is the new turing completeness\n>\n> ===================================================\n> Responding to FUD\n> ===================================================\n>\n> - It could be a good idea to include showing a way to do blacklists in the\n> bug bounty offer\n> - The potential concerns about recursive covenants have to clearly\n> explained so they can be properly examined.\n> - An article about CTV myths similar to segwit: :\n> https://blog.blockstream.com/en-segwit-myths-debunked/\n> - Some users think CTV might delay eltoo\n>\n> TL;DR\n> \"The initial resistance came from the Speedy Trial proposal. Then later on\n> rumors and FUD started spreading around regarding CTV and covenants.\"\n> - hsjoberg\n>\n> https://gnusha.org/ctv-bip-review/2022-05-03.log\n>\n>\n> /dev/fd0\n> Sent with ProtonMail <https://protonmail.com/> secure email.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220507/dfa8dc5b/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-07T22:40:10",
                "message_text_only": "Good morning Jorge,\n\n> I think people may be scared of potential attacks based on covenants. For example, visacoin.\n> But there was a thread with ideas of possible attacks based on covenants.\n> To me the most scary one is visacoin, specially seeing what happened in canada and other places lately and the general censorship in the west, the supposed war on \"misinformation\" going on (really a war against truth imo, but whatever) it's getting really scary. But perhaps someone else can be more scared about a covenant to add demurrage fees to coins or something, I don't know.\n> https://bitcointalk.org/index.php?topic=278122\n\nThis requires *recursive* covenants.\n\nAt the time the post was made, no distinction was seen between recursive and non-recursive covenants, which is why the post points out that covenants suck.\nThe idea then was that anything powerful enough to provide covenants would also be powerful enough to provide *recursive* covenants, so there was no distinction made between recursive and non-recursive covenants (the latter was thought to be impossible).\n\nHowever, `OP_CTV` turns out to enable sort-of covenants, but by construction *cannot* provide recursion.\nIt is just barely powerful enough to make a covenant, but not powerful enough to make *recursive* covenants.\n\nThat is why today we distinguish between recursive and non-recursive covenant opcodes, because we now have opcode designs that provides non-recursive covenants (when previously it was thought all covenant opcodes would provide recursion).\n\n`visacoin` can only work as a recursive covenant, thus it is not possible to use `OP_CTV` to implement `visacoin`, regardless of your political views.\n\n(I was also misinformed in the past and ignored `OP_CTV` since I thought that, like all the other covenant opcodes, it would enable recursive covenants.)\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-05-08T16:32:45",
                "message_text_only": ">  This requires *recursive* covenants.\n\nActually, for practical use, any walled-garden requires *dynamic*\ncovenants, not recursive covenants. CTV can get arbitrarily close to\nrecursive covenants, because you can have an arbitrarily long string of\ncovenants. But this doesn't help someone implement visacoin because CTV\nonly allows a specific predefined iteration of transactions, meaning that\nwhile \"locked\" into the covenant sequence, the coins can't be used in any\nway like normal coins - you can't choose who you pay, the sequence is\npredetermined.\n\nEven covenants that allow infinite recursion (like OP_TLUV and OP_CD\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/bip-constraindestination.md>)\ndon't automatically allow for practical walled gardens. Recursion\ndefinitely allows creating walled gardens, but those gardens would be\nimpractically static. You could add millions of potential addresses to send\nto, which would \"only\" quadruple the size of your transactions, but if\nanyone creates a new address you want to send to, you wouldn't be able to.\nEveryone would have to have a single address whitelisted into every\ngovernment-bitcoin output. If someone lost their key and needs to create a\nnew wallet, suddenly no one would be able to pay them.\n\nIn order to really build a wallet garden, infinite recursion isn't really\nnecessary nor sufficient. You need to be able to dynamically specify\ndestination addresses. For example, if you were a government that wants to\nmake a walled garden where you (the government) could confiscate the funds\nwhenever you wanted, you'd have to have a covenant that allows the end-user\nto specify an arbitrary public key to send money to. The covenant might\nrequire that user to send to another covenant that has a government spend\npath, but also has a spend path for that user-defined public key. That way,\nyou (the government) could allow people to send to each other arbitrarily,\nwhile still ensuring that you (the government) could spend the funds no\nmatter where they may have been sent. Even without recursive covenants, you\ncould have arbitrarily long chains of these, say 1 million long, where at\nthe end of the chain the user must send your coins back to the government\nwho can then send them back with another million-long chain of covenants to\nwork with.\n\nOP_CHECKOUTPUTVERIFY <https://fc16.ifca.ai/bitcoin/papers/MES16.pdf> can do\nthis kind of dynamicness, and OP_PUSHOUTPUTSTACK\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/pos/bip-pushoutputstack.md>\ncan\nenable it for things like OP_TLUV and OP_CD. I personally think dynamic\ncovenants are a *good* thing, as it enables more secure wallet vaults,\namong other things. And I'm not worried about a government creating a\nin-bitcoin visa-coin. Why? Because they can already do it today. They have\nbeen able to do it for 9 years already. How?\n\nReplace the covenant above with a multisig wallet. The government has 2\nkeys, you have 1 key. Every time you make a transaction, you request the\ngovernment's signature on it. The government then only signs if you're\nsending to a wallet they approve of. They might only sign when you're\nsending to another multisig wallet that the government has 2 of 3 keys for.\nIts a very similar walled garden, where the only difference is that the\ngovernment needs to actively sign, which I'm sure wouldn't be a huge\nchallenge for the intrepid dictator of the land. You want to add\ndemurage fees? Easy, the government just spends the fee out of everyone's\nwallets every so often.\n\nOn the other hand, OP_CTV *cannot* be used for such a thing. No combination\nof future opcodes can enable either recursion or dynamicness to an OP_CTV\ncall.\n\n\n\nOn Sat, May 7, 2022 at 5:40 PM ZmnSCPxj via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Jorge,\n>\n> > I think people may be scared of potential attacks based on covenants.\n> For example, visacoin.\n> > But there was a thread with ideas of possible attacks based on covenants.\n> > To me the most scary one is visacoin, specially seeing what happened in\n> canada and other places lately and the general censorship in the west, the\n> supposed war on \"misinformation\" going on (really a war against truth imo,\n> but whatever) it's getting really scary. But perhaps someone else can be\n> more scared about a covenant to add demurrage fees to coins or something, I\n> don't know.\n> > https://bitcointalk.org/index.php?topic=278122\n>\n> This requires *recursive* covenants.\n>\n> At the time the post was made, no distinction was seen between recursive\n> and non-recursive covenants, which is why the post points out that\n> covenants suck.\n> The idea then was that anything powerful enough to provide covenants would\n> also be powerful enough to provide *recursive* covenants, so there was no\n> distinction made between recursive and non-recursive covenants (the latter\n> was thought to be impossible).\n>\n> However, `OP_CTV` turns out to enable sort-of covenants, but by\n> construction *cannot* provide recursion.\n> It is just barely powerful enough to make a covenant, but not powerful\n> enough to make *recursive* covenants.\n>\n> That is why today we distinguish between recursive and non-recursive\n> covenant opcodes, because we now have opcode designs that provides\n> non-recursive covenants (when previously it was thought all covenant\n> opcodes would provide recursion).\n>\n> `visacoin` can only work as a recursive covenant, thus it is not possible\n> to use `OP_CTV` to implement `visacoin`, regardless of your political views.\n>\n> (I was also misinformed in the past and ignored `OP_CTV` since I thought\n> that, like all the other covenant opcodes, it would enable recursive\n> covenants.)\n>\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220508/6162df67/attachment.html>"
            },
            {
                "author": "Keagan McClelland",
                "date": "2022-05-09T15:23:39",
                "message_text_only": "> > > To me the most scary one is visacoin, specially seeing what happened\nin canada and other places lately and the general censorship in the west,\nthe supposed war on \"misinformation\" going on (really a war against truth\nimo, but whatever) it's getting really scary. But perhaps someone else can\nbe more scared about a covenant to add demurrage fees to coins or\nsomething, I don't know.\n> > > https://bitcointalk.org/index.php?topic=278122\n\n> > This requires *recursive* covenants.\n\n> Actually, for practical use, any walled-garden requires *dynamic*\ncovenants, not recursive covenants.\n\nThere's actually also a very straight forward defense for those who do not\nwant to receive \"tainted\" coins. In every covenant design I've seen to date\n(including recursive designs) it requires that the receiver generate a\nscript that is \"compliant\" with the covenant provisions to which the sender\nis bound. The consequence of this is that you can't receive coins that are\nbound by covenants you weren't aware of*. So if you don't want to receive\nrestricted coins, just don't generate an address with those restrictions\nembedded. As long as you can specify the spend conditions upon the receipt\nof your funds, it really doesn't matter how others are structuring their\nown spend conditions. So long as the verification of those conditions can\nbe predictably verified by the rest of the network, all risk incurred is\nquarantined to the receiver of the funds. Worst case scenario is that no\none wants to agree to those conditions and the funds are effectively burned.\n\nIt's not hard to make the case that any time funds are being transferred\nbetween organizations with incompatible interests (external to a firm),\nthat they will want to be completely free to choose their own spend\nconditions and will not wish to inherit the conditions of the spender.\nCorrespondingly, any well implemented covenant contract will include\nprovisions for escaping the recursion loop if some sufficiently high bar is\nmet by the administrators of those funds. Unless governments can mandate\nthat you generate these addresses AND force you to accept funds bound by\nthem for your services**, I don't actually see how this is a real concern.\n\n*This requires good wallet tooling and standards but that isn't materially\ndifferent than wallets experimenting with non-standard recovery policies.\n\n**This is a reason to oppose legal tender laws for Bitcoin imo.\n\nKeagan\n\nOn Sun, May 8, 2022 at 11:32 AM Billy Tetrud via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> >  This requires *recursive* covenants.\n>\n> Actually, for practical use, any walled-garden requires *dynamic*\n> covenants, not recursive covenants. CTV can get arbitrarily close to\n> recursive covenants, because you can have an arbitrarily long string of\n> covenants. But this doesn't help someone implement visacoin because CTV\n> only allows a specific predefined iteration of transactions, meaning that\n> while \"locked\" into the covenant sequence, the coins can't be used in any\n> way like normal coins - you can't choose who you pay, the sequence is\n> predetermined.\n>\n> Even covenants that allow infinite recursion (like OP_TLUV and OP_CD\n> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/bip-constraindestination.md>)\n> don't automatically allow for practical walled gardens. Recursion\n> definitely allows creating walled gardens, but those gardens would be\n> impractically static. You could add millions of potential addresses to send\n> to, which would \"only\" quadruple the size of your transactions, but if\n> anyone creates a new address you want to send to, you wouldn't be able to.\n> Everyone would have to have a single address whitelisted into every\n> government-bitcoin output. If someone lost their key and needs to create a\n> new wallet, suddenly no one would be able to pay them.\n>\n> In order to really build a wallet garden, infinite recursion isn't really\n> necessary nor sufficient. You need to be able to dynamically specify\n> destination addresses. For example, if you were a government that wants to\n> make a walled garden where you (the government) could confiscate the funds\n> whenever you wanted, you'd have to have a covenant that allows the end-user\n> to specify an arbitrary public key to send money to. The covenant might\n> require that user to send to another covenant that has a government spend\n> path, but also has a spend path for that user-defined public key. That way,\n> you (the government) could allow people to send to each other arbitrarily,\n> while still ensuring that you (the government) could spend the funds no\n> matter where they may have been sent. Even without recursive covenants, you\n> could have arbitrarily long chains of these, say 1 million long, where at\n> the end of the chain the user must send your coins back to the government\n> who can then send them back with another million-long chain of covenants to\n> work with.\n>\n> OP_CHECKOUTPUTVERIFY <https://fc16.ifca.ai/bitcoin/papers/MES16.pdf> can\n> do this kind of dynamicness, and OP_PUSHOUTPUTSTACK\n> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/pos/bip-pushoutputstack.md> can\n> enable it for things like OP_TLUV and OP_CD. I personally think dynamic\n> covenants are a *good* thing, as it enables more secure wallet vaults,\n> among other things. And I'm not worried about a government creating a\n> in-bitcoin visa-coin. Why? Because they can already do it today. They have\n> been able to do it for 9 years already. How?\n>\n> Replace the covenant above with a multisig wallet. The government has 2\n> keys, you have 1 key. Every time you make a transaction, you request the\n> government's signature on it. The government then only signs if you're\n> sending to a wallet they approve of. They might only sign when you're\n> sending to another multisig wallet that the government has 2 of 3 keys for.\n> Its a very similar walled garden, where the only difference is that the\n> government needs to actively sign, which I'm sure wouldn't be a huge\n> challenge for the intrepid dictator of the land. You want to add\n> demurage fees? Easy, the government just spends the fee out of everyone's\n> wallets every so often.\n>\n> On the other hand, OP_CTV *cannot* be used for such a thing. No\n> combination of future opcodes can enable either recursion or dynamicness to\n> an OP_CTV call.\n>\n>\n>\n> On Sat, May 7, 2022 at 5:40 PM ZmnSCPxj via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Good morning Jorge,\n>>\n>> > I think people may be scared of potential attacks based on covenants.\n>> For example, visacoin.\n>> > But there was a thread with ideas of possible attacks based on\n>> covenants.\n>> > To me the most scary one is visacoin, specially seeing what happened in\n>> canada and other places lately and the general censorship in the west, the\n>> supposed war on \"misinformation\" going on (really a war against truth imo,\n>> but whatever) it's getting really scary. But perhaps someone else can be\n>> more scared about a covenant to add demurrage fees to coins or something, I\n>> don't know.\n>> > https://bitcointalk.org/index.php?topic=278122\n>>\n>> This requires *recursive* covenants.\n>>\n>> At the time the post was made, no distinction was seen between recursive\n>> and non-recursive covenants, which is why the post points out that\n>> covenants suck.\n>> The idea then was that anything powerful enough to provide covenants\n>> would also be powerful enough to provide *recursive* covenants, so there\n>> was no distinction made between recursive and non-recursive covenants (the\n>> latter was thought to be impossible).\n>>\n>> However, `OP_CTV` turns out to enable sort-of covenants, but by\n>> construction *cannot* provide recursion.\n>> It is just barely powerful enough to make a covenant, but not powerful\n>> enough to make *recursive* covenants.\n>>\n>> That is why today we distinguish between recursive and non-recursive\n>> covenant opcodes, because we now have opcode designs that provides\n>> non-recursive covenants (when previously it was thought all covenant\n>> opcodes would provide recursion).\n>>\n>> `visacoin` can only work as a recursive covenant, thus it is not possible\n>> to use `OP_CTV` to implement `visacoin`, regardless of your political views.\n>>\n>> (I was also misinformed in the past and ignored `OP_CTV` since I thought\n>> that, like all the other covenant opcodes, it would enable recursive\n>> covenants.)\n>>\n>>\n>> Regards,\n>> ZmnSCPxj\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220509/bfc87453/attachment.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-05-10T15:09:45",
                "message_text_only": ">  So if you don't want to receive restricted coins, just don't generate an\naddress with those restrictions embedded.\n\nThis is an interesting point that I for some reason haven't thought of\nbefore. However...\n\n> Unless governments can mandate that you generate these addresses AND\nforce you to accept funds bound by them for your services**, I don't\nactually see how this is a real concern.\n\nActually, I think only the second is necessary. For example, if there was a\nlaw that compelled giving a good or service if payment of a publicly\nadvertised amount was paid, and someone pays to an address that can be\nshown is spendable by the merchant's keys in a way that the government\naccepts, it doesn't matter whether the recipient can or has generated the\naddress.\n\nRegardless I do think its still important to note that a government could\ndo that today using multisig.\n\n> This is a reason to oppose legal tender laws for Bitcoin imo.\n\nI agree.\n\nOn Mon, May 9, 2022 at 10:23 AM Keagan McClelland <\nkeagan.mcclelland at gmail.com> wrote:\n\n> > > > To me the most scary one is visacoin, specially seeing what happened\n> in canada and other places lately and the general censorship in the west,\n> the supposed war on \"misinformation\" going on (really a war against truth\n> imo, but whatever) it's getting really scary. But perhaps someone else can\n> be more scared about a covenant to add demurrage fees to coins or\n> something, I don't know.\n> > > > https://bitcointalk.org/index.php?topic=278122\n>\n> > > This requires *recursive* covenants.\n>\n> > Actually, for practical use, any walled-garden requires *dynamic*\n> covenants, not recursive covenants.\n>\n> There's actually also a very straight forward defense for those who do not\n> want to receive \"tainted\" coins. In every covenant design I've seen to date\n> (including recursive designs) it requires that the receiver generate a\n> script that is \"compliant\" with the covenant provisions to which the sender\n> is bound. The consequence of this is that you can't receive coins that are\n> bound by covenants you weren't aware of*. So if you don't want to receive\n> restricted coins, just don't generate an address with those restrictions\n> embedded. As long as you can specify the spend conditions upon the receipt\n> of your funds, it really doesn't matter how others are structuring their\n> own spend conditions. So long as the verification of those conditions can\n> be predictably verified by the rest of the network, all risk incurred is\n> quarantined to the receiver of the funds. Worst case scenario is that no\n> one wants to agree to those conditions and the funds are effectively burned.\n>\n> It's not hard to make the case that any time funds are being transferred\n> between organizations with incompatible interests (external to a firm),\n> that they will want to be completely free to choose their own spend\n> conditions and will not wish to inherit the conditions of the spender.\n> Correspondingly, any well implemented covenant contract will include\n> provisions for escaping the recursion loop if some sufficiently high bar is\n> met by the administrators of those funds. Unless governments can mandate\n> that you generate these addresses AND force you to accept funds bound by\n> them for your services**, I don't actually see how this is a real concern.\n>\n> *This requires good wallet tooling and standards but that isn't materially\n> different than wallets experimenting with non-standard recovery policies.\n>\n> **This is a reason to oppose legal tender laws for Bitcoin imo.\n>\n> Keagan\n>\n> On Sun, May 8, 2022 at 11:32 AM Billy Tetrud via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> >  This requires *recursive* covenants.\n>>\n>> Actually, for practical use, any walled-garden requires *dynamic*\n>> covenants, not recursive covenants. CTV can get arbitrarily close to\n>> recursive covenants, because you can have an arbitrarily long string of\n>> covenants. But this doesn't help someone implement visacoin because CTV\n>> only allows a specific predefined iteration of transactions, meaning that\n>> while \"locked\" into the covenant sequence, the coins can't be used in any\n>> way like normal coins - you can't choose who you pay, the sequence is\n>> predetermined.\n>>\n>> Even covenants that allow infinite recursion (like OP_TLUV and OP_CD\n>> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/bip-constraindestination.md>)\n>> don't automatically allow for practical walled gardens. Recursion\n>> definitely allows creating walled gardens, but those gardens would be\n>> impractically static. You could add millions of potential addresses to send\n>> to, which would \"only\" quadruple the size of your transactions, but if\n>> anyone creates a new address you want to send to, you wouldn't be able to.\n>> Everyone would have to have a single address whitelisted into every\n>> government-bitcoin output. If someone lost their key and needs to create a\n>> new wallet, suddenly no one would be able to pay them.\n>>\n>> In order to really build a wallet garden, infinite recursion isn't really\n>> necessary nor sufficient. You need to be able to dynamically specify\n>> destination addresses. For example, if you were a government that wants to\n>> make a walled garden where you (the government) could confiscate the funds\n>> whenever you wanted, you'd have to have a covenant that allows the end-user\n>> to specify an arbitrary public key to send money to. The covenant might\n>> require that user to send to another covenant that has a government spend\n>> path, but also has a spend path for that user-defined public key. That way,\n>> you (the government) could allow people to send to each other arbitrarily,\n>> while still ensuring that you (the government) could spend the funds no\n>> matter where they may have been sent. Even without recursive covenants, you\n>> could have arbitrarily long chains of these, say 1 million long, where at\n>> the end of the chain the user must send your coins back to the government\n>> who can then send them back with another million-long chain of covenants to\n>> work with.\n>>\n>> OP_CHECKOUTPUTVERIFY <https://fc16.ifca.ai/bitcoin/papers/MES16.pdf> can\n>> do this kind of dynamicness, and OP_PUSHOUTPUTSTACK\n>> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/pos/bip-pushoutputstack.md> can\n>> enable it for things like OP_TLUV and OP_CD. I personally think dynamic\n>> covenants are a *good* thing, as it enables more secure wallet vaults,\n>> among other things. And I'm not worried about a government creating a\n>> in-bitcoin visa-coin. Why? Because they can already do it today. They have\n>> been able to do it for 9 years already. How?\n>>\n>> Replace the covenant above with a multisig wallet. The government has 2\n>> keys, you have 1 key. Every time you make a transaction, you request the\n>> government's signature on it. The government then only signs if you're\n>> sending to a wallet they approve of. They might only sign when you're\n>> sending to another multisig wallet that the government has 2 of 3 keys for.\n>> Its a very similar walled garden, where the only difference is that the\n>> government needs to actively sign, which I'm sure wouldn't be a huge\n>> challenge for the intrepid dictator of the land. You want to add\n>> demurage fees? Easy, the government just spends the fee out of everyone's\n>> wallets every so often.\n>>\n>> On the other hand, OP_CTV *cannot* be used for such a thing. No\n>> combination of future opcodes can enable either recursion or dynamicness to\n>> an OP_CTV call.\n>>\n>>\n>>\n>> On Sat, May 7, 2022 at 5:40 PM ZmnSCPxj via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Good morning Jorge,\n>>>\n>>> > I think people may be scared of potential attacks based on covenants.\n>>> For example, visacoin.\n>>> > But there was a thread with ideas of possible attacks based on\n>>> covenants.\n>>> > To me the most scary one is visacoin, specially seeing what happened\n>>> in canada and other places lately and the general censorship in the west,\n>>> the supposed war on \"misinformation\" going on (really a war against truth\n>>> imo, but whatever) it's getting really scary. But perhaps someone else can\n>>> be more scared about a covenant to add demurrage fees to coins or\n>>> something, I don't know.\n>>> > https://bitcointalk.org/index.php?topic=278122\n>>>\n>>> This requires *recursive* covenants.\n>>>\n>>> At the time the post was made, no distinction was seen between recursive\n>>> and non-recursive covenants, which is why the post points out that\n>>> covenants suck.\n>>> The idea then was that anything powerful enough to provide covenants\n>>> would also be powerful enough to provide *recursive* covenants, so there\n>>> was no distinction made between recursive and non-recursive covenants (the\n>>> latter was thought to be impossible).\n>>>\n>>> However, `OP_CTV` turns out to enable sort-of covenants, but by\n>>> construction *cannot* provide recursion.\n>>> It is just barely powerful enough to make a covenant, but not powerful\n>>> enough to make *recursive* covenants.\n>>>\n>>> That is why today we distinguish between recursive and non-recursive\n>>> covenant opcodes, because we now have opcode designs that provides\n>>> non-recursive covenants (when previously it was thought all covenant\n>>> opcodes would provide recursion).\n>>>\n>>> `visacoin` can only work as a recursive covenant, thus it is not\n>>> possible to use `OP_CTV` to implement `visacoin`, regardless of your\n>>> political views.\n>>>\n>>> (I was also misinformed in the past and ignored `OP_CTV` since I thought\n>>> that, like all the other covenant opcodes, it would enable recursive\n>>> covenants.)\n>>>\n>>>\n>>> Regards,\n>>> ZmnSCPxj\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220510/06d05ed0/attachment-0001.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2022-05-12T11:46:45",
                "message_text_only": "I think something like visacoin could be kind of feasible without recursive\ncovenants. But as billy points out, I guess they could kind of do it with\nmultisig too.\n\nI fail to understand why non recursive covenants are called covenants at\nall. Probably I'm missing something, but I guess that's another topic.\n\n\nOn Tue, May 10, 2022 at 5:11 PM Billy Tetrud via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> >  So if you don't want to receive restricted coins, just don't generate\n> an address with those restrictions embedded.\n>\n> This is an interesting point that I for some reason haven't thought of\n> before. However...\n>\n> > Unless governments can mandate that you generate these addresses AND\n> force you to accept funds bound by them for your services**, I don't\n> actually see how this is a real concern.\n>\n> Actually, I think only the second is necessary. For example, if there was\n> a law that compelled giving a good or service if payment of a publicly\n> advertised amount was paid, and someone pays to an address that can be\n> shown is spendable by the merchant's keys in a way that the government\n> accepts, it doesn't matter whether the recipient can or has generated the\n> address.\n>\n> Regardless I do think its still important to note that a government could\n> do that today using multisig.\n>\n> > This is a reason to oppose legal tender laws for Bitcoin imo.\n>\n> I agree.\n>\n> On Mon, May 9, 2022 at 10:23 AM Keagan McClelland <\n> keagan.mcclelland at gmail.com> wrote:\n>\n>> > > > To me the most scary one is visacoin, specially seeing what\n>> happened in canada and other places lately and the general censorship in\n>> the west, the supposed war on \"misinformation\" going on (really a war\n>> against truth imo, but whatever) it's getting really scary. But perhaps\n>> someone else can be more scared about a covenant to add demurrage fees to\n>> coins or something, I don't know.\n>> > > > https://bitcointalk.org/index.php?topic=278122\n>>\n>> > > This requires *recursive* covenants.\n>>\n>> > Actually, for practical use, any walled-garden requires *dynamic*\n>> covenants, not recursive covenants.\n>>\n>> There's actually also a very straight forward defense for those who do\n>> not want to receive \"tainted\" coins. In every covenant design I've seen to\n>> date (including recursive designs) it requires that the receiver generate a\n>> script that is \"compliant\" with the covenant provisions to which the sender\n>> is bound. The consequence of this is that you can't receive coins that are\n>> bound by covenants you weren't aware of*. So if you don't want to receive\n>> restricted coins, just don't generate an address with those restrictions\n>> embedded. As long as you can specify the spend conditions upon the receipt\n>> of your funds, it really doesn't matter how others are structuring their\n>> own spend conditions. So long as the verification of those conditions can\n>> be predictably verified by the rest of the network, all risk incurred is\n>> quarantined to the receiver of the funds. Worst case scenario is that no\n>> one wants to agree to those conditions and the funds are effectively burned.\n>>\n>> It's not hard to make the case that any time funds are being transferred\n>> between organizations with incompatible interests (external to a firm),\n>> that they will want to be completely free to choose their own spend\n>> conditions and will not wish to inherit the conditions of the spender.\n>> Correspondingly, any well implemented covenant contract will include\n>> provisions for escaping the recursion loop if some sufficiently high bar is\n>> met by the administrators of those funds. Unless governments can mandate\n>> that you generate these addresses AND force you to accept funds bound by\n>> them for your services**, I don't actually see how this is a real concern.\n>>\n>> *This requires good wallet tooling and standards but that isn't\n>> materially different than wallets experimenting with non-standard recovery\n>> policies.\n>>\n>> **This is a reason to oppose legal tender laws for Bitcoin imo.\n>>\n>> Keagan\n>>\n>> On Sun, May 8, 2022 at 11:32 AM Billy Tetrud via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> >  This requires *recursive* covenants.\n>>>\n>>> Actually, for practical use, any walled-garden requires *dynamic*\n>>> covenants, not recursive covenants. CTV can get arbitrarily close to\n>>> recursive covenants, because you can have an arbitrarily long string of\n>>> covenants. But this doesn't help someone implement visacoin because CTV\n>>> only allows a specific predefined iteration of transactions, meaning that\n>>> while \"locked\" into the covenant sequence, the coins can't be used in any\n>>> way like normal coins - you can't choose who you pay, the sequence is\n>>> predetermined.\n>>>\n>>> Even covenants that allow infinite recursion (like OP_TLUV and OP_CD\n>>> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/bip-constraindestination.md>)\n>>> don't automatically allow for practical walled gardens. Recursion\n>>> definitely allows creating walled gardens, but those gardens would be\n>>> impractically static. You could add millions of potential addresses to send\n>>> to, which would \"only\" quadruple the size of your transactions, but if\n>>> anyone creates a new address you want to send to, you wouldn't be able to.\n>>> Everyone would have to have a single address whitelisted into every\n>>> government-bitcoin output. If someone lost their key and needs to create a\n>>> new wallet, suddenly no one would be able to pay them.\n>>>\n>>> In order to really build a wallet garden, infinite recursion isn't\n>>> really necessary nor sufficient. You need to be able to dynamically specify\n>>> destination addresses. For example, if you were a government that wants to\n>>> make a walled garden where you (the government) could confiscate the funds\n>>> whenever you wanted, you'd have to have a covenant that allows the end-user\n>>> to specify an arbitrary public key to send money to. The covenant might\n>>> require that user to send to another covenant that has a government spend\n>>> path, but also has a spend path for that user-defined public key. That way,\n>>> you (the government) could allow people to send to each other arbitrarily,\n>>> while still ensuring that you (the government) could spend the funds no\n>>> matter where they may have been sent. Even without recursive covenants, you\n>>> could have arbitrarily long chains of these, say 1 million long, where at\n>>> the end of the chain the user must send your coins back to the government\n>>> who can then send them back with another million-long chain of covenants to\n>>> work with.\n>>>\n>>> OP_CHECKOUTPUTVERIFY <https://fc16.ifca.ai/bitcoin/papers/MES16.pdf> can\n>>> do this kind of dynamicness, and OP_PUSHOUTPUTSTACK\n>>> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/pos/bip-pushoutputstack.md> can\n>>> enable it for things like OP_TLUV and OP_CD. I personally think dynamic\n>>> covenants are a *good* thing, as it enables more secure wallet vaults,\n>>> among other things. And I'm not worried about a government creating a\n>>> in-bitcoin visa-coin. Why? Because they can already do it today. They have\n>>> been able to do it for 9 years already. How?\n>>>\n>>> Replace the covenant above with a multisig wallet. The government has 2\n>>> keys, you have 1 key. Every time you make a transaction, you request the\n>>> government's signature on it. The government then only signs if you're\n>>> sending to a wallet they approve of. They might only sign when you're\n>>> sending to another multisig wallet that the government has 2 of 3 keys for.\n>>> Its a very similar walled garden, where the only difference is that the\n>>> government needs to actively sign, which I'm sure wouldn't be a huge\n>>> challenge for the intrepid dictator of the land. You want to add\n>>> demurage fees? Easy, the government just spends the fee out of everyone's\n>>> wallets every so often.\n>>>\n>>> On the other hand, OP_CTV *cannot* be used for such a thing. No\n>>> combination of future opcodes can enable either recursion or dynamicness to\n>>> an OP_CTV call.\n>>>\n>>>\n>>>\n>>> On Sat, May 7, 2022 at 5:40 PM ZmnSCPxj via bitcoin-dev <\n>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> Good morning Jorge,\n>>>>\n>>>> > I think people may be scared of potential attacks based on covenants.\n>>>> For example, visacoin.\n>>>> > But there was a thread with ideas of possible attacks based on\n>>>> covenants.\n>>>> > To me the most scary one is visacoin, specially seeing what happened\n>>>> in canada and other places lately and the general censorship in the west,\n>>>> the supposed war on \"misinformation\" going on (really a war against truth\n>>>> imo, but whatever) it's getting really scary. But perhaps someone else can\n>>>> be more scared about a covenant to add demurrage fees to coins or\n>>>> something, I don't know.\n>>>> > https://bitcointalk.org/index.php?topic=278122\n>>>>\n>>>> This requires *recursive* covenants.\n>>>>\n>>>> At the time the post was made, no distinction was seen between\n>>>> recursive and non-recursive covenants, which is why the post points out\n>>>> that covenants suck.\n>>>> The idea then was that anything powerful enough to provide covenants\n>>>> would also be powerful enough to provide *recursive* covenants, so there\n>>>> was no distinction made between recursive and non-recursive covenants (the\n>>>> latter was thought to be impossible).\n>>>>\n>>>> However, `OP_CTV` turns out to enable sort-of covenants, but by\n>>>> construction *cannot* provide recursion.\n>>>> It is just barely powerful enough to make a covenant, but not powerful\n>>>> enough to make *recursive* covenants.\n>>>>\n>>>> That is why today we distinguish between recursive and non-recursive\n>>>> covenant opcodes, because we now have opcode designs that provides\n>>>> non-recursive covenants (when previously it was thought all covenant\n>>>> opcodes would provide recursion).\n>>>>\n>>>> `visacoin` can only work as a recursive covenant, thus it is not\n>>>> possible to use `OP_CTV` to implement `visacoin`, regardless of your\n>>>> political views.\n>>>>\n>>>> (I was also misinformed in the past and ignored `OP_CTV` since I\n>>>> thought that, like all the other covenant opcodes, it would enable\n>>>> recursive covenants.)\n>>>>\n>>>>\n>>>> Regards,\n>>>> ZmnSCPxj\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220512/8e84e535/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-12T12:20:01",
                "message_text_only": "Good morning Jorge,\n\n> I fail to understand why non recursive covenants are called covenants at all. Probably I'm missing something, but I guess that's another topic.\n\nA covenant simply promises that something will happen in the future.\n\nA recursive covenant guarantees that the same thing will happen in the future.\n\nThus, non-recursive covenants can be useful.\n\nConsider `OP_EVICT`, for example, which is designed for a very specific use-case, and avoids recursion.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-05-12T17:28:39",
                "message_text_only": "@Jorge & Zmn\n>  A recursive covenant guarantees that the same thing will happen in the\nfuture.\n\nJust a clarification: a recursive covenant does not necessarily guarantee\nany particular thing will happen in the future. Both recursives and a\nnon-recursive covenant opcodes *can* be used to guarantee something will\nhappen. Neither *necessarily* guarantee anything (because of\nthe possibility of alternative spend paths). A covenant isn't just a\npromise, its a restriction.\n\nA \"recursive covenant\" opcode is one that allows loops in the progression\nthrough covenant addresses. Here's an example of a set of transitions from\none address with a covenant in the spend path to another (or \"exit\" which\ndoes not have a covenant restriction):\n\nA -> B\nA -> C\nB -> C\nC -> A\nC -> exit\n\nThe possible combinations of changes are:\n\nA -> B -> C -> exit\nA -> C -> A -> ...\nA -> B -> C -> A -> ...\n\nThis would be a recursive covenant with an exit. Remove the exit\ntransition, and you have a walled garden. Even with this walled garden, you\ncan avoid going through address B (since you can skip directly to C).\n\nA covenant opcode that can allow for infinite recursion (often talked about\nas a \"recursive covenant\") can be used to return to a previous state, which\nallows for permanent walled gardens.\n\nSo I would instead characterize a bitcoin covenant as:\n\nA covenant in an input script places a requirement/restriction on the\noutput script(s) that input sends to. Pretty much any covenant allows for a\nchain or graph of covenant-laden addresses to be prescribed, while a\n\"recursive covenant\" opcode allows previous nodes in that graph to be\nreturned to such that the states can be looped through forever (which may\nor may not have some way to exit).\n\nOne potentially confusing thing about the way covenants are usually talked\nabout is that in technical discussions about the risks of covenants, what\nis being talked about is not what a particular covenant opcode always does,\nbut rather what the boundaries are on what can be done with that opcode.\nPretty much any recursive covenant you could design would be able to be\nused to create normal simple non-walled-garden situations. The question is,\nsince they do allow someone to create walled gardens, is that ok.\n\nI suppose maybe an interesting possibility would be to have a covenant\nlimit placed into a covenant opcode. Eg, let's say that you have\nOP_LIMITEDCOVENANT (OP_LC) and OP_LC specifies that the maximum covenant\nchain is 100. The 100th consecutive output with an OP_LC use could simply\nignore it and be spent normally to anywhere (given that the rest of the\nscript allows it). This could effectively prevent the ability to create\nwalled gardens, without eliminating most interesting use cases. Among\npeople who care about covenants on this mailing list, the consensus seems\nto be that infinitely recursive covenants are not something to be afraid\nof. However, if maybe something like this could make more powerful\ncovenants acceptable to a larger group of people, it could be worth doing.\n\nOn Thu, May 12, 2022 at 7:20 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Jorge,\n>\n> > I fail to understand why non recursive covenants are called covenants at\n> all. Probably I'm missing something, but I guess that's another topic.\n>\n> A covenant simply promises that something will happen in the future.\n>\n> A recursive covenant guarantees that the same thing will happen in the\n> future.\n>\n> Thus, non-recursive covenants can be useful.\n>\n> Consider `OP_EVICT`, for example, which is designed for a very specific\n> use-case, and avoids recursion.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220512/23bd0000/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "CTV BIP Meeting #8 Notes",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Keagan McClelland",
                "ZmnSCPxj",
                "alicexbt",
                "Jorge Tim\u00f3n",
                "Billy Tetrud"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 55848
        }
    },
    {
        "title": "[bitcoin-dev] Adding SIGHASH to TXID",
        "thread_messages": [
            {
                "author": "vjudeu at gazeta.pl",
                "date": "2022-05-07T04:50:12",
                "message_text_only": "For now, we have txid:vout as a previous transaction output. This means that to have a stable TXID, we are forced to use SIGHASH_ALL somewhere, just to prevent any transaction modifications that can happen during adding some inputs and outputs. But it seems that new sighashes could be far more powerful than we expected: it is technically possible to not only remove previous transaction output by using SIGHASH_ANYPREVOUT. We can do more and do it better, we could decide, how to calculate this txid at all!\n\nSo, something like SIGHASH_PREVOUT_NONE would be similar to SIGHASH_NONE (applied to the previous transaction, taken from txid). To have SIGHASH_ANYPREVOUT, we need to remove absolutely everything, I don't know any such sighashes, because even SIGHASH_NONE | SIGHASH_ANYONECANPAY will commit at least to some fields, for example to the locktime. But, if we introduce SIGHASH_PREVOUT_XYZ flags for all existing sighashes, we would have this:\n\nSIGHASH_PREVOUT_NONE\nSIGHASH_PREVOUT_SINGLE\nSIGHASH_PREVOUT_ALL\nSIGHASH_PREVOUT_ANYONECANPAY\n\nThen, the procedure is as follows: we use txid:vout to find our previous transaction. Then, we apply those sighashes to this previous transaction, to form a new txid, that will be checked during every OP_CHECKSIG-based opcode. In this way, our txid:vout is used just to do transaction lookup, after that, sighashes can be applied to the previous transaction, so our txid could remain stable, even if someone will add some inputs and outputs.\n\nBy default, we could use SIGHASH_PREVOUT_ALL, that would mean our txid:vout remains unchanged. Then, SIGHASH_PREVOUT_SINGLE would obviously mean, that we want to commit only to this particular previous transaction output. That would allow adding any new outputs to the previous transaction, without affecting our replaced txid, but also without blindly accepting any txid, because some data of the previous transaction would be still hashed.\n\nThen, SIGHASH_PREVOUT_NONE is an interesting case, because it would mean that no outputs of the previous transaction are checked. But still, the inputs will be! That would mean: \"I don't care about in-between addresses, but I care that it was initiated from these inputs\". In this case, it is possible to choose some input without those flags, and then apply SIGHASH_PREVOUT_NONE many times, to make sure that everything started from that input, but everything in-between can be anything.\n\nAll of those three SIGHASH_PREVOUT_XYZ flags could be combined with SIGHASH_PREVOUT_ANYONECANPAY. That would mean all inputs of the previous transaction are discarded, except from the input number matching \"vout\". Or we could just use SIGHASH_PREVOUT_ANY instead and discard all inputs from that previous transaction, that could also be combined with other sighashes.\n\nSo, to sum up, by applying sighashes to the previous transaction, instead of allowing for any transaction, we could still have some control of our txid, and I think it could be better than just saying \"give me any txid, I will accept that\". I think in most cases we don't want to allow any txid: we want to only \"control the flow\", just to make sure that our signatures will sign what we want and will not be invalidated by changing some transaction inputs and outputs, unrelated to the currently-checked signature."
            },
            {
                "author": "Jeremy Rubin",
                "date": "2022-05-07T11:55:35",
                "message_text_only": "Have you seen the inherited ID proposal from John Law on this list?\n\nIt's a pretty thorough treatment of this type of proposal, curious if you\nthink it overlaps what you had in mind?\n\nHonestly, I've yet to fully load in exactly how the applications of it\nwork, but I'd be interested to hear your thoughts.\n\nOn Sat, May 7, 2022, 4:55 AM vjudeu via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> For now, we have txid:vout as a previous transaction output. This means\n> that to have a stable TXID, we are forced to use SIGHASH_ALL somewhere,\n> just to prevent any transaction modifications that can happen during adding\n> some inputs and outputs. But it seems that new sighashes could be far more\n> powerful than we expected: it is technically possible to not only remove\n> previous transaction output by using SIGHASH_ANYPREVOUT. We can do more and\n> do it better, we could decide, how to calculate this txid at all!\n>\n> So, something like SIGHASH_PREVOUT_NONE would be similar to SIGHASH_NONE\n> (applied to the previous transaction, taken from txid). To have\n> SIGHASH_ANYPREVOUT, we need to remove absolutely everything, I don't know\n> any such sighashes, because even SIGHASH_NONE | SIGHASH_ANYONECANPAY will\n> commit at least to some fields, for example to the locktime. But, if we\n> introduce SIGHASH_PREVOUT_XYZ flags for all existing sighashes, we would\n> have this:\n>\n> SIGHASH_PREVOUT_NONE\n> SIGHASH_PREVOUT_SINGLE\n> SIGHASH_PREVOUT_ALL\n> SIGHASH_PREVOUT_ANYONECANPAY\n>\n> Then, the procedure is as follows: we use txid:vout to find our previous\n> transaction. Then, we apply those sighashes to this previous transaction,\n> to form a new txid, that will be checked during every OP_CHECKSIG-based\n> opcode. In this way, our txid:vout is used just to do transaction lookup,\n> after that, sighashes can be applied to the previous transaction, so our\n> txid could remain stable, even if someone will add some inputs and outputs.\n>\n> By default, we could use SIGHASH_PREVOUT_ALL, that would mean our\n> txid:vout remains unchanged. Then, SIGHASH_PREVOUT_SINGLE would obviously\n> mean, that we want to commit only to this particular previous transaction\n> output. That would allow adding any new outputs to the previous\n> transaction, without affecting our replaced txid, but also without blindly\n> accepting any txid, because some data of the previous transaction would be\n> still hashed.\n>\n> Then, SIGHASH_PREVOUT_NONE is an interesting case, because it would mean\n> that no outputs of the previous transaction are checked. But still, the\n> inputs will be! That would mean: \"I don't care about in-between addresses,\n> but I care that it was initiated from these inputs\". In this case, it is\n> possible to choose some input without those flags, and then apply\n> SIGHASH_PREVOUT_NONE many times, to make sure that everything started from\n> that input, but everything in-between can be anything.\n>\n> All of those three SIGHASH_PREVOUT_XYZ flags could be combined with\n> SIGHASH_PREVOUT_ANYONECANPAY. That would mean all inputs of the previous\n> transaction are discarded, except from the input number matching \"vout\". Or\n> we could just use SIGHASH_PREVOUT_ANY instead and discard all inputs from\n> that previous transaction, that could also be combined with other sighashes.\n>\n> So, to sum up, by applying sighashes to the previous transaction, instead\n> of allowing for any transaction, we could still have some control of our\n> txid, and I think it could be better than just saying \"give me any txid, I\n> will accept that\". I think in most cases we don't want to allow any txid:\n> we want to only \"control the flow\", just to make sure that our signatures\n> will sign what we want and will not be invalidated by changing some\n> transaction inputs and outputs, unrelated to the currently-checked\n> signature.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220507/032f51be/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Adding SIGHASH to TXID",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "vjudeu at gazeta.pl",
                "Jeremy Rubin"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 7504
        }
    },
    {
        "title": "[bitcoin-dev] [PROPOSAL] OP_TX: generalized covenants reduced to OP_CHECKTEMPLATEVERIFY",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2022-05-10T10:35:54",
                "message_text_only": "Hi all,\n\n\tTL;DR: a v1 tapscript opcode for generic covenants, but\nOP_SUCCESS unless it's used a-la OP_CHECKTEMPLATEVERIFY.  This gives an\nobvious use case, with clean future expansion.  OP_NOP4 can be\nrepurposed in future as a shortcut, if experience shows that to be a\nuseful optimization.\n\n(This proposal builds on Russell O'Connor's TXHASH[1], with Anthony\nTowns' modification via extending the opcode[2]; I also notice on\nre-reading that James Lu had a similar restriction idea[3]).\n\nDetails\n-------\n\nOP_TX, when inside v1 tapscript, is followed by 4 bytes of flags.\nUnknown flag patterns are OP_SUCCESS, though for thoroughness some future\npotential uses are documented here.  Note that pushing more than 1000\nelements on the stack or an element more than 512 bytes will hit the\nBIP-342 resource limits and fail.\n\nDefined bits\n------------\n\n(Only those marked with * have to be defined for this soft fork; the\n others can have semantics later).\n\nOPTX_SEPARATELY: treat fields separately (vs concatenating)\nOPTX_UNHASHED: push on the stack without hashing (vs SHA256 before push)\n\n- The first nicely sidesteps the lack of OP_CAT, and the latter allows\n  OP_TXHASH semantics (and avoid stack element limits).\n\nOPTX_SELECT_VERSION*: version\nOPTX_SELECT_LOCKTIME*: nLocktime\nOPTX_SELECT_INPUTNUM*: current input number\nOPTX_SELECT_INPUTCOUNT*: number of inputs\nOPTX_SELECT_OUTPUTCOUNT*: number of outputs\n\nOPTX_INPUT_SINGLE: if set, pop input number off stack to apply to\n\t\tOPTX_SELECT_INPUT_*, otherwise iterate through all.\nOPTX_SELECT_INPUT_TXID: txid\nOPTX_SELECT_INPUT_OUTNUM: txout index\nOPTX_SELECT_INPUT_NSEQUENCE*: sequence number\nOPTX_SELECT_INPUT_AMOUNT32x2: sats in, as a high-low u31 pair\nOPTX_SELECT_INPUT_SCRIPT*: input scriptsig\nOPTX_SELECT_INPUT_TAPBRANCH: ?\nOPTX_SELECT_INPUT_TAPLEAF: ?\n\nOPTX_OUTPUT_SINGLE: if set, pop input number off stack to apply to\n\t\tOPTX_SELECT_OUTPUT_*, otherwise iterate through all.\nOPTX_SELECT_OUTPUT_AMOUNT32x2*: sats out, as a high-low u31 pair\nOPTX_SELECT_OUTPUT_SCRIPTPUBKEY*: output scriptpubkey\n\nOPTX_SELECT_19...OPTX_SELECT_31: future expansion.\n\nOP_CHECKTEMPLATEVERIFY is approximated by the following flags:\n\tOPTX_SELECT_VERSION\n\tOPTX_SELECT_LOCKTIME\n\tOPTX_SELECT_INPUTCOUNT\n\tOPTX_SELECT_INPUT_SCRIPT\n\tOPTX_SELECT_INPUT_NSEQUENCE\n\tOPTX_SELECT_OUTPUTCOUNT\n\tOPTX_SELECT_OUTPUT_AMOUNT32x2\n\tOPTX_SELECT_OUTPUT_SCRIPTPUBKEY\n\tOPTX_SELECT_INPUTNUM\n\nAll other flag combinations result in OP_SUCCESS.\n\nDiscussion\n----------\n\nBy enumerating exactly what can be committed to, it's absolutely clear\nwhat is and isn't committed (and what you need to think about!).\n\nThe bits which separate concatenation and hashing provide a simple\nmechanism for template-style (i.e. CTV-style) commitments, or for\nprogramatic treatment of individual elements (e.g. amounts, though the\ntwo s31 style is awkward: a 64-bit push flag could be added in future).\n\nThe lack of double-hashing of scriptsigs and other fields means we\ncannot simply re-use hashing done for SIGHASH_ALL.\n\nThe OP_SUCCESS semantic is only valid in tapscript v1, so this does not\nallow covenants for v0 segwit or pre-segwit inputs.  If covenants prove\nuseful, dedicated opcodes can be provided for those cases (a-la\nOP_CHECKTEMPLATEVERIFY).\n\nCheers,\nRusty.\n\n[1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019813.html\n[2] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019819.html\n[3] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019816.html"
            },
            {
                "author": "Brandon Black",
                "date": "2022-05-10T15:16:10",
                "message_text_only": "Hi Rusty,\n\nThanks for this. Seems like a productive direction to explore.\n\nTo me, one of the biggest limitations of CTV is that the script is\nspecific to the amount of the input being spent. OP_TX makes it\npossible, although clumsy, to emulate OP_IN_OUT_AMOUNT, which could be\ncombined with CTV emulation less OPTX_SELECT_OUTPUT_AMOUNT32x2 to allow\na single script to be reused. Given that potential, I wonder if\nOPTX_SELECT_IN_OUT_AMOUNT32x2 would be worth adding to the initial set\nof flags.\n\nWith that addition, a small script can be constructed for a relocatable,\nbatchable construction (eg. as a building block for vaults):\n\nOPTX_SEPARATELY|OPTX_UNHASHED|OPTX_INPUTNUM OP_TX OP_DUP\n\nOPTX_SELECT_VERSION|\nOPTX_SELECT_LOCKTIME|\nOPTX_SELECT_INPUT_SINGLE|\nOPTX_SELECT_INPUT_SCRIPT|\nOPTX_SELECT_INPUT_NSEQUENCE|\nOPTX_SELECT_OUTPUT_SINGLE|\nOPTX_SELECT_OUTPUT_SCRIPTPUBKEY|\nOPTX_SELECT_IN_OUT_AMOUNT32x2 OP_TX <expectedhash> OP_EQUAL\n\n* Additional inputs and change outputs can be added\n  * Could commit to 0 fee and still be useful\n* Arbitrary amounts can be sent to the same script\n* There is no txid predictability (unlike CTV)\n  * Anyone could rearrange such input/output pairs after broadcast\n\t* Not suitable for some uses\n\t* Potentially helpful for others\n\nBest,\n\n--Brandon\n\nOn 2022-05-10 (Tue) at 20:05:54 +0930, Rusty Russell via bitcoin-dev wrote:\n> Hi all,\n> \n> \tTL;DR: a v1 tapscript opcode for generic covenants, but\n> OP_SUCCESS unless it's used a-la OP_CHECKTEMPLATEVERIFY.  This gives an\n> obvious use case, with clean future expansion.  OP_NOP4 can be\n> repurposed in future as a shortcut, if experience shows that to be a\n> useful optimization.\n> \n> (This proposal builds on Russell O'Connor's TXHASH[1], with Anthony\n> Towns' modification via extending the opcode[2]; I also notice on\n> re-reading that James Lu had a similar restriction idea[3]).\n> \n> Details\n> -------\n> \n> OP_TX, when inside v1 tapscript, is followed by 4 bytes of flags.\n> Unknown flag patterns are OP_SUCCESS, though for thoroughness some future\n> potential uses are documented here.  Note that pushing more than 1000\n> elements on the stack or an element more than 512 bytes will hit the\n> BIP-342 resource limits and fail.\n> \n> Defined bits\n> ------------\n> \n> (Only those marked with * have to be defined for this soft fork; the\n>  others can have semantics later).\n> \n> OPTX_SEPARATELY: treat fields separately (vs concatenating)\n> OPTX_UNHASHED: push on the stack without hashing (vs SHA256 before push)\n> \n> - The first nicely sidesteps the lack of OP_CAT, and the latter allows\n>   OP_TXHASH semantics (and avoid stack element limits).\n> \n> OPTX_SELECT_VERSION*: version\n> OPTX_SELECT_LOCKTIME*: nLocktime\n> OPTX_SELECT_INPUTNUM*: current input number\n> OPTX_SELECT_INPUTCOUNT*: number of inputs\n> OPTX_SELECT_OUTPUTCOUNT*: number of outputs\n> \n> OPTX_INPUT_SINGLE: if set, pop input number off stack to apply to\n> \t\tOPTX_SELECT_INPUT_*, otherwise iterate through all.\n> OPTX_SELECT_INPUT_TXID: txid\n> OPTX_SELECT_INPUT_OUTNUM: txout index\n> OPTX_SELECT_INPUT_NSEQUENCE*: sequence number\n> OPTX_SELECT_INPUT_AMOUNT32x2: sats in, as a high-low u31 pair\n> OPTX_SELECT_INPUT_SCRIPT*: input scriptsig\n> OPTX_SELECT_INPUT_TAPBRANCH: ?\n> OPTX_SELECT_INPUT_TAPLEAF: ?\n> \n> OPTX_OUTPUT_SINGLE: if set, pop input number off stack to apply to\n> \t\tOPTX_SELECT_OUTPUT_*, otherwise iterate through all.\n> OPTX_SELECT_OUTPUT_AMOUNT32x2*: sats out, as a high-low u31 pair\n> OPTX_SELECT_OUTPUT_SCRIPTPUBKEY*: output scriptpubkey\n> \n> OPTX_SELECT_19...OPTX_SELECT_31: future expansion.\n> \n> OP_CHECKTEMPLATEVERIFY is approximated by the following flags:\n> \tOPTX_SELECT_VERSION\n> \tOPTX_SELECT_LOCKTIME\n> \tOPTX_SELECT_INPUTCOUNT\n> \tOPTX_SELECT_INPUT_SCRIPT\n> \tOPTX_SELECT_INPUT_NSEQUENCE\n> \tOPTX_SELECT_OUTPUTCOUNT\n> \tOPTX_SELECT_OUTPUT_AMOUNT32x2\n> \tOPTX_SELECT_OUTPUT_SCRIPTPUBKEY\n> \tOPTX_SELECT_INPUTNUM\n> \n> All other flag combinations result in OP_SUCCESS.\n> \n> Discussion\n> ----------\n> \n> By enumerating exactly what can be committed to, it's absolutely clear\n> what is and isn't committed (and what you need to think about!).\n> \n> The bits which separate concatenation and hashing provide a simple\n> mechanism for template-style (i.e. CTV-style) commitments, or for\n> programatic treatment of individual elements (e.g. amounts, though the\n> two s31 style is awkward: a 64-bit push flag could be added in future).\n> \n> The lack of double-hashing of scriptsigs and other fields means we\n> cannot simply re-use hashing done for SIGHASH_ALL.\n> \n> The OP_SUCCESS semantic is only valid in tapscript v1, so this does not\n> allow covenants for v0 segwit or pre-segwit inputs.  If covenants prove\n> useful, dedicated opcodes can be provided for those cases (a-la\n> OP_CHECKTEMPLATEVERIFY).\n> \n> Cheers,\n> Rusty.\n> \n> [1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019813.html\n> [2] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019819.html\n> [3] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019816.html\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-- \n--Brandon"
            },
            {
                "author": "Alex Schoof",
                "date": "2022-05-11T23:32:34",
                "message_text_only": "Hi Rusty,\n\nOne of the common sentiments thats been expressed over the last few months\nis that more people want to see experimentation with different applications\nusing covenants. I really like this proposal because in addition to\noffering a cleaner upgrade/extension path than adding \u201cCTV++\u201d as a new\nopcode in a few years, it also seems like it would make it very easy to\ncreate prototype applications to game out new ideas:\nIf the \u201conly this combination of fields are valid, otherwise OP_SUCCESS\u201d\ncheck is just comparing with a list of bitmasks for permissible field\ncombinations (which right now is a list of length 1), it seems like it\nwould be *very* easy for people who want to play with other covenant field\nsets to just add the relevant bitmasks and then go spin up a signet to\nbuild applications.\n\nBeing able to make a very targeted change like that to enable\nexperimentation is super cool. Thanks for sharing!\n\nAlex\n\nOn Tue, May 10, 2022 at 6:37 AM Rusty Russell via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi all,\n>\n>         TL;DR: a v1 tapscript opcode for generic covenants, but\n> OP_SUCCESS unless it's used a-la OP_CHECKTEMPLATEVERIFY.  This gives an\n> obvious use case, with clean future expansion.  OP_NOP4 can be\n> repurposed in future as a shortcut, if experience shows that to be a\n> useful optimization.\n>\n> (This proposal builds on Russell O'Connor's TXHASH[1], with Anthony\n> Towns' modification via extending the opcode[2]; I also notice on\n> re-reading that James Lu had a similar restriction idea[3]).\n>\n> Details\n> -------\n>\n> OP_TX, when inside v1 tapscript, is followed by 4 bytes of flags.\n> Unknown flag patterns are OP_SUCCESS, though for thoroughness some future\n> potential uses are documented here.  Note that pushing more than 1000\n> elements on the stack or an element more than 512 bytes will hit the\n> BIP-342 resource limits and fail.\n>\n> Defined bits\n> ------------\n>\n> (Only those marked with * have to be defined for this soft fork; the\n>  others can have semantics later).\n>\n> OPTX_SEPARATELY: treat fields separately (vs concatenating)\n> OPTX_UNHASHED: push on the stack without hashing (vs SHA256 before push)\n>\n> - The first nicely sidesteps the lack of OP_CAT, and the latter allows\n>   OP_TXHASH semantics (and avoid stack element limits).\n>\n> OPTX_SELECT_VERSION*: version\n> OPTX_SELECT_LOCKTIME*: nLocktime\n> OPTX_SELECT_INPUTNUM*: current input number\n> OPTX_SELECT_INPUTCOUNT*: number of inputs\n> OPTX_SELECT_OUTPUTCOUNT*: number of outputs\n>\n> OPTX_INPUT_SINGLE: if set, pop input number off stack to apply to\n>                 OPTX_SELECT_INPUT_*, otherwise iterate through all.\n> OPTX_SELECT_INPUT_TXID: txid\n> OPTX_SELECT_INPUT_OUTNUM: txout index\n> OPTX_SELECT_INPUT_NSEQUENCE*: sequence number\n> OPTX_SELECT_INPUT_AMOUNT32x2: sats in, as a high-low u31 pair\n> OPTX_SELECT_INPUT_SCRIPT*: input scriptsig\n> OPTX_SELECT_INPUT_TAPBRANCH: ?\n> OPTX_SELECT_INPUT_TAPLEAF: ?\n>\n> OPTX_OUTPUT_SINGLE: if set, pop input number off stack to apply to\n>                 OPTX_SELECT_OUTPUT_*, otherwise iterate through all.\n> OPTX_SELECT_OUTPUT_AMOUNT32x2*: sats out, as a high-low u31 pair\n> OPTX_SELECT_OUTPUT_SCRIPTPUBKEY*: output scriptpubkey\n>\n> OPTX_SELECT_19...OPTX_SELECT_31: future expansion.\n>\n> OP_CHECKTEMPLATEVERIFY is approximated by the following flags:\n>         OPTX_SELECT_VERSION\n>         OPTX_SELECT_LOCKTIME\n>         OPTX_SELECT_INPUTCOUNT\n>         OPTX_SELECT_INPUT_SCRIPT\n>         OPTX_SELECT_INPUT_NSEQUENCE\n>         OPTX_SELECT_OUTPUTCOUNT\n>         OPTX_SELECT_OUTPUT_AMOUNT32x2\n>         OPTX_SELECT_OUTPUT_SCRIPTPUBKEY\n>         OPTX_SELECT_INPUTNUM\n>\n> All other flag combinations result in OP_SUCCESS.\n>\n> Discussion\n> ----------\n>\n> By enumerating exactly what can be committed to, it's absolutely clear\n> what is and isn't committed (and what you need to think about!).\n>\n> The bits which separate concatenation and hashing provide a simple\n> mechanism for template-style (i.e. CTV-style) commitments, or for\n> programatic treatment of individual elements (e.g. amounts, though the\n> two s31 style is awkward: a 64-bit push flag could be added in future).\n>\n> The lack of double-hashing of scriptsigs and other fields means we\n> cannot simply re-use hashing done for SIGHASH_ALL.\n>\n> The OP_SUCCESS semantic is only valid in tapscript v1, so this does not\n> allow covenants for v0 segwit or pre-segwit inputs.  If covenants prove\n> useful, dedicated opcodes can be provided for those cases (a-la\n> OP_CHECKTEMPLATEVERIFY).\n>\n> Cheers,\n> Rusty.\n>\n> [1]\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019813.html\n> [2]\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019819.html\n> [3]\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019816.html\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-- \n\n\nAlex Schoof\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220511/03fcb3bf/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "OP_TX: generalized covenants reduced to OP_CHECKTEMPLATEVERIFY",
            "categories": [
                "bitcoin-dev",
                "PROPOSAL"
            ],
            "authors": [
                "Rusty Russell",
                "Alex Schoof",
                "Brandon Black"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 13967
        }
    },
    {
        "title": "[bitcoin-dev] Improving BIP 8 soft fork activation",
        "thread_messages": [
            {
                "author": "alicexbt",
                "date": "2022-05-10T13:40:37",
                "message_text_only": "Hi Bitcoin Developers,\n\nThere were some disagreements with speedy trial activation method recently and BIP 8 became controversial because of LOT earlier. I have tried to solve these two problems after reading some arguments for/against different activation methods by removing LOT from BIP 8 and calculating MUST_SIGNAL state based on threshold reached.\n\nBIP draft with no code and some changes in BIP 8: https://gist.github.com/1440000bytes/5e58cad7ba9d9c1a7000d304920fe6f1\n\nState transitions diagram: https://i.imgur.com/dj4bFVK.png\n\nThis proposal removes lockinontimeout flag, activation never fails although MUST_SIGNAL can be longer if miners signaling does not reach the threshold. Longer period for MUST_SIGNAL state is useful for coordination if LOCKED_IN was not reached.\n\nMUST_SIGNAL = ((100-t)/10)*2016 blocks, where t is threshold reached and blocks that fail to signal in MUST_SIGNAL phase are invalid.\n\nExample:\n\n- This activation method is used for a soft fork\n- Only 60% miners signaled readiness and timeout height was reached\n- MUST_SIGNAL phase starts and will last for 4*2016 blocks\n- LOCKED_IN and ACTIVE states remain same as BIP 8\n- Soft fork is activated with a delay of 2 months\n\n/dev/fd0\n\nSent with [ProtonMail](https://protonmail.com/) secure email.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220510/1d4ece3d/attachment.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-05-10T15:31:17",
                "message_text_only": "I think this is a useful proposal. There are certainly things about BIP9\nthat BIP8 fixes. I believe taproot's speedy trial did kind of a hybrid, but\na BIP spec was never produced for it afaik. A possibly unhelpful comment:\n\n> minimum_activation_height\n\nI think a minor improvement would be to specify this as\nminimum_activation_blocks, ie a number of blocks passed the start_height.\nSlightly easier to reason about and change when necessary. I proposed\nsemantics like that here\n<https://github.com/fresheneesz/bip-trinary-version-signaling/blob/master/bip-trinary-version-bits.md>\n.\n\nIn any case, I'll give this a concept ACK. I would very much like future\nsoft forks to use a previously specified activation mechanism rather than\nrolling out a rushed unspeced thing as part of the (very orthogonal) soft\nfork implementation.\n\nOn Tue, May 10, 2022 at 9:02 AM alicexbt via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Bitcoin Developers,\n>\n> There were some disagreements with speedy trial activation method recently\n> and BIP 8 became controversial because of LOT earlier. I have tried to\n> solve these two problems after reading some arguments for/against different\n> activation methods by removing LOT from BIP 8 and calculating MUST_SIGNAL\n> state based on threshold reached.\n>\n> BIP draft with no code and some changes in BIP 8:\n> https://gist.github.com/1440000bytes/5e58cad7ba9d9c1a7000d304920fe6f1\n>\n> State transitions diagram: https://i.imgur.com/dj4bFVK.png\n>\n> This proposal removes lockinontimeout flag, activation never fails\n> although MUST_SIGNAL can be longer if miners signaling does not reach the\n> threshold. Longer period for MUST_SIGNAL state is useful for coordination\n> if LOCKED_IN was not reached.\n>\n> MUST_SIGNAL = ((100-t)/10)*2016 blocks, where t is threshold reached and\n> blocks that fail to signal in MUST_SIGNAL phase are invalid.\n>\n> Example:\n>\n> - This activation method is used for a soft fork\n> - Only 60% miners signaled readiness and timeout height was reached\n> - MUST_SIGNAL phase starts and will last for 4*2016 blocks\n> - LOCKED_IN and ACTIVE states remain same as BIP 8\n> - Soft fork is activated with a delay of 2 months\n>\n>\n> /dev/fd0\n>\n> Sent with ProtonMail <https://protonmail.com/> secure email.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220510/af6e90ce/attachment.html>"
            },
            {
                "author": "alicexbt",
                "date": "2022-05-11T15:15:15",
                "message_text_only": "Hi Billy,\n\nThanks for the feedback. I agree with everything and\u00a0bip-trinary-version-signaling looks interesting.\n\n> A primary difference from both BIP8 and BIP9 is that this proposal uses tri-state version signaling (rather than binary version bits) that can encode both active support as well as active opposition to an active soft fork.\n\n\nI think 'support' and 'opposition' can be replaced with readiness. Miners should not consider signaling as voting.\n\n> The meaning for each ternary value is as follows:\n\n\n0 - No signal\n1 - Ready for new consensus rules\n2 - Not ready for new consensus rules\n\nThe concept of a minimum and maximum threshold sounds intriguing, and I'm interested to read what other developers have to say about it.\n\nConcept ACK on removing LOT, using tri-state version signaling,\u00a0min/max threshold and required threshold calculation.\n\n\n/dev/fd0\n\nSent with ProtonMail secure email.\n------- Original Message -------\nOn Tuesday, May 10th, 2022 at 9:01 PM, Billy Tetrud billy.tetrud at gmail.com wrote:\n\n\n\n> I think this is a useful proposal. There are certainly things about BIP9 that BIP8 fixes. I believe taproot's speedy trial did kind of a hybrid, but a BIP spec was never produced for it afaik. A possibly unhelpful comment:\n>\n> > minimum_activation_height\n> > I think a minor improvement would be to specify this as minimum_activation_blocks, ie a number of blocks passed the start_height. Slightly easier to reason about and change when necessary. I proposed semantics like that here.\n> > In any case, I'll give this a concept ACK. I would very much like future soft forks to use a previously specified activation mechanism rather than rolling out a rushed unspeced thing as part of the (very orthogonal) soft fork implementation.\n> > On Tue, May 10, 2022 at 9:02 AM alicexbt via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:\n>\n> > Hi Bitcoin Developers,\n> >\n> > There were some disagreements with speedy trial activation method recently and BIP 8 became controversial because of LOT earlier. I have tried to solve these two problems after reading some arguments for/against different activation methods by removing LOT from BIP 8 and calculating MUST_SIGNAL state based on threshold reached.\n> >\n> > BIP draft with no code and some changes in BIP 8: https://gist.github.com/1440000bytes/5e58cad7ba9d9c1a7000d304920fe6f1\n> >\n> > State transitions diagram: https://i.imgur.com/dj4bFVK.png\n> >\n> > This proposal removes lockinontimeout flag, activation never fails although MUST_SIGNAL can be longer if miners signaling does not reach the threshold. Longer period for MUST_SIGNAL state is useful for coordination if LOCKED_IN was not reached.\n> >\n> > MUST_SIGNAL = ((100-t)/10)*2016 blocks, where t is threshold reached and blocks that fail to signal in MUST_SIGNAL phase are invalid.\n> >\n> > Example:\n> >\n> > - This activation method is used for a soft fork\n> > - Only 60% miners signaled readiness and timeout height was reached\n> > - MUST_SIGNAL phase starts and will last for 4*2016 blocks\n> > - LOCKED_IN and ACTIVE states remain same as BIP 8\n> > - Soft fork is activated with a delay of 2 months\n> >\n> > /dev/fd0\n> >\n> > Sent with ProtonMail secure email._______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-05-13T12:23:39",
                "message_text_only": "@alicexbt\n>  I think 'support' and 'opposition' can be replaced with readiness.\nMiners should not consider signaling as voting.\n\nI agree that it isn't voting, its signaling. But whether or not you call it\n'readiness' or 'support', some miners will use it to signal 'support' and\nwill refuse to become ready if they do not support the change. Regardless,\nI'm open to calling it \"readiness\" instead.\n\n@Russell\n>  I'm sure there are lots of design choices available better than a\nMUST_SIGNAL state that does not risk potentially taking a large fraction of\nmining hardware offline for a protracted period of time.\n\nI tend to agree. The case where the fork has not locked in, but some miners\nare beginning to orphan other miners' blocks, seems like a rather chaotic\nstate to program into an activation mechanism. I do like the idea of using\norphaning to ensure that miners are alerted to the fact that a fork has\n*already* locked in, but such a thing should be done at a low level (eg\norphan <10% of their blocks) - just high enough so the drop in revenue\nmakes them investigate, but as minimal as possible to avoid lots of orphans\nand loss of hashpower.\n\n\nOn Wed, May 11, 2022 at 10:15 AM alicexbt <alicexbt at protonmail.com> wrote:\n\n> Hi Billy,\n>\n> Thanks for the feedback. I agree with everything\n> and bip-trinary-version-signaling looks interesting.\n>\n> > A primary difference from both BIP8 and BIP9 is that this proposal uses\n> tri-state version signaling (rather than binary version bits) that can\n> encode both active support as well as active opposition to an active soft\n> fork.\n>\n>\n> I think 'support' and 'opposition' can be replaced with readiness. Miners\n> should not consider signaling as voting.\n>\n> > The meaning for each ternary value is as follows:\n>\n>\n> 0 - No signal\n> 1 - Ready for new consensus rules\n> 2 - Not ready for new consensus rules\n>\n> The concept of a minimum and maximum threshold sounds intriguing, and I'm\n> interested to read what other developers have to say about it.\n>\n> Concept ACK on removing LOT, using tri-state version signaling, min/max\n> threshold and required threshold calculation.\n>\n>\n> /dev/fd0\n>\n> Sent with ProtonMail secure email.\n> ------- Original Message -------\n> On Tuesday, May 10th, 2022 at 9:01 PM, Billy Tetrud billy.tetrud at gmail.com\n> wrote:\n>\n>\n>\n> > I think this is a useful proposal. There are certainly things about BIP9\n> that BIP8 fixes. I believe taproot's speedy trial did kind of a hybrid, but\n> a BIP spec was never produced for it afaik. A possibly unhelpful comment:\n> >\n> > > minimum_activation_height\n> > > I think a minor improvement would be to specify this as\n> minimum_activation_blocks, ie a number of blocks passed the start_height.\n> Slightly easier to reason about and change when necessary. I proposed\n> semantics like that here.\n> > > In any case, I'll give this a concept ACK. I would very much like\n> future soft forks to use a previously specified activation mechanism rather\n> than rolling out a rushed unspeced thing as part of the (very orthogonal)\n> soft fork implementation.\n> > > On Tue, May 10, 2022 at 9:02 AM alicexbt via bitcoin-dev\n> bitcoin-dev at lists.linuxfoundation.org wrote:\n> >\n> > > Hi Bitcoin Developers,\n> > >\n> > > There were some disagreements with speedy trial activation method\n> recently and BIP 8 became controversial because of LOT earlier. I have\n> tried to solve these two problems after reading some arguments for/against\n> different activation methods by removing LOT from BIP 8 and calculating\n> MUST_SIGNAL state based on threshold reached.\n> > >\n> > > BIP draft with no code and some changes in BIP 8:\n> https://gist.github.com/1440000bytes/5e58cad7ba9d9c1a7000d304920fe6f1\n> > >\n> > > State transitions diagram: https://i.imgur.com/dj4bFVK.png\n> > >\n> > > This proposal removes lockinontimeout flag, activation never fails\n> although MUST_SIGNAL can be longer if miners signaling does not reach the\n> threshold. Longer period for MUST_SIGNAL state is useful for coordination\n> if LOCKED_IN was not reached.\n> > >\n> > > MUST_SIGNAL = ((100-t)/10)*2016 blocks, where t is threshold reached\n> and blocks that fail to signal in MUST_SIGNAL phase are invalid.\n> > >\n> > > Example:\n> > >\n> > > - This activation method is used for a soft fork\n> > > - Only 60% miners signaled readiness and timeout height was reached\n> > > - MUST_SIGNAL phase starts and will last for 4*2016 blocks\n> > > - LOCKED_IN and ACTIVE states remain same as BIP 8\n> > > - Soft fork is activated with a delay of 2 months\n> > >\n> > > /dev/fd0\n> > >\n> > > Sent with ProtonMail secure\n> email._______________________________________________\n> > > bitcoin-dev mailing list\n> > > bitcoin-dev at lists.linuxfoundation.org\n> > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220513/6fbdf8b8/attachment.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2022-05-11T19:22:40",
                "message_text_only": "Hi alicexbt,\n\nAs far as I understand things, I believe the whole notion of a MUST_SIGNAL\nstate is misguided today. Please correct me if I'm misunderstanding\nsomething here.\n\nBack when BIP8 was first proposed by Shaolin Fry, we were in a situation\nwhere many existing clients waiting for segwit signalling had already been\ndeployed.  The purpose of mandatory signaling at that point in time was to\nensure all these existing clients would be activated together with any BIP8\nclients.\n\nHowever, if such other clients do not exist, the MUST_SIGNAL state no\nlonger accomplishes its purpose.  Going forward, I think there is little\nreason to expect such other clients to exist alongside a BIP8 deployment.\nIf everyone uses a BIP8 deployment, then there are no other clients to\nactivate.  Alternatively, Speedy Trial was specifically designed to avoid\nthis parallel deployment for the reason that several people object to\nallowing their client's non-BIP8 activation logic to be hijacked in this\nmanner.\n\nNow I understand that some people would like *some* signal on the chain\nthat indicates a soft-fork activation in order to allow people who object\nto the fork to make an \"anti-fork\" that rejects blocks containing the\nsoft-fork signal.  And while some sort of mandatory version bit signaling\n*could* be used for this purpose, we do not *have* to use version bits.  We\nalso don't need such a signal span over multiple blocks.  Indeed, using\nversion bits and signaling over multiple blocks is quite bad because it\nrisks losing mining power if miners don't conform, or are unable to\nconform, to the version bits signal.  (Recall at the time taproot's\nsignaling period started, the firmware needed for many miners to signal\nversion bits did not even exist yet!).\n\nA soft-fork signal to enable an \"anti-fork\" only needs to be on a single\nblock and it can be almost anything.  For example we could have a signal\nthat at the block at lockin or perhaps the block at activation requires\nthat the coinbase must *not* contain the suffix \"taproot sucks!\".  This\nsuffices to prepare an \"anti-fork\" which would simply require that the\nspecified block must contain the suffix \"taproot sucks!\".\n\nAnyway, I'm sure there are lots of design choices available better than a\nMUST_SIGNAL state that does not risk potentially taking a large fraction of\nmining hardware offline for a protracted period of time.\n\nOn Tue, May 10, 2022 at 10:02 AM alicexbt via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Bitcoin Developers,\n>\n> There were some disagreements with speedy trial activation method recently\n> and BIP 8 became controversial because of LOT earlier. I have tried to\n> solve these two problems after reading some arguments for/against different\n> activation methods by removing LOT from BIP 8 and calculating MUST_SIGNAL\n> state based on threshold reached.\n>\n> BIP draft with no code and some changes in BIP 8:\n> https://gist.github.com/1440000bytes/5e58cad7ba9d9c1a7000d304920fe6f1\n>\n> State transitions diagram: https://i.imgur.com/dj4bFVK.png\n>\n> This proposal removes lockinontimeout flag, activation never fails\n> although MUST_SIGNAL can be longer if miners signaling does not reach the\n> threshold. Longer period for MUST_SIGNAL state is useful for coordination\n> if LOCKED_IN was not reached.\n>\n> MUST_SIGNAL = ((100-t)/10)*2016 blocks, where t is threshold reached and\n> blocks that fail to signal in MUST_SIGNAL phase are invalid.\n>\n> Example:\n>\n> - This activation method is used for a soft fork\n> - Only 60% miners signaled readiness and timeout height was reached\n> - MUST_SIGNAL phase starts and will last for 4*2016 blocks\n> - LOCKED_IN and ACTIVE states remain same as BIP 8\n> - Soft fork is activated with a delay of 2 months\n>\n>\n> /dev/fd0\n>\n> Sent with ProtonMail <https://protonmail.com/> secure email.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220511/2cdd2915/attachment.html>"
            },
            {
                "author": "alicexbt",
                "date": "2022-05-12T19:59:38",
                "message_text_only": "Hi Russell,\n\n> As far as I understand things, I believe the whole notion of a MUST_SIGNAL state is misguided today. Please correct me if I'm misunderstanding something here.\n> Back when BIP8 was first proposed by Shaolin Fry, we were in a situation where many existing clients waiting for segwit signalling had already been deployed. The purpose of mandatory signaling at that point in time was to ensure all these existing clients would be activated together with any BIP8 clients.\n\nI won't consider it misguided. Not using MUST_SIGNAL gives opportunity for drama and politics during signaling. MUST_SIGNAL phase is initiated when height + 2016 >= timeoutheight and if a mining pool is still not sure about signaling at that point, maybe they are not interested in mining bitcoin anymore.\n\nRephrasing 'motivation' section in BIP 8:\n\nBIP 9 activation is dependent on near unanimous hashrate signaling which may be impractical and result in veto by a small minority of non-signaling hashrate. All consensus rules are ultimately enforced by full nodes, eventually any new soft fork will be enforced by the economy. BIP 8 provides optional flag day activation after a reasonable time, as well as for accelerated activation by majority of hash rate before the flag date.\n\n> We also don't need such a signal span over multiple blocks. Indeed, using version bits and signaling over multiple blocks is quite bad because it risks losing mining power if miners don't conform, or are unable to conform, to the version bits signal. (Recall at the time taproot's signaling period started, the firmware needed for many miners to signal version bits did not even exist yet!).\n\nSolutions to these problems:\n\n1)Developers plan and ship the binaries with activation code in time.\n2)Mining pools pay attention, participate in soft fork discussions, hire competent developers and reach out to developers in community if require help.\n3)Mining pools understand the loss involved in mining invalid blocks and upgrade during the first month of signaling.\n\nIf some mining pools still mine invalid blocks, Bitcoin should still work normally as it did during May-June 2021 when 50% hashrate went down due to some issues in China.\n\n/dev/fd0\n\nSent with [ProtonMail](https://protonmail.com/) secure email.\n\n------- Original Message -------\nOn Thursday, May 12th, 2022 at 12:52 AM, Russell O'Connor via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi alicexbt,\n>\n> As far as I understand things, I believe the whole notion of a MUST_SIGNAL state is misguided today. Please correct me if I'm misunderstanding something here.\n>\n> Back when BIP8 was first proposed by Shaolin Fry, we were in a situation where many existing clients waiting for segwit signalling had already been deployed. The purpose of mandatory signaling at that point in time was to ensure all these existing clients would be activated together with any BIP8 clients.\n>\n> However, if such other clients do not exist, the MUST_SIGNAL state no longer accomplishes its purpose. Going forward, I think there is little reason to expect such other clients to exist alongside a BIP8 deployment. If everyone uses a BIP8 deployment, then there are no other clients to activate. Alternatively, Speedy Trial was specifically designed to avoid this parallel deployment for the reason that several people object to allowing their client's non-BIP8 activation logic to be hijacked in this manner.\n>\n> Now I understand that some people would like *some* signal on the chain that indicates a soft-fork activation in order to allow people who object to the fork to make an \"anti-fork\" that rejects blocks containing the soft-fork signal. And while some sort of mandatory version bit signaling *could* be used for this purpose, we do not *have* to use version bits. We also don't need such a signal span over multiple blocks. Indeed, using version bits and signaling over multiple blocks is quite bad because it risks losing mining power if miners don't conform, or are unable to conform, to the version bits signal. (Recall at the time taproot's signaling period started, the firmware needed for many miners to signal version bits did not even exist yet!).\n>\n> A soft-fork signal to enable an \"anti-fork\" only needs to be on a single block and it can be almost anything. For example we could have a signal that at the block at lockin or perhaps the block at activation requires that the coinbase must *not* contain the suffix \"taproot sucks!\". This suffices to prepare an \"anti-fork\" which would simply require that the specified block must contain the suffix \"taproot sucks!\".\n>\n> Anyway, I'm sure there are lots of design choices available better than a MUST_SIGNAL state that does not risk potentially taking a large fraction of mining hardware offline for a protracted period of time.\n>\n> On Tue, May 10, 2022 at 10:02 AM alicexbt via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi Bitcoin Developers,\n>>\n>> There were some disagreements with speedy trial activation method recently and BIP 8 became controversial because of LOT earlier. I have tried to solve these two problems after reading some arguments for/against different activation methods by removing LOT from BIP 8 and calculating MUST_SIGNAL state based on threshold reached.\n>>\n>> BIP draft with no code and some changes in BIP 8: https://gist.github.com/1440000bytes/5e58cad7ba9d9c1a7000d304920fe6f1\n>>\n>> State transitions diagram: https://i.imgur.com/dj4bFVK.png\n>>\n>> This proposal removes lockinontimeout flag, activation never fails although MUST_SIGNAL can be longer if miners signaling does not reach the threshold. Longer period for MUST_SIGNAL state is useful for coordination if LOCKED_IN was not reached.\n>>\n>> MUST_SIGNAL = ((100-t)/10)*2016 blocks, where t is threshold reached and blocks that fail to signal in MUST_SIGNAL phase are invalid.\n>>\n>> Example:\n>>\n>> - This activation method is used for a soft fork\n>> - Only 60% miners signaled readiness and timeout height was reached\n>> - MUST_SIGNAL phase starts and will last for 4*2016 blocks\n>> - LOCKED_IN and ACTIVE states remain same as BIP 8\n>> - Soft fork is activated with a delay of 2 months\n>>\n>> /dev/fd0\n>>\n>> Sent with [ProtonMail](https://protonmail.com/) secure email.\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220512/29942cf8/attachment-0001.html>"
            },
            {
                "author": "Greg Sanders",
                "date": "2022-05-12T22:56:22",
                "message_text_only": "I think you may be confused. Mandatory signaling is not the same thing as\nmandatory activation on timeout, aka Lock On Timeout aka LOT=true.\n\nThese are two related but separate things.\n\nOn Thu, May 12, 2022, 6:53 PM alicexbt via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Russell,\n>\n>\n> As far as I understand things, I believe the whole notion of a MUST_SIGNAL\n> state is misguided today. Please correct me if I'm misunderstanding\n> something here.\n>\n> Back when BIP8 was first proposed by Shaolin Fry, we were in a situation\n> where many existing clients waiting for segwit signalling had already been\n> deployed. The purpose of mandatory signaling at that point in time was to\n> ensure all these existing clients would be activated together with any BIP8\n> clients.\n>\n>\n> I won't consider it misguided. Not using MUST_SIGNAL gives opportunity for\n> drama and politics during signaling. MUST_SIGNAL phase is initiated when\n> height + 2016 >= timeoutheight and if a mining pool is still not sure about\n> signaling at that point, maybe they are not interested in mining bitcoin\n> anymore.\n>\n> Rephrasing 'motivation' section in BIP 8:\n>\n> BIP 9 activation is dependent on near unanimous hashrate signaling which\n> may be impractical and result in veto by a small minority of\n> non-signaling hashrate. All consensus rules are ultimately enforced by full\n> nodes, eventually any new soft fork will be enforced by the economy. BIP 8\n> provides optional flag day activation after a reasonable time, as well as\n> for accelerated activation by majority of hash rate before the flag date.\n>\n> We also don't need such a signal span over multiple blocks. Indeed, using\n> version bits and signaling over multiple blocks is quite bad because it\n> risks losing mining power if miners don't conform, or are unable to\n> conform, to the version bits signal. (Recall at the time taproot's\n> signaling period started, the firmware needed for many miners to signal\n> version bits did not even exist yet!).\n>\n>\n> Solutions to these problems:\n>\n> 1)Developers plan and ship the binaries with activation code in time.\n> 2)Mining pools pay attention, participate in soft fork discussions, hire\n> competent developers and reach out to developers in community if require\n> help.\n> 3)Mining pools understand the loss involved in mining invalid blocks and\n> upgrade during the first month of signaling.\n>\n> If some mining pools still mine invalid blocks, Bitcoin should still work\n> normally as it did during May-June 2021 when 50% hashrate went down due to\n> some issues in China.\n>\n>\n> /dev/fd0\n>\n> Sent with ProtonMail <https://protonmail.com/> secure email.\n>\n> ------- Original Message -------\n> On Thursday, May 12th, 2022 at 12:52 AM, Russell O'Connor via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Hi alicexbt,\n>\n> As far as I understand things, I believe the whole notion of a MUST_SIGNAL\n> state is misguided today. Please correct me if I'm misunderstanding\n> something here.\n>\n> Back when BIP8 was first proposed by Shaolin Fry, we were in a situation\n> where many existing clients waiting for segwit signalling had already been\n> deployed. The purpose of mandatory signaling at that point in time was to\n> ensure all these existing clients would be activated together with any BIP8\n> clients.\n>\n> However, if such other clients do not exist, the MUST_SIGNAL state no\n> longer accomplishes its purpose. Going forward, I think there is little\n> reason to expect such other clients to exist alongside a BIP8 deployment.\n> If everyone uses a BIP8 deployment, then there are no other clients to\n> activate. Alternatively, Speedy Trial was specifically designed to avoid\n> this parallel deployment for the reason that several people object to\n> allowing their client's non-BIP8 activation logic to be hijacked in this\n> manner.\n>\n> Now I understand that some people would like *some* signal on the chain\n> that indicates a soft-fork activation in order to allow people who object\n> to the fork to make an \"anti-fork\" that rejects blocks containing the\n> soft-fork signal. And while some sort of mandatory version bit signaling\n> *could* be used for this purpose, we do not *have* to use version bits. We\n> also don't need such a signal span over multiple blocks. Indeed, using\n> version bits and signaling over multiple blocks is quite bad because it\n> risks losing mining power if miners don't conform, or are unable to\n> conform, to the version bits signal. (Recall at the time taproot's\n> signaling period started, the firmware needed for many miners to signal\n> version bits did not even exist yet!).\n>\n> A soft-fork signal to enable an \"anti-fork\" only needs to be on a single\n> block and it can be almost anything. For example we could have a signal\n> that at the block at lockin or perhaps the block at activation requires\n> that the coinbase must *not* contain the suffix \"taproot sucks!\". This\n> suffices to prepare an \"anti-fork\" which would simply require that the\n> specified block must contain the suffix \"taproot sucks!\".\n>\n> Anyway, I'm sure there are lots of design choices available better than a\n> MUST_SIGNAL state that does not risk potentially taking a large fraction of\n> mining hardware offline for a protracted period of time.\n>\n> On Tue, May 10, 2022 at 10:02 AM alicexbt via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi Bitcoin Developers,\n>>\n>> There were some disagreements with speedy trial activation method\n>> recently and BIP 8 became controversial because of LOT earlier. I have\n>> tried to solve these two problems after reading some arguments for/against\n>> different activation methods by removing LOT from BIP 8 and calculating\n>> MUST_SIGNAL state based on threshold reached.\n>>\n>> BIP draft with no code and some changes in BIP 8:\n>> https://gist.github.com/1440000bytes/5e58cad7ba9d9c1a7000d304920fe6f1\n>>\n>> State transitions diagram: https://i.imgur.com/dj4bFVK.png\n>>\n>> This proposal removes lockinontimeout flag, activation never fails\n>> although MUST_SIGNAL can be longer if miners signaling does not reach the\n>> threshold. Longer period for MUST_SIGNAL state is useful for coordination\n>> if LOCKED_IN was not reached.\n>>\n>> MUST_SIGNAL = ((100-t)/10)*2016 blocks, where t is threshold reached and\n>> blocks that fail to signal in MUST_SIGNAL phase are invalid.\n>>\n>> Example:\n>>\n>> - This activation method is used for a soft fork\n>> - Only 60% miners signaled readiness and timeout height was reached\n>> - MUST_SIGNAL phase starts and will last for 4*2016 blocks\n>> - LOCKED_IN and ACTIVE states remain same as BIP 8\n>> - Soft fork is activated with a delay of 2 months\n>>\n>>\n>> /dev/fd0\n>>\n>> Sent with ProtonMail <https://protonmail.com/> secure email.\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220512/ee216a78/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Improving BIP 8 soft fork activation",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Russell O'Connor",
                "alicexbt",
                "Billy Tetrud",
                "Greg Sanders"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 30629
        }
    },
    {
        "title": "[bitcoin-dev] Bringing a nuke to a knife fight: Transaction introspection to stop RBF pinning",
        "thread_messages": [
            {
                "author": "Greg Sanders",
                "date": "2022-05-10T18:53:14",
                "message_text_only": "Hello devs,\n\nI've had this thought rattling around and thought it was worth putting to a\nwider audience since\nI haven't really seen it in other contexts. I've been working on eltoo\ndesigns for Elements and\neventual inclusion into Bitcoin. With that in mind there's been a\nreasonable amount of discussion\non the remaining unknowns on how well eltoo could work. To me the biggest\nissue is BIP125 rule#3.\n\nTo quote:\"The replacement transaction pays an absolute fee of at least the\nsum paid by the original\ntransactions.\"\n\nIn the ANYONECANPAY-like scenarios like eltoo that require \"bring your own\nfees\", this essentially\nmeans the counterparty(or anyone, if you don't include chaperone sigs[0])\ncan post a series of low\nfeerate update transactions, or the final update, with bloated\ninputs/outputs(depending on flags),\nand this results in illicit HTLC timeouts as the channel is unable to be\nsettled in time, unless you fork\nover quite a few sats. This is a problem in both \"vanilla\" eltoo[1] from\nthe original paper, as well as the\n\"layered commitments\" style of eltoo[2]. This problem is highly reminiscent\nof the ANYONECANPAY\npinning that others have discussed for vaults and other usecases, in that\nanyone can include new\ninputs(and sometimes outputs) to make the overall feerate lower. To\npromptly get the final transactions\nsettled, you are forced to over-pay, and essentially refund your griefing\ncounterparty by knocking their\ninputs out of the mempool.\n\nFixing BIP125 rule#3 would be great. It's also a while out at a minimum.\n\nThere are thoughts on how to mitigate some cases[3] of this pinning using\npolicy, and could be extended\nto cover this particular pinning case(restrict both transaction weight AND\nthe weight of the descendant\npackage, or maybe just include the txns weight in the original idea?). This\nmight be the simplest idea,\nif it ends up being deemed incentive compatible and deployed.\n\nIn case the above is not incentive compatible, we can use more drastic\nmeasures. Another tactic would\nbe to use transaction introspection opcodes to smooth around these policy\nissues.\n\nElements has its own set of transaction introspection codes[4], but fairly\nstandard introspection codes\nseem to be sufficient.\n\nThis example is using Rusty's quite recent OP_TX proposal[5] with a single\nextension but as mentioned\nbefore it's all fairly standard. The actual eltoo-enabling opcode\nimplementation is basically orthogonal\nto this problem, so I'm simply focusing on restricting the size of the\ntransaction package being\nsubmitted to mempools.\n\nFor simplicity of a working example, we'll assume a set of \"state\" outputs\nthat are continuously being spent\noff-chain and sent to a committed set of outputs. In vanilla eltoo case\nthis corresponds to the first\ninput and output you typically see in diagrams. The state transitions\ninclude no fees themselves,\nsending inputs of sum value N to outputs that sum to the value of N.\nVanilla eltoo uses SIGHASH_SINGLE\nto bind just the first input/ouput pair. To post on-chain, we will need to\ninclude at least one input,\nand likely an output for change.\n\nWe add OPTX_SELECT_WEIGHT(pushes tx weight to stack, my addition to the\nproposal) to the \"state\" input's script.\nThis is used in the update transaction to set the upper bound on the final\ntransaction weight.\nIn this same input, for each contract participant, we also conditionally\ncommit to the change output's scriptpubkey\nvia OPTX_SELECT_OUTPUT_SCRIPTPUBKEY and OPTX_SELECT_OUTPUTCOUNT==2. This\nmeans any participant can send change back\nto themselves, but with a catch. Each change output script possibility in\nthat state input also includes a 1 block\nCSV to avoid mempool spending to reintroduce pinning. This allows the\nchange value to be anything, contra to\nwhat SIGHASH_ALL would give you instead.\n\nWith this setup, you can't CPFP-spend the fee change outputs you create,\nbut you can RBF as much as\nyou'd like by RBFing at higher feerates, using any number of inputs you'd\nlike provided the total tx\nweight doesn't exceed the OPTX_SELECT_WEIGHT argument.\n\nWith more engineering we can re-enable CPFP of this change output as well.\nHandwaves here, but we could\nencumber change outputs to either the aformentioned 1 block CSV encumbered\noutputs or one to another\nOPTX_SELECT_WEIGHT, recursively. This would allow each counterparty to CPFP\nN times, each transaction\na maximum weight, and use the 1 block CSV as an \"escape hatch\" to get their\nfee output back out from\nthe covenant structure. We could mix and match strategies here as well\nallowing bigger transactions at\neach step, or more steps. I suspect you'd want a single weight-bound CPFP\nthat can later be RBF'd any\nnumber of times under this same weight limit.\n\nTL;DR: Mempool is hard, let's use transaction weight, output count, and\noutput scriptpubkey,\nand ??? introspection to avoid solving life's hard problems.\n\n0:\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2019-May/001994.html\n1: https://blockstream.com/eltoo.pdf\n2:\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2020-January/002448.html\n3:\nhttps://gist.github.com/glozow/25d9662c52453bd08b4b4b1d3783b9ff?permalink_comment_id=4058140#gistcomment-4058140\n4:\nhttps://github.com/ElementsProject/elements/blob/master/doc/tapscript_opcodes.md\n5:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-May/020450.html\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220510/ab9b8fc8/attachment.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2022-05-12T07:17:05",
                "message_text_only": "On 2022-05-10 08:53, Greg Sanders via bitcoin-dev wrote:\n> We add OPTX_SELECT_WEIGHT(pushes tx weight to stack, my addition to\n> the proposal) to the \"state\" input's script.\n> This is used in the update transaction to set the upper bound on the\n> final transaction weight.\n> In this same input, for each contract participant, we also\n> conditionally commit to the change output's scriptpubkey\n> via OPTX_SELECT_OUTPUT_SCRIPTPUBKEY and OPTX_SELECT_OUTPUTCOUNT==2.\n> This means any participant can send change back\n> to themselves, but with a catch. Each change output script possibility\n> in that state input also includes a 1 block\n> CSV to avoid mempool spending to reintroduce pinning.\n\nI like the idea!   However, I'm not sure the `1 CSV` trick helps much.  \nCan't an attacker just submit to the mempool their other eltoo state \nupdates?  For example, let's assume Bob and Mallory have a channel with \n >25 updates and Mallory wants to prevent update[-1] from being committed onchain before its (H|P)TLC timeout.  Mallory also has at least 25 unencumbered UTXOs, so she submits to the mempool update[0], update[1], update[...], update[24]---each of them with a different second input to pay fees.\n\nIf `OPTX_SELECT_WEIGHT OP_TX` limits each update's weight to 1,000 \nvbytes[1] and the default node relay/mempool policy of allowing a \ntransaction and up to 24 descendants remains, Mallory can pin the \nunsubmitted update[-1] under 25,000 vbytes of junk---which is 25% of \nwhat she can pin under current mempool policies.\n\nAlice can't RBF update[0] without paying for update[1..24] (BIP125 rule \n#3), and an RBF of update[24] will have its additional fees divided by \nits size plus the 24,000 vbytes of update[1..24].\n\nTo me, that seems like your proposal makes escaping the pinning at most \n75% cheaper than today.  That's certainly an improvement---yay!---but \nI'm not sure it eliminates the underlying concern.  Also depending on \nthe mempool ancestor/descendant limits makes it harder to raise those \nlimits in the future, which is something I think we might want to do if \nwe can ensure raising them won't increase node memory/CPU DoS risk.\n\nI'd love to hear that my analysis is missing something though!\n\nThanks!,\n\n-Dave\n\n[1] 1,000 vbytes per update seems like a reasonable value to me.  \nObviously there's a tradeoff here: making it smaller limits the amount \nof pinning possible (assuming mempool ancestor/descendant limits remain) \nbut also limits the number and complexity of inputs that may be added.  \nI don't think we want to discourage people too much from holding \nbitcoins in deep taproot trees or sophisticated tapscripts."
            },
            {
                "author": "Greg Sanders",
                "date": "2022-05-12T13:31:02",
                "message_text_only": "Great point in this specific case I unfortunately didn't consider! So\nbasically the design degenerates to the last option I gave, where the\ncounterparty\ncan send off N(25) weight-bound packages.\n\nA couple thoughts:\n\n0) Couldn't we relative-time lock update transactions's state input by 1\nblock as well to close the vector off? People are allowed\none \"update transaction package\" at a time in mempool, so if detected\nin-mempool it can be RBF'd, or in-block can be immediately responded to.\n1) other usages of ANYONECANPAY like behavior may not have these issues,\nlike vault structures.\n\n\nOn Thu, May 12, 2022, 3:17 AM David A. Harding <dave at dtrt.org> wrote:\n\n> On 2022-05-10 08:53, Greg Sanders via bitcoin-dev wrote:\n> > We add OPTX_SELECT_WEIGHT(pushes tx weight to stack, my addition to\n> > the proposal) to the \"state\" input's script.\n> > This is used in the update transaction to set the upper bound on the\n> > final transaction weight.\n> > In this same input, for each contract participant, we also\n> > conditionally commit to the change output's scriptpubkey\n> > via OPTX_SELECT_OUTPUT_SCRIPTPUBKEY and OPTX_SELECT_OUTPUTCOUNT==2.\n> > This means any participant can send change back\n> > to themselves, but with a catch. Each change output script possibility\n> > in that state input also includes a 1 block\n> > CSV to avoid mempool spending to reintroduce pinning.\n>\n> I like the idea!   However, I'm not sure the `1 CSV` trick helps much.\n> Can't an attacker just submit to the mempool their other eltoo state\n> updates?  For example, let's assume Bob and Mallory have a channel with\n>  >25 updates and Mallory wants to prevent update[-1] from being committed\n> onchain before its (H|P)TLC timeout.  Mallory also has at least 25\n> unencumbered UTXOs, so she submits to the mempool update[0], update[1],\n> update[...], update[24]---each of them with a different second input to pay\n> fees.\n>\n> If `OPTX_SELECT_WEIGHT OP_TX` limits each update's weight to 1,000\n> vbytes[1] and the default node relay/mempool policy of allowing a\n> transaction and up to 24 descendants remains, Mallory can pin the\n> unsubmitted update[-1] under 25,000 vbytes of junk---which is 25% of\n> what she can pin under current mempool policies.\n>\n> Alice can't RBF update[0] without paying for update[1..24] (BIP125 rule\n> #3), and an RBF of update[24] will have its additional fees divided by\n> its size plus the 24,000 vbytes of update[1..24].\n>\n> To me, that seems like your proposal makes escaping the pinning at most\n> 75% cheaper than today.  That's certainly an improvement---yay!---but\n> I'm not sure it eliminates the underlying concern.  Also depending on\n> the mempool ancestor/descendant limits makes it harder to raise those\n> limits in the future, which is something I think we might want to do if\n> we can ensure raising them won't increase node memory/CPU DoS risk.\n>\n> I'd love to hear that my analysis is missing something though!\n>\n> Thanks!,\n>\n> -Dave\n>\n> [1] 1,000 vbytes per update seems like a reasonable value to me.\n> Obviously there's a tradeoff here: making it smaller limits the amount\n> of pinning possible (assuming mempool ancestor/descendant limits remain)\n> but also limits the number and complexity of inputs that may be added.\n> I don't think we want to discourage people too much from holding\n> bitcoins in deep taproot trees or sophisticated tapscripts.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220512/6333a535/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Bringing a nuke to a knife fight: Transaction introspection to stop RBF pinning",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "David A. Harding",
                "Greg Sanders"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 11741
        }
    },
    {
        "title": "[bitcoin-dev] Soliciting more discussion for OP_CONSTRAINDESTINATION (a covenant opcode)",
        "thread_messages": [
            {
                "author": "Billy Tetrud",
                "date": "2022-05-13T13:05:47",
                "message_text_only": "Hi all,\n\nSince there's recently been a lot more interest in discussing covenants and\nalternative covenant proposals because of CTV, I figured I'd bring up my\nown proposed covenant opcode again while the urge is still fresh.\n\nTo be clear upfront, this opcode has a spec, but nothing else. No tests. No\nimplementation. No signet. No tooling. While this is a serious proposal\nthat I think has a lot of benefits over any other covenant opcode proposal,\nI am not suggesting that this should supplant CTV. I also don't have any\nplans to work on an implementation of OP_CONSTRAINDESTINATION, and I\ncertainly wouldn't without more interest and an equal partner on a project\nlike this.  I think CTV is a quite useful opcode that is simple and\nincremental. OP_CD on the other hand is significantly more powerful, which\nwould be likely to lead to even more contention than what CTV has had.\n\nTo the opcode itself, there is already plenty of exposition about it in the\nspec:\n\nhttps://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/bip-constraindestination.md\n\nSo I wanted to discuss it from the perspective of what it enables, pros and\ncons, and key considerations:\n\n*OP_CONSTRAINDESTINATION alone*\n\n   - Like OP_CTV\n      - Is fully enumerated (not open ended)\n   - Unlike OP_CTV\n      - Enables infinitely recursive covenants\n      - Does not and cannot prevent malleability on its own\n\nThe wallet vaults that can be created\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/op_cdWalletVault1.md>\nusing this are more flexible than ones that can be created with OP_CTV:\n\n   - Spends from a wallet vault can spend arbitrary amounts, and send the\n   rest back to a change address, just like a normal transaction.\n   - Arbitrary amounts of coins can be sent directly to any of the\n   addresses involved in the wallet vault without any risk of loss of funds.\n   - Anchor outputs are not (necessarily) necessary for fee bumping. A user\n   can have the option of creating a transaction that includes other inputs\n   that can contribute to the fee. Those inputs can also send to other\n   outputs, allowing one to basically attach an anchor output at\n   transaction-creation-time if they think they want it for CPFP fee bumping.\n\nOne less-than-ideal property shared with CTV wallet vaults:\n\n   - If the hot wallet / intermediate wallet key is stolen, the attacker\n   can steal funds after the owner initiates a normal spend.\n\nThe opcode requires some mechanism for fee limiting:\n\n   - As currently specified, an attacker who gets access to the hot key can\n   fee-grief the owner of the vault by spending all the coins as fees. The\n   proposed solution to this is to add an addition opcode to limit the fees,\n   called OP_LIMITFEECONTRIBUTION\n   <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/lfc/bip-limit-fee-contribution.md>.\n   Another solution would be to require 100% of the output values go to the\n   destinations passed to OP_CONSTRAINDESTINATION, and rely on CPFP on an\n   anchor output to pay the fees, which seems less than ideal. A third\n   solution would be to include sponsor transactions alongside the opcode and\n   rely on those instead of CPFP. While I think sponsor transactions would be\n   very useful, always relying on an external wallet to pay the fees is IMO\n   not super great since it allows for inconvenient scenarios if all your\n   money is in this secure vault, in which case you simply wouldn't be able to\n   get it out without either first acquiring more bitcoin in a hotter wallet,\n   or doing a full recovery transaction with all your wallet vault keys.\n\nThe downsides compared to CTV:\n\n   - Increased implementation complexity and complexity of the possibility\n   space. The opcode's main purpose of ensuring that only certain addresses\n   are sent to might be simpler than CTV, but the aspect of counting output\n   values pushes it into more complex territory. And when you consider the\n   solutions to fee-griefing, that adds additional implementation and\n   possibility-space complexity (depending on how its done).\n   - txid malleability\n\n\n*OP_CONSTRAINDESTINATION + OP_PUSHOUTPUTSTACK*\nOP_PUSHOUTPUTSTACK\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/pos/bip-pushoutputstack.md>\nis\nan opcode that allows a script to dynamically add local state to an output\nbeing created.\n\n   - Unlike OP_CTV\n   - Also enables infinitely recursive covenants and does not prevent\n      malleability.\n      - Can be open ended (not fully enumerated)\n      - Can produce dynamic state.\n\nThe wallet vaults that can be created with this combination of opcodes is a\nbit better than ones with just OP_CD on its own:\n\n   - Even if the hot wallet key is stolen, the attacker cannot steal funds\n   without compromising all the seeds that make up the wallet vault.\n\nHowever, the complexity is substantially higher:\n\n   - Being able to push dynamic state onto transactions substantially\n   increases the possibility space of covenant chains. There may be\n   significant consequences of this that no one has thought of yet.\n\n*Summary*\n\nThese opcodes would allow the creation of wallet vaults that could be\nintuitively used in almost the same way that a standard wallet can be used,\nincluding mixing in arbitrary inputs and outputs (including ones you don't\nown). With one more opcode\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/bbv/bip-beforeblockverify.md>,\nfunds could be sent directly out of a wallet vault in a single transaction\n(whereas most wallet vaults require two transactions to send money out to\nan arbitrary destination).\n\nThe opcodes are significantly more complex and powerful than OP_CTV, and\nalso substantially less developed. However, I think they demonstrate a\nnumber of important considerations for covenants in the context of wallet\nvaults. Please feel free to respond or ask questions here or as a github\nissue.\n\nI think wallet vaults in particular are a very important mechanism to\nenable much more secure self-custody setups without sacrificing so much\nusability as normal multisig wallets require. Wallet vaults could enable\nsignificantly faster growth in the rate of bitcoin holders who\nself-custody. CTV is the only opcode that is ready, and no other opcode is\neven being developed, let alone close to being ready. I don't see APO as a\ngood practical covenant mechanism as currently defined. Any \"next\" covenant\nopcode would likely be 4-6 years out. I believe centralized custody is a\nhuge problem in the bitcoin ecosystem, so I think making it easier for\npeople to securely self-custody their bitcoins is an incredibly important\narea of development. I believe even *if* some other covenant opcode makes\nCTV completely obsolete (which it isn't at all clear to me is a likely\nscenario), a 4-6 year head start on better self-custody mechanisms could go\na long way to saving a lot of people who need bitcoin a lot of pain (from\nboth custodial shenanigans and self-custody mishaps).\n\nCheers,\nBT\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220513/3f91a9e9/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Soliciting more discussion for OP_CONSTRAINDESTINATION (a covenant opcode)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Billy Tetrud"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 7211
        }
    },
    {
        "title": "[bitcoin-dev] A small tweak to TLUV to enable off-chain cancellation of payment pool transactions",
        "thread_messages": [
            {
                "author": "Antoine Riard",
                "date": "2022-05-16T00:01:29",
                "message_text_only": "Hi,\n\nProposing a small tweak to TLUV to enable cancellation of an off-chain\ntransaction among a set of pool participants. Namely, to give the index of\nthe constrained output as an opcode item.\n\nUsing CoinPool terminology, the Withdraw phase happens by a participant\npublishing an Update transaction and her own Withdraw transaction, freeing\nher balance from the pool control. From then, any participant can\nrecursively and unilaterally publish a Withdraw transaction. Or the\nconsensus of the remaining participants can agree to stay in the pool by\ncancelling the non-published Withdraw transactions with a Snapshot one\nspending the pool output. This transaction implies a rotation of the\ntapscripts, effectively cancelling the Withdraws.\n\nThe presence of this latest transaction is a bit artificial and could be\nremoved by cancelling the non-published Withdraw transactions. This\ncancellation would be manifested by producing a group signature spending\nany non-published Withdraw transaction `pool_output` and `balance_output`.\n\nIf the SIGHASH_ANYPREVOUTANYSCRIPT semantic is used, this re-lifting Update\ntransaction could be attached on any Withdraw transaction, even if the user\nbalances are not equal, as the amounts are not committed. To enable\nrebinding on multiple cancelled Withdraw\ntransactions, I think SIGHASH_ANYONECANPAY could be used.\n\nHowever, the group producing the signature to spend any cancelled output\nshould reflect the new set of pool participants after the withdrawals have\nbeen played out. Any withdrawing user should have been removed, as there is\nno interest anymore to\ncontribute to the signature. We would like to avoid a former participant\nwith nothing at stake in the pool to block the pool operations.\n\nE,g let's say you have Alice, Bob, Caroll and Dave as pool participants.\nEach of them owns a Withdraw transaction to exit their individual balances\nat any time. Alice publishes her Withdraw transaction. Bob, Caroll and Dave\nwould like to cancel their non-published ones to pursue the pool\noperations. To cancel the non-published transactions, only Bob, Caroll and\nDave should be part of the group of signers encumbering the non-published\nWithdraw transactions outputs.\n\nThat said, the composition of this group of signers is a function of the\nWithdraw transactions order, and as thus is unknown at pool state\ngeneration. Therefore, it should be constrained leveraging some covenant\nmechanism.\n\nI believe this is achievable using TLUV semantics, at the condition to add\nan output index to target the second output. Currently, a Withdraw\ntransaction `balance_output` is only the owner pubkey. The update internal\npubkey should also be inherited there to make the output cancellable. The\nowner withdrawing capability could be moved as a timelock + a key inside a\ntapscript.\n\nA tapscript from a CoinPool Withdraw transaction currently looks like this\n\"0 A MERKLESUB P CHECKSIGVERIFY\" [0]\n\nThe new tapscript would duplicate TLUV with an output index to constrain\nthe spending transactions both outputs, and therefore make them cancellable:\n\n\"<output_index=0> <control_integer> <path_step> <pubkey_tweak> TLUV\n<output_index=1 <control_integer> <path_step> <pubkey_tweak> TLUV\n<pubkey> CHECKSIGVERIFY\"\n\nI think it is a really slight modification of TLUV and it might serve other\nuse-cases, beyond the payment pool one ?\n\nThoughts ?\n\n[0] While it could be argue to split TLUV in two smaller opcodes like\nOP_MERKLESUB or a hypothesis OP_MERKLEADD to save few bytes when only the\nsubtraction or the addition feature is used, I'm not sure it's worthy the\ncomplexity increased. In the context of payment pools, the usage of a TLUV\nopcode should only happen in case of \"pessimistic\" non-cooperative\npublication...\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220515/5c5ac4ea/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "A small tweak to TLUV to enable off-chain cancellation of payment pool transactions",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Antoine Riard"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3917
        }
    },
    {
        "title": "[bitcoin-dev] Improving chaumian ecash and sidechains with fidelity bond federations",
        "thread_messages": [
            {
                "author": "Chris Belcher",
                "date": "2022-05-16T10:26:45",
                "message_text_only": "Hello list,\n\nFidelity bonds could be used to help create trust-minimized federations \nthat are needed for things like chaumian ecash servers or sidechains.\n\n From what I've seen until now, people working on chaumian ecash or \nsidechains say that the federation controlling the multisig keys will be \nbased on some kind of reputation. Perhaps it will be some pseudonymous \nnyms that have built up a good reputation over a long time. I suggest \nanother option is to use fidelity bonds to decide who gets to control \nthe multisig keys.\n\nFidelity bonds are a way to deliberately sacrifice bitcoin value in a \nway that can be proven to a third party. In practice this is done by \nsending bitcoins to an address which is time-locked using the \nOP_CHECKTIMELOCKVERIFY opcode. The redeemscript and UTXO, along with a \nsignature, can be shown to anyone to prove that the sacrifice happened. \nThis system has already been deployed in JoinMarket since August 2021, \nand at the time of writing about 600 btc have been locked up, some for \nseveral years. The whole scheme is similar in some ways to PoW that \nbitcoin itself uses to avoid sybil attacks when solving the double spend \nproblem.\n\nIt's important to understand what is the value-add of fidelity bonds and \nwhat it isn't. Fidelity bonds don't solve the trust issue, as someone \nwith a big fidelity bond could still steal funds from the ecash server \nor sidechain using multisig keys they control. Such systems will always \nbe custodial.\n\nRather, fidelity bonds strongly incentivize that the different fidelity \nbond owners are actually different people. That might be exactly the \nkind of thing needed for distributing the keys of big multisigs, \nespecially now that taproot allows us to create very big multisig \nschemes. This happens because the value of a fidelity bond is calculated \nas a greater-than-linear power of the bitcoin sacrifice. So for example \nif the power was 2, and someone sacrificed 5 bitcoins of value, their \nfidelity bond would be worth 5 x 5 = 25. If instead they sacrificed 6 \nbitcoins their fidelity bond would be worth 6 x 6 = 36. This superlinear \npower is what creates a strong incentive for the different fidelity \nbonds to actually be controlled by different people, because anyone \nbehaving rationally will put all their bitcoins into just one fidelity, \nnot split them up over many bonds. As a sybil attacker needs to \ndistribute their bitcoins over many different bonds, they are \nmathematically punished. The fidelity bond system achieves this without \nrevealing anything much about those people's identities.\n\nAnother value-add of fidelity bonds is they are very much in keeping \nwith the cypherpunk ethos, as anyone can create a fidelity bond and \nadvertise it in the market. As the bitcoins can be mixed with coinjoin \nbefore and after sending to the timelocked address, the scheme doesn't \nhave to be linked to any identity. Only money talks; not reputation, \npolitical power or geographical power.\n\nI don't know yet exactly the details of how such a scheme would work, \nmaybe something like each fidelity bond owner creates a key in the \nmultisig scheme, and transaction fees from the sidechain or ecash server \nare divided amongst the fidelity bonds in proportion to their fidelity \nbond value.\n\nRegards\nCB"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-16T11:26:38",
                "message_text_only": "Good morning Chris,\n\n> I don't know yet exactly the details of how such a scheme would work,\n> maybe something like each fidelity bond owner creates a key in the\n> multisig scheme, and transaction fees from the sidechain or ecash server\n> are divided amongst the fidelity bonds in proportion to their fidelity\n> bond value.\n\nSuch a scheme would probably look a little like my old ideas about \"mainstake\", where you lock up funds on the mainchain and use that as your right to construct new sidechain blocks, with your share of the sideblocks proportional to the value of the mainstake you locked up.\n\nOf note is that it need not operate as a sidechain or chaumian bank, anything that requires a federation can use this scheme as well.\nFor instance, statechains are effectively federation-guarded CoinPools, and could use a similar scheme for selecting federation members.\nSmart contracts unchained can also have users be guided by fidelity bonds in order to select federation members.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Improving chaumian ecash and sidechains with fidelity bond federations",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Chris Belcher",
                "ZmnSCPxj"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 4298
        }
    },
    {
        "title": "[bitcoin-dev] CTV Meeting #9 Reminder + Agenda (Tuesday, May 17th, 12:00 PT / 7PM UTC)",
        "thread_messages": [
            {
                "author": "Jeremy Rubin",
                "date": "2022-05-17T04:27:46",
                "message_text_only": "Developers,\n\nA reminder that the regularly scheduled CTV Meeting is tomorrow at 12:00\nPacific Time in ##ctv-bip-review in Libera.\n\nIn terms of agenda, we'll keep it as an open forum for discussion guided by\nthe participants. We'll try to go over, minimally:\n\n- Rusty's OP_TX\n- Adding OP_CAT / CSFS\n\nFeel free to propose meeting topics in the IRC in advance of the meeting to\naid in allocating time to things that you would like to have discussed.\n\nBest,\n\nJeremy\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220516/514650f5/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "CTV Meeting #9 Reminder + Agenda (Tuesday, May 17th, 12:00 PT / 7PM UTC)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy Rubin"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 695
        }
    },
    {
        "title": "[bitcoin-dev] Package Relay Proposal",
        "thread_messages": [
            {
                "author": "Gloria Zhao",
                "date": "2022-05-17T16:01:04",
                "message_text_only": "Hi everybody,\n\nI\u2019m writing to propose a set of p2p protocol changes to enable package\nrelay, soliciting feedback on the design and approach. Here is a link\nto the most up-to-date proposal:\n\nhttps://github.com/bitcoin/bips/pull/1324\n\nIf you have concept or approach feedback, *please respond on the\nmailing list* to allow everybody to view and participate in the\ndiscussion. If you find a typo or inaccurate wording, please feel free\nto leave suggestions on the PR.\n\nI\u2019m also working on an implementation for Bitcoin Core.\n\n\nThe rest of this post will include the same contents as the proposal,\nwith a bit of reordering and additional context. If you are not 100%\nup-to-date on package relay and find the proposal hard to follow, I\nhope you find this format more informative and persuasive.\n\n\n==Background and Motivation==\n\nUsers may create and broadcast transactions that depend upon, i.e.\nspend outputs of, unconfirmed transactions. A \u201cpackage\u201d is the\nwidely-used term for a group of transactions representable by a\nconnected Directed Acyclic Graph (where a directed edge exists between\na transaction that spends the output of another transaction).\n\nIncentive-compatible mempool and miner policies help create a fair,\nfee-based market for block space. While miners maximize transaction\nfees in order to earn higher block rewards, non-mining users\nparticipating in transaction relay reap many benefits from employing\npolicies that result in a mempool with the same contents, including\nfaster compact block relay and more accurate fee estimation.\nAdditionally, users may take advantage of mempool and miner policy to\nbump the priority of their transactions by attaching high-fee\ndescendants (Child Pays for Parent or CPFP).  Only considering\ntransactions one at a time for submission to the mempool creates a\nlimitation in the node's ability to determine which transactions have\nthe highest feerates, since it cannot take into account descendants\nuntil all the transactions are in the mempool. Similarly, it cannot\nuse a transaction's descendants when considering which of two\nconflicting transactions to keep (Replace by Fee or RBF).\n\nWhen a user's transaction does not meet a mempool's minimum feerate\nand they cannot create a replacement transaction directly, their\ntransaction will simply be rejected by this mempool. They also cannot\nattach a descendant to pay for replacing a conflicting transaction.\nThis limitation harms users' ability to fee-bump their transactions.\nFurther, it presents a security issue in contracting protocols which\nrely on **presigned**, time-sensitive transactions to prevent cheating\n(HTLC-Timeout in LN Penalty [1] [2] [3], Unvault Cancel in Revault\n[4], Refund Transaction in Discreet Log Contracts [5], Updates in\neltoo [6]). In other words, a key security assumption of many\ncontracting protocols is that all parties can propagate and confirm\ntransactions in a timely manner.\n\nIn the past few years, increasing attention [0][1][2][3][6] has been\nbrought to **pinning attacks**, a type of censorship in which the\nattacker uses mempool policy restrictions to prevent a transaction\nfrom being relayed or getting mined.  TLDR: revocation transactions\nmust meet a certain confirmation target to be effective, but their\nfeerates are negotiated well ahead of broadcast time. If the\nforecasted feerate was too low and no fee-bumping options are\navailable, attackers can steal money from their counterparties. I walk\nthrough a concrete example for stealing Lightning HTLC outputs at\n~23:58 in this talk [7][8].  Note that most attacks are only possible\nwhen the market for blockspace at broadcast time  demands much higher\nfeerates than originally anticipated at signing time. Always\noverestimating fees may sidestep this issue temporarily (while mempool\ntraffic is low and predictable), but this solution is not foolproof\nand wastes users' money. The feerate market can change due to sudden\nspikes in traffic (e.g. huge 12sat/vB dump a few days ago [9]) or\nsustained, high volume of Bitcoin payments (e.g.  April 2021 and\nDecember 2017).\n\nThe best solution is to enable nodes to consider packages of\ntransactions as a unit, e.g. one or more low-fee parent transactions\nwith a high-fee child, instead of separately. A package-aware mempool\npolicy can help determine if it would actually be economically\nrational to accept a transaction to the mempool if it doesn't meet fee\nrequirements individually. Network-wide adoption of these policies\nwould create a more purely-feerate-based market for block space and\nallow contracting protocols to adjust fees (and therefore mining\npriority) at broadcast time.  Some support for packages has existed in\nBitcoin Core for years. Since v0.13, Bitcoin Core has used ancestor\npackages instead of individual transactions to evaluate the incentive\ncompatibility of transactions in the mempool [10] and select them for\ninclusion in blocks [11].\n\nPackage Relay, the concept of {announcing, requesting, downloading}\npackages between nodes on the p2p network, has also been discussed for\nmany years. The earliest public mention I can find is from 2015 [12].\nThe two most common use cases for package relay are fee-bumping\notherwise-too-low-fee transactions and reducing the amount of orphans.\nIt seems uncontroversial to say that everybody desires package relay\nconceptually, with varying degrees of urgency. Lots of work has been\ndone by others over the past few years, from which I've taken\ninspiration from [13][14][15][16].\n\nMy approach has been to split the project into two components: (1) Package\nMempool Accept, which includes validation logic and mempool policy.\n(3) Package Relay, which includes the p2p protocol changes.\n\nProgress so far:\nAfter discussions with various developers of contracting protocols\n(with heavier emphasis towards LN), it was determined that a\npackage containing a child with all of its unconfirmed parents\n(child-with-unconfirmed-parents or 1-child-multi-parent package) would\nbe sufficient for their use case, i.e. fee-bumping presigned\ntransactions. A child-with-unconfirmed-parents package has several\nproperties that make many things easier to reason about.\n\nA few months ago, I proposed a set of policies for safe package\nvalidation and fee assessment for packages of this restricted\ntopology [17]. A series of PRs implementing this proposal have\nbeen merged into Bitcoin Core [18].\n\nTheoretically, developing a safe and incentive-compatible package\nmempool acceptance policy is sufficient to solve this issue. Nodes\ncould opportunistically accept packages (e.g. by trying combinations\nof transactions rejected from their mempools), but this practice would\nlikely be inefficient at best and open new Denial of Service attacks\nat worst. Additional p2p messages may enable nodes to request and\nshare package validation-related information with one another in a\nmore communication-efficient way.\n\nGiven that only package RBF remains for package mempool accept, and we\ncan make progress on p2p and mempool in parallel, I think it\u2019s\nappropriate to put forward a package relay proposal.\n\n==Proposal==\n\nThis proposal contains 2 components: a \u201cgeneric\u201d package relay\nprotocol and an extension of it, child-with-unconfirmed-parents\npackages, as version 1 package relay. Another version of packages,\n\u201ctx-with-unconfirmed-ancestors\u201d can be created to extend package relay\nfor eliminating orphans.\n\n===Generic Package Relay===\n\nTwo main ideas are introduced:\n\nDownload and validate packages of transactions together.\n\nProvide information to help peers decide whether to request and/or how\nto validate transactions which are part of a package.\n\n====Intended Protocol Flow====\n\nDue to the asynchronous nature of a distributed transaction relay\nnetwork, nodes may not receive all of the information needed to\nvalidate a transaction at once. For example, after a node completes\nInitial Block Download (IBD) and first starts participating in\ntransaction relay with an empty mempool, it is common to receive\norphans. In such scenarios where a node is aware that it is missing\ninformation, a ''receiver-initiated'' dialogue is appropriate:\n\n1. Receiver requests package information.\n\n2. The sender provides package information, including the wtxids of\n   the transactions in the package and anything else that might be\nrelevant (e.g. total fees and size).\n\n3. The reciever uses the package information to decide how to request\n   and validate the transactions.\n\nSometimes, no matter what order transactions are received by a node,\nvalidating them individually is insufficient. When the sender is aware\nof additional information that the receiver needs to accept a package,\na proactive ''sender-initiated'' dialogue should be enabled:\n\n1. Sender announces they have package information pertaining to a\n   transaction that might otherwise be undesired on its own.\n\n2. The receiver requests package information.\n\n3. The sender provides package information, including the wtxids of\n   the transactions in the package and anything else that might be\nrelevant (e.g. total fees and size).\n\n4. The reciever uses the package information to decide how to request\n   and validate the transactions.\n\nPackage relay is negotiated between two peers during the version\nhandshake. Package relay requires both peers to support wtxid-based\nrelay because package transactions are referenced by their wtxid.\n\n====New Messages====\n\nThree new protocol messages are added for use in any version of\npackage relay. Additionally, each version of package relay must define\nits own inv type and \"pckginfo\" message version, referred to in this\ndocument as \"MSG_PCKG\" and \"pckginfo\" respectively. See\nBIP-v1-packages for a concrete example.\n\n=====sendpackages=====\n\n{|\n|  Field Name  ||  Type  ||  Size  ||  Purpose\n|-\n|version || uint32_t || 4 || Denotes a package version supported by the\nnode.\n|-\n|max_count || uint32_t || 4 ||Specifies the maximum number of transactions\nper package this node is\nwilling to accept.\n|-\n|max_weight || uint32_t || 4 ||Specifies the maximum total weight per\npackage this node is willing\nto accept.\n|-\n|}\n\n1. The \"sendpackages\" message has the structure defined above, with\n   pchCommand == \"sendpackages\".\n\n2. During version handshake, nodes should send a \"sendpackages\"\n   message indicate they support package relay and may request\npackages.\n\n3. The message should contain a version supported by the node. Nodes\n   should send a \"sendpackages\" message for each version they support.\n\n4. The \"sendpackages\" message MUST be sent before sending a \"verack\"\n   message. If a \"sendpackages\" message is received afer \"verack\", the\nsender should be disconnected.\n\n5. If 'fRelay==false' in a peer's version message, the node must not\n   send \"sendpackages\" to them. If a \"sendpackages\" message is\nreceived by a peer after sending `fRelay==false` in their version\nmessage, the sender should be disconnected.\n\n6.. Upon receipt of a \"sendpackages\" message with a version that is\nnot supported, a node must treat the peer as if it never received the\nmessage.\n\n7. If both peers send \"wtxidrelay\" and \"sendpackages\" with the same\n   version, the peers should announce, request, and send package\ninformation to each other.\n\n=====getpckgtxns=====\n\n{|\n|  Field Name  ||  Type  ||  Size  ||   Purpose\n|-\n|txns_length||CompactSize||1 or 3 bytes|| The number of transactions\nrequested.\n|-\n|txns||List of wtxids||txns_length * 32|| The wtxids of each transaction in\nthe package.\n|}\n\n1. The \"getpckgtxns\" message has the structure defined above, with\n   pchCommand == \"getpckgtxns\".\n\n2. A \"getpckgtxns\" message should be used to request all or some of\n   the transactions previously announced in a \"pckginfo\" message,\nspecified by witness transactiosome id.\n\n3. Upon receipt of a \"getpckgtxns\" message, a node must respond with\n   either a \"pckgtxns\" containing the requested transactions or a\n\"notfound\" message indicating one or more of the transactions is\nunavailable. This allows the receiver to avoid downloading and storing\ntransactions that cannot be validated immediately.\n\n4. A \"getpckgtxns\" message should only be sent if both peers agreed to\n   send packages in the version handshake. If a \"getpckgtxns\" message\nis received from a peer with which package relay was not negotiated,\nthe sender should be disconnected.\n\n=====pckgtxns=====\n\n{|\n|  Field Name  ||  Type  ||  Size  ||   Purpose\n|-\n|txns_length||CompactSize||1 or 3 bytes|| The number of transactions\nprovided.\n|-\n|txns||List of transactions||variable|| The transactions in the package.\n|}\n\n1. The \"pckgtxns\" message has the structure defined above, with\n   pchCommand == \"pckgtxns\".\n\n2. A \"pckgtxns\" message should contain the transaction data requested\n   using \"getpckgtxns\".\n\n3. A \"pckgtxns\" message should only be sent to a peer that requested\n   the package using \"getpckgtxns\". If a node receives an unsolicited\npackage, the sender should be disconnected.\n\n4. A \"pckgtxns\" message should only be sent if both peers agreed to\n   send packages in the version handshake. If a \"pckgtxns\" message is\nreceived from a peer with which package relay was not negotiated, the\nsender should be disconnected.\n\n===Version 1 Packages: child-with-unconfirmed-parents===\n\nThis extends package relay for packages consisting of one transaction\nand all of its unconfirmed parents,by defining version 1 packages, a\npckginfo1 message, and a MSG_PCKG1 inv type. It enables the use case\nin which a child pays for its otherwise-too-low-fee parents and their\nmempool conflict(s).\n\n====Intended Protocol Flow====\n\nWhen relaying a package of low-fee parent(s) and high-fee child, the\nsender and receiver do the following:\n\n1. Sender announces they have a child-with-unconfirmed-parents package\n   for a child that pays for otherwise-too-low-fee parent(s) using\n\"inv(MSG_PCKG1)\".\n\n2. The receiver requests package information using\n   \"getdata(MSG_PCKG1)\".\n\n3. The sender provides package information using \"pckginfo1\",\n   including the blockhash of the sender's best block, the wtxids of\nthe transactions in the package, their total fees and total weight.\n\n4. The reciever uses the package information to decide how to request\n   the transactions. For example, if the receiver already has some of\nthe transactions in their mempool, they only request the missing ones.\nThey could also decide not to request the package at all based on the\nfee information provided.\n\n5. Upon receiving a \"pckgtxns\", the receiver submits the transactions\n   together as a package.\n\n====New Messages====\n\nA new inv type, \"MSG_PCKG1\", and new protocol message, \"PCKGINFO1\",\nare added.\n\n=====pckginfo1=====\n\n{|\n|  Field Name  ||  Type  ||  Size  ||   Purpose\n|-\n|blockhash || uint256 || 32 || The chain tip at which this package is\ndefined.\n|-\n|pckg_fee||CAmount||4|| The sum total fees paid by all transactions in the\npackage.\n|-\n|pckg_weight||int64_t||8|| The sum total weight of all transactions in the\npackage.\n|-\n|txns_length||CompactSize||1 or 3 bytes|| The number of transactions\nprovided.\n|-\n|txns||List of wtxids||txns_length * 32|| The wtxids of each transaction in\nthe package.\n|}\n\n\n1. The \"pckginfo1\" message has the structure defined above, with\n   pchCommand == \"pckginfo1\".\n\n2. A \"pckginfo1\" message contains information about a version 1\n   package (defined below), referenced by the wtxid of the transaction\nit pertains to and the current blockhash.\n\n3. Upon receipt of a \"pckginfo1\" message, the node should decide if it\n   wants to validate the package, request transaction data if\nnecessary, etc.\n\n4. Upon receipt of a malformed \"pckginfo1\" message or package that\n   does not abide by the max_count, max_weight, or other rules\nspecified by the version agreed upon in the initial negotiation, the\nsender should be disconnected.  If a node receives a \"pckginfo1\"\nmessage for which the \"pckg_fee\" or \"pckg_weight\" do not reflect the\ntrue total fees and weight, respectively, or the transactions in the\npackage, the message is malformed.\n\n5. A node MUST NOT send a \"pckginfo1\" message that has not been\n   requested by the recipient. Upon receipt of an unsolicited\n\"pckginfo1\", a node should disconnect the sender.\n\n6. A \"pckginfo1\" message should only be sent if both peers agreed to\n   send version 1 packages in the version handshake. If a \"pckginfo1\"\nmessage is received from a peer with which package relay was not\nnegotiated, the sender should be disconnected.\n\n=====MSG_PCKG1=====\n\n1. A new inv type (MSG_PCKG1 == 0x6) is added, for use in inv messages\n   and getdata requests pertaining to version 1 packages.\n\n2. As an inv type, it indicates that both transaction data and version\n   1 package information are available for the transaction. The\ntransaction is referenced by its wtxid. As a getdata request type, it\nindicates that the sender wants package information for the\ntransaction.\n\n3. Upon receipt of a \"getdata\" request for \"MSG_PCKG1\", the node\n   should respond with the version 1 package corresponding to the\nrequested transaction and its current chain tip, or with NOTFOUND.\nThe node should not assume that the sender is requesting the\ntransaction data as well.\n\n====Child With Parent Packages Rules====\n\nA child-with-unconfirmed-parents package sent between nodes must abide\nby the rules below, otherwise the package is malformed and the sender\nshould be disconnected.\n\nA version 1 or ''child-with-unconfirmed-parents'' package can be\ndefined for any transaction that spends unconfirmed inputs. The child\ncan be thought of as the \"representative\" of the package. This package\ncan be uniquely identified by the transaction's wtxid and the current\nchain tip block hash.\n\nA ''child-with-unconfirmed-parents'' package MUST be:\n\n1. ''Sorted topologically.'' For every transaction t in the package,\n   if any of t's parents are present in the package, the parent must\nappear somewhere in the list before t. In other words, the\ntransactions must be sorted in ascending order of the number of\nancestors present in the package.\n\n2. ''Only 1 child with unconfirmed parents.'' The package must consist\n   of one transaction and its unconfirmed parents. There must not be\nany other transactions in the package. Other dependency relationships\nmay exist within the package (e.g. one parent may spend the output of\nanother parent) provided that topological order is respected.\n\n3. ''All unconfirmed parents.'' All of the child's unconfirmed parents\n   must be present.\n\n4. ''No conflicts.'' None of the transactions in the package may\n   conflict with each other (i.e.  spend the same prevout).\n\n5. ''Total fees and weight.'' The 'total_fee' and 'total_weight'\n   fields must accurately represent the sum total of all transactions'\nfees and weights as defined in BIP141, respectively.\n\nNot all of the child's parents must be present; the child transaction\nmay also spend confirmed inputs. However, if the child has confirmed\nparents, they must not be in the package.\n\nWhile a child-with-unconfirmed-parents package is perhaps most\nrelevant when the child has a higher feerate than its parents, this\nproperty is not required to construct a valid package.\n\n====Clarifications====\n\n''Q: Under what circumstances should a sender announce a\nchild-with-unconfirmed-parents package?''\n\nA child-with-unconfirmed-parents package for a transaction should be\nannounced when it meets the peer's fee filter but one or more of its\nparents don't; a \"inv(MSG_PCKG1)\" instead of \"inv(WTX)\" should be sent\nfor the child. Each of the parents which meet the peer's fee filter\nshould still be announced normally.\n\n''Q: What if a new block arrives in between messages?''\n\nA child-with-unconfirmed-parents package is defined for a transaction\nbased on the current chain state. As such, a new block extending the\ntip may decrease the number of transactions in the package (i.e. if\nany of the transaction's parents were included in the block). In a\nreorg, the number of transactions in the package may decrease or\nincrease (i.e. if any of the transaction's parents were included in a\nblock in the previous chain but not the new one).\n\nIf the new block arrives before the \"getdata\" or \"pckginfo1\", nothing\nneeds to change.\n\nIf the new block arrives before \"getpckgtxns\" or before \"pckgtxns\",\nthe receiver may need to re-request package information if the block\ncontained a transaction in the package. If the block doesn't contain\nany transactions in the package, whether it extends the previous tip\nor causes a reorg, nothing needs to change.\n\n''Q: Can \"getpckgtxns\" and \"pckgtxns\" messages contain only one\ntransaction?''\n\nYes.\n\n===Further Protocol Extensions===\n\nWhen introducing a new type of package, assign it a version number \"n\"\nand use an additional \"sendpackages\" message during version handshake\nto negotiate support for it. An additional package information message\n\"pckginfon\" and inv type \"MSG_PCKGn\" should be defined for the type of\npackage.  However, \"getpckgtxns\" and \"pckgtxns\" do not need to be\nchanged.\n\nExample proposal for tx-with-unconfirmed-ancestors package relay: [19]\n\n===Compatibility===\n\nOlder clients remain fully compatible and interoperable after this\nchange. Clients implementing this protocol will only attempt to send\nand request packages if agreed upon during the version handshake.\n\n===Package Erlay===\n\nClients using BIP330 reconciliation-based transaction relay (Erlay)\nare able to use package relay without interference. In fact, a package\nof transactions may be announced using both Erlay and package relay.\nAfter reconciliation, if the initiator would have announced a\ntransaction by wtxid but also has package information for it, they may\nsend \"inv(MSG_PCKG)\" instead of \"inv(WTX)\".\n\n===Rationale===\n\n====P2P Message Design====\n\nThese p2p messages are added for communication efficiency and, as\nsuch, one should measure alternative solutions based on the resources\nused to communicate (not necessarily trustworthy) information: We\nwould like to minimize network bandwidth, avoid downloading a\ntransaction more than once, avoid downloading transactions that are\neventually rejected, and minimize storage allocated for\nnot-yet-validated transactions.\n\nConsider these (plausible) scenarios in transaction relay:\n\nAlice (the \"sender\") is relaying transactions to Bob (the \"receiver\").\nAlice's mempool has a minimum feerate of 1sat/vB and Bob's has a\nminimum feerate of 3sat/vB. For simplicity, all transactions are\n1600Wu in virtual size and 500 bytes in serialized size. Apart from\nthe spending relationships specified, all other inputs are from\nconfirmed UTXOs.\n\n1. Package {A, B} where A pays 0 satoshis and B pays 8000 satoshis in\n   fees.\n\n2. Package {C, D} where C pays 0 satoshis and D pays 1200 satoshis in\n   fees.\n\n3. Package {E, F, G, H, J} that pays 4000, 8000, 0, 2000, and 4000\n   satoshis in fees, respectively.\n\n====Alternative Designs Considered====\n\n''Package Information Only:'' Just having \"pckginfo\" gives enough\ninformation for the receiver to accept the package. Omit the\n\"getpckgtxns\" and \"pckgtxns\" messages. While this option is a good\nfallback if batched transaction download fails for some reason, it\nshouldn't be used as the default because it 'always' requires storage\nof unvalidated transactions.\n\n''No Package Information Round:'' Instead of having a package\ninformation round, just use the child's wtxid to refer to the package\nand always send the entire package together. This would cause nodes to\nredownload duplicate transactions.\n\nI have also created a slidedeck exploring various alternative designs\nand some examples in which they fall flat [20]. Please feel free to\nsuggest other alternatives.\n\n====Versioning System====\n\nThis protocol should be extensible to support multiple types of\npackages based on future desired use cases. Two \"flavors\" of\nversioning were considered:\n\n1. When package mempool acceptance is upgraded to support more types\n   of packages, increment the version number (similar to Erlay).\nDuring version handshake, peers negotiate which version of package\nrelay they will use by each sending one \"sendpackages\" message.\n\n2. When introducing another type of package, assign a version number\n   to it and announce it as an additional supported version (similar\nto Compact Block Relay). During version handshake, peers send one\n\"sendpackages\" message for each version supported.\n\nThe second option was favored because it allows different parameters\nfor different versions.  For example, it should be possible to support\nboth \"arbitrary topology but maximum 3-transaction\" package as well as\n\"child-with-unconfirmed-parents with default mempool ancestor limits\"\npackages simultaneously.\n\n==Acknowledgements==\n\nI hope to have made it abundantly clear that this proposal isn\u2019t\ninventing the concept of package relay, and in fact builds upon years\nof work by many others, including Suhas Daftuar and Antoine Riard.\n\nThank you to John Newbery and Martin Zumsande for input on the design.\n\nThank you to Matt Corallo, Christian Decker, David Harding, Antoine\nPoinsot, Antoine Riard, Gregory Sanders, Chris Stewart, Bastien\nTeinturier, and others for input on the desired interface for\ncontracting protocols.\n\nLooking forward to hearing your thoughts!\n\nBest,\nGloria\n\n[0]:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019817.html\n[1]:\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2020-April/002639.html\n[2]:\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2020-June/002758.html\n[3]: https://github.com/t-bast/lightning-docs/blob/master/pinning-attacks.md\n[4]:\nhttps://github.com/revault/practical-revault/blob/master/transactions.md#cancel_tx\n[5]:\nhttps://github.com/discreetlogcontracts/dlcspecs/blob/master/Transactions.md#refund-transaction\n[6]: https://gist.github.com/instagibbs/60264606e181451e977e439a49f69fe1\n[7]:\nhttps://btctranscripts.com/adopting-bitcoin/2021/2021-11-16-gloria-zhao-transaction-relay-policy/#lightning-attacks\n[8]: https://youtu.be/fbWSQvJjKFs?t=1438\n[9]:\nhttps://www.reddit.com/r/Bitcoin/comments/unew4e/looks_like_70_mvb_of_transactions_just_got_dumped/\n[10]: https://github.com/bitcoin/bitcoin/pull/7594\n[11]: https://github.com/bitcoin/bitcoin/pull/7600\n[12]: https://github.com/bitcoin/bitcoin/pull/6455#issuecomment-122716820\n[13]: https://gist.github.com/sdaftuar/8756699bfcad4d3806ba9f3396d4e66a\n[14]: https://github.com/bitcoin/bitcoin/issues/14895\n[15]: https://github.com/bitcoin/bitcoin/pull/16401\n[16]: https://github.com/bitcoin/bitcoin/pull/19621\n[17]:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html\n[18]: https://github.com/users/glozow/projects/5/views/4?layout=board\n[19]: https://gist.github.com/glozow/9b321cd3ef6505135c763112033ff2a7\n[20]:\nhttps://docs.google.com/presentation/d/1B__KlZO1VzxJGx-0DYChlWawaEmGJ9EGApEzrHqZpQc/edit?usp=sharing\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220517/f2e7c128/attachment-0001.html>"
            },
            {
                "author": "Greg Sanders",
                "date": "2022-05-17T17:56:40",
                "message_text_only": "Hi Gloria,\n\nThanks for working on this important proposal!\n\nStill a lot to digest, but I just had on area of comment/question:\n\n> A child-with-unconfirmed-parents package sent between nodes must abide by\nthe rules below, otherwise the package is malformed and the sender should\nbe disconnected.\n\n> However, if the child has confirmed parents, they must not be in the\npackage.\n\nIf my naive understanding is correct, this means things like otherwise\ncommon situations such as a new block will result in disconnects, say when\nthe sender doesn't hear about a new block which makes the relay package\nsuperfluous/irrelevant. Similar would be disconnection\nwhen confirmed gets turned into unconfirmed, but those situations are\nextremely uncommon. The other rules are entirely under the control\nof the sender, which leads me to wonder if it's appropriate.\n\nCheers,\nGreg\n\nOn Tue, May 17, 2022 at 12:09 PM Gloria Zhao via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi everybody,\n>\n> I\u2019m writing to propose a set of p2p protocol changes to enable package\n> relay, soliciting feedback on the design and approach. Here is a link\n> to the most up-to-date proposal:\n>\n> https://github.com/bitcoin/bips/pull/1324\n>\n> If you have concept or approach feedback, *please respond on the\n> mailing list* to allow everybody to view and participate in the\n> discussion. If you find a typo or inaccurate wording, please feel free\n> to leave suggestions on the PR.\n>\n> I\u2019m also working on an implementation for Bitcoin Core.\n>\n>\n> The rest of this post will include the same contents as the proposal,\n> with a bit of reordering and additional context. If you are not 100%\n> up-to-date on package relay and find the proposal hard to follow, I\n> hope you find this format more informative and persuasive.\n>\n>\n> ==Background and Motivation==\n>\n> Users may create and broadcast transactions that depend upon, i.e.\n> spend outputs of, unconfirmed transactions. A \u201cpackage\u201d is the\n> widely-used term for a group of transactions representable by a\n> connected Directed Acyclic Graph (where a directed edge exists between\n> a transaction that spends the output of another transaction).\n>\n> Incentive-compatible mempool and miner policies help create a fair,\n> fee-based market for block space. While miners maximize transaction\n> fees in order to earn higher block rewards, non-mining users\n> participating in transaction relay reap many benefits from employing\n> policies that result in a mempool with the same contents, including\n> faster compact block relay and more accurate fee estimation.\n> Additionally, users may take advantage of mempool and miner policy to\n> bump the priority of their transactions by attaching high-fee\n> descendants (Child Pays for Parent or CPFP).  Only considering\n> transactions one at a time for submission to the mempool creates a\n> limitation in the node's ability to determine which transactions have\n> the highest feerates, since it cannot take into account descendants\n> until all the transactions are in the mempool. Similarly, it cannot\n> use a transaction's descendants when considering which of two\n> conflicting transactions to keep (Replace by Fee or RBF).\n>\n> When a user's transaction does not meet a mempool's minimum feerate\n> and they cannot create a replacement transaction directly, their\n> transaction will simply be rejected by this mempool. They also cannot\n> attach a descendant to pay for replacing a conflicting transaction.\n> This limitation harms users' ability to fee-bump their transactions.\n> Further, it presents a security issue in contracting protocols which\n> rely on **presigned**, time-sensitive transactions to prevent cheating\n> (HTLC-Timeout in LN Penalty [1] [2] [3], Unvault Cancel in Revault\n> [4], Refund Transaction in Discreet Log Contracts [5], Updates in\n> eltoo [6]). In other words, a key security assumption of many\n> contracting protocols is that all parties can propagate and confirm\n> transactions in a timely manner.\n>\n> In the past few years, increasing attention [0][1][2][3][6] has been\n> brought to **pinning attacks**, a type of censorship in which the\n> attacker uses mempool policy restrictions to prevent a transaction\n> from being relayed or getting mined.  TLDR: revocation transactions\n> must meet a certain confirmation target to be effective, but their\n> feerates are negotiated well ahead of broadcast time. If the\n> forecasted feerate was too low and no fee-bumping options are\n> available, attackers can steal money from their counterparties. I walk\n> through a concrete example for stealing Lightning HTLC outputs at\n> ~23:58 in this talk [7][8].  Note that most attacks are only possible\n> when the market for blockspace at broadcast time  demands much higher\n> feerates than originally anticipated at signing time. Always\n> overestimating fees may sidestep this issue temporarily (while mempool\n> traffic is low and predictable), but this solution is not foolproof\n> and wastes users' money. The feerate market can change due to sudden\n> spikes in traffic (e.g. huge 12sat/vB dump a few days ago [9]) or\n> sustained, high volume of Bitcoin payments (e.g.  April 2021 and\n> December 2017).\n>\n> The best solution is to enable nodes to consider packages of\n> transactions as a unit, e.g. one or more low-fee parent transactions\n> with a high-fee child, instead of separately. A package-aware mempool\n> policy can help determine if it would actually be economically\n> rational to accept a transaction to the mempool if it doesn't meet fee\n> requirements individually. Network-wide adoption of these policies\n> would create a more purely-feerate-based market for block space and\n> allow contracting protocols to adjust fees (and therefore mining\n> priority) at broadcast time.  Some support for packages has existed in\n> Bitcoin Core for years. Since v0.13, Bitcoin Core has used ancestor\n> packages instead of individual transactions to evaluate the incentive\n> compatibility of transactions in the mempool [10] and select them for\n> inclusion in blocks [11].\n>\n> Package Relay, the concept of {announcing, requesting, downloading}\n> packages between nodes on the p2p network, has also been discussed for\n> many years. The earliest public mention I can find is from 2015 [12].\n> The two most common use cases for package relay are fee-bumping\n> otherwise-too-low-fee transactions and reducing the amount of orphans.\n> It seems uncontroversial to say that everybody desires package relay\n> conceptually, with varying degrees of urgency. Lots of work has been\n> done by others over the past few years, from which I've taken\n> inspiration from [13][14][15][16].\n>\n> My approach has been to split the project into two components: (1) Package\n> Mempool Accept, which includes validation logic and mempool policy.\n> (3) Package Relay, which includes the p2p protocol changes.\n>\n> Progress so far:\n> After discussions with various developers of contracting protocols\n> (with heavier emphasis towards LN), it was determined that a\n> package containing a child with all of its unconfirmed parents\n> (child-with-unconfirmed-parents or 1-child-multi-parent package) would\n> be sufficient for their use case, i.e. fee-bumping presigned\n> transactions. A child-with-unconfirmed-parents package has several\n> properties that make many things easier to reason about.\n>\n> A few months ago, I proposed a set of policies for safe package\n> validation and fee assessment for packages of this restricted\n> topology [17]. A series of PRs implementing this proposal have\n> been merged into Bitcoin Core [18].\n>\n> Theoretically, developing a safe and incentive-compatible package\n> mempool acceptance policy is sufficient to solve this issue. Nodes\n> could opportunistically accept packages (e.g. by trying combinations\n> of transactions rejected from their mempools), but this practice would\n> likely be inefficient at best and open new Denial of Service attacks\n> at worst. Additional p2p messages may enable nodes to request and\n> share package validation-related information with one another in a\n> more communication-efficient way.\n>\n> Given that only package RBF remains for package mempool accept, and we\n> can make progress on p2p and mempool in parallel, I think it\u2019s\n> appropriate to put forward a package relay proposal.\n>\n> ==Proposal==\n>\n> This proposal contains 2 components: a \u201cgeneric\u201d package relay\n> protocol and an extension of it, child-with-unconfirmed-parents\n> packages, as version 1 package relay. Another version of packages,\n> \u201ctx-with-unconfirmed-ancestors\u201d can be created to extend package relay\n> for eliminating orphans.\n>\n> ===Generic Package Relay===\n>\n> Two main ideas are introduced:\n>\n> Download and validate packages of transactions together.\n>\n> Provide information to help peers decide whether to request and/or how\n> to validate transactions which are part of a package.\n>\n> ====Intended Protocol Flow====\n>\n> Due to the asynchronous nature of a distributed transaction relay\n> network, nodes may not receive all of the information needed to\n> validate a transaction at once. For example, after a node completes\n> Initial Block Download (IBD) and first starts participating in\n> transaction relay with an empty mempool, it is common to receive\n> orphans. In such scenarios where a node is aware that it is missing\n> information, a ''receiver-initiated'' dialogue is appropriate:\n>\n> 1. Receiver requests package information.\n>\n> 2. The sender provides package information, including the wtxids of\n>    the transactions in the package and anything else that might be\n> relevant (e.g. total fees and size).\n>\n> 3. The reciever uses the package information to decide how to request\n>    and validate the transactions.\n>\n> Sometimes, no matter what order transactions are received by a node,\n> validating them individually is insufficient. When the sender is aware\n> of additional information that the receiver needs to accept a package,\n> a proactive ''sender-initiated'' dialogue should be enabled:\n>\n> 1. Sender announces they have package information pertaining to a\n>    transaction that might otherwise be undesired on its own.\n>\n> 2. The receiver requests package information.\n>\n> 3. The sender provides package information, including the wtxids of\n>    the transactions in the package and anything else that might be\n> relevant (e.g. total fees and size).\n>\n> 4. The reciever uses the package information to decide how to request\n>    and validate the transactions.\n>\n> Package relay is negotiated between two peers during the version\n> handshake. Package relay requires both peers to support wtxid-based\n> relay because package transactions are referenced by their wtxid.\n>\n> ====New Messages====\n>\n> Three new protocol messages are added for use in any version of\n> package relay. Additionally, each version of package relay must define\n> its own inv type and \"pckginfo\" message version, referred to in this\n> document as \"MSG_PCKG\" and \"pckginfo\" respectively. See\n> BIP-v1-packages for a concrete example.\n>\n> =====sendpackages=====\n>\n> {|\n> |  Field Name  ||  Type  ||  Size  ||  Purpose\n> |-\n> |version || uint32_t || 4 || Denotes a package version supported by the\n> node.\n> |-\n> |max_count || uint32_t || 4 ||Specifies the maximum number of transactions\n> per package this node is\n> willing to accept.\n> |-\n> |max_weight || uint32_t || 4 ||Specifies the maximum total weight per\n> package this node is willing\n> to accept.\n> |-\n> |}\n>\n> 1. The \"sendpackages\" message has the structure defined above, with\n>    pchCommand == \"sendpackages\".\n>\n> 2. During version handshake, nodes should send a \"sendpackages\"\n>    message indicate they support package relay and may request\n> packages.\n>\n> 3. The message should contain a version supported by the node. Nodes\n>    should send a \"sendpackages\" message for each version they support.\n>\n> 4. The \"sendpackages\" message MUST be sent before sending a \"verack\"\n>    message. If a \"sendpackages\" message is received afer \"verack\", the\n> sender should be disconnected.\n>\n> 5. If 'fRelay==false' in a peer's version message, the node must not\n>    send \"sendpackages\" to them. If a \"sendpackages\" message is\n> received by a peer after sending `fRelay==false` in their version\n> message, the sender should be disconnected.\n>\n> 6.. Upon receipt of a \"sendpackages\" message with a version that is\n> not supported, a node must treat the peer as if it never received the\n> message.\n>\n> 7. If both peers send \"wtxidrelay\" and \"sendpackages\" with the same\n>    version, the peers should announce, request, and send package\n> information to each other.\n>\n> =====getpckgtxns=====\n>\n> {|\n> |  Field Name  ||  Type  ||  Size  ||   Purpose\n> |-\n> |txns_length||CompactSize||1 or 3 bytes|| The number of transactions\n> requested.\n> |-\n> |txns||List of wtxids||txns_length * 32|| The wtxids of each transaction\n> in the package.\n> |}\n>\n> 1. The \"getpckgtxns\" message has the structure defined above, with\n>    pchCommand == \"getpckgtxns\".\n>\n> 2. A \"getpckgtxns\" message should be used to request all or some of\n>    the transactions previously announced in a \"pckginfo\" message,\n> specified by witness transactiosome id.\n>\n> 3. Upon receipt of a \"getpckgtxns\" message, a node must respond with\n>    either a \"pckgtxns\" containing the requested transactions or a\n> \"notfound\" message indicating one or more of the transactions is\n> unavailable. This allows the receiver to avoid downloading and storing\n> transactions that cannot be validated immediately.\n>\n> 4. A \"getpckgtxns\" message should only be sent if both peers agreed to\n>    send packages in the version handshake. If a \"getpckgtxns\" message\n> is received from a peer with which package relay was not negotiated,\n> the sender should be disconnected.\n>\n> =====pckgtxns=====\n>\n> {|\n> |  Field Name  ||  Type  ||  Size  ||   Purpose\n> |-\n> |txns_length||CompactSize||1 or 3 bytes|| The number of transactions\n> provided.\n> |-\n> |txns||List of transactions||variable|| The transactions in the package.\n> |}\n>\n> 1. The \"pckgtxns\" message has the structure defined above, with\n>    pchCommand == \"pckgtxns\".\n>\n> 2. A \"pckgtxns\" message should contain the transaction data requested\n>    using \"getpckgtxns\".\n>\n> 3. A \"pckgtxns\" message should only be sent to a peer that requested\n>    the package using \"getpckgtxns\". If a node receives an unsolicited\n> package, the sender should be disconnected.\n>\n> 4. A \"pckgtxns\" message should only be sent if both peers agreed to\n>    send packages in the version handshake. If a \"pckgtxns\" message is\n> received from a peer with which package relay was not negotiated, the\n> sender should be disconnected.\n>\n> ===Version 1 Packages: child-with-unconfirmed-parents===\n>\n> This extends package relay for packages consisting of one transaction\n> and all of its unconfirmed parents,by defining version 1 packages, a\n> pckginfo1 message, and a MSG_PCKG1 inv type. It enables the use case\n> in which a child pays for its otherwise-too-low-fee parents and their\n> mempool conflict(s).\n>\n> ====Intended Protocol Flow====\n>\n> When relaying a package of low-fee parent(s) and high-fee child, the\n> sender and receiver do the following:\n>\n> 1. Sender announces they have a child-with-unconfirmed-parents package\n>    for a child that pays for otherwise-too-low-fee parent(s) using\n> \"inv(MSG_PCKG1)\".\n>\n> 2. The receiver requests package information using\n>    \"getdata(MSG_PCKG1)\".\n>\n> 3. The sender provides package information using \"pckginfo1\",\n>    including the blockhash of the sender's best block, the wtxids of\n> the transactions in the package, their total fees and total weight.\n>\n> 4. The reciever uses the package information to decide how to request\n>    the transactions. For example, if the receiver already has some of\n> the transactions in their mempool, they only request the missing ones.\n> They could also decide not to request the package at all based on the\n> fee information provided.\n>\n> 5. Upon receiving a \"pckgtxns\", the receiver submits the transactions\n>    together as a package.\n>\n> ====New Messages====\n>\n> A new inv type, \"MSG_PCKG1\", and new protocol message, \"PCKGINFO1\",\n> are added.\n>\n> =====pckginfo1=====\n>\n> {|\n> |  Field Name  ||  Type  ||  Size  ||   Purpose\n> |-\n> |blockhash || uint256 || 32 || The chain tip at which this package is\n> defined.\n> |-\n> |pckg_fee||CAmount||4|| The sum total fees paid by all transactions in the\n> package.\n> |-\n> |pckg_weight||int64_t||8|| The sum total weight of all transactions in the\n> package.\n> |-\n> |txns_length||CompactSize||1 or 3 bytes|| The number of transactions\n> provided.\n> |-\n> |txns||List of wtxids||txns_length * 32|| The wtxids of each transaction\n> in the package.\n> |}\n>\n>\n> 1. The \"pckginfo1\" message has the structure defined above, with\n>    pchCommand == \"pckginfo1\".\n>\n> 2. A \"pckginfo1\" message contains information about a version 1\n>    package (defined below), referenced by the wtxid of the transaction\n> it pertains to and the current blockhash.\n>\n> 3. Upon receipt of a \"pckginfo1\" message, the node should decide if it\n>    wants to validate the package, request transaction data if\n> necessary, etc.\n>\n> 4. Upon receipt of a malformed \"pckginfo1\" message or package that\n>    does not abide by the max_count, max_weight, or other rules\n> specified by the version agreed upon in the initial negotiation, the\n> sender should be disconnected.  If a node receives a \"pckginfo1\"\n> message for which the \"pckg_fee\" or \"pckg_weight\" do not reflect the\n> true total fees and weight, respectively, or the transactions in the\n> package, the message is malformed.\n>\n> 5. A node MUST NOT send a \"pckginfo1\" message that has not been\n>    requested by the recipient. Upon receipt of an unsolicited\n> \"pckginfo1\", a node should disconnect the sender.\n>\n> 6. A \"pckginfo1\" message should only be sent if both peers agreed to\n>    send version 1 packages in the version handshake. If a \"pckginfo1\"\n> message is received from a peer with which package relay was not\n> negotiated, the sender should be disconnected.\n>\n> =====MSG_PCKG1=====\n>\n> 1. A new inv type (MSG_PCKG1 == 0x6) is added, for use in inv messages\n>    and getdata requests pertaining to version 1 packages.\n>\n> 2. As an inv type, it indicates that both transaction data and version\n>    1 package information are available for the transaction. The\n> transaction is referenced by its wtxid. As a getdata request type, it\n> indicates that the sender wants package information for the\n> transaction.\n>\n> 3. Upon receipt of a \"getdata\" request for \"MSG_PCKG1\", the node\n>    should respond with the version 1 package corresponding to the\n> requested transaction and its current chain tip, or with NOTFOUND.\n> The node should not assume that the sender is requesting the\n> transaction data as well.\n>\n> ====Child With Parent Packages Rules====\n>\n> A child-with-unconfirmed-parents package sent between nodes must abide\n> by the rules below, otherwise the package is malformed and the sender\n> should be disconnected.\n>\n> A version 1 or ''child-with-unconfirmed-parents'' package can be\n> defined for any transaction that spends unconfirmed inputs. The child\n> can be thought of as the \"representative\" of the package. This package\n> can be uniquely identified by the transaction's wtxid and the current\n> chain tip block hash.\n>\n> A ''child-with-unconfirmed-parents'' package MUST be:\n>\n> 1. ''Sorted topologically.'' For every transaction t in the package,\n>    if any of t's parents are present in the package, the parent must\n> appear somewhere in the list before t. In other words, the\n> transactions must be sorted in ascending order of the number of\n> ancestors present in the package.\n>\n> 2. ''Only 1 child with unconfirmed parents.'' The package must consist\n>    of one transaction and its unconfirmed parents. There must not be\n> any other transactions in the package. Other dependency relationships\n> may exist within the package (e.g. one parent may spend the output of\n> another parent) provided that topological order is respected.\n>\n> 3. ''All unconfirmed parents.'' All of the child's unconfirmed parents\n>    must be present.\n>\n> 4. ''No conflicts.'' None of the transactions in the package may\n>    conflict with each other (i.e.  spend the same prevout).\n>\n> 5. ''Total fees and weight.'' The 'total_fee' and 'total_weight'\n>    fields must accurately represent the sum total of all transactions'\n> fees and weights as defined in BIP141, respectively.\n>\n> Not all of the child's parents must be present; the child transaction\n> may also spend confirmed inputs. However, if the child has confirmed\n> parents, they must not be in the package.\n>\n> While a child-with-unconfirmed-parents package is perhaps most\n> relevant when the child has a higher feerate than its parents, this\n> property is not required to construct a valid package.\n>\n> ====Clarifications====\n>\n> ''Q: Under what circumstances should a sender announce a\n> child-with-unconfirmed-parents package?''\n>\n> A child-with-unconfirmed-parents package for a transaction should be\n> announced when it meets the peer's fee filter but one or more of its\n> parents don't; a \"inv(MSG_PCKG1)\" instead of \"inv(WTX)\" should be sent\n> for the child. Each of the parents which meet the peer's fee filter\n> should still be announced normally.\n>\n> ''Q: What if a new block arrives in between messages?''\n>\n> A child-with-unconfirmed-parents package is defined for a transaction\n> based on the current chain state. As such, a new block extending the\n> tip may decrease the number of transactions in the package (i.e. if\n> any of the transaction's parents were included in the block). In a\n> reorg, the number of transactions in the package may decrease or\n> increase (i.e. if any of the transaction's parents were included in a\n> block in the previous chain but not the new one).\n>\n> If the new block arrives before the \"getdata\" or \"pckginfo1\", nothing\n> needs to change.\n>\n> If the new block arrives before \"getpckgtxns\" or before \"pckgtxns\",\n> the receiver may need to re-request package information if the block\n> contained a transaction in the package. If the block doesn't contain\n> any transactions in the package, whether it extends the previous tip\n> or causes a reorg, nothing needs to change.\n>\n> ''Q: Can \"getpckgtxns\" and \"pckgtxns\" messages contain only one\n> transaction?''\n>\n> Yes.\n>\n> ===Further Protocol Extensions===\n>\n> When introducing a new type of package, assign it a version number \"n\"\n> and use an additional \"sendpackages\" message during version handshake\n> to negotiate support for it. An additional package information message\n> \"pckginfon\" and inv type \"MSG_PCKGn\" should be defined for the type of\n> package.  However, \"getpckgtxns\" and \"pckgtxns\" do not need to be\n> changed.\n>\n> Example proposal for tx-with-unconfirmed-ancestors package relay: [19]\n>\n> ===Compatibility===\n>\n> Older clients remain fully compatible and interoperable after this\n> change. Clients implementing this protocol will only attempt to send\n> and request packages if agreed upon during the version handshake.\n>\n> ===Package Erlay===\n>\n> Clients using BIP330 reconciliation-based transaction relay (Erlay)\n> are able to use package relay without interference. In fact, a package\n> of transactions may be announced using both Erlay and package relay.\n> After reconciliation, if the initiator would have announced a\n> transaction by wtxid but also has package information for it, they may\n> send \"inv(MSG_PCKG)\" instead of \"inv(WTX)\".\n>\n> ===Rationale===\n>\n> ====P2P Message Design====\n>\n> These p2p messages are added for communication efficiency and, as\n> such, one should measure alternative solutions based on the resources\n> used to communicate (not necessarily trustworthy) information: We\n> would like to minimize network bandwidth, avoid downloading a\n> transaction more than once, avoid downloading transactions that are\n> eventually rejected, and minimize storage allocated for\n> not-yet-validated transactions.\n>\n> Consider these (plausible) scenarios in transaction relay:\n>\n> Alice (the \"sender\") is relaying transactions to Bob (the \"receiver\").\n> Alice's mempool has a minimum feerate of 1sat/vB and Bob's has a\n> minimum feerate of 3sat/vB. For simplicity, all transactions are\n> 1600Wu in virtual size and 500 bytes in serialized size. Apart from\n> the spending relationships specified, all other inputs are from\n> confirmed UTXOs.\n>\n> 1. Package {A, B} where A pays 0 satoshis and B pays 8000 satoshis in\n>    fees.\n>\n> 2. Package {C, D} where C pays 0 satoshis and D pays 1200 satoshis in\n>    fees.\n>\n> 3. Package {E, F, G, H, J} that pays 4000, 8000, 0, 2000, and 4000\n>    satoshis in fees, respectively.\n>\n> ====Alternative Designs Considered====\n>\n> ''Package Information Only:'' Just having \"pckginfo\" gives enough\n> information for the receiver to accept the package. Omit the\n> \"getpckgtxns\" and \"pckgtxns\" messages. While this option is a good\n> fallback if batched transaction download fails for some reason, it\n> shouldn't be used as the default because it 'always' requires storage\n> of unvalidated transactions.\n>\n> ''No Package Information Round:'' Instead of having a package\n> information round, just use the child's wtxid to refer to the package\n> and always send the entire package together. This would cause nodes to\n> redownload duplicate transactions.\n>\n> I have also created a slidedeck exploring various alternative designs\n> and some examples in which they fall flat [20]. Please feel free to\n> suggest other alternatives.\n>\n> ====Versioning System====\n>\n> This protocol should be extensible to support multiple types of\n> packages based on future desired use cases. Two \"flavors\" of\n> versioning were considered:\n>\n> 1. When package mempool acceptance is upgraded to support more types\n>    of packages, increment the version number (similar to Erlay).\n> During version handshake, peers negotiate which version of package\n> relay they will use by each sending one \"sendpackages\" message.\n>\n> 2. When introducing another type of package, assign a version number\n>    to it and announce it as an additional supported version (similar\n> to Compact Block Relay). During version handshake, peers send one\n> \"sendpackages\" message for each version supported.\n>\n> The second option was favored because it allows different parameters\n> for different versions.  For example, it should be possible to support\n> both \"arbitrary topology but maximum 3-transaction\" package as well as\n> \"child-with-unconfirmed-parents with default mempool ancestor limits\"\n> packages simultaneously.\n>\n> ==Acknowledgements==\n>\n> I hope to have made it abundantly clear that this proposal isn\u2019t\n> inventing the concept of package relay, and in fact builds upon years\n> of work by many others, including Suhas Daftuar and Antoine Riard.\n>\n> Thank you to John Newbery and Martin Zumsande for input on the design.\n>\n> Thank you to Matt Corallo, Christian Decker, David Harding, Antoine\n> Poinsot, Antoine Riard, Gregory Sanders, Chris Stewart, Bastien\n> Teinturier, and others for input on the desired interface for\n> contracting protocols.\n>\n> Looking forward to hearing your thoughts!\n>\n> Best,\n> Gloria\n>\n> [0]:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019817.html\n> [1]:\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-April/002639.html\n> [2]:\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-June/002758.html\n> [3]:\n> https://github.com/t-bast/lightning-docs/blob/master/pinning-attacks.md\n> [4]:\n> https://github.com/revault/practical-revault/blob/master/transactions.md#cancel_tx\n> [5]:\n> https://github.com/discreetlogcontracts/dlcspecs/blob/master/Transactions.md#refund-transaction\n> [6]: https://gist.github.com/instagibbs/60264606e181451e977e439a49f69fe1\n> [7]:\n> https://btctranscripts.com/adopting-bitcoin/2021/2021-11-16-gloria-zhao-transaction-relay-policy/#lightning-attacks\n> [8]: https://youtu.be/fbWSQvJjKFs?t=1438\n> [9]:\n> https://www.reddit.com/r/Bitcoin/comments/unew4e/looks_like_70_mvb_of_transactions_just_got_dumped/\n> [10]: https://github.com/bitcoin/bitcoin/pull/7594\n> [11]: https://github.com/bitcoin/bitcoin/pull/7600\n> [12]: https://github.com/bitcoin/bitcoin/pull/6455#issuecomment-122716820\n> [13]: https://gist.github.com/sdaftuar/8756699bfcad4d3806ba9f3396d4e66a\n> [14]: https://github.com/bitcoin/bitcoin/issues/14895\n> [15]: https://github.com/bitcoin/bitcoin/pull/16401\n> [16]: https://github.com/bitcoin/bitcoin/pull/19621\n> [17]:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html\n> [18]: https://github.com/users/glozow/projects/5/views/4?layout=board\n> [19]: https://gist.github.com/glozow/9b321cd3ef6505135c763112033ff2a7\n> [20]:\n> https://docs.google.com/presentation/d/1B__KlZO1VzxJGx-0DYChlWawaEmGJ9EGApEzrHqZpQc/edit?usp=sharing\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220517/06bd18af/attachment-0001.html>"
            },
            {
                "author": "Gloria Zhao",
                "date": "2022-05-17T20:45:42",
                "message_text_only": "Hi Greg,\n\nThanks for reading!\n\n>> A child-with-unconfirmed-parents package sent between nodes must abide by\nthe rules below, otherwise the package is malformed and the sender should\nbe disconnected.\n\n>> However, if the child has confirmed parents, they must not be in the\npackage.\n\n> If my naive understanding is correct, this means things like otherwise\ncommon situations such as a new block will result in disconnects, say when\n> the sender doesn't hear about a new block which makes the relay package\nsuperfluous/irrelevant. Similar would be disconnection\n> when confirmed gets turned into unconfirmed, but those situations are\nextremely uncommon. The other rules are entirely under the control\n> of the sender, which leads me to wonder if it's appropriate.\n\nThis is why the \"pckginfo1\" message includes the blockhash at which the\npackage was defined.\nAlso please see Clarifications - \"Q: What if a new block arrives in between\nmessages?'' section in the v1-packages portion. It covers both cases, i.e.\na transaction going from unconfirmed->confirmed and confirmed->unconfirmed\nin a reorg.\n\nIn case anybody is wondering \"why don't we just allow confirmed parents?\":\nSince we validate based on the UTXO set, when we see a recently-confirmed\ntransaction, it just looks like it spends nonexistent inputs. In these\ncases, we don't really know if the input was recently spent in a block or\njust never existed, unless we plan on looking up transactions in past\nblocks. We do some guesswork when we deal with new blocks in normal\ntransaction relay (e.g. we requested the tx before a block arrived):\nhttps://github.com/bitcoin/bitcoin/blob/d5d40d59f8d12cf53c5ad1ce9710f3f108cec386/src/validation.cpp#L780-L784\nI believe it's cleaner to just explicitly say which blockhash you're on to\navoid confusion.\n\nThanks,\nGloria\n\nOn Tue, May 17, 2022 at 1:56 PM Greg Sanders <gsanders87 at gmail.com> wrote:\n\n> Hi Gloria,\n>\n> Thanks for working on this important proposal!\n>\n> Still a lot to digest, but I just had on area of comment/question:\n>\n> > A child-with-unconfirmed-parents package sent between nodes must abide by\n> the rules below, otherwise the package is malformed and the sender should\n> be disconnected.\n>\n> > However, if the child has confirmed parents, they must not be in the\n> package.\n>\n> If my naive understanding is correct, this means things like otherwise\n> common situations such as a new block will result in disconnects, say when\n> the sender doesn't hear about a new block which makes the relay package\n> superfluous/irrelevant. Similar would be disconnection\n> when confirmed gets turned into unconfirmed, but those situations are\n> extremely uncommon. The other rules are entirely under the control\n> of the sender, which leads me to wonder if it's appropriate.\n>\n> Cheers,\n> Greg\n>\n> On Tue, May 17, 2022 at 12:09 PM Gloria Zhao via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi everybody,\n>>\n>> I\u2019m writing to propose a set of p2p protocol changes to enable package\n>> relay, soliciting feedback on the design and approach. Here is a link\n>> to the most up-to-date proposal:\n>>\n>> https://github.com/bitcoin/bips/pull/1324\n>>\n>> If you have concept or approach feedback, *please respond on the\n>> mailing list* to allow everybody to view and participate in the\n>> discussion. If you find a typo or inaccurate wording, please feel free\n>> to leave suggestions on the PR.\n>>\n>> I\u2019m also working on an implementation for Bitcoin Core.\n>>\n>>\n>> The rest of this post will include the same contents as the proposal,\n>> with a bit of reordering and additional context. If you are not 100%\n>> up-to-date on package relay and find the proposal hard to follow, I\n>> hope you find this format more informative and persuasive.\n>>\n>>\n>> ==Background and Motivation==\n>>\n>> Users may create and broadcast transactions that depend upon, i.e.\n>> spend outputs of, unconfirmed transactions. A \u201cpackage\u201d is the\n>> widely-used term for a group of transactions representable by a\n>> connected Directed Acyclic Graph (where a directed edge exists between\n>> a transaction that spends the output of another transaction).\n>>\n>> Incentive-compatible mempool and miner policies help create a fair,\n>> fee-based market for block space. While miners maximize transaction\n>> fees in order to earn higher block rewards, non-mining users\n>> participating in transaction relay reap many benefits from employing\n>> policies that result in a mempool with the same contents, including\n>> faster compact block relay and more accurate fee estimation.\n>> Additionally, users may take advantage of mempool and miner policy to\n>> bump the priority of their transactions by attaching high-fee\n>> descendants (Child Pays for Parent or CPFP).  Only considering\n>> transactions one at a time for submission to the mempool creates a\n>> limitation in the node's ability to determine which transactions have\n>> the highest feerates, since it cannot take into account descendants\n>> until all the transactions are in the mempool. Similarly, it cannot\n>> use a transaction's descendants when considering which of two\n>> conflicting transactions to keep (Replace by Fee or RBF).\n>>\n>> When a user's transaction does not meet a mempool's minimum feerate\n>> and they cannot create a replacement transaction directly, their\n>> transaction will simply be rejected by this mempool. They also cannot\n>> attach a descendant to pay for replacing a conflicting transaction.\n>> This limitation harms users' ability to fee-bump their transactions.\n>> Further, it presents a security issue in contracting protocols which\n>> rely on **presigned**, time-sensitive transactions to prevent cheating\n>> (HTLC-Timeout in LN Penalty [1] [2] [3], Unvault Cancel in Revault\n>> [4], Refund Transaction in Discreet Log Contracts [5], Updates in\n>> eltoo [6]). In other words, a key security assumption of many\n>> contracting protocols is that all parties can propagate and confirm\n>> transactions in a timely manner.\n>>\n>> In the past few years, increasing attention [0][1][2][3][6] has been\n>> brought to **pinning attacks**, a type of censorship in which the\n>> attacker uses mempool policy restrictions to prevent a transaction\n>> from being relayed or getting mined.  TLDR: revocation transactions\n>> must meet a certain confirmation target to be effective, but their\n>> feerates are negotiated well ahead of broadcast time. If the\n>> forecasted feerate was too low and no fee-bumping options are\n>> available, attackers can steal money from their counterparties. I walk\n>> through a concrete example for stealing Lightning HTLC outputs at\n>> ~23:58 in this talk [7][8].  Note that most attacks are only possible\n>> when the market for blockspace at broadcast time  demands much higher\n>> feerates than originally anticipated at signing time. Always\n>> overestimating fees may sidestep this issue temporarily (while mempool\n>> traffic is low and predictable), but this solution is not foolproof\n>> and wastes users' money. The feerate market can change due to sudden\n>> spikes in traffic (e.g. huge 12sat/vB dump a few days ago [9]) or\n>> sustained, high volume of Bitcoin payments (e.g.  April 2021 and\n>> December 2017).\n>>\n>> The best solution is to enable nodes to consider packages of\n>> transactions as a unit, e.g. one or more low-fee parent transactions\n>> with a high-fee child, instead of separately. A package-aware mempool\n>> policy can help determine if it would actually be economically\n>> rational to accept a transaction to the mempool if it doesn't meet fee\n>> requirements individually. Network-wide adoption of these policies\n>> would create a more purely-feerate-based market for block space and\n>> allow contracting protocols to adjust fees (and therefore mining\n>> priority) at broadcast time.  Some support for packages has existed in\n>> Bitcoin Core for years. Since v0.13, Bitcoin Core has used ancestor\n>> packages instead of individual transactions to evaluate the incentive\n>> compatibility of transactions in the mempool [10] and select them for\n>> inclusion in blocks [11].\n>>\n>> Package Relay, the concept of {announcing, requesting, downloading}\n>> packages between nodes on the p2p network, has also been discussed for\n>> many years. The earliest public mention I can find is from 2015 [12].\n>> The two most common use cases for package relay are fee-bumping\n>> otherwise-too-low-fee transactions and reducing the amount of orphans.\n>> It seems uncontroversial to say that everybody desires package relay\n>> conceptually, with varying degrees of urgency. Lots of work has been\n>> done by others over the past few years, from which I've taken\n>> inspiration from [13][14][15][16].\n>>\n>> My approach has been to split the project into two components: (1) Package\n>> Mempool Accept, which includes validation logic and mempool policy.\n>> (3) Package Relay, which includes the p2p protocol changes.\n>>\n>> Progress so far:\n>> After discussions with various developers of contracting protocols\n>> (with heavier emphasis towards LN), it was determined that a\n>> package containing a child with all of its unconfirmed parents\n>> (child-with-unconfirmed-parents or 1-child-multi-parent package) would\n>> be sufficient for their use case, i.e. fee-bumping presigned\n>> transactions. A child-with-unconfirmed-parents package has several\n>> properties that make many things easier to reason about.\n>>\n>> A few months ago, I proposed a set of policies for safe package\n>> validation and fee assessment for packages of this restricted\n>> topology [17]. A series of PRs implementing this proposal have\n>> been merged into Bitcoin Core [18].\n>>\n>> Theoretically, developing a safe and incentive-compatible package\n>> mempool acceptance policy is sufficient to solve this issue. Nodes\n>> could opportunistically accept packages (e.g. by trying combinations\n>> of transactions rejected from their mempools), but this practice would\n>> likely be inefficient at best and open new Denial of Service attacks\n>> at worst. Additional p2p messages may enable nodes to request and\n>> share package validation-related information with one another in a\n>> more communication-efficient way.\n>>\n>> Given that only package RBF remains for package mempool accept, and we\n>> can make progress on p2p and mempool in parallel, I think it\u2019s\n>> appropriate to put forward a package relay proposal.\n>>\n>> ==Proposal==\n>>\n>> This proposal contains 2 components: a \u201cgeneric\u201d package relay\n>> protocol and an extension of it, child-with-unconfirmed-parents\n>> packages, as version 1 package relay. Another version of packages,\n>> \u201ctx-with-unconfirmed-ancestors\u201d can be created to extend package relay\n>> for eliminating orphans.\n>>\n>> ===Generic Package Relay===\n>>\n>> Two main ideas are introduced:\n>>\n>> Download and validate packages of transactions together.\n>>\n>> Provide information to help peers decide whether to request and/or how\n>> to validate transactions which are part of a package.\n>>\n>> ====Intended Protocol Flow====\n>>\n>> Due to the asynchronous nature of a distributed transaction relay\n>> network, nodes may not receive all of the information needed to\n>> validate a transaction at once. For example, after a node completes\n>> Initial Block Download (IBD) and first starts participating in\n>> transaction relay with an empty mempool, it is common to receive\n>> orphans. In such scenarios where a node is aware that it is missing\n>> information, a ''receiver-initiated'' dialogue is appropriate:\n>>\n>> 1. Receiver requests package information.\n>>\n>> 2. The sender provides package information, including the wtxids of\n>>    the transactions in the package and anything else that might be\n>> relevant (e.g. total fees and size).\n>>\n>> 3. The reciever uses the package information to decide how to request\n>>    and validate the transactions.\n>>\n>> Sometimes, no matter what order transactions are received by a node,\n>> validating them individually is insufficient. When the sender is aware\n>> of additional information that the receiver needs to accept a package,\n>> a proactive ''sender-initiated'' dialogue should be enabled:\n>>\n>> 1. Sender announces they have package information pertaining to a\n>>    transaction that might otherwise be undesired on its own.\n>>\n>> 2. The receiver requests package information.\n>>\n>> 3. The sender provides package information, including the wtxids of\n>>    the transactions in the package and anything else that might be\n>> relevant (e.g. total fees and size).\n>>\n>> 4. The reciever uses the package information to decide how to request\n>>    and validate the transactions.\n>>\n>> Package relay is negotiated between two peers during the version\n>> handshake. Package relay requires both peers to support wtxid-based\n>> relay because package transactions are referenced by their wtxid.\n>>\n>> ====New Messages====\n>>\n>> Three new protocol messages are added for use in any version of\n>> package relay. Additionally, each version of package relay must define\n>> its own inv type and \"pckginfo\" message version, referred to in this\n>> document as \"MSG_PCKG\" and \"pckginfo\" respectively. See\n>> BIP-v1-packages for a concrete example.\n>>\n>> =====sendpackages=====\n>>\n>> {|\n>> |  Field Name  ||  Type  ||  Size  ||  Purpose\n>> |-\n>> |version || uint32_t || 4 || Denotes a package version supported by the\n>> node.\n>> |-\n>> |max_count || uint32_t || 4 ||Specifies the maximum number of\n>> transactions per package this node is\n>> willing to accept.\n>> |-\n>> |max_weight || uint32_t || 4 ||Specifies the maximum total weight per\n>> package this node is willing\n>> to accept.\n>> |-\n>> |}\n>>\n>> 1. The \"sendpackages\" message has the structure defined above, with\n>>    pchCommand == \"sendpackages\".\n>>\n>> 2. During version handshake, nodes should send a \"sendpackages\"\n>>    message indicate they support package relay and may request\n>> packages.\n>>\n>> 3. The message should contain a version supported by the node. Nodes\n>>    should send a \"sendpackages\" message for each version they support.\n>>\n>> 4. The \"sendpackages\" message MUST be sent before sending a \"verack\"\n>>    message. If a \"sendpackages\" message is received afer \"verack\", the\n>> sender should be disconnected.\n>>\n>> 5. If 'fRelay==false' in a peer's version message, the node must not\n>>    send \"sendpackages\" to them. If a \"sendpackages\" message is\n>> received by a peer after sending `fRelay==false` in their version\n>> message, the sender should be disconnected.\n>>\n>> 6.. Upon receipt of a \"sendpackages\" message with a version that is\n>> not supported, a node must treat the peer as if it never received the\n>> message.\n>>\n>> 7. If both peers send \"wtxidrelay\" and \"sendpackages\" with the same\n>>    version, the peers should announce, request, and send package\n>> information to each other.\n>>\n>> =====getpckgtxns=====\n>>\n>> {|\n>> |  Field Name  ||  Type  ||  Size  ||   Purpose\n>> |-\n>> |txns_length||CompactSize||1 or 3 bytes|| The number of transactions\n>> requested.\n>> |-\n>> |txns||List of wtxids||txns_length * 32|| The wtxids of each transaction\n>> in the package.\n>> |}\n>>\n>> 1. The \"getpckgtxns\" message has the structure defined above, with\n>>    pchCommand == \"getpckgtxns\".\n>>\n>> 2. A \"getpckgtxns\" message should be used to request all or some of\n>>    the transactions previously announced in a \"pckginfo\" message,\n>> specified by witness transactiosome id.\n>>\n>> 3. Upon receipt of a \"getpckgtxns\" message, a node must respond with\n>>    either a \"pckgtxns\" containing the requested transactions or a\n>> \"notfound\" message indicating one or more of the transactions is\n>> unavailable. This allows the receiver to avoid downloading and storing\n>> transactions that cannot be validated immediately.\n>>\n>> 4. A \"getpckgtxns\" message should only be sent if both peers agreed to\n>>    send packages in the version handshake. If a \"getpckgtxns\" message\n>> is received from a peer with which package relay was not negotiated,\n>> the sender should be disconnected.\n>>\n>> =====pckgtxns=====\n>>\n>> {|\n>> |  Field Name  ||  Type  ||  Size  ||   Purpose\n>> |-\n>> |txns_length||CompactSize||1 or 3 bytes|| The number of transactions\n>> provided.\n>> |-\n>> |txns||List of transactions||variable|| The transactions in the package.\n>> |}\n>>\n>> 1. The \"pckgtxns\" message has the structure defined above, with\n>>    pchCommand == \"pckgtxns\".\n>>\n>> 2. A \"pckgtxns\" message should contain the transaction data requested\n>>    using \"getpckgtxns\".\n>>\n>> 3. A \"pckgtxns\" message should only be sent to a peer that requested\n>>    the package using \"getpckgtxns\". If a node receives an unsolicited\n>> package, the sender should be disconnected.\n>>\n>> 4. A \"pckgtxns\" message should only be sent if both peers agreed to\n>>    send packages in the version handshake. If a \"pckgtxns\" message is\n>> received from a peer with which package relay was not negotiated, the\n>> sender should be disconnected.\n>>\n>> ===Version 1 Packages: child-with-unconfirmed-parents===\n>>\n>> This extends package relay for packages consisting of one transaction\n>> and all of its unconfirmed parents,by defining version 1 packages, a\n>> pckginfo1 message, and a MSG_PCKG1 inv type. It enables the use case\n>> in which a child pays for its otherwise-too-low-fee parents and their\n>> mempool conflict(s).\n>>\n>> ====Intended Protocol Flow====\n>>\n>> When relaying a package of low-fee parent(s) and high-fee child, the\n>> sender and receiver do the following:\n>>\n>> 1. Sender announces they have a child-with-unconfirmed-parents package\n>>    for a child that pays for otherwise-too-low-fee parent(s) using\n>> \"inv(MSG_PCKG1)\".\n>>\n>> 2. The receiver requests package information using\n>>    \"getdata(MSG_PCKG1)\".\n>>\n>> 3. The sender provides package information using \"pckginfo1\",\n>>    including the blockhash of the sender's best block, the wtxids of\n>> the transactions in the package, their total fees and total weight.\n>>\n>> 4. The reciever uses the package information to decide how to request\n>>    the transactions. For example, if the receiver already has some of\n>> the transactions in their mempool, they only request the missing ones.\n>> They could also decide not to request the package at all based on the\n>> fee information provided.\n>>\n>> 5. Upon receiving a \"pckgtxns\", the receiver submits the transactions\n>>    together as a package.\n>>\n>> ====New Messages====\n>>\n>> A new inv type, \"MSG_PCKG1\", and new protocol message, \"PCKGINFO1\",\n>> are added.\n>>\n>> =====pckginfo1=====\n>>\n>> {|\n>> |  Field Name  ||  Type  ||  Size  ||   Purpose\n>> |-\n>> |blockhash || uint256 || 32 || The chain tip at which this package is\n>> defined.\n>> |-\n>> |pckg_fee||CAmount||4|| The sum total fees paid by all transactions in\n>> the package.\n>> |-\n>> |pckg_weight||int64_t||8|| The sum total weight of all transactions in\n>> the package.\n>> |-\n>> |txns_length||CompactSize||1 or 3 bytes|| The number of transactions\n>> provided.\n>> |-\n>> |txns||List of wtxids||txns_length * 32|| The wtxids of each transaction\n>> in the package.\n>> |}\n>>\n>>\n>> 1. The \"pckginfo1\" message has the structure defined above, with\n>>    pchCommand == \"pckginfo1\".\n>>\n>> 2. A \"pckginfo1\" message contains information about a version 1\n>>    package (defined below), referenced by the wtxid of the transaction\n>> it pertains to and the current blockhash.\n>>\n>> 3. Upon receipt of a \"pckginfo1\" message, the node should decide if it\n>>    wants to validate the package, request transaction data if\n>> necessary, etc.\n>>\n>> 4. Upon receipt of a malformed \"pckginfo1\" message or package that\n>>    does not abide by the max_count, max_weight, or other rules\n>> specified by the version agreed upon in the initial negotiation, the\n>> sender should be disconnected.  If a node receives a \"pckginfo1\"\n>> message for which the \"pckg_fee\" or \"pckg_weight\" do not reflect the\n>> true total fees and weight, respectively, or the transactions in the\n>> package, the message is malformed.\n>>\n>> 5. A node MUST NOT send a \"pckginfo1\" message that has not been\n>>    requested by the recipient. Upon receipt of an unsolicited\n>> \"pckginfo1\", a node should disconnect the sender.\n>>\n>> 6. A \"pckginfo1\" message should only be sent if both peers agreed to\n>>    send version 1 packages in the version handshake. If a \"pckginfo1\"\n>> message is received from a peer with which package relay was not\n>> negotiated, the sender should be disconnected.\n>>\n>> =====MSG_PCKG1=====\n>>\n>> 1. A new inv type (MSG_PCKG1 == 0x6) is added, for use in inv messages\n>>    and getdata requests pertaining to version 1 packages.\n>>\n>> 2. As an inv type, it indicates that both transaction data and version\n>>    1 package information are available for the transaction. The\n>> transaction is referenced by its wtxid. As a getdata request type, it\n>> indicates that the sender wants package information for the\n>> transaction.\n>>\n>> 3. Upon receipt of a \"getdata\" request for \"MSG_PCKG1\", the node\n>>    should respond with the version 1 package corresponding to the\n>> requested transaction and its current chain tip, or with NOTFOUND.\n>> The node should not assume that the sender is requesting the\n>> transaction data as well.\n>>\n>> ====Child With Parent Packages Rules====\n>>\n>> A child-with-unconfirmed-parents package sent between nodes must abide\n>> by the rules below, otherwise the package is malformed and the sender\n>> should be disconnected.\n>>\n>> A version 1 or ''child-with-unconfirmed-parents'' package can be\n>> defined for any transaction that spends unconfirmed inputs. The child\n>> can be thought of as the \"representative\" of the package. This package\n>> can be uniquely identified by the transaction's wtxid and the current\n>> chain tip block hash.\n>>\n>> A ''child-with-unconfirmed-parents'' package MUST be:\n>>\n>> 1. ''Sorted topologically.'' For every transaction t in the package,\n>>    if any of t's parents are present in the package, the parent must\n>> appear somewhere in the list before t. In other words, the\n>> transactions must be sorted in ascending order of the number of\n>> ancestors present in the package.\n>>\n>> 2. ''Only 1 child with unconfirmed parents.'' The package must consist\n>>    of one transaction and its unconfirmed parents. There must not be\n>> any other transactions in the package. Other dependency relationships\n>> may exist within the package (e.g. one parent may spend the output of\n>> another parent) provided that topological order is respected.\n>>\n>> 3. ''All unconfirmed parents.'' All of the child's unconfirmed parents\n>>    must be present.\n>>\n>> 4. ''No conflicts.'' None of the transactions in the package may\n>>    conflict with each other (i.e.  spend the same prevout).\n>>\n>> 5. ''Total fees and weight.'' The 'total_fee' and 'total_weight'\n>>    fields must accurately represent the sum total of all transactions'\n>> fees and weights as defined in BIP141, respectively.\n>>\n>> Not all of the child's parents must be present; the child transaction\n>> may also spend confirmed inputs. However, if the child has confirmed\n>> parents, they must not be in the package.\n>>\n>> While a child-with-unconfirmed-parents package is perhaps most\n>> relevant when the child has a higher feerate than its parents, this\n>> property is not required to construct a valid package.\n>>\n>> ====Clarifications====\n>>\n>> ''Q: Under what circumstances should a sender announce a\n>> child-with-unconfirmed-parents package?''\n>>\n>> A child-with-unconfirmed-parents package for a transaction should be\n>> announced when it meets the peer's fee filter but one or more of its\n>> parents don't; a \"inv(MSG_PCKG1)\" instead of \"inv(WTX)\" should be sent\n>> for the child. Each of the parents which meet the peer's fee filter\n>> should still be announced normally.\n>>\n>> ''Q: What if a new block arrives in between messages?''\n>>\n>> A child-with-unconfirmed-parents package is defined for a transaction\n>> based on the current chain state. As such, a new block extending the\n>> tip may decrease the number of transactions in the package (i.e. if\n>> any of the transaction's parents were included in the block). In a\n>> reorg, the number of transactions in the package may decrease or\n>> increase (i.e. if any of the transaction's parents were included in a\n>> block in the previous chain but not the new one).\n>>\n>> If the new block arrives before the \"getdata\" or \"pckginfo1\", nothing\n>> needs to change.\n>>\n>> If the new block arrives before \"getpckgtxns\" or before \"pckgtxns\",\n>> the receiver may need to re-request package information if the block\n>> contained a transaction in the package. If the block doesn't contain\n>> any transactions in the package, whether it extends the previous tip\n>> or causes a reorg, nothing needs to change.\n>>\n>> ''Q: Can \"getpckgtxns\" and \"pckgtxns\" messages contain only one\n>> transaction?''\n>>\n>> Yes.\n>>\n>> ===Further Protocol Extensions===\n>>\n>> When introducing a new type of package, assign it a version number \"n\"\n>> and use an additional \"sendpackages\" message during version handshake\n>> to negotiate support for it. An additional package information message\n>> \"pckginfon\" and inv type \"MSG_PCKGn\" should be defined for the type of\n>> package.  However, \"getpckgtxns\" and \"pckgtxns\" do not need to be\n>> changed.\n>>\n>> Example proposal for tx-with-unconfirmed-ancestors package relay: [19]\n>>\n>> ===Compatibility===\n>>\n>> Older clients remain fully compatible and interoperable after this\n>> change. Clients implementing this protocol will only attempt to send\n>> and request packages if agreed upon during the version handshake.\n>>\n>> ===Package Erlay===\n>>\n>> Clients using BIP330 reconciliation-based transaction relay (Erlay)\n>> are able to use package relay without interference. In fact, a package\n>> of transactions may be announced using both Erlay and package relay.\n>> After reconciliation, if the initiator would have announced a\n>> transaction by wtxid but also has package information for it, they may\n>> send \"inv(MSG_PCKG)\" instead of \"inv(WTX)\".\n>>\n>> ===Rationale===\n>>\n>> ====P2P Message Design====\n>>\n>> These p2p messages are added for communication efficiency and, as\n>> such, one should measure alternative solutions based on the resources\n>> used to communicate (not necessarily trustworthy) information: We\n>> would like to minimize network bandwidth, avoid downloading a\n>> transaction more than once, avoid downloading transactions that are\n>> eventually rejected, and minimize storage allocated for\n>> not-yet-validated transactions.\n>>\n>> Consider these (plausible) scenarios in transaction relay:\n>>\n>> Alice (the \"sender\") is relaying transactions to Bob (the \"receiver\").\n>> Alice's mempool has a minimum feerate of 1sat/vB and Bob's has a\n>> minimum feerate of 3sat/vB. For simplicity, all transactions are\n>> 1600Wu in virtual size and 500 bytes in serialized size. Apart from\n>> the spending relationships specified, all other inputs are from\n>> confirmed UTXOs.\n>>\n>> 1. Package {A, B} where A pays 0 satoshis and B pays 8000 satoshis in\n>>    fees.\n>>\n>> 2. Package {C, D} where C pays 0 satoshis and D pays 1200 satoshis in\n>>    fees.\n>>\n>> 3. Package {E, F, G, H, J} that pays 4000, 8000, 0, 2000, and 4000\n>>    satoshis in fees, respectively.\n>>\n>> ====Alternative Designs Considered====\n>>\n>> ''Package Information Only:'' Just having \"pckginfo\" gives enough\n>> information for the receiver to accept the package. Omit the\n>> \"getpckgtxns\" and \"pckgtxns\" messages. While this option is a good\n>> fallback if batched transaction download fails for some reason, it\n>> shouldn't be used as the default because it 'always' requires storage\n>> of unvalidated transactions.\n>>\n>> ''No Package Information Round:'' Instead of having a package\n>> information round, just use the child's wtxid to refer to the package\n>> and always send the entire package together. This would cause nodes to\n>> redownload duplicate transactions.\n>>\n>> I have also created a slidedeck exploring various alternative designs\n>> and some examples in which they fall flat [20]. Please feel free to\n>> suggest other alternatives.\n>>\n>> ====Versioning System====\n>>\n>> This protocol should be extensible to support multiple types of\n>> packages based on future desired use cases. Two \"flavors\" of\n>> versioning were considered:\n>>\n>> 1. When package mempool acceptance is upgraded to support more types\n>>    of packages, increment the version number (similar to Erlay).\n>> During version handshake, peers negotiate which version of package\n>> relay they will use by each sending one \"sendpackages\" message.\n>>\n>> 2. When introducing another type of package, assign a version number\n>>    to it and announce it as an additional supported version (similar\n>> to Compact Block Relay). During version handshake, peers send one\n>> \"sendpackages\" message for each version supported.\n>>\n>> The second option was favored because it allows different parameters\n>> for different versions.  For example, it should be possible to support\n>> both \"arbitrary topology but maximum 3-transaction\" package as well as\n>> \"child-with-unconfirmed-parents with default mempool ancestor limits\"\n>> packages simultaneously.\n>>\n>> ==Acknowledgements==\n>>\n>> I hope to have made it abundantly clear that this proposal isn\u2019t\n>> inventing the concept of package relay, and in fact builds upon years\n>> of work by many others, including Suhas Daftuar and Antoine Riard.\n>>\n>> Thank you to John Newbery and Martin Zumsande for input on the design.\n>>\n>> Thank you to Matt Corallo, Christian Decker, David Harding, Antoine\n>> Poinsot, Antoine Riard, Gregory Sanders, Chris Stewart, Bastien\n>> Teinturier, and others for input on the desired interface for\n>> contracting protocols.\n>>\n>> Looking forward to hearing your thoughts!\n>>\n>> Best,\n>> Gloria\n>>\n>> [0]:\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019817.html\n>> [1]:\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-April/002639.html\n>> [2]:\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-June/002758.html\n>> [3]:\n>> https://github.com/t-bast/lightning-docs/blob/master/pinning-attacks.md\n>> [4]:\n>> https://github.com/revault/practical-revault/blob/master/transactions.md#cancel_tx\n>> [5]:\n>> https://github.com/discreetlogcontracts/dlcspecs/blob/master/Transactions.md#refund-transaction\n>> [6]: https://gist.github.com/instagibbs/60264606e181451e977e439a49f69fe1\n>> [7]:\n>> https://btctranscripts.com/adopting-bitcoin/2021/2021-11-16-gloria-zhao-transaction-relay-policy/#lightning-attacks\n>> [8]: https://youtu.be/fbWSQvJjKFs?t=1438\n>> [9]:\n>> https://www.reddit.com/r/Bitcoin/comments/unew4e/looks_like_70_mvb_of_transactions_just_got_dumped/\n>> [10]: https://github.com/bitcoin/bitcoin/pull/7594\n>> [11]: https://github.com/bitcoin/bitcoin/pull/7600\n>> [12]: https://github.com/bitcoin/bitcoin/pull/6455#issuecomment-122716820\n>> [13]: https://gist.github.com/sdaftuar/8756699bfcad4d3806ba9f3396d4e66a\n>> [14]: https://github.com/bitcoin/bitcoin/issues/14895\n>> [15]: https://github.com/bitcoin/bitcoin/pull/16401\n>> [16]: https://github.com/bitcoin/bitcoin/pull/19621\n>> [17]:\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html\n>> [18]: https://github.com/users/glozow/projects/5/views/4?layout=board\n>> [19]: https://gist.github.com/glozow/9b321cd3ef6505135c763112033ff2a7\n>> [20]:\n>> https://docs.google.com/presentation/d/1B__KlZO1VzxJGx-0DYChlWawaEmGJ9EGApEzrHqZpQc/edit?usp=sharing\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220517/321c2029/attachment-0001.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2022-05-18T00:35:31",
                "message_text_only": "On Tue, May 17, 2022 at 12:01:04PM -0400, Gloria Zhao via bitcoin-dev wrote:\n> ====New Messages====\n> Three new protocol messages are added for use in any version of\n> package relay. Additionally, each version of package relay must define\n> its own inv type and \"pckginfo\" message version, referred to in this\n> document as \"MSG_PCKG\" and \"pckginfo\" respectively. See\n> BIP-v1-packages for a concrete example.\n\nThe \"PCKG\" abbreviation threw me for a loop; isn't the usual\nabbreviation \"PKG\" ?\n\n> =====sendpackages=====\n> |version || uint32_t || 4 || Denotes a package version supported by the\n> node.\n> |max_count || uint32_t || 4 ||Specifies the maximum number of transactions\n> per package this node is\n> willing to accept.\n> |max_weight || uint32_t || 4 ||Specifies the maximum total weight per\n> package this node is willing\n> to accept.\n\nDoes it make sense for these to be configurable, rather than implied\nby the version? \n\nI presume the idea is to cope with people specifying different values for\n-limitancestorcount or -limitancestorsize, but if people are regularly\nrelaying packages around, it seems like it becomes hard to have those\nvalues really be configurable while being compatible with that?\n\nI guess I'm asking: would it be better to either just not do sendpackages\nat all if you're limiting ancestors in the mempool incompatibly; or\nalternatively, would it be better to do the package relay, then reject\nthe particular package if it turns out too big, and log that you've\ndropped it so that the node operator has some way of realising \"whoops,\nI'm not relaying packages properly because of how I configured my node\"?\n\n> 5. If 'fRelay==false' in a peer's version message, the node must not\n>    send \"sendpackages\" to them. If a \"sendpackages\" message is\n> received by a peer after sending `fRelay==false` in their version\n> message, the sender should be disconnected.\n\nSeems better to just say \"if you set fRelay=false in your version\nmessage, you must not send sendpackages\"? You already won't do packages\nwith the peer if they don't also announce sendpackages.\n\n> 7. If both peers send \"wtxidrelay\" and \"sendpackages\" with the same\n>    version, the peers should announce, request, and send package\n> information to each other.\n\nMaybe: \"You must not send sendpackages unless you also send wtxidrelay\" ?\n\n\nAs I understand it, the two cases for the protocol flow are \"I received\nan orphan, and I'd like its ancestors please\" which seems simple enough,\nand \"here's a child you may be interested in, even though you possibly\nweren't interested in the parents of that child\". I think the logic for\nthe latter is:\n\n * if tx C's fee rate is less than the peer's feefilter, skip it\n   (will maybe treat it as a parent in some package later though)\n * if tx C's ancestor fee rate is less than the peer's feefilter, skip\n   it?\n * look at the lowest ancestor fee rate for any of C's in-mempool\n   parents\n * if that is higher than the peer's fee filter, send a normal INV\n * if it's lower than the peer's fee filter, send a PCKG INV\n\nAre \"getpckgtxns\" / \"pcktxns\" really limited to packages, or are they\njust a general way to request a batch of transactions? Particularly in\nthe case of requesting the parents of an orphan tx you already have,\nit seems hard for the node receiving getpckgtxns to validate that the\ntxs are related in some way; but also it doesn't seem very necessary?\n\nMaybe call those messages \"getbatchtxns\" and \"batchtxns\" and allow them to\nbe used more generally, potentially in ways unrelated to packages/cpfp?\nThe \"only be sent if both peers agreed to do package relay\" rule could\nsimply be dropped, I think.\n\n> 4. The reciever uses the package information to decide how to request\n>    the transactions. For example, if the receiver already has some of\n> the transactions in their mempool, they only request the missing ones.\n> They could also decide not to request the package at all based on the\n> fee information provided.\n\nShouldn't the sender only be sending package announcements when they know\nthe recipient will be interested in the package, based on their feefilter?\n\n> =====pckginfo1=====\n> {|\n> |  Field Name  ||  Type  ||  Size  ||   Purpose\n> |-\n> |blockhash || uint256 || 32 || The chain tip at which this package is\n> defined.\n> |-\n> |pckg_fee||CAmount||4|| The sum total fees paid by all transactions in the\n> package.\n\nCAmount in consensus/amount.h is a int64_t so shouldn't this be 8\nbytes? If you limit a package to 101kvB, an int32_t is enough to cover\nany package with a fee rate of about 212 BTC/block or lower, though.\n\n> |pckg_weight||int64_t||8|| The sum total weight of all transactions in the\n> package.\n\nThe maximum block weight is 4M, and the default -limitancestorsize\npresumably implies a max package weight of 404k; seems odd to provide\na uint64_t rather than an int32_t here, which easily allows either of\nthose values?\n\n> 2. ''Only 1 child with unconfirmed parents.'' The package must consist\n>    of one transaction and its unconfirmed parents. There must not be\n> any other transactions in the package. Other dependency relationships\n> may exist within the package (e.g. one parent may spend the output of\n> another parent) provided that topological order is respected.\n\nI think this means that some of the parents could also have unconfirmed\nparents, but they won't be included in the package, and must be requested\nvia the recipient-initiated approach?\n\n> 5. ''Total fees and weight.'' The 'total_fee' and 'total_weight'\n>    fields must accurately represent the sum total of all transactions'\n>    fees and weights as defined in BIP141, respectively.\n\nPresumably this excludes any unconfirmed grandparents and earlier\nancestors since they aren't part of the package, in this approach? Doesn't\nthat make this both harder to calculate (assuming we already have\nancestor summaries) and less useful, in the case where those ancestors\nhave a lower fee rate?\n\n> ''Q: Can \"getpckgtxns\" and \"pckgtxns\" messages contain only one\n> transaction?''\n> Yes.\n\nThis would be normal if you're requesting a single missing parent for\nan orphan you've received, I think?\n\nI'm slightly surprised the process is:\n\n ->  INV PCKG1 C\n  <- GETDATA PCKG1 C\n ->  PCKGINFO1 blockhash A B C fee weight\n\nrather than announcing the package fee info in the first message.\nBut if the sender is already applying the feefilter to the package before\nannouncing it, it probably doesn't matter, and means you're only getting\na 32B INV from every peer, rather than a 32*(n+2) PCKGINFO1 message from\nevery peer.\n\nI guess tx relay is low priority enough that it wouldn't be worth tagging\nsome peers as \"high bandwidth\" and having them immediately announce the\nPCKGINFO1 message, and skip the INV/GETDATA step?\n\nCheers,\naj"
            },
            {
                "author": "Gloria Zhao",
                "date": "2022-05-18T18:40:58",
                "message_text_only": "(To everyone):\nI should have made it much clearer that version 1 is only supposed to solve\n1 of the 2 use cases. I was a lot more focused on the fee-bumping use case,\nsince it\u2019s more important. Orphan-fetching was added to the motivation\nsection last-minute because John Newbery mentioned to me \u201chey you could\ndeal with orphans really easily with this.\u201d Of course,\nchild-with-unconfirmed-parents packages aren\u2019t very useful for\norphan-fetching since non-parent ancestors are quite common.\n\nMaybe a version 2 package for orphan-fetching could look like this:\n\n\u201cpckginfo2\u201d message contains a tx with all of its ancestors\n\n\u201cMSG_PCKG2\u201d inv type refers to a \u201cpckginfo2\u201d for a tx. You don\u2019t send\ninv(MSG_PCKG2), but a node can request getdata(MSG_PCKG2) for a transaction\nthey want the ancestors for, provided they sent sendpackages(version=2)\nahead of time. It seems to me that orphan-fetching only ever needs to be\nreceiver-initiated.\n\nProtocol flow would look like this:\nhttps://user-images.githubusercontent.com/25183001/168891185-1630f583-de47-4937-86b1-2652cf8852f2.png\n\nWe don\u2019t have a policy for dealing with anything more than a child with its\ndirect parents, but I also don\u2019t think anybody is relying on fee-bumping\nmore than 2 generations, so the validation logic here could probably just\nsubmit them all individually. Maybe they can request a pckginfo1 if they\nsee something that\u2019s too-low-fee, and/or use the\nchild-with-unconfirmed-parents logic opportunistically.\n\nThanks aj for the feedback! Responding:\n\n> The \"PCKG\" abbreviation threw me for a loop; isn't the usual\n> abbreviation \"PKG\" ?\n\nOh I didn't know that. I could change it if people feel strongly.\n\n> Does it make sense for these to be configurable, rather than implied\n> by the version?\n> \u2026 would it be better to either just not do sendpackages\n> at all if you're limiting ancestors in the mempool incompatibly\n\nEffectively: if you\u2019re setting your ancestor/descendant limits lower than\nthe default, you can\u2019t do package relay. I wonder if this might be\ncontroversial, since it adds pressure to adhere to Bitcoin Core\u2019s current\nmempool policy? I would be happy to do it this way, though - makes things\neasier to implement.\n\n> > 5. If 'fRelay==false' in a peer's version message, the node must not\n> >    send \"sendpackages\" to them. If a \"sendpackages\" message is\n> > received by a peer after sending `fRelay==false` in their version\n> > message, the sender should be disconnected.\n\n> Seems better to just say \"if you set fRelay=false in your version\n> message, you must not send sendpackages\"? You already won't do packages\n> with the peer if they don't also announce sendpackages.\n\nI guess, theoretically, if you allow bloom filters with this peer, it\u2019s\nplausible they\u2019re saying \u201cfRelay=false, I\u2019ll send you a bloom filter later,\nand I\u2019ll also want to talk about packages.\u201d\nI don\u2019t know if that\u2019s a use case we want to support - my gut reaction is\nno.\n\n> Maybe: \"You must not send sendpackages unless you also send wtxidrelay\" ?\n\nDo you mean if we get a verack, and the peer sent \u201csendpackages\u201d but not\n\u201cwtxidrelay,\u201d we should disconnect them?\n\n> As I understand it, the two cases for the protocol flow are \"I received\n> an orphan, and I'd like its ancestors please\" which seems simple enough,\n> and \"here's a child you may be interested in, even though you possibly\n> weren't interested in the parents of that child\".\n\n(Btw, please see my notes at the top of this email about separating those\ntwo use cases. sorry for the confusion).\n\n> I think the logic for the latter is: [\u2026]\n\nI have it as: we send a PCKG INV when this transaction\u2019s feerate is above\nthe fee filter, but one or more of its parents don\u2019t. I don\u2019t think using\nancestor feerate is better.\nSee this counterexample:\nhttps://raw.githubusercontent.com/glozow/bitcoin-notes/master/mempool_garden/abc_1parent_2kids.png\nA (0fee) has 2 kids, B (3sat/vB) and C (20sat/vB), everything\u2019s the same\nvsize. Let\u2019s say the fee filter is 3sat/vB.\nIf we do it based on ancestor feerate, we won\u2019t send B. But B is actually\nfine; C is paying for A.\n\n> Are \"getpckgtxns\" / \"pcktxns\" really limited to packages, or are they\n> just a general way to request a batch of transactions?\n\n> Maybe call those messages \"getbatchtxns\" and \"batchtxns\" and allow them to\n> be used more generally, potentially in ways unrelated to packages/cpfp?\n\nIndeed, it\u2019s a general way to request a batch of transactions. I\u2019ll\nhighlight that it is \u201call or nothing,\u201d i.e. if the sender is missing any of\nthem, they\u2019ll just send a notfound.\nThe idea here was to avoid downloading any transactions that can\u2019t be\nvalidated right away. With packages, this makes sense, because there are\ndependency relationships. But if you\u2019re requesting multiple unrelated\ntransactions, for example, it\u2019s unnecessary. You might end up with even\nmore transaction data that\u2019s just sitting around waiting to be validated.\n\n> The \"only be sent if both peers agreed to do package relay\" rule could\n> simply be dropped, I think.\n\nWouldn\u2019t we need some way of saying \u201chey I support batchtxns?\u201d Otherwise\nyou would have to guess by sending a request and waiting to see if it\u2019s\nignored?\n\n> Shouldn't the sender only be sending package announcements when they know\n> the recipient will be interested in the package, based on their feefilter?\n\nI think there are cases where the sender doesn\u2019t necessarily know.\nConsider this example:\nhttps://raw.githubusercontent.com/glozow/bitcoin-notes/master/mempool_garden/rich_parent_bad_cpfp.png\nD (5sat/vB) has 2 parents, A (0sat/vB) and B (20sat/vB). All same size.\nFeefilter is 3sat/vB.\nIf the receiver already has B, they\u2019ll know they can just reject the\npackage already based on the pckginfo.\nBut the sender doesn\u2019t really know that. The sender just knows A is below\nfeerate and D is above. D is above the fee filter, and its ancestor feerate\nis above the fee filter.\n\n> CAmount in consensus/amount.h is a int64_t\n> The maximum block weight is 4M\u2026\n\n Oops yes. I think we just usually use int64_t for vsizes afaik. Agree that\nit should be 8 bytes for fee, and 4 bytes is enough for vsize.\n\n> I guess tx relay is low priority enough that it wouldn't be worth tagging\n> some peers as \"high bandwidth\" and having them immediately announce the\n> PCKGINFO1 message, and skip the INV/GETDATA step?\n\nI had the same idea as well, but seemed unnecessary. It would reduce the\nnumber of round trips, but I don\u2019t think an extra round trip is that big of\na deal for transaction relay. Block relay, yes of course, but I don\u2019t think\nwe care that much if it takes an extra second to send a transaction?\n\nBest,\nGloria\n\nOn Tue, May 17, 2022 at 8:35 PM Anthony Towns <aj at erisian.com.au> wrote:\n\n> On Tue, May 17, 2022 at 12:01:04PM -0400, Gloria Zhao via bitcoin-dev\n> wrote:\n> > ====New Messages====\n> > Three new protocol messages are added for use in any version of\n> > package relay. Additionally, each version of package relay must define\n> > its own inv type and \"pckginfo\" message version, referred to in this\n> > document as \"MSG_PCKG\" and \"pckginfo\" respectively. See\n> > BIP-v1-packages for a concrete example.\n>\n> The \"PCKG\" abbreviation threw me for a loop; isn't the usual\n> abbreviation \"PKG\" ?\n>\n> > =====sendpackages=====\n> > |version || uint32_t || 4 || Denotes a package version supported by the\n> > node.\n> > |max_count || uint32_t || 4 ||Specifies the maximum number of\n> transactions\n> > per package this node is\n> > willing to accept.\n> > |max_weight || uint32_t || 4 ||Specifies the maximum total weight per\n> > package this node is willing\n> > to accept.\n>\n> Does it make sense for these to be configurable, rather than implied\n> by the version?\n>\n> I presume the idea is to cope with people specifying different values for\n> -limitancestorcount or -limitancestorsize, but if people are regularly\n> relaying packages around, it seems like it becomes hard to have those\n> values really be configurable while being compatible with that?\n>\n> I guess I'm asking: would it be better to either just not do sendpackages\n> at all if you're limiting ancestors in the mempool incompatibly; or\n> alternatively, would it be better to do the package relay, then reject\n> the particular package if it turns out too big, and log that you've\n> dropped it so that the node operator has some way of realising \"whoops,\n> I'm not relaying packages properly because of how I configured my node\"?\n>\n> > 5. If 'fRelay==false' in a peer's version message, the node must not\n> >    send \"sendpackages\" to them. If a \"sendpackages\" message is\n> > received by a peer after sending `fRelay==false` in their version\n> > message, the sender should be disconnected.\n>\n> Seems better to just say \"if you set fRelay=false in your version\n> message, you must not send sendpackages\"? You already won't do packages\n> with the peer if they don't also announce sendpackages.\n>\n> > 7. If both peers send \"wtxidrelay\" and \"sendpackages\" with the same\n> >    version, the peers should announce, request, and send package\n> > information to each other.\n>\n> Maybe: \"You must not send sendpackages unless you also send wtxidrelay\" ?\n>\n>\n> As I understand it, the two cases for the protocol flow are \"I received\n> an orphan, and I'd like its ancestors please\" which seems simple enough,\n> and \"here's a child you may be interested in, even though you possibly\n> weren't interested in the parents of that child\". I think the logic for\n> the latter is:\n>\n>  * if tx C's fee rate is less than the peer's feefilter, skip it\n>    (will maybe treat it as a parent in some package later though)\n>  * if tx C's ancestor fee rate is less than the peer's feefilter, skip\n>    it?\n>  * look at the lowest ancestor fee rate for any of C's in-mempool\n>    parents\n>  * if that is higher than the peer's fee filter, send a normal INV\n>  * if it's lower than the peer's fee filter, send a PCKG INV\n>\n> Are \"getpckgtxns\" / \"pcktxns\" really limited to packages, or are they\n> just a general way to request a batch of transactions? Particularly in\n> the case of requesting the parents of an orphan tx you already have,\n> it seems hard for the node receiving getpckgtxns to validate that the\n> txs are related in some way; but also it doesn't seem very necessary?\n>\n> Maybe call those messages \"getbatchtxns\" and \"batchtxns\" and allow them to\n> be used more generally, potentially in ways unrelated to packages/cpfp?\n> The \"only be sent if both peers agreed to do package relay\" rule could\n> simply be dropped, I think.\n>\n> > 4. The reciever uses the package information to decide how to request\n> >    the transactions. For example, if the receiver already has some of\n> > the transactions in their mempool, they only request the missing ones.\n> > They could also decide not to request the package at all based on the\n> > fee information provided.\n>\n> Shouldn't the sender only be sending package announcements when they know\n> the recipient will be interested in the package, based on their feefilter?\n>\n> > =====pckginfo1=====\n> > {|\n> > |  Field Name  ||  Type  ||  Size  ||   Purpose\n> > |-\n> > |blockhash || uint256 || 32 || The chain tip at which this package is\n> > defined.\n> > |-\n> > |pckg_fee||CAmount||4|| The sum total fees paid by all transactions in\n> the\n> > package.\n>\n> CAmount in consensus/amount.h is a int64_t so shouldn't this be 8\n> bytes? If you limit a package to 101kvB, an int32_t is enough to cover\n> any package with a fee rate of about 212 BTC/block or lower, though.\n>\n> > |pckg_weight||int64_t||8|| The sum total weight of all transactions in\n> the\n> > package.\n>\n> The maximum block weight is 4M, and the default -limitancestorsize\n> presumably implies a max package weight of 404k; seems odd to provide\n> a uint64_t rather than an int32_t here, which easily allows either of\n> those values?\n>\n> > 2. ''Only 1 child with unconfirmed parents.'' The package must consist\n> >    of one transaction and its unconfirmed parents. There must not be\n> > any other transactions in the package. Other dependency relationships\n> > may exist within the package (e.g. one parent may spend the output of\n> > another parent) provided that topological order is respected.\n>\n> I think this means that some of the parents could also have unconfirmed\n> parents, but they won't be included in the package, and must be requested\n> via the recipient-initiated approach?\n>\n> > 5. ''Total fees and weight.'' The 'total_fee' and 'total_weight'\n> >    fields must accurately represent the sum total of all transactions'\n> >    fees and weights as defined in BIP141, respectively.\n>\n> Presumably this excludes any unconfirmed grandparents and earlier\n> ancestors since they aren't part of the package, in this approach? Doesn't\n> that make this both harder to calculate (assuming we already have\n> ancestor summaries) and less useful, in the case where those ancestors\n> have a lower fee rate?\n>\n> > ''Q: Can \"getpckgtxns\" and \"pckgtxns\" messages contain only one\n> > transaction?''\n> > Yes.\n>\n> This would be normal if you're requesting a single missing parent for\n> an orphan you've received, I think?\n>\n> I'm slightly surprised the process is:\n>\n>  ->  INV PCKG1 C\n>   <- GETDATA PCKG1 C\n>  ->  PCKGINFO1 blockhash A B C fee weight\n>\n> rather than announcing the package fee info in the first message.\n> But if the sender is already applying the feefilter to the package before\n> announcing it, it probably doesn't matter, and means you're only getting\n> a 32B INV from every peer, rather than a 32*(n+2) PCKGINFO1 message from\n> every peer.\n>\n> I guess tx relay is low priority enough that it wouldn't be worth tagging\n> some peers as \"high bandwidth\" and having them immediately announce the\n> PCKGINFO1 message, and skip the INV/GETDATA step?\n>\n> Cheers,\n> aj\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220518/f022b65c/attachment-0001.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2022-05-23T21:34:16",
                "message_text_only": "On Wed, May 18, 2022 at 02:40:58PM -0400, Gloria Zhao via bitcoin-dev wrote:\n> > Does it make sense for these to be configurable, rather than implied\n> > by the version?\n> > \u2026 would it be better to either just not do sendpackages\n> > at all if you're limiting ancestors in the mempool incompatibly\n> Effectively: if you\u2019re setting your ancestor/descendant limits lower than\n> the default, you can\u2019t do package relay. I wonder if this might be\n> controversial, since it adds pressure to adhere to Bitcoin Core\u2019s current\n> mempool policy? I would be happy to do it this way, though - makes things\n> easier to implement.\n\nHow about looking at it the other way: if you're writing a protocol that's\ndependent on people seeing that a package as a whole pays a competitive\nfeerate, don't you want to know in advance what conditions the network\nis going to impose on your transactions in order to consider them as a\npackage? In that case, aren't the \"depth\" and \"size\" constraints things\nwe should specify in a standard?\n\n(The above's not a rhetorical question; I'm not sure what the answer is.\nAnd even if it's \"yes\", maybe core's defaults should be reconsidered\nrather than standardised as-is)\n\nWorst case, you could presumably do a new package relay version with\ndifferent constraints, if needed.\n\n> > > 5. If 'fRelay==false' in a peer's version message, the node must not\n> > >    send \"sendpackages\" to them. If a \"sendpackages\" message is\n> > > received by a peer after sending `fRelay==false` in their version\n> > > message, the sender should be disconnected.\n> > Seems better to just say \"if you set fRelay=false in your version\n> > message, you must not send sendpackages\"? You already won't do packages\n> > with the peer if they don't also announce sendpackages.\n> I guess, theoretically, if you allow bloom filters with this peer, it\u2019s\n> plausible they\u2019re saying \u201cfRelay=false, I\u2019ll send you a bloom filter later,\n> and I\u2019ll also want to talk about packages.\u201d\n\nI was just meaning \"it's okay to send VERSION fRelay=true then immediately\nsend WTXIDRELAY then immediately send SENDPACKAGES\" without having to\nfirst verify what the other guy's fRelay was set to. On the other hand,\nyou do already have to verify the other guy's version is high enough,\nbut it would be kind-of nice to move towards just announcing the features\nyou support, and not having to make it a multistep negotiation...\n\n> > Maybe: \"You must not send sendpackages unless you also send wtxidrelay\" ?\n> Do you mean if we get a verack, and the peer sent \u201csendpackages\u201d but not\n> \u201cwtxidrelay,\u201d we should disconnect them?\n\nYes.\n\n> I have it as: we send a PCKG INV when this transaction\u2019s feerate is above\n> the fee filter, but one or more of its parents don\u2019t. I don\u2019t think using\n> ancestor feerate is better.\n> See this counterexample:\n> https://raw.githubusercontent.com/glozow/bitcoin-notes/master/mempool_garden/abc_1parent_2kids.png\n> A (0fee) has 2 kids, B (3sat/vB) and C (20sat/vB), everything\u2019s the same\n> vsize. Let\u2019s say the fee filter is 3sat/vB.\n> If we do it based on ancestor feerate, we won\u2019t send B. But B is actually\n> fine; C is paying for A.\n\nBut that only works if the receiver also has C, in which case they also\nhave A, and you don't need package relay to do anything with B? If they\ndidn't have C already, then relaying {A,B} would be a waste of time,\nbecause {A,B} would be rejected as only paying 1.5sat/vB or whatever..\n\nIf you switch it to being:\n\n  A (0 sats, 200vB)\n  B (2000 sats, 200vB, spends A:0)\n  C (200 sats, 200vB)\n  D (1000 sats, 200vB, sepnds A:1, C:0)\n\nthen you get:\n\n  A alone = 0s/vB\n  B+A = 5s/vB\n\n  C alone = 1s/vB\n  D+C+A = 2s/vB\n  D+C = 3s/vB      (B+A already at 5s/vB)\n\nwhich I think recovers your point, while also having all the details\nonly be dealing with direct parents.\n\n> > Are \"getpckgtxns\" / \"pcktxns\" really limited to packages, or are they\n> > just a general way to request a batch of transactions?\n> > Maybe call those messages \"getbatchtxns\" and \"batchtxns\" and allow them to\n> > be used more generally, potentially in ways unrelated to packages/cpfp?\n> Indeed, it\u2019s a general way to request a batch of transactions. I\u2019ll\n> highlight that it is \u201call or nothing,\u201d i.e. if the sender is missing any of\n> them, they\u2019ll just send a notfound.\n> The idea here was to avoid downloading any transactions that can\u2019t be\n> validated right away.\n\nRight; maybe I should just be calling a \"batch of packages to be validated\ntogether\" a \"tx package\" in the first place.\n\nMaybe it would be worth emphasising that you should be expecting to\nvalidate all the txs you receive as a response to getpckgtxns (getpkgtxs\n:) all at the same time, and immediately upon receiving them?\n\n> > The \"only be sent if both peers agreed to do package relay\" rule could\n> > simply be dropped, I think.\n> Wouldn\u2019t we need some way of saying \u201chey I support batchtxns?\u201d Otherwise\n> you would have to guess by sending a request and waiting to see if it\u2019s\n> ignored?\n\nSure, perhaps I should have said leave that rule, but drop the following\n\"should be disconnected\" rule, so that other BIPs could add in other\nways of negotiating the connection in future? *shrug*\n\n> > Shouldn't the sender only be sending package announcements when they know\n> > the recipient will be interested in the package, based on their feefilter?\n> I think there are cases where the sender doesn\u2019t necessarily know.\n> Consider this example:\n> https://raw.githubusercontent.com/glozow/bitcoin-notes/master/mempool_garden/rich_parent_bad_cpfp.png\n> D (5sat/vB) has 2 parents, A (0sat/vB) and B (20sat/vB). All same size.\n> Feefilter is 3sat/vB.\n> If the receiver already has B, they\u2019ll know they can just reject the\n> package already based on the pckginfo.\n> But the sender doesn\u2019t really know that. The sender just knows A is below\n> feerate and D is above. D is above the fee filter, and its ancestor feerate\n> is above the fee filter.\n\nThe sender would also need to know whether or not there's some other\nchild E that pays for A sufficiently?\n\nIf you're asking for the package for \"D\", would a response telling you:\n\n  txid_D (500 sat, 100vB)\n  txid_A (0 sat, 100vB)\n  txid_B (2000 sat, 100 vB)\n\nbe better, in that case? Then the receiver can maybe do the logic\nthemselves to figure out that they already have A in their mempool\nso it's fine, or not?\n\nIf you've got a package for X, and its direct parents P1..Pn, then\nI think the logic would be:\n\n  * is X alone above my fee rate? no, then forget it\n  * otherwise, s := X.size, f := X.fees, R := [X]\n  * for P = P1..Pn:\n    * do I already have P? then skip to the next parent\n    * s += P.size, f += P.fees, R += [P]\n  * if f/s above my fee rate floor? if so, request all the txs in R\n\nand you'd request txs if-and-only-if they're a match for you mempool rate?\n\nIf you have a tx with 20 in-mempool parents, then the pkginfo1 message\nas proposed would be 737 bytes; including all the fee/size info would be\n957 bytes, maybe a 30% increase. Might be worth it though?\n\nCheers,\naj"
            },
            {
                "author": "Gloria Zhao",
                "date": "2022-05-24T01:13:43",
                "message_text_only": "Hi aj,\n\n> if you're writing a protocol that's\n> dependent on people seeing that a package as a whole pays a competitive\n> feerate, don't you want to know in advance what conditions the network\n> is going to impose on your transactions in order to consider them as a\n> package?\n\nI do think unifying the size/count constraints would result in a more\nstable/easier to reason about interface for L2 devs. Then the requirement\nfor propagation is just a path of nodes that support v1 package relay, and\nit\u2019s implied their mempool policy supports it as well. Also seems like it\ncould be a fingerprinting problem for nodes to give very specific\ncount/size limits.\n\n> (\u2026 maybe core's defaults should be reconsidered rather than standardised\nas-is)\n\n> Worst case, you could presumably do a new package relay version with\n> different constraints, if needed.\n\nMaybe this was my actual concern. I think the defaults are safe but it\u2019s\nnot like they\u2019ve been proven to be optimal. This creates an obstacle to\nchanging them, especially if we want to make them smaller. But I think it\u2019s\nunlikely we\u2019ll do that, and adding another version for new constraints\ndoesn\u2019t seem too bad.\n\n\n(Agreed with everything here, thanks for the feedback and clarifications!)\nTLDR, making these changes:\n- Count and size are implied by the version. Version 1 is specifically\nchild-with-unconfirmed-parents, where the whole package is at most 25\ntransactions and 101KvB.\n- Announce sendpackages based on our own state. It\u2019s ok to send\n\u201csendpackages\u201d if they sent fRelay=false.\n- At verack, require fRelay=true and wtxidrelay if they sent sendpackages,\notherwise disconnect.\n- If we get \u201cgetpckgtxns\u201d or \u201cpckgtxns\u201d without having negotiated\n\u201csendpackages\u201d ahead of time, ignore, don\u2019t disconnect. Emphasize that the\nintention is to validate all of the transactions received through\n\u201cpckgtxns\u201d together.\n\n> If you're asking for the package for \"D\", would a response telling you:\n>   txid_D (500 sat, 100vB)\n>   txid_A (0 sat, 100vB)\n>   txid_B (2000 sat, 100 vB)\n> be better, in that case? Then the receiver can maybe do the logic\n> themselves to figure out that they already have A in their mempool\n> so it's fine, or not?\n\nRight, I also considered giving the fees and sizes of each transaction in\nthe package in \u201cpckginfo1\u201d. But I don\u2019t think that information provides\nadditional meaning unless you know the exact topology, i.e. also know if\nthe parents have dependency relationships between them. For instance, in\nthe {A, B, D} package there, even if you have the information listed, your\ndecision should be different depending on whether B spends from A. The only\nthing you know for sure about a child with direct parents is: if the\naggregate feerate is too low, you won\u2019t want the child since it depends on\neveryone else. If there\u2019s a good-feerate transaction in there that doesn\u2019t\nhave a dependency, you\u2019re fine as long as someone sends it to you\nindividually.\n\nBest,\nGloria\n\nOn Mon, May 23, 2022 at 2:34 PM Anthony Towns via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Wed, May 18, 2022 at 02:40:58PM -0400, Gloria Zhao via bitcoin-dev\n> wrote:\n> > > Does it make sense for these to be configurable, rather than implied\n> > > by the version?\n> > > \u2026 would it be better to either just not do sendpackages\n> > > at all if you're limiting ancestors in the mempool incompatibly\n> > Effectively: if you\u2019re setting your ancestor/descendant limits lower than\n> > the default, you can\u2019t do package relay. I wonder if this might be\n> > controversial, since it adds pressure to adhere to Bitcoin Core\u2019s current\n> > mempool policy? I would be happy to do it this way, though - makes things\n> > easier to implement.\n>\n> How about looking at it the other way: if you're writing a protocol that's\n> dependent on people seeing that a package as a whole pays a competitive\n> feerate, don't you want to know in advance what conditions the network\n> is going to impose on your transactions in order to consider them as a\n> package? In that case, aren't the \"depth\" and \"size\" constraints things\n> we should specify in a standard?\n>\n> (The above's not a rhetorical question; I'm not sure what the answer is.\n> And even if it's \"yes\", maybe core's defaults should be reconsidered\n> rather than standardised as-is)\n>\n> Worst case, you could presumably do a new package relay version with\n> different constraints, if needed.\n>\n> > > > 5. If 'fRelay==false' in a peer's version message, the node must not\n> > > >    send \"sendpackages\" to them. If a \"sendpackages\" message is\n> > > > received by a peer after sending `fRelay==false` in their version\n> > > > message, the sender should be disconnected.\n> > > Seems better to just say \"if you set fRelay=false in your version\n> > > message, you must not send sendpackages\"? You already won't do packages\n> > > with the peer if they don't also announce sendpackages.\n> > I guess, theoretically, if you allow bloom filters with this peer, it\u2019s\n> > plausible they\u2019re saying \u201cfRelay=false, I\u2019ll send you a bloom filter\n> later,\n> > and I\u2019ll also want to talk about packages.\u201d\n>\n> I was just meaning \"it's okay to send VERSION fRelay=true then immediately\n> send WTXIDRELAY then immediately send SENDPACKAGES\" without having to\n> first verify what the other guy's fRelay was set to. On the other hand,\n> you do already have to verify the other guy's version is high enough,\n> but it would be kind-of nice to move towards just announcing the features\n> you support, and not having to make it a multistep negotiation...\n>\n> > > Maybe: \"You must not send sendpackages unless you also send\n> wtxidrelay\" ?\n> > Do you mean if we get a verack, and the peer sent \u201csendpackages\u201d but not\n> > \u201cwtxidrelay,\u201d we should disconnect them?\n>\n> Yes.\n>\n> > I have it as: we send a PCKG INV when this transaction\u2019s feerate is above\n> > the fee filter, but one or more of its parents don\u2019t. I don\u2019t think using\n> > ancestor feerate is better.\n> > See this counterexample:\n> >\n> https://raw.githubusercontent.com/glozow/bitcoin-notes/master/mempool_garden/abc_1parent_2kids.png\n> > A (0fee) has 2 kids, B (3sat/vB) and C (20sat/vB), everything\u2019s the same\n> > vsize. Let\u2019s say the fee filter is 3sat/vB.\n> > If we do it based on ancestor feerate, we won\u2019t send B. But B is actually\n> > fine; C is paying for A.\n>\n> But that only works if the receiver also has C, in which case they also\n> have A, and you don't need package relay to do anything with B? If they\n> didn't have C already, then relaying {A,B} would be a waste of time,\n> because {A,B} would be rejected as only paying 1.5sat/vB or whatever..\n>\n> If you switch it to being:\n>\n>   A (0 sats, 200vB)\n>   B (2000 sats, 200vB, spends A:0)\n>   C (200 sats, 200vB)\n>   D (1000 sats, 200vB, sepnds A:1, C:0)\n>\n> then you get:\n>\n>   A alone = 0s/vB\n>   B+A = 5s/vB\n>\n>   C alone = 1s/vB\n>   D+C+A = 2s/vB\n>   D+C = 3s/vB      (B+A already at 5s/vB)\n>\n> which I think recovers your point, while also having all the details\n> only be dealing with direct parents.\n>\n> > > Are \"getpckgtxns\" / \"pcktxns\" really limited to packages, or are they\n> > > just a general way to request a batch of transactions?\n> > > Maybe call those messages \"getbatchtxns\" and \"batchtxns\" and allow\n> them to\n> > > be used more generally, potentially in ways unrelated to packages/cpfp?\n> > Indeed, it\u2019s a general way to request a batch of transactions. I\u2019ll\n> > highlight that it is \u201call or nothing,\u201d i.e. if the sender is missing any\n> of\n> > them, they\u2019ll just send a notfound.\n> > The idea here was to avoid downloading any transactions that can\u2019t be\n> > validated right away.\n>\n> Right; maybe I should just be calling a \"batch of packages to be validated\n> together\" a \"tx package\" in the first place.\n>\n> Maybe it would be worth emphasising that you should be expecting to\n> validate all the txs you receive as a response to getpckgtxns (getpkgtxs\n> :) all at the same time, and immediately upon receiving them?\n>\n> > > The \"only be sent if both peers agreed to do package relay\" rule could\n> > > simply be dropped, I think.\n> > Wouldn\u2019t we need some way of saying \u201chey I support batchtxns?\u201d Otherwise\n> > you would have to guess by sending a request and waiting to see if it\u2019s\n> > ignored?\n>\n> Sure, perhaps I should have said leave that rule, but drop the following\n> \"should be disconnected\" rule, so that other BIPs could add in other\n> ways of negotiating the connection in future? *shrug*\n>\n> > > Shouldn't the sender only be sending package announcements when they\n> know\n> > > the recipient will be interested in the package, based on their\n> feefilter?\n> > I think there are cases where the sender doesn\u2019t necessarily know.\n> > Consider this example:\n> >\n> https://raw.githubusercontent.com/glozow/bitcoin-notes/master/mempool_garden/rich_parent_bad_cpfp.png\n> > D (5sat/vB) has 2 parents, A (0sat/vB) and B (20sat/vB). All same size.\n> > Feefilter is 3sat/vB.\n> > If the receiver already has B, they\u2019ll know they can just reject the\n> > package already based on the pckginfo.\n> > But the sender doesn\u2019t really know that. The sender just knows A is below\n> > feerate and D is above. D is above the fee filter, and its ancestor\n> feerate\n> > is above the fee filter.\n>\n> The sender would also need to know whether or not there's some other\n> child E that pays for A sufficiently?\n>\n> If you're asking for the package for \"D\", would a response telling you:\n>\n>   txid_D (500 sat, 100vB)\n>   txid_A (0 sat, 100vB)\n>   txid_B (2000 sat, 100 vB)\n>\n> be better, in that case? Then the receiver can maybe do the logic\n> themselves to figure out that they already have A in their mempool\n> so it's fine, or not?\n>\n> If you've got a package for X, and its direct parents P1..Pn, then\n> I think the logic would be:\n>\n>   * is X alone above my fee rate? no, then forget it\n>   * otherwise, s := X.size, f := X.fees, R := [X]\n>   * for P = P1..Pn:\n>     * do I already have P? then skip to the next parent\n>     * s += P.size, f += P.fees, R += [P]\n>   * if f/s above my fee rate floor? if so, request all the txs in R\n>\n> and you'd request txs if-and-only-if they're a match for you mempool rate?\n>\n> If you have a tx with 20 in-mempool parents, then the pkginfo1 message\n> as proposed would be 737 bytes; including all the fee/size info would be\n> 957 bytes, maybe a 30% increase. Might be worth it though?\n>\n> Cheers,\n> aj\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220523/c502fd7c/attachment-0001.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2022-05-24T19:48:02",
                "message_text_only": "On 23 May 2022 9:13:43 pm GMT-04:00, Gloria Zhao <gloriajzhao at gmail.com> wrote:\n>> If you're asking for the package for \"D\", would a response telling you:\n>>   txid_D (500 sat, 100vB)\n>>   txid_A (0 sat, 100vB)\n>>   txid_B (2000 sat, 100 vB)\n>> be better, in that case? Then the receiver can maybe do the logic\n>> themselves to figure out that they already have A in their mempool\n>> so it's fine, or not?\n>Right, I also considered giving the fees and sizes of each transaction in\n>the package in \u201cpckginfo1\u201d. But I don\u2019t think that information provides\n>additional meaning unless you know the exact topology, i.e. also know if\n>the parents have dependency relationships between them. For instance, in\n>the {A, B, D} package there, even if you have the information listed, your\n>decision should be different depending on whether B spends from A.\n\nI don't think that's true? We already know D is above our fee floor so if B with A is also above the floor, we want them all, but also if B isn't above the floor, but all of them combined are, then we also do?\n\nIf you've got (A,B,C,X) where B spends A and X spends A,B,C where X+C is below fee floor while A+B and A+B+C+X are above fee floor you have the problem though.\n\nIs it plausible to add the graph in?\n\nCheers,\naj\n\n\n\n-- \nSent from my phone."
            },
            {
                "author": "Gloria Zhao",
                "date": "2022-05-24T21:05:35",
                "message_text_only": "Hi aj,\n\n> If you've got (A,B,C,X) where B spends A and X spends A,B,C where X+C is\nbelow fee floor while A+B and A+B+C+X are above fee floor you have the\nproblem though.\n\nTo clarify, in this situation, I'm imagining something like\nA: 0 sat, 100vB\nB: 1500 sat, 100vB\nC: 0 sat, 100vB\nX: 500 sat, 100vB\nfeerate floor is 3sat/vB\n\nWith the algo:\n>  * is X alone above my fee rate? no, then forget it\n>  * otherwise, s := X.size, f := X.fees, R := [X]\n>  * for P = P1..Pn:\n>   * do I already have P? then skip to the next parent\n>   * s += P.size, f += P.fees, R += [P]\n>  * if f/s above my fee rate floor? if so, request all the txs in R\n\nWe'd erroneously ask for A+B+C+X, but really we should only take A+B.\nBut wouldn't A+B also be a package that was announced for B?\nPlease lmk if you were imagining something different. I think I may be\nmissing something.\n\n> Is it plausible to add the graph in?\n\nFun to think about. Most basic design would be to represent {spends,\ndoesn\u2019t spend} for a previous transaction in the package as a bit. Can\nthink of it as a matrix where row i, column j tells you whether Tx j\n(directly) spends Tx i.\nBut of course you can omit the last row, since the child spends all of\nthem. And since topological ordering is a requirement, you only need as\nmany bits as there are transactions preceding this one in the package.\nIf you have up to 24 parents, you need 1 + 2 + ... + 23 bits to codify\nspending for the 2nd ... 24th parent. For a maximum 25 transactions,\n23*24/2 = 276, seems like 36 bytes for a child-with-parents package. A few\nmore for tx-with-ancestors.\nThen you can split it up into sub-packages and everything. Still not sure\nif we really need to.\n\nAlso side note, since there are no size/count params, wondering if we\nshould just have \"version\" in \"sendpackages\" be a bit field instead of\nsending a message for each version. 32 versions should be enough right?\n\nBest,\nGloria\n\nOn Tue, 24 May 2022 at 12:48 Anthony Towns <aj at erisian.com.au> wrote:\n\n> On 23 May 2022 9:13:43 pm GMT-04:00, Gloria Zhao <gloriajzhao at gmail.com>\n> wrote:\n> >> If you're asking for the package for \"D\", would a response telling you:\n> >>   txid_D (500 sat, 100vB)\n> >>   txid_A (0 sat, 100vB)\n> >>   txid_B (2000 sat, 100 vB)\n> >> be better, in that case? Then the receiver can maybe do the logic\n> >> themselves to figure out that they already have A in their mempool\n> >> so it's fine, or not?\n> >Right, I also considered giving the fees and sizes of each transaction in\n> >the package in \u201cpckginfo1\u201d. But I don\u2019t think that information provides\n> >additional meaning unless you know the exact topology, i.e. also know if\n> >the parents have dependency relationships between them. For instance, in\n> >the {A, B, D} package there, even if you have the information listed, your\n> >decision should be different depending on whether B spends from A.\n>\n> I don't think that's true? We already know D is above our fee floor so if\n> B with A is also above the floor, we want them all, but also if B isn't\n> above the floor, but all of them combined are, then we also do?\n>\n> If you've got (A,B,C,X) where B spends A and X spends A,B,C where X+C is\n> below fee floor while A+B and A+B+C+X are above fee floor you have the\n> problem though.\n>\n> Is it plausible to add the graph in?\n>\n> Cheers,\n> aj\n>\n>\n>\n> --\n> Sent from my phone.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220524/056c9996/attachment-0001.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2022-05-24T23:43:57",
                "message_text_only": "The set of txs is the graph. Anything else would just reproduce the tx graph which must be traversed in any case.\n\nSimilarly the set of txs is the fee, the sigops, the size, and the weight. The only information required by packaging is the association of the txs with each other for the purpose of aggregate (vs. individual) net reward consideration.\n\nSince a package can only be reasonably considered for a single block, there is a natural effective limit on acceptable package size. Since any number of individual txs may be transmitted, and the size/weight/sigops of one tx is bounded only by block validity, there is no reason to put any other constraints on packages. A package is just a set of txs that may fit into a block and may collectively be worth mining. A rational package is just a block or compact block without the header. Making it any more than that is unnecessary complexity.\n\nIf parts of a package satisfy profitability constraints, they will be accepted/mined and if other parts do not, they will be rejected. There\u2019s no preventing this.\n\nThe only pertinent feature missing in the p2p protocol is the ability to associate a set of txs for consideration, where the set (or subset) may satisfy profitability constraints that would not be satisfied if the txs were considered individually.\n\ne\n\n> On May 24, 2022, at 16:21, Gloria Zhao via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> \ufeff\n> Hi aj,\n> \n> > If you've got (A,B,C,X) where B spends A and X spends A,B,C where X+C is below fee floor while A+B and A+B+C+X are above fee floor you have the problem though.\n> \n> To clarify, in this situation, I'm imagining something like\n> A: 0 sat, 100vB\n> B: 1500 sat, 100vB\n> C: 0 sat, 100vB\n> X: 500 sat, 100vB\n> feerate floor is 3sat/vB\n> \n> With the algo:\n> >  * is X alone above my fee rate? no, then forget it\n> >  * otherwise, s := X.size, f := X.fees, R := [X]\n> >  * for P = P1..Pn:\n> >   * do I already have P? then skip to the next parent\n> >   * s += P.size, f += P.fees, R += [P]\n> >  * if f/s above my fee rate floor? if so, request all the txs in R\n> \n> We'd erroneously ask for A+B+C+X, but really we should only take A+B.\n> But wouldn't A+B also be a package that was announced for B?\n> Please lmk if you were imagining something different. I think I may be missing something.\n> \n> > Is it plausible to add the graph in?\n> \n> Fun to think about. Most basic design would be to represent {spends, doesn\u2019t spend} for a previous transaction in the package as a bit. Can think of it as a matrix where row i, column j tells you whether Tx j (directly) spends Tx i.\n> But of course you can omit the last row, since the child spends all of them. And since topological ordering is a requirement, you only need as many bits as there are transactions preceding this one in the package.\n> If you have up to 24 parents, you need 1 + 2 + ... + 23 bits to codify spending for the 2nd ... 24th parent. For a maximum 25 transactions, 23*24/2 = 276, seems like 36 bytes for a child-with-parents package. A few more for tx-with-ancestors.\n> Then you can split it up into sub-packages and everything. Still not sure if we really need to.\n> \n> Also side note, since there are no size/count params, wondering if we should just have \"version\" in \"sendpackages\" be a bit field instead of sending a message for each version. 32 versions should be enough right?\n> \n> Best,\n> Gloria\n> \n>> On Tue, 24 May 2022 at 12:48 Anthony Towns <aj at erisian.com.au> wrote:\n>> On 23 May 2022 9:13:43 pm GMT-04:00, Gloria Zhao <gloriajzhao at gmail.com> wrote:\n>> >> If you're asking for the package for \"D\", would a response telling you:\n>> >>   txid_D (500 sat, 100vB)\n>> >>   txid_A (0 sat, 100vB)\n>> >>   txid_B (2000 sat, 100 vB)\n>> >> be better, in that case? Then the receiver can maybe do the logic\n>> >> themselves to figure out that they already have A in their mempool\n>> >> so it's fine, or not?\n>> >Right, I also considered giving the fees and sizes of each transaction in\n>> >the package in \u201cpckginfo1\u201d. But I don\u2019t think that information provides\n>> >additional meaning unless you know the exact topology, i.e. also know if\n>> >the parents have dependency relationships between them. For instance, in\n>> >the {A, B, D} package there, even if you have the information listed, your\n>> >decision should be different depending on whether B spends from A.\n>> \n>> I don't think that's true? We already know D is above our fee floor so if B with A is also above the floor, we want them all, but also if B isn't above the floor, but all of them combined are, then we also do?\n>> \n>> If you've got (A,B,C,X) where B spends A and X spends A,B,C where X+C is below fee floor while A+B and A+B+C+X are above fee floor you have the problem though.\n>> \n>> Is it plausible to add the graph in?\n>> \n>> Cheers,\n>> aj\n>> \n>> \n>> \n>> -- \n>> Sent from my phone.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220524/0e92938d/attachment.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2022-05-25T18:55:35",
                "message_text_only": "On 24 May 2022 5:05:35 pm GMT-04:00, Gloria Zhao via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>To clarify, in this situation, I'm imagining something like\n>A: 0 sat, 100vB\n>B: 1500 sat, 100vB\n>C: 0 sat, 100vB\n>X: 500 sat, 100vB\n>feerate floor is 3sat/vB\n>\n>With the algo:\n>>  * is X alone above my fee rate? no, then forget it\n>>  * otherwise, s := X.size, f := X.fees, R := [X]\n>>  * for P = P1..Pn:\n>>   * do I already have P? then skip to the next parent\n>>   * s += P.size, f += P.fees, R += [P]\n>>  * if f/s above my fee rate floor? if so, request all the txs in R\n>\n>We'd erroneously ask for A+B+C+X, but really we should only take A+B.\n>But wouldn't A+B also be a package that was announced for B?\n\nIn theory, yes, but maybe it was announced earlier (while our node was down?) or had dropped from our mempool or similar, either way we don't have those txs yet.\n\n>Please lmk if you were imagining something different. I think I may be\n>missing something.\n\nThat's what I was thinking, yes.\n\nSo the other thing is what happens if the peer announcing packages to us is dishonest?\n\nThey announce pkg X, say X has parents A B C and the fee rate is garbage. But actually X has parent D and the fee rate is excellent. Do we request the package from another peer, or every peer, to double check? Otherwise we're allowing the first peer we ask about a package to censor that tx from us?\n\nI think the fix for that is just to provide the fee and weight when announcing the package rather than only being asked for its info? Then if one peer makes it sound like a good deal you ask for the parent txids from them, dedupe, request, and verify they were honest about the parents.\n\n>> Is it plausible to add the graph in?\n\nLikewise, I think you'd have to have the graph info from many nodes if you're going to make decisions based on it and don't want hostile peers to be able to trick you into ignoring txs.\n\nOther idea: what if you encode the parent txs as a short hash of the wtxid (something like bip152 short ids? perhaps seeded per peer so collisions will be different per peer?) and include that in the inv announcement? Would that work to avoid a round trip almost all of the time, while still giving you enough info to save bw by deduping parents?\n\n\n> For a maximum 25 transactions,\n>23*24/2 = 276, seems like 36 bytes for a child-with-parents package.\n\nIf you're doing short ids that's maybe 25*4B=100B already, then the above is up to 36% overhead, I guess. Might be worth thinking more about, but maybe more interesting with ancestors than just parents.\n\n>Also side note, since there are no size/count params, wondering if we\n>should just have \"version\" in \"sendpackages\" be a bit field instead of\n>sending a message for each version. 32 versions should be enough right?\n\nMaybe but a couple of messages per connection doesn't really seem worth arguing about?\n\nCheers,\naj\n\n\n-- \nSent from my phone."
            },
            {
                "author": "eric at voskuil.org",
                "date": "2022-05-25T20:52:07",
                "message_text_only": "> From: bitcoin-dev <bitcoin-dev-bounces at lists.linuxfoundation.org> On\nBehalf\n> Of Anthony Towns via bitcoin-dev\n> Sent: Wednesday, May 25, 2022 11:56 AM\n\n> So the other thing is what happens if the peer announcing packages to us\nis\n> dishonest?\n> \n> They announce pkg X, say X has parents A B C and the fee rate is garbage.\nBut\n> actually X has parent D and the fee rate is excellent. Do we request the\n> package from another peer, or every peer, to double check? Otherwise we're\n> allowing the first peer we ask about a package to censor that tx from us?\n> \n> I think the fix for that is just to provide the fee and weight when\nannouncing\n> the package rather than only being asked for its info? Then if one peer\nmakes\n> it sound like a good deal you ask for the parent txids from them, dedupe,\n> request, and verify they were honest about the parents.\n\nSingle tx broadcasts do not carry an advertised fee rate, however the'\nfeefilter' message (BIP133) provides this distinction. This should be\ninterpreted as applicable to packages. Given this message there is no reason\nto send a (potentially bogus) fee rate with every package. It can only be\nvalidated by obtaining the full set of txs, and the only recourse is\ndropping (etc.) the peer, as is the case with single txs. Relying on the\nexisting message is simpler, more consistent, and more efficient.\n\n> >> Is it plausible to add the graph in?\n> \n> Likewise, I think you'd have to have the graph info from many nodes if\nyou're\n> going to make decisions based on it and don't want hostile peers to be\nable to\n> trick you into ignoring txs.\n> \n> Other idea: what if you encode the parent txs as a short hash of the wtxid\n> (something like bip152 short ids? perhaps seeded per peer so collisions\nwill\n> be different per peer?) and include that in the inv announcement? Would\n> that work to avoid a round trip almost all of the time, while still giving\nyou\n> enough info to save bw by deduping parents?\n\nAs I suggested earlier, a package is fundamentally a compact block (or\nblock) announcement without the header. Compact block (BIP152) announcement\nis already well-defined and widely implemented. A node should never be\nrequired to retain an orphan, and BIP152 ensures this is not required.\n\nOnce a validated set of txs within the package has been obtained with\nsufficient fee, a fee-optimal node would accept the largest subgraph of the\npackage that conforms to fee constraints and drop any peer that provides a\npackage for which the full graph does not.\n\nLet us not reinvent the wheel and/or introduce accidental complexity. I see\nno reason why packaging is not simply BIP152 without the 'header' field, an\nupdated protocol version, and the following sort of changes to names:\n\nsendpkg\nMSG_CMPCT_PKG\ncmpctpkg\ngetpkgtxn\npkgtxn\n\n> > For a maximum 25 transactions,\n> >23*24/2 = 276, seems like 36 bytes for a child-with-parents package.\n> \n> If you're doing short ids that's maybe 25*4B=100B already, then the above\nis\n> up to 36% overhead, I guess. Might be worth thinking more about, but maybe\n> more interesting with ancestors than just parents.\n> \n> >Also side note, since there are no size/count params,\n\nSize is restricted in the same manner as block and transaction broadcasts,\nby consensus. If the fee rate is sufficient there would be no reason to\npreclude any valid size up to what can be mined in one block (packaging\nacross blocks is not economically rational under the assumption that one\nminer cannot expect to mine multiple blocks in a row). Count is incorporated\ninto BIP152 as 'shortids_length'.\n\n> > wondering if we\n> >should just have \"version\" in \"sendpackages\" be a bit field instead of\n> >sending a message for each version. 32 versions should be enough right?\n\nAdding versioning to individual protocols is just a reflection of the\ninsufficiency of the initial protocol versioning design, and that of the\nvarious ad-hoc changes to it (including yet another approach in this\nproposal) that have been introduced to compensate for it, though I'll\naddress this in an independent post at some point.\n\nBest,\ne\n\n> Maybe but a couple of messages per connection doesn't really seem worth\n> arguing about?\n> \n> Cheers,\n> aj\n> \n> \n> --\n> Sent from my phone.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "eric at voskuil.org",
                "date": "2022-05-26T02:59:01",
                "message_text_only": "Given that packages have no header, the package requires identity in a\nBIP152 scheme. For example 'header' and 'blockhash' fields can be replaced\nwith a Merkle root (e.g. \"identity\" field) for the package, uniquely\nidentifying the partially-ordered set of txs. And use of 'getdata' (to\nobtain a package by hash) can be eliminated (not a use case).\n\ne\n\n> -----Original Message-----\n> From: eric at voskuil.org <eric at voskuil.org>\n> Sent: Wednesday, May 25, 2022 1:52 PM\n> To: 'Anthony Towns' <aj at erisian.com.au>; 'Bitcoin Protocol Discussion'\n> <bitcoin-dev at lists.linuxfoundation.org>; 'Gloria Zhao'\n> <gloriajzhao at gmail.com>\n> Subject: RE: [bitcoin-dev] Package Relay Proposal\n> \n> > From: bitcoin-dev <bitcoin-dev-bounces at lists.linuxfoundation.org> On\n> Behalf\n> > Of Anthony Towns via bitcoin-dev\n> > Sent: Wednesday, May 25, 2022 11:56 AM\n> \n> > So the other thing is what happens if the peer announcing packages to us\n> is\n> > dishonest?\n> >\n> > They announce pkg X, say X has parents A B C and the fee rate is\ngarbage.\n> But\n> > actually X has parent D and the fee rate is excellent. Do we request the\n> > package from another peer, or every peer, to double check? Otherwise\n> we're\n> > allowing the first peer we ask about a package to censor that tx from\nus?\n> >\n> > I think the fix for that is just to provide the fee and weight when\n> announcing\n> > the package rather than only being asked for its info? Then if one peer\n> makes\n> > it sound like a good deal you ask for the parent txids from them,\ndedupe,\n> > request, and verify they were honest about the parents.\n> \n> Single tx broadcasts do not carry an advertised fee rate, however the'\n> feefilter' message (BIP133) provides this distinction. This should be\n> interpreted as applicable to packages. Given this message there is no\nreason\n> to send a (potentially bogus) fee rate with every package. It can only be\n> validated by obtaining the full set of txs, and the only recourse is\n> dropping (etc.) the peer, as is the case with single txs. Relying on the\n> existing message is simpler, more consistent, and more efficient.\n> \n> > >> Is it plausible to add the graph in?\n> >\n> > Likewise, I think you'd have to have the graph info from many nodes if\n> you're\n> > going to make decisions based on it and don't want hostile peers to be\n> able to\n> > trick you into ignoring txs.\n> >\n> > Other idea: what if you encode the parent txs as a short hash of the\nwtxid\n> > (something like bip152 short ids? perhaps seeded per peer so collisions\n> will\n> > be different per peer?) and include that in the inv announcement? Would\n> > that work to avoid a round trip almost all of the time, while still\ngiving\n> you\n> > enough info to save bw by deduping parents?\n> \n> As I suggested earlier, a package is fundamentally a compact block (or\n> block) announcement without the header. Compact block (BIP152)\n> announcement\n> is already well-defined and widely implemented. A node should never be\n> required to retain an orphan, and BIP152 ensures this is not required.\n> \n> Once a validated set of txs within the package has been obtained with\n> sufficient fee, a fee-optimal node would accept the largest subgraph of\nthe\n> package that conforms to fee constraints and drop any peer that provides a\n> package for which the full graph does not.\n> \n> Let us not reinvent the wheel and/or introduce accidental complexity. I\nsee\n> no reason why packaging is not simply BIP152 without the 'header' field,\nan\n> updated protocol version, and the following sort of changes to names:\n> \n> sendpkg\n> MSG_CMPCT_PKG\n> cmpctpkg\n> getpkgtxn\n> pkgtxn\n> \n> > > For a maximum 25 transactions,\n> > >23*24/2 = 276, seems like 36 bytes for a child-with-parents package.\n> >\n> > If you're doing short ids that's maybe 25*4B=100B already, then the\nabove\n> is\n> > up to 36% overhead, I guess. Might be worth thinking more about, but\n> maybe\n> > more interesting with ancestors than just parents.\n> >\n> > >Also side note, since there are no size/count params,\n> \n> Size is restricted in the same manner as block and transaction broadcasts,\n> by consensus. If the fee rate is sufficient there would be no reason to\n> preclude any valid size up to what can be mined in one block (packaging\n> across blocks is not economically rational under the assumption that one\n> miner cannot expect to mine multiple blocks in a row). Count is\nincorporated\n> into BIP152 as 'shortids_length'.\n> \n> > > wondering if we\n> > >should just have \"version\" in \"sendpackages\" be a bit field instead of\n> > >sending a message for each version. 32 versions should be enough right?\n> \n> Adding versioning to individual protocols is just a reflection of the\n> insufficiency of the initial protocol versioning design, and that of the\n> various ad-hoc changes to it (including yet another approach in this\n> proposal) that have been introduced to compensate for it, though I'll\n> address this in an independent post at some point.\n> \n> Best,\n> e\n> \n> > Maybe but a couple of messages per connection doesn't really seem worth\n> > arguing about?\n> >\n> > Cheers,\n> > aj\n> >\n> >\n> > --\n> > Sent from my phone.\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Gloria Zhao",
                "date": "2022-05-28T01:54:13",
                "message_text_only": "Hi aj, answering slightly out of order:\n\n> what happens if the peer announcing packages to us is dishonest?\n> They announce pkg X, say X has parents A B C and the fee rate is garbage.\nBut actually X has parent D and the fee rate is excellent. Do we request\nthe package from another peer, or every peer, to double check? Otherwise\nwe're allowing the first peer we ask about a package to censor that tx from\nus?\n\nYes, providing false information shouldn't be worse than not announcing the\npackage at all, otherwise we have a censorship vector. In general, the\nrequest logic should not let one peer prevent us from requesting a similar\nannouncement from another peer.\nYes I was indeed expecting that we would ask for package info from everyone\nwho announces it until it accepts the package or has full information.\nI can see that it's a fair bit of messages (request pckginfo, oh it's low\nfee, request pckginfo from somebody else), but we also need to track\nannouncements / potentially go through the same circle to handle\n\"notfound\"s, right?\nIn normal running, the fee filter should stop a bunch of honest nodes from\ntelling us packages that are low fee.\n\n> I think the fix for that is just to provide the fee and weight when\nannouncing the package rather than only being asked for its info? Then if\none peer makes it sound like a good deal you ask for the parent txids from\nthem, dedupe, request, and verify they were honest about the parents.\n> Likewise, I think you'd have to have the graph info from many nodes if\nyou're going to make decisions based on it and don't want hostile peers to\nbe able to trick you into ignoring txs.\n\nI don't think providing more information up front can ever sufficiently\nresolve the censorship issue. If we want to prevent any one peer from being\nable to censor requests to other peers, we need to store all announcements\nand be prepared to request from everybody.\n\nWould it be better if we just took out the fee information and had\n\"pckginfo\" only consist of transaction ids? Sender tries its best to apply\nthe fee filter? Presumably you have a txInventoryKnown of your peer based\non what they've announced to you... just take the ancestor set of a\ntransaction, subtract what they already have, and apply the fee filter to\nthat? Or some kind of algorithm that ensures we don't underestimate? If\nit's imperfect, the worst case is the receiver downloads a few transactions\nand rejects them. Given that our goal is just to avoid this case, perhaps\nopting for simplicity is better than adding a topology graph\nserialization/deserialization + feerate assessment algorithm on top of this\nprotocol...?\n\n>>We'd erroneously ask for A+B+C+X, but really we should only take A+B.\n>>But wouldn't A+B also be a package that was announced for B?\n\n> In theory, yes, but maybe it was announced earlier (while our node was\ndown?) or had dropped from our mempool or similar, either way we don't have\nthose txs yet.\n\nHm. It's fine if they have Erlay, since a sender would know in advance that\nB is missing and announce it as a package. A potential tack-on solution\nwould be to request package information whenever you have a \"low fee\" error\non a parent and \"missing inputs\" on a child. Or we solve it at the\nvalidation level - instead of submitting each tx individually, we submit\neach ancestor subset. Do you think any of these is sufficient? At least the\npackage properly propagates across nodes which are online when it is\nbroadcasted...\n\nBest,\nGloria\n\nOn Wed, May 25, 2022 at 11:55 AM Anthony Towns <aj at erisian.com.au> wrote:\n\n> On 24 May 2022 5:05:35 pm GMT-04:00, Gloria Zhao via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >To clarify, in this situation, I'm imagining something like\n> >A: 0 sat, 100vB\n> >B: 1500 sat, 100vB\n> >C: 0 sat, 100vB\n> >X: 500 sat, 100vB\n> >feerate floor is 3sat/vB\n> >\n> >With the algo:\n> >>  * is X alone above my fee rate? no, then forget it\n> >>  * otherwise, s := X.size, f := X.fees, R := [X]\n> >>  * for P = P1..Pn:\n> >>   * do I already have P? then skip to the next parent\n> >>   * s += P.size, f += P.fees, R += [P]\n> >>  * if f/s above my fee rate floor? if so, request all the txs in R\n> >\n> >We'd erroneously ask for A+B+C+X, but really we should only take A+B.\n> >But wouldn't A+B also be a package that was announced for B?\n>\n> In theory, yes, but maybe it was announced earlier (while our node was\n> down?) or had dropped from our mempool or similar, either way we don't have\n> those txs yet.\n>\n> >Please lmk if you were imagining something different. I think I may be\n> >missing something.\n>\n> That's what I was thinking, yes.\n>\n> So the other thing is what happens if the peer announcing packages to us\n> is dishonest?\n>\n> They announce pkg X, say X has parents A B C and the fee rate is garbage.\n> But actually X has parent D and the fee rate is excellent. Do we request\n> the package from another peer, or every peer, to double check? Otherwise\n> we're allowing the first peer we ask about a package to censor that tx from\n> us?\n>\n> I think the fix for that is just to provide the fee and weight when\n> announcing the package rather than only being asked for its info? Then if\n> one peer makes it sound like a good deal you ask for the parent txids from\n> them, dedupe, request, and verify they were honest about the parents.\n>\n> >> Is it plausible to add the graph in?\n>\n> Likewise, I think you'd have to have the graph info from many nodes if\n> you're going to make decisions based on it and don't want hostile peers to\n> be able to trick you into ignoring txs.\n>\n> Other idea: what if you encode the parent txs as a short hash of the wtxid\n> (something like bip152 short ids? perhaps seeded per peer so collisions\n> will be different per peer?) and include that in the inv announcement?\n> Would that work to avoid a round trip almost all of the time, while still\n> giving you enough info to save bw by deduping parents?\n>\n>\n> > For a maximum 25 transactions,\n> >23*24/2 = 276, seems like 36 bytes for a child-with-parents package.\n>\n> If you're doing short ids that's maybe 25*4B=100B already, then the above\n> is up to 36% overhead, I guess. Might be worth thinking more about, but\n> maybe more interesting with ancestors than just parents.\n>\n> >Also side note, since there are no size/count params, wondering if we\n> >should just have \"version\" in \"sendpackages\" be a bit field instead of\n> >sending a message for each version. 32 versions should be enough right?\n>\n> Maybe but a couple of messages per connection doesn't really seem worth\n> arguing about?\n>\n> Cheers,\n> aj\n>\n>\n> --\n> Sent from my phone.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220527/262714e4/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Package Relay Proposal",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Eric Voskuil",
                "Anthony Towns",
                "eric at voskuil.org",
                "Gloria Zhao",
                "Greg Sanders"
            ],
            "messages_count": 14,
            "total_messages_chars_count": 155807
        }
    },
    {
        "title": "[bitcoin-dev] A Calculus of Covenants",
        "thread_messages": [
            {
                "author": "Keagan McClelland",
                "date": "2022-05-18T17:08:43",
                "message_text_only": "> One must also analyze all the covenants that one *could* author using a\nprimitive\n\nSo as I've been contemplating this more, I'm realizing that a calculus of\ncovenants themselves may not make as much sense as a broader calculus of\nBitcoin transactions as a whole. I think this comment that you made in your\nfollowup solidified that position. If you have to analyze it in the context\nof all of the other opcodes that could potentially interact with it, you\ndon't really have a closed algebra that you can really try to understand\nand evaluate. I'm still ruminating on what such a calculus would be, but it\nalso makes me more convinced that Simplicity gets a lot right here. That\nsaid, there is probably an opportunity for a significantly more domain\nspecific set of primitives than what simplicity offers that would allow you\nsimilar practical use cases but with a much more high level analysis.\n\nThe way I think about this now is that most of the primitives in the\nBitcoin script VM right now are constraints on the witness, you have a\ncouple of opcodes that are constraints on the chain state, and then\ncovenants are really a constraint on the body of the transaction that\nspends an input. I think most of the time we imagine covenants of output\nconstraints but you can also imagine a hypothetical covenant that says,\n\"this input may not be spent alongside any other inputs\". This is still a\nconstraint on the spending transaction despite the fact that it mentions\nnothing of the outputs, and I would still broadly think of this as a\ncovenant. I think depending on how you define \"family\" and \"state\ntransition\" it would tolerate this distinction. However, it definitely\ncomplicates the question of things like unrollability. Is a covenant that\npermits any output(s) but the input must be spent alone unrollable? Does\nthe concept unrollable even make any sense when you aren't constraining the\noutputs?\n\nThese thoughts aren't completely baked but I figured I'd jot them down\nwhile I was thinking about it.\n\nKeagan\n\nOn Tue, Apr 12, 2022 at 9:04 AM Jeremy Rubin via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> note of clarification:\n>\n> this is from the perspective of a developer trying to build infrastructure\n> for covenants. from the perspective of bitcoin consensus, a covenant\n> enforcing primitve would be something like OP_TLUV and less so it's use in\n> conjunction with other opcodes, e.g. OP_AMOUNT.\n>\n> One must also analyze all the covenants that one *could* author using a\n> primitive, in some sense, to demonstrate that our understanding is\n> sufficient. As a trivial example, you could use\n> OP_DELETE_BITCOIN_ENTIRELY_IF_KNOWS_PREIMAGE_TO_X_OR_TLUV and just because\n> you could use it safely for TLUV would not mean we should add that opcode\n> if there's some way of using it negatively.\n>\n> Cheers,\n>\n> Jeremy\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n>\n>\n> On Tue, Apr 12, 2022 at 10:33 AM Jeremy Rubin <jeremy.l.rubin at gmail.com>\n> wrote:\n>\n>> Sharing below a framework for thinking about covenants. It is most useful\n>> for modeling local covenants, that is, covenants where only one coin must\n>> be examined, and not multi-coin covenants whereby you could have issues\n>> with protocol forking requiring a more powerful stateful prover. It's the\n>> model I use in Sapio.\n>>\n>> I define a covenant primitive as follows:\n>>\n>> 1) A set of sets of transaction intents (a *family)*, potentially\n>> recursive or co-recursive (e.g., the types of state transitions that can be\n>> generated). These intents can also be represented by a language that\n>> generates the transactions, rather than the literal transactions\n>> themselves. We do the family rather than just sets at this level because to\n>> instantiate a covenant we must pick a member of the family to use.\n>> 2) A verifier generator function that generates a function that accepts\n>> an intent that is any element of one member of the family of intents and a\n>> proof for it and rejects others.\n>> 3) A prover generator function that generates a function that takes an\n>> intent that is any element of one member of the family and some extra data\n>> and returns either a new prover function, a finished proof, or a rejection\n>> (if not a valid intent).\n>> 4) A set of proofs that the Prover, Verifier, and a set of intents are\n>> \"impedance matched\", that is, all statements the prover can prove and all\n>> statements the verifier can verify are one-to-one and onto (or something\n>> similar), and that this also is one-to-one and onto with one element of the\n>> intents (a set of transactions) and no other.\n>> 5) A set of assumptions under which the covenant is verified (e.g., a\n>> multi-sig covenant with at least 1-n honesty, a multisig covenant with any\n>> 3-n honesty required, Sha256 collision resistance, DLog Hardness, a SGX\n>> module being correct).\n>>\n>> To instantiate a covenant, the user would pick a particular element of\n>> the set of sets of transaction intents. For example, in TLUV payment pool,\n>> it would be the set of all balance adjusting transactions and redemptions. *Note,\n>> we can 'cleave' covenants into separate bits -- e.g. one TLUV + some extra\n>> CTV paths can be 'composed', but the composition is not guaranteed to be\n>> well formed.*\n>>\n>> Once the user has a particular intent, they then must generate a verifier\n>> which can receive any member of the set of intents and accept it, and\n>> receive any transaction outside the intents and reject it.\n>>\n>> With the verifier in hand (or at the same time), the user must then\n>> generate a prover function that can make a proof for any intent that the\n>> verifier will accept. This could be modeled as a continuation system (e.g.,\n>> multisig requires multiple calls into the prover), or it could be\n>> considered to be wrapped as an all-at-once function. The prover could be\n>> done via a multi-sig in which case the assumptions are stronger, but it\n>> still should be well formed such that the signers can clearly and\n>> unambiguously sign all intents and reject all non intents, otherwise the\n>> covenant is not well formed.\n>>\n>> The proofs of validity of the first three parts and the assumptions for\n>> them should be clear, but do not require generation for use. However,\n>> covenants which do not easily permit proofs are less useful.\n>>\n>> We now can analyze three covenants under this, plain CTV, 2-3 online\n>> multisig, 3-3 presigned + deleted.\n>>\n>> CTV:\n>> 1) Intent sets: the set of specific next transactions, with unbound\n>> inputs into it that can be mutated (but once the parent is known, can be\n>> filled in for all children).\n>> 2) Verifier: The transaction has the hash of the intent\n>> 3) Prover: The transaction itself and no other work\n>> 4) Proofs of impedance: trivial.\n>> 5) Assumptions: sha256\n>> 6) Composition: Any two CTVs can be OR'd together as separate leafs\n>>\n>> 2-3 Multisig:\n>> 1) Intent: All possible sets of transactions, one set selected per\n>> instance\n>> 2) Verifier: At least 2 signed the transition\n>> 3) Prover: Receive some 'state' in the form of business logic to enforce,\n>> only sign if that is satisfied. Produce a signature.\n>> 4) Impedance: The business logic must cover the instance's Intent set and\n>> must not be able to reach any other non-intent\n>> 5) Assumptions: at least 2 parties are 'honest' for both liveness and for\n>> correctness, and the usual suspects (sha256, schnorr, etc)\n>> 6) Composition: Any two groups can be OR'd together, if the groups have\n>> different signers, then the assumptions expand\n>>\n>> 3-3 Presigned:\n>> Same as CTV except:\n>> 5) Assumptions: at least one party deletes their key after signing\n>>\n>>\n>>  You can also think through other covenants like TLUV in this model.\n>>\n>> One useful question is the 'cardinality' of an intent set. The useful\n>> notion of this is both in magnitude but also contains. Obviously, many of\n>> these are infinite sets, but if one set 'contains' another then it is\n>> definitionally more powerful. Also, if a set of transitions is 'bigger'\n>> (work to do on what that means?) than another it is potentially more\n>> powerful.\n>>\n>> Another question is around composition of different covenants inside of\n>> an intent -- e.g., a TLUV that has a branch with a CTV or vice versa. We\n>> consider this outside the model, analysis should be limited to \"with only\n>> these covenants what could you build\". Obviously, one recursive primitive\n>> makes all primitives recursive.\n>>\n>> Another question is 'unrollability'. Can the intents, and the intents of\n>> the outputs of the intents, be unrolled into a representation for a\n>> specific instantiation? Or is that set of possible transactions infinite?\n>> How infinite? CTV is, e.g., unrollable.\n>>\n>>\n>> Last note on statefulness: The above has baked into it a notion of\n>> 'statelessness', but it's very possible and probably required that provers\n>> maintain some external state in order to prove (whether multisig or not).\n>> E.g., a multisig managing an account model covenant may need to track who\n>> is owed what. This data can sometimes be put e.g. in an op return, an extra\n>> tapleaf branch, or just considered exogenous to the covenant. But the idea\n>> that a prover isn't just deciding on what to do based on purely local\n>> information to an output descriptor is important.\n>>\n>>\n>> For Sapio in particular, this framework is useful because if you can\n>> answer the above questions on intents, and prover/verifier generators, then\n>> you would be able to generate tooling that could integrate your covenant\n>> into Sapio and have things work nicely. If you can't answer these questions\n>> (in code?) then your covenant might not be 'well formed'. The efficiency of\n>> a prover or verifier is out of scope of this framework, which focuses on\n>> the engineering + design, but can also be analyzed.\n>>\n>>\n>> Grateful for any and all feedback on this model and if there are examples\n>> that cannot be described within it,\n>>\n>> Jeremy\n>>\n>>\n>>\n>>\n>> --\n>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220518/68ca4404/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "A Calculus of Covenants",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Keagan McClelland"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 10445
        }
    },
    {
        "title": "[bitcoin-dev] CTV BIP Meeting #9 Notes",
        "thread_messages": [
            {
                "author": "alicexbt",
                "date": "2022-05-19T15:57:55",
                "message_text_only": "Hi Bitcoin Developers,\n\nSummary for the last CTV meeting:\n\nTopics:\n\n1)OP_TX\n2)OP_CAT / CSFS / General Covenants\n3)Script interpreter flags\n\n===================================================\nOP_TX\n===================================================\n\nJeremy Rubin thinks that if folks believe OP_TX is a superior upgrading path, he would be delighted to shift focus. Although prefers more thorough evaluation of CTV / NOP upgradability vs the multibyte op-success.\n\nAnthony Towns doesn't find OP_TX interesting if it just does CTV from start. He prefers adding SEPARATELY, UNHASHED and maybe things to do APO equivalent behavior.\n\nHarding considers OP_TX==OP_CTV only somewhat more interesting than just OP_CTV because it provides a very clear upgrade path. He would be more interested if it came with a few more initial features.\n\n===================================================\nOP_CAT / CSFS / General Covenants\n===================================================\n\nHarding believes that concerns regarding general covenants are unfounded. He indicated an interest in learning more about one of ZmnSCPxj's criticisms, which is the only one about which he is personally concerned. It has to do with general covenants making scripts more difficult to evaluate.\n\nHarding's thoughts on CAT+CSFS:\n\n13:01 < harding> Without regard to the generalized covenants concern, I think CAT+CSFS add the smallest amount of consensus complexity to enable the greatest amount of experimentation with covenants and other features (like signature delegation), which can provide significant data about real-world usage for informing future soft fork designs. There'd still be lots of question marks, plus chances for abuse (e.g. the sort of tx spamming we saw during the block\n13:01 < harding> size debates), but I think it's worth giving devs the tools to experiment onchain (with only their and their supporters' money) and allowing economic full node operators to evualuate actual use before agreeing to enforce future soft forks whose code will need to be maintained in perpetuitity.\n13:02 < harding> Consensus stability is a reference to, for example, being able to implement something like drivechains on top of CAT+CSFS?\n\nJeremy Rubin shared some issues that are being discussed on mailing list and social media related to general bitcoin covenants:\n\n- Scripts harder to analyze\n- Fungibility\n- MEV & consensus stability\n- Whitelist/Blacklist\n\nAnthony Towns and TechMiX added that some users think covenants can be imposed on their coins without consent or everyone will accept covenants so unable to pay them. Some bitcoin users in Iran are afraid that a generalized form of the covenants would enable some kind of censorship.\n\nMEV could be one the issues associated with general covenants. There are some resources on https://mev.day if anyone interested to read more about it.\n\n13:06 <@jeremyrubin> the covenants are \"self executing\" and can be e.g. sandwiched\n13:07 <@jeremyrubin> so given that bitmatrix is sandwich attackable, you'd see similar types of MEV as Eth sees\n13:07 <@jeremyrubin> v.s. the MEV of e.g. lightning channels\n\n13:14 < _aj_> i guess i'd rather not have that sort of MEV available, because then it makes complicated MEV extraction profitable, which then makes \"smart\" miners more profitable than \"Dumb\" ones, which is maybe centralising\n\n===================================================\nScript interpreter flags\n===================================================\n\nAnthony Towns likes the idea of documenting exactly what rules the flags are meant to enforce (associated BIPs).\n\n13:54 <@jeremyrubin> The test flags infrastructure relies on some particular features of validity/invalidity and flagging, which has previously been avoided surfacing because upgrades were at the output type level. The way the flagging works is a not quite the right thing for testability and simple consensus code, it's worth re-evaluating?\n13:55 < _aj_> we changed how \"things are done\" with taproot, and need to re-evaluate how we do script enforcement in light of wanting to keep doing things that way?\n13:56 < _aj_> we don't really have to do things the way we did for taproot, but i thought it was kind-of nice, i guess\n13:56 <@jeremyrubin> Well taproot just sidestepped the issue because it was an outputtype\n13:56 < _aj_> taproot had it easy because it was an outputtype\n13:57 <@jeremyrubin> yes\n\nIRC Logs: https://gnusha.org/ctv-bip-review/2022-05-17.log\n\n/dev/fd0\n\nSent with [ProtonMail](https://protonmail.com/) secure email.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220519/c6a13a4e/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-20T01:03:11",
                "message_text_only": "Good morning fd0,\n\n\n> MEV could be one the issues associated with general covenants. There are some resources on https://mev.day if anyone interested to read more about it.\n> 13:06 <@jeremyrubin> the covenants are \"self executing\" and can be e.g. sandwiched13:07 <@jeremyrubin> so given that bitmatrix is sandwich attackable, you'd see similar types of MEV as Eth sees13:07 <@jeremyrubin> v.s. the MEV of e.g. lightning channels\n> 13:14 < _aj_> i guess i'd rather not have that sort of MEV available, because then it makes complicated MEV extraction profitable, which then makes \"smart\" miners more profitable than \"Dumb\" ones, which is maybe centralising\n\nWell that was interesting....\n\nTLDR: MEV = Miner-extractable value, basically if your contracts are complex enough, miners can analyze which of the possible contract executions are most profitable for them, and order transactions on the block they are building in such a way that it is the most profitable path that gets executed.\n(do correct me if that summary is inaccurate or incomplete)\n\nAs a concrete example: in a LN channel breach condition, the revocation transaction must be confirmed within the CSV timeout, or else the theft will be accepted and confirmed.\nNow, some software will be aware of this timeout and will continually raise the fee of the revocation transaction per block.\nA rational miner which sees a channel breach condition might prefer to not mine such a transaction, since if it is not confirmed, the software will bump up the fees and the miner could try again on the next block with the higher feerates.\nDepending on the channel size and how the software behaves exactly, the miner may be able to make a decision on whether it should or should not work on the revocation transaction and instead hold out for a later higher fee.\n\nNow, having thought of this problem for no more than 5 minutes, it seems to me, naively, that a mechanism with privacy would be helpful, i.e. the contract details should be as little-revealed as possible, to reduce the scope of miner-extractable value.\nFor instance, Taproot is good since only one branch at a time can be revealed, however, in case of a dispute, multiple competing branches of the Taproot may be revealed by the disputants, and the miners may now be able to make a choice.\n\nProbably, it is best if our covenants systems take full advantage of the linearity of Schnorr signing, in that case, if there is at all some kind of branch involved; for example, a previous transaction may reveal, if you have the proper adaptor signature, some scalar, and that scalar is actually the `s` component for a signature of a different transaction.\nWithout knowledge of the adaptor signature, and without knowledge of the link between this previous transaction and some other one, a miner cannot extract additional value by messing with the ordering the transactions get confirmed on the blockchain, or whatever.\n\nThis may mean that mechanisms that inspect the block outside of the transaction being validated (e.g. `OP_BRIBE` for drivechains, or similar mechanisms that might be capable of looking beyond the transaction) should be verboten; such cross-transaction introspection should require an adaptor signature that is kept secret by the participants from the miner that might want to manipulate the transactions to make other alternate branches more favorable to the miner.\n\nIn addition, covenant mechanisms that require large witness data are probably more vulnerable to MEV.\nFor instance, if in a dispute case, one of the disputants needs to use a large witness data while the other requires a smaller one, then the disputant with the smaller witness data would have an advantage, and can match the fee offered by the disputant with the larger witness.\nThen a fee-maximizing miner would prefer the smaller-witness branch of the contract, as they get more fees for less blockspace.\nOf course, this mechanism itself can be used if we can arrange that the disputant that is inherently \"wrong\" (i.e. went against the expected behavior of the protocol) is the one that is burdened with the larger witness.\n\nOr I could be entirely wrong and MEV is something even worse than that.\n\nHmmmmmm\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "alicexbt",
                "date": "2022-05-20T23:23:58",
                "message_text_only": "Hi ZmnSCPxj,\n\n\n> TLDR: MEV = Miner-extractable value, basically if your contracts are complex enough, miners can analyze which of the possible contract executions are most profitable for them, and order transactions on the block they are building in such a way that it is the most profitable path that gets executed.\n> (do correct me if that summary is inaccurate or incomplete)\n\nYes its elaborated as Miner Extractable Value and also referred as Maximal Extractable Value sometimes because value could be extracted by validators, sequencers and others in some chains. MEV is basically frontrunning some transactions based on mempool activity for profit. Profit could be achieved by order or include/exclude some transactions in block. Normally such opportunities are only found in complex smart contracts that allow trades being settled on-chain.\n\nIn this (IRC logs) context, Jeremy mentioned sandwich attack. An attacker looks for buy orders in mempool, buy before others and profit from selling at higher price.\n\n> Now, having thought of this problem for no more than 5 minutes, it seems to me, naively, that a mechanism with privacy would be helpful, i.e. the contract details should be as little-revealed as possible, to reduce the scope of miner-extractable value.\n\nThis makes sense and Tarun has shared similar ideas for AMMs in this pdf: https://drive.google.com/file/d/1W6PtJhGgqlNTCENE7I5pO5Brh2oqasVc/view?usp=sharing\n\n> Probably, it is best if our covenants systems take full advantage of the linearity of Schnorr signing, in that case, if there is at all some kind of branch involved; for example, a previous transaction may reveal, if you have the proper adaptor signature, some scalar, and that scalar is actually the `s` component for a signature of a different transaction.\n> Without knowledge of the adaptor signature, and without knowledge of the link between this previous transaction and some other one, a miner cannot extract additional value by messing with the ordering the transactions get confirmed on the blockchain, or whatever.\n\nI am assuming this is possible using all the bitcoin covenant proposals including CTV.\n\n> In addition, covenant mechanisms that require large witness data are probably more vulnerable to MEV.\n\nWhich covenant mechanisms require large witness data?\n\n\n/dev/fd0\n\nSent with ProtonMail secure email.\n------- Original Message -------\nOn Friday, May 20th, 2022 at 6:33 AM, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n\n> Good morning fd0,\n>\n> > MEV could be one the issues associated with general covenants. There are some resources on https://mev.day if anyone interested to read more about it.\n> > 13:06 <@jeremyrubin> the covenants are \"self executing\" and can be e.g. sandwiched13:07 <@jeremyrubin> so given that bitmatrix is sandwich attackable, you'd see similar types of MEV as Eth sees13:07 <@jeremyrubin> v.s. the MEV of e.g. lightning channels\n> > 13:14 < aj> i guess i'd rather not have that sort of MEV available, because then it makes complicated MEV extraction profitable, which then makes \"smart\" miners more profitable than \"Dumb\" ones, which is maybe centralising\n>\n>\n> Well that was interesting....\n>\n> TLDR: MEV = Miner-extractable value, basically if your contracts are complex enough, miners can analyze which of the possible contract executions are most profitable for them, and order transactions on the block they are building in such a way that it is the most profitable path that gets executed.\n> (do correct me if that summary is inaccurate or incomplete)\n>\n> As a concrete example: in a LN channel breach condition, the revocation transaction must be confirmed within the CSV timeout, or else the theft will be accepted and confirmed.\n> Now, some software will be aware of this timeout and will continually raise the fee of the revocation transaction per block.\n> A rational miner which sees a channel breach condition might prefer to not mine such a transaction, since if it is not confirmed, the software will bump up the fees and the miner could try again on the next block with the higher feerates.\n> Depending on the channel size and how the software behaves exactly, the miner may be able to make a decision on whether it should or should not work on the revocation transaction and instead hold out for a later higher fee.\n>\n> Now, having thought of this problem for no more than 5 minutes, it seems to me, naively, that a mechanism with privacy would be helpful, i.e. the contract details should be as little-revealed as possible, to reduce the scope of miner-extractable value.\n> For instance, Taproot is good since only one branch at a time can be revealed, however, in case of a dispute, multiple competing branches of the Taproot may be revealed by the disputants, and the miners may now be able to make a choice.\n>\n> Probably, it is best if our covenants systems take full advantage of the linearity of Schnorr signing, in that case, if there is at all some kind of branch involved; for example, a previous transaction may reveal, if you have the proper adaptor signature, some scalar, and that scalar is actually the `s` component for a signature of a different transaction.\n> Without knowledge of the adaptor signature, and without knowledge of the link between this previous transaction and some other one, a miner cannot extract additional value by messing with the ordering the transactions get confirmed on the blockchain, or whatever.\n>\n> This may mean that mechanisms that inspect the block outside of the transaction being validated (e.g. `OP_BRIBE` for drivechains, or similar mechanisms that might be capable of looking beyond the transaction) should be verboten; such cross-transaction introspection should require an adaptor signature that is kept secret by the participants from the miner that might want to manipulate the transactions to make other alternate branches more favorable to the miner.\n>\n> In addition, covenant mechanisms that require large witness data are probably more vulnerable to MEV.\n> For instance, if in a dispute case, one of the disputants needs to use a large witness data while the other requires a smaller one, then the disputant with the smaller witness data would have an advantage, and can match the fee offered by the disputant with the larger witness.\n> Then a fee-maximizing miner would prefer the smaller-witness branch of the contract, as they get more fees for less blockspace.\n> Of course, this mechanism itself can be used if we can arrange that the disputant that is inherently \"wrong\" (i.e. went against the expected behavior of the protocol) is the one that is burdened with the larger witness.\n>\n> Or I could be entirely wrong and MEV is something even worse than that.\n>\n> Hmmmmmm\n>\n> Regards,\n> ZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-05-20T23:47:54",
                "message_text_only": "Good morning fd0,\n\n\n> > In addition, covenant mechanisms that require large witness data are probably more vulnerable to MEV.\n>\n>\n> Which covenant mechanisms require large witness data?\n\n`OP_CSFS` + `OP_CAT`, which requires that you copy parts of the transaction into the witness data if you want to use it for covenants.\nAnd the script itself is in the witness data, and AFAIK `OP_CSFS` needs large scripts if used for covenants.\n\nArguably though `OP_CSFS` is not designed for covenants, it just *happens to enable* covenants when you throw enough data at it.\n\nIf we are going to tolerate recursive covenants, we might want an opcode that explicitly supports recursion, instead of one that happens to enable recursive covenants, because the latter is likely to require more data to be pushed on the witness stack.\nE.g. instead of the user having to quine the script (i.e. the script is really written twice, so it ends up doubling the witness size of the SCRIPT part), make an explicitly quining opcode.\n\nBasically, Do not Repeat Yourself.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Bram Cohen",
                "date": "2022-05-21T15:37:51",
                "message_text_only": "On Thu, May 19, 2022 at 9:17 AM alicexbt via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> MEV could be one the issues associated with general covenants. There are\n> some resources on https://mev.day if anyone interested to read more about\n> it.\n>\n\nOne of the top things to do about MEV is to make all transactions in a\nblock simultaneous, so for example if you have a price oracle it can be\nlimited to only reporting one price per block so although it can be\nmanipulated to either report a high or low price it can't simultaneously do\nboth. In Bitcoin ordering is strictly enforced but there's a loophole that\nthings which happen in the same transaction do happen simultaneously, so\nfuture extensions could be made to only sign things they care about and are\nokay with transactions getting aggregated just by smushing them together.\nThat of course requires a new signature opcode, because current signatures\nalways sign the whole transaction.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220521/f44e89f7/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "CTV BIP Meeting #9 Notes",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "alicexbt",
                "Bram Cohen"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 17901
        }
    },
    {
        "title": "[bitcoin-dev] MuSig2 BIP",
        "thread_messages": [
            {
                "author": "AdamISZ",
                "date": "2022-05-22T22:26:08",
                "message_text_only": "Jonas,\n\nMany thanks for getting the BIP draft out. Particularly appreciate the reference code!\n\nI have a question about identical pubkeys (including how it relates to MuSig2* optimization):\n\nWhat is the purpose of allowing this? Isn't it always the case that N equal keys combined with M non-equal keys is logically equivalent to 1+M keys? It non trivially complicates certain aspects of the algorithm to allow it and I guess I must be missing something in my previous statement because, otherwise, isn't it pointless (and pretty unwise, considering how likely it is to come from an error)? The whole 'second key' thing in MuSig2 is a sorty of icky side effect.\n\nA valid point about this is already made in the BIP and enunciated clearly and in detail: that MuSig2 is designed to discover lying at the partial sig verify stage, so it's not really that I'm saying that what's in the BIP is logically or mathematically wrong; it just seems unwise and needlessly complex. The case of 2 keys being identical does not imply an attacker; it is far more likely to be a busted implementation by counterparties where they're accidentally using P1, P1 instead of their intended P1, P2.\n\nI suppose the key word is 'needlessly' - is there a need for this that I'm overlooking?\n\nCheers,\nwaxwing/AdamISZ\n\n\nSent with ProtonMail secure email.\n------- Original Message -------\nOn Tuesday, April 5th, 2022 at 17:57, Jonas Nick via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n\n> Tim Ruffing, Elliott Jin, and I are working on a MuSig2 BIP that we would like\n> to propose to the community for discussion. The BIP is compatible with BIP340\n> public keys and signatures. It supports tweaking, which allows deriving BIP32\n> child keys from aggregate keys and creating BIP341 Taproot outputs with key and\n> script paths. You can find the BIP draft at:\n> https://github.com/jonasnick/bips/blob/musig2/bip-musig2.mediawiki\n>\n> The draft is in a state where it should be possible to write an implementation\n> based on the BIP that passes the basic test vectors (as, e.g., demonstrated by\n> [0]). The draft BIP also contains a reference implementation in python. Please\n> be aware that this is only a draft and that it may still be necessary to make\n> small tweaks to the algorithms and test vectors.\n>\n> [0] https://github.com/btcsuite/btcd/pull/1820\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Jonas Nick",
                "date": "2022-05-23T15:56:54",
                "message_text_only": "Thank you for taking the time to look at the BIP and reference code, waxwing. I\ndon't know if you're overlooking anything, so let me try to restate the\nparagraph in the BIP draft that attempts to cover this topic [0].\n\nSuppose signers would just abort in the presence of identical public keys. In\nthat case, a disruptive signer can permanently DoS-attack a session by simply\ncopying the public key of some other signer. Therefore, the BIP is much more\nuseful if it can deal with identical public keys.\n\nThe MuSig2 BIP draft requires some added complexity to handle identical public\nkeys (because of the MuSig2* optimization). But this solution naturally allows\nidentifying and removing disruptive signers, which ultimately reduces the\ncomplexity for MuSig2 users.\n\n[0] https://github.com/jonasnick/bips/blob/musig2/bip-musig2.mediawiki#public-key-aggregation"
            },
            {
                "author": "AdamISZ",
                "date": "2022-05-23T22:09:52",
                "message_text_only": "Jonas, all,:\n\nSo I do want to ask a couple further clarifying questions on this point, but I got rather majorly sidetracked :)\nI wonder can you (and other list readers!) take a look at my attempt here to summarize what is described in Footnote 2 of the draft BIP (as it's related to this discussion and also .. it's pretty interesting generally!):\n\nhttps://gist.github.com/AdamISZ/ca974ed67889cedc738c4a1f65ff620b\n\n(btw github gists have equation rendering now which is nice!)\n\nThanks,\nwaxwing/AdamISZ\n\n\n\nSent with ProtonMail secure email.\n------- Original Message -------\nOn Monday, May 23rd, 2022 at 10:56, Jonas Nick via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n\n> Thank you for taking the time to look at the BIP and reference code, waxwing. I\n> don't know if you're overlooking anything, so let me try to restate the\n> paragraph in the BIP draft that attempts to cover this topic [0].\n>\n> Suppose signers would just abort in the presence of identical public keys. In\n> that case, a disruptive signer can permanently DoS-attack a session by simply\n> copying the public key of some other signer. Therefore, the BIP is much more\n> useful if it can deal with identical public keys.\n>\n> The MuSig2 BIP draft requires some added complexity to handle identical public\n> keys (because of the MuSig2* optimization). But this solution naturally allows\n> identifying and removing disruptive signers, which ultimately reduces the\n> complexity for MuSig2 users.\n>\n> [0] https://github.com/jonasnick/bips/blob/musig2/bip-musig2.mediawiki#public-key-aggregation\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "AdamISZ",
                "date": "2022-05-24T19:06:41",
                "message_text_only": "------- Original Message -------\nOn Monday, May 23rd, 2022 at 17:09, AdamISZ via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n\n> Jonas, all,:\n>\n> So I do want to ask a couple further clarifying questions on this point, but I got rather majorly sidetracked :)\n> I wonder can you (and other list readers!) take a look at my attempt here to summarize what is described in Footnote 2 of the draft BIP (as it's related to this discussion and also .. it's pretty interesting generally!):\n>\n> https://gist.github.com/AdamISZ/ca974ed67889cedc738c4a1f65ff620b\n>\n> (btw github gists have equation rendering now which is nice!)\n>\n> Thanks,\n> waxwing/AdamISZ\n>\nJonas, list,\n\nSo given that that's basically correct (see the comments), continuing on this point of how to handle duplicate keys:\n\nIn https://github.com/jonasnick/bips/blob/musig2/bip-musig2.mediawiki#identifiying-disruptive-signers we have:\n\n\"If partial signatures are received over authenticated channels, this method can be used to identify disruptive signers and hold them accountable. Note that partial signatures are not signatures. An adversary can forge a partial signature, i.e., create a partial signature without knowing the secret key for the claimed public key.\"\n\n(the gist in the previous message was just fleshing out what's stated there and in Footnote 2: if you get a \"valid\" partial sig at index i, it doesn't mean that the signer at index i knows the key for index i, *if* they also control index j; it just means they won't be able to produce \"valid\" partial sigs for both indices i and j).\n\n(scare quotes \"valid\" - there is no notion in MuSig2 of a partial signature as a signature, only the aggregate signature in toto is valid or invalid or forged).\n\nSo we see in the above quote, that the concept of 'authenticated channels' is rather important. Consider 2 scenarios:\n1. \"Persistent\": Every signer has a persistent identity across many signing sessions, and their communications are authenticated against that identity.\n2. \"Spontaneous\": Signers join the protocol in some ad hoc way, but authenticate specifically inasmuch as they set up temporary nyms and use e.g. diffie hellman to establish a confidential and authenticated channel for the period of this signing session.\n\nAn example of \"Spontaneous\" might be: a variant of a multiparty channel construction with anonymous participants on LN or LN* in which participants set up such constructions ad hoc e.g. via liquidity markets .. in contrast, e.g. a hardware wallet multisig setup with a known provider might be a \"Persistent\" case.\n\nNot sure, but ... are we mainly talking about the \"Spontaneous\" case?\n\nBecause the \"Persistent\" case doesn't seem interesting: If I \"know\" the counterparty that I'm engaging in this protocol with, first, a Sybil at two indices is kinda weird, so the occurrence of a duplicated key from them tells me something is wrong and manual intervention is needed (or equivalently some sanity check in the meta-protocol). Often (e.g. cold storage, devices) there'd be a way to know in advance what the keys *should* be. It's very likely a bug. (I suppose you could argue waiting till the second signing round helps, because it helps us isolate the bug (except it might not, if in certain protocols, both signers have access to some shared keys, but, meh) ... but that doesn't seem convincing ... executing more of a protocol when you already know the implementation is broken seems unwise).\n\nSo, to the \"Spontaneous\" case: if we see two identical pubkeys from two pseud/anonymous counterparties, I can see the argument for waiting until partial sig sending occurs, before establishing misbehaviour. The main substance of the argument seems to be something like: we can't actually deduce adversarial behaviour at key exchange time, so we *have* to wait for the partial signature step. I'm objecting to this on two fronts:\n\n* A general principle of security should be 'abort early'. It's to me just sensibly conservative to not continue given the substantial risk of bugs (esp. in systems exposed to nonce-fragility!)\n* The claim that the protocol laid out in the BIP identifies misbehaviour seems to be at best partially correct, it cannot be true in the general case.\n\nJonas has already countered my first bullet point by stating that this abort-early (at key exchange) strategy opens up an unlimited DOS vector. My counter here is that that, because of the second bullet oint, the DOS vector remains, in the \"Spontaneous\" case, anyway; and that the only way to close it is to use either identities (switch to \"Persistent\": see e.g. Coinshuffle which registers identities via inputs), or cost.\n\n(Why does the DOS vector remain? Because of the partial sig \"validation\" issue as per my gist and Footnote2: if key 3 and key 4 are identical in a set of 5, we can wait, and then find that partial sig 3 verifies, and partial sig 4 *also* verifies, and only at index 5 do we see an 'invalid' partial sig. If the adversary (as seems extremely likely.. I can't imagine it being otherwise) has used two *different* nyms for his two adversarial indices 4 and 5, then ejecting 5 doesn't really seem to close the DOS potential? If we then restart and 'grab another anonymous nym' for the 5th index, can't it be the adversary again? And haven't we let the adversary stay, at index 4? (though I'm not sure the implications)).\n\nAnother way to look at it, I'm saying that this claim:\n\n\"In contrast, MuSig2 is designed to identify disruptive signers at signing time: any signer who prevents a signing session from completing successfully by sending incorrect contributions in the session can be identified and held accountable (see below).\"\n\nisn't *fully* correct. That is, for sure the algorithm will identify a disruptive signer who simply operates one key, but it doesn't (as current) always identify every key owned by a disruptive signer. So it doesn't close the DOS vector.\n\n(To be clear the whole 'fake partial sig' adversarial behaviour is *not* specific to having duplicate public keys; I'm just discussing whether the protocol should continue if duplicates are seen).\n\nSo overall I have the feeling that allowing duplicate keys at setup makes the implementation messier (and this protocol is complex, so that matters a bit more), and it strikes me as risky in the inevitable presence of implementation errors.\n\nCheers,\nwaxwing/AdamISZ"
            },
            {
                "author": "Jonas Nick",
                "date": "2022-05-26T15:32:33",
                "message_text_only": "Thanks for the detailed feedback. Let me try to summarize your argument: Key\naggregation should fail if there are duplicate keys because this is likely a bug\nand continuing might be dangerous. If it is not a bug but a dishonest signer\ntrying to disrupt, then resuming the protocol and trying to identify the\ndishonest signer does not work because partial signatures are not real\nsignatures.\n\nI disagree that identifying dishonest signers is useless. But if I try hard, I\ncan see your point that honest signers should not continue in order to protect\nterribly broken implementations. Broken could mean that signers reuse nonces,\noutput their secret key instead of a partial signature, etc. However, terribly\nbroken implementations are terribly broken. It seems very unlikely that they're\nnice enough to truthfully indicate their brokenness by copying someone elses\npublic key. Perhaps they use the sum of every other key, actually create a\nproper public key, or do something entirely different. So I think in practice,\nit is implausible to find a single instance of an implementation that doesn't\nsurvive partial signature creation by looking at duplicate public keys.\n\nHowever, your suggestion to abort in KeyAgg when encountering duplicate public\nkeys is compatible with the MuSig2 BIP draft. No one can force a signer to\naccept an arbitrary set of public keys for the multi-signature, so signers are\nalways fine to abort at the key aggregation stage to try to protect terribly\nbroken co-signers. In that sense, the BIP draft takes a more general and\nflexible approach. I doubt that identifying duplicate public keys is less\ncomplex. The only consequence of allowing duplicate public keys is that the\n`GetSecondKey` is required to loop over the public keys. Aborting when\nencountering duplicate public keys also has the added complexity of giving users\nthe unspecific instruction to \"debug signers X and Y\" versus \"there's something\ndefinitely wrong with signer Z\".\n\nAs mentioned above, I don't follow your argument that identifying signers\nclaiming the public key of other signers is useless. I do think the \"persistent\"\ncase is interesting. It's easy to imagine persistent identities not tied to\nsecp256k1 curve points. Only for creating BIP-340 multi-signatures do they use\nsecp256k1 public keys. These keys can be fresh, or if they are persistent, the\nparticipants may want to rotate them from time to time. So there are plenty of\nopportunities for an attacker to overtake a participant and try to disrupt the\nprotocol. You mention that duplicating keys would require \"a Sybil at two\nindices\", but actually a single malicious signer that copies some public key is\nsufficient.\n\nYour analysis of the \"spontaneous\" case misses that partial signature\nverification identifies at least one of the dishonest signers and therefore\nallows to make progress. This closes the DoS vector as far as the MuSig protocol\nis concerned. If there are multiple disruptive signers, they may not all be\nidentified in a single round but require multiple signing attempts. Of course,\napplications that use MuSig and replace disruptive signers with just some other\narbitrary nym may be so unlucky that it always has disruptive signers. But\nthat's a problem of the application layer, and it's easy to conceive smarter\npeer selection.\n\nI agree that the claim \"any signer who prevents a signing session from\ncompleting successfully by sending incorrect contributions in the session can be\nidentified\" is incorrect. We can identify at least one, and that means\napplications can make progress. I opened a PR to fix the wording [0].\n\n[0] https://github.com/jonasnick/bips/pull/25"
            },
            {
                "author": "AdamISZ",
                "date": "2022-05-26T17:34:47",
                "message_text_only": "Hi Jonas, list,\nresponses inline\n\n\n\n\nSent with Proton Mail secure email.\n------- Original Message -------\nOn Thursday, May 26th, 2022 at 10:32, Jonas Nick via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n\n> Thanks for the detailed feedback. Let me try to summarize your argument: Key\n> aggregation should fail if there are duplicate keys because this is likely a bug\n> and continuing might be dangerous. If it is not a bug but a dishonest signer\n> trying to disrupt, then resuming the protocol and trying to identify the\n> dishonest signer does not work because partial signatures are not real\n> signatures.\n>\n> I disagree that identifying dishonest signers is useless.\n\nOh but that wasn't the claim - that it's useless. I'd characterize it more like: the benefit of identifying one disruptor index is less than claimed (but PR now to fix that), and in certain (see 'spontaneous' case) does not allow a guarantee of progress (but see below .. you have convinced me that this is kind of a false conclusion to draw). That combined with the risk potential from implementation errors weighted my opinion in favour of the abort early option.\n\n\n> It seems very unlikely that they're\n> nice enough to truthfully indicate their brokenness by copying someone elses\n> public key.\n\nI don't really buy that. My thinking was, there are of course an infinite number of ways an implementation can be broken, but this is not a vanishingly unlikely case, especially when you consider how often there might be ex-protocol cooperative interactions between signers. The obvious case that crops up is when one agent actually stands behind multiple different signing keys; in that scenario it's not that unlikely, and if that agent is co-signing with *other* agents something very bad might happen.\n\n\n>\n> However, your suggestion to abort in KeyAgg when encountering duplicate public\n> keys is compatible with the MuSig2 BIP draft. No one can force a signer to\n> accept an arbitrary set of public keys for the multi-signature, so signers are\n> always fine to abort at the key aggregation stage to try to protect terribly\n> broken co-signers. In that sense, the BIP draft takes a more general and\n> flexible approach.\n\nThat's a very fair point, and good to mention. The BIP strongly justifies no abort early, though.\n\n I doubt that identifying duplicate public keys is less\n> complex. The only consequence of allowing duplicate public keys is that the\n> `GetSecondKey` is required to loop over the public keys. Aborting when\n> encountering duplicate public keys also has the added complexity of giving users\n> the unspecific instruction to \"debug signers X and Y\" versus \"there's something\n> definitely wrong with signer Z\".\n\nYeah, this is the 'we can identify the disruptor' point which has been discussed in the previous mail and below, re: spontaneous. It's true except when it, partially, isn't :)\n\n>\n> As mentioned above, I don't follow your argument that identifying signers\n> claiming the public key of other signers is useless. I do think the \"persistent\"\n> case is interesting. It's easy to imagine persistent identities not tied to\n> secp256k1 curve points. Only for creating BIP-340 multi-signatures do they use\n> secp256k1 public keys. These keys can be fresh, or if they are persistent, the\n> participants may want to rotate them from time to time. So there are plenty of\n> opportunities for an attacker to overtake a participant and try to disrupt the\n> protocol. You mention that duplicating keys would require \"a Sybil at two\n> indices\", but actually a single malicious signer that copies some public key is\n> sufficient.\n>\n> Your analysis of the \"spontaneous\" case misses that partial signature\n> verification identifies at least one of the dishonest signers and therefore\n> allows to make progress. This closes the DoS vector as far as the MuSig protocol\n> is concerned.\n\nWell but I didn't miss that point, I addressed it in the section \"Why does the DOS vector remain?\".\nI see that where we've diverged here is only that you consider the case 'the same adversary keeps joining the group' to be out of scope as something that higher level protocols would have to address.\n\nOn reflection I guess I agree: such a protocol needs to address this point, regardless of the quirk of repeated keys, and regardless of forged partial sigs; if participant 5 is a disruptor and you replace him with another, you have to have a mechanism to handle that it might be the same guy, and it's outside the scope of this doc. The fact that the disruptor may still stay at another index modulates that argument a little bit, but doesn't invalidate it, I believe.\n\nSo from that perspective, my point here was more a 'quibble' than an actual critique: because the document kind of implies that you can do a bit more than you can, and didn't let the reader know that such an attacker, in this specific case, might 'still be around' in some sense, as you agree below:\n\n>\n> I agree that the claim \"any signer who prevents a signing session from\n> completing successfully by sending incorrect contributions in the session can be\n> identified\" is incorrect. We can identify at least one, and that means\n> applications can make progress. I opened a PR to fix the wording [0].\n>\n> [0] https://github.com/jonasnick/bips/pull/25\n\nRight, thanks, will follow up.\n\nHonestly, as an implementor, I would still abort early *in most usage scenarios* ... So many more coins were lost to screw ups in implementations than super genius attackers.\n\nCheers,\nwaxwing/AdamISZ"
            }
        ],
        "thread_summary": {
            "title": "MuSig2 BIP",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "AdamISZ",
                "Jonas Nick"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 20736
        }
    },
    {
        "title": "[bitcoin-dev]  Silent Payments \u2013 Non-interactive private payments with no on-chain overhead",
        "thread_messages": [
            {
                "author": "woltx",
                "date": "2022-05-24T01:31:23",
                "message_text_only": "I created a short and simple tutorial on how to make silent payments on signet.\nhttps://gist.github.com/w0xlt/72390ded95dd797594f80baba5d2e6ee\nIn this tutorial, the user will generate an address, publish it, receive and spend coins from it and still no transactions are shown from this address in a blockchain explorer.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220524/45256620/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Silent Payments \u2013 Non-interactive private payments with no on-chain overhead",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "woltx"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 502
        }
    },
    {
        "title": "[bitcoin-dev] Silent Payments \u2013 Non-interactive private payments with no on-chain overhead",
        "thread_messages": [
            {
                "author": "alicexbt",
                "date": "2022-05-24T13:49:34",
                "message_text_only": "Hi woltx,\n\nThanks for implementing silent payments in Bitcoin Core. I tried the steps shared in tutorial and everything works as expected.\n\nI have updated the silent payment address (signet) as TXT record for domain alice.silentbitco.in\n\n$ dig -t txt alice.silentbitco.in +short\n\"tb1px3kma8e8y8z9l7e640v0x2chzrzww9cu06mqvwyrz805ffletu3s067sgh\"\n\nI have also added basic information about silent payments proposal, implementation and tutorial on https://silentbitco.in\n\nI had no issues with performance of the UTXO Set and the blocks scan. I don't mind using flag but a new address/descriptor format should be a better approach. I could not review the code in detail or test edge cases however these suggestions by Pavol Rusnak make sense: https://gist.github.com/RubenSomsen/c43b79517e7cb701ebf77eec6dbb46b8?permalink_comment_id=4177027#gistcomment-4177027\n\n/dev/fd0\n\nSent with [ProtonMail](https://protonmail.com/) secure email.\n\n------- Original Message -------\nOn Tuesday, May 24th, 2022 at 7:01 AM, woltx via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I created a short and simple tutorial on how to make silent payments on signet.\n> https://gist.github.com/w0xlt/72390ded95dd797594f80baba5d2e6ee\n> In this tutorial, the user will generate an address, publish it, receive and spend coins from it and still no transactions are shown from this address in a blockchain explorer.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220524/81d2b9ae/attachment.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2022-05-25T13:13:05",
                "message_text_only": "i like the  00 || X_spend || X_scan + mandate address reuse prevention.\n\nmight as well start with something strict\n\neasy to loosen it later - if needed - harder to tighten it later because of\nback-compatibility with addresses in-use\n\n\nOn Tue, May 24, 2022 at 11:02 AM alicexbt via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi woltx,\n>\n> Thanks for implementing silent payments in Bitcoin Core. I tried the steps\n> shared in tutorial and everything works as expected.\n>\n> I have updated the silent payment address (signet) as TXT record for\n> domain alice.silentbitco.in\n>\n> $ dig -t txt alice.silentbitco.in +short\n> \"tb1px3kma8e8y8z9l7e640v0x2chzrzww9cu06mqvwyrz805ffletu3s067sgh\"\n>\n> I have also added basic information about silent payments proposal,\n> implementation and tutorial on https://silentbitco.in\n>\n> I had no issues with performance of the UTXO Set and the blocks scan. I\n> don't mind using flag but a new address/descriptor format should be a\n> better approach. I could not review the code in detail or test edge cases\n> however these suggestions by Pavol Rusnak make sense:\n> https://gist.github.com/RubenSomsen/c43b79517e7cb701ebf77eec6dbb46b8?permalink_comment_id=4177027#gistcomment-4177027\n>\n>\n> /dev/fd0\n>\n> Sent with ProtonMail <https://protonmail.com/> secure email.\n>\n> ------- Original Message -------\n> On Tuesday, May 24th, 2022 at 7:01 AM, woltx via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> I created a short and simple tutorial on how to make silent payments on\n> signet.\n> https://gist.github.com/w0xlt/72390ded95dd797594f80baba5d2e6ee\n>\n> In this tutorial, the user will generate an address, publish it, receive\n> and spend coins from it and still no transactions are shown from this\n> address in a blockchain explorer.\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220525/a6d14e05/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Silent Payments \u2013 Non-interactive private payments with no on-chain overhead",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "alicexbt",
                "Erik Aronesty"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 3759
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Knots 23.0.knots20220529 released",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2022-05-30T13:40:18",
                "message_text_only": "Bitcoin Knots version 23.0.knots20220529 is now available from:\n\n  https://bitcoinknots.org/files/23.x/23.0.knots20220529/\n\nThis release includes new features, various bug fixes and performance\nimprovements, as well as updated translations.\n\nPlease report bugs using the issue tracker at GitHub:\n\n  https://github.com/bitcoinknots/bitcoin/issues\n\nTo receive security and update notifications, please subscribe to:\n\n  https://bitcoinknots.org/list/announcements/join/\n\nFor the full release notes and change log, see:\n\nhttps://github.com/bitcoinknots/bitcoin/blob/v23.0.knots20220529-release-notes/doc/release-notes.md\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 1528 bytes\nDesc: This is a digitally signed message part.\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220530/02496a9a/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Knots 23.0.knots20220529 released",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Luke Dashjr"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 917
        }
    }
]