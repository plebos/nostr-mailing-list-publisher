[
    {
        "title": "[bitcoin-dev] BIP sighash_noinput",
        "thread_messages": [
            {
                "author": "Gregory Maxwell",
                "date": "2018-07-02T18:11:54",
                "message_text_only": "On Mon, Apr 30, 2018 at 4:29 PM, Christian Decker via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Hi all,\n>\n> I'd like to pick up the discussion from a few months ago, and propose a new\n> sighash flag, `SIGHASH_NOINPUT`, that removes the commitment to the previous\n\nI know it seems kind of silly, but I think it's somewhat important\nthat the formal name of this flag is something like\n\"SIGHASH_REPLAY_VULNERABLE\" or likewise or at least\n\"SIGHASH_WEAK_REPLAYABLE\". This is because noinput is materially\ninsecure for traditional applications where a third party might pay to\nan address a second time, and should only be used in special protocols\nwhich make that kind of mistake unlikely.   Otherwise, I'm worried\nthat wallets might start using this sighash because it simplifies\nhandling malleability without realizing that when a third party reuses\na script pubkey, completely outside of control of the wallet that uses\nthe flag, funds will be lost as soon as a troublemaker shows up (but\nnot, sadly, in testing).  This sort of risk is magnified because the\nthird party address reuser has no way to know that this sighash flag\nhas (or will) be used with a particular scriptpubkey.\n\nSo, one could even argue that the possibility that someone might use\nthis flag means that it's generally unsafe to reuse a scriptpubkey.  I\ndon't think the same argument applies for NONE or the single-bug\nbecause they render even a single use insecure...  The best mitigation\nI can think of is defence in depth to ensure that anyone who uses this\nsighash flag understands the consequences."
            },
            {
                "author": "Rusty Russell",
                "date": "2018-07-03T04:56:53",
                "message_text_only": "Gregory Maxwell via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> writes:\n> On Mon, Apr 30, 2018 at 4:29 PM, Christian Decker via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> Hi all,\n>>\n>> I'd like to pick up the discussion from a few months ago, and propose a new\n>> sighash flag, `SIGHASH_NOINPUT`, that removes the commitment to the previous\n>\n> I know it seems kind of silly, but I think it's somewhat important\n> that the formal name of this flag is something like\n> \"SIGHASH_REPLAY_VULNERABLE\" or likewise or at least\n> \"SIGHASH_WEAK_REPLAYABLE\".\n\nI agree with the DO_NOT_WANT-style naming.  REUSE_VULNERABLE seems to\ncapture it: the word VULNERABLE should scare people away (or at least\ncause them to google further).\n\nThanks,\nRusty."
            },
            {
                "author": "Peter Todd",
                "date": "2018-07-03T05:21:00",
                "message_text_only": "On Tue, Jul 03, 2018 at 02:26:53PM +0930, Rusty Russell via bitcoin-dev wrote:\n> Gregory Maxwell via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> writes:\n> > On Mon, Apr 30, 2018 at 4:29 PM, Christian Decker via bitcoin-dev\n> > <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >> Hi all,\n> >>\n> >> I'd like to pick up the discussion from a few months ago, and propose a new\n> >> sighash flag, `SIGHASH_NOINPUT`, that removes the commitment to the previous\n> >\n> > I know it seems kind of silly, but I think it's somewhat important\n> > that the formal name of this flag is something like\n> > \"SIGHASH_REPLAY_VULNERABLE\" or likewise or at least\n> > \"SIGHASH_WEAK_REPLAYABLE\".\n> \n> I agree with the DO_NOT_WANT-style naming.  REUSE_VULNERABLE seems to\n> capture it: the word VULNERABLE should scare people away (or at least\n> cause them to google further).\n\nThe problem with that name is `SIGHASH_REUSE_VULNERABLE` tells you nothing\nabout what the flag actually does.\n\nWhat name are we going to give a future flag that does something different, but\nis also replay vulnerable?\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180703/5fb58689/attachment.sig>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-07-03T23:45:22",
                "message_text_only": "On Tue, Jul 3, 2018 at 5:21 AM, Peter Todd <pete at petertodd.org> wrote:\n> The problem with that name is `SIGHASH_REUSE_VULNERABLE` tells you nothing\n> about what the flag actually does.\n\nI believe that making the signature replayable is 1:1 with omitting\nthe identification of the specific coin being spent from it."
            },
            {
                "author": "Peter Todd",
                "date": "2018-07-09T09:41:39",
                "message_text_only": "On Tue, Jul 03, 2018 at 11:45:22PM +0000, Gregory Maxwell wrote:\n> On Tue, Jul 3, 2018 at 5:21 AM, Peter Todd <pete at petertodd.org> wrote:\n> > The problem with that name is `SIGHASH_REUSE_VULNERABLE` tells you nothing\n> > about what the flag actually does.\n> \n> I believe that making the signature replayable is 1:1 with omitting\n> the identification of the specific coin being spent from it.\n\nI think you have a good point there. But that's not the only way that reuse\ncould be a vulnerability: consider hash-based signatures.\n\nI'm happy with adding a suffix or prefix to the term SIGHASH_NOINPUT, e.g.\nSIGHASH_NOINPUT_UNSAFE to re-use Rust terminology.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180709/28ee2dde/attachment-0001.sig>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-07-03T12:05:09",
                "message_text_only": "Gregory Maxwell <greg at xiph.org> writes:\n> I know it seems kind of silly, but I think it's somewhat important\n> that the formal name of this flag is something like\n> \"SIGHASH_REPLAY_VULNERABLE\" or likewise or at least\n> \"SIGHASH_WEAK_REPLAYABLE\". This is because noinput is materially\n> insecure for traditional applications where a third party might pay to\n> an address a second time, and should only be used in special protocols\n> which make that kind of mistake unlikely.   Otherwise, I'm worried\n> that wallets might start using this sighash because it simplifies\n> handling malleability without realizing that when a third party reuses\n> a script pubkey, completely outside of control of the wallet that uses\n> the flag, funds will be lost as soon as a troublemaker shows up (but\n> not, sadly, in testing).  This sort of risk is magnified because the\n> third party address reuser has no way to know that this sighash flag\n> has (or will) be used with a particular scriptpubkey.\n\nAbsolutely agree that we should be signaling the danger of using noinput\nas clearly as possible to developers, and I'm more than happy to adopt\nthe _unsafe suffix suggested by jb55. I think using non-sighash_all\nsighashes is always a huge danger, as you have correctly pointed out, so\nmaybe we should be marking all of them as being unsafe, or make sure to\ncommunicate that danger on a higher level (docs)."
            }
        ],
        "thread_summary": {
            "title": "BIP sighash_noinput",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Gregory Maxwell",
                "Peter Todd",
                "Christian Decker"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 6470
        }
    },
    {
        "title": "[bitcoin-dev] [Lightning-dev]  BIP sighash_noinput",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2018-07-03T12:13:44",
                "message_text_only": "On Monday 02 July 2018 18:11:54 Gregory Maxwell wrote:\n> I know it seems kind of silly, but I think it's somewhat important\n> that the formal name of this flag is something like\n> \"SIGHASH_REPLAY_VULNERABLE\" or likewise or at least\n> \"SIGHASH_WEAK_REPLAYABLE\". This is because noinput is materially\n> insecure for traditional applications where a third party might pay to\n> an address a second time, and should only be used in special protocols\n> which make that kind of mistake unlikely. \n\nI don't agree. Address reuse is undefined behaviour. Nobody should assume it \nis safe or works.\n\nI intend to possibly use SIGHASH_NOINPUT for ordinary Bitcoin transactions in \na wallet I am writing, which explicitly does not support address reuse.\n\nLuke"
            },
            {
                "author": "fred savage",
                "date": "2018-07-04T18:08:43",
                "message_text_only": "you cannot specifically NOT support addrss reuse. on a blockchain where people can send you funds without your permission required to send you funds. so ALWAYS expect multiple payments to the same address\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Luke Dashjr via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: 03 July 2018 12:13:44\nTo: lightning-dev at lists.linuxfoundation.org\nCc: Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] [Lightning-dev] BIP sighash_noinput\n\nOn Monday 02 July 2018 18:11:54 Gregory Maxwell wrote:\n> I know it seems kind of silly, but I think it's somewhat important\n> that the formal name of this flag is something like\n> \"SIGHASH_REPLAY_VULNERABLE\" or likewise or at least\n> \"SIGHASH_WEAK_REPLAYABLE\". This is because noinput is materially\n> insecure for traditional applications where a third party might pay to\n> an address a second time, and should only be used in special protocols\n> which make that kind of mistake unlikely.\n\nI don't agree. Address reuse is undefined behaviour. Nobody should assume it\nis safe or works.\n\nI intend to possibly use SIGHASH_NOINPUT for ordinary Bitcoin transactions in\na wallet I am writing, which explicitly does not support address reuse.\n\nLuke\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180704/a9830de3/attachment.html>"
            },
            {
                "author": "vv01f",
                "date": "2018-07-05T08:18:44",
                "message_text_only": "You can provide a reusable payment code (BIP-47) instead of an actual address. Unfortunately that not yet supported by the clients/apps most people use. Just that would be less a hurdle than providing a service that e.g. generates addresses from xpub.\n\nAm July 4, 2018 6:08:43 PM UTC schrieb fred savage via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>:\n>you cannot specifically NOT support addrss reuse. on a blockchain where\n>people can send you funds without your permission required to send you\n>funds. so ALWAYS expect multiple payments to the same address\n\n-- \nDiese Nachricht wurde von meinem Android-Ger\u00e4t mit K-9 Mail gesendet."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-07-03T06:58:36",
                "message_text_only": "Good morning,\n\n>The problem with that name is `SIGHASH_REUSE_VULNERABLE` tells you nothing\n>about what the flag actually does.\n\nSIGHASH_NOINPUT_REUSE_VULNERABLE?\n\nSIGHASH_NOINPUT_VULNERABLE?\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180703/3b401352/attachment.html>"
            },
            {
                "author": "William Casarin",
                "date": "2018-07-03T11:54:37",
                "message_text_only": "A convention in Haskell libraries is to use an \"unsafe\" prefix to any function that may have side effects (here be dragons, etc)\n\nI'm happy with a _VULNERABLE or _UNSAFE postfix as a standard way to signal this."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-07-11T07:43:49",
                "message_text_only": "Good morning DING FENG,\n\nWhile your concern is valid, the general intent is the below:\n\n1.  We will use a scary name like SIGHASH_NOINPUT_UNSAFE to explicitly inform to wallet and Bitcoin software developers that the flag is potentially unsafe.\n2.  SIGHASH_NOINPUT_UNSAFE is intended to be used for specialty protocols like LN, CoinSwap, etc. and not for general-purpose user wallets (except for Luke Dash Jr wallet which explicitly rejects address reuse).  By default, this flag is not set and address reuse is still slightly safe for common usage, modulo other bugs in the implementation such as weak generation of random R (which are already existing concerns for SIGHASH_ALL).\n2.1.  Even for LN/CoinSwap/etc., SIGHASH_NOINPUT_UNSAFE will be used only in the exact specialty protocol, and not e.g. for general wallet usage.\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn July 11, 2018 12:37 PM, DING FENG <dingfeng12345 at gmail.com> wrote:\n\n> Hi,\n>\n> I'm a junior developer and a bitcoin user.\n> And I have read this thread carefully.\n>\n> I'm very worried about \"SIGHASH_NOINPUT\".\n>\n> Because \"SIGHASH_NOINPUT\" looks will be widely used, and it makes reuse address more dangerous.\n> Now, most donate addresses (even bitcointalk.org and bitcoin.org) used as reuse addresss, and fans continually send bitcoins to these addresses.\n> So, if user import his address (keys, seeds) to one of the \"SIGHASH_NOINPUT\" enabled Bitcoin/LN wallet and sign a Tx, this will make his donate address disabled immediately and will continue loss coins future(although the input amount is included by the SIGHASH_NOINPUT signature).\n>\n> \"SIGHASH_NONE\" only influence the current coin in the single Tx, and may be no wallet implement it.\n> \"SIGHASH_NOINPUT\" influence the whole wallet and future coins, and \"SIGHASH_NOINPUT\" intent to be widely used in Bitcoin/LN wallet.\n>\n> \"SIGHASH_NOINPUT\" look more like give away my signature right (as release my private key, I know that there is an exchange of private keys operation in LN).\n> Other SIGHASH flag just giveaway my designated coins.\n>\n> Although address reuse is not perfect safe, but it can be used and widely used in fact,\n> So, I think \"SIGHASH_NOINPUT\" may let a lot of users at risk.\n>\n> 2018-07-03 20:13 GMT+08:00 Luke Dashjr <luke at dashjr.org>:\n>\n>> On Monday 02 July 2018 18:11:54 Gregory Maxwell wrote:\n>>> I know it seems kind of silly, but I think it's somewhat important\n>>> that the formal name of this flag is something like\n>>> \"SIGHASH_REPLAY_VULNERABLE\" or likewise or at least\n>>> \"SIGHASH_WEAK_REPLAYABLE\". This is because noinput is materially\n>>> insecure for traditional applications where a third party might pay to\n>>> an address a second time, and should only be used in special protocols\n>>> which make that kind of mistake unlikely.\n>>\n>> I don't agree. Address reuse is undefined behaviour. Nobody should assume it\n>> is safe or works.\n>>\n>> I intend to possibly use SIGHASH_NOINPUT for ordinary Bitcoin transactions in\n>> a wallet I am writing, which explicitly does not support address reuse.\n>>\n>> Luke\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n> --\n>\n> Mob: +86-18667916176\n>\n> Email:dingfeng12345 at gmail.com\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180711/89cee71e/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-07-13T00:04:14",
                "message_text_only": "DING FENG <dingfeng12345 at gmail.com> writes:\n> Hi,\n>\n> I'm a junior developer and a bitcoin user.\n> And I have read this thread carefully.\n>\n> I'm very worried about \"SIGHASH_NOINPUT\".\n>\n> Because \"SIGHASH_NOINPUT\" looks will be widely used, and it makes reuse\n> address more dangerous.\n\nNo.\n\nA wallet should *never* create a SIGHASH_NOINPUT to spend its own UTXOs.\nSIGHASH_NOINPUT is useful for smart contracts which have unique\nconditions, such as a pair of peers rotating keys according to an agreed\nschedule (eg. lightning).\n\nCheers,\nRusty."
            },
            {
                "author": "fred savage",
                "date": "2018-07-13T09:50:47",
                "message_text_only": "the issues with sighash_noinput is this\n\n  1.  you cannot prevent address-reuse. because bitcoin is a PUSH payment. meaning other people can send funds to one address without the owner of the key approval/refusal. thus luke cannot control address reuse if many people start spamming him donations.\n  2.  for average users who would just 'autopilot' LN and only see the GUI. they will have no clue what transaction types and technicals are happening under the hood. also with LN being not validated by the community. a user creating a channel could tweak their own LN node to make their counterparty sign a sighash-noinput as a term/condition of the channel\nthis is also a risk for the under the hood raw tx risks where a tx can be signed but then allow the out's to alter value(using a different opcode). .. you know the premiss of allowing a counterpart to alter the outs value to vary so that they can control the broadcast fee at the time of broadcast to cover being acceptd onchain.. which can be abused by a counter party just editing it so A gets nothing and B gets it all..\n  3.  by allowing certain things to change after signing. is infact bringing back malleability for those that use a TXID to identify a tx has been confirmed. as a TXID would change if values change.. just like how malleation abused old transactions by editing a tx without needing to re-sign a tx\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Rusty Russell via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: 13 July 2018 00:04:14\nTo: DING FENG; Luke Dashjr\nCc: Bitcoin Protocol Discussion; lightning-dev at lists.linuxfoundation.org\nSubject: Re: [bitcoin-dev] [Lightning-dev] BIP sighash_noinput\n\nDING FENG <dingfeng12345 at gmail.com> writes:\n> Hi,\n>\n> I'm a junior developer and a bitcoin user.\n> And I have read this thread carefully.\n>\n> I'm very worried about \"SIGHASH_NOINPUT\".\n>\n> Because \"SIGHASH_NOINPUT\" looks will be widely used, and it makes reuse\n> address more dangerous.\n\nNo.\n\nA wallet should *never* create a SIGHASH_NOINPUT to spend its own UTXOs.\nSIGHASH_NOINPUT is useful for smart contracts which have unique\nconditions, such as a pair of peers rotating keys according to an agreed\nschedule (eg. lightning).\n\nCheers,\nRusty.\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180713/62400699/attachment.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-07-13T11:07:48",
                "message_text_only": "fred savage via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> writes:\n> the issues with sighash_noinput is this\n>\n>   1.  you cannot prevent address-reuse. because bitcoin is a PUSH\n>   payment. meaning other people can send funds to one address without\n>   the owner of the key approval/refusal. thus luke cannot control\n>   address reuse if many people start spamming him donations.\n\nThis point is pretty much moot since these are scripts, that are used in\nvery specialized contexts, and should not be shown to any\nend-user. Sure, if you go through the blockchain looking for these\naddresses, and send the exact same value to it, and create a matching\nscript then you could end up exposing those funds to this, however\nthat'd be very silly of you, and you'd have jumped through a lot of\nhoops to lose money :-)\n\n>   2.  for average users who would just 'autopilot' LN and only see the\n> GUI. they will have no clue what transaction types and technicals are\n> happening under the hood. also with LN being not validated by the\n> community. a user creating a channel could tweak their own LN node to\n> make their counterparty sign a sighash-noinput as a term/condition of\n> the channel this is also a risk for the under the hood raw tx risks\n> where a tx can be signed but then allow the out's to alter value(using\n> a different opcode). .. you know the premiss of allowing a counterpart\n> to alter the outs value to vary so that they can control the broadcast\n> fee at the time of broadcast to cover being acceptd onchain.. which\n> can be abused by a counter party just editing it so A gets nothing and\n> B gets it all..\n\nYou cannot force the counterparty to sign with a sighash-flag that they\ndon't chose themselves. We are very clear in the BIP that you should\nonly use sighash_noinput_unsafe in the context of protocols, that need\nto be designed in such a way that these issues are excluded. In\nparticular, eltoo uses a public key, provided by the signing party,\nwhich they can ensure is not reused (ensuring script\nuniqueness). Finally, wallets that are not part of LN or eltoo, won't\neven know how to sign with sighash-noinput (try signing anything but\nsighash-all on a hardware wallet for example).\n\nThe kind of editing you describe also doesn't work, since sighash-single\nis used for the late fee binding, not sighash-noinput. sighash-single\nmakes sure that the input is only valid if the matching output is still\nintact, so redirecting funds away from the desired output doesn't work.\n\n>   3.  by allowing certain things to change after signing. is infact\n>   bringing back malleability for those that use a TXID to identify a\n>   tx has been confirmed. as a TXID would change if values\n>   change.. just like how malleation abused old transactions by editing\n>   a tx without needing to re-sign a tx\n\nAgain, this is only to be used in the context of applications that\nrequire it, which also means that they know how to deal with this\nmalleability (in fact this malleability is wanted here). If you squint\nat it you can probably see that sighash-noinput is also a poor-man's\nmalleability fix, allowing you to take a transaction that is based on a\nmalleated output, and rebind it to re-establish the connection.\n\nIt seems people believe that we are advocating the use of\nsighash-noinput-unsafe in general purpose wallets and in everyday\ntransactions, this couldn't be further from the truth: sighash-noinput\nis a sharp tool, that should only be used in very specific situations,\nto enable a bit more flexibility, and it can improve the safety of\noff-chain protocols a lot, however general purpose wallets should not\neven allow signing with it.\n\nCheers,\nChristian"
            }
        ],
        "thread_summary": {
            "title": "BIP sighash_noinput",
            "categories": [
                "bitcoin-dev",
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "fred savage",
                "William Casarin",
                "vv01f",
                "ZmnSCPxj",
                "Luke Dashjr",
                "Christian Decker"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 14214
        }
    },
    {
        "title": "[bitcoin-dev] SIGHASH2 for version 1 witness programme",
        "thread_messages": [
            {
                "author": "Gregory Maxwell",
                "date": "2018-07-02T18:23:48",
                "message_text_only": "On Thu, May 31, 2018 at 6:35 PM, Johnson Lau via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> The bit 0 to 3 of hashtype denotes a value between 0 and 15:\n>\n>         \u2022 If the value is 1, the signature is invalid.\n>         \u2022 If the value is 3 or below, hashPrevouts is the hash of all input, same as defined in BIP143. Otherwise, it is 32-byte of 0x0000......0000.\n>         \u2022 If the value is 7 or below, outpoint is the COutPoint of the current input. Otherwise, it is 36-byte of 0x0000......0000.\n>         \u2022 If the value is 0, hashSequence is the hash of all sequence, same as defined in BIP143. Otherwise, it is 32-byte of 0x0000......0000.\n>         \u2022 If the value is even (including 0), nSequence is the nSequence of the current input. Otherwise, it is 0x00000000.\n>         \u2022 If the value is 6, 7, 10, 11, 14, or 15, nInputIndex is 0x00000000. Otherwise, it is the index of the current input.\n>         \u2022 If the value is 11 or below, nAmount is the value of the current input (same as BIP143). Otherwise, it is 0x0000000000000000.\n>\n> The bit 4 and 5 of hashtype denotes a value between 0 and 3:\n>\n>         \u2022 If the value is 0, hashOutputs is same as the SIGHASH_ALL case in BIP143 as a hash of all outputs.\n>         \u2022 If the value is 1, the signature is invalid.\n>         \u2022 If the value is 2, hashOutputs is same as the SIGHASH_SINGLE case in BIP143 as a hash of the matching output. If a matching output does not exist, hashOutputs is 32-byte of 0x0000......0000.\n>         \u2022 If the value is 3, hashOutputs is 32-byte of 0x0000......0000.\n> If bit 6 is set (SIGHASH2_NOFEE), nFees is 0x0000000000000000. Otherwise, it is the fee paid by the transaction.\n> If bit 7 is set (SIGHASH2_NOLOCKTIME), nLockTime is 0x00000000. Otherwise, it is the transaction nLockTime.\n>\n> If bit 8 is set (SIGHASH2_NOVERSION), nVersion is 0x00000000. Otherwise, it is the transaction nVersion.\n>\n> If bit 9 is set (SIGHASH2_NOSCRIPTCODE), scriptCode is an empty script. Otherwise, it is same as described in BIP143.\n>\n> Bits 10 to 15 are reserved and ignored, but the signature still commits to their value as hashtype.\n>\n> hashtype of 0 is also known as SIGHASH2_ALL, which covers all the available options. In this case the singnature MUST be exactly 64-byte.\n>\n> hashtype of 0x3ff is also known as SIGHASH2_NONE, which covers nothing and is effectively forfeiting the right related to this public key to anyone.\n\n\nThis seems fairly complicated and yet-- if I don't misunderstand-- it\ndoesn't capture the one special output masking case that I've seen\nactual applications want (which itself, is one out of the only two\nspecial sighash cases I've seen applications want-- the other being\nno-input).\n\nThe case I think this is missing is SIGHASH_SINGLE |\nSIGHASH_LAST_OUTPUT   e.g. \"Sign the matching output, and the last\noutput regardless of its index\". The application for this style is\n\"kickstarter\" joint-payment transactions where you wish to sign both\nyour change output (SIGHASH_SINGLE)  and the joint-payment output\n(SIGHASH_LAST_OUTPUT).  Without it, this kind of usage requires\nusually a chain of depth two for each input to split off the change.\n\nI came back around to your post at Sipa's recommendation because I was\nmusing on is there a _simple_ set of enhanced sighash flags that\ncapture real useful behaviour without falling down a rathole of\nspecifying a totally general behaviour."
            }
        ],
        "thread_summary": {
            "title": "SIGHASH2 for version 1 witness programme",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Gregory Maxwell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3407
        }
    },
    {
        "title": "[bitcoin-dev] An efficient re-implementation of Electrum Server in Rust",
        "thread_messages": [
            {
                "author": "Roman Zeyde",
                "date": "2018-07-02T20:03:01",
                "message_text_only": "Hello all,\n\nI was working on this project for the last few months, so a user could run his own Electrum server, with required hardware resources not much beyond those of a full node (using ideas from ElectrumX [1], Electrum Personal Server [2] and bitcoincore-indexd [3]).\n\nThe code and usage instructions can be found here:\nhttps://github.com/romanz/electrs\n\nThe server indexes the entire Bitcoin blockchain, and the resulting index [4] enables fast queries for any given user wallet, allowing the user to keep real-time track of his balances and his transaction history using the Electrum wallet [5].\nSince it runs on the user's own machine, there is no need for the wallet to communicate with external Electrum servers, thus preserving the privacy of the user's addresses and balances.\n\nFeatures:\n * Supports latest Electrum protocol [6].\n * Maintains an index of transaction inputs and outputs, allowing fast balance queries\n * Fast synchronization of the Bitcoin blockchain (~2.5 hours for ~185GB @ June 2018) on modest hardware [7]\n * Low CPU & memory usage (after initial indexing)\n * Low index storage overhead (~20%), relying on a local full node for transaction retrieval\n * Efficient mempool tracker allowing better fee estimation [8].\n * `-txindex` is not required for the Bitcoin node\n * Uses `rust-bitcoin` library [9] for efficient serialization/deserialization of Bitcoin transactions\n * Uses a single RocksDB [10] database, for better consistency and crash recovery\n\nHope you'll find it useful :)\nQuestions, suggestions and pull requests are welcome!\n\n[1] https://github.com/kyuupichan/electrumx\n[2] https://github.com/chris-belcher/electrum-personal-server\n[3] https://github.com/jonasschnelli/bitcoincore-indexd\n[4] https://github.com/romanz/electrs/blob/master/doc/schema.md\n[5] https://electrum.org\n[6] https://electrumx.readthedocs.io/en/latest/protocol.html\n[7] https://gist.github.com/romanz/cd9324474de0c2f121198afe3d063548\n[8] https://github.com/spesmilo/electrum/blob/59c1d03f018026ac301c4e74facfc64da8ae4708/RELEASE-NOTES#L34-L46)\n[9] https://github.com/rust-bitcoin/rust-bitcoin\n[10] https://github.com/spacejam/rust-rocksdb"
            },
            {
                "author": "Jim Posen",
                "date": "2018-07-05T21:35:39",
                "message_text_only": "This is awesome, nice work!\n\nOn Mon, Jul 2, 2018 at 4:16 PM Roman Zeyde via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hello all,\n>\n> I was working on this project for the last few months, so a user could run\n> his own Electrum server, with required hardware resources not much beyond\n> those of a full node (using ideas from ElectrumX [1], Electrum Personal\n> Server [2] and bitcoincore-indexd [3]).\n>\n> The code and usage instructions can be found here:\n> https://github.com/romanz/electrs\n>\n> The server indexes the entire Bitcoin blockchain, and the resulting index\n> [4] enables fast queries for any given user wallet, allowing the user to\n> keep real-time track of his balances and his transaction history using the\n> Electrum wallet [5].\n> Since it runs on the user's own machine, there is no need for the wallet\n> to communicate with external Electrum servers, thus preserving the privacy\n> of the user's addresses and balances.\n>\n> Features:\n>  * Supports latest Electrum protocol [6].\n>  * Maintains an index of transaction inputs and outputs, allowing fast\n> balance queries\n>  * Fast synchronization of the Bitcoin blockchain (~2.5 hours for ~185GB @\n> June 2018) on modest hardware [7]\n>  * Low CPU & memory usage (after initial indexing)\n>  * Low index storage overhead (~20%), relying on a local full node for\n> transaction retrieval\n>  * Efficient mempool tracker allowing better fee estimation [8].\n>  * `-txindex` is not required for the Bitcoin node\n>  * Uses `rust-bitcoin` library [9] for efficient\n> serialization/deserialization of Bitcoin transactions\n>  * Uses a single RocksDB [10] database, for better consistency and crash\n> recovery\n>\n> Hope you'll find it useful :)\n> Questions, suggestions and pull requests are welcome!\n>\n> [1] https://github.com/kyuupichan/electrumx\n> [2] https://github.com/chris-belcher/electrum-personal-server\n> [3] https://github.com/jonasschnelli/bitcoincore-indexd\n> [4] https://github.com/romanz/electrs/blob/master/doc/schema.md\n> [5] https://electrum.org\n> [6] https://electrumx.readthedocs.io/en/latest/protocol.html\n> [7] https://gist.github.com/romanz/cd9324474de0c2f121198afe3d063548\n> [8]\n> https://github.com/spesmilo/electrum/blob/59c1d03f018026ac301c4e74facfc64da8ae4708/RELEASE-NOTES#L34-L46\n> )\n> [9] https://github.com/rust-bitcoin/rust-bitcoin\n> [10] https://github.com/spacejam/rust-rocksdb\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180705/6c5cd00e/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "An efficient re-implementation of Electrum Server in Rust",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jim Posen",
                "Roman Zeyde"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 4909
        }
    },
    {
        "title": "[bitcoin-dev] Alert key disclosure",
        "thread_messages": [
            {
                "author": "Bryan Bishop",
                "date": "2018-07-02T23:03:13",
                "message_text_only": "The bitcoin alert keys are disclosed in this email, followed by a\ndisclosure of various known vulnerabilities in what was once the alert\nsystem. The bitcoin alert system has been completely retired. The\nnetwork is not at risk and this warning may be safely ignored if you\ndo not have an ancient node (running v0.12.x or older) using the\ndeprecated bitcoin alert system or its public keys.\n\nmainnet public key:\n04fc9702847840aaf195de8442ebecedf5b095cdbb9bc716bda9110971b28a49e0ead8564ff0db22209e0374782c093bb899692d524e9d6a6956e7c5ecbcd68284\n\nmainnet private key:\n30820113020101042053cdc1e0cfac07f7e1c312768886f4635f6bceebec0887f63a9d37a26a92e6b6a081a53081a2020101302c06072a8648ce3d0101022100fffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffc2f300604010004010704410479be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798483ada7726a3c4655da4fbfc0e1108a8fd17b448a68554199c47d08ffb10d4b8022100fffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd0364141020101a14403420004fc9702847840aaf195de8442ebecedf5b095cdbb9bc716bda9110971b28a49e0ead8564ff0db22209e0374782c093bb899692d524e9d6a6956e7c5ecbcd68284\n\ntestnet public key:\n04302390343f91cc401d56d68b123028bf52e5fca1939df127f63c6467cdf9c8e2c14b61104cf817d0b780da337893ecc4aaff1309e536162dabbdb45200ca2b0a\n\ntestnet private key:\n308201130201010420474d447aa6f46b4f45f67f21180a5de2722fc807401c4c4d95fdae64b3d6c294a081a53081a2020101302c06072a8648ce3d0101022100fffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffc2f300604010004010704410479be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798483ada7726a3c4655da4fbfc0e1108a8fd17b448a68554199c47d08ffb10d4b8022100fffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd0364141020101a14403420004302390343f91cc401d56d68b123028bf52e5fca1939df127f63c6467cdf9c8e2c14b61104cf817d0b780da337893ecc4aaff1309e536162dabbdb45200ca2b0a\n\nThese are openssl-serialized private keys.\n\nIn 2016, a plan was proposed[1] for the completion of the retirement\nof the bitcoin alert system which included the idea of revealing the\nalert system private keys. The proposal still contains good\ninformation regarding the purpose and intention of alert system\nretirement and motivation for the disclosure of the private keys.\nAdditionally, an overview of the alert system retirement and its\ntimeline is available on the web at [2]. This disclosure was recently\ndiscussed in an IRC meeting logs at [3]. A media site also recently\ndiscussed this topic[4].\n\nOne of the reasons for disclosure of the keys is to mitigate the\neffects of unknown dissemination and proliferation of the keys. By\nbroadcasting the values to make them available to everyone, the value\nof the keys is intended to be to be eliminated, since now everyone\ncould feasibly sign messages, the value of the signed messages becomes\nzero.\n\n[1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-September/013104.html\n[2] https://bitcoin.org/en/alert/2016-11-01-alert-retirement\n[3] http://www.erisian.com.au/meetbot/bitcoin-core-dev/2018/bitcoin-core-dev.2018-06-21-19.00.log.html#l-30\n[4] https://www.coindesk.com/long-secret-bitcoin-key-finally-revealed/\n\n\n# Vulnerabilities in the bitcoin alert system\n\nThe following text[5] discloses a number of known vulnerabilities in\nthe alert system. Writeup contributed by achow101.\n\n[5] https://gist.github.com/achow101/18a2dfc371c421419d494a3ae0447f66\n\nThe Alert System previously utilized by Bitcoin has several issues\n(some of which may be classified as vulnerabilities). These issues no\nlonger exist in Bitcoin as of network protocol version 700013 which\nwas released with Bitcoin Core 0.13.0. Many altcoins and Bitcoin\nclient implementations were notified of the Alert System's removal and\nhave since removed the alert system themselves or transitioned to\nusing an Alert system that does not share an Alert Key with Bitcoin.\n\nAll of the issues described below allow an attacker in possession of\nthe Alert Key to perform a Denial of Service attack on nodes that\nstill support the Alert system. These issues involve the exhaustion of\nmemory which causes node software to crash or be killed due to\nexcessive memory usage.\n\nMany of these issues were not known until the Alert System was removed\nas developers inspected the code for vulnerabilities prior to\nreleasing the Alert Key. Due to these issues, the publication of the\nAlert Key was delayed and affected altcoins and software were\nnotified.\n\nAs of this writing, less than 4% of Bitcoin nodes are vulnerable.\nFurthermore, the Bitcoin Core developers have created a \"final alert\"\nwhich is a maximum ID number alert which overrides all previous alerts\nand displays a fixed \"URGENT: Alert key compromised, upgrade required\"\nmessage on all vulnerable software. The Bitcoin Core developers\nbelieve that so few vulnerable nodes are present on the network, and\nrisks to those nodes so minor, that it is safe to publish the Alert\nKey.\n\nAn Alert contains these fields:\n\n    int32_t nVersion;\n    int64_t nRelayUntil;      // when newer nodes stop relaying to newer nodes\n    int64_t nExpiration;\n    int32_t nID;\n    int32_t nCancel;\n    std::set<int32_t> setCancel;\n    int32_t nMinVer;            // lowest version inclusive\n    int32_t nMaxVer;            // highest version inclusive\n    std::set<std::string> setSubVer;  // empty matches all\n    int32_t nPriority;\n\nAlerts are also identified by their SHA256 hash. The above fields can\nbe freely modified to generate alerts with differing hashes.\n\n# Infinitely sized map (CVE-2016-10724)\n\nThe Alert System was designed to support multiple Alerts\nsimultaneously. As such, Alerts were stored in memory in a map.\nHowever, there is no limit on how large this map can be, thus an\nattacker with the Alert Key can send a large number of Alerts to a\nnode. Eventually, the map containing all of the Alerts will be so\nlarge that the node runs out of memory and crashes, thus causing a\nDenial of Service attack.\n\nThe infinitely sized map is the basis for which the Alert system can\nbe used to cause Denial of Service attacks.\n\n# Infinitely sized alerts\n\nAlthough the infinitely sized map is what causes the crash itself, an\nattacker can also send very large Alerts. Alerts themselves are not\nlimited in size explicitly, they are only limited by the maximum\nnetwork message size. This maximum network message size has varied\nbetween versions. At times in the past, it has been 32 MB. For Bitcoin\nCore 0.12.0 (the most recent version of Bitcoin Core with the alert\nsystem enabled by default), the maximum message size is 2 MB.\n\nAlthough large Alerts do not directly cause a Denial of Service by\nthemselves, combined with the infinitely sized map, large Alerts can\nmore quickly cause a node to run out of memory.\n\n* The setCancel field has no length limit (besides the maximum message\nsize) and is a std::set of 32-bit integers. Given that it has no size\nconstraints, an attacker can use this field to create a very large\nAlert by filling the set with many integers.\n\n* The setSubVer field, like setCancel, has no length limit and is a\nstd::set. However instead of integers it has std::strings. These\nstrings do not have a length limit themselves and can thus be\narbitrarily long to produce an Alert that is arbitrarily large.\n\n* Bitcoin Core versions prior to 0.10.0 did not have a limit on the\nlength of the strComment, strStatusBar, and strReserved fields. These\nstrings can have an arbitrary length.\n\n# The final alert\n\nTo protect against attackers abusing the Alert key following its\npublication, the Bitcoin Core developers constructed a \"final alert\".\nThis final alert is a maximum ID alert which overrides all previous\nalerts. All Bitcoin Core versions since and including Bitcoin Core\n0.14.0 contain the final alert and will send it to any node which is\nvulnerable to issues including the following disclosures. However this\nprotection is not enough to protect those nodes as a few issues were\nfound with the final alert implementation itself.\n\nFinal alerts are those which meet the following conditions:\n\n    nExpiration == maxInt &&\n    nCancel == (maxInt-1) &&\n    nMinVer == 0 &&\n    nMaxVer == maxInt &&\n    setSubVer.empty() &&\n    nPriority == maxInt &&\n    strStatusBar == \"URGENT: Alert key compromised, upgrade required\"\n\nmaxInt is the maximum signed integer as defined by\nstd::numeric_limits<int>::max().\n\n# Multiple final alerts\n\nThe definition for a final alert does not include a few fields.\nBecause alerts are identified by their hashes, changing the omitted\nfields allows an Alert to be classified as a final alert but still be\nan alert that is added to the infinitely sized map. The nCancel field\nomits the maxInt ID number used by the final alert so all of the final\nalerts share the same ID.\n\n* Since setCancel is not required to be empty for an alert to be a\nfinal alert, the setCancel field can contain different integers to\nproduce alerts that have different hashes and are thus different\nalerts. Combined with the infinitely sized map and the infinitely\nsized setCancel issues, many final alerts can be created which are\nlarge, fill the map, and cause a node to run out of memory.\n\n* The strComment field, while having a maximum length of 65536 bytes\n(and no maximum length prior to Bitcoin Core version 0.10.0), is not\nrequired to be a particular string in order for an alert to be a final\nalert. Thus multiple final alerts can be crafted which have different\nhashes by using different values for strComment\n\n* The strReserved field, while having a maximum length of 256 bytes,\nis not required to be a particular string in order for an alert to be\na final alert. Thus multiple final alerts can be crafted which have\ndifferent hashes by using different values for strReserved.\n\n* The nVersion field is also not required to be a particular value.\nThus this can be used to construct final alerts with different hashes\nby having different values for nVersion.\n\n* nRelayUntil field is also not required to be a particular value.\nThus this can be used to construct final alerts with different hashes\nby having different values for nRelayUntil.\n\n# Final Alert Cancellation (CVE-2016-10725)\n\nAlthough the final alert is supposed to be uncancellable, it\nunfortunately is cancellable due to the order of actions when\nprocessing an alert. Alerts are first processed by checking whether\nthey cancel any existing alert. Then they are checked whether any of\nthe remaining alerts cancels it. Because of this order, it is possible\nto create an alert which cancels a final alert before the node checks\nwhether that alert is canceled by the final alert. Thus an attacker\ncan cancel a final alert with another alert allowing a node to be\nvulnerable to all of the aforementioned attacks.\n\n# Protecting against DoS attacks from the alert system\n\nFixing these issues is relatively easy. The first and most obvious\nsolution is to simply remove the Alert system entirely. As nodes\nupgrade to versions without the Alert system, fewer nodes will be\nvulnerable to attack should the Alert keys become public. This is the\noption that Bitcoin has taken. However, because Bitcoin has retired\nthe Alert system entirely, the Alert key will also be published to\nreduce the risk that the Alert Key is mistakenly depended upon in the\nfuture.\nShould altcoins wish to continue using the Alert system but with a\ndifferent Alert Key, a few very simple fixes will safeguard nodes from\nthe aforementioned issues. Limiting the number of alerts, the size of\nsetCancel and setSubVer, and only allowing one final alert altogether\nfix the above issues. This patch[6], on top of Bitcoin Core 0.11 (a\nvulnerable version), fixes the aforementioned issues. Altcoins that\nstill use the Alert system are recommended to port this patch to their\nsoftware. Outdated node software is still vulnerable.\n\n[6] https://gist.github.com/achow101/02d03238090691558a68010a9ccbbf9d\n\nThis disclosure was authored primarily by Bryan Bishop (kanzure) and\nAndrew Chow (achow101). Special thanks to reviewers. Also, an\ninteresting proposal was floated to not disclose the private keys in\nWIF format-- one is that this is not how the original values were\nreceived, and second (more importantly) to prevent users from\nimporting the key into their wallet and reusing it in their wallet key\ncirculation.\n\n- Bryan\nhttp://heybryan.org/\n1 512 203 0507"
            }
        ],
        "thread_summary": {
            "title": "Alert key disclosure",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Bryan Bishop"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 12313
        }
    },
    {
        "title": "[bitcoin-dev] BIP 174 thoughts",
        "thread_messages": [
            {
                "author": "matejcik",
                "date": "2018-07-04T13:19:11",
                "message_text_only": "hello,\n\nwe still have some concerns about the BIP as currently proposed - not\nabout the format or data contents, but more about strictness and\nsecurity properties. I have raised some in the previous e-mails, but\nthey might have been lost in the overall talk about format.\n\n* Choosing from duplicate keys when combining.\nWe believe that \"choose whichever value it wishes\" is not a good\nresolution strategy. We propose to either change this to \"in case of\nconflicts, software MUST reject the conflicting PSBTs\", or explain in\nmore detail why picking at random is a safe choice.\n\n* Signing records with unknown keys.\nThere's been some talk about this at start, but there should be a clear\nstrategy for Signers when unknown fields are encountered. We intend to\nimplement the rule: \"will not sign an input with any unknown fields\npresent\".\nMaybe it is worth codifying this behavior in the standard, or maybe\nthere should be a way to mark a field as \"optional\" so that strict\nSigners know they can _safely_ ignore the unknown field.\n\n\nAnd two minor points:\n\n* Fields with empty keys.\nThis might be inferred from the definition, but is probably worth\nspelling out explicitly: If a field definition states that the key data\nis empty, an implementation MUST enforce this and reject PSBTs that\ncontain non-empty data.\nWe suggest adding something to the effect of:\n\"If a key or value data in a field doesn't match the specified format,\nthe PSBT is invalid. In particular, if key data is specified as \"none\"\nbut the key contains data beyond the type specifier, implementation MUST\nreject the PSBT.\"\n(not sure about the languge, this should of course allow processing\nunknown fields)\n\n* \"Combiner can detect inconsistencies\"\nAdded in response to this comment [1], the current wording looks like\nit's describing what the Combiner is _capable of_, as opposed to\nprescribing what the combiner is _allowed to_ do.\nWe suggest changing to something like:\n\"For every field type that the Combiner understands, it MAY also refuse\nto combine PSBTs that have inconsistencies in that field, or cause a\nconflict when combined.\"\n\nregards\nm.\n\n[1] https://github.com/bitcoin/bips/pull/694#discussion_r199232318\n\nOn 29.6.2018 21:12, Achow101 wrote:\n> Hi,\n> \n> I do not think that protobuf is the way to go for this. Not only is it another dependency\n> which many wallets do not want to add (e.g. Armory has not added BIP 70 support because\n> of its dependency on protobuf), but it is a more drastic change than the currently proposed\n> changes. The point of this email thread isn't to rewrite and design a new BIP (which is effectively\n> what is currently going on). The point is to modify and improve the current one. In particular,\n> we do not want such drastic changes that people who have already implemented the current\n> BIP would have to effectively rewrite everything from scratch again.\n> \n> I believe that this discussion has become bikeshedding and is really no longer constructive. Neither\n> of us are going to convince the other to use or not use protobuf. ASeeing how no one else\n> has really participated in this discussion about protobuf and key uniqueness, I do not think\n> that these suggested changes are really necessary nor useful to others. It boils down to personal preference\n> rather than technical merit. As such, I have opened a PR to the BIPs repo (https://github.com/bitcoin/bips/pull/694)\n> which contains the changes that I proposed in an earlier email.\n> \n> Additionally, because there have been no objections to the currently proposed changes, I propose\n> to move the BIP from Draft to Proposed status.\n> \n> Andrew\n> \n> \n> \u200b\u200b\n> \n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> \n> On June 29, 2018 2:53 AM, matejcik via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n>> \u200b\u200b\n>>\n>> Short version:\n>>\n>> -   I propose that conflicting \"values\" for the same \"key\" are considered\n>>     \n>>     invalid.\n>>     \n>> -   Let's not optimize for invalid data.\n>> -   Given that, there's an open question on how to handle invalid data\n>>     \n>>     when encountered\n>>     \n>>     In general, I don't think it's possible to enforce correctness at the\n>>     \n>>     format level. You still need application level checks - and that calls\n>>     \n>>     into question what we gain by trying to do this on the format level.\n>>     \n>>     Long version:\n>>     \n>>     Let's look at this from a different angle.\n>>     \n>>     There are roughly two possible \"modes\" for the format with regard to\n>>     \n>>     possibly-conflicting data. Call them \"permissive\" and \"restrictive\".\n>>     \n>>     The spec says:\n>>     \n>>     \"\"\"\n>>     \n>>     Keys within each scope should never be duplicated; all keys in the\n>>     \n>>     format are unique. PSBTs containing duplicate keys are invalid. However\n>>     \n>>     implementors will still need to handle events where keys are duplicated\n>>     \n>>     when combining transactions with duplicated fields. In this event, the\n>>     \n>>     software may choose whichever value it wishes.\n>>     \n>>     \"\"\"\n>>     \n>>     The last sentence of this paragraph sets the mode to permissive:\n>>     \n>>     duplicate values are pretty much OK. If you see them, just pick one.\n>>     \n>>     You seem to argue that Combiners, in particular simple ones that don't\n>>     \n>>     understand field semantics, should merge keys permissively, but\n>>     \n>>     deduplicate values restrictively.\n>>     \n>>     IOW: if you receive two different values for the same key, just pick\n>>     \n>>     whichever, but $deity forbid you include both!\n>>     \n>>     This choice doesn't make sense to me.\n>>     \n>>     What would make sense is fully restrictive mode: receiving two\n>>     \n>>     different values for the same key is a fatal condition with no recovery.\n>>     \n>>     If you have a non-deterministic scheme, put a differentiator in the key.\n>>     \n>>     Or all the data, for that matter.\n>>     \n>>     (Incidentally, this puts key-aware and keyless Combiners on the same\n>>     \n>>     footing. As long as all participants uphold the protocol, different\n>>     \n>>     value = different key = different full record.)\n>>     \n>>     Given that, it's nice to have the Combiner perform the task of detecting\n>>     \n>>     this and failing. But not at all necessary. As the quoted paragraph\n>>     \n>>     correctly notes, consumers still need to handle PSBTs with duplicate keys.\n>>     \n>>     (In this context, your implied permissive/restrictive Combiner is\n>>     \n>>     optimized for dealing with invalid data. That seems like a wrong\n>>     \n>>     optimization.)\n>>     \n>>     A reasonable point to decide is whether the handling at the consumer\n>>     \n>>     should be permissive or restrictive. Personally I'm OK with either. I'd\n>>     \n>>     go with the following change:\n>>     \n>>     \"\"\"\n>>     \n>>     In this event, the software MAY reject the transaction as invalid. If it\n>>     \n>>     decides to accept it, it MUST choose the last value encountered.\n>>     \n>>     \"\"\"\n>>     \n>>     (deterministic way of choosing, instead of \"whichever you like\")\n>>     \n>>     We could also drop the first part, explicitly allowing consumers to\n>>     \n>>     pick, and simplifying the Combiner algorithm to `sort -u`.\n>>     \n>>     Note that this sort of \"picking\" will probably be implicit. I'd expect\n>>     \n>>     the consumer to look like this:\n>>     \n>>\n>>     for key, value in parse(nextRecord()):\n>>       data[key] = value\n>>     \n>>\n>> Or we could drop the second part and switch MAY to MUST, for a fully\n>>\n>> restrictive mode - which, funnily enough, still lets the Combiner work\n>>\n>> as `sort -u`.\n>>\n>> To see why, remember that distinct values for the same key are not\n>>\n>> allowed in fully restrictive mode. If a Combiner encounters two\n>>\n>> conflicting values F(1) and F(2), it should fail -- but if it doesn't,\n>>\n>> it includes both and the same failure WILL happen on the fully\n>>\n>> restrictive consumer.\n>>\n>> This was (or is) my point of confusion re Combiners: the permissive key\n>>\n>> -   restrictive value mode of operation doesn't seem to help subsequent\n>>     \n>>     consumers in any way.\n>>     \n>>     Now, for the fully restrictive consumer, the key-value model is indeed\n>>     \n>>     advantageous (and this is the only scenario that I can imagine in which\n>>     \n>>     it is advantageous), because you can catch key duplication on the parser\n>>     \n>>     level.\n>>     \n>>     But as it turns out, it's not enough. Consider the following records:\n>>     \n>>     key(<PSBT_IN_REDEEM_SCRIPT> + abcde), value(<some redeem script>)\n>>     \n>>\n>> and:\n>>\n>> key(<PSBT_IN_REDEEM_SCRIPT> + fghij), value(<some other redeem script>)\n>>\n>> A purely syntactic Combiner simply can't handle this case. The\n>>\n>> restrictive consumer needs to know whether the key is supposed to be\n>>\n>> repeating or not.\n>>\n>> We could fix this, e.g., by saying that repeating types must have high\n>>\n>> bit set and non-repeating must not. We also don't have to, because the\n>>\n>> worst failure here is that a consumer passes an invalid record to a\n>>\n>> subsequent one and the failure happens one step later.\n>>\n>> At this point it seems weird to be concerned about the \"unique key\"\n>>\n>> correctness, which is a very small subset of possibly invalid inputs. As\n>>\n>> a strict safety measure, I'd instead propose that a consumer MUST NOT\n>>\n>> operate on inputs or outputs, unless it understand ALL included fields -\n>>\n>> IOW, if you're signing a particular input, all fields in said input are\n>>\n>> mandatory. This prevents a situation where a simple Signer processes an\n>>\n>> input incorrectly based on incomplete set of fields, while still\n>>\n>> allowing Signers with different capabilities within the same PSBT.\n>>\n>> (The question here is whether to have either a flag or a reserved range\n>>\n>> for \"optional fields\" that can be safely ignored by consumers that don't\n>>\n>> understand them, but provide data for consumers who do.)\n>>\n>>>> To repeat and restate my central question: Why is it important,\n>>>>\n>>>> that an agent which doesn't understand a particular field\n>>>>\n>>>> structure, can nevertheless make decisions about its inclusion or\n>>>>\n>>>> omission from the result (based on a repeated prefix)?\n>>>\n>>> Again, because otherwise you may need a separate Combiner for each\n>>>\n>>> type of script involved. That would be unfortunate, and is very\n>>>\n>>> easily avoided.\n>>\n>> This is still confusing to me, and I would really like to get to the\n>>\n>> same page on this particular thing, because a lot of the debate hinges\n>>\n>> on it. I think I covered most of it above, but there are still pieces to\n>>\n>> clarify.\n>>\n>> As I understand it, the Combiner role (actually all the roles) is mostly\n>>\n>> an algorithm, with the implication that it can be performed\n>>\n>> independently by a separate agent, say a network node.\n>>\n>> So there's two types of Combiners:\n>>\n>> a) Combiner as a part of an intelligent consumer -- the usual scenario\n>>\n>> is a Creator/Combiner/Finalizer/Extractor being one participant, and\n>>\n>> Updater/Signers as other participants.\n>>\n>> In this case, the discussion of \"simple Combiners\" is actually talking\n>>\n>> about intelligent Combiners which don't understand new fields and must\n>>\n>> correctly pass them on. I argue that this can safely be done without\n>>\n>> loss of any important properties.\n>>\n>> b) Combiner as a separate service, with no understanding of semantics.\n>>\n>> Although parts of the debate seem to assume this scenario, I don't think\n>>\n>> it's worth considering. Again, do you have an usecase in mind for it?\n>>\n>> You also insist on enforcing a limited form of correctness on the\n>>\n>> Combiner level, but that is not worth it IMHO, as discussed above.\n>>\n>> Or am I missing something else?\n>>\n>>> Perhaps you want to avoid signing with keys that are already signed\n>>>\n>>> with? If you need to derive all the keys before even knowing what\n>>>\n>>> was already signed with, you've already performed 80% of the work.\n>>\n>> This wouldn't concern me at all, honestly. If the user sends an already\n>>\n>> signed PSBT to the same signer, IMHO it is OK to sign again; the\n>>\n>> slowdown is a fault of the user/workflow. You could argue that signing\n>>\n>> again is the valid response. Perhaps the Signer should even \"consume\"\n>>\n>> its keys and not pass them on after producing a signature? That seems\n>>\n>> like a sensible rule.\n>>\n>>> To your point: proto v2 afaik has no way to declare \"whole record\n>>>\n>>> uniqueness\", so either you drop that (which I think is unacceptable\n>>>\n>>> -   see the copy/sign/combine argument above), or you deal with it in\n>>>     \n>>>     your application code.\n>>>     \n>>\n>> Yes. My argument is that \"whole record uniqueness\" isn't in fact an\n>>\n>> important property, because you need application-level checks anyway.\n>>\n>> Additionally, protobuf provides awareness of which fields are repeated\n>>\n>> and which aren't, and implicitly implements the \"pick last\" resolution\n>>\n>> strategy for duplicates.\n>>\n>> The simplest possible protobuf-based Combiner will:\n>>\n>> -   assume all fields are repeating\n>> -   concatenate and parse\n>> -   deduplicate and reserialize.\n>>     \n>>     More knowledgeable Combiner will intelligently handle non-repeating\n>>     \n>>     fields, but still has to assume that unknown fields are repeating and\n>>     \n>>     use the above algorithm.\n>>     \n>>     For \"pick last\" strategy, a consumer can simply parse the message and\n>>     \n>>     perform appropriate application-level checks.\n>>     \n>>     For \"hard-fail\" strategy, it must parse all fields as repeating and\n>>     \n>>     check that there's only one of those that are supposed to be unique.\n>>     \n>>     This is admittedly more work, and yes, protobuf is not perfectly suited\n>>     \n>>     for this task.\n>>     \n>>     But:\n>>     \n>>     One, this work must be done by hand anyway, if we go with a custom\n>>     \n>>     hand-parsed format. There is a protobuf implementation for every\n>>     \n>>     conceivable platform, we'll never have the same amount of BIP174 parsing\n>>     \n>>     code.\n>>     \n>>     (And if you're hand-writing a parser in order to avoid the dependency,\n>>     \n>>     you can modify it to do the checks at parser level. Note that this is\n>>     \n>>     not breaking the format! The modifed parser will consume well-formed\n>>     \n>>     protobuf and reject that which is valid protobuf but invalid bip174 - a\n>>     \n>>     correct behavior for a bip174 parser.)\n>>     \n>>     Two, it is my opinion that this is worth it in order to have a standard,\n>>     \n>>     well described, well studied and widely implemented format.\n>>     \n>>     Aside: I ha that there is no advantage to a record-set based\n>>     \n>>     custom format by itself, so IMHO the choice is between protobuf vs\n>>     \n>>     a custom key-value format. Additionally, it's even possible to implement\n>>     \n>>     a hand-parsable key-value format in terms of protobuf -- again, arguing\n>>     \n>>     that \"standardness\" of protobuf is valuable in itself.\n>>     \n>>     regards\n>>     \n>>     m.\n>>     \n>>\n>> bitcoin-dev mailing list\n>>\n>> bitcoin-dev at lists.linuxfoundation.org\n>>\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n> \n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 819 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180704/20cc4baa/attachment-0001.sig>"
            },
            {
                "author": "Achow101",
                "date": "2018-07-04T18:35:16",
                "message_text_only": "Hi,\u200b\n\n\nOn July 4, 2018 6:19 AM, matejcik <jan.matejek at satoshilabs.com> wrote:\n\n> \u200b\u200b\n> \n> hello,\n> \n> we still have some concerns about the BIP as currently proposed - not\n> \n> about the format or data contents, but more about strictness and\n> \n> security properties. I have raised some in the previous e-mails, but\n> \n> they might have been lost in the overall talk about format.\n> \n> -   Choosing from duplicate keys when combining.\n>     \n>     We believe that \"choose whichever value it wishes\" is not a good\n>     \n>     resolution strategy. We propose to either change this to \"in case of\n>     \n>     conflicts, software MUST reject the conflicting PSBTs\", or explain in\n>     \n>     more detail why picking at random is a safe choice.\n\nYou cannot simply reject PSBTs for having conflicting values for the same key. Especially\nfor the Partial Signatures, you can have two signatures for the same pubkey that are both\ncompletely valid. This situation could happen, for example, if a signer that does not use deterministic\nk values can sign multiple inputs but one input is missing a UTXO so it doesn't sign it. So it receives\n one PSBT and signs the first input but not the second. It receives a PSBT for the same transaction\nwhich has the second input's UTXO but does not have its signatures for the first input. The signer\nwould sign both inputs. When the two PSBTs are combined (suppose the first PSBT has other \nsignatures too), you will have two keys that have different values. The different values are both\nvalid signatures, just with different k values since they were randomly generated instead of\ndeterministically. If we fail to merge these, then you could potentially have a situation where\nnothing can be done with the PSBTs now, or now everyone has to resign and in some specific\norder to avoid the conflict. That complicates things and is much more annoying to deal with.\nSo a simple solution is to allow the combiner to choose any value it wants as it is likely that\nboth values are valid.\n\nAllowing combiners to choose any value also allows for intelligent combiners to choose the\ncorrect values in the case of conflicts. A smart combiner could, when combining redeem scripts\nand witness scripts, check that the redeem scripts and witness scripts match the hash provided\nin the UTXO (or in the redeem script) and choose the correct redeem script and witness script\naccordingly if there were, for some reason, a conflict there.\n\nCan you explain why it would be unsafe for combiners to arbitrarily choose a value?\n\n>     \n> -   Signing records with unknown keys.\n>     \n>     There's been some talk about this at start, but there should be a clear\n>     \n>     strategy for Signers when unknown fields are encountered. We intend to\n>     \n>     implement the rule: \"will not sign an input with any unknown fields\n>     \n>     present\".\n>     \n>     Maybe it is worth codifying this behavior in the standard, or maybe\n>     \n>     there should be a way to mark a field as \"optional\" so that strict\n>     \n>     Signers know they can safely ignore the unknown field.\n\nI think that requiring there to be no unknowns is a safe change.\n\n>     \n>     And two minor points:\n>     \n> -   Fields with empty keys.\n>     \n>     This might be inferred from the definition, but is probably worth\n>     \n>     spelling out explicitly: If a field definition states that the key data\n>     \n>     is empty, an implementation MUST enforce this and reject PSBTs that\n>     \n>     contain non-empty data.\n>     \n>     We suggest adding something to the effect of:\n>     \n>     \"If a key or value data in a field doesn't match the specified format,\n>     \n>     the PSBT is invalid. In particular, if key data is specified as \"none\"\n>     \n>     but the key contains data beyond the type specifier, implementation MUST\n>     \n>     reject the PSBT.\"\n>     \n>     (not sure about the languge, this should of course allow processing\n>     \n>     unknown fields)\n\nAgreed.\n\n>     \n> -   \"Combiner can detect inconsistencies\"\n>     \n>     Added in response to this comment [1], the current wording looks like\n>     \n>     it's describing what the Combiner is capable of, as opposed to\n>     \n>     prescribing what the combiner is allowed to do.\n>     \n>     We suggest changing to something like:\n>     \n>     \"For every field type that the Combiner understands, it MAY also refuse\n>     \n>     to combine PSBTs that have inconsistencies in that field, or cause a\n>     \n>     conflict when combined.\"\n\nAgreed.\n\n\nAndrew"
            },
            {
                "author": "Jason Les",
                "date": "2018-07-05T17:23:51",
                "message_text_only": "Has there been any thought to standardizing file names used when creating\n.psbt files? Maybe something that gives some reliability of being collision\nresistant and descriptive. For example:\n\n[8 char trim of hash of unsigned tx]+[Role that created file (Ex:\nSigner)]+[4 char trim of hash of data unique to that role (Ex: partial sig)]\n\nIt may be useful to especially the combiner to have some idea of what files\nthey have.\n\n-Jason Les\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180705/062b1c0a/attachment.html>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2018-07-04T19:09:29",
                "message_text_only": "On Wed, Jul 4, 2018 at 6:19 AM, matejcik <jan.matejek at satoshilabs.com> wrote:\n> hello,\n>\n> we still have some concerns about the BIP as currently proposed - not\n> about the format or data contents, but more about strictness and\n> security properties. I have raised some in the previous e-mails, but\n> they might have been lost in the overall talk about format.\n>\n> * Choosing from duplicate keys when combining.\n> We believe that \"choose whichever value it wishes\" is not a good\n> resolution strategy. We propose to either change this to \"in case of\n> conflicts, software MUST reject the conflicting PSBTs\", or explain in\n> more detail why picking at random is a safe choice.\n\nOutlawing conflicting values would imply forcing all Signers to\nimplement fixed deterministic nonce generation, which I don't think it\nvery desirable. Otherwise PSBTs that got copied and signed and\ncombined again may fail. So I think we should see it the other way: we\nchoose the keys in such a way that picking arbitrarily is safe. If\nthere really is a future extension for which it would not be the case\nthat picking arbitrarily is acceptable, more data can be moved to the\nkeys, and leave the actual resolution strategy to the Finalizer. That\nway Combiners can remain dumb and not need script-specific logic in\nevery interaction.\n\nAn alternative would be to have a fixed resolution strategy (for\nexample, when combining multiple PSBTs, pick the value from the first\none that has a particular key set), but I don't think this adds very\nmuch - if picking the first is fine, picking a arbitrary one should be\nfine too.\n\n> * Signing records with unknown keys.\n> There's been some talk about this at start, but there should be a clear\n> strategy for Signers when unknown fields are encountered. We intend to\n> implement the rule: \"will not sign an input with any unknown fields\n> present\".\n> Maybe it is worth codifying this behavior in the standard, or maybe\n> there should be a way to mark a field as \"optional\" so that strict\n> Signers know they can _safely_ ignore the unknown field.\n\nCan you envision a situation in which this is needed? In every\nscenario I can come up with, the worst that can happen is that the\nresulting signature is just invalid. For example, if PSBT existed\nbefore segwit, and then was later extended to support it, a pre-segwit\nsigner would not recognize that BIP143 would need to be used for\nsegwit inputs, and produce signatures using the old sighashing\nalgorithm. The result is just an invalid signature.\n\nI believe that what you're trying to accomplish is preventing signing\nsomething you don't understand, but that's an independent issue.\nSigners generally will want to inspect the transaction they're\nsigning, or ask for confirmation w.r.t. fees or payment destinations\ninvolved. The case where unknown fields are present for a reason you'd\nwant to withhold signing for will generally also just be the situation\nwhere you don't understand the transaction you're signing.\n\nHere is (perhaps far fetched) example of why it may not be desirable\nto reject unknown fields when signing. Imagine an extension is defined\nwhich adds pay-to-contract derivation for keys (Q = P + H(Q||C)G);\nthis would be a field similar to the current BIP32 derivation one, but\ninstead give a base key P and a contract C. Now say there is a 2-of-2\nmultisig in which you're one signer, and the other signer is (unknown\nto you) using P2C. After the other party Updating, the input would\ncontain a P2C field which you don't understand - but it also isn't\nsomething you care about or affects you.\n\nI would not be opposed to having fields with an explicit flag bit that\nsays \"Don't sign if you don't understand this\", but I expect that that\ncan also be left for future extensions.\n\n> * Fields with empty keys.\n> This might be inferred from the definition, but is probably worth\n> spelling out explicitly: If a field definition states that the key data\n> is empty, an implementation MUST enforce this and reject PSBTs that\n> contain non-empty data.\n> We suggest adding something to the effect of:\n> \"If a key or value data in a field doesn't match the specified format,\n> the PSBT is invalid. In particular, if key data is specified as \"none\"\n> but the key contains data beyond the type specifier, implementation MUST\n> reject the PSBT.\"\n> (not sure about the languge, this should of course allow processing\n> unknown fields)\n\nCompletely agree here. Any implementation that understands a\nparticular field must enforce whatever structure the field is known to\nhave.\n\n> * \"Combiner can detect inconsistencies\"\n> Added in response to this comment [1], the current wording looks like\n> it's describing what the Combiner is _capable of_, as opposed to\n> prescribing what the combiner is _allowed to_ do.\n> We suggest changing to something like:\n> \"For every field type that the Combiner understands, it MAY also refuse\n> to combine PSBTs that have inconsistencies in that field, or cause a\n> conflict when combined.\"\n\nAgree, just because Combiners are expected to work correctly on\nunknown fields doesn't mean they can't enforce extra consistency\nchecks on known fields.\n\nCheers,\n\n-- \nPieter"
            },
            {
                "author": "William Casarin",
                "date": "2018-07-05T19:20:32",
                "message_text_only": "I have another concern with the format. (my original bip comment for some context: [1])\n\nIt looks like the one of the reasons I was confused is because you can\nonly parse the format properly by first deserializing the transaction.\nSince there is no \"length\" field for the key-value map arrays, you must\ncount the number of transaction input/outputs, and use that as the\nnumber of kv maps to parse.\n\nThis is pretty brittle, because now if a Combiner writes the wrong\nnumber of key-value maps that don't align with the number of inputs and\noutputs in the transaction, then the psbt will not be able to be\ndeserialized properly, but is still a valid PSBT. It can't even detect\nthese situations, because the input and output types share the same enum\nvalues. I don't see anywhere that says the number of key value maps MUST\nmatch the number of inputs/outputs, perhaps it's implied?\n\nI think I think we should either make this explicit in the BIP, add an\narray length prefix, or make all (global/input/output) types share the\nsame enum.\n\nCheers,\nWilliam\n\n[1] https://github.com/bitcoin/bips/pull/694#issuecomment-402812041"
            },
            {
                "author": "Achow101",
                "date": "2018-07-06T18:59:50",
                "message_text_only": "Hi,\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n\nOn July 5, 2018 12:20 PM, William Casarin <jb55 at jb55.com> wrote:\n\n> \u200b\u200b\n> \n> I have another concern with the format. (my original bip comment for some context: [1])\n> \n> It looks like the one of the reasons I was confused is because you can\n> \n> only parse the format properly by first deserializing the transaction.\n> \n> Since there is no \"length\" field for the key-value map arrays, you must\n> \n> count the number of transaction input/outputs, and use that as the\n> \n> number of kv maps to parse.\n\nI don't think this is really a problem.\n\nAlmost all roles have to deserialize the unsigned tx anyways before they can do anything.\nThe only role that doesn't is a simple combiner (a combiner that does sanity checks would\nstill have to deserialize the unsigned tx), and even then it doesn't matter. It just shoves\nkey value pairs together and doesn't need to know whether the map is for an input or for\nan output.\n\n> \n> This is pretty brittle, because now if a Combiner writes the wrong\n> \n> number of key-value maps that don't align with the number of inputs and\n> \n> outputs in the transaction, then the psbt will not be able to be\n> \n> deserialized properly, but is still a valid PSBT. It can't even detect\n> \n> these situations, because the input and output types share the same enum\n> \n> values. \n\nIf a combiner writes the wrong number of key-value maps, then it would simply be invalid\nto the next person that receives the PSBT. It would not deserialize properly because the\nkey value pairs would have incorrect values for their types. Not deserializing properly means\nthat the PSBT is simply invalid. The same numerical types might\nbe shared, but their meanings are different between the input and output types.\n\nI don't see anywhere that says the number of key value maps MUST\n> \n> match the number of inputs/outputs, perhaps it's implied?\n\nI have added that to the BIP.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n\nOn July 5, 2018 10:23 AM, Jason Les <jasonles at gmail.com> wrote:\n\n> Has there been any thought to standardizing file names used when creating .psbt files? Maybe something that gives some reliability of being collision resistant and descriptive. For example:\n> \n> [8 char trim of hash of unsigned tx]+[Role that created file (Ex: Signer)]+[4 char trim of hash of data unique to that role (Ex: partial sig)]\n> \n> It may be useful to especially the combiner to have some idea of what files they have.\n> \n> -Jason Les\n\nI haven't considered this, but I'm not sure if it is really useful. I don't think it is really necessary\nfor any role to know who created the PSBT. If it did, this information would generally come\nout-of-band anyways as someone has to give the PSBT to that person.\n\n\n\nAndrew"
            },
            {
                "author": "Pieter Wuille",
                "date": "2018-07-05T22:06:53",
                "message_text_only": "On Thu, Jul 5, 2018 at 4:52 AM, matejcik <jan.matejek at satoshilabs.com> wrote:\n>> Allowing combiners to choose any value also allows for intelligent combiners to choose the\n>> correct values in the case of conflicts. A smart combiner could, when combining redeem scripts\n>> and witness scripts, check that the redeem scripts and witness scripts match the hash provided\n>> in the UTXO (or in the redeem script) and choose the correct redeem script and witness script\n>> accordingly if there were, for some reason, a conflict there.\n>>\n>> Can you explain why it would be unsafe for combiners to arbitrarily choose a value?\n>\n> We're worried that the \"pick one of non-deterministic signatures\" is a\n> special case and that most fields don't have this property:\n>\n> * conflicts in UTXOs, sighash type, redeem/witness scripts, derivation\n> paths, are at best a recoverable error, usually an unrecoverable error,\n> at worst malicious activity.\n>\n> * conflict in finalized scripts, in case more than one valid\n> finalization exists, might indicate that the Finalizers picked different\n> ND signatures, or it might indicate two possible interpretations of the\n> transaction (see next point). Picking arbitrarily in the latter case\n> would be an error.\n>\n> * even for partial signatures: if two Signers with the same public key\n> use different sighash types, the Combiner shouldn't pick the winning one\n> arbitrarily.\n>\n> It seems generally safer to default to rejecting conflicts, and\n> explicitly allowing the Combiner to process them intelligently if it\n> understands the relevant fields.\n\nSo consider two possible topologies for a multiparty signing:\n\nA) Creator and Updater produce a PSBT T. T is sent to signer 1 who\nturns it into PSBT T1. T1 is then forwarded to Signer 2 who turns it\ninto T12. A Finalizer extracts the transaction.\nB) Creator and Updater produce a PSBT T. T is sent to signer 1 and 2\nsimultaneously, who then produce T1 and T2 respectively. A Combiner\ncombines those into T12. A Finalizer extracts the transaction.\n\nThe only case where \"malicious\" conflicting values can occur is when\none of the Signers produces an invalid signature, or modifies any of\nthe other fields already present in the PSBT for consumption by\nothers. If this were an issue, it would be an issue regardless of the\nCombiner's operation, as in topology A no Combiner is even present.\nThis is generally true I think - Combiners can always be replaced with\njust a different (and possibly less parallel) topology of data flow.\n\nSo the question is independent of Combiners IMHO, and really about how\nwe deal with roles that intentionally or unintentionally produce\ninvalid values. I believe this is mostly not an issue. Let's go over\nthe cases:\n* If a partial signature is invalid, the resulting transaction will be invalid.\n* if a non-witness UTXO is incorrect, you'll fail to sign because the\ntxid mismatches the input's prevout (which you do have to check)\n* If a witness UTXO is incorrect, the resulting signature will be invalid.\n* If a derivation path is incorrect, the signer will fail to find the\nkey, or sign with the wrong key resulting in an invalid transaction.\n* If a witnessscript or redeemscript is incorrect, the resulting\nsignature will be invalid (as those go into the scriptCode of the\nsighash, and affect the type of sighashing)\n* If a sighash type is incorrect, the resulting transaction may be\nuseless for its intended purpose (but still something every signer\nagreed to sign).\n\nSo all of this boils down to dealing with the possibility that there\ncan be roles which intentionally or unintentionally create incorrect\nfields in a PSBT, and the solution is (a) checking that prevout txids\nmatch non-witness utxos (b) checking that the transaction you're\nsigning is one you want to sign (including sighash type) (c) worst\ncase accepting that the resulting transaction may be invalid.\n\nNow, (c) can sometimes be caught early, by implementing additional\nsanity checks for known fields. For example, rejecting PSBTs with\npartial signatures that are invalid (feed them through a verifier).\nThis is something a Combiner can of course optionally do, but so can a\nSigner or any other role.\n\nThe bottom line is that a Combiner which picks arbitrarily in case of\nconflicts will never end up with something worse than what you already\nneed to deal with. If you disregard the case of invalid fields\n(because the result will just be an invalid transaction), then any\nchoice the Combiner makes is fine, because all the values it can pick\nfrom are valid.\n\n> I agree with your response, and I also think that in technical sense,\n> the worst that can happen is an invalid signature. Our concern is twofold:\n>\n> 1. the produced signature is most likely valid, _for a different\n> transaction_ than the Creator intended. It is a transaction that the\n> Signer must have authorized, so we could argue that they would not mind\n> if that unintended transaction was published. Nevertheless, this opens\n> an attack surface.\n\nIf you're worried about attack surface, I don't believe rejecting\ninvalid fields ever matters. An attacker can always drop the fields\nyou don't understand before giving you the PSBT, making your behavior\nidentical to one where you'd have ignore those fields in the first\nplace.\n\nAt best, you can make it protect against accidental mistakes that\nwould result in invalid transactions anyway.\n\nIf there is a way to sign a message in a way that can be\nmisinterpreted as a signature on a different message with a different\nmeaning, then that is a huge flaw in Bitcoin itself, and not going to\nbe solved by rejecting to sign unknown fields.\n\nWith regard to defense in depth:\n\n>> I would not be opposed to having fields with an explicit flag bit that\n>> says \"Don't sign if you don't understand this\", but I expect that that\n>> can also be left for future extensions.\n>\n> It seems safer to consider this flag be on by default, and leave it to a\n> future extension to allow non-mandatory fields. The worst case here is\n> that legacy Signers can't natively process new PSBTs (solvable by a\n> preprocessor) - as opposed to legacy Signers signing unintended values.\n\nThere could be some rule like \"if the highest bit of the field type is\nset, don't sign\", but I don't think there is any current field where\nsuch a flag would be necessary right now.\n\nCheers,\n\n-- \nPieter"
            },
            {
                "author": "Pieter Wuille",
                "date": "2018-07-11T18:27:11",
                "message_text_only": "On Tue, Jul 10, 2018 at 5:10 AM, matejcik <jan.matejek at satoshilabs.com> wrote:\n> On 6.7.2018 00:06, Pieter Wuille wrote:> The only case where \"malicious\"\n> conflicting values can occur is when\n>> one of the Signers produces an invalid signature, or modifies any of\n>> the other fields already present in the PSBT for consumption by\n>> others. If this were an issue, it would be an issue regardless of the\n>> Combiner's operation, as in topology A no Combiner is even present.\n>> This is generally true I think - Combiners can always be replaced with\n>> just a different (and possibly less parallel) topology of data flow.\n>\n> This is an interesting thesis, and also an unspoken assumption ISTM. It\n> seems worth adding something like this to the spec:\n> \"\"\"\n> In general, the result of Combiner combining two PSBTs from independent\n> participants A and B should be functionally equivalent to a result\n> obtained from processing the original PSBT by A and then B in a sequence.\n> or, for participants performing fA(psbt) and fB(psbt):\n> Combine(fA(psbt), fB(psbt)) == fA(fB(psbt)) == fB(fA(psbt))\n> \"\"\"\n\nAdding that sounds like a good idea, indeed.\n\n>> The bottom line is that a Combiner which picks arbitrarily in case of\n>> conflicts will never end up with something worse than what you already\n>> need to deal with. If you disregard the case of invalid fields\n>> (because the result will just be an invalid transaction), then any\n>> choice the Combiner makes is fine, because all the values it can pick\n>> from are valid.\n>\n> This sounds reasonable and IMHO it would be good to have a summary of\n> this argument in the Rationale section.\n\nSounds good.\n\n>> If you're worried about attack surface, I don't believe rejecting\n>> invalid fields ever matters. An attacker can always drop the fields\n>> you don't understand before giving you the PSBT, making your behavior\n>> identical to one where you'd have ignore those fields in the first\n>> place.\n>\n> I'm reluctant to sign an input with unknown data, on the premise that there could be *anything* in that data\n\nBut the point is: you are not signing an input with unknown data. You\nare signing your own interpretation (since you compute the sighash\nyourself), which doesn't include what you don't understand. If that\ninterpretation doesn't match reality, the signature is at worst\nuseless. Who cares that someone added information about a transaction\nthat doesn't affect what you sign?\n\n> We are most likely to implement the \"do not sign with unknown fields\"\n> rule in any case (technically a whitelist of \"known OK\" field types),\n> and resolve potential problems as they arise. I raised this point mainly\n> because I think discussing this explicitly in the spec is beneficial: a\n> distinction between mandatory and optional fields is one way, mentioning\n> or prescribing possible signing strategies is another.\n\nI don't think that's a particularly useful policy, but certainly\nSigners are allowed to implement any policy they like about what they\naccept in signing.\n\nCheers,\n\n-- \nPieter"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-07-11T20:05:32",
                "message_text_only": "On Wed, Jul 11, 2018 at 6:27 PM, Pieter Wuille via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> I don't think that's a particularly useful policy, but certainly\n> Signers are allowed to implement any policy they like about what they\n> accept in signing.\n\nDo we really want the specification to permit conforming\nimplementations to refuse to sign because there is extra metadata?\nISTM this would make it very hard to implement new features that\nrequire extra data. For example, say you have a checkmultisig with one\nkey in it using schnorr multisignature which require the extra rounds\nto establish an R, and the other keys are legacy stuff.  If the other\nsigner(s) suddenly stop working when there are extra fields irrelevant\nto them, then this will create a substantial pressure to not extend\nthe PSBT in the intended way, but to instead find places to stuff the\nextra data where it won't interfere with already deployed signers.\nThis would be really unfortunate since PSBT was created specifically\nto avoid field stuffing (otherwise we could have accomplished all the\nintended goals by field stuffing a bitcoin transaction encoding).\n\nObviously no signer should be signing data they don't understand,  but\nextra data that they ignore which doesn't change their signature\nshould not stop them.  Another way of looking at it, perhaps somewhere\nsomeplace some idiot defined signatures starting with 0xdead to give\naway all the users funds or whatever.  That's something you \"can't\nunderstand\" either, ... but no one would conclude because something\ncould happen somewhere that you don't know about that you just can't\nsign at all... yet it is possible. :)\n\nIf someone wants to make a non-conforming signer, that is cool too and\nthey may have good reason to do so-- but I think it would be sad if\nnew applications get gunked up, slowed down or forced to use ugly\nhacks, due to the intentional extension support in the protocol being\nblocked by things claiming to support the spec.  The whole reason the\nspec doesn't lock in exactly the possible fields and allow no others\nis to allow extensions without breaking compatibility."
            }
        ],
        "thread_summary": {
            "title": "BIP 174 thoughts",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "William Casarin",
                "Jason Les",
                "Achow101",
                "Gregory Maxwell",
                "Pieter Wuille",
                "matejcik"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 41327
        }
    },
    {
        "title": "[bitcoin-dev]  BIP 174 thoughts",
        "thread_messages": [
            {
                "author": "matejcik",
                "date": "2018-07-05T11:52:02",
                "message_text_only": "On 4.7.2018 20:35, Achow101 wrote:\n> You cannot simply reject PSBTs for having conflicting values for the same key. Especially\n> for the Partial Signatures, you can have two signatures for the same pubkey that are both\n\n(...)\n\n> order to avoid the conflict. That complicates things and is much more annoying to deal with.\n> So a simple solution is to allow the combiner to choose any value it wants as it is likely that\n> both values are valid.\n>\n> Allowing combiners to choose any value also allows for intelligent combiners to choose the\n> correct values in the case of conflicts. A smart combiner could, when combining redeem scripts\n> and witness scripts, check that the redeem scripts and witness scripts match the hash provided\n> in the UTXO (or in the redeem script) and choose the correct redeem script and witness script\n> accordingly if there were, for some reason, a conflict there.\n>\n> Can you explain why it would be unsafe for combiners to arbitrarily choose a value?\n\nWe're worried that the \"pick one of non-deterministic signatures\" is a\nspecial case and that most fields don't have this property:\n\n* conflicts in UTXOs, sighash type, redeem/witness scripts, derivation\npaths, are at best a recoverable error, usually an unrecoverable error,\nat worst malicious activity.\n\n* conflict in finalized scripts, in case more than one valid\nfinalization exists, might indicate that the Finalizers picked different\nND signatures, or it might indicate two possible interpretations of the\ntransaction (see next point). Picking arbitrarily in the latter case\nwould be an error.\n\n* even for partial signatures: if two Signers with the same public key\nuse different sighash types, the Combiner shouldn't pick the winning one\narbitrarily.\n\nIt seems generally safer to default to rejecting conflicts, and\nexplicitly allowing the Combiner to process them intelligently if it\nunderstands the relevant fields.\n\n\nOn 4.7.2018 21:09, Pieter Wuille wrote:\n> combined again may fail. So I think we should see it the other way: we\n> choose the keys in such a way that picking arbitrarily is safe. If\n> there really is a future extension for which it would not be the case\n> that picking arbitrarily is acceptable, more data can be moved to the\n> keys, and leave the actual resolution strategy to the Finalizer.\n\nI like this explanation and I think that if nothing else, this should be\nspelled out explicitly in the spec.\n\nBut I don't think it answers the above points very well.\n\n\n> An alternative would be to have a fixed resolution strategy (for\n> example, when combining multiple PSBTs, pick the value from the first\n> one that has a particular key set), but I don't think this adds very\n> much - if picking the first is fine, picking a arbitrary one should be\n> fine too.\n\nAgreed.\n\n\n>> * Signing records with unknown keys.\n>> There's been some talk about this at start, but there should be a clear\n>> strategy for Signers when unknown fields are encountered. We intend to\n>> implement the rule: \"will not sign an input with any unknown fields\n>> present\".\n>> Maybe it is worth codifying this behavior in the standard, or maybe\n>> there should be a way to mark a field as \"optional\" so that strict\n>> Signers know they can _safely_ ignore the unknown field.\n> \n> Can you envision a situation in which this is needed? In every\n> scenario I can come up with, the worst that can happen is that the\n> resulting signature is just invalid.\n\n(...)\n\n> I believe that what you're trying to accomplish is preventing signing\n> something you don't understand, but that's an independent issue.\n\nWe're actually trying to prevent signing something we don't _intend_.\n\nI agree with your response, and I also think that in technical sense,\nthe worst that can happen is an invalid signature. Our concern is twofold:\n\n1. the produced signature is most likely valid, _for a different\ntransaction_ than the Creator intended. It is a transaction that the\nSigner must have authorized, so we could argue that they would not mind\nif that unintended transaction was published. Nevertheless, this opens\nan attack surface.\n\n2. defence in depth: the \"worst that can happen\" assumption is only\nvalid if the rest of the protocol does things right.\n\nAt an intersection lies an example: say there's a fork that changes\nformat of inputs in the network serialized tx, in a way that happens to\nbe invisible to PSBT (because scripts must be set to empty). To\ndifferentiate, we add a \"Fork ID\", but old Signers will still produce\nsignatures valid on the original chain - and, importantly, this will be\ninvisible to users.\n\nThis is of course contrived and several mistakes would have to happen at\nthe same time, but that's what defence in depth is for.\n\n\n> Here is (perhaps far fetched) example of why it may not be desirable\n> to reject unknown fields when signing. Imagine an extension is defined\n\nThis is definitely worth taking into consideration. But I'd argue that\nsome way of signalling \"optionalness\" is a better match here.\nAlternately, a pre-processor with the appropriate knowledge can strip\nthe new fields for a legacy Signer - that's what I expect to happen in\npractice.\n\n> I would not be opposed to having fields with an explicit flag bit that\n> says \"Don't sign if you don't understand this\", but I expect that that\n> can also be left for future extensions.\n\nIt seems safer to consider this flag be on by default, and leave it to a\nfuture extension to allow non-mandatory fields. The worst case here is\nthat legacy Signers can't natively process new PSBTs (solvable by a\npreprocessor) - as opposed to legacy Signers signing unintended values.\n\nregards\nm.\n\n\n\n\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 819 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180705/ab413ef2/attachment-0001.sig>"
            },
            {
                "author": "matejcik",
                "date": "2018-07-10T12:10:10",
                "message_text_only": "On 6.7.2018 00:06, Pieter Wuille wrote:> The only case where \"malicious\"\nconflicting values can occur is when\n> one of the Signers produces an invalid signature, or modifies any of\n> the other fields already present in the PSBT for consumption by\n> others. If this were an issue, it would be an issue regardless of the\n> Combiner's operation, as in topology A no Combiner is even present.\n> This is generally true I think - Combiners can always be replaced with\n> just a different (and possibly less parallel) topology of data flow.\n\nThis is an interesting thesis, and also an unspoken assumption ISTM. It\nseems worth adding something like this to the spec:\n\"\"\"\nIn general, the result of Combiner combining two PSBTs from independent\nparticipants A and B should be functionally equivalent to a result\nobtained from processing the original PSBT by A and then B in a sequence.\nor, for participants performing fA(psbt) and fB(psbt):\nCombine(fA(psbt), fB(psbt)) == fA(fB(psbt)) == fB(fA(psbt))\n\"\"\"\n\n(...)\n\n> The bottom line is that a Combiner which picks arbitrarily in case of\n> conflicts will never end up with something worse than what you already\n> need to deal with. If you disregard the case of invalid fields\n> (because the result will just be an invalid transaction), then any\n> choice the Combiner makes is fine, because all the values it can pick\n> from are valid.\n\nThis sounds reasonable and IMHO it would be good to have a summary of\nthis argument in the Rationale section.\n\n\n> If you're worried about attack surface, I don't believe rejecting\n> invalid fields ever matters. An attacker can always drop the fields\n> you don't understand before giving you the PSBT, making your behavior\n> identical to one where you'd have ignore those fields in the first\n> place.\n\nModifying the PSBT requires an active attacker. A passive attacker could\npossibly sniff the invalid signatures and misuse them.\nWhere an active attacker can likely do more than drop fields.\n\n\nIn general, this comes down to a philosophical difference again. I'm\nreluctant to sign an input with unknown data, on the premise that there\ncould be *anything* in that data; the fact that right now I can't come\nup with a field that would be problematic does not mean that tomorrow\nwon't bring one. (in particular, a potential failure here is silent,\ninvisible to the user)\n\nWe are most likely to implement the \"do not sign with unknown fields\"\nrule in any case (technically a whitelist of \"known OK\" field types),\nand resolve potential problems as they arise. I raised this point mainly\nbecause I think discussing this explicitly in the spec is beneficial: a\ndistinction between mandatory and optional fields is one way, mentioning\nor prescribing possible signing strategies is another.\n\nregards\nm.\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 819 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180710/57948001/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "BIP 174 thoughts",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "matejcik"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 8969
        }
    },
    {
        "title": "[bitcoin-dev] BIP proposal - Dandelion: Privacy Preserving Transaction Propagation",
        "thread_messages": [
            {
                "author": "Neudecker, Till (TM)",
                "date": "2018-07-05T14:50:26",
                "message_text_only": "Dear Bradley,\n\nmaybe I\u2019m a little bit late to the discussion, but I\u2019d also like to share some thoughts:\n\n* Could you elaborate on the reasoning behind choosing the periodic route shuffling interval to be around 10 minutes? I guess that there is some tradeoff between making intersection attacks possible by choosing a too small interval, and making graph-learning attacks possible by choosing a too large interval. Intuitively, this interval should depend on the number of forwarded Dandelion transactions, because these are the events that leak information, and not the absolute elapsed time. On the other hand, making the interval dependent on the number of processed transactions would allow an active adversary to trigger route shuffling by sending Dandelion transaction to specific peers, which could enable intersection attacks...\n\n* Speaking of active adversaries: Adversaries could send a large number of transactions to selected peers - either by creating the transactions on their own, or by relaying (Dandelion) transactions observed by the adversary\u2019s peers to the selected peer. Could this allow the adversary to launch fingerprinting attacks on the selected peer by comparing the observed propagation of the transactions relayed through the peer to other transactions observed?\n\n* If an adversary performs a black-hole attack (i.e., drops Dandelion transactions), and if the adversary is able to identify the diffusion source, reconstruction of parts of the anonymity graph (i.e., the part between the diffusion source and the last peer before the black-hole) might be possible. I understand that the adversary does not gain much from the knowledge of the anonymity graph, but it nonetheless helps the adversary.\n\n* Out of personal interest: Inferring Bitcoin\u2019s network topology is hard. I think it\u2019s wise to assume a strong adversary that has perfect knowledge of the topology, but can you make any statements on the sensitivity of the adversary\u2019s precision and recall regarding imperfect topology knowledge?\n\n\n--Till\n\n\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org [mailto:bitcoin-dev-bounces at lists.linuxfoundation.org] On Behalf Of Bradley Denby via bitcoin-dev\nSent: Monday, June 4, 2018 10:30 PM\nTo: bitcoin-dev at lists.linuxfoundation.org\nSubject: Re: [bitcoin-dev] BIP proposal - Dandelion: Privacy Preserving Transaction Propagation\n\nHello all,\n\nWe now have an arXiv preprint of our latest findings available, which provides additional details regarding Dandelion: https://arxiv.org/pdf/1805.11060.pdf\n\nNote that Dandelion's precision guarantees are at the population level, while the recall guarantees can be interpreted as individual guarantees. Expected recall is equivalent to the probability of an adversary associating a single transaction with a given source.\n\nSince these guarantees are probabilistic, a node cannot be sure whether all of its peers are monitoring it. Dandelion does not protect against these adversaries, and individuals who are worried about targeted deanonymization should still use Tor.\n\nOne way to conceptualize Dandelion is as a \"public health\" fix or an \"anonymity vaccination.\" Higher adoption leads to greater benefits, even for those who are not using Tor. Individuals who adopt Dandelion benefit because their transactions make at least one hop before diffusing (or more as adoption increases).\n\nNevertheless, the probabilistic nature of the guarantees means that they are not absolute. We have shown that any solution based only on routing cannot be absolute due to fundamental lower bounds on precision and recall.\n\nThank you to Eric Voskuil, Pieter Wuille, Suhas Daftuar, Christian Decker, and Tim Ruffing for the recent feedback!\n\nOn Thu, May 10, 2018 at 8:59 AM, Bradley Denby <bdenby at cmu.edu> wrote:\nHi all,\n\nWe're writing with an update on the Dandelion project. As a reminder, Dandelion\nis a practical, lightweight privacy solution that provides Bitcoin users formal\nanonymity guarantees. While other privacy solutions aim to protect individual\nusers, Dandelion protects privacy by limiting the capability of adversaries to\ndeanonymize the entire network.\n\nBitcoin's transaction spreading protocol is vulnerable to deanonymization\nattacks. When a node generates a transaction without Dandelion, it transmits\nthat transaction to its peers with independent, exponential delays. This\napproach, known as diffusion in academia, allows network adversaries to link\ntransactions to IP addresses.\n\nDandelion prevents this class of attacks by sending transactions over a randomly\nselected path before diffusion. Transactions travel along this path during the\n\"stem phase\" and are then diffused during the \"fluff phase\" (hence the name\nDandelion). We have shown that this routing protocol provides near-optimal\nanonymity guarantees among schemes that do not introduce additional encryption\nmechanisms.\n\nSince the last time we contacted the list, we have:\n - Completed additional theoretical analysis and simulations\n - Built a working prototype\n   (https://github.com/mablem8/bitcoin/tree/dandelion)\n - Built a test suite for the prototype\n   (https://github.com/mablem8/bitcoin/blob/dandelion/test/functional/p2p_dandelion.py)\n - Written detailed documentation for the new implementation\n   (https://github.com/mablem8/bips/blob/master/bip-dandelion/dandelion-reference-documentation.pdf)\n\nAmong other things, one question we've addressed in our additional analysis is\nhow to route messages during the stem phase. For example, if two Dandelion\ntransactions arrive at a node from different inbound peers, to which Dandelion\ndestination(s) should these transactions be sent? We have found that some\nchoices are much better than others.\n\nConsider the case in which each Dandelion transaction is forwarded to a\nDandelion destination selected uniformly at random. We have shown that this\napproach results in a fingerprint attack allowing network-level botnet\nadversaries to achieve total deanonymization of the P2P network after observing\nless than ten transactions per node.\n\nTo avoid this issue, we suggest \"per-inbound-edge\" routing. Each inbound peer is\nassigned a particular Dandelion destination. Each Dandelion transaction that\narrives via this peer is forwarded to the same Dandelion destination.\nPer-inbound-edge routing breaks the described attack by blocking an adversary's\nability to construct useful fingerprints.\n\nThis iteration of Dandelion has been tested on our own small network, and we\nwould like to get the implementation in front of a wider audience. An updated\nBIP document with further details on motivation, specification, compatibility,\nand implementation is located here:\nhttps://github.com/mablem8/bips/blob/master/bip-dandelion.mediawiki\n\nWe would like to thank the Bitcoin Core developers and Gregory Maxwell in\nparticular for their insightful comments, which helped to inform this\nimplementation and some of the follow-up work we conducted. We would also like\nto thank the Mimblewimble development community for coining the term \"stempool,\"\nwhich we happily adopted for this implementation.\n\nAll the best,\nBrad Denby <bdenby at cmu.edu>\nAndrew Miller <soc1024 at illinois.edu>\nGiulia Fanti <gfanti at andrew.cmu.edu>\nSurya Bakshi <sbakshi3 at illinois.edu>\nShaileshh Bojja Venkatakrishnan <shaileshh.bv at gmail.com>\nPramod Viswanath <pramodv at illinois.edu>"
            },
            {
                "author": "Giulia Fanti",
                "date": "2018-07-08T12:50:43",
                "message_text_only": "Hi Till,\n\nThank you for the comments! Responses are inline:\n\n* Could you elaborate on the reasoning behind choosing the periodic route\n> shuffling interval to be around 10 minutes? I guess that there is some\n> tradeoff between making intersection attacks possible by choosing a too\n> small interval, and making graph-learning attacks possible by choosing a\n> too large interval. Intuitively, this interval should depend on the number\n> of forwarded Dandelion transactions, because these are the events that leak\n> information, and not the absolute elapsed time. On the other hand, making\n> the interval dependent on the number of processed transactions would allow\n> an active adversary to trigger route shuffling by sending Dandelion\n> transaction to specific peers, which could enable intersection attacks...\n>\nYour intuition is spot-on in the sense that shorter intervals help with\nintersection attacks, whereas longer ones help with graph learning. On that\ntradeoff curve, we would recommend favoring graph learning attacks;\nintersection attacks can be really devastating (with recall tending to 1),\nwhereas graph learning attacks still have limited recall and precision. If\nwe decide to allow graph learning in order to prevent intersection attacks,\nthe natural conclusion would be to use as long a time interval as possible.\nWe are open to changing this time interval; 10 minutes was just a heuristic\nwe proposed at the time of writing.\n\n\n> * Speaking of active adversaries: Adversaries could send a large number of\n> transactions to selected peers - either by creating the transactions on\n> their own, or by relaying (Dandelion) transactions observed by the\n> adversary?s peers to the selected peer. Could this allow the adversary to\n> launch fingerprinting attacks on the selected peer by comparing the\n> observed propagation of the transactions relayed through the peer to other\n> transactions observed?\n>\nYes, this is one of the main ways we envision adversaries potentially\nlearning the graph in practice.\n\n\n> * If an adversary performs a black-hole attack (i.e., drops Dandelion\n> transactions), and if the adversary is able to identify the diffusion\n> source, reconstruction of parts of the anonymity graph (i.e., the part\n> between the diffusion source and the last peer before the black-hole) might\n> be possible. I understand that the adversary does not gain much from the\n> knowledge of the anonymity graph, but it nonetheless helps the adversary.\n>\nThis is also true. Using a small shuffle time interval  would help prevent\nthis, but if we go with a longer interval, this approach could certainly\nhelp with graph learning.\n\n\n> * Out of personal interest: Inferring Bitcoin?s network topology is hard.\n> I think it?s wise to assume a strong adversary that has perfect knowledge\n> of the topology, but can you make any statements on the sensitivity of the\n> adversary?s precision and recall regarding imperfect topology knowledge?\n>\nWe only studied what happens when the adversary has full knowledge of the\ngraph and local knowledge (i.e. the spy nodes know their own neighbors, but\nnothing else). We did not study what happens when the adversary has partial\ngraph knowledge, but that would be an interesting and useful question to\nlook at.\n\n\n>\n> --Till\n>\n>\n> From: bitcoin-dev-bounces at lists.linuxfoundation.org [mailto:\n> bitcoin-dev-bounces at lists.linuxfoundation.org] On Behalf Of Bradley Denby\n> via bitcoin-dev\n> Sent: Monday, June 4, 2018 10:30 PM\n> To: bitcoin-dev at lists.linuxfoundation.org\n> Subject: Re: [bitcoin-dev] BIP proposal - Dandelion: Privacy Preserving\n> Transaction Propagation\n>\n> Hello all,\n>\n> We now have an arXiv preprint of our latest findings available, which\n> provides additional details regarding Dandelion:\n> https://arxiv.org/pdf/1805.11060.pdf\n>\n> Note that Dandelion's precision guarantees are at the population level,\n> while the recall guarantees can be interpreted as individual guarantees.\n> Expected recall is equivalent to the probability of an adversary\n> associating a single transaction with a given source.\n>\n> Since these guarantees are probabilistic, a node cannot be sure whether\n> all of its peers are monitoring it. Dandelion does not protect against\n> these adversaries, and individuals who are worried about targeted\n> deanonymization should still use Tor.\n>\n> One way to conceptualize Dandelion is as a \"public health\" fix or an\n> \"anonymity vaccination.\" Higher adoption leads to greater benefits, even\n> for those who are not using Tor. Individuals who adopt Dandelion benefit\n> because their transactions make at least one hop before diffusing (or more\n> as adoption increases).\n>\n> Nevertheless, the probabilistic nature of the guarantees means that they\n> are not absolute. We have shown that any solution based only on routing\n> cannot be absolute due to fundamental lower bounds on precision and recall.\n>\n> Thank you to Eric Voskuil, Pieter Wuille, Suhas Daftuar, Christian Decker,\n> and Tim Ruffing for the recent feedback!\n>\n> On Thu, May 10, 2018 at 8:59 AM, Bradley Denby <bdenby at cmu.edu> wrote:\n> Hi all,\n>\n> We're writing with an update on the Dandelion project. As a reminder,\n> Dandelion\n> is a practical, lightweight privacy solution that provides Bitcoin users\n> formal\n> anonymity guarantees. While other privacy solutions aim to protect\n> individual\n> users, Dandelion protects privacy by limiting the capability of\n> adversaries to\n> deanonymize the entire network.\n>\n> Bitcoin's transaction spreading protocol is vulnerable to deanonymization\n> attacks. When a node generates a transaction without Dandelion, it\n> transmits\n> that transaction to its peers with independent, exponential delays. This\n> approach, known as diffusion in academia, allows network adversaries to\n> link\n> transactions to IP addresses.\n>\n> Dandelion prevents this class of attacks by sending transactions over a\n> randomly\n> selected path before diffusion. Transactions travel along this path during\n> the\n> \"stem phase\" and are then diffused during the \"fluff phase\" (hence the name\n> Dandelion). We have shown that this routing protocol provides near-optimal\n> anonymity guarantees among schemes that do not introduce additional\n> encryption\n> mechanisms.\n>\n> Since the last time we contacted the list, we have:\n>  - Completed additional theoretical analysis and simulations\n>  - Built a working prototype\n>    (https://github.com/mablem8/bitcoin/tree/dandelion)\n>  - Built a test suite for the prototype\n>    (\n> https://github.com/mablem8/bitcoin/blob/dandelion/test/functional/p2p_dandelion.py\n> )\n>  - Written detailed documentation for the new implementation\n>    (\n> https://github.com/mablem8/bips/blob/master/bip-dandelion/dandelion-reference-documentation.pdf\n> )\n>\n> Among other things, one question we've addressed in our additional\n> analysis is\n> how to route messages during the stem phase. For example, if two Dandelion\n> transactions arrive at a node from different inbound peers, to which\n> Dandelion\n> destination(s) should these transactions be sent? We have found that some\n> choices are much better than others.\n>\n> Consider the case in which each Dandelion transaction is forwarded to a\n> Dandelion destination selected uniformly at random. We have shown that this\n> approach results in a fingerprint attack allowing network-level botnet\n> adversaries to achieve total deanonymization of the P2P network after\n> observing\n> less than ten transactions per node.\n>\n> To avoid this issue, we suggest \"per-inbound-edge\" routing. Each inbound\n> peer is\n> assigned a particular Dandelion destination. Each Dandelion transaction\n> that\n> arrives via this peer is forwarded to the same Dandelion destination.\n> Per-inbound-edge routing breaks the described attack by blocking an\n> adversary's\n> ability to construct useful fingerprints.\n>\n> This iteration of Dandelion has been tested on our own small network, and\n> we\n> would like to get the implementation in front of a wider audience. An\n> updated\n> BIP document with further details on motivation, specification,\n> compatibility,\n> and implementation is located here:\n> https://github.com/mablem8/bips/blob/master/bip-dandelion.mediawiki\n>\n> We would like to thank the Bitcoin Core developers and Gregory Maxwell in\n> particular for their insightful comments, which helped to inform this\n> implementation and some of the follow-up work we conducted. We would also\n> like\n> to thank the Mimblewimble development community for coining the term\n> \"stempool,\"\n> which we happily adopted for this implementation.\n>\n> All the best,\n> Brad Denby <bdenby at cmu.edu>\n> Andrew Miller <soc1024 at illinois.edu>\n> Giulia Fanti <gfanti at andrew.cmu.edu>\n> Surya Bakshi <sbakshi3 at illinois.edu>\n> Shaileshh Bojja Venkatakrishnan <shaileshh.bv at gmail.com>\n> Pramod Viswanath <pramodv at illinois.edu>\n>\n>\n> ------------------------------\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n> End of bitcoin-dev Digest, Vol 38, Issue 8\n> ******************************************\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180708/5a1ba688/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP proposal - Dandelion: Privacy Preserving Transaction Propagation",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Giulia Fanti",
                "Neudecker, Till (TM)"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 16702
        }
    },
    {
        "title": "[bitcoin-dev] BIP 174 thoughts on graphics",
        "thread_messages": [
            {
                "author": "vv01f",
                "date": "2018-07-11T20:54:04",
                "message_text_only": "this is intended to fix the graphics\n\n* as not scaleable bitmap/png\n* with broken capitalization\n* not easy editable plaintext for git\n\nhave a view[1] on the suggestion for an example[0].\n\n\n[0]:\nhttps://github.com/bitcoin/bips/blob/master/bip-0174/coinjoin-workflow.png\n[1]: https://de.sharelatex.com/read/hrvvwcvhrbyz\n\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 898 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180711/960c3fc0/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "BIP 174 thoughts on graphics",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "vv01f"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 605
        }
    },
    {
        "title": "[bitcoin-dev] Schnorr signatures BIP",
        "thread_messages": [
            {
                "author": "Pieter Wuille",
                "date": "2018-07-06T18:08:34",
                "message_text_only": "Hello everyone,\n\nHere is a proposed BIP for 64-byte elliptic curve Schnorr signatures,\nover the same curve as is currently used in ECDSA:\nhttps://github.com/sipa/bips/blob/bip-schnorr/bip-schnorr.mediawiki\n\nIt is simply a draft specification of the signature scheme itself. It\ndoes not concern consensus rules, aggregation, or any other\nintegration into Bitcoin - those things are left for other proposals,\nwhich can refer to this scheme if desirable. Standardizing the\nsignature scheme is a first step towards that, and as it may be useful\nin other contexts to have a common Schnorr scheme available, it is its\nown informational BIP.\n\nIf accepted, we'll work on more production-ready reference\nimplementations and tests.\n\nThis is joint work with several people listed in the document.\n\nCheers,\n\n-- \nPieter"
            },
            {
                "author": "Russell O'Connor",
                "date": "2018-07-06T21:05:03",
                "message_text_only": "Some quick comments:\n\nSigning\n>\n> To sign:\n>\n>    - Let *k = int(hash(bytes(d) || m)) mod n*[8\n>    <https://github.com/sipa/bips/blob/bip-schnorr/bip-schnorr.mediawiki#cite_note-8>\n>    ].\n>    - Let *R = kG*.\n>    - If *jacobi(y(R)) \u2260 1*, let *k = n - k*.\n>    - Let *e = int(hash(bytes(x(R)) || bytes(dG) || m)) mod n*.\n>    - The signature is *bytes(x(R)) || bytes(k + ex mod n)*.\n>\n> Can we avoid mutable variables in these specification?  I know this is\ncommonly done in RFCs, but I think it is fairly confusing to have `k`\ndefined in two different ways within a single specification.\nLet's let k' = k when jacobi(y(R)) = 1 and let k' = n - k when jacobi(y(R))\n= -1.  Note that this ensures that jacobi(y(k'G)) = 1.\n\nAlso you've sort of left it undefined what to do when k = 0.  According to\nthe current specification, you will produce an invalid signature.  The\nexpected result is that you should win a 1000 BTC prize.\n\nOne solution is to let k = *1 + int(hash(bytes(d) || m)) mod (n-1)*.\nAlternatively you could let k' = 1 when k = 0.  Or you could just make a\nnote that signature generation fails with this message and private key pair\nwhen this happens.\n\nLet *e = int(hash(bytes(x(R)) || bytes(dG) || m)) mod n*.\n>\n\nP = dG should probably be noted somewhere in the text.  I.e. this signature\nis generated for the public key P = dG.\n\nIf the inputs to hash were reordered as *hash(bytes(dG) || bytes(x(R)) ||\nm)* then there is an opportunity for SHA256 expander to be partially\nprefilled for a fixed public key.  This could provide a little benefit,\nespecially when multiple signatures for a single public key need to be\ngenerated and/or verified.  If all things are otherwise equal, perhaps this\nalternate order is better.\n\n The signature is *bytes(x(R)) || bytes(k + ex mod n)*.\n\n\nYou haven't defined `x`.  I'm guessing you mean `d` instead.\n\n> Optimizations\n>\n> *Jacobian coordinates*\n>\n>    - *oncurve(P)* can be implemented as *y2 = x3 + 7z6 mod p*.\n>\n> oncurve(P) requires that `P` be on the curve and not infinity.  You need\nanother condition here to ensure that `P` is not infinity.\n\n\nOn Fri, Jul 6, 2018 at 2:08 PM, Pieter Wuille via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hello everyone,\n>\n> Here is a proposed BIP for 64-byte elliptic curve Schnorr signatures,\n> over the same curve as is currently used in ECDSA:\n> https://github.com/sipa/bips/blob/bip-schnorr/bip-schnorr.mediawiki\n>\n> It is simply a draft specification of the signature scheme itself. It\n> does not concern consensus rules, aggregation, or any other\n> integration into Bitcoin - those things are left for other proposals,\n> which can refer to this scheme if desirable. Standardizing the\n> signature scheme is a first step towards that, and as it may be useful\n> in other contexts to have a common Schnorr scheme available, it is its\n> own informational BIP.\n>\n> If accepted, we'll work on more production-ready reference\n> implementations and tests.\n>\n> This is joint work with several people listed in the document.\n>\n> Cheers,\n>\n> --\n> Pieter\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180706/46edd80f/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-07-06T22:00:28",
                "message_text_only": "On Fri, Jul 6, 2018 at 9:05 PM, Russell O'Connor via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> If the inputs to hash were reordered as hash(bytes(dG) || bytes(x(R)) || m)\n> then there is an opportunity for SHA256 expander to be partially prefilled\n> for a fixed public key.  This could provide a little benefit, especially\n> when multiple signatures for a single public key need to be generated and/or\n> verified.  If all things are otherwise equal, perhaps this alternate order\n> is better.\n\nThere is a minor design preference to have message before nonce when\nH() is a MD-style hash function.  Say the attacker knows some weakness\nin H and can find pairs of messages m and m' so that the compression\nfunction results in the same midstate.  He could then ask you to sign\nm but get a signature that also works for m'.   If the signer\ncontrolled R value comes first, then this doesn't work.    The pubkey\nbeing where it is in the current design just follows from the idea\nthat it is just logically prepended on the message.  I don't think the\npubkey is sufficiently attacker controlled that the above argument\nwould apply,  so H(P || R.x || m) would be okay.\n\nBUT, the sha256 compression function reads 64 bytes at a time. PRM\nwould not let you precompute a whole compression function run, but\ninstead would just let you hardwire part of the expander in a pubkey\ndependant way-- an optimization I'm pretty confident virtually no one\nwould use.  (Hardwiring to a constant, yes. Hardwiring to a reused\ndynamic value that comes in from the network, no)\n\nIf instead the hash function were defined as using 31 zeros then\nP||R||m (or P || 31 zeros bytes || R || m, I'm not sure what would be\nbetter), an entire midstate could be cached for different pubkeys. m\nis often 32 bytes, sadly- - but the final compression run in that case\nwould only be the constant update with the length.... and\nalmost-all-zeros + constant length, is an easy optimization. (Bitcoin\ncore even has it for computing sha256(sha256())).\n\n[I'm not really sure if I was clear, so I'll try TLDRing it:  I think\noptimizing sha256 where part of the input is constant is realistic,\noptimizing midstate reuse is realistic, optimizing where part is\nreused is less realistic.  If we insert padding, and put P first, we\ncan make it possible to midstate cache P,  and the 'extra' compression\nfunction run ends up with all constant input, so it could be made\nfaster.]"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-07-06T22:01:32",
                "message_text_only": "On Fri, Jul 6, 2018 at 10:00 PM, Gregory Maxwell <greg at xiph.org> wrote:\n> There is a minor design preference to have message before nonce when\n\n::sigh:: to NOT have the message before the nonce."
            },
            {
                "author": "Russell O'Connor",
                "date": "2018-07-08T14:36:16",
                "message_text_only": "On Fri, Jul 6, 2018 at 6:00 PM, Gregory Maxwell <greg at xiph.org> wrote:\n\n> On Fri, Jul 6, 2018 at 9:05 PM, Russell O'Connor via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > If the inputs to hash were reordered as hash(bytes(dG) || bytes(x(R)) ||\n> m)\n> > then there is an opportunity for SHA256 expander to be partially\n> prefilled\n> > for a fixed public key.  This could provide a little benefit, especially\n> > when multiple signatures for a single public key need to be generated\n> and/or\n> > verified.  If all things are otherwise equal, perhaps this alternate\n> order\n> > is better.\n>\n> There is a minor design preference to have message before nonce when\n> H() is a MD-style hash function.  Say the attacker knows some weakness\n> in H and can find pairs of messages m and m' so that the compression\n> function results in the same midstate.  He could then ask you to sign\n> m but get a signature that also works for m'.   If the signer\n> controlled R value comes first, then this doesn't work.    The pubkey\n> being where it is in the current design just follows from the idea\n> that it is just logically prepended on the message.  I don't think the\n> pubkey is sufficiently attacker controlled that the above argument\n> would apply,  so H(P || R.x || m) would be okay.\n>\n> BUT, the sha256 compression function reads 64 bytes at a time. PRM\n> would not let you precompute a whole compression function run, but\n> instead would just let you hardwire part of the expander in a pubkey\n> dependant way-- an optimization I'm pretty confident virtually no one\n> would use.  (Hardwiring to a constant, yes. Hardwiring to a reused\n> dynamic value that comes in from the network, no)\n>\n\nRight.  I readily admit my proposal has extremely marginal efficiency\nbenefits. However, I didn't realize there is also an extremely marginal\nsecurity benefit to placing the nonce in front of everything.  Although\nthese things are so marginal that it is perhaps a waste of time to even be\nconsidering them, I think I'd judge the extremely marginal security benefit\nto exceed the value of the extremely marginal efficiency gain.  It's\nprobably best to leave the nonce at the beginning after all.\n\n\n> If instead the hash function were defined as using 31 zeros then\n> P||R||m (or P || 31 zeros bytes || R || m, I'm not sure what would be\n> better), an entire midstate could be cached for different pubkeys. m\n> is often 32 bytes, sadly- - but the final compression run in that case\n> would only be the constant update with the length.... and\n> almost-all-zeros + constant length, is an easy optimization. (Bitcoin\n> core even has it for computing sha256(sha256())).\n>\n\nI did consider this, however the 31 bytes of zeros, plus the SHA256 padding\nmeans we would need to compress *three* blocks in general instead of the\ncurrent proposal of just two blocks.  This burden seems to exceed the\nbenefit of maybe sometimes getting a slightly fast\ntwo-blocks-with-lots-of-zeros when public keys are reused. I wouldn't\nrecommend it.\n\nThere is an alternative of just dropping the SHA-256 length padding.  This\nwould still be secure in this context because the data is of fixed size.\nHowever, I doubt it is worth breaking the API of every SHA-256 library in\nexistence to enable that.\n\n\n> [I'm not really sure if I was clear, so I'll try TLDRing it:  I think\n> optimizing sha256 where part of the input is constant is realistic,\n> optimizing midstate reuse is realistic, optimizing where part is\n> reused is less realistic.  If we insert padding, and put P first, we\n> can make it possible to midstate cache P,  and the 'extra' compression\n> function run ends up with all constant input, so it could be made\n> faster.]\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180708/c8327c14/attachment.html>"
            },
            {
                "author": "Sjors Provoost",
                "date": "2018-07-14T15:42:58",
                "message_text_only": "> Op 6 jul. 2018, om 20:08 heeft Pieter Wuille via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:\n> \n> Hello everyone,\n> \n> Here is a proposed BIP for 64-byte elliptic curve Schnorr signatures,\n> over the same curve as is currently used in ECDSA:\n> https://github.com/sipa/bips/blob/bip-schnorr/bip-schnorr.mediawiki\n\nThe power of simplification at work, thanks Pieter!\n\nQuestions:\n\nRegarding verification: why does bytes(P) use compressed key serialization rather than the implicit Y coordinate used for signing? I understand space savings don't matter since these values don't end up on the blockchain. Is it just easier to implement or is it faster?\n\nRegarding rationale for choosing (e,s) vs. (R,s), you say that (e,s) \"avoids the difficulty of encoding a point R in the signature\". But since e = H(sG - eP || m) also involves converting a point to some byte encoding in order to hash it, how much difficulty is actually avoided? Is that, like for previous question, because you could get away with compressed keys rather than implicit Y coordinates?\n\nRegarding batch verification: \"randomly generated independently for each batch of verifications\" - by whom? I assume randomly picked by the verifier?\n\nRegarding random number used for signing. The suggested (?) deterministic algorithm to derive secret key ''k'' from the private key ''d''  seems similar to RFC6979. Maybe it's useful to briefly explain the difference, as well as your rationale for not making it mandatory (presumably the same as why RFC6979 isn't mandatory although most (?) wallets use it).\n\nNits:\n\n* Motivation: \"signatures ... These are standardized\", but the \"standardized\" link points to the secp256k1 curve parameters, not to anything signature related afaik\n* \"message m: an array of 32 bytes\", maybe add \"typically the sha256 hash of the transaction components commited to by SIGHASH_TYPE\u201d\n* I left a few even smaller nits as a PR: https://github.com/sipa/bips/pull/10\n\nCheers,\n\nSjors\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180714/065df004/attachment.sig>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2018-07-14T21:20:48",
                "message_text_only": "On Sat, Jul 14, 2018 at 8:42 AM, Sjors Provoost <sjors at sprovoost.nl> wrote:\n> Questions:\n>\n> Regarding verification: why does bytes(P) use compressed key serialization rather than the implicit Y coordinate used for signing? I understand space savings don't matter since these values don't end up on the blockchain. Is it just easier to implement or is it faster?\n\nFollowing the design decision to use key-prefixed Schnorr, the\nsignature must commit to the entire public key, including its Y\ncoordinate.\n\nIt would be possible to only permit public keys whose Y coordinates\nare even, or quadratic residues (like the signature internally uses\nfor the R point), but that would mean changing what public keys are\nacceptable. Not doing so has significant practical advantages, like\nnot breaking existing key generation mechanisms (like BIP32 and\nderivatives).\n\nSo if we're going to serialize the public key into the hash, in full,\nthe easiest choice seems to be to use the encoding everyone already\nuses for public keys.\n\n> Regarding rationale for choosing (e,s) vs. (R,s), you say that (e,s) \"avoids the difficulty of encoding a point R in the signature\". But since e = H(sG - eP || m) also involves converting a point to some byte encoding in order to hash it, how much difficulty is actually avoided? Is that, like for previous question, because you could get away with compressed keys rather than implicit Y coordinates?\n\nThis is mostly a historical argument. When Schnorr is applied to an\ninteger multiplication group rather than an elliptic curve group,\nserializing a group element is many times larger than serializing a\nhash. For elliptic curve based Schnorr, there is hardly any benefit\nfor choosing the (e,s) form over (R,s).\n\n> Regarding batch verification: \"randomly generated independently for each batch of verifications\" - by whom? I assume randomly picked by the verifier?\n\nRandomly picked by the verifier, yes. The randomization factors are\nthere so that an attacker cannot choose signatures which cancel out\nother invalid signatures within the same batch.\n\n> Regarding random number used for signing. The suggested (?) deterministic algorithm to derive secret key ''k'' from the private key ''d''  seems similar to RFC6979. Maybe it's useful to briefly explain the difference, as well as your rationale for not making it mandatory (presumably the same as why RFC6979 isn't mandatory although most (?) wallets use it).\n\nWhat would \"mandatory\" mean? To follow the BIP, signers must sign\nusing nonces generated deterministically following the provided\nmethod. That's as far as mandatory can go.\n\nHowever, it is not possible to enforce (by a verifier) than nonces\nwere generated in a specific way. To do so, the verifier would need to\nknow the nonce, which implies learning the private key. So the nonce\nchoosing algorithm cannot be enforced by the verifier. This implies\nthat it is possible to generate valid (and secure) nonces in a way\nthat does not follow the BIP.\n\n> * Motivation: \"signatures ... These are standardized\", but the \"standardized\" link points to the secp256k1 curve parameters, not to anything signature related afaik\n\nThere are two documents on the site linked to. One describes the ECDSA\nsigning algorithm and serializations, the other specifies the curve\nparameter. I could link to both.\n\n> * \"message m: an array of 32 bytes\", maybe add \"typically the sha256 hash of the transaction components commited to by SIGHASH_TYPE\u201d\n\nOk.\n\n> * I left a few even smaller nits as a PR: https://github.com/sipa/bips/pull/10\n\nThanks for your comments, will review.\n\nCheers,\n\n-- \nPieter"
            },
            {
                "author": "\u0410\u0440\u0442\u0451\u043c \u041b\u0438\u0442\u0432\u0438\u043d\u043e\u0432\u0438\u0447",
                "date": "2018-07-07T02:47:40",
                "message_text_only": "Neat.\n\nSome minor notes as an outsider who just spent an hour implementing and\nplaying with this:\n\n-In several places you have things like \"Let k = int(hash(bytes(d) || m))\nmod n\", but reference code says things like \"e = sha256(R[0].to_bytes(32,\nbyteorder=\"big\") + bytes_point(point_mul(G, seckey)) + msg)\", no modulo.\nConfusing.\n\n-x is not defined in \"The signature is *bytes(x(R)) || bytes(k + ex mod n)*\",\napparently it's the private key.\n\n-jacobi function is great at exposing bugs in divmod implementations, due\nto the full 256 bit exponent. Add a line about it being something to watch\nfor?\n\n-\"bytes\" notation is defined as \"turn to bytes\" for an integer, but the\nsame for a point is \"take X with prefix and turn to bytes\". Confusing,\nmight be a good idea to name it differently?\n\n-Finally, it would have been nice to have a larger set of test vectors in a\nJSON or CSV file, covering all the edge cases.\n\n\nArtem\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180707/caba391c/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Schnorr signatures BIP",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Russell O'Connor",
                "\u0410\u0440\u0442\u0451\u043c \u041b\u0438\u0442\u0432\u0438\u043d\u043e\u0432\u0438\u0447",
                "Gregory Maxwell",
                "Sjors Provoost",
                "Pieter Wuille"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 17762
        }
    },
    {
        "title": "[bitcoin-dev] Multiparty signatures",
        "thread_messages": [
            {
                "author": "Erik Aronesty",
                "date": "2018-07-08T14:19:52",
                "message_text_only": "To save space, start with the wiki terminology on schnorr sigs.\n\nConsider changing the \"e\" term in the schnorr algorithm to hash of message\n(elligator style) to the power of r, rather than using concatenation.\n\nI don't think this changes the security.   An attacker would need to know k\nto either way to compromise the private key.\n\nThis would allow m of n devices to sign a transaction without any of them\nknowing a private key at all.\n\nIE: each device can roll a random number as a share and the interpolation\nof that is the private key.\n\nThe public shares can be broadcast and combines.  And signature shares can\nbe broadcast and combined.\n\nThe net result of this is it really possible for an arbitrary set of\ndevices to create a perfectly secure public-private key pair set.\n\nAt no point was the private key anywhere.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180708/cbdf80dd/attachment.html>"
            },
            {
                "author": "Tim Ruffing",
                "date": "2018-07-08T15:16:34",
                "message_text_only": "Hi Erik,\n\nOn Sun, 2018-07-08 at 10:19 -0400, Erik Aronesty via bitcoin-dev wrote:\n> Consider changing the \"e\" term in the schnorr algorithm to hash of\n> message (elligator style) to the power of r, rather than using\n> concatenation.  \n\nHow do you compute s = x*e if e is an element of group G?\n(Similar question: How do you verify if e is element of G?)\n\nAre you aware of \n http://cacr.uwaterloo.ca/techreports/2001/corr2001-13.ps ?\nThis is a threshold signature scheme for Schnorr signatures, so what\nyou want is possible already with Schnorr signatures.\n\nBest,\nTim"
            },
            {
                "author": "Erik Aronesty",
                "date": "2018-07-08T18:23:45",
                "message_text_only": "You don't have to treat the hash as a group member for the purposes of\nsigning.\n\nEverything else about the algorithm works the same.\n\nThis just enables signatures to be computed much more simply.\n\nOn Sun, Jul 8, 2018, 11:32 AM Tim Ruffing via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Erik,\n>\n> On Sun, 2018-07-08 at 10:19 -0400, Erik Aronesty via bitcoin-dev wrote:\n> > Consider changing the \"e\" term in the schnorr algorithm to hash of\n> > message (elligator style) to the power of r, rather than using\n> > concatenation.\n>\n> How do you compute s = x*e if e is an element of group G?\n> (Similar question: How do you verify if e is element of G?)\n>\n> Are you aware of\n>  http://cacr.uwaterloo.ca/techreports/2001/corr2001-13.ps ?\n> This is a threshold signature scheme for Schnorr signatures, so what\n> you want is possible already with Schnorr signatures.\n>\n> Best,\n> Tim\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180708/d7a9e8b4/attachment-0001.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-07-08T21:01:36",
                "message_text_only": "On Sun, Jul 8, 2018 at 3:16 PM, Tim Ruffing via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> so what\n> you want is possible already with Schnorr signatures.\n\nAs also described in \"Multisignatures and Threshold Signatures\" in the BIP."
            },
            {
                "author": "Erik Aronesty",
                "date": "2018-07-09T00:27:53",
                "message_text_only": "Pretty sure these non interactive sigs are more secure.\n\n\n\nOn Sun, Jul 8, 2018, 5:02 PM Gregory Maxwell via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Sun, Jul 8, 2018 at 3:16 PM, Tim Ruffing via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > so what\n> > you want is possible already with Schnorr signatures.\n>\n> As also described in \"Multisignatures and Threshold Signatures\" in the BIP.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180708/c768e8bd/attachment-0001.html>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2018-07-09T02:33:06",
                "message_text_only": "On Sun, Jul 8, 2018, 19:23 Erik Aronesty via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Pretty sure these non interactive sigs are more secure.\n>\n\nSchnorr signatures are provably secure in the random oracle model assuming\nthe discrete logarithm problem is hard in the used group.\n\nWhat does \"more secure\" mean? Is your construction secure with weaker\nassumptions?\n\n-- \nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180708/4f9bcb27/attachment.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2018-07-09T04:29:02",
                "message_text_only": "Because it's non-interactive, this construction can produce multisig\nsignatures offline.   Each device produces a signature using it's own\nk-share and x-share.   It's only necessary to interpolate M of n shares.\n\nThere are no round trips.\n\nThe security is Shamir + discrete log.\n\nit's just something I've been tinkering with and I can't see an obvious\nproblem.\n\nIt's basically the same as schnorr, but you use a threshold hash to fix the\nneed to be online.\n\nJust seems more useful to me.\n\n\nOn Sun, Jul 8, 2018, 10:33 PM Pieter Wuille <pieter.wuille at gmail.com> wrote:\n\n> On Sun, Jul 8, 2018, 19:23 Erik Aronesty via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Pretty sure these non interactive sigs are more secure.\n>>\n>\n> Schnorr signatures are provably secure in the random oracle model assuming\n> the discrete logarithm problem is hard in the used group.\n>\n> What does \"more secure\" mean? Is your construction secure with weaker\n> assumptions?\n>\n> --\n> Pieter\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180709/364d4561/attachment.html>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2018-07-09T02:29:19",
                "message_text_only": "On Sun, Jul 8, 2018, 07:26 Erik Aronesty via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> To save space, start with the wiki terminology on schnorr sigs.\n>\n> Consider changing the \"e\" term in the schnorr algorithm to hash of message\n> (elligator style) to the power of r, rather than using concatenation.\n>\n\nThis is a very vague description. Is there some paper you can reference, or\na more detailed explanation of the algorithm?\n\nThis would allow m of n devices to sign a transaction without any of them\n> knowing a private key at all.\n>\nIE: each device can roll a random number as a share and the interpolation\n> of that is the private key.\n>\n> The public shares can be broadcast and combines.  And signature shares can\n> be broadcast and combined.\n>\n> The net result of this is it really possible for an arbitrary set of\n> devices to create a perfectly secure public-private key pair set.\n>\nAt no point was the private key anywhere.\n>\n\nAll of this sounds like a threshold signature scheme, which as Tim pointed\nout is already possible with Schnorr.\n\nWhat are the advantages of what you're describing?\n\nCheers,\n\n-- \nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180708/396b25b7/attachment.html>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2018-07-09T04:39:56",
                "message_text_only": "On Sun, Jul 8, 2018, 21:29 Erik Aronesty <erik at q32.com> wrote:\n\n> Because it's non-interactive, this construction can produce multisig\n> signatures offline.   Each device produces a signature using it's own\n> k-share and x-share.   It's only necessary to interpolate M of n shares.\n>\n> There are no round trips.\n>\n> The security is Shamir + discrete log.\n>\n> it's just something I've been tinkering with and I can't see an obvious\n> problem.\n>\n> It's basically the same as schnorr, but you use a threshold hash to fix\n> the need to be online.\n>\n> Just seems more useful to me.\n>\n\nThat sounds very useful if true, but I don't think we should include novel\ncryptography in Bitcoin based on your not seeing an obvious problem with it.\n\nI'm looking forward to seeing a more complete writeup though.\n\nCheers,\n\n-- \nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180708/3551e8cf/attachment.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2018-07-09T15:02:30",
                "message_text_only": "Actually, it looks like in order to compute a multiparty signature you will\nneed to broadcast shares of r first, so it's not offline :(\n\nIt is still seems, to me, to be a simpler mechanism than musig - with\nsecurity assumptions that match the original Schnorr construction more\nclosely, and should therefore be easier to prove secure in a multiparty\ncontext.\n\nShamir/Schnorr threshold multi-signature scheme:\n\nEach party:\n\n- Has a public key g*x', where x' is their private key, and where H(g*x)\ncan be considered their public index for the purposes of Shamir polynomial\ninterpolation\n- Rolls a random k' and compute r' = g*k'\n- Broadcast r' as a share\n- Computes g*k, via lagrange interpolation across shares.   At this point k\nis not known to any party unless Shamir is vulnerable or DL is not hard\n- Computes e' = H(M) * r'\n- Computes s' = k'-x*e'\n- Share of signature is (s', e')\n\nVerification is the same as Scnhorr, but only after using interpolation to\nget the needed (s, e, g*x) from shares of s', e' and g*x':\n\n- Using lagrange interpolation, compute the public key g*x\n- Again, using lagrange interpolation, compute (s, e)\n- Verify the signature as per standard Schnorr\n\nSecurity assumptions:\n\n - Because this is not additive, and instead we are using Shamir\ncombination, the additional blinding and masking steps of musig are not\nneeded to create a secure scheme.\n - The scheme is the same as Schnorr otherwise\n - The only thing to prove is that H(M) * r does not reveal any information\nabout k ... which relies on the same DL assumptions as Bitcoin itself\n - Overall, this seems, to me at least, to have a smaller attack surface\nbecause there's fewer moving parts\n\n\nOn Mon, Jul 9, 2018 at 8:24 AM, Erik Aronesty <erik at q32.com> wrote:\n\n> I was hoping that nobody in this group saw an obvious problem with it then\n> I'd sit down and try to write up a paper.\n>\n> Not that hard to just reuse the work done on schnorr.   And demonstrate\n> that there are no additional assumptions.\n>\n> On Mon, Jul 9, 2018, 12:40 AM Pieter Wuille <pieter.wuille at gmail.com>\n> wrote:\n>\n>> On Sun, Jul 8, 2018, 21:29 Erik Aronesty <erik at q32.com> wrote:\n>>\n>>> Because it's non-interactive, this construction can produce multisig\n>>> signatures offline.   Each device produces a signature using it's own\n>>> k-share and x-share.   It's only necessary to interpolate M of n shares.\n>>>\n>>> There are no round trips.\n>>>\n>>> The security is Shamir + discrete log.\n>>>\n>>> it's just something I've been tinkering with and I can't see an obvious\n>>> problem.\n>>>\n>>> It's basically the same as schnorr, but you use a threshold hash to fix\n>>> the need to be online.\n>>>\n>>> Just seems more useful to me.\n>>>\n>>\n>> That sounds very useful if true, but I don't think we should include\n>> novel cryptography in Bitcoin based on your not seeing an obvious problem\n>> with it.\n>>\n>> I'm looking forward to seeing a more complete writeup though.\n>>\n>> Cheers,\n>>\n>> --\n>> Pieter\n>>\n>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180709/0f0198c0/attachment.html>"
            },
            {
                "author": "Dan Robinson",
                "date": "2018-07-09T15:57:07",
                "message_text_only": "Can you please clarify which terms in that description are elliptic curve\npoints, and which are scalars?\nOn Mon, Jul 9, 2018 at 11:10 AM Erik Aronesty via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Actually, it looks like in order to compute a multiparty signature you\n> will need to broadcast shares of r first, so it's not offline :(\n>\n> It is still seems, to me, to be a simpler mechanism than musig - with\n> security assumptions that match the original Schnorr construction more\n> closely, and should therefore be easier to prove secure in a multiparty\n> context.\n>\n> Shamir/Schnorr threshold multi-signature scheme:\n>\n> Each party:\n>\n> - Has a public key g*x', where x' is their private key, and where H(g*x)\n> can be considered their public index for the purposes of Shamir polynomial\n> interpolation\n> - Rolls a random k' and compute r' = g*k'\n> - Broadcast r' as a share\n> - Computes g*k, via lagrange interpolation across shares.   At this point\n> k is not known to any party unless Shamir is vulnerable or DL is not hard\n> - Computes e' = H(M) * r'\n> - Computes s' = k'-x*e'\n> - Share of signature is (s', e')\n>\n> Verification is the same as Scnhorr, but only after using interpolation to\n> get the needed (s, e, g*x) from shares of s', e' and g*x':\n>\n> - Using lagrange interpolation, compute the public key g*x\n> - Again, using lagrange interpolation, compute (s, e)\n> - Verify the signature as per standard Schnorr\n>\n> Security assumptions:\n>\n>  - Because this is not additive, and instead we are using Shamir\n> combination, the additional blinding and masking steps of musig are not\n> needed to create a secure scheme.\n>  - The scheme is the same as Schnorr otherwise\n>  - The only thing to prove is that H(M) * r does not reveal any\n> information about k ... which relies on the same DL assumptions as Bitcoin\n> itself\n>  - Overall, this seems, to me at least, to have a smaller attack surface\n> because there's fewer moving parts\n>\n>\n> On Mon, Jul 9, 2018 at 8:24 AM, Erik Aronesty <erik at q32.com> wrote:\n>\n>> I was hoping that nobody in this group saw an obvious problem with it\n>> then I'd sit down and try to write up a paper.\n>>\n>> Not that hard to just reuse the work done on schnorr.   And demonstrate\n>> that there are no additional assumptions.\n>>\n>\n>> On Mon, Jul 9, 2018, 12:40 AM Pieter Wuille <pieter.wuille at gmail.com>\n>> wrote:\n>>\n>>> On Sun, Jul 8, 2018, 21:29 Erik Aronesty <erik at q32.com> wrote:\n>>>\n>>>> Because it's non-interactive, this construction can produce multisig\n>>>> signatures offline.   Each device produces a signature using it's own\n>>>> k-share and x-share.   It's only necessary to interpolate M of n shares.\n>>>>\n>>>> There are no round trips.\n>>>>\n>>>> The security is Shamir + discrete log.\n>>>>\n>>>> it's just something I've been tinkering with and I can't see an obvious\n>>>> problem.\n>>>>\n>>>> It's basically the same as schnorr, but you use a threshold hash to fix\n>>>> the need to be online.\n>>>>\n>>>> Just seems more useful to me.\n>>>>\n>>>\n>>> That sounds very useful if true, but I don't think we should include\n>>> novel cryptography in Bitcoin based on your not seeing an obvious problem\n>>> with it.\n>>>\n>>> I'm looking forward to seeing a more complete writeup though.\n>>>\n>>> Cheers,\n>>>\n>>> --\n>>> Pieter\n>>>\n>>>\n>>> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180709/d898f72d/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-07-09T15:59:28",
                "message_text_only": "On Mon, Jul 9, 2018 at 3:02 PM, Erik Aronesty via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> with\n> security assumptions that match the original Schnorr construction more\n> closely,\n\nMore closely than what?"
            },
            {
                "author": "Erik Aronesty",
                "date": "2018-07-09T16:33:01",
                "message_text_only": "> More closely than what?\n\nMore closely than musig.\n\nIn fact there's no need to distribute the hash at all if you have the first\nround, you can leave the schnorr construction... thanks for the feedback.\nI literally can't think about this stuff without someone asking questions.\n\n1. For those who asked, the construction from section 7.1 of this paper\ndescribes how to use lagrange interpolation in a group context:\n        http://crypto.stanford.edu/~dabo/papers/homprf.pdf\n\n2. Using shamir interpolation is cleaner than the additive multisig\n\n3. Taking your comments into consideration, I think it's possible to remove\nthe point multiplication instead of a hash and stick to Schnorr \"as is\",\nand still cut out all but one online round:\n\nOK, so this is a new Multisig variant of schnorr with fewer rounds... I\nknow this is possible, I just needed to have that back and forth... sorry:\n\nFor sake of terminology and typing in ascii, I'm using ^ to mean \"point\nmultiplcation\"\n\nEach party:\n\n1. Has a public g^x\n2. Computes and broadcasts g^k' ... where k' is a random number\n3. Computes r = g^k using lagrange interpolation (see\nhttp://crypto.stanford.edu/~dabo/papers/homprf.pdf)\n4. Computes H(r || M), as per standard schnorr\n5. Computes s' = k' - xe , as per standard schnorr .. except k' is a \"share\"\n6. Publish (s', e)\n\nVerification:\n\nWith m of n share-signatures:\n\n1. Use lagrange interpolation on m of n s' shares to get s\n2. Standard schnorr verification\n\n- Erik\n\n\n\n\nOn Mon, Jul 9, 2018 at 11:59 AM, Gregory Maxwell <greg at xiph.org> wrote:\n\n> On Mon, Jul 9, 2018 at 3:02 PM, Erik Aronesty via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > with\n> > security assumptions that match the original Schnorr construction more\n> > closely,\n>\n> More closely than what?\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180709/0db6454e/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-07-09T16:58:38",
                "message_text_only": "On Mon, Jul 9, 2018 at 4:33 PM, Erik Aronesty <erik at q32.com> wrote:\n>>> with security assumptions that match the original Schnorr construction more closely,\n>> More closely than what?\n> More closely than musig.\n\nMusig is instructions on using the original schnorr construction for\nmultiparty signing which is secure against participants adaptively\nchoosing their keys, which is something the naive scheme of just\ninterpolating keys and shares is vulnerable to. It works as\npreprocessing on the keys, then you continue on with the naive\nprotocol. The verifier (e.g. network consensus rules) is the same.\n\nNow that you're back to using a cryptographic hash, I think what\nyou're suggesting is \"use naive interpolation of schnorr signatures\"\n-- which you can do, including with the verifier proposed in the BIP,\nbut doing that alone is insecure against adaptive key choice (and\npotentially adaptive R choice, depending on specifics which aren't\nclear enough to me in your description). In particular, although it\nseems surprising picking your interpolation locations with the hash of\neach key isn't sufficient to prevent cancellation attacks due to the\nremarkable power of wagner's algorithm."
            },
            {
                "author": "Erik Aronesty",
                "date": "2018-07-09T17:59:23",
                "message_text_only": "- Adaptive r choice shouldn't be possible since r is derived from the\noriginal threshold prf and it's not possible for a party to have any\nadaptive impact on the value of r\n - I'm guess I don't see how an attacker can use adaptive key choice in\nthis context either.   Any modification of the key should be useless\nAH!\n\nI forgot to include some assumptions.   The important part here is that\neach party only has a share of the private key and publishes a share of the\npublic key.\n\nThis hopefully should preclude any sort of adaptive key attack.\n\n>From scratch:\n\n1. Has a public g^x'\n2. Computes and broadcasts g^k' ... where k' is a random number\n3. Computes r = g^k using lagrange interpolation (see\nhttp://crypto.stanford.edu/~dabo/papers/homprf.pdf)\n4. Computes H(r || M), as per standard schnorr\n5. Computes s' = k' - xe , as per standard schnorr .. except k' is a \"share\"\n6. Publish (s', e, g^x')\n\nVerification:\n\nWith m of n share-signatures:\n\n1. Interpolation on m of n s' shares to get s\n2. Interpolation on m of n g^x' shares to get g^x\n3. Standard schnorr verification\n\nThe actual public key of the \"set of signers\" is interpolated.\n\n\n\nOn Mon, Jul 9, 2018 at 12:58 PM, Gregory Maxwell <greg at xiph.org> wrote:\n\n> On Mon, Jul 9, 2018 at 4:33 PM, Erik Aronesty <erik at q32.com> wrote:\n> >>> with security assumptions that match the original Schnorr construction\n> more closely,\n> >> More closely than what?\n> > More closely than musig.\n>\n> Musig is instructions on using the original schnorr construction for\n> multiparty signing which is secure against participants adaptively\n> choosing their keys, which is something the naive scheme of just\n> interpolating keys and shares is vulnerable to. It works as\n> preprocessing on the keys, then you continue on with the naive\n> protocol. The verifier (e.g. network consensus rules) is the same.\n>\n> Now that you're back to using a cryptographic hash, I think what\n> you're suggesting is \"use naive interpolation of schnorr signatures\"\n> -- which you can do, including with the verifier proposed in the BIP,\n> but doing that alone is insecure against adaptive key choice (and\n> potentially adaptive R choice, depending on specifics which aren't\n> clear enough to me in your description). In particular, although it\n> seems surprising picking your interpolation locations with the hash of\n> each key isn't sufficient to prevent cancellation attacks due to the\n> remarkable power of wagner's algorithm.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180709/5b9f7929/attachment.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2018-07-10T11:46:17",
                "message_text_only": "Basically you're just replacing addition with interpolation everywhere in\nthe musig construction.\n\nBut maybe I just don't understand how Wagner's algorithm is relevant here.\n\n\n\nOn Mon, Jul 9, 2018, 1:59 PM Erik Aronesty <erik at q32.com> wrote:\n\n>  - Adaptive r choice shouldn't be possible since r is derived from the\n> original threshold prf and it's not possible for a party to have any\n> adaptive impact on the value of r\n>  - I'm guess I don't see how an attacker can use adaptive key choice in\n> this context either.   Any modification of the key should be useless\n> AH!\n>\n> I forgot to include some assumptions.   The important part here is that\n> each party only has a share of the private key and publishes a share of the\n> public key.\n>\n> This hopefully should preclude any sort of adaptive key attack.\n>\n> From scratch:\n>\n> 1. Has a public g^x'\n> 2. Computes and broadcasts g^k' ... where k' is a random number\n> 3. Computes r = g^k using lagrange interpolation (see\n> http://crypto.stanford.edu/~dabo/papers/homprf.pdf)\n> 4. Computes H(r || M), as per standard schnorr\n> 5. Computes s' = k' - xe , as per standard schnorr .. except k' is a\n> \"share\"\n> 6. Publish (s', e, g^x')\n>\n> Verification:\n>\n> With m of n share-signatures:\n>\n> 1. Interpolation on m of n s' shares to get s\n> 2. Interpolation on m of n g^x' shares to get g^x\n> 3. Standard schnorr verification\n>\n> The actual public key of the \"set of signers\" is interpolated.\n>\n>\n>\n> On Mon, Jul 9, 2018 at 12:58 PM, Gregory Maxwell <greg at xiph.org> wrote:\n>\n>> On Mon, Jul 9, 2018 at 4:33 PM, Erik Aronesty <erik at q32.com> wrote:\n>> >>> with security assumptions that match the original Schnorr\n>> construction more closely,\n>> >> More closely than what?\n>> > More closely than musig.\n>>\n>> Musig is instructions on using the original schnorr construction for\n>> multiparty signing which is secure against participants adaptively\n>> choosing their keys, which is something the naive scheme of just\n>> interpolating keys and shares is vulnerable to. It works as\n>> preprocessing on the keys, then you continue on with the naive\n>> protocol. The verifier (e.g. network consensus rules) is the same.\n>>\n>> Now that you're back to using a cryptographic hash, I think what\n>> you're suggesting is \"use naive interpolation of schnorr signatures\"\n>> -- which you can do, including with the verifier proposed in the BIP,\n>> but doing that alone is insecure against adaptive key choice (and\n>> potentially adaptive R choice, depending on specifics which aren't\n>> clear enough to me in your description). In particular, although it\n>> seems surprising picking your interpolation locations with the hash of\n>> each key isn't sufficient to prevent cancellation attacks due to the\n>> remarkable power of wagner's algorithm.\n>>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180710/41640355/attachment-0001.html>"
            },
            {
                "author": "Adam Back",
                "date": "2018-07-11T10:35:08",
                "message_text_only": "On Wed, Jul 11, 2018, 02:42 Erik Aronesty via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n> Basically you're just replacing addition with interpolation everywhere in\nthe musig construction\n\nYes, but you can't do that without a delinearization mechanism to prevent\nadaptive public key choice being used to break the scheme using Wagner's\nattack. It is not specific to addition, it is a generalized birthday attack.\n\nLook at the delinearization mechanism for an intuition, all public keys are\nhashed along with per value hash, so that pre-commits and forces the public\nkeys to be non-adaptively chosen.\n\nAdaptively chosen public keys are dangerous and simple to exploit for\nexample pub keys A+B, add party C' he chooses C=C'-A-B, now we can sign for\nA+B+C using adaptively chose public key C.\n\nBtw Wagner also breaks this earlier delinearization scheme\nS=H(A)*A+H(B)*B+H(C)*C\n\nAdam\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180711/6ff37bd5/attachment.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2018-07-11T14:45:58",
                "message_text_only": "OK, so you're going with this scenario:\n\n1. I know Apub and Bpub,\n2. I know M is 3\n3. I'm choosing a random number for C's private key\n\nCpub is g^C\n\nThe equation I am solving for .. and trying to factor myself out of is g^Ax\n+ g^B*2 + g^C*3\n\nI don't know A or B... I only know their public keys.\n\nI don't think it's possible to adaptively choose C for an attack on the\nmultisig construction, when using hash of the public key as the X\ncoordinate in the polynomial, because in order to satisfy the equation and\nfactor out C, you would need to be able to break the hash.\n\nWith an additive construction, yes... adaptive attacks are possible.   But\nin a shamir secret sharing interpolation, you need a public X coordinate as\nwell as a secret share.   Choosing hash(pub) as X, prevents this attack.\n\n\nOn Wed, Jul 11, 2018 at 6:35 AM, Adam Back <adam.back at gmail.com> wrote:\n\n> On Wed, Jul 11, 2018, 02:42 Erik Aronesty via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > Basically you're just replacing addition with interpolation everywhere\n> in the musig construction\n>\n> Yes, but you can't do that without a delinearization mechanism to prevent\n> adaptive public key choice being used to break the scheme using Wagner's\n> attack. It is not specific to addition, it is a generalized birthday attack.\n>\n> Look at the delinearization mechanism for an intuition, all public keys\n> are hashed along with per value hash, so that pre-commits and forces the\n> public keys to be non-adaptively chosen.\n>\n> Adaptively chosen public keys are dangerous and simple to exploit for\n> example pub keys A+B, add party C' he chooses C=C'-A-B, now we can sign for\n> A+B+C using adaptively chose public key C.\n>\n> Btw Wagner also breaks this earlier delinearization scheme\n> S=H(A)*A+H(B)*B+H(C)*C\n>\n> Adam\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180711/f22cac1f/attachment.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2018-07-19T12:16:04",
                "message_text_only": "Also Wagner's algorithm shouldn't be applicable for a number of reasons.\nyou can't birthday attack something where there's only a single variable\nthat you can modify.    And when you change the equation from additive you\nnow have a multi-dimensional equation we're partitioning won't function.\nthis is the basis of the perfect security of Shamir secret sharing.\n\nOn Wed, Jul 11, 2018, 10:45 AM Erik Aronesty <erik at q32.com> wrote:\n\n> OK, so you're going with this scenario:\n>\n> 1. I know Apub and Bpub,\n> 2. I know M is 3\n> 3. I'm choosing a random number for C's private key\n>\n> Cpub is g^C\n>\n> The equation I am solving for .. and trying to factor myself out of is\n> g^Ax + g^B*2 + g^C*3\n>\n> I don't know A or B... I only know their public keys.\n>\n> I don't think it's possible to adaptively choose C for an attack on the\n> multisig construction, when using hash of the public key as the X\n> coordinate in the polynomial, because in order to satisfy the equation and\n> factor out C, you would need to be able to break the hash.\n>\n> With an additive construction, yes... adaptive attacks are possible.   But\n> in a shamir secret sharing interpolation, you need a public X coordinate as\n> well as a secret share.   Choosing hash(pub) as X, prevents this attack.\n>\n>\n> On Wed, Jul 11, 2018 at 6:35 AM, Adam Back <adam.back at gmail.com> wrote:\n>\n>> On Wed, Jul 11, 2018, 02:42 Erik Aronesty via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> > Basically you're just replacing addition with interpolation everywhere\n>> in the musig construction\n>>\n>> Yes, but you can't do that without a delinearization mechanism to prevent\n>> adaptive public key choice being used to break the scheme using Wagner's\n>> attack. It is not specific to addition, it is a generalized birthday attack.\n>>\n>> Look at the delinearization mechanism for an intuition, all public keys\n>> are hashed along with per value hash, so that pre-commits and forces the\n>> public keys to be non-adaptively chosen.\n>>\n>> Adaptively chosen public keys are dangerous and simple to exploit for\n>> example pub keys A+B, add party C' he chooses C=C'-A-B, now we can sign for\n>> A+B+C using adaptively chose public key C.\n>>\n>> Btw Wagner also breaks this earlier delinearization scheme\n>> S=H(A)*A+H(B)*B+H(C)*C\n>>\n>> Adam\n>>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180719/0ab2aed3/attachment.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2018-07-19T12:24:39",
                "message_text_only": "Probably because my descriptions are a bit vague and rambling.\n\nbut I can't help but think that a SMC of a bitcoin private key, followed by\na secure multiparty computation of a signature is going to be more secure\noverall.\n\nI couldn't figure out how to do it offline.  But one round of exchange\nseems to work.\n\nIt comes down to the blinding factor (k).  All parties need to agree to it\n... which creates the second round.\n\nOn Thu, Jul 19, 2018, 8:16 AM Erik Aronesty <erik at q32.com> wrote:\n\n> Also Wagner's algorithm shouldn't be applicable for a number of reasons.\n> you can't birthday attack something where there's only a single variable\n> that you can modify.    And when you change the equation from additive you\n> now have a multi-dimensional equation we're partitioning won't function.\n> this is the basis of the perfect security of Shamir secret sharing.\n>\n> On Wed, Jul 11, 2018, 10:45 AM Erik Aronesty <erik at q32.com> wrote:\n>\n>> OK, so you're going with this scenario:\n>>\n>> 1. I know Apub and Bpub,\n>> 2. I know M is 3\n>> 3. I'm choosing a random number for C's private key\n>>\n>> Cpub is g^C\n>>\n>> The equation I am solving for .. and trying to factor myself out of is\n>> g^Ax + g^B*2 + g^C*3\n>>\n>> I don't know A or B... I only know their public keys.\n>>\n>> I don't think it's possible to adaptively choose C for an attack on the\n>> multisig construction, when using hash of the public key as the X\n>> coordinate in the polynomial, because in order to satisfy the equation and\n>> factor out C, you would need to be able to break the hash.\n>>\n>> With an additive construction, yes... adaptive attacks are possible.\n>>  But in a shamir secret sharing interpolation, you need a public X\n>> coordinate as well as a secret share.   Choosing hash(pub) as X, prevents\n>> this attack.\n>>\n>>\n>> On Wed, Jul 11, 2018 at 6:35 AM, Adam Back <adam.back at gmail.com> wrote:\n>>\n>>> On Wed, Jul 11, 2018, 02:42 Erik Aronesty via bitcoin-dev <\n>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> > Basically you're just replacing addition with interpolation everywhere\n>>> in the musig construction\n>>>\n>>> Yes, but you can't do that without a delinearization mechanism to\n>>> prevent adaptive public key choice being used to break the scheme using\n>>> Wagner's attack. It is not specific to addition, it is a generalized\n>>> birthday attack.\n>>>\n>>> Look at the delinearization mechanism for an intuition, all public keys\n>>> are hashed along with per value hash, so that pre-commits and forces the\n>>> public keys to be non-adaptively chosen.\n>>>\n>>> Adaptively chosen public keys are dangerous and simple to exploit for\n>>> example pub keys A+B, add party C' he chooses C=C'-A-B, now we can sign for\n>>> A+B+C using adaptively chose public key C.\n>>>\n>>> Btw Wagner also breaks this earlier delinearization scheme\n>>> S=H(A)*A+H(B)*B+H(C)*C\n>>>\n>>> Adam\n>>>\n>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180719/27427750/attachment.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2018-07-19T13:11:28",
                "message_text_only": "On Thu, Jul 19, 2018 at 8:16 AM, Erik Aronesty via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>  you can't birthday attack something where there's only a single variable\n> that you can modify.\n>\n\nWhen engaging in a multiparty signature, the attacker can more than one\nvariable to modify.  When you are party to a multi-party signature (for\nexample, in some sort of coin-join protocol) it could be that every other\nparticipant in the multi-party signature is, in fact, the same single\nattacker representing themselves as multiple participants.  This is how the\nattacker gets their hands on multiple variables.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180719/70bd09ca/attachment-0001.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2018-07-20T16:25:34",
                "message_text_only": "That's a great point.  It's been solved in musig and that doesn't change\nthe m of n multisig construction.\n\nYou use the same musig construction where you hash all keys and sum the\nmultiples....and use that when computing k ... the shared blinding\nfactor.... you're still improving the system .... Getting a nice Shamir m\nof n multisig.... with a single signature...and all the same properties\notherwise.\n\n\nOn Thu, Jul 19, 2018, 9:11 AM Russell O'Connor <roconnor at blockstream.io>\nwrote:\n\n> On Thu, Jul 19, 2018 at 8:16 AM, Erik Aronesty via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>>  you can't birthday attack something where there's only a single variable\n>> that you can modify.\n>>\n>\n> When engaging in a multiparty signature, the attacker can more than one\n> variable to modify.  When you are party to a multi-party signature (for\n> example, in some sort of coin-join protocol) it could be that every other\n> participant in the multi-party signature is, in fact, the same single\n> attacker representing themselves as multiple participants.  This is how the\n> attacker gets their hands on multiple variables.\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180720/ee083e30/attachment-0001.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2018-07-20T17:34:29",
                "message_text_only": "Hi, thanks for all the help.   I'm going to summarize again, and see if\nwe've arrived at the correct solution for an M of N \"single sig\" extension\nof MuSig, which I think we have.\n\n- Using MuSig's solution for the blinding to solve the Wagner attack\n- Using interpolation to enhance MuSig to be M of N instead of M of M\n\nReferences:\n\n - MuSig\nhttps://blockstream.com/2018/01/23/musig-key-aggregation-schnorr-signatures.html\n - HomPrf http://crypto.stanford.edu/~dabo/papers/homprf.pdf (sections 7.1\nand 7.4)\n\nEach party:\n\n1. Publishes public key G*xi\n3. Xi = H(G*xi) ... Xi is the parties x coordinate, for the purposes of\ninterpolation\n3. r = G*x = via interpolation of Gx1, Gx2... (see HomPrf)\n4. L = H(X1,X2,\u2026) (see MuSig)\n5. X = sum of all H(L,Xi)Xi (see MuSig)\n6. Computes e = H(r | M | X) .... standard schnorr e... not a share\n7. Computes si = xi - xe ... where si is a \"share\" of the sig, and xi is\nthe private data\n8. Publishes (si, e, G*Xi)\n\nAny party can then derive s from m of n shares, by interpolating, not\nadding.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180720/f3f8901d/attachment-0001.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2018-07-20T20:18:47",
                "message_text_only": "Sorry there were typos:\n\n- Using MuSig's solution for the blinding factor (e)\n- Using interpolation to enhance MuSig to be M of N instead of M of M\n\nReferences:\n\n - MuSig https://blockstream.com/2018/01/23/musig-key-aggregation-\nschnorr-signatures.html\n - HomPrf http://crypto.stanford.edu/~dabo/papers/homprf.pdf (sections 7.1\nand 7.4)\n\nEach party:\n\n1. Publishes public key G*xi, G*ki, where ki is a random nonce\n3. Xi = H(G*xi) ... Xi is the parties x coordinate, for the purposes of\ninterpolation\n3. R = G*k = via interpolation of r1=Gk1, r2=Gk2... (see HomPrf)\n4. L = H(X1,X2,\u2026) (see MuSig)\n5. X = sum of all H(L,Xi)Xi (see MuSig)\n6. Computes e = H(R | M | X) .... standard schnorr e... not a share\n7. Computes si = ki *e+ xi * e ... where si is a \"share\" of the sig, and xi\nis the private data, and e is the blinding factor\n8. Publishes (si, e) as the share sig\n\nIf an attacker has multiple devices, e is safe, because of the musig\nconstruction.\n\nBut what protects k from the same multiparty birthday attack?\n\nIf an attacker has multiple devices, by carefully controlling the selection\nof private keys, the attacker can try to solve\nthe polynomial equation to force the selection of a \"known k\".\n\nA \"known k\" would allow an attacker to sign messages on his own.\n\nTo fix this, we need to somehow \"blind k as well\".\n\nDoes this work?\n\nThe revision below seems to solve this problem.\n\n1. Publishes public key G*xi, G*ki, where ki is a random nonce\n3. Xi = H(G*xi) ... Xi is the parties x coordinate, for the purposes of\ninterpolation\n3. R = G*k = via interpolation of r1=Gk1, r2=Gk2... (see HomPrf)\n4. L = H(X1,X2,\u2026) (see MuSig)\n5. L2 = H2(XN,XN-1,\u2026) (see MuSig... H2 is a \"second hash\")\n6. X = sum of all H(L,Xi)Xi (see MuSig)\n7. Computes e = H(R | M | X) .... standard schnorr e... not a share\n8. Computes e2 = H(R | M | X2) ... a second blinding factor\n9. Computes si = ki *e2 + xi * e ... where si is a \"share\" of the sig, and\nxi is the private data, and e, e2 are blinding factors\n10. Publishes (si, e, e2) as the share sig\n\nThe final signature is computed via interpolation, and e2 is can be\nsubtracted to recover a \"normal\" schnor sig for the set of participants.\n\nNow there's no mechanism for a birthday attack on k.\n\n\n\nOn Fri, Jul 20, 2018 at 1:34 PM, Erik Aronesty <erik at q32.com> wrote:\n\n> Hi, thanks for all the help.   I'm going to summarize again, and see if\n> we've arrived at the correct solution for an M of N \"single sig\" extension\n> of MuSig, which I think we have.\n>\n> - Using MuSig's solution for the blinding to solve the Wagner attack\n> - Using interpolation to enhance MuSig to be M of N instead of M of M\n>\n> References:\n>\n>  - MuSig https://blockstream.com/2018/01/23/musig-key-aggregation-\n> schnorr-signatures.html\n>  - HomPrf http://crypto.stanford.edu/~dabo/papers/homprf.pdf (sections\n> 7.1 and 7.4)\n>\n> Each party:\n>\n> 1. Publishes public key G*xi\n> 3. Xi = H(G*xi) ... Xi is the parties x coordinate, for the purposes of\n> interpolation\n> 3. r = G*x = via interpolation of Gx1, Gx2... (see HomPrf)\n> 4. L = H(X1,X2,\u2026) (see MuSig)\n> 5. X = sum of all H(L,Xi)Xi (see MuSig)\n> 6. Computes e = H(r | M | X) .... standard schnorr e... not a share\n> 7. Computes si = xi - xe ... where si is a \"share\" of the sig, and xi is\n> the private data\n> 8. Publishes (si, e, G*Xi)\n>\n> Any party can then derive s from m of n shares, by interpolating, not\n> adding.\n>\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180720/69dcd246/attachment-0001.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2018-07-26T02:05:05",
                "message_text_only": "Also we don't need any new opcodes to support this.  Done right this could\nliterally go out into clients immediately.\n\nOn Fri, Jul 20, 2018, 4:18 PM Erik Aronesty <erik at q32.com> wrote:\n\n> Sorry there were typos:\n>\n> - Using MuSig's solution for the blinding factor (e)\n> - Using interpolation to enhance MuSig to be M of N instead of M of M\n>\n> References:\n>\n>  - MuSig\n> https://blockstream.com/2018/01/23/musig-key-aggregation-schnorr-signatures.html\n>  - HomPrf http://crypto.stanford.edu/~dabo/papers/homprf.pdf (sections\n> 7.1 and 7.4)\n>\n> Each party:\n>\n> 1. Publishes public key G*xi, G*ki, where ki is a random nonce\n> 3. Xi = H(G*xi) ... Xi is the parties x coordinate, for the purposes of\n> interpolation\n> 3. R = G*k = via interpolation of r1=Gk1, r2=Gk2... (see HomPrf)\n> 4. L = H(X1,X2,\u2026) (see MuSig)\n> 5. X = sum of all H(L,Xi)Xi (see MuSig)\n> 6. Computes e = H(R | M | X) .... standard schnorr e... not a share\n> 7. Computes si = ki *e+ xi * e ... where si is a \"share\" of the sig, and\n> xi is the private data, and e is the blinding factor\n> 8. Publishes (si, e) as the share sig\n>\n> If an attacker has multiple devices, e is safe, because of the musig\n> construction.\n>\n> But what protects k from the same multiparty birthday attack?\n>\n> If an attacker has multiple devices, by carefully controlling the\n> selection of private keys, the attacker can try to solve\n> the polynomial equation to force the selection of a \"known k\".\n>\n> A \"known k\" would allow an attacker to sign messages on his own.\n>\n> To fix this, we need to somehow \"blind k as well\".\n>\n> Does this work?\n>\n> The revision below seems to solve this problem.\n>\n> 1. Publishes public key G*xi, G*ki, where ki is a random nonce\n> 3. Xi = H(G*xi) ... Xi is the parties x coordinate, for the purposes of\n> interpolation\n> 3. R = G*k = via interpolation of r1=Gk1, r2=Gk2... (see HomPrf)\n> 4. L = H(X1,X2,\u2026) (see MuSig)\n> 5. L2 = H2(XN,XN-1,\u2026) (see MuSig... H2 is a \"second hash\")\n> 6. X = sum of all H(L,Xi)Xi (see MuSig)\n> 7. Computes e = H(R | M | X) .... standard schnorr e... not a share\n> 8. Computes e2 = H(R | M | X2) ... a second blinding factor\n> 9. Computes si = ki *e2 + xi * e ... where si is a \"share\" of the sig, and\n> xi is the private data, and e, e2 are blinding factors\n> 10. Publishes (si, e, e2) as the share sig\n>\n> The final signature is computed via interpolation, and e2 is can be\n> subtracted to recover a \"normal\" schnor sig for the set of participants.\n>\n> Now there's no mechanism for a birthday attack on k.\n>\n>\n>\n> On Fri, Jul 20, 2018 at 1:34 PM, Erik Aronesty <erik at q32.com> wrote:\n>\n>> Hi, thanks for all the help.   I'm going to summarize again, and see if\n>> we've arrived at the correct solution for an M of N \"single sig\" extension\n>> of MuSig, which I think we have.\n>>\n>> - Using MuSig's solution for the blinding to solve the Wagner attack\n>> - Using interpolation to enhance MuSig to be M of N instead of M of M\n>>\n>> References:\n>>\n>>  - MuSig\n>> https://blockstream.com/2018/01/23/musig-key-aggregation-schnorr-signatures.html\n>>  - HomPrf http://crypto.stanford.edu/~dabo/papers/homprf.pdf (sections\n>> 7.1 and 7.4)\n>>\n>> Each party:\n>>\n>> 1. Publishes public key G*xi\n>> 3. Xi = H(G*xi) ... Xi is the parties x coordinate, for the purposes of\n>> interpolation\n>> 3. r = G*x = via interpolation of Gx1, Gx2... (see HomPrf)\n>> 4. L = H(X1,X2,\u2026) (see MuSig)\n>> 5. X = sum of all H(L,Xi)Xi (see MuSig)\n>> 6. Computes e = H(r | M | X) .... standard schnorr e... not a share\n>> 7. Computes si = xi - xe ... where si is a \"share\" of the sig, and xi is\n>> the private data\n>> 8. Publishes (si, e, G*Xi)\n>>\n>> Any party can then derive s from m of n shares, by interpolating, not\n>> adding.\n>>\n>>\n>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180725/7362f800/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-07-09T16:21:59",
                "message_text_only": "On Mon, Jul 9, 2018 at 3:02 PM, Erik Aronesty via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> and where H(g*x) can\n> be considered their public index for the purposes of Shamir polynomial\n> interpolation\n\nThis is isomorphic to the insecure musig variant where keys are\nblinded by H(g*x) instead of a commitment to all keys. It is insecure\nbecause it vulnerable to an attacker knowing a victim pubkey P  who\nuses wagner's algorithim to solve a random modular subset sum problem:\n-1H(P) = H(aP)/a + H(bP)/b + H(cP)/c + ... for some a,b,c...  then\nclaiming to be participants with keys aP, bP, cP, ..., xG (their own\nkey) and canceling out key P, allowing the value to just be signed for\nwith their key alone.\n\nAFAICT your suggestion is using simple multiplication in the place of\na cryptographic hash.  E.g.  you have just suggested a schnorr\nsignature where H() is  just r*m in the field of size n. It doesn't\nhave any new properties about how you can use it. The same linearities\ndo and don't apply as the normal schnorr construction, but for any of\nthe security proofs to hold we'd have to believe that multiplication\nin the field of n is a suitable random oracle-- which is not very\nplausible."
            }
        ],
        "thread_summary": {
            "title": "Multiparty signatures",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Adam Back",
                "Tim Ruffing",
                "Russell O'Connor",
                "Erik Aronesty",
                "Gregory Maxwell",
                "Dan Robinson",
                "Pieter Wuille"
            ],
            "messages_count": 26,
            "total_messages_chars_count": 44526
        }
    },
    {
        "title": "[bitcoin-dev] Creating smaller testnet blocks",
        "thread_messages": [
            {
                "author": "rhavar at protonmail.com",
                "date": "2018-07-08T17:30:23",
                "message_text_only": "More of a shower-thought, but I am currently working on a bitcoin wallet that is designed to handle \"free pressure\" properly (e.g. CPFP aware, transaction merging, automated progressive fee bumping, etc) and one kind of annoying thing is that there really is no fee market on testnet.\n\nI was thinking it would be cool if tesnet blocks were a bit smaller, so they didn't just mine the entire mempool each block. A full-blown softfork on testnet seems overkill, but just changing the default mining maxBlockWeight to something like 50% of the current mempool weight would help test things and help wallet developers fixing things like \"stuck transactions\" and what not.  (And of course some miners will not use the default, but it's not really a big deal..)\n\n-Ryan\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180708/b0d63a30/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Creating smaller testnet blocks",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "rhavar at protonmail.com"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 945
        }
    },
    {
        "title": "[bitcoin-dev] Weekly IRC Meeting Time Poll",
        "thread_messages": [
            {
                "author": "Cory Fields",
                "date": "2018-07-10T20:24:15",
                "message_text_only": "Hi all\n\nThis is a bit offtopic for bitcoin-dev, but I'm sending here since\nmany core devs are subscribed.\n\nAs discussed in last week's meeting, it would be helpful to have an\nidea of what times devs are generally available to meet online. With\nbetter data, we could potentially reschedule the weekly IRC meetings\nto a time that would exclude fewer people.\n\nI've thrown together a quick poll, please watch for a mail from\ncivs at cs.cornell.edu and follow the link to vote. To keep it simple,\nthe day of the week (Thursday) is fixed for now.\n\nThe initial list of voters is based on previous meeting participation.\nIf you regularly attend the weekly meetings (or can't now but may be\nable to attend at a different time), but do not receive a link to vote\nin the next hour, please reply here or ping me on IRC so that I may\nadd you.\n\nPolling will conclude at the end of the scheduled IRC meeting on July 19.\n\nRegards,\nCory"
            },
            {
                "author": "Simon Selitsky",
                "date": "2018-07-10T23:17:56",
                "message_text_only": "Cory,\n\nPlease send me a link to vote.\n\nThanks !\n\n> On Jul 10, 2018, at 4:24 PM, Cory Fields via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Hi all\n> \n> This is a bit offtopic for bitcoin-dev, but I'm sending here since\n> many core devs are subscribed.\n> \n> As discussed in last week's meeting, it would be helpful to have an\n> idea of what times devs are generally available to meet online. With\n> better data, we could potentially reschedule the weekly IRC meetings\n> to a time that would exclude fewer people.\n> \n> I've thrown together a quick poll, please watch for a mail from\n> civs at cs.cornell.edu and follow the link to vote. To keep it simple,\n> the day of the week (Thursday) is fixed for now.\n> \n> The initial list of voters is based on previous meeting participation.\n> If you regularly attend the weekly meetings (or can't now but may be\n> able to attend at a different time), but do not receive a link to vote\n> in the next hour, please reply here or ping me on IRC so that I may\n> add you.\n> \n> Polling will conclude at the end of the scheduled IRC meeting on July 19.\n> \n> Regards,\n> Cory\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "mark M",
                "date": "2018-07-11T01:35:32",
                "message_text_only": "What\u2019s the irc channel address   \n  \n\n  \n  \n\n  \n  \n>   \n> On Jul 11, 2018 at 4:47 AM,  <Simon Selitsky via bitcoin-dev (mailto:bitcoin-dev at lists.linuxfoundation.org)>  wrote:\n>   \n>   \n>   \n>  Cory,  \n>\n> Please send me a link to vote.  \n>\n> Thanks !  \n>\n> >  On Jul 10, 2018, at 4:24 PM, Cory Fields via bitcoin-dev  <bitcoin-dev at lists.linuxfoundation.org>  wrote:  \n> >   \n> >  Hi all  \n> >   \n> >  This is a bit offtopic for bitcoin-dev, but I'm sending here since  \n> >  many core devs are subscribed.  \n> >   \n> >  As discussed in last week's meeting, it would be helpful to have an  \n> >  idea of what times devs are generally available to meet online. With  \n> >  better data, we could potentially reschedule the weekly IRC meetings  \n> >  to a time that would exclude fewer people.  \n> >   \n> >  I've thrown together a quick poll, please watch for a mail from  \n> >  civs at cs.cornell.edu and follow the link to vote. To keep it simple,  \n> >  the day of the week (Thursday) is fixed for now.  \n> >   \n> >  The initial list of voters is based on previous meeting participation.  \n> >  If you regularly attend the weekly meetings (or can't now but may be  \n> >  able to attend at a different time), but do not receive a link to vote  \n> >  in the next hour, please reply here or ping me on IRC so that I may  \n> >  add you.  \n> >   \n> >  Polling will conclude at the end of the scheduled IRC meeting on July 19.  \n> >   \n> >  Regards,  \n> >  Cory  \n> >  _______________________________________________  \n> >  bitcoin-dev mailing list  \n> >  bitcoin-dev at lists.linuxfoundation.org  \n> >  https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev  \n> _______________________________________________  \n> bitcoin-dev mailing list  \n> bitcoin-dev at lists.linuxfoundation.org  \n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev  \n>              \n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180711/12c743fc/attachment.html>"
            },
            {
                "author": "Cory Fields",
                "date": "2018-07-11T22:15:19",
                "message_text_only": "Hi Simon\n\nThe poll is intended for regular Bitcoin Core contributors, who meet\nonce a week to discuss what they're working on. It is a mundane\nsoftware meeting, unrelated to the research and discussion of Bitcoin\nitself. The meetings are open to all, but it makes sense to constrain\nscheduling decisions to the current active contributors. If you'd like\nto attend but are unable, meeting transcripts are always made\navailable online afterwards.\n\nPlease see the Contributing doc [0] if you're interested in becoming a\nregular contributor to Bitcoin Core :)\n\nRegards,\nCory\n\n0: https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md\n\nOn Tue, Jul 10, 2018 at 7:17 PM, Simon Selitsky <simon at coingyft.com> wrote:\n> Cory,\n>\n> Please send me a link to vote.\n>\n> Thanks !\n>\n>> On Jul 10, 2018, at 4:24 PM, Cory Fields via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> Hi all\n>>\n>> This is a bit offtopic for bitcoin-dev, but I'm sending here since\n>> many core devs are subscribed.\n>>\n>> As discussed in last week's meeting, it would be helpful to have an\n>> idea of what times devs are generally available to meet online. With\n>> better data, we could potentially reschedule the weekly IRC meetings\n>> to a time that would exclude fewer people.\n>>\n>> I've thrown together a quick poll, please watch for a mail from\n>> civs at cs.cornell.edu and follow the link to vote. To keep it simple,\n>> the day of the week (Thursday) is fixed for now.\n>>\n>> The initial list of voters is based on previous meeting participation.\n>> If you regularly attend the weekly meetings (or can't now but may be\n>> able to attend at a different time), but do not receive a link to vote\n>> in the next hour, please reply here or ping me on IRC so that I may\n>> add you.\n>>\n>> Polling will conclude at the end of the scheduled IRC meeting on July 19.\n>>\n>> Regards,\n>> Cory\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            }
        ],
        "thread_summary": {
            "title": "Weekly IRC Meeting Time Poll",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Simon Selitsky",
                "mark M",
                "Cory Fields"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 6354
        }
    },
    {
        "title": "[bitcoin-dev] Transaction Coins",
        "thread_messages": [
            {
                "author": "PJ Fitzpatrick",
                "date": "2018-07-12T08:05:42",
                "message_text_only": "I am considering a method to derive digital scarcity from bitcoin\ntransactions. Coins are created from transactions if their hash is among\nthe closest n to the non zero portion of the block hash. Only a single coin\ncan be created per transaction irrespective of the size of the transaction.\nTherefore n coins are created per block.\n\nThe initial coin supply and addresses can be fully determined by the\nexisting blockchain. Additionally coins are scarce as coins can only be\nproduced by transactions.\n\nThere are a number of variants such as creating computation puzzles from\nthe previous block.\n\nHas anyone seen anything similar.\n\n\nPJ Fitzpatrick\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180712/70e6df74/attachment.html>"
            },
            {
                "author": "Jakub Trnka",
                "date": "2018-07-13T00:27:31",
                "message_text_only": "I think building some overlay scarcity and value on top of bitcoin blockchain would incentivize people to transact a lot. An equilibrium would emerge between paying transaction fees and mining new coins. Which would effectively be equivalent to selling bitcoin and buying some mergemined altcoin, except this would congest the bitcoin network. You can easily borrow scarcity from bitcoin in some sidechain.\n\nJakub Trnka\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn 12 July 2018 10:05 AM, PJ Fitzpatrick via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I am considering a method to derive digital scarcity from bitcoin transactions. Coins are created from transactions if their hash is among the closest n to the non zero portion of the block hash. Only a single coin can be created per transaction irrespective of the size of the transaction. Therefore n coins are created per block.\n>\n> The initial coin supply and addresses can be fully determined by the existing blockchain. Additionally coins are scarce as coins can only be produced by transactions.\n>\n> There are a number of variants such as creating computation puzzles from the previous block.\n>\n> Has anyone seen anything similar.\n>\n> PJ Fitzpatrick\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180712/adf92377/attachment-0001.html>"
            },
            {
                "author": "PJ Fitzpatrick",
                "date": "2018-07-13T10:11:27",
                "message_text_only": "On Fri, Jul 13, 2018 at 1:27 AM Jakub Trnka <jakub.trnka at chainanalytics.net>\nwrote:\n\n> I think building some overlay scarcity and value on top of bitcoin\n> blockchain would incentivize people to transact a lot. An equilibrium would\n> emerge between paying transaction fees and mining new coins. Which would\n> effectively be equivalent to selling bitcoin and buying some mergemined\n> altcoin, except this would congest the bitcoin network. You can easily\n> borrow scarcity from bitcoin in some sidechain.\n>\n\nYes  what you say is correct. Therefore n could be a function of the\ntransaction fees of the block. I think this should be on bitcointalk and I\nam going to start a discussion there.\nPJ Fitzpatrick\n\n\n> Jakub Trnka\n>\n>\n> Sent with ProtonMail <https://protonmail.com> Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On 12 July 2018 10:05 AM, PJ Fitzpatrick via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> I am considering a method to derive digital scarcity from bitcoin\n> transactions. Coins are created from transactions if their hash is among\n> the closest n to the non zero portion of the block hash. Only a single coin\n> can be created per transaction irrespective of the size of the transaction.\n> Therefore n coins are created per block.\n>\n> The initial coin supply and addresses can be fully determined by the\n> existing blockchain. Additionally coins are scarce as coins can only be\n> produced by transactions.\n>\n> There are a number of variants such as creating computation puzzles from\n> the previous block.\n>\n> Has anyone seen anything similar.\n>\n>\n> PJ Fitzpatrick\n>\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180713/d335ddde/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Transaction Coins",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "PJ Fitzpatrick",
                "Jakub Trnka"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 4103
        }
    },
    {
        "title": "[bitcoin-dev] Generalised taproot",
        "thread_messages": [
            {
                "author": "Anthony Towns",
                "date": "2018-07-13T01:51:57",
                "message_text_only": "On Fri, Jan 26, 2018 at 09:34:39PM +0000, Gregory Maxwell via bitcoin-dev wrote:\n> I ask because recursive taproot by itself isn't very interesting,\n> since (other than accountability) there is no gain to not just merging\n> the alternative, but if there are additional conditions then it can be\n> useful. E.g.\n> \n> [pubkey]\n>       \\-[pubkey]&&CSV\n>              \\-[fancy script]\n\nI think it's possible to do recursive taproot in this manner in a\nneat way, using Pedersen Commitments. \n\n(Background: A Pedersen commitment uses a second generator in the curve,\nand rather than constructing a point from a single secret, like A=a*G,\nit constructs a point from two secrets, like C=a*G+b*G2, and finding a\ndifferent c,d such that C=c*G+d*G2 gives you the discrete log of G2)\n\nSo combining this with the taproot structure gives an equation like:\n\n  P = a*G + s*G2 + H(a*G+s*G2, Q)*G\n\nIf you take \"a\" to be a private key (so A=a*G is the corresponding\npubkey), \"s\" to be (the hash of) a set of additional conditions for\nspending with the pubkey, and \"Q\" to be an alternative method of spending,\nyou get a recursive taproot construction.\n\nTo spend \"P\", you would either:\n\n  - sign with P directly (only possible if s=0, indicating there are no\n    additional conditions to satisfy when spending with this key)\n\n  - reveal the extra conditions you have to satisfy (s), satisfy\n    them, and provide a signature the key \"P-s*G2\"\n\n  - reveal the points \"a*G+s*G2\" and \"Q\", and satisfy \"Q\"\n\nIf you structure the conditions as:\n\n  (pubkey A) |\n    (pubkey B & script x) |\n      (pubkey C & script y) |\n        (merkle tree of scripts, root=z)\n\nThen you can construct a pubkey point as:\n\n   D' = z\n   C' = C + y*G2 + H(C+y*G2, D')*G\n   B' = B + x*G2 + H(B+x*G2, C')*G\n   A' = A + H(A, B')*G\n\nand if you want to spend something with a scriptPubKey of A', you could\nuse:\n\n   (1) plain signature with privkey = a+H(A,B')\n\n   (2) reveal [A, B'], reveal [x], provide [witness(x)],\n       signature with privkey = b+H(B+x*G2,C')\n\n   (3) reveal [A, B'], reveal [B+x*G2, C'], reveal [y], provide\n       [witness(y)], signature with privkey = c+H(C+y*G2, D')\n\n   (4) reveal [A, B'], reveal [B+x*G2, C'], reveal [C+y*G2],\n       reveal [script], reveal merkle path from script to z,\n       provide [witness(script)].\n\nThat way, you can keep two sets of things secret:\n\n - until you hit the merkle-tree of scripts, you don't reveal\n   whether there are or aren't any lower layers\n\n - you don't reveal the conditions corresponding with any of the\n   keys, other than the key you're spending with\n\nThis is as (space) efficient as basic taproot:\n\n  taproot: P + H(P, [Q CHECKSIGVERIFY cond]) \n  witness:\n    (1) sig(P)\n    (2) P [Q CHECKSIGVERIFY cond] sig(Q) witness(cond)\n\nbecomes:\n\n  g'root: P + H(P, Q + cond*G2)*G\n  witness:\n    (1) sig(P+H(..)*G)\n    (2) P Q sig(Q) cond witness(cond)\n\n[0]\n\nIt's potentially more efficient for cases where the taproot assumption\ndoesn't hold, and the common case is to spend with conditions:\n\n  g'root: P + cond*G2 + H(P+cond*G2, Q)*G\n  witness:\n    (1) cond witness(cond) sig(P+H(..)*G)\n    (2) [P+cond*G2] Q sig(Q)\n\n  taproot: Q + H(Q, [P checksig cond])*G\n    (1) Q [P CHECKSIG cond] [sig(P) witness(cond)]   (64 bytes overhead)\n    (2) sig(Q+H(..)*G)                               (64 bytes saved)\n\nIt's also potentially more efficient than using a merkle tree with taproot\nwhen there are three spending paths, and one merkle branch is more likely\nthan the other, eg, if the conditions are \"sign with A\", or \"sign with\nB and satisfy x\", or (least likely) \"sign with C and satisfy y\":\n\nLet s = [B CHECKSIGVERIFY x], t = [C CHECKSIGVERIFY y], r = H(H(s),H(t))\n\n taproot+MAST: A + H(A,r)*G\n  (1t) sig(A+H(..)*G)\n  (2t) A,s,H(t),sig(B),witness(x)\n  (3t) A,t,H(s),sig(C),witness(y)\n\n g'root: A', where:\n           C' = C + y*G2\n           B' = B + x*G2 + H(B+x*G2,C')*G\n           A' = A + H(A,B')*G\n  (1g) sig(A+H(..)*G)\n  (2g) A B' x sig(B'-x*G2) witness(x)\n  (3g) A B' [B+x*G2] C' y sig(C) witness(y)\n\n(1t) and (1g) are the same; (2t) is about 32B larger than (2g) because\ns=[B x], and  (3t) is about 32B smaller than (3g) because the g'root\ndescent reveals two additional points.\n\n(As far as deployment goes, I think it makes sense to get an initial\nschnorr/taproot/mast deployment out first, and add graftroot/aggregation\nlater. My feeling is there's no great urgency for generalised taproot, so\nit would make sense to keep doing schnorr/taproot/mast for now, take time\nanalysing generalised taproot, and if it seems sane and useful, aim to\nenable it in a later phase, eg at the same time as graftroot/aggregation)\n\nCheers,\naj\n\n[0] My inital name for these was \"MAST-ended sc'roots\", since it\n    combines \"taproot\" and \"scripts\" and something MAST-like but only\n    at the very end, but I was warned that the Mimblewimble folks have\n    vast teams monitoring for Harry Potter references and will DMCA me,\n    which I assume stands for \"Dementors, Ministry, Cruciatus and Avada\n    kedavra\"... So I'm abbreviating generalised taproot as \"g'root\"\n    instead. After all, what's the worst the Marvel guys could do?"
            }
        ],
        "thread_summary": {
            "title": "Generalised taproot",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Anthony Towns"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 5128
        }
    },
    {
        "title": "[bitcoin-dev] v0.16.1 test_bitcoin fails on Deian 9",
        "thread_messages": [
            {
                "author": "Shigeya Suzuki",
                "date": "2018-07-14T13:48:59",
                "message_text_only": "Hi,\n\nI observed strange result when running src/test/test_bitcoin on Debian 9.\n\nI tested with the following platforms:\n\n1) OS X High Sierra 10.13.6 with\n   ./configiure --enable-debug\n\n2) Debian 9 (with latest packages) with \n   ./configure --enable-debug --disable-wallet --without-gui\n\n3) Ubuntu 16.04 with:\n   ./configure --with-debug --disable-wallet\n\nstrangely,  configuration 2 cause core dump but others not:\n\nRunning 264 test cases...\nunknown location(0): fatal error: in \"validation_block_tests/processnewblock_signals_ordering\": memory access violation at address: 0x00000000: no mapping at fault address\nzsh: segmentation fault  ./test_bitcoin\n\nI guess it is due to toolchain differences.\n\nAny thoughts?\n\nShigeya Suzuki"
            },
            {
                "author": "Marco Falke",
                "date": "2018-07-14T15:23:43",
                "message_text_only": "Hi, and thanks for the detailed issue report.\n\nThis was a known issue in test code that is only compiled when\ndebugging. It will be fixed in the upcoming 0.16.2 and 0.17.0\nreleases.\n\nIf you see any further issues, note that we track technical issues\nrelated to the Bitcoin Core code base on our issue tracker:\nhttps://github.com/bitcoin/bitcoin/issues/new\n\nMarco\n\nOn Sat, Jul 14, 2018 at 9:48 AM, Shigeya Suzuki via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Hi,\n>\n> I observed strange result when running src/test/test_bitcoin on Debian 9.\n>\n> I tested with the following platforms:\n>\n> 1) OS X High Sierra 10.13.6 with\n>    ./configiure --enable-debug\n>\n> 2) Debian 9 (with latest packages) with\n>    ./configure --enable-debug --disable-wallet --without-gui\n>\n> 3) Ubuntu 16.04 with:\n>    ./configure --with-debug --disable-wallet\n>\n> strangely,  configuration 2 cause core dump but others not:\n>\n> Running 264 test cases...\n> unknown location(0): fatal error: in \"validation_block_tests/processnewblock_signals_ordering\": memory access violation at address: 0x00000000: no mapping at fault address\n> zsh: segmentation fault  ./test_bitcoin\n>\n> I guess it is due to toolchain differences.\n>\n> Any thoughts?\n>\n> Shigeya Suzuki\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Shigeya Suzuki",
                "date": "2018-07-14T15:35:00",
                "message_text_only": "Hi, \n\nI see. thank you very much.\n\nshigeya\n\nOn Sun, Jul 15, 2018, at 00:23, Marco Falke via bitcoin-dev wrote:\n> Hi, and thanks for the detailed issue report.\n> \n> This was a known issue in test code that is only compiled when\n> debugging. It will be fixed in the upcoming 0.16.2 and 0.17.0\n> releases.\n> \n> If you see any further issues, note that we track technical issues\n> related to the Bitcoin Core code base on our issue tracker:\n> https://github.com/bitcoin/bitcoin/issues/new\n> \n> Marco\n> \n> On Sat, Jul 14, 2018 at 9:48 AM, Shigeya Suzuki via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > Hi,\n> >\n> > I observed strange result when running src/test/test_bitcoin on Debian 9.\n> >\n> > I tested with the following platforms:\n> >\n> > 1) OS X High Sierra 10.13.6 with\n> >    ./configiure --enable-debug\n> >\n> > 2) Debian 9 (with latest packages) with\n> >    ./configure --enable-debug --disable-wallet --without-gui\n> >\n> > 3) Ubuntu 16.04 with:\n> >    ./configure --with-debug --disable-wallet\n> >\n> > strangely,  configuration 2 cause core dump but others not:\n> >\n> > Running 264 test cases...\n> > unknown location(0): fatal error: in \"validation_block_tests/processnewblock_signals_ordering\": memory access violation at address: 0x00000000: no mapping at fault address\n> > zsh: segmentation fault  ./test_bitcoin\n> >\n> > I guess it is due to toolchain differences.\n> >\n> > Any thoughts?\n> >\n> > Shigeya Suzuki\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            }
        ],
        "thread_summary": {
            "title": "v0.16.1 test_bitcoin fails on Deian 9",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Shigeya Suzuki",
                "Marco Falke"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 3982
        }
    },
    {
        "title": "[bitcoin-dev] URI scheme with optional bech32 address",
        "thread_messages": [
            {
                "author": "Federico Tenga",
                "date": "2018-07-24T12:05:27",
                "message_text_only": "Hello everyone,\n\nWith my team we are working on a walleting application which ideally will\ngenerate a bech32 address when receiving from a bech32 compatible wallet,\nand a P2WPKH-nested-in-P2SH address when receiving for a legacy wallet.\nHowever, it is of course impossible for the payee to know in advance the\ntechnological capabilities of the payer, so a solution could be to encode\nin a Bitcoin URI both bech32 and P2SH addresses in a way that legacy\nwallets only see the P2SH address, while new wallets can also see the\nbech32 address and use it to perform the transaction.\n\nIn particular, to keep compatibility with BIP21, the <address> field of the\nURI can be used for the P2WPKH-nested-in-P2SH address and a new field (e.g.\n<segwitaddress> or <bech32address>), which will be ignored by legacy\nwallets, can be used to encode the bech32 address. The assumption here is\nthat the wallets using such scheme will monitor incoming transaction both\non the P2SH address and on the bech32 address.\n\nI did some research around and I did not find any proposal addressing the\nsame issue, so my questions are (i) does anybody already proposed something\ngoing in the same direction and (ii) do you see any major drawback in the\nBIP21 compatible scheme proposed in this message?\n\nThanks in advance,\n\nFederico\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180724/28e07878/attachment.html>"
            },
            {
                "author": "vv01f",
                "date": "2018-07-24T23:44:35",
                "message_text_only": "When I use the example of HTML forms \u2026\n\n```test.html\n<!DOCTYPE html>\n<html><head><title>test for URI schema</title>\n<body><form method=\"get\" action=\"./test.html\">\n<select multiple name=\"attr\">\n<option value=\"val1\" selected>1</option>\n<option value=\"val2\" selected>2</option>\n<option value=\"val3\">3</option>\n</select>\n<input type=\"submit\" value=\"send\" />\n</form></body></head></html>\n```\n\nThe resulting URI is:\nfile:///tmp/test.html?attr=val1&attr=val2\n\nThat means that a URI attribute is not necessarily singular and can\nindeed occur multiple times.\n\nSo as we do not have athority in our URI\u2026\nfor URI = scheme:path[?query][#fragment]\nwhere query=[key1=value1[&key2=value2]]\n\n\u2026under the circumstance that path has a newer standard we can implement\nfallback with: query=[path=newerversion[&path=evennewerversion]]\n\n\u2026as our path is the address, resulting in e.g.:\nbitcoin:p2pkh?[amount=value][&address=p2sh][&address=p2sh-p2wpkh][&address=bech32]\n\nthe effect should be\n\n1. old clients ignore address attribute\n2. supporting clients select the address attribute over the address\ngiven in path *if* they support the format\n3. future address formats do not need a new attribute\n\nopen to me would be:\n* the order of the attributes and how this should be recognized/priorized\n* is there any precedence for that multiple use of an attribute in URI\nschemes?\n\nI think order of attributes should remain irrelevant, thus supporting\nclients should check all attributes of the same name and attributes\nshould be defined for repetitive (like address) or not (amount) in the\nBIP. This will still not support sending different amounts to multiple\naddresses and be consistent with the older version of the URI scheme.\n\nOn 24.07.2018 14:05, Federico Tenga via bitcoin-dev wrote:\n> Hello everyone,\n> \n> With my team we are working on a walleting application which ideally will\n> generate a bech32 address when receiving from a bech32 compatible wallet,\n> and a P2WPKH-nested-in-P2SH address when receiving for a legacy wallet.\n> However, it is of course impossible for the payee to know in advance the\n> technological capabilities of the payer, so a solution could be to encode\n> in a Bitcoin URI both bech32 and P2SH addresses in a way that legacy\n> wallets only see the P2SH address, while new wallets can also see the\n> bech32 address and use it to perform the transaction.\n> \n> In particular, to keep compatibility with BIP21, the <address> field of the\n> URI can be used for the P2WPKH-nested-in-P2SH address and a new field (e.g.\n> <segwitaddress> or <bech32address>), which will be ignored by legacy\n> wallets, can be used to encode the bech32 address. The assumption here is\n> that the wallets using such scheme will monitor incoming transaction both\n> on the P2SH address and on the bech32 address.\n> \n> I did some research around and I did not find any proposal addressing the\n> same issue, so my questions are (i) does anybody already proposed something\n> going in the same direction and (ii) do you see any major drawback in the\n> BIP21 compatible scheme proposed in this message?\n> \n> Thanks in advance,\n> \n> Federico\n> \n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 898 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180725/fdd0fc27/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "URI scheme with optional bech32 address",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "vv01f",
                "Federico Tenga"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 5073
        }
    },
    {
        "title": "[bitcoin-dev] A BIP proposal for segwit addresses",
        "thread_messages": [
            {
                "author": "Russell O'Connor",
                "date": "2018-07-26T13:43:19",
                "message_text_only": "Hi Pieter,\n\n> The *human-readable part*, which is intended to convey the type of data,\nor anything else that is relevant to the reader. This part MUST contain 1\nto 83 US-ASCII characters, with each character having a value in the range\n[33-126]. HRP validity may be further restricted by specific applications.\n\nYou should also add to this section that the HRP should be lowercase.\n\nSince Bech32 forbids mixed-case and otherwise converts everything to\nlowercase, it is good to warn upfront against using uppercase in the HRP.\n\nI know the BIP is marked as final, but this wouldn't be a normative change.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180726/8f9e0bd6/attachment.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2018-07-26T14:31:30",
                "message_text_only": "I think I phrased this badly.\n\nWhat I mean is that there should be a note that HRP should be specified in\nlowercase, or at least mention that uppercase and lowercase HRPs are\nconsidered equivalent and will be canonicalized to lowercase during\nvalidation.\n\nOn Thu, Jul 26, 2018 at 9:43 AM, Russell O'Connor <roconnor at blockstream.io>\nwrote:\n\n> Hi Pieter,\n>\n> > The *human-readable part*, which is intended to convey the type of\n> data, or anything else that is relevant to the reader. This part MUST\n> contain 1 to 83 US-ASCII characters, with each character having a value in\n> the range [33-126]. HRP validity may be further restricted by specific\n> applications.\n>\n> You should also add to this section that the HRP should be lowercase.\n>\n> Since Bech32 forbids mixed-case and otherwise converts everything to\n> lowercase, it is good to warn upfront against using uppercase in the HRP.\n>\n> I know the BIP is marked as final, but this wouldn't be a normative change.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180726/673e006b/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "A BIP proposal for segwit addresses",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Russell O'Connor"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 1939
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Core 0.16.2 released",
        "thread_messages": [
            {
                "author": "Wladimir J. van der Laan",
                "date": "2018-07-29T16:58:37",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nBitcoin Core version 0.16.2 is now available from:\n\n  <https://bitcoincore.org/bin/bitcoin-core-0.16.2/>\n\nor through bittorrent:\n\n    magnet:?xt=urn:btih:b64eacae7d6e5f7ba50de3da8aca4368c27f0823&dn=bitcoin-core-0.16.2&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969&tr=udp%3A%2F%2Ftracker.leechers-paradise.org%3A6969&tr=udp%3A%2F%2Fzer0day.ch%3A1337&tr=udp%3A%2F%2Fexplodie.org%3A6969\n\nThis is a new minor version release, with various bugfixes\nas well as updated translations.\n\nPlease report bugs using the issue tracker at GitHub:\n\n  <https://github.com/bitcoin/bitcoin/issues>\n\nTo receive security and update notifications, please subscribe to:\n\n  <https://bitcoincore.org/en/list/announcements/join/>\n\nHow to Upgrade\n==============\n\nIf you are running an older version, shut it down. Wait until it has completely\nshut down (which might take a few minutes for older versions), then run the\ninstaller (on Windows) or just copy over `/Applications/Bitcoin-Qt` (on Mac)\nor `bitcoind`/`bitcoin-qt` (on Linux).\n\nThe first time you run version 0.15.0 or newer, your chainstate database will be converted to a\nnew format, which will take anywhere from a few minutes to half an hour,\ndepending on the speed of your machine.\n\nNote that the block database format also changed in version 0.8.0 and there is no\nautomatic upgrade code from before version 0.8 to version 0.15.0 or higher. Upgrading\ndirectly from 0.7.x and earlier without re-downloading the blockchain is not supported.\nHowever, as usual, old wallet versions are still supported.\n\nDowngrading warning\n- -------------------\n\nWallets created in 0.16 and later are not compatible with versions prior to 0.16\nand will not work if you try to use newly created wallets in older versions. Existing\nwallets that were created with older versions are not affected by this.\n\nCompatibility\n==============\n\nBitcoin Core is extensively tested on multiple operating systems using\nthe Linux kernel, macOS 10.8+, and Windows Vista and later. Windows XP is not supported.\n\nBitcoin Core should also work on most other Unix-like systems but is not\nfrequently tested on them.\n\n0.16.2 change log\n- ------------------\n\n### Wallet\n- - #13622 `c04a4a5` Remove mapRequest tracking that just effects Qt display. (TheBlueMatt)\n- - #12905 `cfc6f74` [rpcwallet] Clamp walletpassphrase value at 100M seconds (sdaftuar)\n- - #13437 `ed82e71` wallet: Erase wtxOrderd wtx pointer on removeprunedfunds (MarcoFalke)\n\n### RPC and other APIs\n- - #13451 `cbd2f70` rpc: expose CBlockIndex::nTx in getblock(header) (instagibbs)\n- - #13507 `f7401c8` RPC: Fix parameter count check for importpubkey (kristapsk)\n- - #13452 `6b9dc8c` rpc: have verifytxoutproof check the number of txns in proof structure (instagibbs)\n- - #12837 `bf1f150` rpc: fix type mistmatch in `listreceivedbyaddress` (joemphilips)\n- - #12743 `657dfc5` Fix csBestBlock/cvBlockChange waiting in rpc/mining (sipa)\n\n### GUI\n- - #12432 `f78e7f6` [qt] send: Clear All also resets coin control options (Sjors)\n- - #12617 `21dd512` gui: Show messages as text not html (laanwj)\n- - #12793 `cf6feb7` qt: Avoid reseting on resetguisettigs=0 (MarcoFalke)\n\n### Build system\n- - #13544 `9fd3e00` depends: Update Qt download url (fanquake)\n- - #12573 `88d1a64` Fix compilation when compiler do not support `__builtin_clz*` (532479301)\n\n### Tests and QA\n- - #13061 `170b309` Make tests pass after 2020 (bmwiedemann)\n- - #13192 `79c4fff` [tests] Fixed intermittent failure in `p2p_sendheaders.py` (lmanners)\n- - #13300 `d9c5630` qa: Initialize lockstack to prevent null pointer deref (MarcoFalke)\n- - #13545 `e15e3a9` tests: Fix test case `streams_serializedata_xor` Remove Boost dependency. (practicalswift)\n- - #13304 `cbdabef` qa: Fix `wallet_listreceivedby` race (MarcoFalke)\n\n### Miscellaneous\n- - #12887 `2291774` Add newlines to end of log messages (jnewbery)\n- - #12859 `18b0c69` Bugfix: Include <memory> for `std::unique_ptr` (luke-jr)\n- - #13131 `ce8aa54` Add Windows shutdown handler (ken2812221)\n- - #13652 `20461fc` rpc: Fix that CWallet::AbandonTransaction would leave the grandchildren, etc. active (Empact)\n\nCredits\n=======\n\nThanks to everyone who directly contributed to this release:\n\n- - 532479301\n- - Ben Woosley\n- - Bernhard M. Wiedemann\n- - Chun Kuan Lee\n- - Cory Fields\n- - fanquake\n- - Gregory Sanders\n- - joemphilips\n- - John Newbery\n- - Kristaps Kaupe\n- - lmanners\n- - Luke Dashjr\n- - MarcoFalke\n- - Matt Corallo\n- - Pieter Wuille\n- - practicalswift\n- - Sjors Provoost\n- - Suhas Daftuar\n- - Wladimir J. van der Laan\n\nAnd to those that reported security issues:\n\n- - Braydon Fuller\n- - Himanshu Mehta\n\nAs well as everyone that helped translating on [Transifex](https://www.transifex.com/projects/p/bitcoin/).\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v2\n\niQEcBAEBCgAGBQJbXfGUAAoJEB5K7WKYbNJdmLUIAJc+Emy+4SWk00lPshKW+1vF\nUHVw0I/jSrBDxKXT8CgsTR8OhIJA2bSzHk4IRdmKyZHTkUCW1SH3Dq6/XgSYOyqV\n6IrnWRlmdIkOiOh93gvBYfEJjAWlFvckDDALBlFCu2SL+JmjzPKEUmvJ/hAUkYmM\nAg1J4HWYF6UalEtTmr3J7d0cMsdlK93bfvUp3EyWGj1DocMab97gZNMqIkf+eJ6B\nByfmiVG5SciPnSjBKM09JbILWYe1Hq0Ad5MxWyGI1GMuKHe0XDg45Or+vSjqvX3j\n9n9/oD/FvPeARSpkkOxESs9xuNfV5B7UNlRzfEwS4YlDk0RRchIauQhuS1ct7eU=\n=piBb\n-----END PGP SIGNATURE-----"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Core 0.16.2 released",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Wladimir J. van der Laan"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 5312
        }
    },
    {
        "title": "[bitcoin-dev] bitcoin-transactions",
        "thread_messages": [
            {
                "author": "Aymeric Vitte",
                "date": "2018-07-31T11:25:48",
                "message_text_only": "I know this list is not to advertise personal projects but\nhttps://peersm.com/wallet might be of some interest, this is the web\ninterface for https://github.com/Ayms/bitcoin-transactions since\napparently quasi nobody succeeds to use it\n\nAs far as I know (and surprisingly) this is the only online tool that\nconverts bech32 addresses (Sipa's one does not output something\nunderstandable by everybody, the tool is using his code), the only one\nthat converts from any address to any address, maybe the only one that\ndecodes simply redeem scripts and probably the only one that allows to\ncreate transactions by its own (the advanced mode is not implemented for\nnow but will be soon)\n\nIdeally it should be an offline tool if there is some incentive to do\nso, so of course it is not advised to use his private keys for now\n\nMaybe they are mistaken but some users are reporting invalid bech32\naddresses from their Electrum wallet, after segwit, bech32 confusion\nseems to be the topic of the moment\n\nRegards\n\nAymeric\n\n-- \nBitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions\nZcash wallets made simple: https://github.com/Ayms/zcash-wallets\nBitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets\nGet the torrent dynamic blocklist: http://peersm.com/getblocklist\nCheck the 10 M passwords list: http://peersm.com/findmyass\nAnti-spies and private torrents, dynamic blocklist: http://torrent-live.org\nPeersm : http://www.peersm.com\ntorrent-live: https://github.com/Ayms/torrent-live\nnode-Tor : https://www.github.com/Ayms/node-Tor\nGitHub : https://www.github.com/Ayms"
            }
        ],
        "thread_summary": {
            "title": "bitcoin-transactions",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Aymeric Vitte"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1594
        }
    }
]