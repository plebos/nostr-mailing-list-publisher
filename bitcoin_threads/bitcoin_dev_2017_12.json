[
    {
        "title": "[bitcoin-dev] A DNS-like decentralized mapping for wallet addresses?",
        "thread_messages": [
            {
                "author": "Tao Effect",
                "date": "2017-12-01T00:00:26",
                "message_text_only": "Check out Blockstack, they're doing something like that.\n\n--\nPlease do not email me anything that you are not comfortable also sharing with the NSA.\n\n> On Nov 30, 2017, at 2:20 PM, mandar mulherkar via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> \n> Hello,\n> \n> I am new, so apologies if this has been asked before.\n> \n> Here are a few questions to start with -\n> \n> I was wondering in terms of mass adoption, instead of long wallet addresses, maybe there should be a DNS-like decentralized mapping service to provide a user at crypto address?\n> \n> This address translation can happen with confirmations from the network. So instead of providing a long string, or a QR code that needs an app, you simply type in a human readable address, and the wallet software converts it to a wallet address.\n> \n> Please let me know where I can research this more - if there already is literature about this somewhere.\n> \n> thanks!\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/a79f414b/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/a79f414b/attachment-0001.sig>"
            },
            {
                "author": "Justin Newton",
                "date": "2017-12-01T00:10:29",
                "message_text_only": "https://www.walletnames.com\n\nBased on a standard that can support blockchain based or traditional ICANN\nDNS.\n\n\n\nOn Fri, Dec 1, 2017 at 6:20 AM, mandar mulherkar via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hello,\n>\n> I am new, so apologies if this has been asked before.\n>\n> Here are a few questions to start with -\n>\n> I was wondering in terms of mass adoption, instead of long wallet\n> addresses, maybe there should be a DNS-like decentralized mapping service\n> to provide a user at crypto address?\n>\n> This address translation can happen with confirmations from the network.\n> So instead of providing a long string, or a QR code that needs an app, you\n> simply type in a human readable address, and the wallet software converts\n> it to a wallet address.\n>\n> Please let me know where I can research this more - if there already is\n> literature about this somewhere.\n>\n> thanks!\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n\n\n-- \n\nJustin W. Newton\nFounder/CEO\nNetki, Inc.\n\njustin@ <justin at netki.com>netki.com <justin at netki.com>\n\n*+1.818.927.2646*\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/8ec413e8/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: PastedGraphic-1.tiff\nType: image/tiff\nSize: 10972 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/8ec413e8/attachment.tiff>"
            },
            {
                "author": "Douglas Roark",
                "date": "2017-12-01T03:08:24",
                "message_text_only": "On 2017/11/30 14:20, mandar mulherkar via bitcoin-dev wrote:\n> I was wondering in terms of mass adoption, instead of long wallet\n> addresses, maybe there should be a DNS-like decentralized mapping\n> service to provide a user at crypto address?\n\nA few years ago, I was part of an effort with Armory and Verisign to\nmake something similar to what you're describing.\nhttps://tools.ietf.org/html/draft-wiley-paymentassoc-00 is where you can\nfind the one and only official draft. I worked on a follow-up with some\nchanges and some nice appendices, explaining some nice tricks one could\nuse to make payment management flexible. For various reasons, it never\ngot published. I think it's an interesting draft that could be turned\ninto something useful. Among other things, it was able to leverage BIP32\nand allow payment requests to be generated that automatically pointed\npayees to the correct branch. DNSSEC may have some issues but, AFAIK,\nit's as the easiest way to bootstrap identity to a common, reasonably\nsecure standard.\n\n-- \n---\nDouglas Roark\nCryptocurrency, network security, travel, and art.\nhttps://onename.com/droark\njoroark at vt.edu\nPGP key ID: 26623924\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 895 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/ee8ac2e0/attachment-0001.sig>"
            },
            {
                "author": "Sjors Provoost",
                "date": "2017-12-18T11:26:19",
                "message_text_only": "Have you thought about combining this with BIP-47? You could associate payment codes with email via DNS.\n\nIt would be nice if there was a way to get rid of the announcement transaction in BIP-47 and establish a shared secret out of bound. That would simplify things, at the cost of an additional burden of storing more than an HD seed to recover a wallet that received funds this way.\n\nPerhaps the sender can email to the recipient the information they need to retrieve the funds. The (first) transaction could have a time locked refund in it, in case the payment code is stale.\n\nSjors\n\n> Op 1 dec. 2017, om 04:08 heeft Douglas Roark via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:\n> \n> On 2017/11/30 14:20, mandar mulherkar via bitcoin-dev wrote:\n>> I was wondering in terms of mass adoption, instead of long wallet\n>> addresses, maybe there should be a DNS-like decentralized mapping\n>> service to provide a user at crypto address?\n> \n> A few years ago, I was part of an effort with Armory and Verisign to\n> make something similar to what you're describing.\n> https://tools.ietf.org/html/draft-wiley-paymentassoc-00 is where you can\n> find the one and only official draft. I worked on a follow-up with some\n> changes and some nice appendices, explaining some nice tricks one could\n> use to make payment management flexible. For various reasons, it never\n> got published. I think it's an interesting draft that could be turned\n> into something useful. Among other things, it was able to leverage BIP32\n> and allow payment requests to be generated that automatically pointed\n> payees to the correct branch. DNSSEC may have some issues but, AFAIK,\n> it's as the easiest way to bootstrap identity to a common, reasonably\n> secure standard.\n> \n> --\n> ---\n> Douglas Roark\n> Cryptocurrency, network security, travel, and art.\n> https://onename.com/droark\n> joroark at vt.edu\n> PGP key ID: 26623924\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/376f96f6/attachment.sig>"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-19T09:05:34",
                "message_text_only": "There is no reason it should not be easily possible to develop a Bitcoin wallet that has an integrated name to address mapping feature. It might be a good idea for a software product, it could even be based on Bitcoin Core. There is no specific reason that people wanting that sort of feature could not use it. In fact, you could map names, strings, email addresses, it could be very flexible.\n\n\nRelying on an additional service like DNS which is flexible enough to handle the job, does introduce an additional availability risk. There is no additional privacy risk provided each mapped name or address is only used once to send/receive one payment unless you directly use something personally identifiable like an email address which could be used to map bitcoin addresses to an individual. Personally, I am not concerned about privacy so much but can understand that some highly value their privacy.\n\n\nIf you get it right it will be a service better than namecoin transacting in Bitcoin. If you think that is valuable, go for it.\n\n\nRegards,\n\nDamian Williamson\n\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Sjors Provoost via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Monday, 18 December 2017 10:26 PM\nTo: Douglas Roark; Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] A DNS-like decentralized mapping for wallet addresses?\n\nHave you thought about combining this with BIP-47? You could associate payment codes with email via DNS.\n\nIt would be nice if there was a way to get rid of the announcement transaction in BIP-47 and establish a shared secret out of bound. That would simplify things, at the cost of an additional burden of storing more than an HD seed to recover a wallet that received funds this way.\n\nPerhaps the sender can email to the recipient the information they need to retrieve the funds. The (first) transaction could have a time locked refund in it, in case the payment code is stale.\n\nSjors\n\n> Op 1 dec. 2017, om 04:08 heeft Douglas Roark via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:\n>\n> On 2017/11/30 14:20, mandar mulherkar via bitcoin-dev wrote:\n>> I was wondering in terms of mass adoption, instead of long wallet\n>> addresses, maybe there should be a DNS-like decentralized mapping\n>> service to provide a user at crypto address?\n>\n> A few years ago, I was part of an effort with Armory and Verisign to\n> make something similar to what you're describing.\n> https://tools.ietf.org/html/draft-wiley-paymentassoc-00 is where you can\n> find the one and only official draft. I worked on a follow-up with some\n> changes and some nice appendices, explaining some nice tricks one could\n> use to make payment management flexible. For various reasons, it never\n> got published. I think it's an interesting draft that could be turned\n> into something useful. Among other things, it was able to leverage BIP32\n> and allow payment requests to be generated that automatically pointed\n> payees to the correct branch. DNSSEC may have some issues but, AFAIK,\n> it's as the easiest way to bootstrap identity to a common, reasonably\n> secure standard.\n>\n> --\n> ---\n> Douglas Roark\n> Cryptocurrency, network security, travel, and art.\n> https://onename.com/droark\n> joroark at vt.edu\n> PGP key ID: 26623924\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171219/60b0253d/attachment.html>"
            },
            {
                "author": "Hampus Sj\u00f6berg",
                "date": "2017-12-19T13:11:24",
                "message_text_only": "Most solutions only work with a single Bitcoin address (terrible for\nprivacy, and also potentially a security risk) or xpubkey (also terrible\nfor privacy).\n\nI think the best solution here is some kind of store-and-forward server,\nwhere you trade a little bit of privacy (to the server, that is), but get\nthe convenience of using (for example) an email address as the account.\nI like for example BIP75 for this, and I hope the community can work\ntowards a solution like this. This could potentially work good with LN as\nwell. https://github.com/bitcoin/bips/blob/master/bip-0075.mediawiki\n\nHampus\n\n2017-12-19 10:05 GMT+01:00 Damian Williamson via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org>:\n\n> There is no reason it should not be easily possible to develop a Bitcoin\n> wallet that has an integrated name to address mapping feature. It might be\n> a good idea for a software product, it could even be based on Bitcoin Core.\n> There is no specific reason that people wanting that sort of feature could\n> not use it. In fact, you could map names, strings, email addresses, it\n> could be very flexible.\n>\n>\n> Relying on an additional service like DNS which is flexible enough to\n> handle the job, does introduce an additional availability risk. There is no\n> additional privacy risk provided each mapped name or address is only used\n> once to send/receive one payment unless you directly use something\n> personally identifiable like an email address which could be used to map\n> bitcoin addresses to an individual. Personally, I am not concerned about\n> privacy so much but can understand that some highly value their privacy.\n>\n>\n> If you get it right it will be a service better than namecoin transacting\n> in Bitcoin. If you think that is valuable, go for it.\n>\n>\n> Regards,\n>\n> Damian Williamson\n>\n>\n> ------------------------------\n> *From:* bitcoin-dev-bounces at lists.linuxfoundation.org <\n> bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Sjors\n> Provoost via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n> *Sent:* Monday, 18 December 2017 10:26 PM\n> *To:* Douglas Roark; Bitcoin Protocol Discussion\n> *Subject:* Re: [bitcoin-dev] A DNS-like decentralized mapping for wallet\n> addresses?\n>\n> Have you thought about combining this with BIP-47? You could associate\n> payment codes with email via DNS.\n>\n> It would be nice if there was a way to get rid of the announcement\n> transaction in BIP-47 and establish a shared secret out of bound. That\n> would simplify things, at the cost of an additional burden of storing more\n> than an HD seed to recover a wallet that received funds this way.\n>\n> Perhaps the sender can email to the recipient the information they need to\n> retrieve the funds. The (first) transaction could have a time locked refund\n> in it, in case the payment code is stale.\n>\n> Sjors\n>\n> > Op 1 dec. 2017, om 04:08 heeft Douglas Roark via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:\n> >\n> > On 2017/11/30 14:20, mandar mulherkar via bitcoin-dev wrote:\n> >> I was wondering in terms of mass adoption, instead of long wallet\n> >> addresses, maybe there should be a DNS-like decentralized mapping\n> >> service to provide a user at crypto address?\n> >\n> > A few years ago, I was part of an effort with Armory and Verisign to\n> > make something similar to what you're describing.\n> > https://tools.ietf.org/html/draft-wiley-paymentassoc-00 is where you can\n> > find the one and only official draft. I worked on a follow-up with some\n> > changes and some nice appendices, explaining some nice tricks one could\n> > use to make payment management flexible. For various reasons, it never\n> > got published. I think it's an interesting draft that could be turned\n> > into something useful. Among other things, it was able to leverage BIP32\n> > and allow payment requests to be generated that automatically pointed\n> > payees to the correct branch. DNSSEC may have some issues but, AFAIK,\n> > it's as the easiest way to bootstrap identity to a common, reasonably\n> > secure standard.\n> >\n> > --\n> > ---\n> > Douglas Roark\n> > Cryptocurrency, network security, travel, and art.\n> > https://onename.com/droark\n> > joroark at vt.edu\n> > PGP key ID: 26623924\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171219/cbaee39b/attachment-0001.html>"
            },
            {
                "author": "Lucas Clemente Vella",
                "date": "2017-12-01T03:15:00",
                "message_text_only": "The original altcoin, Namecoin, aimed a building a bitcoin-like, blockchain\nbased decentralized DNS system. Unfortunately it didn't catch, but it would\nbe the most logical choice for the name registry database.\n\n2017-11-30 20:20 GMT-02:00 mandar mulherkar via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org>:\n\n> Hello,\n>\n> I am new, so apologies if this has been asked before.\n>\n> Here are a few questions to start with -\n>\n> I was wondering in terms of mass adoption, instead of long wallet\n> addresses, maybe there should be a DNS-like decentralized mapping service\n> to provide a user at crypto address?\n>\n> This address translation can happen with confirmations from the network.\n> So instead of providing a long string, or a QR code that needs an app, you\n> simply type in a human readable address, and the wallet software converts\n> it to a wallet address.\n>\n> Please let me know where I can research this more - if there already is\n> literature about this somewhere.\n>\n> thanks!\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n\n\n-- \nLucas Clemente Vella\nlvella at gmail.com\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/4f29dac1/attachment.html>"
            },
            {
                "author": "CANNON",
                "date": "2017-12-01T04:17:37",
                "message_text_only": "On 12/01/2017 03:15 AM, Lucas Clemente Vella via bitcoin-dev wrote:\n> Unfortunately it didn't catch, but it would\n\nInteresting, I just mentioned namecoin literally seconds before this email arrived.\nSaying \"it did not catch\" is not accurate I'd say. It still works great, and namecoin\nhas actually made great progress this year 2017. I'd say that namecoin has great potential\nbut just not widely adopted yet.\n\nWould be real nice to have namecion support in major bitcoin wallets for name to data mapping."
            },
            {
                "author": "J\u00e9r\u00e9mie Dubois-Lacoste",
                "date": "2017-12-01T08:24:44",
                "message_text_only": "https://openalias.org/\n\n\n2017-12-01 4:15 GMT+01:00 Lucas Clemente Vella via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org>:\n\n> The original altcoin, Namecoin, aimed a building a bitcoin-like,\n> blockchain based decentralized DNS system. Unfortunately it didn't catch,\n> but it would be the most logical choice for the name registry database.\n>\n> 2017-11-30 20:20 GMT-02:00 mandar mulherkar via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org>:\n>\n>> Hello,\n>>\n>> I am new, so apologies if this has been asked before.\n>>\n>> Here are a few questions to start with -\n>>\n>> I was wondering in terms of mass adoption, instead of long wallet\n>> addresses, maybe there should be a DNS-like decentralized mapping service\n>> to provide a user at crypto address?\n>>\n>> This address translation can happen with confirmations from the network.\n>> So instead of providing a long string, or a QR code that needs an app, you\n>> simply type in a human readable address, and the wallet software converts\n>> it to a wallet address.\n>>\n>> Please let me know where I can research this more - if there already is\n>> literature about this somewhere.\n>>\n>> thanks!\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>\n>\n> --\n> Lucas Clemente Vella\n> lvella at gmail.com\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/d3907753/attachment.html>"
            },
            {
                "author": "CANNON",
                "date": "2017-12-01T04:12:24",
                "message_text_only": "On 11/30/2017 10:20 PM, mandar mulherkar via bitcoin-dev wrote:\n> Hello,\n> \n> I am new, so apologies if this has been asked before.\n> \n> Here are a few questions to start with -\n> \n> I was wondering in terms of mass adoption, instead of long wallet\n> addresses, maybe there should be a DNS-like decentralized mapping service\n> to provide a user at crypto address?\n\nCheck out namecoin, there is also blockstack as someone mentioned, but I personally feel namecoin is technologically better.\n\nIf do not want a static bitcoin address mapped to a username, could use a stealth address (we need more\nsupport for stealth addresses in bitcoin wallets)."
            },
            {
                "author": "Antonis Anastasiadis",
                "date": "2017-12-01T11:07:14",
                "message_text_only": "Also check the Open Alias project. It's based on DNS+DNSSEC but it\noffers the usability feature you mention (nice addresses).\n\nhttps://openalias.org/\n\nOn 01/12/2017 00:20, mandar mulherkar via bitcoin-dev wrote:\n> Hello,\u00a0\n>\n> I am new, so apologies if this has been asked before.\n>\n> Here are a few questions to start with -\u00a0\n>\n> I was wondering in terms of mass adoption, instead of long wallet\n> addresses, maybe there should be a DNS-like decentralized mapping\n> service to provide a user at crypto address?\n>\n> This address translation can happen with confirmations from the\n> network. So instead of providing a long string, or a QR code that\n> needs an app, you simply type in a human readable address, and the\n> wallet software converts it to a wallet address.\n>\n> Please let me know where I can research this more - if there already\n> is literature about this somewhere.\n>\n> thanks!\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/bac2e69b/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "A DNS-like decentralized mapping for wallet addresses?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Lucas Clemente Vella",
                "Hampus Sj\u00f6berg",
                "Justin Newton",
                "Damian Williamson",
                "Sjors Provoost",
                "J\u00e9r\u00e9mie Dubois-Lacoste",
                "Douglas Roark",
                "Antonis Anastasiadis",
                "Tao Effect",
                "CANNON"
            ],
            "messages_count": 11,
            "total_messages_chars_count": 21426
        }
    },
    {
        "title": "[bitcoin-dev] BIP Idea: Marginal Pricing",
        "thread_messages": [
            {
                "author": "Ryan J Martin",
                "date": "2017-12-01T07:58:01",
                "message_text_only": "Interesting thoughts William, however much of what you describe already exists:\n\"I predict that this scheme would result in two markets: a backlog market and a real-time market. Users targeting the backlog market would match the price of the largest backlog section in order to be included in the next backlog block.\"\nThis happens with users deciding to pay (essentially) a fee smaller or larger than the 1999th tx in the mempool. If user is willing to pay more than the 1999th highest fee tx in mempool (or whatever tx byte 1,000,000 in a mempool ranked by tx fee) then they will get to be on the next block. This is a simplification but you get the idea.\n\nFurther, Greg Maxwell's one reply covers alot of the biggest pitfalls well. Especially that much of this already happens and that behavior in response to such a change could be hairy to predict. So I'm not sure that---what is basically--- a multi-unit Vickrey auction is the best way to go... but it is an interesting idea worth further examination.\n\nSecond, minimizing invididual user tx fees and maximizing total tx fees are essentially incompatible within the current development structure. Even if the block limit is increased to 3mb the same problem will eventually occur. While I agree it would be ideal to maximize social benefit (i.e. maximize both consumer and producer surplus) through more simple protocol changes---at least in the medium term, that isn't on the table so it is better to move on.\n\n  This is not an easy optimization problem to solve though. The difficulty is trying to model a market like bitcoin; the only thing that comes close is electricity markets. With 2,000 tx in the pool, users aren't willing to pay shit to send a tx; there is always a miner to process it. So at 2,000tx per 10 min (3.333 txps, 1mb/10min,etc) and below users price elasticity is flat. Once the pool has >2,000 tx in it, especially for any extended amount of time, users price elasticity is about as elastic as a brick and goes near vertical. This creates a situation where miners are always better off when there is a significant backlog (this can be seen in miners revenue from tx fees anytime there is an ongoing backlog).\nSimply put, it would take some very large blocks to have total fees/block exceed total fees/block for constrained size blocks given the near vertical price elasticity users face when there is a backlog.\n\nSo I suspect that the multi-unit Vickrey would potentially do some to help this, but likely not much:\nUsers willingness to pay is what they pay---no surplus. Miner elasticity is more or less flat but we can call their willingness to accept whatever the lowest fee tx is in a block. Say it is 180 sat/b (NL), and the highest tx fee in a block (NH)is 320 sat/b. If you subtract each tx in the block (N) greater than NL\nand sum the result you get surplus to miners:  \u03a3(N1,2...- NL)\nSo, yes, the multi-unit Vickrey simply shifts the surplus to users. However, a case could be made that since---as mentioned in an earlier reply, the optimal strategy for miners is to accept zero fees (given their flat elasticity), and therefore all fees are surplus benefit to miners---shifting this surplus over to consumers could create some good effects. Primarily pushing users' price elasticity away from near vertical inelasticity as it would take some of the upward pressure off rapidly increasing fees in a backlog scenario.\nIt would be interesting to see a simulation of how this would play out, but without that this is too risky to implement.\n\nRegards,\nRyan J. Martin (tunafizz / ohituna)\n\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org [bitcoin-dev-bounces at lists.linuxfoundation.org] on behalf of William Morriss via bitcoin-dev [bitcoin-dev at lists.linuxfoundation.org]\nSent: Wednesday, November 29, 2017 7:47 PM\nTo: bitcoin-dev at lists.linuxfoundation.org\nSubject: [bitcoin-dev] BIP Idea: Marginal Pricing\n\nComrades,\n\nLong term, tx fees must support hash power by themselves. The following is an economic approach to maximize total fee collection, and therefore hashpower.\n\nGoals\nMaximize total transaction fees\nReduce pending transaction time\nReduce individual transaction fees\n\nChallenges\nValidators must agree on the maximum block size, else miners can cheat and include extra transactions.\nAllowing too many transactions per block will increase the cost of the mining without collecting much income for the network.\n\nProblem\nIn the transaction market, users are the demand curve, because they will transact less when fees are higher, and prefer altcoins. The block size is the supply curve, because it represents miners' willingness to accept transactions.\nCurrently, the supply curve is inelastic:\n[cid:ii_jalpxsnl1_1600a3d9def1eaff]\n\u200bIncreasing the block size will not affect the inelasticity for any fixed block size. The downsides of a fixed block size limit are well-known:\n- Unpredictable transaction settlement time\n- Variable transaction fees depending on network congestion\n- Frequent overpay\n\nProposal\n1. Miners implicitly choose the market sat/byte rate with the cheapest-fee transaction included in their block. Excess transaction fees are refunded to the inputs.\n2. Remove the block size limit, which is no longer necessary.\n\nBenefits\n- Dynamic block size limit regulated by profit motive\n- Transaction fees maximized for every block\n- No overpay; all fees are fair\n[cid:ii_jalqir4g2_1600a4c89811347a]\n\u200bMiners individually will make decisions to maximize their block-reward profit.\nMiners are incentivized to ignore low-fee transactions because they would shave the profits of their other transactions and increase their hash time.\nUsers and services are free to bid higher transaction fees in order to reach the next block, since their excess bid will be refunded.\n\nThe block size limit was added as a spam-prevention measure, but in order for an attacker to spam the network with low-fee transactions, they would have to offset the marginal cost of reducing the price with their own transaction fees. Anti-spam is thus built into the marginal system without the need for an explicit limit.\n\nRarely, sections of the backlog would become large enough to be profitable. This means every so many blocks, lower-fee transactions would be included en masse after having been ignored long enough. Low-fee transactions thus gain a liveness property not previously enjoyed: low-fee transactions will eventually confirm. Miners targeting these transactions would be at a noteworthy disadvantage because they would be hashing a larger block. I predict that this scheme would result in two markets: a backlog market and a real-time market. Users targeting the backlog market would match the price of the largest backlog section in order to be included in the next backlog block.\n\nExamples\n\nScenario 1\nSat/byte        Bytes   Reward\n400     500000  200000000\n300     700000  210000000\n200     1000000 200000000\n100     1500000 150000000\n50      5000000 250000000\n20      10000000        200000000\nA miner would create a 5MB block and receive 0.25 BTC\n\nScenario 2\nSat/byte        Bytes   Reward\n400     600000  240000000\n300     700000  210000000\n200     1000000 200000000\n100     1800000 180000000\n50      4000000 200000000\n20      10000000        200000000\nA miner would create a 600KB block and receive 0.24 BTC\n\nThanks,\nWilliam Morriss\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/d32a6976/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: fixedblocksize.png\nType: image/png\nSize: 18199 bytes\nDesc: fixedblocksize.png\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/d32a6976/attachment-0003.png>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: fixedblocksize.png\nType: image/png\nSize: 18199 bytes\nDesc: fixedblocksize.png\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/d32a6976/attachment-0004.png>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: marginal.png\nType: image/png\nSize: 21403 bytes\nDesc: marginal.png\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/d32a6976/attachment-0005.png>"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-02T03:55:22",
                "message_text_only": "I also am for the idea of removing blocksize limits if it is workable, however, would propose an alternative method for selecting transactions to be included in a block.\n\n\nSome of the issues discussed in other replies to this thread are valid.\n\n\nAlternative proposal:\n\nProvide each transaction with a transaction weight, being a function of the fee paid (on a curve), and the time waiting in the pool (also on a curve) out to n days (n=30 ?), the transaction weight serving as the likelihood of a transaction being included in the current block, and then use an uncapped block size. The curve allows that the higher a fee allows a transaction to be much more likely to be included, the highest fee gets 100%, and, transactions at the n days limit get near 100%. Would need protocol enforcement since, as I understand, no miner would mine more transactions than are necessary to meet min blocksize. Other than that it should function fine. Non-urgent transactions pay a lower fee, people choose fees from fee recommendation based on how many days before a tx begins confirmation, all transactions are eventually included in the blockchain.\n\n\nRegards,\n\nDamian Williamson\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of William Morriss via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Thursday, 30 November 2017 11:47:43 AM\nTo: bitcoin-dev at lists.linuxfoundation.org\nSubject: [bitcoin-dev] BIP Idea: Marginal Pricing\n\nComrades,\n\nLong term, tx fees must support hash power by themselves. The following is an economic approach to maximize total fee collection, and therefore hashpower.\n\nGoals\nMaximize total transaction fees\nReduce pending transaction time\nReduce individual transaction fees\n\nChallenges\nValidators must agree on the maximum block size, else miners can cheat and include extra transactions.\nAllowing too many transactions per block will increase the cost of the mining without collecting much income for the network.\n\nProblem\nIn the transaction market, users are the demand curve, because they will transact less when fees are higher, and prefer altcoins. The block size is the supply curve, because it represents miners' willingness to accept transactions.\nCurrently, the supply curve is inelastic:\n[cid:ii_jalpxsnl1_1600a3d9def1eaff]\n\u200bIncreasing the block size will not affect the inelasticity for any fixed block size. The downsides of a fixed block size limit are well-known:\n- Unpredictable transaction settlement time\n- Variable transaction fees depending on network congestion\n- Frequent overpay\n\nProposal\n1. Miners implicitly choose the market sat/byte rate with the cheapest-fee transaction included in their block. Excess transaction fees are refunded to the inputs.\n2. Remove the block size limit, which is no longer necessary.\n\nBenefits\n- Dynamic block size limit regulated by profit motive\n- Transaction fees maximized for every block\n- No overpay; all fees are fair\n[cid:ii_jalqir4g2_1600a4c89811347a]\n\u200bMiners individually will make decisions to maximize their block-reward profit.\nMiners are incentivized to ignore low-fee transactions because they would shave the profits of their other transactions and increase their hash time.\nUsers and services are free to bid higher transaction fees in order to reach the next block, since their excess bid will be refunded.\n\nThe block size limit was added as a spam-prevention measure, but in order for an attacker to spam the network with low-fee transactions, they would have to offset the marginal cost of reducing the price with their own transaction fees. Anti-spam is thus built into the marginal system without the need for an explicit limit.\n\nRarely, sections of the backlog would become large enough to be profitable. This means every so many blocks, lower-fee transactions would be included en masse after having been ignored long enough. Low-fee transactions thus gain a liveness property not previously enjoyed: low-fee transactions will eventually confirm. Miners targeting these transactions would be at a noteworthy disadvantage because they would be hashing a larger block. I predict that this scheme would result in two markets: a backlog market and a real-time market. Users targeting the backlog market would match the price of the largest backlog section in order to be included in the next backlog block.\n\nExamples\n\nScenario 1\nSat/byte        Bytes   Reward\n400     500000  200000000\n300     700000  210000000\n200     1000000 200000000\n100     1500000 150000000\n50      5000000 250000000\n20      10000000        200000000\nA miner would create a 5MB block and receive 0.25 BTC\n\nScenario 2\nSat/byte        Bytes   Reward\n400     600000  240000000\n300     700000  210000000\n200     1000000 200000000\n100     1800000 180000000\n50      4000000 200000000\n20      10000000        200000000\nA miner would create a 600KB block and receive 0.24 BTC\n\nThanks,\nWilliam Morriss\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171202/4d3b164f/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: fixedblocksize.png\nType: image/png\nSize: 18199 bytes\nDesc: fixedblocksize.png\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171202/4d3b164f/attachment-0003.png>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: fixedblocksize.png\nType: image/png\nSize: 18199 bytes\nDesc: fixedblocksize.png\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171202/4d3b164f/attachment-0004.png>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: marginal.png\nType: image/png\nSize: 21403 bytes\nDesc: marginal.png\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171202/4d3b164f/attachment-0005.png>"
            }
        ],
        "thread_summary": {
            "title": "BIP Idea: Marginal Pricing",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Damian Williamson",
                "Ryan J Martin"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 14347
        }
    },
    {
        "title": "[bitcoin-dev] Two Drivechain BIPs",
        "thread_messages": [
            {
                "author": "Paul Sztorc",
                "date": "2017-12-01T18:38:16",
                "message_text_only": "Hello,\n\nFirst, Drivechain has vaguely escaped vaporware status. If you've ever\nthought \"I'd like to take a look into Drivechain when there is code\",\nthen now is a pretty good time. (Unfinished items include M1, and M8_V2.)\n\nhttps://github.com/drivechain-project/bitcoin/tree/mainchainBMM\n\nAlso,\nSite:\u00a0 http://www.drivechain.info/\nBlank sidechain:\nhttps://github.com/drivechain-project/bitcoin/tree/sidechainBMM\n\nSecond, I think drivechain's documentation / BIP-Drafts are tolerably\nreadable.\n\nHere they are:\n\n1.\nhttps://github.com/drivechain-project/docs/blob/master/bip1-hashrate-escrow.md\n2.\nhttps://github.com/drivechain-project/docs/blob/master/bip2-blind-merged-mining.md\n\ncc: Luke, I think they are ready to be assigned formal BIP Numbers.\n\nThis is also a request for code review. The most helpful review will\nprobably take place on GitHub.\n\nRegular review is also welcome. Although, please read our\nrecently-updated FAQ, at: http://www.drivechain.info/faq .\nAnd also see major earlier discussions:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/014364.html\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-June/014559.html\n\nHave a nice weekend everyone,\nPaul"
            },
            {
                "author": "Matt Corallo",
                "date": "2017-12-03T21:32:15",
                "message_text_only": "Process note: It looks like the BIPs have never been posted to\nbitcoin-dev, only high-level discussion around the idea. As I understand\nit, this is *not* sufficient for BIP number assignment nor\n(realistically) sufficient to call it a hard \"proposal\" for a change to\nconsensus rules.\n\nWould love to get feedback from some others who are looking at deploying\nreal-world sidechains, eg the RSK folks. We can't end up with *two*\nprotocols for sidechains in Bitcoin.\n\nComments on BIP 1:\n\nAt a high level, I'm rather dissapointed by the amount of data that is\ngoing into the main chain here. Things such as a human readable name\nhave no place in the chain, IMO. Further, the use of a well-known\nprivate key seems misplaced, why not just track the sidechain balance\nwith something that looks like `OP_NOPX genesis_block_hash`?\n\nI'm not convinced by the full semantics of proposal/ack of new\nsidechains. Given the lack of convincing evidence of that \"Risk of\ncentralisation of mining\" drawback in section 4.3 of the sidechains\npaper has been meaningfully addressed, I'd say its pretty important that\nnew sidechains be an incredibly rare event. Thus, a much simpler system\n(eg a version-bits-based upgrade cycle with high threshold) could be\nused to add new sidechains based on well-known public parameters.\n\nThe semantics of the deposit process seem very suboptimal. You note that\nonly one user can deposit at a time, but this seems entirely\nunnecessary. As implemented in the first Elements Alpha release (though\nI believe subsequently removed in later versions due to the nature of\nElements of targeting asymmetric \"federated\" sidechains), if you have\noutputs that look like `OP_NOPX genesis_block_hash` as the sidechain\ndeposit/storage address, deposit can be fully parallel. To reduce\nblockchain bloat, spending them for the purpose of combining such\noutputs is also allowed. You could even go further and allow some new\nsighash type to define something like SIGHASH_ALL|SIGHASH_ANYONECANPAY\nwhich further specifies some semantics for combining inputs which all\npay into the same output.\n\nFinally, you may also want to explore some process for the removal of\nsidechain balances from the main chain. As proposed it seems like a\nsidechain might, over time, fade into an insecure state as mining power\nshifts and new miners no longer consider it worth the value to mine an\nold sidechain (as has happened over time with namecoin, arguably).\n\n\nComments on BIP 2:\n\nI may be missing something, but I find the security model here kind of\ndepressing...Not only do hashpower-secured sidechains already have a\nsignificantly reduced security level, but now you're proposing to\nfurther (drastically) reduce it by requiring users to potentially pay in\nexcess of the value an attacker is willing to pay to keep their chain\nsecure, on a recurring basis? It seems like if a chain has 10 BTC stored\nin it, and I wish to reorg it for a potential gain of, lets say, 6 BTC,\nI can pay 6 * 1 BTC (1 per block) to reorg it, and users on the chain\nwould be forced to pay >6 BTC to avoid this?\n\nWhile I appreciate the desire to implement the proposed mitigation in\nsection 4.3 of the sidechains paper (delegating the mining effort of a\nmerge-mined sidechain to an external entity), I believe it was primarily\nreferencing pooling the sidechain work, not blindly taking the highest\nbidder. I suppose, indeed, that, ultimately, as long as the sidechain is\nof relatively small value in comparison to BTC, miners do not risk the\nvalue of their BTC/mining investment in simply taking the highest bidder\nof a merge-mined block, even if its a clear attack, but I don't think\nthats something to be celebrated, encouraged, or designed to be possible\nby default. Instead, I'd, in line with Peter Todd's (and others')\nobjection to merged mining generally, call this one of the most critical\nissues with the security model.\n\nUltimately, I dont believe your proposal here really solves the drawback\nin section 4.3 of the paper, and possibly makes it worse. Instead, it\nmay be more useful to rely on a high threshold for the addition of new\nsidechains, though I'd love to see discussion on this point specifically\non this list. Further, I'd say, at a minimum, a very stable\ndefault-available low-bandwidth implementation of at least the\npool-based mitigation suggested in the paper must exist for something\nlike this to be considered readily stable enough to be deployed into the\nBitcoin ecosystem.\n\nMatt\n\nOn 12/01/17 13:38, Paul Sztorc via bitcoin-dev wrote:\n> Hello,\n> \n> First, Drivechain has vaguely escaped vaporware status. If you've ever\n> thought \"I'd like to take a look into Drivechain when there is code\",\n> then now is a pretty good time. (Unfinished items include M1, and M8_V2.)\n> \n> https://github.com/drivechain-project/bitcoin/tree/mainchainBMM\n> \n> Also,\n> Site:\u00a0 http://www.drivechain.info/\n> Blank sidechain:\n> https://github.com/drivechain-project/bitcoin/tree/sidechainBMM\n> \n> Second, I think drivechain's documentation / BIP-Drafts are tolerably\n> readable.\n> \n> Here they are:\n> \n> 1.\n> https://github.com/drivechain-project/docs/blob/master/bip1-hashrate-escrow.md\n> 2.\n> https://github.com/drivechain-project/docs/blob/master/bip2-blind-merged-mining.md\n> \n> cc: Luke, I think they are ready to be assigned formal BIP Numbers.\n> \n> This is also a request for code review. The most helpful review will\n> probably take place on GitHub.\n> \n> Regular review is also welcome. Although, please read our\n> recently-updated FAQ, at: http://www.drivechain.info/faq .\n> And also see major earlier discussions:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/014364.html\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-June/014559.html\n> \n> Have a nice weekend everyone,\n> Paul\n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Paul Sztorc",
                "date": "2017-12-04T19:05:09",
                "message_text_only": "Hi Matt,\n\nThanks for very much for your thoughtful review\n\nComments below.\n\nOn 12/3/2017 4:32 PM, Matt Corallo wrote:\n> ...\n>\n> ...\n>\n> Comments on BIP 1:\n>\n> At a high level, I'm rather dissapointed by the amount of data that is\n> going into the main chain here. Things such as a human readable name\n> have no place in the chain, IMO.\n\nWell, that is quite a minor quibble, because it is just a one-time cost\nof 120 bytes per sidechain.\n\nTo address it, there could instead be a hash commitment to this\ninformation. That commitment could be \"optional\", in that old nodes\nwouldn't need to possess the 120 bytes. Although, all of the sidechains\nare themselves optional. And old nodes will be ignoring all of this data\nanyways. So I do not think\n\nThe inclusion of this field is deliberate. Probably, you do not buy my\nlengthy argument about \"categorical control\".\n\nhttp://www.drivechain.info/faq/#categorical-control\n\nPerhaps you have seen my May 2016 presentation on the topic. It was\nitself a lengthy reply to comments that Greg Maxwell made about the\noriginal Nov 2015 Drivechain post.\n\nhttps://www.youtube.com/watch?v=xGu0o8HH10U&list=PLw8-6ARlyVciMH79ZyLOpImsMug3LgNc4&index=1\n\nEither you aren't aware [of why I want each sidechain to have a\ncomprehensible category]. Or, you are aware and you disagree. But if it\nis the latter we might just have to agree to disagree.\n\n> ....\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Further, the use of a well-known\n> private key seems misplaced, why not just track the sidechain balance\n> with something that looks like `OP_NOPX genesis_block_hash`?\n\nI agree. I myself am unhappy with the private key approach, as it\nresults in a totally pointless signature being generated, and a\npointless CheckSig operation. (Somewhere, buried in\ndocumentation/GitHub-issue purgatory, there is a discussion of replacing\nit with OP TRUE.)\n\nBasically, our way was just a hack to make sure uses knew where they had\nto send the money, and also to get the balances to show up in all user's\nwallets. I do not pretend to have any expertise in this area (or even\nexperience) so it is surely an area for improvement.\n\n>\n> I'm not convinced by the full semantics of proposal/ack of new\n> sidechains.\u00a0 ...\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 I'd say its pretty important that\n> new sidechains be an incredibly rare event.\n\nWell, I partially agree.\n\nHowever, if drivechain is a soft fork, and if 51% hashrate can add new\nsoftforks at any time, then our ability to alter the rate of\nsidechain-creation is very low. While we might use the rules of\n\"Drivechain I\" to impose restrictions on the \"add a sidechain\" process,\nnothing prevents 51% hashrate from re-adding Drivechain to Core a second\ntime, creating a \"Drivechain II\" system with its own \"add a sidechain\"\nrules. Thus, the activation speed can increase, even if miners are\nincapable of writing any code. Or, miners might add \"Drivechain I\" to\none of the sidechains. (And of course the new-sidechain-rate can\ndecrease, through mere miner-censorship.)\n\nSo, I think there really is no threat model, other than to say: we\neither open Pandora's box or we do not. My vision (for any Redditors who\nmay be reading this, years in the future!!) is of a stable, conservative\nBitcoin Core with 3-8 sidechains, of which at least one is rather\nexperimental, and at least one of which has its own sidechains. But who\nknows.\n\nMore importantly, the problem you've outlined is much much worse for\nextension blocks.\n\n(It can scarcely be denied that hashrate wants more block space, and\nthat they can easily add one or many extension blocks, in public or in\nsecret, at any time. Will a UASF really be able to disable an in-use\nextension block? I think the UASF-case is much less persuasive,\nespecially since it involves loss/freezing of user funds.)\n\nSo I would argue that one of *the* greatest benefits of Drivechain is\nthat it neutralizes the threat of extension blocks by giving everyone a\nbetter alternative. In fact, I do not know of any other way to\nneutralize this threat.\n\n>\u00a0 ... Thus, a much simpler system\n> (eg a version-bits-based upgrade cycle with high threshold) could be\n> used to add new sidechains based on well-known public parameters.\n\nI don't have a problem with this. In fact that is mostly how we have it\ntoday.\n\nMy concern is a scenario where:\n\nPerson A: is running the latest version of Bitcoin (which has\ndrivechain), and full nodes for 3 out of 3 sidechains\nPerson B: is running the 2nd-latest version of Bitcoin (which has\ndrivechain), and was disconnected when the 3rd sidechain activated\nPerson C: is running the 3rd-latest version of Bitcoin (which has\ndrivechain), but was disconnected for the activation of all sidechains.\nPerson D: is running 0.5.3 and has no idea what drivechain is.\n\nThen, we consider a case where someone attempts a side-to-main\nwithdrawal from sidechain #2, but which tries to cheat the drivechain\nrules (which are mainchain-enforced).\n\nIn one setup, C's security is downgraded. But in other settings it is\nnot. And in other settings it might do something complicated.\n\n(Although, I also plan to introduce minimum parameter values, both to\nprevent C from being harassed in this case, and to force all\ndrivechain-killing actions to be comparable to each other.)\n\nMy thought was to have all drivechain parts to either stand or fall by\nthemselves. But I am open-minded on this.\n\n> The semantics of the deposit process seem very suboptimal. You note that\n> only one user can deposit at a time, but this seems entirely\n> unnecessary. As implemented in the first Elements Alpha release (though\n> I believe subsequently removed in later versions due to the nature of\n> Elements of targeting asymmetric \"federated\" sidechains), if you have\n> outputs that look like `OP_NOPX genesis_block_hash` as the sidechain\n> deposit/storage address, deposit can be fully parallel. To reduce\n> blockchain bloat, spending them for the purpose of combining such\n> outputs is also allowed. ....\n\nWell, your proposal doesn't reduce the bloat, it merely makes\nbloat-reduction possible. And your way relies (slightly) on\nminer-charity, because it imposes an opportunity cost on miners. (Miners\ncould sell their blockspace for fees, but instead they must use it to\nmake these combinations you describe.)\n\nIn contrast, the one-user-deposits-at-a-time not only allows bloat to be\naddressed, but also forces it to be addressed. It is like forcing\nsomeone who uses a shared kitchen to leave it exactly as clean as they\nfound it.\n\nWhile I am concerned by the one-at-a-time concept, I would point out:\n\n* It is NOT one deposit per block. Just one at a time. In general, there\ncan be as many deposits as needed.\n* It will not be a problem if [a] transactions propagate very quickly,\nand [b] transactions are signed very quickly.\n* If the deposit fails, it will likely be easy for the user to re-do it\n(or, this will be made easy, in the UX eventually).\n* It may ultimately be the case, that the task of shepherding the coins\naround is one that is only ever performed by specialists. They would\nhave their own ways of batching txns to deal with this issue. In\ncontrast, regular users might always use atomic swaps / ShapeShift-like\ntools.\n\nNonetheless, I think this is another opportunity for improvement.\nProbably, if someone goes deeper into the scripting language and block\nvalidation rules, they will be able to achieve all of the objectives\nsimultaneously. As you say:\n\n> ...\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 You could even go further and allow some new\n> sighash type to define something like SIGHASH_ALL|SIGHASH_ANYONECANPAY\n> which further specifies some semantics for combining inputs which all\n> pay into the same output.\n\n\n> Finally, you may also want to explore some process for the removal of\n> sidechain balances from the main chain. As proposed it seems like a\n> sidechain might, over time, fade into an insecure state as mining power\n> shifts and new miners no longer consider it worth the value to mine an\n> old sidechain (as has happened over time with namecoin, arguably).\n\nYes, I think there should be some kind of switch for saying \"please\nwithdraw all of your funds because this chain is being closed down\".\nHowever, if miners stopped mining a chain, I think sidechain-users would\nnotice because their blocktimes would start to increase (under blind\nmerged mining, anyway).\n\n\n> Comments on BIP 2:\n>\n> I may be missing something, but I find the security model here kind of\n> depressing...Not only do hashpower-secured sidechains already have a\n> significantly reduced security level, but now you're proposing to\n> further (drastically) reduce it by requiring users to potentially pay in\n> excess of the value an attacker is willing to pay to keep their chain\n> secure, on a recurring basis?\n\nI think you are missing a few things.\n\nFirst of all, I think the security model for sidechains is the same as\nthat of every blockchain\n\nPeople will say things, like \"but with sidechains 51% hashrate can steal\nyour coins!\", but as I have repeated many times, this is also true of\nmainchain btc-tx. As I say on drivechain.info:\n\n\u00a0\"\"\" In theory, the incentives of miners and investors are very strongly\naligned: both are compensated most when the exchange rate is highest.\nAnd, in practice, we do not see large reorganizations (where miners can\n\u201csteal\u201d, by first depositing BTC to major exchanges, then selling that\nBTC for fiat (which they withdraw), and finally rewriting the last 3 or\n4 days of chain history, to un-confirm the original deposits). These\nreorgs would devastate the exchange rate, as they would cast doubt on\nthe entire Bitcoin experiment. The thesis of Drivechain is that\nsidechain-theft would also devastate the exchange rate, as it would cast\ndoubt on the entire sidechain experiment (which would itself cast doubt\non the Bitcoin experiment, given the anti-competitive power of\nsidechains). \"\"\"\n\nIn fact, it is true of everything, including the lightning network. LN\nhas the advantage of allowing victims to spend the attacker's funds on\ntx fees (as these victims desperately try to get their txn included).\nBut the LN loses the blockchain's \"strength in numbers\" advantage --\nminers can single-out unpopular individuals, figure out their channels,\nand steal from them (and only them) at an inopportune time.\n\nThis is not to knock the lightning network -- I believe it is\nwell-designed and likely to be secure. I am merely saying that this\nconcept of stringing these security models on a line from \"most secure\"\nto \"least secure\" is a concept which is reductionist and incorrect.\n\nDrivechain will be more secure if sidechains are popular. But if they\nare not popular, the question of how secure they are is not really\ninteresting, is it?\n\nSecondly, I think you have overlooked something very important indeed.\nSidechains are optional, and so their use should be up to each\nindividual user, and no one else. Users should be free to make their own\nmistakes -- specifically, they should be the ones to decide for\nthemselves if they want to use an \"insecure\" system or not.\n\nIt would be another matter, if you had a competing sidechain idea which\naccomplished the same goal. But you do not.\n\nThirdly, I do not agree with your claim that the security model is\nreduced by BMM. In fact, the way I see it, it is the same as the model\nwe already have, if not better.\n\nTo make this point, let me ask: Who determines the contents (valid or\notherwise) of \"the next block that meets the difficulty requirement\"?\n\nIn Mainchain Bitcoin Core: \"Highest Cumulative Difficulty\"\nBMM Sidechain: \"Highest BTC Payment\"\n\nBut these are actually the very same thing! We merely need to clarify\nour thinking with a few simplifications. First, substitute \"Most Hashes\"\nfor \"Cumulative Difficulty\" (as these are expected converge to each\nother). Second, ignore *unexpected* fluctuations in the two denominator\nprices in the following:\n\n\"Most Hashes\" = \"Most USD Spent on Mining\" / (hashes-per-usd price)\n\"Highest BTC Payment\" = \"Most USD Spent on Mining\" / (btc-per-usd price)\n\n\"Most Hashes\" = \"Highest BTC Payment\" = \"Most USD Spent on Mining\"\n\nIt should be clearer now that they are the same model. While the\nmainchain follows the heaviest chain, measured in hashes, the sidechain\nfollows the heaviest chain, measured in BTC. Both are expressions of the\nsame concept (\"value sacrificed\")...just expressed in different units.\n\nWith that explained, let me bring in this:\n\n>\u00a0\u00a0\u00a0\u00a0\u00a0 ...\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 It seems like if a chain has 10 BTC stored\n> in it, and I wish to reorg it for a potential gain of, lets say, 6 BTC,\n> I can pay 6 * 1 BTC (1 per block) to reorg it, and users on the chain\n> would be forced to pay >6 BTC to avoid this?\n\nYour example (which is a great example) sounds bleak, but it is in fact\nthe security model of Bitcoin itself, in the long future without the\nblock subsidy. Likely, Bitcoin will have new advantages by then\n(assuming it survives that long). But this is a problem that just\n*can't* be solved without a new block subsidy (which can't be added to\nsidechains).\n\nSo, you may be successfully arguing that sidechains can never work. (But\nthat is different from saying that users should be prohibited from\ntrying them out, as I said above). Or, you may be successfully arguing\nthat Bitcoin itself will stop working when fees overwhelm the block\nsubsidy. (Since that hour is rapidly approaching, we might as well start\nrunning experiments now).\n\nThe equivalence between hashes and purchases is not perfect. Certainly,\nregular miners might be better-behaved than BM-miners, because r-miners\nstand to lose their entire hardware investment if the system fails,\nwhereas BM-miners do not. On the other hand, BMM is *better* in a few\nways, namely that it makes \"mining\" much more competitive, because it\nlowers the barriers to entry for sidechain-mining all the way to zero.\nAny node can do it. Furthermore, BM-miners are more cypherpunk-like:\nthey will not be confined to any physical location, they do not give\naway their location (via power usage or thermal exhaust), when they\ngreedily move into high-efficiency spaces (data centers, EC2 instances)\nthey can instantly destroy themselves and reappear somewhere else.\n\nI'm not sure if that made you more, or less depressed. But here is a\nsmiley face :-] .\n\n> While I appreciate the desire to implement the proposed mitigation in\n> section 4.3 of the sidechains paper (delegating the mining effort of a\n> merge-mined sidechain to an external entity), I believe it was primarily\n> referencing pooling the sidechain work, not blindly taking the highest\n> bidder.\n\nWell, BMM is more efficient when there are pools. Without them, the\nsidechain nodes would be trying to connect to all mainchain miners.\n\nAnd there's no need for that. In my view, pools are cannot really do\nanything wrong (ie, pools cannot do anything except what their members\nwant them to do). If a pool operator goes rogue and attempts to censor a\ntransaction, what has actually happened is just that the transaction is\ndelayed (until the hashers learn about the inefficient policy, and\nswitch pools). Same for everything else.\n\nIn other words, yes pool operators would almost certainly be running a\nnode of each sidechain.\n\n>\u00a0 ...\u00a0 I suppose, indeed, that, ultimately, as long as the sidechain is\n> of relatively small value in comparison to BTC, miners do not risk the\n> value of their BTC/mining investment in simply taking the highest bidder\n> of a merge-mined block, even if its a clear attack, ...\n\nIt is not about the amount of BTC on the sidechain. It is about miner's\nestimations of user's valuation of their option to use the sidechain at\nany point in the future. The idea of \"911 emergency response\" is\nvaluable, and people would complain about a motion to get rid of it,\neven though most of those people wouldn't currently be using it.\n\n> Ultimately, I dont believe your proposal here really solves the drawback\n> in section 4.3 of the paper, and possibly makes it worse.\n\nThat is interesting because that section reads:\n\n\u00a0\"\"\" As miners provide work for more blockchains, more resources are\nneeded to track and validate them all. Miners that provide work for a\nsubset of blockchains are compensated less than those which provide work\nfor every possible blockchain. Smaller-scale miners may be unable to\nafford the full costs to mine every blockchain, and could thus be put at\na disadvantage compared to larger, established miners who are able to\nclaim greater compensation from a larger set of blockchains. \"\"\"\n\n\u00a0Which is exactly what BMM does address. It allows miners to ignore the\nresource-cost of the sidechain, and therefore smaller miners will not be\nat a revenue-disadvantage.\n\nDo you think that the drawback is something else?\n\nAnd, are you ever going to define \"miner centralization\"? Is it \"the\neconomic barrier-to-entry for mining\", to you?\n\nPaul\n\n>\n> On 12/01/17 13:38, Paul Sztorc via bitcoin-dev wrote:\n>> Hello,\n>>\n>> First, Drivechain has vaguely escaped vaporware status. If you've ever\n>> thought \"I'd like to take a look into Drivechain when there is code\",\n>> then now is a pretty good time. (Unfinished items include M1, and M8_V2.)\n>>\n>> https://github.com/drivechain-project/bitcoin/tree/mainchainBMM\n>>\n>> Also,\n>> Site:\u00a0 http://www.drivechain.info/\n>> Blank sidechain:\n>> https://github.com/drivechain-project/bitcoin/tree/sidechainBMM\n>>\n>> Second, I think drivechain's documentation / BIP-Drafts are tolerably\n>> readable.\n>>\n>> Here they are:\n>>\n>> 1.\n>>\nhttps://github.com/drivechain-project/docs/blob/master/bip1-hashrate-escrow.md\n>> 2.\n>>\nhttps://github.com/drivechain-project/docs/blob/master/bip2-blind-merged-mining.md\n>>\n>> cc: Luke, I think they are ready to be assigned formal BIP Numbers.\n>>\n>> This is also a request for code review. The most helpful review will\n>> probably take place on GitHub.\n>>\n>> Regular review is also welcome. Although, please read our\n>> recently-updated FAQ, at: http://www.drivechain.info/faq .\n>> And also see major earlier discussions:\n>>\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/014364.html\n>>\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-June/014559.html\n>>\n>> Have a nice weekend everyone,\n>> Paul\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>"
            },
            {
                "author": "Chris Pacia",
                "date": "2017-12-04T19:36:31",
                "message_text_only": "I think you are missing a few things.\n\nFirst of all, I think the security model for sidechains is the same as\nthat of every blockchain\n\nPeople will say things, like \"but with sidechains 51% hashrate can steal\nyour coins!\", but as I have repeated many times, this is also true of\nmainchain btc-tx.  is something else?\n\n\nThere are substantial opportunity costs as well as a collective action\nproblem when it comes to re-writing the mainchain.\n\nIs there anything similar for drivechains? As far as I can tell there is no\nopportunity cost to casting a malicious vote, no repercussions, and no\ncollective action barrier that needs to be overcome.\n\nUnless I'm missing something I wouldn't liken the security of a drivechain\nto that of the mainchain.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171204/2f0566b4/attachment.html>"
            },
            {
                "author": "Chris Stewart",
                "date": "2017-12-04T20:11:13",
                "message_text_only": ">As far as I can tell there is no opportunity cost to casting a malicious\nvote, no repercussions, and no collective action barrier that needs to be\novercome.\n\nThere is another interesting analysis on BMM and drivechains from /u/almkglor\non reddit\n<https://www.reddit.com/r/Bitcoin/comments/6ztp3b/lets_discuss_something_techrelated_for_a_change/dn0rsdo/>.\nI'm going to share here for visibility.\n\nThe problem with drivechains and blind merged mining is the disconnect\n> between voting and \"blind\" merge mining. With BMM, a miner can do:\n>\n>    1. Not accept BMM, not vote.\n>    2. Not accept BMM, operate their own sidechain node, mine sidecoin,\n>    and vote correctly.\n>    3. Not accept BMM, always upvote (i.e. allow theft).\n>    4. Not accept BMM, always downvote (i.e. strangle).\n>    5. Accept BMM, not vote.\n>    6. Accept BMM, operate their own sidechain node, and vote correctly.\n>    (not mine sidecoin directly: they get paid in maincoin by sidecoin-only\n>    miners).\n>    7. Accept BMM, always upvote (i.e. allow theft).\n>    8. Accept BMM, always downvote (i.e. strangle).\n>\n> 3 and 7 will mean that non-verifying miners will be (inadvertently)\n> complicit in theft. Drivechains have 1008-block cycles ostensibly to\n> protect against theft, so that someone can \"raise the alarm\" and tell\n> miners to downvote a particular theft withdrawal, but that sounds too much\n> like centralized collusion to me.\n>\n> Strategy 8 will dominate over strategy 6, since the miner does not have to\n> run a sidechain node (reduced cost) while still earning the same as\n> strategy 6.\n>\n> Strategies 5->8 are all strictly superior to 1->4, so BMM does not really\n> change anything: strategy 8 (equivalent to strategy 4 if BMM is not\n> implemented) will still choke strategy 6 (equivalent to strategy 2 if BMM\n> is not implemented)\n>\n> It seems Drivechain's security model is: miners always upvote by default.\n> If a theft withdrawal is done on the mainchain, some sidechain nodes call\n> up their miner friends (which makes me worry about miner centralization) to\n> downvote it instead.\n>\n> The problem is: what if after a theft withdrawal is defeated, another\n> theft withdrawal is done? And another, and another? This weakens the peg:\n> while a theft withdrawal is on-going, a genuine withdrawal can't be posted\n> (at least as I understand Sztorc's explanation). This chokes the sidechain\n> withdrawal.\n>\n> The difference from maincoin is that attempts to choke the block are\n> somewhat costly and a maincoin user can offer a higher transaction fee to\n> beat the spam. If side->main is choked, no amount of sidecoin can be\n> offered to beat the spammed theft transactions.\n>\n> I don't know, it seems like very weak security to me.\n>\nTLDR: a miner is most profitable if he always accepts BMM bribes, but\ndownvotes withdrawal transactions (WT). This obviously isn't ideal because\na withdrawal will never occur from the drivechain if enough miners employ\nthis strategy -- which seems to be the most profitable strategy.\n\n-Chris\n\n\nOn Mon, Dec 4, 2017 at 1:36 PM, Chris Pacia via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> I think you are missing a few things.\n>\n> First of all, I think the security model for sidechains is the same as\n> that of every blockchain\n>\n> People will say things, like \"but with sidechains 51% hashrate can steal\n> your coins!\", but as I have repeated many times, this is also true of\n> mainchain btc-tx.  is something else?\n>\n>\n> There are substantial opportunity costs as well as a collective action\n> problem when it comes to re-writing the mainchain.\n>\n> Is there anything similar for drivechains? As far as I can tell there is\n> no opportunity cost to casting a malicious vote, no repercussions, and no\n> collective action barrier that needs to be overcome.\n>\n> Unless I'm missing something I wouldn't liken the security of a drivechain\n> to that of the mainchain.\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171204/dd24792f/attachment-0001.html>"
            },
            {
                "author": "Paul Sztorc",
                "date": "2017-12-05T19:55:33",
                "message_text_only": "Hi Other Chris,\n\nThanks for pointing this out. Here are my responses.\n\nOn 12/4/2017 3:11 PM, Chris Stewart wrote:\n>There is another interesting analysis on BMM and drivechains from\n/u/almkglor on reddit. I'm going to share here for visibility.\n>> 3 and 7 will mean that non-verifying miners will be (inadvertently)\ncomplicit in theft. Drivechains have 1008-block cycles ostensibly to\nprotect against theft, so that someone can \"raise the alarm\" and tell\nminers to downvote a particular theft withdrawal, but that sounds too\nmuch like centralized collusion to me.\n\nWell, that is simply not what \"centralized\" means. \"Centralized\" means\nthat one person has special, irreplaceable influence. In contrast,\n\"decentralized\" means that the process is not uniquely influenced by\nwhat any *one* individual does or believes. Which is the case here: each\nminer can independently make a decision about what to check, how to\ncheck it, and what to do as a result. They could do undertake this\nprocess, even if they ignored what everyone else was doing.\n\n>> ...\n>>\n>> It seems Drivechain's security model is: miners always upvote by\ndefault. If a theft withdrawal is done on the mainchain, some sidechain\nnodes call up their miner friends (which makes me worry about miner\ncentralization) to downvote it instead.\n>>\n>> The problem is: what if after a theft withdrawal is defeated, another\ntheft withdrawal is done? And another, and another? This weakens the\npeg: while a theft withdrawal is on-going, a genuine withdrawal can't be\nposted (at least as I understand Sztorc's explanation). This chokes the\nsidechain withdrawal.\n\nThis is a good question.\n\nThe answer is that there are mechanisms in place to address these\nproblems. Contrary to the reviewer's interpretation, multiple\nwithdrawal-attempts *are* allowed simultaneously. (This part of design\nmay have changed between now and Nov 2015, and I'm not sure if it was\never documented anywhere until very recently). Second, only one\nwithdrawal can be upvoted at a time [ie, per sidechain per main:block].\nThird, upvoting one withdrawal automatically downvotes all of the other\nwithdrawals (all in-progress withdrawals for that sidechain). Thus, we\nhave the asymmetry we desire. An \"auditor class\" can ignore all of the\nwithdrawals, until a significant amount of time has been invested in one\ncandidate. This makes the attempt more futile. Since they are unlikely\nto be meaninglessly harassed, this opens the door to a \"farmer class\"\nwho can take it upon themselves to make sure the good withdrawals get\nin, and get upvotes (especially early upvotes). Thus, the system can\ntolerate a large \"loafer class\" who just lazily upvotes everything (or\nnothing, or only the front-runner).\n\n> TLDR: a miner is most profitable if he always accepts BMM bribes, but\ndownvotes withdrawal transactions (WT). This obviously isn't ideal\nbecause a withdrawal will never occur from the drivechain if enough\nminers employ this strategy -- which seems to be the most profitable\nstrategy.\n>\n>-Chris\n\nI agree that miners should \"always accept BMM bribes\". In my recent\nemail to Matt Corallo, I described that this is basically the same as\nsaying that miners should \"always mine on top of the heaviest chain\".\n(Of course, in mainchain Bitcoin miners are advised to mine atop the\nheaviest *valid* chain, which is different from this case. It is\ndifferent because blind-merged-miners have no way of knowing if the\nsidechain blocks they are mining are valid or not, which is kind of the\npoint. In practice I estimate that between 70% and 100% of today's\nhashpower is already mining the mainchain \"blind\" -- through some\ncombination of pools, spv and spy mining.)\n\nI don't agree with the conclusion (that the optimal policy is \"always\ndownvoting\", see above), but even if this analysis turns out to be\ncorrect, it isn't a total disaster. The result (which is in the original\nNov 2015 specification) is that miners are the ones who perform the\natomic swaps. Then they walk the coins side-to-main (which, at this\npoint, are *their* coins). As long as there are a few large mining\ngroups, competition will drive the atomic swap fees down to negligible\nlevels. This slightly encourages mining to consolidate into two large\npools...but of course that is also true of the status quo!\n\nPaul\n\u00a0\n>\n> On Mon, Dec 4, 2017 at 1:36 PM, Chris Pacia via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org\n> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>\n>\n>         I think you are missing a few things.\n>\n>         First of all, I think the security model for sidechains is the\n>         same as\n>         that of every blockchain\n>\n>         People will say things, like \"but with sidechains 51% hashrate\n>         can steal\n>         your coins!\", but as I have repeated many times, this is also\n>         true of\n>         mainchain btc-tx. \u00a0is something else?\n>\n>\n>     There are substantial opportunity costs as well as a collective\n>     action problem when it comes to re-writing the mainchain.\u00a0\n>\n>     Is there anything similar for drivechains? As far as I can tell\n>     there is no opportunity cost to casting a malicious vote, no\n>     repercussions, and no collective action barrier that needs to be\n>     overcome.\u00a0\n>\n>     Unless I'm missing something I wouldn't liken the security of a\n>     drivechain to that of the mainchain.\n>\n>     _______________________________________________\n>     bitcoin-dev mailing list\n>     bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>\n>\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/1ade3365/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2017-12-07T07:28:03",
                "message_text_only": "Good morning Paul and Chris,\n\n>I don't agree with the conclusion (that the optimal policy is \"always downvoting\", see above), but even if this analysis turns out to be correct, it isn't a total disaster. The result (which is in the original Nov\n>2015 specification) is that miners are the ones who perform the atomic swaps. Then they walk the coins side-to-main (which, at this point, are *their* coins). As long as there are a few large mining groups,\n>competition will drive the atomic swap fees down to negligible levels.\n\nAssuming there are three large mining groups who will ruthlessly want to undercut their competition, and with roughly 33% of total hashpower each (with the remaining 1% being some negligible hoi polloi), then one strategy to undercut your competitors would be to upvote only your own withdrawals and downvote that of your competitors.  A miner using this strategy hopes that the other miners will give up on withdrawing their own coin and trade their sidecoins at a discount to the undercutting miner.  That is, it is a hostage attempt of the sidecoin funds of the other miners.\n\nIn the case of three large mining pools that mistrust one another, then, no withdrawal would ever push through and drivechains stabilize to one-way pegs.\n\nNow suppose that two of the mining pools collude.  They join their withdrawals into a single withdrawal proposal and upvote that, while downvoting the withdrawal of the third miner.  I observe that this is an opposite disaster: the 66% colluding miners can instead decide to simply outright make an invalid withdrawal of all funds, split up in half between themselves.\n\n--\n\nBut three exactly equal mining pools is unnatural, for that matter\n\nSuppose that there are three mining pools: A with 34%, B with 33%, C with 32%, and the hoi polloi making up the remaining 1%.  Those three pools cannot safely let the others withdraw funds.\n\nSuppose A colludes with C to join their withdrawal proposals and their hashpower to withdraw.  This means that B can be pressured to sell its sidecoins for a discount to the joint coalition of A and C, since B cannot withdraw its own coins.  This lowers the profitability of B, causing grinders to leave them in favor of either A or C.  Since A is slightly larger than C, it is slightly more preferable, so it grows in size slightly more than C does.  Eventually B dies due to the coalition of A and C.  A and C are the only remaining pools, with A slightly larger than C.  In this case, A can break from the coalition and squeeze C of its sidecoins, since only A can withdraw (as it has more hashpower than C).  Again, grinders will leave C for A.  A rational C that is capable of considering this possible future path will thus never ally with A in a coalition to crush B, as it will then be next in line for being destroyed.\n\nSimilar analyses for coalitions of (B, C) and (A, B).\n\nKnowing this, and knowing that they will end up sidecoin bagholders if they cannot withdraw coins, all miners decide to collude together and put all their withdrawals into a single withdrawal proposal.  But this removes any check-and-balance that the single withdrawal proposal is truthful to the sidechain: that is, the single coalition of A,B, and C can decide to just steal all sidechain funds and reassign them in proportion to their hashpower.  This might be stable at end-of-life for the sidechain where all ordinary users of the sidechain have exited it, but is otherwise a theft risk if the sidechain is operating normally.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171207/61cd76b3/attachment.html>"
            },
            {
                "author": "Paul Sztorc",
                "date": "2017-12-12T22:16:47",
                "message_text_only": "Hello ZmnSCPxj,\n\nThanks for contributing your thoughts. I wish I were able to respond sooner!\n\n1. I'm a little confused about the second half of your message, and its\nemphasis on pools. As you know, pools can be created or destroyed an\nunbounded number of times, costing only a small time lag. So I do not\nsee why anyone would care about pool-death (except for the administrator\nof the pool of course -- and this exception is, itself, strong evidence\nthat pools will reflect the interests of their members). Pools are just\nsome naturally-occurring phenomenon that arise when many different\nhashers all want similar things.\n\n2. You have quoted a section where I suppose that miners are offering an\n'atomic swaps' service. And you usually talk about that hypothetical\nscenario I've outlined. But sometimes you talk in a way that leads me to\nbelieve that you have departed from that hypothetical. For example you\ntalk about frozen withdrawals, invalid withdrawals, and miner-to-user\nharm. But that isn't possible in my hypothetical, because users can\nescape all of those things by using atomic swaps (which, recall are\ninstant and competitively priced, see #4). Moreover, miners can pretend\nto be users (for the purpose of using these atomic swaps). If you want\nto talk about a world where users aren't using these swaps, I would\nappreciate it if you were more clear.\n\n3. The question of miners harassing each other using strategy is a very\ninteresting one.\n\nFirst, (as you seem to know) the withdrawals are designed to be\ncombine-able. This is in fact not only the default behavior but also the\nmost efficient behavior. (Assuming that n quantity of economic transfers\nmust go across, it is of course best to do them in one transaction.) So,\nyour complaint must immediately be limited to the case of \"spiteful\"\nminers who care more about blocking opponent's transfers (for whatever\nreason) than they care about upvoting their own transfers.\n\nHowever, if any miner pursues a spiteful strategy, the victim(s) can\nrespond by orphaning. For example, if 33% are producing 'spiteful\nblocks', the other 66% can easily orphan these. The central issues, as I\nsee it, is that to be *spiteful* is also to be *different* and\n*noticeable*. Thus, different blocks can be orphaned.\n\nSome may worry that this opens the door to endless vindictive arbitrary\norphaning (and that this is either the reason that such an alternative\nwill not work and therefore not be persuasive, or else that the outcome\nof endless arbitrary orphaning would itself be a bad one). My view (and\nobservation) is that the threat of eventual orphaning is sufficient, and\nthat therefore there will be no actual orphaning. This is because the\nantagonizing 33% group is now its own victim group, and they now have an\noverwhelming incentive to either [a] stop being different (in this case,\nspiteful), or else to [b] quickly obtain an additional 18% hashrate so\nas to survive the orphaning. Should they add 18% to their 33%, \"they\"\nwill have 51%, and we might wonder if they will try orphaning of their\nown. However, if they do, it merely restarts the above logic, with the\n49% fighting to persuade a critical 2% to join.\n\nSo far, this logic may terminate with two 50% pools that each stubbornly\nrefuse to interact. But eventually chance will one of their blockchains\nahead of the other's, and the members of the disfavored group will feel\npressure to defect (or else they are likely to be left behind). It is no\ndifferent from traditional miner-bitterness over having not found the\nmost-recent block.\n\nUsers who move side-to-main via atomic swaps will have no reason to care\nabout any of this.\u00a0\n\n4. As I point out in the Nov 2015 specification and security model, and\nas you have suggested, the atomic swaps will only be ultra-cheap and\nultra-available if there exists *some other way* of *eventually* moving\nside-to-main with *certainty*. The goal is to have a side-to-main method\nthat definitely will work, even if it takes a very long time to work.\nThen the atomic swap is paying a premium for speed only, relative to\nthis method. This is why the security model of drivechain relies\n(partially) on investor disappointment that sidechains are no longer\ngoing to be supported. And it is why the slow (non-AtomicSwap)\nwithdrawal process is so slow and delay-able in the first place -- to\nincrease its security. If it is secure enough to withstand any attack,\nthen attackers will eventually give up (or else, they will never attack\nin the first place). This satisfies the criterion of an alternative\nwithdrawal process that is certain and eventual.\n\nPaul\n\n\nOn 12/7/2017 2:28 AM, ZmnSCPxj wrote:\n> Good morning Paul and Chris,\n>\n> >I don't agree with the conclusion (that the optimal policy is \"always\n> downvoting\", see above), but even if this analysis turns out to be\n> correct, it isn't a total disaster. The result (which is in the\n> original Nov\n> >2015 specification) is that miners are the ones who perform the\n> atomic swaps. Then they walk the coins side-to-main (which, at this\n> point, are *their* coins). As long as there are a few large mining\n> groups,\n> >competition will drive the atomic swap fees down to negligible levels.\n>\n> Assuming there are three large mining groups who will ruthlessly want\n> to undercut their competition, and with roughly 33% of total hashpower\n> each (with the remaining 1% being some negligible hoi polloi), then\n> one strategy to undercut your competitors would be to upvote only your\n> own withdrawals and downvote that of your competitors.\u00a0 A miner using\n> this strategy hopes that the other miners will give up on withdrawing\n> their own coin and trade their sidecoins at a discount to the\n> undercutting miner.\u00a0 That is, it is a hostage attempt of the sidecoin\n> funds of the other miners.\n>\n> In the case of three large mining pools that mistrust one another,\n> then, no withdrawal would ever push through and drivechains stabilize\n> to one-way pegs.\n>\n> Now suppose that two of the mining pools collude.\u00a0 They join their\n> withdrawals into a single withdrawal proposal and upvote that, while\n> downvoting the withdrawal of the third miner.\u00a0 I observe that this is\n> an opposite disaster: the 66% colluding miners can instead decide to\n> simply outright make an invalid withdrawal of all funds, split up in\n> half between themselves.\n>\n> --\n>\n> But three exactly equal mining pools is unnatural, for that matter\n>\n> Suppose that there are three mining pools: A with 34%, B with 33%, C\n> with 32%, and the hoi polloi making up the remaining 1%.\u00a0 Those three\n> pools cannot safely let the others withdraw funds.\n>\n> Suppose A colludes with C to join their withdrawal proposals and their\n> hashpower to withdraw.\u00a0 This means that B can be pressured to sell its\n> sidecoins for a discount to the joint coalition of A and C, since B\n> cannot withdraw its own coins.\u00a0 This lowers the profitability of B,\n> causing grinders to leave them in favor of either A or C.\u00a0 Since A is\n> slightly larger than C, it is slightly more preferable, so it grows in\n> size slightly more than C does.\u00a0 Eventually B dies due to the\n> coalition of A and C.\u00a0 A and C are the only remaining pools, with A\n> slightly larger than C.\u00a0 In this case, A can break from the coalition\n> and squeeze C of its sidecoins, since only A can withdraw (as it has\n> more hashpower than C).\u00a0 Again, grinders will leave C for A.\u00a0 A\n> rational C that is capable of considering this possible future path\n> will thus never ally with A in a coalition to crush B, as it will then\n> be next in line for being destroyed.\n>\n> Similar analyses for coalitions of (B, C) and (A, B).\n>\n> Knowing this, and knowing that they will end up sidecoin bagholders if\n> they cannot withdraw coins, all miners decide to collude together and\n> put all their withdrawals into a single withdrawal proposal.\u00a0 But this\n> removes any check-and-balance that the single withdrawal proposal is\n> truthful to the sidechain: that is, the single coalition of A,B, and C\n> can decide to just steal all sidechain funds and reassign them in\n> proportion to their hashpower.\u00a0 This might be stable at end-of-life\n> for the sidechain where all ordinary users of the sidechain have\n> exited it, but is otherwise a theft risk if the sidechain is operating\n> normally.\n>\n> Regards,\n> ZmnSCPxj"
            },
            {
                "author": "Paul Sztorc",
                "date": "2017-12-05T18:05:39",
                "message_text_only": "Hello Chris,\n\n1. Marginal Cost\n\nThere actually is a very small cost to casting a malicious vote,\nrelative to an honest vote. This is because the software (when run\nas-is), will automatically vote correctly. But to vote fraudulently you\nmust decide on what to do instead, and configure that! This might not be\nas easy as it seems (see collective action part, below).\n\nIt is true that there is no *marginal* cost to creating a bad vote, in\nthe fraudulent withdrawal case. But then again there is no marginal cost\nto creating a good vote either -- in fact there is no cost at all. In\nfact, there is no marginal cost to creating a bad block either, in the\n51% hashrate reorganization case. Epistemologically, the protocol has no\nway of differentiating a \"bad\" block/vote from a good one. So one cannot\n\"cost\" more than the other, in a narrow sense.\n\nI suppose in the reorganization case there is the risk of lost mining\neffort on a chain that actually does *not* have 51% and therefore won't\ncatch up. But this only encourages conformity to the longest chain,\nincluding fraudulent chains. For example, imagine that the\nreorganization is done via secretly mining a longer chain -- once that\nchain is published, it will be the longest. Then, according to your\nframework, there will be a \"marginal cost\" to doing the *right* thing\n(trying to preserve the honest, transparent chain). So I'm afraid I\ndon't understand what you mean.\n\n2. Repercussions\n\nAs for there being no repercussions, that is incorrect. The miner's\nchoice to engage in a fraudulent withdraw is one that has several\nnegative consequences. They take a variety of forms and likelihoods, but\nthey definitely exist and are very relevant.\n\nThe first repercussion is the loss of victim-sidechain future tx-fees. A\nsecond is the loss of all future tx fees on all sidechains. A third is\nthat the Bitcoin super-network is changed from being a \"sidechain\nenabled\" network to a \"sidechain disabled\" network.\n\nThe impact of these repercussions is still unclear and open to\ninterpretation. On one hand, the impact may be small and therefore not\nvery persuasive (as in the case where a sidechain has few tx-fees, few\nsidechains are used, few are expected to be created/used, and so little\nis lost by attacking). On the other hand, a single fraudulent withdrawal\nmight motivate the creation of a new spinoff network that is exactly the\nsame as the old network, but with merely two changes: the fraudulent\nwithdrawal surgically removed (as if it were never attempted) AND a new\nproof of work algorithm. Since the withdrawals are so slow, there would\nbe plenty of time to organize such an option (and people who already\nwant a pow-change would jump at this glaring opportunity). Will the\nrepercussions be small or large? Even if there is only a *risk* of large\nrepercussions, it can be very persuasive. (Just as the IRS is very\npersuasive to tax-paying Americans, even though only a tiny proportion\nof tax returns are audited.)\n\n0. Useless Sidechain Fallacy\n\nFinally, you are joining the long list of people who are committing the\n\"useless sidechain fallacy\". You are saying that because you believe the\nsidechain is useless, therefore everyone must believe as you do, and\ntherefore the option to use a sidechain must be one that has zero value.\nHowever, in the real world people are heterogeneous. They may decide\nthat your interpretation contains errors, or else their circumstances\nmight incline them towards a different risk-reward tradeoff. Finally,\nthis fallacy obfuscates the main benefit of sidechains, which is that\nthey are optional -- the sidechain-designer must convince users to\ndeposit funds there.\n\n3. Collective Action Problem\n\nThere actually is a collective action problem inherent to fraudulent\nwithdrawals.\n\nIf miners wish to fraudulently withdraw from the sidechain, they need to\nchoose the destination addresses (on mainchain Bitcoin Core) months in\nadvance. Then they need to upvote/downvote this destination, despite\nthat fact that --during this time-- new hashpower might be coming\nonline/offline, and/or hashers might be joining/leaving specific pools.\nI bring this up to demonstrate that even the most straightforward attack\n(of \"a 51% hashrate group attacks a sidechain and distributes the\nproceeds to the group proportional to hashpower\") is actually one that\ncontains a difficult (and potentially interminable) negotiation. The\neffort required to initiate the negotiation is the source of the\ncollective action problem here.\n\nI think that this collective action problem is actually more burdensome\nthan Bitcoin's -- for mainchain Bitcoin miners merely need to decide\nwhich block height they intend to reorganize from.\n\nYou may wish to read Drivechain's security model to learn more:\nhttp://www.truthcoin.info/blog/drivechain/#drivechains-security\n\nIn this case, I don't see a way to measure \"security\" cardinally or\nordinally. Instead, I am only able to see it as either \"secure enough\"\nor \"not secure enough\". But perhaps someone can enlighten me as to the\nmath they are using to produce these cardinal/ordinal rankings.\n\n--Paul\n\nOn 12/4/2017 2:36 PM, Chris Pacia wrote:\n>\n>     I think you are missing a few things.\n>\n>     First of all, I think the security model for sidechains is the same as\n>     that of every blockchain\n>\n>     People will say things, like \"but with sidechains 51% hashrate can\n>     steal\n>     your coins!\", but as I have repeated many times, this is also true of\n>     mainchain btc-tx. \u00a0is something else?\n>\n>\n> There are substantial opportunity costs as well as a collective action\n> problem when it comes to re-writing the mainchain.\u00a0\n>\n> Is there anything similar for drivechains? As far as I can tell there\n> is no opportunity cost to casting a malicious vote, no repercussions,\n> and no collective action barrier that needs to be overcome.\u00a0\n>\n> Unless I'm missing something I wouldn't liken the security of a\n> drivechain to that of the mainchain.\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/cabb88c2/attachment.html>"
            },
            {
                "author": "AJ West",
                "date": "2017-12-05T18:20:49",
                "message_text_only": "Hello,\n\nI would like to refer to these BIPs in other contexts and conversations.\nRegardless of the pitfalls or benefits, the discussion and technical review\nhappening in this thread (and the ones before) are well-formed ideas with\nan active champion. The point of BIP numbers/conventions are so we're all\non the same page about what we're talking about.\n\nPlease assign these BIP numbers so discussion may continue in a controlled,\ntagged, linear manner, instead of \"the first BIP\" and \"the second BIP.\"\n\nThank you\nAJ West\n\nOn Tue, Dec 5, 2017 at 1:05 PM, Paul Sztorc via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hello Chris,\n>\n> 1. Marginal Cost\n>\n> There actually is a very small cost to casting a malicious vote, relative\n> to an honest vote. This is because the software (when run as-is), will\n> automatically vote correctly. But to vote fraudulently you must decide on\n> what to do instead, and configure that! This might not be as easy as it\n> seems (see collective action part, below).\n>\n> It is true that there is no *marginal* cost to creating a bad vote, in the\n> fraudulent withdrawal case. But then again there is no marginal cost to\n> creating a good vote either -- in fact there is no cost at all. In fact,\n> there is no marginal cost to creating a bad block either, in the 51%\n> hashrate reorganization case. Epistemologically, the protocol has no way of\n> differentiating a \"bad\" block/vote from a good one. So one cannot \"cost\"\n> more than the other, in a narrow sense.\n>\n> I suppose in the reorganization case there is the risk of lost mining\n> effort on a chain that actually does *not* have 51% and therefore won't\n> catch up. But this only encourages conformity to the longest chain,\n> including fraudulent chains. For example, imagine that the reorganization\n> is done via secretly mining a longer chain -- once that chain is published,\n> it will be the longest. Then, according to your framework, there will be a\n> \"marginal cost\" to doing the *right* thing (trying to preserve the honest,\n> transparent chain). So I'm afraid I don't understand what you mean.\n>\n> 2. Repercussions\n>\n> As for there being no repercussions, that is incorrect. The miner's choice\n> to engage in a fraudulent withdraw is one that has several negative\n> consequences. They take a variety of forms and likelihoods, but they\n> definitely exist and are very relevant.\n>\n> The first repercussion is the loss of victim-sidechain future tx-fees. A\n> second is the loss of all future tx fees on all sidechains. A third is that\n> the Bitcoin super-network is changed from being a \"sidechain enabled\"\n> network to a \"sidechain disabled\" network.\n>\n> The impact of these repercussions is still unclear and open to\n> interpretation. On one hand, the impact may be small and therefore not very\n> persuasive (as in the case where a sidechain has few tx-fees, few\n> sidechains are used, few are expected to be created/used, and so little is\n> lost by attacking). On the other hand, a single fraudulent withdrawal might\n> motivate the creation of a new spinoff network that is exactly the same as\n> the old network, but with merely two changes: the fraudulent withdrawal\n> surgically removed (as if it were never attempted) AND a new proof of work\n> algorithm. Since the withdrawals are so slow, there would be plenty of time\n> to organize such an option (and people who already want a pow-change would\n> jump at this glaring opportunity). Will the repercussions be small or\n> large? Even if there is only a *risk* of large repercussions, it can be\n> very persuasive. (Just as the IRS is very persuasive to tax-paying\n> Americans, even though only a tiny proportion of tax returns are audited.)\n>\n> 0. Useless Sidechain Fallacy\n>\n> Finally, you are joining the long list of people who are committing the\n> \"useless sidechain fallacy\". You are saying that because you believe the\n> sidechain is useless, therefore everyone must believe as you do, and\n> therefore the option to use a sidechain must be one that has zero value.\n> However, in the real world people are heterogeneous. They may decide that\n> your interpretation contains errors, or else their circumstances might\n> incline them towards a different risk-reward tradeoff. Finally, this\n> fallacy obfuscates the main benefit of sidechains, which is that they are\n> optional -- the sidechain-designer must convince users to deposit funds\n> there.\n>\n> 3. Collective Action Problem\n>\n> There actually is a collective action problem inherent to fraudulent\n> withdrawals.\n>\n> If miners wish to fraudulently withdraw from the sidechain, they need to\n> choose the destination addresses (on mainchain Bitcoin Core) months in\n> advance. Then they need to upvote/downvote this destination, despite that\n> fact that --during this time-- new hashpower might be coming\n> online/offline, and/or hashers might be joining/leaving specific pools. I\n> bring this up to demonstrate that even the most straightforward attack (of\n> \"a 51% hashrate group attacks a sidechain and distributes the proceeds to\n> the group proportional to hashpower\") is actually one that contains a\n> difficult (and potentially interminable) negotiation. The effort required\n> to initiate the negotiation is the source of the collective action problem\n> here.\n>\n> I think that this collective action problem is actually more burdensome\n> than Bitcoin's -- for mainchain Bitcoin miners merely need to decide which\n> block height they intend to reorganize from.\n>\n> You may wish to read Drivechain's security model to learn more:\n> http://www.truthcoin.info/blog/drivechain/#drivechains-security\n>\n> In this case, I don't see a way to measure \"security\" cardinally or\n> ordinally. Instead, I am only able to see it as either \"secure enough\" or\n> \"not secure enough\". But perhaps someone can enlighten me as to the math\n> they are using to produce these cardinal/ordinal rankings.\n>\n> --Paul\n>\n>\n> On 12/4/2017 2:36 PM, Chris Pacia wrote:\n>\n>\n> I think you are missing a few things.\n>\n> First of all, I think the security model for sidechains is the same as\n> that of every blockchain\n>\n> People will say things, like \"but with sidechains 51% hashrate can steal\n> your coins!\", but as I have repeated many times, this is also true of\n> mainchain btc-tx.  is something else?\n>\n>\n> There are substantial opportunity costs as well as a collective action\n> problem when it comes to re-writing the mainchain.\n>\n> Is there anything similar for drivechains? As far as I can tell there is\n> no opportunity cost to casting a malicious vote, no repercussions, and no\n> collective action barrier that needs to be overcome.\n>\n> Unless I'm missing something I wouldn't liken the security of a drivechain\n> to that of the mainchain.\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/c6cc0277/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2017-12-06T04:49:12",
                "message_text_only": "Good morning Paul and Chris,\n\n>3. Collective Action Problem\n>\n>There actually is a collective action problem inherent to fraudulent withdrawals.\n>\n>If miners wish to fraudulently withdraw from the sidechain, they need to choose the destination addresses (on mainchain Bitcoin Core) months in advance. Then they need to upvote/downvote this\n>destination, despite that fact that --during this time-- new hashpower might be coming online/offline, and/or hashers might be joining/leaving specific pools. I bring this up to demonstrate that even the most\n>straightforward attack (of \"a 51% hashrate group attacks a sidechain and distributes the proceeds to the group proportional to hashpower\") is actually one that contains a difficult (and potentially\n>interminable) negotiation. The effort required to initiate the negotiation is the source of the collective action problem here.\n>\n>I think that this collective action problem is actually more burdensome than Bitcoin's -- for mainchain Bitcoin miners merely need to decide which block height they intend to reorganize from.\n\nI actually devised a way to work around this collective action problem, and discussed it obliquely in a private e-mail with Chris, while I was preparing my article on sidechain weaknesses.  I removed it before publication of the sidechain weaknesses article, but perhaps I should not have.\n\nCollective action can be ensured by contract.  In a world where some system can enforce certain actions programmatically, it is possible to ensure collective action via a program, i.e. a \"smart contract\".\n\nThe thief pays out to the destination address that is a P2SH of the below script:\n\nOP_IF\n  OP_HASH160 <hash> OP_EQUALVERIFY\n  OP_DUP OP_HASH160 <thiefPubKeyHash> OP_EQUALVERIFY OP_CHECKSIG\nOP_ELSE\n  <withdrawTime+1week> OP_CHECKLOCKTIMEVERIFY OP_DROP\n  OP_TRUE\nOP_ENDIF\n\nIf the thief does not publish the preimage of the hash within 1 week of the withdrawal time, then it becomes possible for anyone to spend the above script; basically, some lucky miner who wins the first block past the specified time will get the entire winnings.  Let us call the above script, the Theft Contract.\n\nThe thief then recruits accomplices to the theft.  Note that the attack can be prepared and initiated before the accomplices are even recruited.\n\nThe thief locks some coins (the \"cut\" the accomplice gets), to the below script, for each accomplice it tries to entice:\n\nOP_IF\n  OP_HASH160 <hash> OP_EQUALVERIFY\n  OP_DUP OP_HASH160 <accomplicePubKeyHash> OP_EQUALVERIFY OP_CHECKSIG\nOP_ELSE\n  <withdrawTime+2week> OP_CHECKLOCKTIMEVERIFY OP_DROP\n  OP_DUP OP_HASH160 <thiefPubKeyHash> OP_EQUALVERIFY OP_CHECKSIG\nOP_ENDIF\n\nLet us call the above script, the Accomplice Contract.  If the accomplice accepts, he or she then starts to vote for the invalid withdrawal.\n\nIf the invalid withdrawal succeeds, the thief acquires the entire theft price from the Theft Contract by publishing the preimage to the <hash>.  (If he or she does not, then, some randomly-selected miner will acquire the money after the timeout, so the thief needs to publish the hash, before the timeout in the Theft Contract).\n\nThis publishes the preimage on the blockchain.  Each accomplice can then acquire their \"cut\" of the theft by copying the preimage and claiming from the Accomplice Contract.\n\nIf the theft never succeeds, then there is no reason for the thief to ever publish the preimage, and after the timeout on the Accomplice Contract, the thief can recover his or her offered funds at no loss (minus transaction fees),  This incentivizes accomplices to actually cooperate with the thief, as they will not get paid if the theft does not push through.\n\nAll that is necessary is for a single \"mastermind\" thief to begin this process.  Accomplices can be recruited later, with the \"cut\" they get negotiated according to how much hashpower they can bring to bear on theft.\n\nNewly-created miners and mining pools can be enticed at the time they arise by offering an Accomplice Contract to them.  Thus, newly-created miners and mining pools can be brought into cooperation with the thief as soon as they make a presence on the blockchain.\n\nEven if some mining pool makes a public statement that they will not assist in the theft, the thief may still commit an Accomplice Contract for them on-chain anyway, and publicize it, in order to put the integrity of that mining pool in question and drive out support from that mining pool.  True accomplices may pretend to initially be honest and then signal dishonestly later, in order to make it more plausible that a pool that \"committed\" to not support the theft is not trustable since they have an Accomplice Contract that will compensate them if they support the theft, creating further confusion and discord among honest miners.  The thief may also use the existence of such an Accomplice Contract while negotiating with more minor miners and mining pools, in order to entice those also to join, and thus gain additional buffer against the stochastic process of miner voting.\n\nWith the Theft Contract and the Accomplice Contract, negotiation can be done in parallel with the theft attempt, reducing the cost of organizing collective action, as we have all hoped \"smart contracts\" would do.\n\n----\n\nWhile it is true, that this requires that the thief have significant funds in reserve prior to theft (in order to fund the Accomplice Contracts he or she will have to offer to potential accomplices), we have always been assured that theft can be initiated by miners only, and that miners already have a significant amount of money they control.  So it will be no problem for a potential thief to reserve some funds for paying to Accomplice Contracts.\n\nThis vulnerability can be fixed if withdrawals are restricted to simple P2PKH or P2WPKH only, but in the presence of Scriptless Script and Bellare-Neven signatures, that may be sufficient to create the Theft Contract and the Accomplice Contract (but I know too little of Scriptless Script to be sure).\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/7541418d/attachment-0001.html>"
            },
            {
                "author": "CryptAxe",
                "date": "2017-12-06T20:51:43",
                "message_text_only": "On 12/05/2017 08:49 PM, ZmnSCPxj via bitcoin-dev wrote:\n\n> ...\n> This vulnerability can be fixed if withdrawals are restricted to\n> simple P2PKH or P2WPKH only,\n\nLimiting the withdrawal outputs to P2PKH and perhaps P2WPKH (would there\nbe any network benefit to supporting witness pubkeys for withdrawals?)\nwouldn't be too much work for me. The downside is that people might want\nto withdraw to multisig scripts, or any other legitimate P2SH. If it\nprevents a huge issue, then it is probably worth it.\n\n\n> but in the presence of Scriptless Script and Bellare-Neven signatures,\n> that may be sufficient to create the Theft Contract and the Accomplice\n> Contract (but I know too little of Scriptless Script to be sure).\n>\n> Regards,\n> ZmnSCPxj\n>\n\nI'm curious if anyone on this list could help answer this.\n\nThanks!"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2017-12-08T15:40:11",
                "message_text_only": "Good morning CryptAxe,\n\nI have come to realize that P2PKH is powerful enough to write a Theft Contract from which other Accomplice Contracts can derive.\n\nThe core of the Theft Contract and the Accomplice Contract is that they are both HTLCs.  The difference is that the Theft Contract, the timelock is anyone-can-spend after the time limit.  The Accomplice Contract is an ordinary HTLC.\n\nHowever, P2PKH, plus an off-chain method, can be combined to form a HTLC with anyone-can-spend after the timelock.\n\nP2PKH includes <pubKeyHash>.  Spending from a P2PKH reveals the preimage to <pubKeyHash>, the public key.  Thus, the Accomplice Contract can use the P2PKH <pubKeyHash> as the hash, and when the P2PKH is spent, acquire the public key to be used as the preimage of the hashlock.\n\nThe remaining ingredient is a timelock with anyone-can-spend after the time limit.  And I belatedly realized that I have in fact seen an offchain method of imposing a timelock on information: https://www.gwern.net/Self-decrypting-files  To create a timelock, the \"mastermind\" thief encrypts the private key to the P2PKH in such a timelocked-encryption scheme, and publishes it as part of the theft attempt to commit themselves to the timelock, together with a zero-knowledge proof that the timelock-encrypted private key is correctly the private key to the given public key hash (I am not mathematically gifted enough to know if such a proof if possible, however, and if this is impossible, then this entire scheme cannot work).  Thus, if the thief does not spend the P2PKH (which reveals the preimage to the hash, which unlocks the Accomplice Contracts and pays the accomplices), then someone else can grind the timelock-encryption and spend the P2PKH (and also incidentally unlocks the Accomplice Contracts anyway).\n\nOf course, timelock-encryption is significantly less reliable as a time measure (different sequential processing speeds yield different timelocks from the same timelock-encrypted data), but that may be enough to have a reasonably trustless Thief-Accomplice coordination structure.\n\nAnother issue is that if the Accomplice does not cooperate and the theft fails, the Accomplices may still grind the timelock-encryption and acquire the private key, from which they can compute the public key, which is also the preimage to their hashlock.  So there may not actually be an incentive to coordinate with the Thief under this structure.  But perhaps this idea may trigger someone else to consider how to exploit the precise mathematics of P2PKH to create something similar to a HTLC.\n\nRegards,\nZmnSCPxj\n\n-------- Original Message --------\nSubject: Re: [bitcoin-dev] Two Drivechain BIPs\nLocal Time: December 7, 2017 4:51 AM\nUTC Time: December 6, 2017 8:51 PM\nFrom: bitcoin-dev at lists.linuxfoundation.org\nTo: bitcoin-dev at lists.linuxfoundation.org\n\nOn 12/05/2017 08:49 PM, ZmnSCPxj via bitcoin-dev wrote:\n...\nThis vulnerability can be fixed if withdrawals are restricted to\nsimple P2PKH or P2WPKH only,\n\nLimiting the withdrawal outputs to P2PKH and perhaps P2WPKH (would there\nbe any network benefit to supporting witness pubkeys for withdrawals?)\nwouldn't be too much work for me. The downside is that people might want\nto withdraw to multisig scripts, or any other legitimate P2SH. If it\nprevents a huge issue, then it is probably worth it.\n\nbut in the presence of Scriptless Script and Bellare-Neven signatures,\nthat may be sufficient to create the Theft Contract and the Accomplice\nContract (but I know too little of Scriptless Script to be sure).\nRegards,\nZmnSCPxj\n\nI'm curious if anyone on this list could help answer this.\n\nThanks!\n\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171208/63502b3f/attachment.html>"
            },
            {
                "author": "Paul Sztorc",
                "date": "2017-12-12T22:29:39",
                "message_text_only": "Hi Zmn,\n\nI'm actually not sure that the existence of these tools makes the\nattacker's collective action problem that much easier to solve.\n\nAs I said: \"...even the most straightforward attack (of \"a 51% hashrate\ngroup attacks a sidechain and distributes the proceeds to the group\nproportional to hashpower\") is actually one that contains a difficult\n(and potentially interminable) negotiation.\"\n\nBut even under your scheme, there is someone who has to seek out the\nAccomplices, and has to try to figure out what is acceptable to pay\nthem. This sparks a tiresome negotiation that drains both parties of\ntime and effort and might potentially last forever. Problematically,\nthere is a Market for Lemons problem with respect to how many blocks an\nAccomplice \"will\" mine. If many people try to be Thieves at once, then\neach individual Thief has less of an incentive to bother trying to steal\nin the first place.\n\nAnd so, even if your scheme does work, the improvement seems small. And\neven if the improvement is very great, the remaining collective action\nproblem is still more difficult than the one in the comparative \"reorg\ncase\" (in which the problem is just to \"pick the block number from which\nto start the reorg\").\n\nPaul\n\n\n\nOn 12/5/2017 11:49 PM, ZmnSCPxj wrote:\n> Good morning Paul and Chris,\n>\n> >3. Collective Action Problem\n> >\n> >There actually is a collective action problem inherent to fraudulent\n> withdrawals.\n> >\n> >If miners wish to fraudulently withdraw from the sidechain, they need\n> to choose the destination addresses (on mainchain Bitcoin Core) months\n> in advance. Then they need to upvote/downvote this\n> >destination, despite that fact that --during this time-- new\n> hashpower might be coming online/offline, and/or hashers might be\n> joining/leaving specific pools. I bring this up to demonstrate that\n> even the most\n> >straightforward attack (of \"a 51% hashrate group attacks a sidechain\n> and distributes the proceeds to the group proportional to hashpower\")\n> is actually one that contains a difficult (and potentially\n> >interminable) negotiation. The effort required to initiate the\n> negotiation is the source of the collective action problem here.\n> >\n> >I think that this collective action problem is actually more\n> burdensome than Bitcoin's -- for mainchain Bitcoin miners merely need\n> to decide which block height they intend to reorganize from.\n>\n> I actually devised a way to work around this collective action\n> problem, and discussed it obliquely in a private e-mail with Chris,\n> while I was preparing my article on sidechain weaknesses.\u00a0 I removed\n> it before publication of the sidechain weaknesses article, but perhaps\n> I should not have.\n>\n> Collective action can be ensured by contract.\u00a0 In a world where some\n> system can enforce certain actions programmatically, it is possible to\n> ensure collective action via a program, i.e. a \"smart contract\".\n>\n> The thief pays out to the destination address that is a P2SH of the\n> below script:\n>\n> OP_IF\n> \u00a0 OP_HASH160 <hash> OP_EQUALVERIFY\n> \u00a0 OP_DUP OP_HASH160 <thiefPubKeyHash> OP_EQUALVERIFY OP_CHECKSIG\n> OP_ELSE\n> \u00a0 <withdrawTime+1week> OP_CHECKLOCKTIMEVERIFY OP_DROP\n> \u00a0 OP_TRUE\n> OP_ENDIF\n>\n> If the thief does not publish the preimage of the hash within 1 week\n> of the withdrawal time, then it becomes possible for anyone to spend\n> the above script; basically, some lucky miner who wins the first block\n> past the specified time will get the entire winnings.\u00a0 Let us call the\n> above script, the Theft Contract.\n>\n> The thief then recruits accomplices to the theft.\u00a0 Note that the\n> attack can be prepared and initiated before the accomplices are even\n> recruited.\n>\n> The thief locks some coins (the \"cut\" the accomplice gets), to the\n> below script, for each accomplice it tries to entice:\n>\n> OP_IF\n> \u00a0 OP_HASH160 <hash> OP_EQUALVERIFY\n> \u00a0 OP_DUP OP_HASH160 <accomplicePubKeyHash> OP_EQUALVERIFY OP_CHECKSIG\n> OP_ELSE\n> \u00a0 <withdrawTime+2week> OP_CHECKLOCKTIMEVERIFY OP_DROP\n> \u00a0 OP_DUP OP_HASH160 <thiefPubKeyHash> OP_EQUALVERIFY OP_CHECKSIG\n> OP_ENDIF\n>\n> Let us call the above script, the Accomplice Contract.\u00a0 If the\n> accomplice accepts, he or she then starts to vote for the invalid\n> withdrawal.\n>\n> If the invalid withdrawal succeeds, the thief acquires the entire\n> theft price from the Theft Contract by publishing the preimage to the\n> <hash>.\u00a0 (If he or she does not, then, some randomly-selected miner\n> will acquire the money after the timeout, so the thief needs to\n> publish the hash, before the timeout in the Theft Contract).\n>\n> This publishes the preimage on the blockchain.\u00a0 Each accomplice can\n> then acquire their \"cut\" of the theft by copying the preimage and\n> claiming from the Accomplice Contract.\n>\n> If the theft never succeeds, then there is no reason for the thief to\n> ever publish the preimage, and after the timeout on the Accomplice\n> Contract, the thief can recover his or her offered funds at no loss\n> (minus transaction fees),\u00a0 This incentivizes accomplices to actually\n> cooperate with the thief, as they will not get paid if the theft does\n> not push through.\n>\n> All that is necessary is for a single \"mastermind\" thief to begin this\n> process.\u00a0 Accomplices can be recruited later, with the \"cut\" they get\n> negotiated according to how much hashpower they can bring to bear on\n> theft.\n>\n> Newly-created miners and mining pools can be enticed at the time they\n> arise by offering an Accomplice Contract to them.\u00a0 Thus, newly-created\n> miners and mining pools can be brought into cooperation with the thief\n> as soon as they make a presence on the blockchain.\n>\n> Even if some mining pool makes a public statement that they will not\n> assist in the theft, the thief may still commit an Accomplice Contract\n> for them on-chain anyway, and publicize it, in order to put the\n> integrity of that mining pool in question and drive out support from\n> that mining pool.\u00a0 True accomplices may pretend to initially be honest\n> and then signal dishonestly later, in order to make it more plausible\n> that a pool that \"committed\" to not support the theft is not trustable\n> since they have an Accomplice Contract that will compensate them if\n> they support the theft, creating further confusion and discord among\n> honest miners.\u00a0 The thief may also use the existence of such an\n> Accomplice Contract while negotiating with more minor miners and\n> mining pools, in order to entice those also to join, and thus gain\n> additional buffer against the stochastic process of miner voting.\n>\n> With the Theft Contract and the Accomplice Contract, negotiation can\n> be done in parallel with the theft attempt, reducing the cost of\n> organizing collective action, as we have all hoped \"smart contracts\"\n> would do.\n>\n> ----\n>\n> While it is true, that this requires that the thief have significant\n> funds in reserve prior to theft (in order to fund the Accomplice\n> Contracts he or she will have to offer to potential accomplices), we\n> have always been assured that theft can be initiated by miners only,\n> and that miners already have a significant amount of money they\n> control.\u00a0 So it will be no problem for a potential thief to reserve\n> some funds for paying to Accomplice Contracts.\n>\n> This vulnerability can be fixed if withdrawals are restricted to\n> simple P2PKH or P2WPKH only, but in the presence of Scriptless Script\n> and Bellare-Neven signatures, that may be sufficient to create the\n> Theft Contract and the Accomplice Contract (but I know too little of\n> Scriptless Script to be sure).\n>\n> Regards,\n> ZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2017-12-14T03:24:07",
                "message_text_only": "Good morning Paul,\n\nIt seems many blocks have a coinbase that pays out to a P2PKH.\n\nThe public key hash of a potential Accomplice is then readily visible on-chain on the P2PKH of the coinbase.\n\nWhat is more, the potential Accomplice's hashpower can be judged on-chain also: the more blocks pay out to their P2PKH, the greater their hashpower.\n\nFrom this, the motivating Thief can blindly and automatically create HTLCs paying out to the public key hash of potential Accomplices, weighed according to how many blocks were mined by those.\n\nThen the motivating Thief can broadcast (perhaps on some website they control, via social media, and so on) the fact of the HTLCs existing, without negotiating with the Accomplices.  It is a simple \"take it or leave it\": if the theft succeeds (whether the Accomplice assisted in the theft or not) the Accompilce can get paid.  Thus, communication overhead is reduced to a single broadcast message (the Thief might batch a number of different possible Accomplices, and in addition, might want to play on the psychological effect of the broadcast), and the Accomplice is simply faced with the choice: either participate in the theft (and increase the chance they earn money from it) or protect against the theft (and reduce the chance they earn money from it).\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n> -------- Original Message --------\n> Subject: Re: [bitcoin-dev] Two Drivechain BIPs\n> Local Time: December 13, 2017 6:29 AM\n> UTC Time: December 12, 2017 10:29 PM\n> From: truthcoin at gmail.com\n> To: ZmnSCPxj <ZmnSCPxj at protonmail.com>, Chris Stewart <chris at suredbits.com>\n> Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\n>\n> Hi Zmn,\n>\n> I'm actually not sure that the existence of these tools makes the\n> attacker's collective action problem that much easier to solve.\n>\n> As I said: \"...even the most straightforward attack (of \"a 51% hashrate\n> group attacks a sidechain and distributes the proceeds to the group\n> proportional to hashpower\") is actually one that contains a difficult\n> (and potentially interminable) negotiation.\"\n>\n> But even under your scheme, there is someone who has to seek out the\n> Accomplices, and has to try to figure out what is acceptable to pay\n> them. This sparks a tiresome negotiation that drains both parties of\n> time and effort and might potentially last forever. Problematically,\n> there is a Market for Lemons problem with respect to how many blocks an\n> Accomplice \"will\" mine. If many people try to be Thieves at once, then\n> each individual Thief has less of an incentive to bother trying to steal\n> in the first place.\n>\n> And so, even if your scheme does work, the improvement seems small. And\n> even if the improvement is very great, the remaining collective action\n> problem is still more difficult than the one in the comparative \"reorg\n> case\" (in which the problem is just to \"pick the block number from which\n> to start the reorg\").\n>\n> Paul\n>\n> On 12/5/2017 11:49 PM, ZmnSCPxj wrote:\n>\n>> Good morning Paul and Chris,\n>>\n>>> - Collective Action Problem\n>>>\n>>> There actually is a collective action problem inherent to fraudulent\n>>> withdrawals.\n>>> If miners wish to fraudulently withdraw from the sidechain, they need\n>>> to choose the destination addresses (on mainchain Bitcoin Core) months\n>>> in advance. Then they need to upvote/downvote this\n>>> destination, despite that fact that --during this time-- new\n>>> hashpower might be coming online/offline, and/or hashers might be\n>>> joining/leaving specific pools. I bring this up to demonstrate that\n>>> even the most\n>>> straightforward attack (of \"a 51% hashrate group attacks a sidechain\n>>> and distributes the proceeds to the group proportional to hashpower\")\n>>> is actually one that contains a difficult (and potentially\n>>> interminable) negotiation. The effort required to initiate the\n>>> negotiation is the source of the collective action problem here.\n>>> I think that this collective action problem is actually more\n>>> burdensome than Bitcoin's -- for mainchain Bitcoin miners merely need\n>>> to decide which block height they intend to reorganize from.\n>>\n>> I actually devised a way to work around this collective action\n>> problem, and discussed it obliquely in a private e-mail with Chris,\n>> while I was preparing my article on sidechain weaknesses.  I removed\n>> it before publication of the sidechain weaknesses article, but perhaps\n>> I should not have.\n>> Collective action can be ensured by contract.  In a world where some\n>> system can enforce certain actions programmatically, it is possible to\n>> ensure collective action via a program, i.e. a \"smart contract\".\n>> The thief pays out to the destination address that is a P2SH of the\n>> below script:\n>> OP_IF\n>>   OP_HASH160 <hash> OP_EQUALVERIFY\n>>   OP_DUP OP_HASH160 <thiefPubKeyHash> OP_EQUALVERIFY OP_CHECKSIG\n>> OP_ELSE\n>>   <withdrawTime+1week> OP_CHECKLOCKTIMEVERIFY OP_DROP\n>>   OP_TRUE\n>> OP_ENDIF\n>> If the thief does not publish the preimage of the hash within 1 week\n>> of the withdrawal time, then it becomes possible for anyone to spend\n>> the above script; basically, some lucky miner who wins the first block\n>> past the specified time will get the entire winnings.  Let us call the\n>> above script, the Theft Contract.\n>> The thief then recruits accomplices to the theft.  Note that the\n>> attack can be prepared and initiated before the accomplices are even\n>> recruited.\n>> The thief locks some coins (the \"cut\" the accomplice gets), to the\n>> below script, for each accomplice it tries to entice:\n>> OP_IF\n>>   OP_HASH160 <hash> OP_EQUALVERIFY\n>>   OP_DUP OP_HASH160 <accomplicePubKeyHash> OP_EQUALVERIFY OP_CHECKSIG\n>> OP_ELSE\n>>   <withdrawTime+2week> OP_CHECKLOCKTIMEVERIFY OP_DROP\n>>   OP_DUP OP_HASH160 <thiefPubKeyHash> OP_EQUALVERIFY OP_CHECKSIG\n>> OP_ENDIF\n>> Let us call the above script, the Accomplice Contract.  If the\n>> accomplice accepts, he or she then starts to vote for the invalid\n>> withdrawal.\n>> If the invalid withdrawal succeeds, the thief acquires the entire\n>> theft price from the Theft Contract by publishing the preimage to the\n>> <hash>.  (If he or she does not, then, some randomly-selected miner\n>> will acquire the money after the timeout, so the thief needs to\n>> publish the hash, before the timeout in the Theft Contract).\n>> This publishes the preimage on the blockchain.  Each accomplice can\n>> then acquire their \"cut\" of the theft by copying the preimage and\n>> claiming from the Accomplice Contract.\n>> If the theft never succeeds, then there is no reason for the thief to\n>> ever publish the preimage, and after the timeout on the Accomplice\n>> Contract, the thief can recover his or her offered funds at no loss\n>> (minus transaction fees),  This incentivizes accomplices to actually\n>> cooperate with the thief, as they will not get paid if the theft does\n>> not push through.\n>> All that is necessary is for a single \"mastermind\" thief to begin this\n>> process.  Accomplices can be recruited later, with the \"cut\" they get\n>> negotiated according to how much hashpower they can bring to bear on\n>> theft.\n>> Newly-created miners and mining pools can be enticed at the time they\n>> arise by offering an Accomplice Contract to them.  Thus, newly-created\n>> miners and mining pools can be brought into cooperation with the thief\n>> as soon as they make a presence on the blockchain.\n>> Even if some mining pool makes a public statement that they will not\n>> assist in the theft, the thief may still commit an Accomplice Contract\n>> for them on-chain anyway, and publicize it, in order to put the\n>> integrity of that mining pool in question and drive out support from\n>> that mining pool.  True accomplices may pretend to initially be honest\n>> and then signal dishonestly later, in order to make it more plausible\n>> that a pool that \"committed\" to not support the theft is not trustable\n>> since they have an Accomplice Contract that will compensate them if\n>> they support the theft, creating further confusion and discord among\n>> honest miners.  The thief may also use the existence of such an\n>> Accomplice Contract while negotiating with more minor miners and\n>> mining pools, in order to entice those also to join, and thus gain\n>> additional buffer against the stochastic process of miner voting.\n>> With the Theft Contract and the Accomplice Contract, negotiation can\n>> be done in parallel with the theft attempt, reducing the cost of\n>> organizing collective action, as we have all hoped \"smart contracts\"\n>> would do.\n>> ---------------------------------------------------------------\n>>\n>> While it is true, that this requires that the thief have significant\n>> funds in reserve prior to theft (in order to fund the Accomplice\n>> Contracts he or she will have to offer to potential accomplices), we\n>> have always been assured that theft can be initiated by miners only,\n>> and that miners already have a significant amount of money they\n>> control.  So it will be no problem for a potential thief to reserve\n>> some funds for paying to Accomplice Contracts.\n>> This vulnerability can be fixed if withdrawals are restricted to\n>> simple P2PKH or P2WPKH only, but in the presence of Scriptless Script\n>> and Bellare-Neven signatures, that may be sufficient to create the\n>> Theft Contract and the Accomplice Contract (but I know too little of\n>> Scriptless Script to be sure).\n>> Regards,\n>> ZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171213/f53d60bf/attachment-0001.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2017-12-05T07:41:59",
                "message_text_only": "On Sunday 03 December 2017 9:32:15 PM Matt Corallo wrote:\n> Given the lack of convincing evidence of that \"Risk of centralisation of\n> mining\" drawback in section 4.3 of the sidechains paper has been\n> meaningfully addressed, I'd say its pretty important that new sidechains be\n> an incredibly rare event.\n\nThis is impossible to guarantee. Federated sidechains are already possible \nwith simple multisig (and they could very well be merge-mined chains instead \nof simply signed). At the same time, the value of permissionless sidechain \ninnovation is potentially huge.\n\nLuke"
            }
        ],
        "thread_summary": {
            "title": "Two Drivechain BIPs",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Chris Stewart",
                "CryptAxe",
                "ZmnSCPxj",
                "Luke Dashjr",
                "Paul Sztorc",
                "Matt Corallo",
                "Chris Pacia",
                "AJ West"
            ],
            "messages_count": 16,
            "total_messages_chars_count": 90689
        }
    },
    {
        "title": "[bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks",
        "thread_messages": [
            {
                "author": "Damian Williamson",
                "date": "2017-12-03T04:07:16",
                "message_text_only": "# BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks\n\nI admit, with my limited experience in the operation of the protocol, the section entitled 'Solution operation' may not be entirely correct but you will get the idea. If I have it wrong, please correct it back to the list.\n\n\n## The problem:\n\n\nEverybody wants value. Miners want to maximize revenue from fees. Consumers want transaction reliability and, (we presume) low fees.\n\nCurrent transaction bandwidth limit is a limiting factor for both.\n\n\n## Solution summary:\n\n\nProvide each transaction with a transaction weight, being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=30 ?); the transaction weight serving as the likelihood of a transaction being included in the current block, and then use a target block size.\n\nProtocol enforcement to prevent high or low blocksize cheating to be handled by having the protocol determine the target size for the current block using; current transaction pool size x ( 1 / (144 x n days ) ) = transactions to be included in the current block.\n\nThe curves used for the weight of transactions would have to be appropriate.\n\n\n## Pros:\n\n* Maximizes transaction reliability.\n* Maximizes possibility for consumer and business uptake.\n* Maximizes total fees paid per block without reducing reliability; because of reliability, confidence and uptake are greater; therefore, more transactions and more transactions total at priority fees.\n* Market determines fee paid for transaction priority.\n\n* Fee recommendations work all the way out to 30 days or greater.\n\n* Provides additional block entropy and greater security since there is less probability of predicting the next block.\n\n\n## Cons:\n\n* ?\n* Must be first be programmed.\n* Anything else?\n\n\n## Solution operation:\n\n\nAs I have said, my simplistic view of the operation. If I have this wrong, please correct it back to the list.\n\n1. The protocol determines the target block size.\n\n2. Assign each transaction in the pool a transaction weight based on fee and time waiting in the transaction pool.\n\n3. Begin selecting transactions to include in the current block using transaction weight as the likelihood of inclusion until target block size is met.\n\n4. Solve block.\n\n\nRegards,\n\nDamian Williamson\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171203/15371876/attachment-0001.html>"
            },
            {
                "author": "Jim Renkel",
                "date": "2017-12-06T05:18:11",
                "message_text_only": "As i understand it, the transactions to be included in a block are \nentirely up to the miner of that block.\n\n\nWhat prevents a miner from implementing the proposal on their own?\n\n\nIf this is adopted as some kind of \"policy\", what forces a miner to \nfollow it?\n\nJim Renkel\n\nOn 12/2/2017 10:07 PM, Damian Williamson via bitcoin-dev wrote:\n>\n> # BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering \n> Transactions In Blocks\n>\n>\n> I admit, with my limited experience in the operation of the protocol, \n> the section entitled 'Solution operation' may not be entirely correct \n> but you will get the idea. If I have it wrong, please correct it back \n> to the list.\n>\n> ## The problem:\n>\n>\n> Everybody wants value. Miners want to maximize revenue from fees. \n> Consumers want transaction reliability and, (we presume) low fees.\n>\n>\n> Current transaction bandwidth limit is a limiting factor for both.\n>\n> ## Solution summary:\n>\n>\n> Provide each transaction with a transaction weight, being a function \n> of the fee paid (on a curve), and the time waiting in the transaction \n> pool (also on a curve) out to n days (n=30 ?); the transaction weight \n> serving as the likelihood of a transaction being included in the \n> current block, and then use a target block size.\n>\n>\n> Protocol enforcement to prevent high or low blocksize cheating to be \n> handled by having the protocol determine the target size for the \n> current block using; current transaction pool size x ( 1 / (144 x n \n> days ) ) = transactions to be included in the current block.\n>\n> The curves used for the weight of transactions would have to be \n> appropriate.\n>\n> ## Pros:\n>\n>\n> * Maximizes transaction reliability.\n> * Maximizes possibility for consumer and business uptake.\n> * Maximizes total fees paid per block without reducing reliability; \n> because of reliability, confidence and uptake are greater; therefore, \n> more transactions and more transactions total at priority fees.\n> * Market determines fee paid for transaction priority.\n>\n> * Fee recommendations work all the way out to 30 days or greater.\n>\n> * Provides additional block entropy and greater security since there \n> is less probability of predicting the next block.\n>\n> ## Cons:\n>\n>\n> * ?\n> * Must be first be programmed.\n> * Anything else?\n>\n> ## Solution operation:\n>\n>\n> As I have said, my simplistic view of the operation. If I have this \n> wrong, please correct it back to the list.\n>\n>\n> 1. The protocol determines the target block size.\n>\n> 2. Assign each transaction in the pool a transaction weight based on \n> fee and time waiting in the transaction pool.\n>\n> 3. Begin selecting transactions to include in the current block using \n> transaction weight as the likelihood of inclusion until target block \n> size is met.\n>\n> 4. Solve block.\n>\n> Regards,\n>\n> Damian Williamson\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/c143a467/attachment-0001.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-07T06:34:39",
                "message_text_only": "Hello Jim,\n\n\nThe variable block sizes would not, as I understand it, be easily implemented by a solo miner.\n\n\nYou are right, there is presently nothing stopping a miner from ordering the transactions included by a priority that is not entirely based on the fee.\n\n\nIt may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conform to a probability distribution curve, if that is necessary and,  *if* the individual transaction priority can be recreated. I am not that deep into the mathematics, however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Needs a clever mathematician.\n\n\nIt is certainly possible to verify that blocks conform to the expected size.\n\n\nHonour is why people follow policy without enforcement. I may be in the wrong group. (sic)\n\n\nRegards,\n\nDamian Williamson\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Jim Renkel via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Wednesday, 6 December 2017 4:18:11 PM\nTo: bitcoin-dev at lists.linuxfoundation.org\nSubject: Re: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks\n\n\nAs i understand it, the transactions to be included in a block are entirely up to the miner of that block.\n\n\nWhat prevents a miner from implementing the proposal on their own?\n\n\nIf this is adopted as some kind of \"policy\", what forces a miner to follow it?\n\nJim Renkel\n\n\nOn 12/2/2017 10:07 PM, Damian Williamson via bitcoin-dev wrote:\n\n# BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks\n\nI admit, with my limited experience in the operation of the protocol, the section entitled 'Solution operation' may not be entirely correct but you will get the idea. If I have it wrong, please correct it back to the list.\n\n\n## The problem:\n\n\nEverybody wants value. Miners want to maximize revenue from fees. Consumers want transaction reliability and, (we presume) low fees.\n\nCurrent transaction bandwidth limit is a limiting factor for both.\n\n\n## Solution summary:\n\n\nProvide each transaction with a transaction weight, being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=30 ?); the transaction weight serving as the likelihood of a transaction being included in the current block, and then use a target block size.\n\nProtocol enforcement to prevent high or low blocksize cheating to be handled by having the protocol determine the target size for the current block using; current transaction pool size x ( 1 / (144 x n days ) ) = transactions to be included in the current block.\n\nThe curves used for the weight of transactions would have to be appropriate.\n\n\n## Pros:\n\n* Maximizes transaction reliability.\n* Maximizes possibility for consumer and business uptake.\n* Maximizes total fees paid per block without reducing reliability; because of reliability, confidence and uptake are greater; therefore, more transactions and more transactions total at priority fees.\n* Market determines fee paid for transaction priority.\n\n* Fee recommendations work all the way out to 30 days or greater.\n\n* Provides additional block entropy and greater security since there is less probability of predicting the next block.\n\n\n## Cons:\n\n* ?\n* Must be first be programmed.\n* Anything else?\n\n\n## Solution operation:\n\n\nAs I have said, my simplistic view of the operation. If I have this wrong, please correct it back to the list.\n\n1. The protocol determines the target block size.\n\n2. Assign each transaction in the pool a transaction weight based on fee and time waiting in the transaction pool.\n\n3. Begin selecting transactions to include in the current block using transaction weight as the likelihood of inclusion until target block size is met.\n\n4. Solve block.\n\n\nRegards,\n\nDamian Williamson\n\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171207/312cb740/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2017-12-06T05:46:45",
                "message_text_only": "Good morning Damian,\n\nThe primary problem in your proposal, as I understand it, is that the \"transaction pool\" is never committed to and is not part of consensus currently.  It is unlikely that the transaction pool will ever be part of consensus, as putting the transaction pool into consensus is effectively lifting the block size to include the entire transaction pool into each block.  The issue is that the transaction pool is transient and future fullnodes cannot find the contents of the transaction pool at the time blocks were made and cannot verify the correctness of historical blocks.  Also, fullnodes using -blocksonly mode have no transaction pool and cannot verify incoming blocks for these new rules.\n\nApplying a patch that follows this policy into Bitcoin Core without enforcing it in all fullnodes will simply lead to miners removing the patch in software they run, making it an exercise in futility to write, review, and test this code in the first place.\n\nIn addition, you reuse the term \"weight\" for something different than its current use.  Current use, is that the \"weight\" of a transaction, is the computed weight from the SegWit weight equation, measured in virtual units called \"sipa\", using the equation (4sipa / non-witness byte + 1sipa/witness byte).\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n> -------- Original Message --------\n> Subject: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks\n> Local Time: December 6, 2017 3:38 AM\n> UTC Time: December 5, 2017 7:38 PM\n> From: bitcoin-dev at lists.linuxfoundation.org\n> To: bitcoin-dev at lists.linuxfoundation.org <bitcoin-dev at lists.linuxfoundation.org>\n>\n> # BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks\n>\n> I admit, with my limited experience in the operation of the protocol, the section entitled 'Solution operation' may not be entirely correct but you will get the idea. If I have it wrong, please correct it back to the list.\n>\n> ## The problem:\n>\n> Everybody wants value. Miners want to maximize revenue from fees. Consumers want transaction reliability and, (we presume) low fees.\n>\n> Current transaction bandwidth limit is a limiting factor for both.\n>\n> ## Solution summary:\n>\n> Provide each transaction with a transaction weight, being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=30 ?); the transaction weight serving as the likelihood of a transaction being included in the current block, and then use a target block size.\n>\n> Protocol enforcement to prevent high or low blocksize cheating to be handled by having the protocol determine the target size for the current block using; current transaction pool size x ( 1 / (144 x n days ) ) = transactions to be included in the current block.\n>\n> The curves used for the weight of transactions would have to be appropriate.\n>\n> ## Pros:\n>\n> * Maximizes transaction reliability.\n> * Maximizes possibility for consumer and business uptake.\n> * Maximizes total fees paid per block without reducing reliability; because of reliability, confidence and uptake are greater; therefore, more transactions and more transactions total at priority fees.\n> * Market determines fee paid for transaction priority.\n>\n> * Fee recommendations work all the way out to 30 days or greater.\n>\n> * Provides additional block entropy and greater security since there is less probability of predicting the next block.\n>\n> ## Cons:\n>\n> * ?\n> * Must be first be programmed.\n> * Anything else?\n>\n> ## Solution operation:\n>\n> As I have said, my simplistic view of the operation. If I have this wrong, please correct it back to the list.\n>\n> 1. The protocol determines the target block size.\n>\n> 2. Assign each transaction in the pool a transaction weight based on fee and time waiting in the transaction pool.\n>\n> 3. Begin selecting transactions to include in the current block using transaction weight as the likelihood of inclusion until target block size is met.\n>\n> 4. Solve block.\n>\n> Regards,\n>\n> Damian Williamson\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171206/fe883569/attachment-0001.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-06T09:27:30",
                "message_text_only": "Good afternoon ZmnSCPxj,\n\n\nI have posted some discussion on the need for this proposal and, some refinements to the proposal explanation (not changes to the intended operation) to the bitcoin-discuss list. I didn't exactly mean to double post but thought it could use the discussion and, not to post it again, I will link to it when (if) it turns up, or will post it back here as an update on request. Currently, that post is awaiting moderator approval. I have also rewritten the solution operation section a bit in that post, not the idea that is being conveyed. I have added an additional step, reject blocks that do not meet the target block size for the current block.\n\nI suggest it still should be added to the solution operation, to broadcast the next target block size with the current block when it is solved. Using that method may answer a part of your concern.\n\nAs I understand it, each node would be aware independently of x transactions waiting for confirmation, the transaction pool. Each node would no doubt have its own idea about how many waiting transactions there are and which particular transactions exist. I do not see why each node could not just work with the information at hand, it is my understanding that is what happens now, even with solved blocks vs the longest chain. I have not followed why you foresee from my proposal the need for fullnodes to back confirm the previous blocks in that manner.\n\nIf next blocksize is broadcast with the completed block it would be a simple matter to back confirm that. With transaction weight (transaction priority) I am suggesting that value gives the likelihood of a transaction being included, presuming an element of randomness as to whether any particular transaction is then included or not. Back confirmations on a transaction basis would be impossible anyway, all that could be confirmed is that a particular block has transactions that conform to a probability curve, if the variables are known, fee amount and time waiting in the pool, then the transaction priority can be recreated to establish that the probability of a particular block conforms. I certainly do not foresee including the full transaction pool in each block.\n\nI am also presuming blocksize as a number of transactions rather than KB.\n\nMy suggestion, if adopted, is to directly make the operation of transaction priority a part of the operational standard - even without verification that it is being followed. The result of full transactional reliability is actually in the interests of miners as much as anyone.\n\nThe benefit of the proposal, not directly stated, is variable sized blocks (uncapped block size).\n\nYes, I have learned not to recycle terminology. My apologies, I had not been made aware that terminology already had use. Perhaps it would be simpler to call the proposal that I am putting forward here Transaction Priority.\n\nRegards,\nDamian Williamson\n\n\n________________________________\nFrom: ZmnSCPxj <ZmnSCPxj at protonmail.com>\nSent: Wednesday, 6 December 2017 4:46:45 PM\nTo: Damian Williamson\nCc: bitcoin-dev at lists.linuxfoundation.org\nSubject: Re: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks\n\nGood morning Damian,\n\nThe primary problem in your proposal, as I understand it, is that the \"transaction pool\" is never committed to and is not part of consensus currently.  It is unlikely that the transaction pool will ever be part of consensus, as putting the transaction pool into consensus is effectively lifting the block size to include the entire transaction pool into each block.  The issue is that the transaction pool is transient and future fullnodes cannot find the contents of the transaction pool at the time blocks were made and cannot verify the correctness of historical blocks.  Also, fullnodes using -blocksonly mode have no transaction pool and cannot verify incoming blocks for these new rules.\n\nApplying a patch that follows this policy into Bitcoin Core without enforcing it in all fullnodes will simply lead to miners removing the patch in software they run, making it an exercise in futility to write, review, and test this code in the first place.\n\nIn addition, you reuse the term \"weight\" for something different than its current use.  Current use, is that the \"weight\" of a transaction, is the computed weight from the SegWit weight equation, measured in virtual units called \"sipa\", using the equation (4sipa / non-witness byte + 1sipa/witness byte).\n\nRegards,\nZmnSCPxj\n\n\n\n\nSent with ProtonMail<https://protonmail.com> Secure Email.\n\n-------- Original Message --------\nSubject: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks\nLocal Time: December 6, 2017 3:38 AM\nUTC Time: December 5, 2017 7:38 PM\nFrom: bitcoin-dev at lists.linuxfoundation.org\nTo: bitcoin-dev at lists.linuxfoundation.org <bitcoin-dev at lists.linuxfoundation.org>\n\n\n\n# BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks\n\nI admit, with my limited experience in the operation of the protocol, the section entitled 'Solution operation' may not be entirely correct but you will get the idea. If I have it wrong, please correct it back to the list.\n\n\n\n## The problem:\n\n\nEverybody wants value. Miners want to maximize revenue from fees. Consumers want transaction reliability and, (we presume) low fees.\n\nCurrent transaction bandwidth limit is a limiting factor for both.\n\n\n\n## Solution summary:\n\n\nProvide each transaction with a transaction weight, being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=30 ?); the transaction weight serving as the likelihood of a transaction being included in the current block, and then use a target block size.\n\nProtocol enforcement to prevent high or low blocksize cheating to be handled by having the protocol determine the target size for the current block using; current transaction pool size x ( 1 / (144 x n days ) ) = transactions to be included in the current block.\n\nThe curves used for the weight of transactions would have to be appropriate.\n\n\n\n## Pros:\n\n* Maximizes transaction reliability.\n* Maximizes possibility for consumer and business uptake.\n* Maximizes total fees paid per block without reducing reliability; because of reliability, confidence and uptake are greater; therefore, more transactions and more transactions total at priority fees.\n* Market determines fee paid for transaction priority.\n\n\n* Fee recommendations work all the way out to 30 days or greater.\n\n* Provides additional block entropy and greater security since there is less probability of predicting the next block.\n\n\n\n## Cons:\n\n* ?\n* Must be first be programmed.\n* Anything else?\n\n\n\n## Solution operation:\n\n\nAs I have said, my simplistic view of the operation. If I have this wrong, please correct it back to the list.\n\n1. The protocol determines the target block size.\n\n\n2. Assign each transaction in the pool a transaction weight based on fee and time waiting in the transaction pool.\n\n3. Begin selecting transactions to include in the current block using transaction weight as the likelihood of inclusion until target block size is met.\n\n4. Solve block.\n\n\n\nRegards,\n\nDamian Williamson\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171206/462fabf4/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2017-12-07T06:46:08",
                "message_text_only": "Good morning Damian,\n\n>As I understand it, each node would be aware independently of x transactions waiting for confirmation, the transaction pool.\n\nEach long-running node would have a view that is roughly the same as the view of every other long-running node.\n\nHowever, suppose a node, Sleeping Beauty, was temporarily stopped for a day (for various reasons) then is started again.  That node cannot verify what the \"consensus\" transaction pool was during the time it was stopped -- it has no view of that.  It can only trust that the longest chain is valid -- but that means it is SPV for this particular rule.\n\n>If next blocksize is broadcast with the completed block it would be a simple matter to back confirm that.\n\nIt would not. Suppose Sleeping Beauty slept at block height 500,000.  On awakening, some node provides some purported block at height 500,001.  This block indicates some \"next blocksize\" for the block at height 500,002.  How does Sleeping Beauty know that the transaction pool at block 500,001 was of the correct size to provide the given \"next blocksize\"?  The only way, would be to look if there is some other chain with greater height that includes or does not include that block: that is, SPV confirmation.\n\nHow does Sleeping Beauty know it has caught up, and that its transaction pool is similar to that of its neighbors (who might be lying to it, for that matter), and that it should therefore stop using SPV confirmation and switch to strict fullnode rejection of blocks that indicate a \"next blocksize\" that is too large or too small according to your equation?  OR will it simply follow the longest chain always, in which case, it trusts miners to be honest about how loaded (or unloaded) the transaction pool is?\n\n-------\n\nAs a general rule, consensus rules should restrict themselves to:\n\n1.  The characteristics of the block.\n2.  The characteristics of the transactions within the block.\n\nThe transaction pool is specifically those transaction that are NOT in any block, and thus, are not safe to depend on for any consensus rules.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171207/4e19d047/attachment.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-07T08:13:14",
                "message_text_only": "Good morning ZmnSCPxj, it must be where you are,\n\n\nI suppose that we are each missing each other's point some.\n\n\nI understand that nodes would not be expected to agree on the transaction pool and do not propose validating that the correct transactions are included in a block. I speak of probability and likelihood of a transaction being included in a block, implying a random element. I do not propose rejecting blocks on the basis that the next block size is stated too large or too small for the transaction pool, only that the block received conforms to the next block size given on the previous block. Yes, it could be cheated. Also, various nodes may have at times wildly different amounts of transactions waiting in the transaction pool compared to each other and there could be a great disparity between them. It would not be possible in any case I can think of to validate the next block size is correct for the current transaction pool. Even as it is now, nodes may include transactions in a block that no other nodes have even heard of, nodes have no way to validate that either. If the block is built on sufficiently, it is the blockchain.\n\n\nI will post back the revised proposal to the list. I have fleshed parts of it out more, given more explanation and, tried this time not to recycle terminology.\n\n\nRegards,\n\nDamian Williamson\n\n________________________________\nFrom: ZmnSCPxj <ZmnSCPxj at protonmail.com>\nSent: Thursday, 7 December 2017 5:46:08 PM\nTo: Damian Williamson\nCc: bitcoin-dev at lists.linuxfoundation.org\nSubject: Re: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks\n\nGood morning Damian,\n\n>As I understand it, each node would be aware independently of x transactions waiting for confirmation, the transaction pool.\n\nEach long-running node would have a view that is roughly the same as the view of every other long-running node.\n\nHowever, suppose a node, Sleeping Beauty, was temporarily stopped for a day (for various reasons) then is started again.  That node cannot verify what the \"consensus\" transaction pool was during the time it was stopped -- it has no view of that.  It can only trust that the longest chain is valid -- but that means it is SPV for this particular rule.\n\n>If next blocksize is broadcast with the completed block it would be a simple matter to back confirm that.\n\nIt would not. Suppose Sleeping Beauty slept at block height 500,000.  On awakening, some node provides some purported block at height 500,001.  This block indicates some \"next blocksize\" for the block at height 500,002.  How does Sleeping Beauty know that the transaction pool at block 500,001 was of the correct size to provide the given \"next blocksize\"?  The only way, would be to look if there is some other chain with greater height that includes or does not include that block: that is, SPV confirmation.\n\nHow does Sleeping Beauty know it has caught up, and that its transaction pool is similar to that of its neighbors (who might be lying to it, for that matter), and that it should therefore stop using SPV confirmation and switch to strict fullnode rejection of blocks that indicate a \"next blocksize\" that is too large or too small according to your equation?  OR will it simply follow the longest chain always, in which case, it trusts miners to be honest about how loaded (or unloaded) the transaction pool is?\n\n-------\n\nAs a general rule, consensus rules should restrict themselves to:\n\n1.  The characteristics of the block.\n2.  The characteristics of the transactions within the block.\n\nThe transaction pool is specifically those transaction that are NOT in any block, and thus, are not safe to depend on for any consensus rules.\n\nRegards,\nZmnSCPxj\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171207/91199698/attachment.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-07T20:49:41",
                "message_text_only": "Good morning ZmnSCPxj,\n\n\nActually, there is no incentive to cheat target block size by providing a next block size that is higher or lower than the proposal would give. Under the proposal the transaction pool can grow quite large. A low next block size just defers collecting transaction fees, while a high next block size shrinks the transaction pool and thereby lowers fees. It seems like a standoff. This is especially true if the curve for time waiting in the transaction pool is extended beyond n days, since it is a curve, after waiting longer than 60 days (if n = 60 days) a transaction would have a priority greater than one-hundred and would therfore be the first transaction included with no possibility of failing the likelihood, so, even low fee paying transactions would be included first if the pool size is growing through incorrectly providing the next block size.\n\n\nAs it is now, I presume, a miner could include exactly one transaction in a block and pad?\n\n\nRegards,\n\nDamian Williamson\n\n________________________________\nFrom: Damian Williamson <willtech at live.com.au>\nSent: Thursday, 7 December 2017 7:13:14 PM\nTo: ZmnSCPxj\nCc: bitcoin-dev at lists.linuxfoundation.org\nSubject: Re: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks\n\n\nGood morning ZmnSCPxj, it must be where you are,\n\n\nI suppose that we are each missing each other's point some.\n\n\nI understand that nodes would not be expected to agree on the transaction pool and do not propose validating that the correct transactions are included in a block. I speak of probability and likelihood of a transaction being included in a block, implying a random element. I do not propose rejecting blocks on the basis that the next block size is stated too large or too small for the transaction pool, only that the block received conforms to the next block size given on the previous block. Yes, it could be cheated. Also, various nodes may have at times wildly different amounts of transactions waiting in the transaction pool compared to each other and there could be a great disparity between them. It would not be possible in any case I can think of to validate the next block size is correct for the current transaction pool. Even as it is now, nodes may include transactions in a block that no other nodes have even heard of, nodes have no way to validate that either. If the block is built on sufficiently, it is the blockchain.\n\n\nI will post back the revised proposal to the list. I have fleshed parts of it out more, given more explanation and, tried this time not to recycle terminology.\n\n\nRegards,\n\nDamian Williamson\n\n________________________________\nFrom: ZmnSCPxj <ZmnSCPxj at protonmail.com>\nSent: Thursday, 7 December 2017 5:46:08 PM\nTo: Damian Williamson\nCc: bitcoin-dev at lists.linuxfoundation.org\nSubject: Re: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks\n\nGood morning Damian,\n\n>As I understand it, each node would be aware independently of x transactions waiting for confirmation, the transaction pool.\n\nEach long-running node would have a view that is roughly the same as the view of every other long-running node.\n\nHowever, suppose a node, Sleeping Beauty, was temporarily stopped for a day (for various reasons) then is started again.  That node cannot verify what the \"consensus\" transaction pool was during the time it was stopped -- it has no view of that.  It can only trust that the longest chain is valid -- but that means it is SPV for this particular rule.\n\n>If next blocksize is broadcast with the completed block it would be a simple matter to back confirm that.\n\nIt would not. Suppose Sleeping Beauty slept at block height 500,000.  On awakening, some node provides some purported block at height 500,001.  This block indicates some \"next blocksize\" for the block at height 500,002.  How does Sleeping Beauty know that the transaction pool at block 500,001 was of the correct size to provide the given \"next blocksize\"?  The only way, would be to look if there is some other chain with greater height that includes or does not include that block: that is, SPV confirmation.\n\nHow does Sleeping Beauty know it has caught up, and that its transaction pool is similar to that of its neighbors (who might be lying to it, for that matter), and that it should therefore stop using SPV confirmation and switch to strict fullnode rejection of blocks that indicate a \"next blocksize\" that is too large or too small according to your equation?  OR will it simply follow the longest chain always, in which case, it trusts miners to be honest about how loaded (or unloaded) the transaction pool is?\n\n-------\n\nAs a general rule, consensus rules should restrict themselves to:\n\n1.  The characteristics of the block.\n2.  The characteristics of the transactions within the block.\n\nThe transaction pool is specifically those transaction that are NOT in any block, and thus, are not safe to depend on for any consensus rules.\n\nRegards,\nZmnSCPxj\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171207/2337b33a/attachment-0001.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2017-12-07T21:39:56",
                "message_text_only": "You can feel free to write this version and try to get miners to use it.\n That's the nice thing about Bitcoin.\n\nOn Thu, Dec 7, 2017 at 3:49 PM, Damian Williamson via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning ZmnSCPxj,\n>\n>\n> Actually, there is no incentive to cheat target block size by providing a\n> next block size that is higher or lower than the proposal would give. Under\n> the proposal the transaction pool can grow quite large. A low next block\n> size just defers collecting transaction fees, while a high next block size\n> shrinks the transaction pool and thereby lowers fees. It seems like a\n> standoff. This is especially true if the curve for time waiting in the\n> transaction pool is extended beyond n days, since it is a curve, after\n> waiting longer than 60 days (if n = 60 days) a transaction would have a\n> priority greater than one-hundred and would therfore be the first\n> transaction included with no possibility of failing the likelihood, so,\n> even low fee paying transactions would be included first if the pool size\n> is growing through incorrectly providing the next block size.\n>\n>\n> As it is now, I presume, a miner could include exactly one transaction in\n> a block and pad?\n>\n>\n> Regards,\n>\n> Damian Williamson\n> ------------------------------\n> *From:* Damian Williamson <willtech at live.com.au>\n> *Sent:* Thursday, 7 December 2017 7:13:14 PM\n> *To:* ZmnSCPxj\n>\n> *Cc:* bitcoin-dev at lists.linuxfoundation.org\n> *Subject:* Re: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction\n> Weight For Ordering Transactions In Blocks\n>\n>\n> Good morning ZmnSCPxj, it must be where you are,\n>\n>\n> I suppose that we are each missing each other's point some.\n>\n>\n> I understand that nodes would not be expected to agree on the transaction\n> pool and do not propose validating that the correct transactions are\n> included in a block. I speak of probability and likelihood of a transaction\n> being included in a block, implying a random element. I do not propose\n> rejecting blocks on the basis that the next block size is stated too large\n> or too small for the transaction pool, only that the block received\n> conforms to the next block size given on the previous block. Yes, it could\n> be cheated. Also, various nodes may have at times wildly different amounts\n> of transactions waiting in the transaction pool compared to each other and\n> there could be a great disparity between them. It would not be possible in\n> any case I can think of to validate the next block size is correct for the\n> current transaction pool. Even as it is now, nodes may include transactions\n> in a block that no other nodes have even heard of, nodes have no way to\n> validate that either. If the block is built on sufficiently, it is the\n> blockchain.\n>\n>\n> I will post back the revised proposal to the list. I have fleshed parts of\n> it out more, given more explanation and, tried this time not to recycle\n> terminology.\n>\n>\n> Regards,\n>\n> Damian Williamson\n> ------------------------------\n> *From:* ZmnSCPxj <ZmnSCPxj at protonmail.com>\n> *Sent:* Thursday, 7 December 2017 5:46:08 PM\n> *To:* Damian Williamson\n> *Cc:* bitcoin-dev at lists.linuxfoundation.org\n> *Subject:* Re: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction\n> Weight For Ordering Transactions In Blocks\n>\n> Good morning Damian,\n>\n> >As I understand it, each node would be aware independently of x\n> transactions waiting for confirmation, the transaction pool.\n>\n> Each long-running node would have a view that is roughly the same as the\n> view of every other long-running node.\n>\n> However, suppose a node, Sleeping Beauty, was temporarily stopped for a\n> day (for various reasons) then is started again.  That node cannot verify\n> what the \"consensus\" transaction pool was during the time it was stopped --\n> it has no view of that.  It can only trust that the longest chain is valid\n> -- but that means it is SPV for this particular rule.\n>\n> >If next blocksize is broadcast with the completed block it would be a\n> simple matter to back confirm that.\n>\n> It would not. Suppose Sleeping Beauty slept at block height 500,000.  On\n> awakening, some node provides some purported block at height 500,001.  This\n> block indicates some \"next blocksize\" for the block at height 500,002.  How\n> does Sleeping Beauty know that the transaction pool at block 500,001 was of\n> the correct size to provide the given \"next blocksize\"?  The only way,\n> would be to look if there is some other chain with greater height that\n> includes or does not include that block: that is, SPV confirmation.\n>\n> How does Sleeping Beauty know it has caught up, and that its transaction\n> pool is similar to that of its neighbors (who might be lying to it, for\n> that matter), and that it should therefore stop using SPV confirmation and\n> switch to strict fullnode rejection of blocks that indicate a \"next\n> blocksize\" that is too large or too small according to your equation?  OR\n> will it simply follow the longest chain always, in which case, it trusts\n> miners to be honest about how loaded (or unloaded) the transaction pool is?\n>\n> -------\n>\n> As a general rule, consensus rules should restrict themselves to:\n>\n> 1.  The characteristics of the block.\n> 2.  The characteristics of the transactions within the block.\n>\n> The transaction pool is specifically those transaction that are NOT in any\n> block, and thus, are not safe to depend on for any consensus rules.\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171207/846eb2b7/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Damian Williamson",
                "ZmnSCPxj",
                "Erik Aronesty",
                "Jim Renkel"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 39262
        }
    },
    {
        "title": "[bitcoin-dev] Updates on Confidential Transactions efficiency",
        "thread_messages": [
            {
                "author": "Andrew Poelstra",
                "date": "2017-12-04T17:17:11",
                "message_text_only": "To follow up on the remarkable work Greg announced from Benedikt B\u00fcnz (Stanford)\nand Jonathan Bootle (UCL) on Bulletproofs: https://eprint.iacr.org/2017/1066\n\nSummary\n=========\n\nOver the last couple weeks, along with Jonas Nick, Pieter Wuille, Greg Maxwell\nand Peter Dettmann, I've implemented the single-output version of Bulletproofs\nat https://github.com/ElementsProject/secp256k1-zkp/pull/16 and have some\nperformance numbers.\n\nAll of these benchmarks were performed on one core of an Intel i7-6820MQ\nthrottled to 2.00Ghz, and reflect verification of a single 64-bit rangeproof.\n\n\nOld Rangeproof    14.592 ms\n     with endo    10.304 ms\nBulletproof        4.208 ms\n     with endo     4.031 ms\nECDSA verify       0.117 ms\n     with endo     0.084 ms\n\n\nHere \"with endo\" refers to use of the GLV endomorphism supported by the curve\nsecp256k1, which libsecp256k1 (and therefore Bitcoin) supports but does not\nenable by default, out of an abundance of caution regarding potential patents.\n\nAs we can see, without the endomorphism this reflects a 3.47x speedup over\nthe verification speed of the old rangeproofs. Because Bulletproof verification\nscales with O(N/log(N)) while the old rangeproof scales with O(N), we can\nextrapolate forward to say that a 2-output aggregate would verify with 4.10x\nthe speed of the old rangeproofs.\n\nBy the way, even without aggregation, we can verify two rangeproofs nearly 15%\nfaster than verifying one twice (so a 3.95x speedup) because the nature of the\nverification equation makes it amenable to batch verification. This number\nimproves with the more proofs that you're verifying simultaneously (assuming\nyou have enough RAM), such that for example you can batch-verify 10000\nbulletproofs 9.9 times as fast as you could verify 10000 of the old proofs.\n\n\nWhile this is a remarkable speedup which greatly improves the feasibility of\nCT for Bitcoin (though still not to the point where I'd expect a serious\nproposal to get anywhere, IMHO), the concerns highlighted by Greg regarding\nunconditional versus computational soundness remain. I won't expand on that\nmore than it has already been discussed in this thread, I just want to tamp\ndown any irrational exhuberance about these result.\n\n\nPeople who only care about numbers can stop reading here. What follows is a\ndiscussion about how this speedup is possible and why we weren't initially\nsure that we'd get any speedup at all.\n\n\nDetails\n=========\n\nSection 6 of the linked preprint discusses performance vs our old rangeproofs. As\nGreg mentioned, it is possible to fit two 64-bit bulletproofs into 738 bytes,\nwith logarithmic scaling. (So one proof would take 674 bytes, but eight proofs\nonly 866 bytes.)\n\nHowever, this section does not give performance numbers, because at the time\nthe preprint was written, there was no optimized implementation on which to\nbenchmark. It was known that verification time would be roughly linear in the\nsize of the proof: 141 scalar-multiplies for a 64-bit proof, 270 for an\naggregate of two proofs, and so on [*]. Our old rangeproofs required only 128\nmultiplies for a 64-bit proof, then 256 for two, and so on. So naively we were\nconcerned that the new Bulletproofs, despite being fantastically smaller than\nthe original rangeproofs, might wind up taking a bit longer to verify.\n\nFor reference, an ordinary ECDSA signature verification involves 2 multiplies.\nSo roughly speaking, the naive expectation was that a N-bit rangeproof would\nrequire N-many signature verifications' worth of CPU time, even with this new\nresearch. Worse, we initially expected bulletproofs to require 1.5x this much,\nwhich we avoided with a trick that I'll describe at the end of this mail.\n\nAs you can see in the above numbers, the old rangeproofs actually perform worse\nthan this expectation, while the new Bulletproofs perform significantly **better**.\nThese are for the same reason: when performing a series of scalar multiplications\nof the form\n\n  a*G + b*H + c*I + ...\n\nwhere G, H, I are curvepoints and a, b, c are scalars, it is possible to compute\nthis sum much more quickly than simply computing a*G, b*H, c*I separately and\nthen adding the results. Signature validation takes advantage of this speedup,\nusing a technique called Strauss' algorithm, to compute the sum of two multiplies\nmuch faster than twice the multiple-speed. Similarly, as we have learned, the\n141 scalar-multiplies in a single-output Bulletproof can also be done in a single\nsum. To contrast, the old rangeproofs required we do each multiplication separately,\nas the result of one would be hashed to determine the multiplier for the next.\n\nlibsecp256k1 has supported Strauss' algorithm for two points since its inception\nin 2013, since this was needed for ECDSA verification. Extending it to many points\nwas a nontrivial task which Pieter, Greg and Jonas Nick took on this year as part\nof our aggregate signatures project. Of the algorithms that we tested, we found\nthat Strauss was fastest up to about 100 points, at which point Pippenger's was\nfastest. You can see our initial benchmarks here\n\nhttps://user-images.githubusercontent.com/2582071/32731185-12c0f108-c881-11e7-83c7-c2432b5fadf5.png\n\nthough this does not reflect some optimizations from Peter Dettmann in the last\nweek.\n\n\nIt was a happy coincidence that the Bulletproofs paper was published at nearly\nthe same time that we had working multi-point code to test with.\n\n\nFinally, the Bulletproof verification process, as written in the paper, is a\nrecursive process which does not appear to be expressible as a single multiproduct,\nand in fact it appears to require nearly twice as many multiplications as I claim\nabove. I want to draw attention to two optimizations in particular which made this\npossible.\n\n1. By expanding out the recursive process, one can see that the inner-product argument\n   (Protocol 1 in the paper) is actually one multiproduct: you hash each (L_i, R_i)\n   pair to obtain logarithmically many scalars, invert these, and then each scalar in\n   the final multiproduct is a product containing either the inverse or original of\n   each scalar.\n\n   Peter Dettmann found a way to reduce this to one scalar inversion, from which\n   every single scalar was obtainable from a single multiplication or squaring of a\n   previous result. I was able to implement this in a way that cached only log-many\n   previous results.\n\n2. Next, line (62) of the Bulletproofs paper appears to require N multiplications\n   beyond the 2N multiplications already done in the recursive step. But since\n   these multiplications used the same basepoints that were used in the recursive\n   step, we could use the distributive property to combine them. This sounds\n   trivial but took a fair bit of care to ensure that all the right data was still\n   committed to at the right stage of proof verification.\n\n\n\nFurther Work\n=========\n\nThere are still a few open issues I plan to help resolve in the coming month:\n\n  - Bulletproof aggregation is not compatible with Confidential Assets, where each\n    output has a unique asset tag associated with it. There are a couple possible\n    solutions to this but nothing public-ready.\n\n  - Bulletproofs, as described in the paper, work only when proving 2^n-many bits.\n    I believe there is a straightforward and verifier-efficient way to extend it\n    to support non-powers-of-2, but this requires some work to modify the proof in\n    the paper.\n\n  - Bulletproofs are actually much more general than rangeproofs. They can be used\n    to prove results of arbitrary arithmetic circuits, which is something we are\n    very interested in implementing.\n\n\n[*] By \"and so on\", I mean that N bits require 2N + 2log_2(N) + 6 scalar multiplies.\n\n\nCheers\nAndrew\n\n\n\n-- \nAndrew Poelstra\nMathematics Department, Blockstream\nEmail: apoelstra at wpsoftware.net\nWeb:   https://www.wpsoftware.net/andrew\n\n\"A goose alone, I suppose, can know the loneliness of geese\n who can never find their peace,\n whether north or south or west or east\"\n       --Joanna Newsom\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171204/42dfe0d1/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Updates on Confidential Transactions efficiency",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Andrew Poelstra"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 8287
        }
    },
    {
        "title": "[bitcoin-dev] Scalable Semi-Trustless Asset Transfer via Single-Use-Seals and Proof-of-Publication",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2017-12-05T10:15:51",
                "message_text_only": "I recently wrote this up for a client, and although the material has been\ncovered elsewhere, I thought being a worked example it might be of interest,\nparticularly while sidechains are being discussed again.\n\nAs per (1) I've perhaps foolishly committed to making an even more fleshed out\nexample, so peer review here before it gets to an even wider audience would be\nappreciated. :)\n\n1) https://twitter.com/petertoddbtc/status/937401676042039296\n\n\ntl;dr: We can do trustless with respect to validity, trusted with respect to\ncensorship resistance, indivisible asset transfer with less than 5MB/year/token\nof proof data, assuming token ownership is updated every two hours, at a rate\nof ~500,000 transfers per second. The scalability of this scheme is linear with\nrespect to update interval, and logarithmic with respect to overall transfer\nrate.\n\n\n## Single-Use-Seal Definition\n\nAnalogous to the real-world, physical, single-use-seals used to secure shipping\ncontainers, a single-use-seal primitive is a unique object that can be closed\nover a message exactly once. In short, a single-use-seal is an abstract\nmechanism to prevent double-spends.\n\nA single-use-seal implementation supports two fundamental operations:\n\n    Close(l,m) -> w_l\n        Close seal l over message m, producing a witness w_l\n\n    Verify(l,w_l,m) -> bool\n        Verify that the seal l was closed over message m\n\nA single-use-seal implementation is secure if it is impossible for an attacker\nto cause the Verify function to return true for two distinct messages m_1, m_2,\nwhen applied to the same seal (it _is_ acceptable, although non-ideal, for\nthere to exist multiple witnesses for the same seal/message pair).\n\nPractical single-use-seal implementations will also obviously require some way\nof generating new single-use-seals. Secondly, authentication is generally\nuseful. Thus we have:\n\n    Gen(p) -> l\n        Generate a new seal bound to pubkey p\n\n    Close(l,m,s) -> w_l\n        Close seal l over message m, authenticated by signature s valid for pubkey p\n\nObviously, in the above, pubkey can be replaced by any cryptographic identity\nscheme, such as a Bitcoin-style predicate script, zero-knowledge proof, etc.\n\nFinally, _some_ single-use-seal implementations may support the ability to\nprove that a seal is _open_, e.g. as of a given block height or point in time.\nThis however is optional, and as it can be difficult to implement, it is\nsuggested that seal-using protocols avoid depending on this functionality\nexisting.\n\n\n## Indivisible Token Transfer\n\nWith a secure single-use-seal primitive we can build a indivisible token\ntransfer system, allowing the secure transfer of a token from one party to\nanother, with the seals preventing double-spends of that indivisible token.\n\nEach token is identified by its genesis seal l_0. To transfer a token, the most\nrecent seal l_n is closed over a message committing to a new seal, l_{n+1},\nproducing a witness w_{l_n} attesting to that transfer. This allows a recipient\nto securely verify that they have received the desired token as follows:\n\n1. Generate a fresh, open, seal l_{n+1} that only they can close.\n2. Ask the sender to close their seal, l_n, over the seal l_{n+1}\n3. Verify that there exist a set of valid witnesses w_0 .. w_n, and seals\n   l_0 .. l_n, such that for each seal l_i in i = 0 .. n, Verify(l_i, w_i, l_{i+1})\n   returns true.\n\nSince a secure single-use-seal protocol prohibits the closure of a single seal\nover multiple messages, the above protocol ensures that the token can not be\ndouble-spent. Secondly, by ensuring that seal l_{n+1} can be closed by the\nrecipient and only the recipient, the receipient of the token knows that they\nand they alone have the ability to send that token to the next owner.\n\n\n## Divisible Asset Transfer\n\nIn the case of a divisible asset, rather than transferring a single, unique,\ntoken we want to transfer a _quantity_ of an asset. We can accomplish this in a\nmanner similar how Bitcoin's UTXO-based transactions, in which one or more\ninputs are combined in a single transaction, then split amongst zero or more\noutputs.\n\nWe define the concept of an _output_. Each output x is associated with a seal l\nand value v. For each asset we define a set of _genesis outputs_, X_G, whose\nvalidity is assumed.\n\nTo transfer divisible assets we further define the concepts of a _spend_ and a\n_split_. A spend, D, is a commitment to a set of outputs x_i .. x_j; the value\nof a spend is simply the sum of the values of all outputs in the spend. A split\ncommitments to a set of zero or seal/value, (l_i,v_i), tuples, with the sum\nvalue of the split being the sum of a values in the split.\n\nSpends and splits are used to define a _split output_. While a genesis output\nis simply assumed valid, a split output x is then the tuple (D,V,i), committing\nto a spend D, split V, and within that split, a particular output i.\n\nA split output is valid if:\n\n1. Each output in the spend set D is a valid output.\n2. The sum value of the spend set D is >= the sum value of the split V.\n3. i corresponds to a valid output in the split.\n4. There exists a set of witnesses w_i .. w_j, such that each seal in the spend\n   set closed over the message (D,V) (the spend and split).\n\nAs with the indivisible asset transfer, a recipient can verify that an asset\nhas been securely transferred to them by generating a fresh seal, asking the\nsender to create a new split output for that seal and requested output amount,\nand verifying that the newly created split output is in fact valid. As with\nBitcoin transactions, in most transfers will also result in a change output.\n\nNote how an actual implementation can usefully use a merkle-sum-tree to commit\nto the split set, allowing outputs to be proven to the recipient by giving only\na single branch of the tree, with other outputs pruned. This can have both\nefficiency and privacy advantages.\n\n\n\n## Single-Use-Seal Implementation\n\nAn obvious single-use-seal implementation is to simply have a trusted notary,\nwith each seal committing to that notary's identity, and witnesses being\ncryptographic signatures produced by that notary. A further obvious refinement\nis to use disposable keys, with a unique private key being generated by the\nnotary for each seal, and the private key being securely destroyed when the\nseal is closed.\n\nSecondly Bitcoin (or similar) transaction outputs can implement\nsingle-use-seals, with each seal being uniquely identified by outpoint\n(txid:n), and witnesses being transactions spending that outpoint in a\nspecified way (e.g. the first output being an OP_RETURN committing to the\nmessage).\n\n\n### Proof-of-Publication Ledger\n\nFor a scalable, trust-minimized, single-use-seal implementation we can use a\nproof-of-publication ledger, where consensus over the state of the ledger is\nachieved with a second single-use-seal implementation (e.g. Bitcoin).\n\nSuch a ledger is associated with a genesis seal, L_0, with each entry M_i in\nthe ledger being committed by closing the most recent seal over that entry,\nproducing W_i such that Verify(L_i, (L_{i+1}, M_i), W_i) returns true.\nThus we achieve consensus over the state of the ledger as we can prove the\ncontents of the ledger.\n\nSpecifically, given starting point L_i we can prove that the subsequent ledger\nentries M_i .. M_j are valid with witnesses W_i .. W_j and seals L_{i+1} .. L_{j+1}.\n\nA proof-of-publication-based seal can then be constructed via the tuple (L_i,\np), where L_i is one of the ledger's seals, and p is a pubkey (or similar). To\nclose a proof-of-publication ledger seal a valid signature for that pubkey and\nmessage m is published in the ledger in entry M_j.\n\nThus the seal witness is proof that:\n\n1. Entry M_j contained a valid signature by pubkey p, for message m.\n2. All prior entries M_i .. M_{j-1} (possibly an empty set) did _not_ contain\n   valid signatures.\n\nFinally, for the purpose of scalability, instead of each ledger entry M_i\nconsisting of a unstructured message, we can instead commit to a merkelized\nkey:value tree, with each key being a pubkey p, and each value being an\nalleged signature (possibly invalid). Now the non-publication condition is\nproven by showing that either:\n\n1. Tree M_i does not contain key p.\n2. Tree M_i does contain key p, but alleged signature s is invalid.\n\nThe publication condition is proven by showing that tree M_j does contain key\np, and that key is associated with valid signature s.\n\nA merkelized key:value tree can prove both statements with a log2(n) sized\nproof, and thus we achieve log2(n) size scalability, with the constant factor\ngrowing by the age of the seals, the ledger update frequency, the rate at which\nseals are closed, and the maximum size allowed for signatures.\n\nNote how a number of simple optimizations are possible, such as preventing the\ncreation of \"spam\" invalid signatures by blinding the actual pubkey with a\nnonce, ensuring only valid signatures are published, etc. Also note how it is\n_not_ necessary to validate all entries in the ledger form a chain: the\nsingle-use-seals guarantees that a particular range of ledger entries will be\nunique, regardless of whether all ledger history was unique.\n\nProof-of-Publication ledgers are trustless with regard to false seal witnesses:\nthe ledger maintainer(s) are unable to falsify a witness because they are\nunable to produce a valid signature. They are however trusted with regard to\ncensorship: the ledger maintainer can prevent the publication of a signature\nand/or or withhold data necessary to prove the state of the seal.\n\n\n# Performance Figures\n\nAssume a indivisible token transfer via a PoP ledger using Bitcoin-based\nsingle-use-seals, with the ledger updated 12 times a day (every two hours).\nAssume each ledger update corresponds to 2^32, 4 billion, transfers.\n\nThe data required to prove publication/non-publication for a given ledger\nupdate is less than:\n\n    lite-client BTC tx proof:                            = ~1KB\n    merkle path down k/v tree: 32 levels * 32bytes/level =  1KB\n    key/value: 32 bytes predicate hash + 1KB script sig  = ~1KB\n                                                   Total = ~3KB/ledger update\n\n        * 356 days/year * 12 updates/day = 13MB/year\n\nNow, those are *absolute worst case* numbers, and there's a number of ways that\nthey can be substantially reduced such as only publishing valid signatures, or\njust assuming you're not being attacked constantly... Also, note how for a\nclient with multiple tokens, much of the data can be shared amongst each token.\nBut even then, being able to prove the ownership status of a token, in a\ntrustless fashion, with just 13MB/year of data is an excellent result for many\nuse-cases.\n\nWith these optimizations, the marginal cost per token after the first one is\njust 1KB/ledger update, 4.4MB/year.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 488 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/8de5b811/attachment.sig>"
            },
            {
                "author": "Pulat Yunusov",
                "date": "2017-12-11T22:23:21",
                "message_text_only": "Thank you for your post, Peter. Why is it necessary to centralize the p-o-p\nsidechain and have a maintainer? It seems the Bitcoin network will secure\nthe most critical element, which is the witness authenticity. Wouldn't a\nsecond decentralized network be able to perform the functions of the\nmaintainer so the entire system is trustless?\n\nOn Tue, Dec 5, 2017 at 5:16 AM Peter Todd via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I recently wrote this up for a client, and although the material has been\n> covered elsewhere, I thought being a worked example it might be of\n> interest,\n> particularly while sidechains are being discussed again.\n>\n> As per (1) I've perhaps foolishly committed to making an even more fleshed\n> out\n> example, so peer review here before it gets to an even wider audience\n> would be\n> appreciated. :)\n>\n> 1) https://twitter.com/petertoddbtc/status/937401676042039296\n>\n>\n> tl;dr: We can do trustless with respect to validity, trusted with respect\n> to\n> censorship resistance, indivisible asset transfer with less than\n> 5MB/year/token\n> of proof data, assuming token ownership is updated every two hours, at a\n> rate\n> of ~500,000 transfers per second. The scalability of this scheme is linear\n> with\n> respect to update interval, and logarithmic with respect to overall\n> transfer\n> rate.\n>\n>\n> ## Single-Use-Seal Definition\n>\n> Analogous to the real-world, physical, single-use-seals used to secure\n> shipping\n> containers, a single-use-seal primitive is a unique object that can be\n> closed\n> over a message exactly once. In short, a single-use-seal is an abstract\n> mechanism to prevent double-spends.\n>\n> A single-use-seal implementation supports two fundamental operations:\n>\n>     Close(l,m) -> w_l\n>         Close seal l over message m, producing a witness w_l\n>\n>     Verify(l,w_l,m) -> bool\n>         Verify that the seal l was closed over message m\n>\n> A single-use-seal implementation is secure if it is impossible for an\n> attacker\n> to cause the Verify function to return true for two distinct messages m_1,\n> m_2,\n> when applied to the same seal (it _is_ acceptable, although non-ideal, for\n> there to exist multiple witnesses for the same seal/message pair).\n>\n> Practical single-use-seal implementations will also obviously require some\n> way\n> of generating new single-use-seals. Secondly, authentication is generally\n> useful. Thus we have:\n>\n>     Gen(p) -> l\n>         Generate a new seal bound to pubkey p\n>\n>     Close(l,m,s) -> w_l\n>         Close seal l over message m, authenticated by signature s valid\n> for pubkey p\n>\n> Obviously, in the above, pubkey can be replaced by any cryptographic\n> identity\n> scheme, such as a Bitcoin-style predicate script, zero-knowledge proof,\n> etc.\n>\n> Finally, _some_ single-use-seal implementations may support the ability to\n> prove that a seal is _open_, e.g. as of a given block height or point in\n> time.\n> This however is optional, and as it can be difficult to implement, it is\n> suggested that seal-using protocols avoid depending on this functionality\n> existing.\n>\n>\n> ## Indivisible Token Transfer\n>\n> With a secure single-use-seal primitive we can build a indivisible token\n> transfer system, allowing the secure transfer of a token from one party to\n> another, with the seals preventing double-spends of that indivisible token.\n>\n> Each token is identified by its genesis seal l_0. To transfer a token, the\n> most\n> recent seal l_n is closed over a message committing to a new seal, l_{n+1},\n> producing a witness w_{l_n} attesting to that transfer. This allows a\n> recipient\n> to securely verify that they have received the desired token as follows:\n>\n> 1. Generate a fresh, open, seal l_{n+1} that only they can close.\n> 2. Ask the sender to close their seal, l_n, over the seal l_{n+1}\n> 3. Verify that there exist a set of valid witnesses w_0 .. w_n, and seals\n>    l_0 .. l_n, such that for each seal l_i in i = 0 .. n, Verify(l_i, w_i,\n> l_{i+1})\n>    returns true.\n>\n> Since a secure single-use-seal protocol prohibits the closure of a single\n> seal\n> over multiple messages, the above protocol ensures that the token can not\n> be\n> double-spent. Secondly, by ensuring that seal l_{n+1} can be closed by the\n> recipient and only the recipient, the receipient of the token knows that\n> they\n> and they alone have the ability to send that token to the next owner.\n>\n>\n> ## Divisible Asset Transfer\n>\n> In the case of a divisible asset, rather than transferring a single,\n> unique,\n> token we want to transfer a _quantity_ of an asset. We can accomplish this\n> in a\n> manner similar how Bitcoin's UTXO-based transactions, in which one or more\n> inputs are combined in a single transaction, then split amongst zero or\n> more\n> outputs.\n>\n> We define the concept of an _output_. Each output x is associated with a\n> seal l\n> and value v. For each asset we define a set of _genesis outputs_, X_G,\n> whose\n> validity is assumed.\n>\n> To transfer divisible assets we further define the concepts of a _spend_\n> and a\n> _split_. A spend, D, is a commitment to a set of outputs x_i .. x_j; the\n> value\n> of a spend is simply the sum of the values of all outputs in the spend. A\n> split\n> commitments to a set of zero or seal/value, (l_i,v_i), tuples, with the sum\n> value of the split being the sum of a values in the split.\n>\n> Spends and splits are used to define a _split output_. While a genesis\n> output\n> is simply assumed valid, a split output x is then the tuple (D,V,i),\n> committing\n> to a spend D, split V, and within that split, a particular output i.\n>\n> A split output is valid if:\n>\n> 1. Each output in the spend set D is a valid output.\n> 2. The sum value of the spend set D is >= the sum value of the split V.\n> 3. i corresponds to a valid output in the split.\n> 4. There exists a set of witnesses w_i .. w_j, such that each seal in the\n> spend\n>    set closed over the message (D,V) (the spend and split).\n>\n> As with the indivisible asset transfer, a recipient can verify that an\n> asset\n> has been securely transferred to them by generating a fresh seal, asking\n> the\n> sender to create a new split output for that seal and requested output\n> amount,\n> and verifying that the newly created split output is in fact valid. As with\n> Bitcoin transactions, in most transfers will also result in a change\n> output.\n>\n> Note how an actual implementation can usefully use a merkle-sum-tree to\n> commit\n> to the split set, allowing outputs to be proven to the recipient by giving\n> only\n> a single branch of the tree, with other outputs pruned. This can have both\n> efficiency and privacy advantages.\n>\n>\n>\n> ## Single-Use-Seal Implementation\n>\n> An obvious single-use-seal implementation is to simply have a trusted\n> notary,\n> with each seal committing to that notary's identity, and witnesses being\n> cryptographic signatures produced by that notary. A further obvious\n> refinement\n> is to use disposable keys, with a unique private key being generated by the\n> notary for each seal, and the private key being securely destroyed when the\n> seal is closed.\n>\n> Secondly Bitcoin (or similar) transaction outputs can implement\n> single-use-seals, with each seal being uniquely identified by outpoint\n> (txid:n), and witnesses being transactions spending that outpoint in a\n> specified way (e.g. the first output being an OP_RETURN committing to the\n> message).\n>\n>\n> ### Proof-of-Publication Ledger\n>\n> For a scalable, trust-minimized, single-use-seal implementation we can use\n> a\n> proof-of-publication ledger, where consensus over the state of the ledger\n> is\n> achieved with a second single-use-seal implementation (e.g. Bitcoin).\n>\n> Such a ledger is associated with a genesis seal, L_0, with each entry M_i\n> in\n> the ledger being committed by closing the most recent seal over that entry,\n> producing W_i such that Verify(L_i, (L_{i+1}, M_i), W_i) returns true.\n> Thus we achieve consensus over the state of the ledger as we can prove the\n> contents of the ledger.\n>\n> Specifically, given starting point L_i we can prove that the subsequent\n> ledger\n> entries M_i .. M_j are valid with witnesses W_i .. W_j and seals L_{i+1}\n> .. L_{j+1}.\n>\n> A proof-of-publication-based seal can then be constructed via the tuple\n> (L_i,\n> p), where L_i is one of the ledger's seals, and p is a pubkey (or\n> similar). To\n> close a proof-of-publication ledger seal a valid signature for that pubkey\n> and\n> message m is published in the ledger in entry M_j.\n>\n> Thus the seal witness is proof that:\n>\n> 1. Entry M_j contained a valid signature by pubkey p, for message m.\n> 2. All prior entries M_i .. M_{j-1} (possibly an empty set) did _not_\n> contain\n>    valid signatures.\n>\n> Finally, for the purpose of scalability, instead of each ledger entry M_i\n> consisting of a unstructured message, we can instead commit to a merkelized\n> key:value tree, with each key being a pubkey p, and each value being an\n> alleged signature (possibly invalid). Now the non-publication condition is\n> proven by showing that either:\n>\n> 1. Tree M_i does not contain key p.\n> 2. Tree M_i does contain key p, but alleged signature s is invalid.\n>\n> The publication condition is proven by showing that tree M_j does contain\n> key\n> p, and that key is associated with valid signature s.\n>\n> A merkelized key:value tree can prove both statements with a log2(n) sized\n> proof, and thus we achieve log2(n) size scalability, with the constant\n> factor\n> growing by the age of the seals, the ledger update frequency, the rate at\n> which\n> seals are closed, and the maximum size allowed for signatures.\n>\n> Note how a number of simple optimizations are possible, such as preventing\n> the\n> creation of \"spam\" invalid signatures by blinding the actual pubkey with a\n> nonce, ensuring only valid signatures are published, etc. Also note how it\n> is\n> _not_ necessary to validate all entries in the ledger form a chain: the\n> single-use-seals guarantees that a particular range of ledger entries will\n> be\n> unique, regardless of whether all ledger history was unique.\n>\n> Proof-of-Publication ledgers are trustless with regard to false seal\n> witnesses:\n> the ledger maintainer(s) are unable to falsify a witness because they are\n> unable to produce a valid signature. They are however trusted with regard\n> to\n> censorship: the ledger maintainer can prevent the publication of a\n> signature\n> and/or or withhold data necessary to prove the state of the seal.\n>\n>\n> # Performance Figures\n>\n> Assume a indivisible token transfer via a PoP ledger using Bitcoin-based\n> single-use-seals, with the ledger updated 12 times a day (every two hours).\n> Assume each ledger update corresponds to 2^32, 4 billion, transfers.\n>\n> The data required to prove publication/non-publication for a given ledger\n> update is less than:\n>\n>     lite-client BTC tx proof:                            = ~1KB\n>     merkle path down k/v tree: 32 levels * 32bytes/level =  1KB\n>     key/value: 32 bytes predicate hash + 1KB script sig  = ~1KB\n>                                                    Total = ~3KB/ledger\n> update\n>\n>         * 356 days/year * 12 updates/day = 13MB/year\n>\n> Now, those are *absolute worst case* numbers, and there's a number of ways\n> that\n> they can be substantially reduced such as only publishing valid\n> signatures, or\n> just assuming you're not being attacked constantly... Also, note how for a\n> client with multiple tokens, much of the data can be shared amongst each\n> token.\n> But even then, being able to prove the ownership status of a token, in a\n> trustless fashion, with just 13MB/year of data is an excellent result for\n> many\n> use-cases.\n>\n> With these optimizations, the marginal cost per token after the first one\n> is\n> just 1KB/ledger update, 4.4MB/year.\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/8d130370/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2017-12-11T23:16:19",
                "message_text_only": "On Mon, Dec 11, 2017 at 10:23:21PM +0000, Pulat Yunusov wrote:\n> Thank you for your post, Peter. Why is it necessary to centralize the p-o-p\n> sidechain and have a maintainer? It seems the Bitcoin network will secure\n> the most critical element, which is the witness authenticity. Wouldn't a\n> second decentralized network be able to perform the functions of the\n> maintainer so the entire system is trustless?\n\nIt's centralized in that writeup basically because centralizing it is\n*significantly* easier; it's not obvious how to maintain a proof-of-publication\nledger in a decentralized, scalable, way.\n\nIn the centralized version it's obvious how to scale process by which the\nledger is built via sharding: split the key range up as needed and assign each\nrange to a separate server (be it an actual server, or a fault-tolerate cluster\nacting as a single server) that reports back to a master co-ordinator who\nbuilds the tree from the per-range sub-tips reported back by the shards. If\nrequired due to extreme scale, do this on multiple levels. Similarly, once the\ntree is built, storage and distribution can obviously be done via sharding.\n\nIn short, no matter how much the transaction rate on a PoP ledger grows, it's\npossible to meet demand by simply buying more hardware, and distributing the\nkey space over a larger number of smaller shards.\n\nBut that simple architecture only works with trust: the coordinator is trusting\nthe shards to build valid trees and distribute the results. Without trust, how\ndo you ensure that actually happens? How do you pick who is assigned to what\nshard? How do you incentivise correct behavior?\n\nThat's not to say this is impossible - in fact my prior work on Treechains(1)\nis an attempt to do just this - but it's an orders of magnitude more difficult\nproblem.\n\n1) https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2014-March/004797.html,\n   \"[Bitcoin-development] Tree-chains preliminary summary\", Mar 25th 2014,\n   Peter Todd\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/9f7f9401/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Scalable Semi-Trustless Asset Transfer via Single-Use-Seals and Proof-of-Publication",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Pulat Yunusov",
                "Peter Todd"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 25633
        }
    },
    {
        "title": "[bitcoin-dev] BIP-21 amendment proposal: -no125",
        "thread_messages": [
            {
                "author": "Sjors Provoost",
                "date": "2017-12-05T19:24:04",
                "message_text_only": "One way to reduce fees is to encourage usage of Replace-By-Fee, BIP 125 [0]. It allows wallets to recommend lower fees, because if a transaction gets stuck due to underestimation, the fee can easily be bumped.\n\nBitcoin Core has had support for RBF for a while, and as of v0.15.0 recommends lower fees [1] when the user chooses to use RBF.\n\nI recently submitted a pull request that would turn on RBF by default, which triggered some discussion [2]. To ease the transition for merchants who are reluctant to see their customers use RBF, Matt Corallo suggested that wallets honor a no125=1 flag.\n\nSo a BIP-21 URI would look like this: bitcoin:175t...45W?amount=20.3&no125=1\n\nWhen this flag is set, wallets should not use RBF, regardless of their default, unless the user explicitly overrides the merchant's preference.\n\nAfaik adding this flag won't break existing BIP-21 support. It doesn't use the req- prefix, because it's optional. I'm also not aware of any ad hoc standards that use no125 in BIP-21-ish URIs.\n\n- Sjors\n\nP.S. I'd similarly suggest adding a bech32 param, but that's for another discussion\n\n[0] https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki\n[1] https://bitcoincore.org/en/2017/09/01/release-0.15.0/#better-fee-estimates\n[2] https://github.com/bitcoin/bitcoin/pull/11605\n[3] https://github.com/bitcoin/bitcoin/issues/11828\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/5beec6ce/attachment.sig>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2017-12-05T19:39:32",
                "message_text_only": "On Tuesday 05 December 2017 7:24:04 PM Sjors Provoost wrote:\n> I recently submitted a pull request that would turn on RBF by default,\n> which triggered some discussion [2]. To ease the transition for merchants\n> who are reluctant to see their customers use RBF, Matt Corallo suggested\n> that wallets honor a no125=1 flag.\n> \n> So a BIP-21 URI would look like this:\n> bitcoin:175t...45W?amount=20.3&no125=1\n> \n> When this flag is set, wallets should not use RBF, regardless of their\n> default, unless the user explicitly overrides the merchant's preference.\n\nThis seems counterproductive. There is no reason to ever avoid the RBF flag. \nI'm not aware of any evidence it even reduces risk of, and it certainly \ndoesn't prevent double spending. Plenty of miners allow RBF regardless of the \nflag, and malicious double spending doesn't benefit much from RBF in any case.\n\n> P.S. I'd similarly suggest adding a bech32 param, but that's for another\n> discussion\n\nBech32 addresses are just normal addresses. What need is there for a param?\n\nLuke"
            },
            {
                "author": "Sjors Provoost",
                "date": "2017-12-05T20:00:01",
                "message_text_only": "CryptAxe wrote:\n> Perhaps instead of a flag that can be used to disable a specific operation, there should be a \"-ignoredflags=x,y,z\" section of the URI that can be used to ignore whatever BIP this might also be useful for in the future?\n\nI don't think all BIPs lend themselves to this pattern. Can you think of another example? I also suspect each ignored flag requires carefully defined behavior, so it's probably better to spell that out in the BIP.\n\nI also wouldn't be surprised if this BIP will get superseded in its entirety in the not too distant future; I believe there's some earlier discussion on this list about variations on BIP-71. So I don't think there will be many additional params in the future that warrant abstraction.\n\n\nLuke Dashjr wrote:\n>> P.S. I'd similarly suggest adding a bech32 param, but that's for another\n>> discussion\n> \n> Bech32 addresses are just normal addresses. What need is there for a param?\n> \n> Luke\n\nMost wallets consider bech32 addresses to be invalid. This would allow merchants to display a backwards compatible P2SH address and allow modern wallets to use bech32. In fact, this should be encouraged because it's slightly cheaper for the recipient to spend these funds (but not worth even a tiny increase in shopping cart abandonment).\n\nOnce the new format has sufficient adoption, merchants can simply drop support for old wallets and not use this parameter.\n\nSjors\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/6a2b0451/attachment.sig>"
            },
            {
                "author": "CryptAxe",
                "date": "2017-12-05T20:06:31",
                "message_text_only": "On Dec 5, 2017 12:00 PM, \"Sjors Provoost\" <sjors at sprovoost.nl> wrote:\n\n...\n\nI don't think all BIPs lend themselves to this pattern. Can you think of\nanother example?\n\n\nNot right now, just seemed like a good idea to consider making it useful\nfor more than one thing (maybe CT or something else could use it in the\nfuture?).\n\nI also suspect each ignored flag requires carefully defined behavior, so\nit's probably better to spell that out in the BIP.\n\nSjors\n\n\nAgreed, no reason they couldn't reuse the same section of the payment\nrequest URI though. (And define that behavior in the BIP)\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/f2230fff/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2017-12-11T18:19:43",
                "message_text_only": "On Tue, Dec 05, 2017 at 07:39:32PM +0000, Luke Dashjr via bitcoin-dev wrote:\n> On Tuesday 05 December 2017 7:24:04 PM Sjors Provoost wrote:\n> > I recently submitted a pull request that would turn on RBF by default,\n> > which triggered some discussion [2]. To ease the transition for merchants\n> > who are reluctant to see their customers use RBF, Matt Corallo suggested\n> > that wallets honor a no125=1 flag.\n> > \n> > So a BIP-21 URI would look like this:\n> > bitcoin:175t...45W?amount=20.3&no125=1\n> > \n> > When this flag is set, wallets should not use RBF, regardless of their\n> > default, unless the user explicitly overrides the merchant's preference.\n> \n> This seems counterproductive. There is no reason to ever avoid the RBF flag. \n> I'm not aware of any evidence it even reduces risk of, and it certainly \n> doesn't prevent double spending. Plenty of miners allow RBF regardless of the \n> flag, and malicious double spending doesn't benefit much from RBF in any case.\n\nI'll second the objection to a no-RBF flag.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/160e761a/attachment.sig>"
            },
            {
                "author": "Matt Corallo",
                "date": "2017-12-23T16:25:08",
                "message_text_only": "While the usability of non-RBF transactions tends to be quite poor, there are some legitimate risk-analysis-based reasons why people use them (eg to sell BTC based on a incoming transaction which you will need to convert to fiat, which has low cost if the transaction doesn't confirm), and if people want to overpay on fees to do so, no reason not to let them, including if the merchant is willing to CPFP to do so.\n\nHonestly, I anticipate very low usage of such a flag, which is appropriate, but also strongly support including it. If things turn out differently with merchants reducing the usability of BTC without taking over the CPFP responsibility we could make the option imply receiver-pays-fee, but no reason to overcomplicate it yet.\n\nOn December 11, 2017 1:19:43 PM EST, Peter Todd via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>On Tue, Dec 05, 2017 at 07:39:32PM +0000, Luke Dashjr via bitcoin-dev\n>wrote:\n>> On Tuesday 05 December 2017 7:24:04 PM Sjors Provoost wrote:\n>> > I recently submitted a pull request that would turn on RBF by\n>default,\n>> > which triggered some discussion [2]. To ease the transition for\n>merchants\n>> > who are reluctant to see their customers use RBF, Matt Corallo\n>suggested\n>> > that wallets honor a no125=1 flag.\n>> > \n>> > So a BIP-21 URI would look like this:\n>> > bitcoin:175t...45W?amount=20.3&no125=1\n>> > \n>> > When this flag is set, wallets should not use RBF, regardless of\n>their\n>> > default, unless the user explicitly overrides the merchant's\n>preference.\n>> \n>> This seems counterproductive. There is no reason to ever avoid the\n>RBF flag. \n>> I'm not aware of any evidence it even reduces risk of, and it\n>certainly \n>> doesn't prevent double spending. Plenty of miners allow RBF\n>regardless of the \n>> flag, and malicious double spending doesn't benefit much from RBF in\n>any case.\n>\n>I'll second the objection to a no-RBF flag.\n>\n>-- \n>https://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171223/feda2c15/attachment.html>"
            },
            {
                "author": "Paul Iverson",
                "date": "2017-12-23T18:33:21",
                "message_text_only": "Allowing a \"no-RBF\" flag serves only to fool new users into believing that\n0-conf is more secure than it is. There is already too much confusion about\nthis point.\n\nIn Bitcoin was assume that miners are profit-maximizing agents, and so we\nmust assume that (flag or not) miners will replace transactions from\nmempool with conflicts paying a higher fee. From that viewpoint, full RBF\nis already \"de facto\" policy in Bitcoin. So I agree with Luke and Peter:\nremove the flag and make all transactions RBF as \"de jure\" policy too.\n\nAt the same time, we need more outreach and education to clarify the risks\nof 0-conf, and we need to show miners how they can earn more profits by\nadopting full RBF.\n\nPaul.\n\nOn Sat, Dec 23, 2017 at 8:25 AM, Matt Corallo via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> While the usability of non-RBF transactions tends to be quite poor, there\n> are some legitimate risk-analysis-based reasons why people use them (eg to\n> sell BTC based on a incoming transaction which you will need to convert to\n> fiat, which has low cost if the transaction doesn't confirm), and if people\n> want to overpay on fees to do so, no reason not to let them, including if\n> the merchant is willing to CPFP to do so.\n>\n> Honestly, I anticipate very low usage of such a flag, which is\n> appropriate, but also strongly support including it. If things turn out\n> differently with merchants reducing the usability of BTC without taking\n> over the CPFP responsibility we could make the option imply\n> receiver-pays-fee, but no reason to overcomplicate it yet.\n>\n> On December 11, 2017 1:19:43 PM EST, Peter Todd via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> On Tue, Dec 05, 2017 at 07:39:32PM +0000, Luke Dashjr via bitcoin-dev wrote:\n>>\n>>>  On Tuesday 05 December 2017 7:24:04 PM Sjors Provoost wrote:\n>>>\n>>>>  I recently submitted a pull request that would turn on RBF by default,\n>>>>  which triggered some discussion [2]. To ease the transition for merchants\n>>>>  who are reluctant to see their customers use RBF, Matt Corallo suggested\n>>>>  that wallets honor a no125=1 flag.\n>>>>\n>>>>  So a BIP-21 URI would look like this:\n>>>>  bitcoin:175t...45W?amount=20.3&no125=1\n>>>>\n>>>>  When this flag is set, wallets should not use RBF, regardless of their\n>>>>  default, unless the user explicitly overrides the merchant's preference.\n>>>>\n>>>\n>>>  This seems counterproductive. There is no reason to ever avoid the RBF flag.\n>>>  I'm not aware of any evidence it even reduces risk of, and it certainly\n>>>  doesn't prevent double spending. Plenty of miners allow RBF regardless of the\n>>>  flag, and malicious double spending doesn't benefit much from RBF in any case.\n>>>\n>>\n>> I'll second the objection to a no-RBF flag.\n>>\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171223/5d90c5a8/attachment.html>"
            },
            {
                "author": "CryptAxe",
                "date": "2017-12-05T19:40:42",
                "message_text_only": "Perhaps instead of a flag that can be used to disable a specific operation,\nthere should be a \"-ignoredflags=x,y,z\" section of the URI that can be used\nto ignore whatever BIP this might also be useful for in the future?\n\nOn Dec 5, 2017 11:34 AM, \"Sjors Provoost via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> One way to reduce fees is to encourage usage of Replace-By-Fee, BIP 125\n> [0]. It allows wallets to recommend lower fees, because if a transaction\n> gets stuck due to underestimation, the fee can easily be bumped.\n>\n> Bitcoin Core has had support for RBF for a while, and as of v0.15.0\n> recommends lower fees [1] when the user chooses to use RBF.\n>\n> I recently submitted a pull request that would turn on RBF by default,\n> which triggered some discussion [2]. To ease the transition for merchants\n> who are reluctant to see their customers use RBF, Matt Corallo suggested\n> that wallets honor a no125=1 flag.\n>\n> So a BIP-21 URI would look like this: bitcoin:175t...45W?amount=20.\n> 3&no125=1\n>\n> When this flag is set, wallets should not use RBF, regardless of their\n> default, unless the user explicitly overrides the merchant's preference.\n>\n> Afaik adding this flag won't break existing BIP-21 support. It doesn't use\n> the req- prefix, because it's optional. I'm also not aware of any ad hoc\n> standards that use no125 in BIP-21-ish URIs.\n>\n> - Sjors\n>\n> P.S. I'd similarly suggest adding a bech32 param, but that's for another\n> discussion\n>\n> [0] https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki\n> [1] https://bitcoincore.org/en/2017/09/01/release-0.15.0/#\n> better-fee-estimates\n> [2] https://github.com/bitcoin/bitcoin/pull/11605\n> [3] https://github.com/bitcoin/bitcoin/issues/11828\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/923ac704/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP-21 amendment proposal: -no125",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "CryptAxe",
                "Peter Todd",
                "Luke Dashjr",
                "Sjors Provoost",
                "Matt Corallo",
                "Paul Iverson"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 13918
        }
    },
    {
        "title": "[bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks",
        "thread_messages": [
            {
                "author": "Damian Williamson",
                "date": "2017-12-07T21:01:43",
                "message_text_only": "Good afternoon,\n\nThe need for this proposal:\n\nWe all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.\n\nI recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.\n\nI argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.\n\nBusiness cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.\n\nUnder the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.\n\nOnce there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.\n\nI also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.\n\nI do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.\n\nThis great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.\n\nI have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.\n\n# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n## The problem:\nEverybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.\n\nThe current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.\n\nCurrent fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.\n\nBitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.\n\nThe possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.\n\n## Solution summary:\nProvide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.\n\nUse a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.\n\nThe curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?\n\n**Explanation of the operation of priority:**\n> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.\n\n>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.\n\nI am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.\n\n## Pros:\n* Maximizes transaction reliability.\n* Fully scalable.\n* Maximizes possibility for consumer and business uptake.\n* Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.\n* Market determines fee paid for transaction priority.\n* Fee recommendations work all the way out to 30 days or greater.\n* Provides additional block entropy; greater security since there is less probability of predicting the next block.\n\n## Cons:\n* Could initially lower total transaction fees per block.\n* Must be first be programmed.\n\n## Solution operation:\nThis is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.\n\n1. Determine the target block size for the current block.\n2. Assign a transaction priority to each transaction in the pool.\n3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.\n5. Solve block.\n6. Broadcast the next target block size with the current block when it is solved.\n7. Block is received.\n8. Block verification process.\n9. Accept/reject block based on verification result.\n10. Repeat.\n\n## Closing comments:\nIt may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.\n\nI implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.\n\nRegards,\nDamian Williamson\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171207/79e32368/attachment.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-15T09:42:42",
                "message_text_only": "I should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?\n\nI suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.\n\nIt has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.\n\n\nIf someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?\n\nRegards,\nDamian Williamson\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Friday, 8 December 2017 8:01 AM\nTo: bitcoin-dev at lists.linuxfoundation.org\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n\nGood afternoon,\n\nThe need for this proposal:\n\nWe all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.\n\nI recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.\n\nI argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.\n\nBusiness cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.\n\nUnder the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.\n\nOnce there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.\n\nI also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.\n\nI do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.\n\nThis great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.\n\nI have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.\n\n# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n## The problem:\nEverybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.\n\nThe current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.\n\nCurrent fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.\n\nBitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.\n\nThe possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.\n\n## Solution summary:\nProvide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.\n\nUse a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.\n\nThe curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?\n\n**Explanation of the operation of priority:**\n> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.\n\n>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.\n\nI am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.\n\n## Pros:\n* Maximizes transaction reliability.\n* Fully scalable.\n* Maximizes possibility for consumer and business uptake.\n* Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.\n* Market determines fee paid for transaction priority.\n* Fee recommendations work all the way out to 30 days or greater.\n* Provides additional block entropy; greater security since there is less probability of predicting the next block.\n\n## Cons:\n* Could initially lower total transaction fees per block.\n* Must be first be programmed.\n\n## Solution operation:\nThis is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.\n\n1. Determine the target block size for the current block.\n2. Assign a transaction priority to each transaction in the pool.\n3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.\n5. Solve block.\n6. Broadcast the next target block size with the current block when it is solved.\n7. Block is received.\n8. Block verification process.\n9. Accept/reject block based on verification result.\n10. Repeat.\n\n## Closing comments:\nIt may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.\n\nI implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.\n\nRegards,\nDamian Williamson\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171215/dc268c35/attachment-0001.html>"
            },
            {
                "author": "Rhavar",
                "date": "2017-12-15T16:38:46",
                "message_text_only": "> I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?\n\nUnfortunately your proposal is really fundamentally broken, on a few levels. I think you might need to do a bit more research into how bitcoin works before coming up with such improvements =)\n\nBut just some quick notes:\n\n* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.\n\n* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.\n\n* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by \"priority\".  What are you going to do if a \"malicious\" miner decides to go after their profits and order by what makes them the most money. Add \"ordered by priority\" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.\n\nIf you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.\n\n-Ryan\n\n> -------- Original Message --------\n> Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n> Local Time: December 15, 2017 3:42 AM\n> UTC Time: December 15, 2017 9:42 AM\n> From: bitcoin-dev at lists.linuxfoundation.org\n> To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\n>\n> I should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?\n>\n> I suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.\n>\n> It has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.\n>\n> If someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?\n>\n> Regards,\n> Damian Williamson\n>\n> ---------------------------------------------------------------\n>\n> From: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n> Sent: Friday, 8 December 2017 8:01 AM\n> To: bitcoin-dev at lists.linuxfoundation.org\n> Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n>\n> Good afternoon,\n>\n> The need for this proposal:\n>\n> We all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.\n>\n> I recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.\n>\n> I argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.\n>\n> Business cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.\n>\n> Under the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.\n>\n> Once there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.\n>\n> I also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.\n>\n> I do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.\n>\n> This great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.\n>\n> I have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.\n>\n> # BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n>\n> ## The problem:\n> Everybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.\n>\n> The current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.\n>\n> Current fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.\n>\n> Bitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.\n>\n> The possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.\n>\n> ## Solution summary:\n> Provide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.\n>\n> Use a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.\n>\n> The curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?\n>\n> **Explanation of the operation of priority:**\n>> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.\n>\n>>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.\n>\n> I am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.\n>\n> ## Pros:\n> * Maximizes transaction reliability.\n> * Fully scalable.\n> * Maximizes possibility for consumer and business uptake.\n> * Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.\n> * Market determines fee paid for transaction priority.\n> * Fee recommendations work all the way out to 30 days or greater.\n> * Provides additional block entropy; greater security since there is less probability of predicting the next block.\n>\n> ## Cons:\n> * Could initially lower total transaction fees per block.\n> * Must be first be programmed.\n>\n> ## Solution operation:\n> This is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.\n>\n> 1. Determine the target block size for the current block.\n> 2. Assign a transaction priority to each transaction in the pool.\n> 3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.\n> 5. Solve block.\n> 6. Broadcast the next target block size with the current block when it is solved.\n> 7. Block is received.\n> 8. Block verification process.\n> 9. Accept/reject block based on verification result.\n> 10. Repeat.\n>\n> ## Closing comments:\n> It may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.\n>\n> I implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.\n>\n> Regards,\n> Damian Williamson\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171215/4158a992/attachment-0001.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-15T20:59:51",
                "message_text_only": "There are really two separate problems to solve.\n\n\n  1.  How does Bitcoin scale with fixed block size?\n  2.  How do we ensure that all valid transactions are eventually included in the blockchain?\n\n\nThose are the two issues that the proposal attempts to address. It makes sense to resolve these two problems together. Using the proposed system for variable block sizes would solve the first problem but there would still be a whole bunch of never confirming transactions. I am not sure how to reliably solve the second problem at scale without first solving the first.\n\n\n>* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.\n\nI do not suggest a consensus. Depending on which node solves a block the value for next block size will be different. The consensus would be that blocks will adhere to the next block size value transmitted with the current block. It is easy to verify that the consensus is being adhered to once in place.\n\n>* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.\n\nNot a necessary function, just an effect of using a probability-based distribution.\n\n>* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by \"priority\".  What are you going to do if a \"malicious\" miner decides to go after their profits and order by what makes them the most money. Add \"ordered by priority\" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.\n\nI entirely agree with your sentiment that Bitcoin must be incentive compatible. It is necessary.\n\nIt is in only miners immediate interest to make the most profitable block from the available transaction pool. As with so many other things, it is necessary to partially ignore short-term gain for long-term benefit. It is in miners and everybody's long-term interest to have a reliable transaction service. A busy transaction service that confirms lots of transactions per hour will become more profitable as demand increases and more users are prepared to pay for priority. As it is there is currently no way to fully scale because of the transaction bandwidth limit and that is problematic. If all valid transactions must eventually confirm then there must be a way to resolve that problem.\n\nBitcoin deliberately removes traditional scale by ensuring blocks take ten minutes on average to solve, an ingenious idea and, incentive compatible but, fixed block sizes leaves us with a problem to solve when we want to scale.\n\n>If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.\n\nI am confident that the math to verify blocks based on the proposal can be developed (and I think it will not be too complex for a mathematician with the relevant experience), however, I am nowhere near experienced enough with probability and statistical analysis to do it. Yes, if Bitcoin doesn't then it might make another great opportunity for an altcoin but I am not even nearly interested in promoting any altcoins.\n\n\nIf not the proposal that I have put forward, then, hopefully, someone can come up with a better solution. The important thing is that the issues are resolved.\n\n\nRegards,\n\nDamian Williamson\n\n\n________________________________\nFrom: Rhavar <rhavar at protonmail.com>\nSent: Saturday, 16 December 2017 3:38 AM\nTo: Damian Williamson\nCc: Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n> I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?\n\nUnfortunately your proposal is really fundamentally broken, on a few levels. I think you might need to do a bit more research into how bitcoin works before coming up with such improvements =)\n\nBut just some quick notes:\n\n* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.\n\n* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.\n\n* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by \"priority\".  What are you going to do if a \"malicious\" miner decides to go after their profits and order by what makes them the most money. Add \"ordered by priority\" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.\n\nIf you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.\n\n\n\n\n-Ryan\n\n\n-------- Original Message --------\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\nLocal Time: December 15, 2017 3:42 AM\nUTC Time: December 15, 2017 9:42 AM\nFrom: bitcoin-dev at lists.linuxfoundation.org\nTo: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\n\n\n\n\nI should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?\n\nI suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.\n\nIt has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.\n\n\n\nIf someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?\n\nRegards,\nDamian Williamson\n\n\n________________________________\n\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Friday, 8 December 2017 8:01 AM\nTo: bitcoin-dev at lists.linuxfoundation.org\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n\n\nGood afternoon,\n\nThe need for this proposal:\n\nWe all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.\n\nI recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.\n\nI argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.\n\nBusiness cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.\n\nUnder the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.\n\nOnce there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.\n\nI also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.\n\nI do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.\n\nThis great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.\n\nI have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.\n\n# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n## The problem:\nEverybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.\n\nThe current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.\n\nCurrent fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.\n\nBitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.\n\nThe possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.\n\n## Solution summary:\nProvide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.\n\nUse a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.\n\nThe curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?\n\n**Explanation of the operation of priority:**\n> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.\n\n>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.\n\nI am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.\n\n## Pros:\n* Maximizes transaction reliability.\n* Fully scalable.\n* Maximizes possibility for consumer and business uptake.\n* Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.\n* Market determines fee paid for transaction priority.\n* Fee recommendations work all the way out to 30 days or greater.\n* Provides additional block entropy; greater security since there is less probability of predicting the next block.\n\n## Cons:\n* Could initially lower total transaction fees per block.\n* Must be first be programmed.\n\n## Solution operation:\nThis is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.\n\n1. Determine the target block size for the current block.\n2. Assign a transaction priority to each transaction in the pool.\n3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.\n5. Solve block.\n6. Broadcast the next target block size with the current block when it is solved.\n7. Block is received.\n8. Block verification process.\n9. Accept/reject block based on verification result.\n10. Repeat.\n\n## Closing comments:\nIt may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.\n\nI implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.\n\nRegards,\nDamian Williamson\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171215/b36462c3/attachment-0001.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-17T04:14:39",
                "message_text_only": "I do not know why people make the leap that the proposal requires a consensus on the transaction pool. It does not.\n\n\nIt may be helpful to have the discussion from the previous thread linked here.\n\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015370.html\n\n\nWhere I speak of validating that a block conforms to the broadcast next block size, I do not propose validating the number broadcast for the next block size itself, only that the next generated block is that size.\n\n\nRegards,\n\nDamian Williamson\n\n\n________________________________\nFrom: Damian Williamson <willtech at live.com.au>\nSent: Saturday, 16 December 2017 7:59 AM\nTo: Rhavar\nCc: Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n\nThere are really two separate problems to solve.\n\n\n  1.  How does Bitcoin scale with fixed block size?\n  2.  How do we ensure that all valid transactions are eventually included in the blockchain?\n\n\nThose are the two issues that the proposal attempts to address. It makes sense to resolve these two problems together. Using the proposed system for variable block sizes would solve the first problem but there would still be a whole bunch of never confirming transactions. I am not sure how to reliably solve the second problem at scale without first solving the first.\n\n\n>* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.\n\nI do not suggest a consensus. Depending on which node solves a block the value for next block size will be different. The consensus would be that blocks will adhere to the next block size value transmitted with the current block. It is easy to verify that the consensus is being adhered to once in place.\n\n>* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.\n\nNot a necessary function, just an effect of using a probability-based distribution.\n\n>* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by \"priority\".  What are you going to do if a \"malicious\" miner decides to go after their profits and order by what makes them the most money. Add \"ordered by priority\" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.\n\nI entirely agree with your sentiment that Bitcoin must be incentive compatible. It is necessary.\n\nIt is in only miners immediate interest to make the most profitable block from the available transaction pool. As with so many other things, it is necessary to partially ignore short-term gain for long-term benefit. It is in miners and everybody's long-term interest to have a reliable transaction service. A busy transaction service that confirms lots of transactions per hour will become more profitable as demand increases and more users are prepared to pay for priority. As it is there is currently no way to fully scale because of the transaction bandwidth limit and that is problematic. If all valid transactions must eventually confirm then there must be a way to resolve that problem.\n\nBitcoin deliberately removes traditional scale by ensuring blocks take ten minutes on average to solve, an ingenious idea and, incentive compatible but, fixed block sizes leaves us with a problem to solve when we want to scale.\n\n>If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.\n\nI am confident that the math to verify blocks based on the proposal can be developed (and I think it will not be too complex for a mathematician with the relevant experience), however, I am nowhere near experienced enough with probability and statistical analysis to do it. Yes, if Bitcoin doesn't then it might make another great opportunity for an altcoin but I am not even nearly interested in promoting any altcoins.\n\n\nIf not the proposal that I have put forward, then, hopefully, someone can come up with a better solution. The important thing is that the issues are resolved.\n\n\nRegards,\n\nDamian Williamson\n\n\n________________________________\nFrom: Rhavar <rhavar at protonmail.com>\nSent: Saturday, 16 December 2017 3:38 AM\nTo: Damian Williamson\nCc: Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n> I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?\n\nUnfortunately your proposal is really fundamentally broken, on a few levels. I think you might need to do a bit more research into how bitcoin works before coming up with such improvements =)\n\nBut just some quick notes:\n\n* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.\n\n* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.\n\n* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by \"priority\".  What are you going to do if a \"malicious\" miner decides to go after their profits and order by what makes them the most money. Add \"ordered by priority\" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.\n\nIf you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.\n\n\n\n\n-Ryan\n\n\n-------- Original Message --------\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\nLocal Time: December 15, 2017 3:42 AM\nUTC Time: December 15, 2017 9:42 AM\nFrom: bitcoin-dev at lists.linuxfoundation.org\nTo: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\n\n\n\n\nI should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?\n\nI suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.\n\nIt has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.\n\n\n\nIf someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?\n\nRegards,\nDamian Williamson\n\n\n________________________________\n\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Friday, 8 December 2017 8:01 AM\nTo: bitcoin-dev at lists.linuxfoundation.org\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n\n\nGood afternoon,\n\nThe need for this proposal:\n\nWe all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.\n\nI recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.\n\nI argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.\n\nBusiness cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.\n\nUnder the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.\n\nOnce there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.\n\nI also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.\n\nI do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.\n\nThis great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.\n\nI have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.\n\n# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n## The problem:\nEverybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.\n\nThe current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.\n\nCurrent fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.\n\nBitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.\n\nThe possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.\n\n## Solution summary:\nProvide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.\n\nUse a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.\n\nThe curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?\n\n**Explanation of the operation of priority:**\n> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.\n\n>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.\n\nI am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.\n\n## Pros:\n* Maximizes transaction reliability.\n* Fully scalable.\n* Maximizes possibility for consumer and business uptake.\n* Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.\n* Market determines fee paid for transaction priority.\n* Fee recommendations work all the way out to 30 days or greater.\n* Provides additional block entropy; greater security since there is less probability of predicting the next block.\n\n## Cons:\n* Could initially lower total transaction fees per block.\n* Must be first be programmed.\n\n## Solution operation:\nThis is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.\n\n1. Determine the target block size for the current block.\n2. Assign a transaction priority to each transaction in the pool.\n3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.\n5. Solve block.\n6. Broadcast the next target block size with the current block when it is solved.\n7. Block is received.\n8. Block verification process.\n9. Accept/reject block based on verification result.\n10. Repeat.\n\n## Closing comments:\nIt may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.\n\nI implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.\n\nRegards,\nDamian Williamson\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171217/371a19f8/attachment-0001.html>"
            },
            {
                "author": "Chris Riley",
                "date": "2017-12-18T12:09:34",
                "message_text_only": "Regarding \"problem\" #2 where you say \"How do we ensure that all valid\ntransactions are eventually included in the blockchain?\":  I do not believe\nthat all people would (a) agree this is a problem or (b) that we do want to\n*ENSURE* that *ALL* valid transactions are eventually included in the\nblockchain.  There are many *valid* transactions that oftentimes miners do\nnot (and should not) wish to require be confirmed and included in the\nblockchain.  Spam transactions for example can be valid, but used to attack\nbitcoin by using no or low fee.  Any valid transaction MAY be included by a\nminer, but requiring it in some fashion at this point would open the\nnetwork to other attack vectors.  Perhaps you meant it a different way.\n\n\nOn Fri, Dec 15, 2017 at 3:59 PM, Damian Williamson via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> There are really two separate problems to solve.\n>\n>\n> How does Bitcoin scale with fixed block size?\n> How do we ensure that all valid transactions are eventually included in\nthe blockchain?\n>\n>\n> Those are the two issues that the proposal attempts to address. It makes\nsense to resolve these two problems together. Using the proposed system for\nvariable block sizes would solve the first problem but there would still be\na whole bunch of never confirming transactions. I am not sure how to\nreliably solve the second problem at scale without first solving the first.\n>\n>\n> >* Every node has a (potentially) different mempool, you can't use it to\ndecide consensus values like the max block size.\n>\n>\n> I do not suggest a consensus. Depending on which node solves a block the\nvalue for next block size will be different. The consensus would be that\nblocks will adhere to the next block size value transmitted with the\ncurrent block. It is easy to verify that the consensus is being adhered to\nonce in place.\n>\n> >* Increasing the entropy in a block to make it more unpredictable\ndoesn't really make sense.\n>\n> Not a necessary function, just an effect of using a probability-based\ndistribution.\n>\n> >* Bitcoin should be roughly incentive compatible. Your proposal\nexplicits asks miners to ignore their best interests, and confirm\ntransactions by \"priority\".  What are you going to do if a \"malicious\"\nminer decides to go after their profits and order by what makes them the\nmost money. Add \"ordered by priority\" as a consensus requirement? And even\nif you miners can still sort their mempool by fee, and then order the top\n1MB by priority.\n>\n> I entirely agree with your sentiment that Bitcoin must be incentive\ncompatible. It is necessary.\n>\n> It is in only miners immediate interest to make the most profitable block\nfrom the available transaction pool. As with so many other things, it is\nnecessary to partially ignore short-term gain for long-term benefit. It is\nin miners and everybody's long-term interest to have a reliable transaction\nservice. A busy transaction service that confirms lots of transactions per\nhour will become more profitable as demand increases and more users are\nprepared to pay for priority. As it is there is currently no way to fully\nscale because of the transaction bandwidth limit and that is problematic.\nIf all valid transactions must eventually confirm then there must be a way\nto resolve that problem.\n>\n> Bitcoin deliberately removes traditional scale by ensuring blocks take\nten minutes on average to solve, an ingenious idea and, incentive\ncompatible but, fixed block sizes leaves us with a problem to solve when we\nwant to scale.\n>\n> >If you could find a good solution that would allow you to know if miners\nwere following your rule or not (and thus ignore it if it doesn't) then you\nwouldn't even need bitcoin in the first place.\n>\n> I am confident that the math to verify blocks based on the proposal can\nbe developed (and I think it will not be too complex for a mathematician\nwith the relevant experience), however, I am nowhere near experienced\nenough with probability and statistical analysis to do it. Yes, if Bitcoin\ndoesn't then it might make another great opportunity for an altcoin but I\nam not even nearly interested in promoting any altcoins.\n>\n>\n> If not the proposal that I have put forward, then, hopefully, someone can\ncome up with a better solution. The important thing is that the issues are\nresolved.\n>\n>\n> Regards,\n>\n> Damian Williamson\n>\n>\n>\n> ________________________________\n> From: Rhavar <rhavar at protonmail.com>\n> Sent: Saturday, 16 December 2017 3:38 AM\n> To: Damian Williamson\n> Cc: Bitcoin Protocol Discussion\n> Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use\nTransaction Priority For Ordering Transactions In Blocks\n>\n> > I understand that there would be technical issues to resolve in\nimplementation, but, are there no fundamental errors?\n>\n> Unfortunately your proposal is really fundamentally broken, on a few\nlevels. I think you might need to do a bit more research into how bitcoin\nworks before coming up with such improvements =)\n>\n> But just some quick notes:\n>\n> * Every node has a (potentially) different mempool, you can't use it to\ndecide consensus values like the max block size.\n>\n> * Increasing the entropy in a block to make it more unpredictable doesn't\nreally make sense.\n>\n> * Bitcoin should be roughly incentive compatible. Your proposal explicits\nasks miners to ignore their best interests, and confirm transactions by\n\"priority\".  What are you going to do if a \"malicious\" miner decides to go\nafter their profits and order by what makes them the most money. Add\n\"ordered by priority\" as a consensus requirement? And even if you miners\ncan still sort their mempool by fee, and then order the top 1MB by priority.\n>\n> If you could find a good solution that would allow you to know if miners\nwere following your rule or not (and thus ignore it if it doesn't) then you\nwouldn't even need bitcoin in the first place.\n>\n>\n>\n>\n> -Ryan\n>\n>\n> -------- Original Message --------\n> Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction\nPriority For Ordering Transactions In Blocks\n> Local Time: December 15, 2017 3:42 AM\n> UTC Time: December 15, 2017 9:42 AM\n> From: bitcoin-dev at lists.linuxfoundation.org\n> To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\n>\n>\n>\n> I should not take it that the lack of critical feedback to this revised\nproposal is a glowing endorsement. I understand that there would be\ntechnical issues to resolve in implementation, but, are there no\nfundamental errors?\n>\n> I suppose that it if is difficult to determine how long a transaction has\nbeen waiting in the pool then, each node could simply keep track of when a\ntransaction was first seen. This may have implications for a verify\nroutine, however, for example, if a node was offline, how should it\ndifferentiate how long each transaction was waiting in that case? If a node\nwas restarted daily would it always think that all transactions had been\nwaiting in the pool less than one day If each node keeps the current\ntransaction pool in a file and updates it, as transactions are included in\nblocks and, as new transactions appear in the pool, then that would go some\nway to alleviate the issue, apart from entirely new nodes. There should be\nno reason the contents of a transaction pool files cannot be shared without\nagreement as to the transaction pool between nodes, just as nodes transmit\nnew transactions freely.\n>\n> It has been questioned why miners could not cheat. For the question of\nhow many transactions to include in a block, I say it is a standoff and\nminers will conform to the proposal, not wanting to leave transactions with\nvalid fees standing, and, not wanting to shrink the transaction pool. In\nany case, if miners shrink the transaction pool then I am not immediately\nconcerned since it provides a more efficient service. For the question of\nincluding transactions according to the proposal, I say if it is possible\nto keep track of how long transactions are waiting in the pool so that they\ncan be included on a probability curve then it is possible to verify that\nblocks conform to the proposal, since the input is a probability, the\noutput should conform to a probability curve.\n>\n>\n> If someone has the necessary skill, would anyone be willing to develop\nthe math necessary for the proposal?\n>\n> Regards,\n> Damian Williamson\n>\n>\n> ________________________________\n>\n> From: bitcoin-dev-bounces at lists.linuxfoundation.org <\nbitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian\nWilliamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n> Sent: Friday, 8 December 2017 8:01 AM\n> To: bitcoin-dev at lists.linuxfoundation.org\n> Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction\nPriority For Ordering Transactions In Blocks\n>\n>\n>\n> Good afternoon,\n>\n> The need for this proposal:\n>\n> We all must learn to admit that transaction bandwidth is still lurking as\na serious issue for the operation, reliability, safety, consumer\nacceptance, uptake and, for the value of Bitcoin.\n>\n> I recently sent a payment which was not urgent so; I chose three-day\ntarget confirmation from the fee recommendation. That transaction has still\nnot confirmed after now more than six days - even waiting twice as long\nseems quite reasonable to me. That transaction is a valid transaction; it\nis not rubbish, junk or, spam. Under the current model with transaction\nbandwidth limitation, the longer a transaction waits, the less likely it is\never to confirm due to rising transaction numbers and being pushed back by\ntransactions with rising fees.\n>\n> I argue that no transactions are rubbish or junk, only some zero fee\ntransactions might be spam. Having an ever-increasing number of valid\ntransactions that do not confirm as more new transactions with higher fees\nare created is the opposite of operating a robust, reliable transaction\nsystem.\n>\n> Business cannot operate with a model where transactions may or may not\nconfirm. Even a business choosing a modest fee has no guarantee that their\nvalid transaction will not be shuffled down by new transactions to the\nrealm of never confirming after it is created. Consumers also will not\naccept this model as Bitcoin expands. If Bitcoin cannot be a reliable\npayment system for confirmed transactions then consumers, by and large,\nwill simply not accept the model once they understand. Bitcoin will be a\ndirty payment system, and this will kill the value of Bitcoin.\n>\n> Under the current system, a minority of transactions will eventually be\nthe lucky few who have fees high enough to escape being pushed down the\nlist.\n>\n> Once there are more than x transactions (transaction bandwidth limit)\nevery ten minutes, only those choosing twenty-minute confirmation (2\nblocks) will have initially at most a fifty percent chance of ever having\ntheir payment confirm. Presently, not even using fee recommendations can\nensure a sufficiently high fee is paid to ensure transaction confirmation.\n>\n> I also argue that the current auction model for limited transaction\nbandwidth is wrong, is not suitable for a reliable transaction system and,\nis wrong for Bitcoin. All transactions must confirm in due time. Currently,\nBitcoin is not a safe way to send payments.\n>\n> I do not believe that consumers and business are against paying fees,\neven high fees. What is required is operational reliability.\n>\n> This great issue needs to be resolved for the safety and reliability of\nBitcoin. The time to resolve issues in commerce is before they become great\nbig issues. The time to resolve this issue is now. We must have the\nforesight to identify and resolve problems before they trip us over.\nSimply doubling block sizes every so often is reactionary and is not a\nreliable permanent solution. I have written a BIP proposal for a technical\nsolution but, need your help to write it up to an acceptable standard to be\na full BIP.\n>\n> I have formatted the following with markdown which is human readable so,\nI hope nobody minds. I have done as much with this proposal as I feel that\nI am able so far but continue to take your feedback.\n>\n> # BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering\nTransactions In Blocks\n>\n> ## The problem:\n> Everybody wants value. Miners want to maximize revenue from fees (and we\npresume, to minimize block size). Consumers need transaction reliability\nand, (we presume) want low fees.\n>\n> The current transaction bandwidth limit is a limiting factor for both. As\nthe operational safety of transactions is limited, so is consumer\nconfidence as they realize the issue and, accordingly, uptake is limited.\nFees are artificially inflated due to bandwidth limitations while failing\nto provide a full confirmation service for all transactions.\n>\n> Current fee recommendations provide no satisfaction for transaction\nreliability and, as Bitcoin scales, this will worsen.\n>\n> Bitcoin must be a fully scalable and reliable service, providing full\ntransaction confirmation for every valid transaction.\n>\n> The possibility to send a transaction with a fee lower than one that is\nacceptable to allow eventual transaction confirmation should be removed\nfrom the protocol and also from the user interface.\n>\n> ## Solution summary:\n> Provide each transaction with an individual transaction priority each\ntime before choosing transactions to include in the current block, the\npriority being a function of the fee paid (on a curve), and the time\nwaiting in the transaction pool (also on a curve) out to n days (n=60 ?).\nThe transaction priority to serve as the likelihood of a transaction being\nincluded in the current block, and for determining the order in which\ntransactions are tried to see if they will be included.\n>\n> Use a target block size. Determine the target block size using; current\ntransaction pool size x ( 1 / (144 x n days ) ) = number of transactions to\nbe included in the current block. Broadcast the next target block size with\nthe current block when it is solved so that nodes know the next target\nblock size for the block that they are building on.\n>\n> The curves used for the priority of transactions would have to be\nappropriate. Perhaps a mathematician with experience in probability can\ndevelop the right formulae. My thinking is a steep curve. I suppose that\nthe probability of all transactions should probably account for a\nsufficient number of inclusions that the target block size is met although,\nit may not always be. As a suggestion, consider including some zero fee\ntransactions to pad, highest BTC value first?\n>\n> **Explanation of the operation of priority:**\n> > If transaction priority is, for example, a number between one (low) and\none-hundred (high) it can be directly understood as the percentage chance\nin one-hundred of a transaction being included in the block. Using\nprobability or likelihood infers that there is some function of random. If\nrandom (100) < transaction priority then the transaction is included.\n>\n> >To break it down further, if both the fee on a curve value and the time\nwaiting on a curve value are each a number between one and one-hundred, a\nrudimentary method may be to simply multiply those two numbers, to find the\npriority number. For example, a middle fee transaction waiting thirty days\n(if n = 60 days) may have a value of five for each part  (yes, just five,\nthe values are on a curve). When multiplied that will give a priority value\nof twenty-five, or,  a twenty-five percent chance at that moment of being\nincluded in the block; it will likely be included in one of the next four\nblocks, getting more likely each chance. If it is still not included then\nthe value of time waiting will be higher, making for more probability. A\nvery low fee transaction would have a value for the fee of one. It would\nnot be until near sixty-days that the particular low fee transaction has a\nhigh likelihood of being included in the block.\n>\n> I am not concerned with low (or high) transaction fees, the primary\nreason for addressing the issue is to ensure transactional reliability and\nscalability while having each transaction confirm in due time.\n>\n> ## Pros:\n> * Maximizes transaction reliability.\n> * Fully scalable.\n> * Maximizes possibility for consumer and business uptake.\n> * Maximizes total fees paid per block without reducing reliability;\nbecause of reliability, in time confidence and overall uptake are greater;\ntherefore, more transactions.\n> * Market determines fee paid for transaction priority.\n> * Fee recommendations work all the way out to 30 days or greater.\n> * Provides additional block entropy; greater security since there is less\nprobability of predicting the next block.\n>\n> ## Cons:\n> * Could initially lower total transaction fees per block.\n> * Must be first be programmed.\n>\n> ## Solution operation:\n> This is a simplistic view of the operation. The actual operation will\nneed to be determined in a spec for the programmer.\n>\n> 1. Determine the target block size for the current block.\n> 2. Assign a transaction priority to each transaction in the pool.\n> 3. Select transactions to include in the current block using probability\nin transaction priority order until the target block size is met.\n> 5. Solve block.\n> 6. Broadcast the next target block size with the current block when it is\nsolved.\n> 7. Block is received.\n> 8. Block verification process.\n> 9. Accept/reject block based on verification result.\n> 10. Repeat.\n>\n> ## Closing comments:\n> It may be possible to verify blocks conform to the proposal by showing\nthat the probability for all transactions included in the block\nstatistically conforms to a probability distribution curve, *if* the\nindividual transaction priority can be recreated. I am not that deep into\nthe mathematics; however, it may also be possible to use a similar method\nto do this just based on the fee, that statistically, the blocks conform to\na fee distribution. Any zero fee transactions would have to be ignored.\nThis solution needs a clever mathematician.\n>\n> I implore, at the very least, that we use some method that validates full\ntransaction reliability and enables scalability of block sizes. If not this\nproposal, an alternative.\n>\n> Regards,\n> Damian Williamson\n>\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/50d68c11/attachment-0001.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-19T07:48:37",
                "message_text_only": "Thank you for your constructive feedback. I now see that the proposal introduces a potential issue.\n\n\nIt is difficult to define then, what is a valid transaction? Clearly, my definition was insufficient.\n\n\nRegards,\n\nDamian Williamson\n\n\n________________________________\nFrom: Chris Riley <criley at gmail.com>\nSent: Monday, 18 December 2017 11:09 PM\nTo: Damian Williamson; Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\nRegarding \"problem\" #2 where you say \"How do we ensure that all valid transactions are eventually included in the blockchain?\":  I do not believe that all people would (a) agree this is a problem or (b) that we do want to *ENSURE* that *ALL* valid transactions are eventually included in the blockchain.  There are many *valid* transactions that oftentimes miners do not (and should not) wish to require be confirmed and included in the blockchain.  Spam transactions for example can be valid, but used to attack bitcoin by using no or low fee.  Any valid transaction MAY be included by a miner, but requiring it in some fashion at this point would open the network to other attack vectors.  Perhaps you meant it a different way.\n\n\nOn Fri, Dec 15, 2017 at 3:59 PM, Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>\n> There are really two separate problems to solve.\n>\n>\n> How does Bitcoin scale with fixed block size?\n> How do we ensure that all valid transactions are eventually included in the blockchain?\n>\n>\n> Those are the two issues that the proposal attempts to address. It makes sense to resolve these two problems together. Using the proposed system for variable block sizes would solve the first problem but there would still be a whole bunch of never confirming transactions. I am not sure how to reliably solve the second problem at scale without first solving the first.\n>\n>\n> >* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.\n>\n>\n> I do not suggest a consensus. Depending on which node solves a block the value for next block size will be different. The consensus would be that blocks will adhere to the next block size value transmitted with the current block. It is easy to verify that the consensus is being adhered to once in place.\n>\n> >* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.\n>\n> Not a necessary function, just an effect of using a probability-based distribution.\n>\n> >* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by \"priority\".  What are you going to do if a \"malicious\" miner decides to go after their profits and order by what makes them the most money. Add \"ordered by priority\" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.\n>\n> I entirely agree with your sentiment that Bitcoin must be incentive compatible. It is necessary.\n>\n> It is in only miners immediate interest to make the most profitable block from the available transaction pool. As with so many other things, it is necessary to partially ignore short-term gain for long-term benefit. It is in miners and everybody's long-term interest to have a reliable transaction service. A busy transaction service that confirms lots of transactions per hour will become more profitable as demand increases and more users are prepared to pay for priority. As it is there is currently no way to fully scale because of the transaction bandwidth limit and that is problematic. If all valid transactions must eventually confirm then there must be a way to resolve that problem.\n>\n> Bitcoin deliberately removes traditional scale by ensuring blocks take ten minutes on average to solve, an ingenious idea and, incentive compatible but, fixed block sizes leaves us with a problem to solve when we want to scale.\n>\n> >If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.\n>\n> I am confident that the math to verify blocks based on the proposal can be developed (and I think it will not be too complex for a mathematician with the relevant experience), however, I am nowhere near experienced enough with probability and statistical analysis to do it. Yes, if Bitcoin doesn't then it might make another great opportunity for an altcoin but I am not even nearly interested in promoting any altcoins.\n>\n>\n> If not the proposal that I have put forward, then, hopefully, someone can come up with a better solution. The important thing is that the issues are resolved.\n>\n>\n> Regards,\n>\n> Damian Williamson\n>\n>\n>\n> ________________________________\n> From: Rhavar <rhavar at protonmail.com<mailto:rhavar at protonmail.com>>\n> Sent: Saturday, 16 December 2017 3:38 AM\n> To: Damian Williamson\n> Cc: Bitcoin Protocol Discussion\n> Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n>\n> > I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?\n>\n> Unfortunately your proposal is really fundamentally broken, on a few levels. I think you might need to do a bit more research into how bitcoin works before coming up with such improvements =)\n>\n> But just some quick notes:\n>\n> * Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.\n>\n> * Increasing the entropy in a block to make it more unpredictable doesn't really make sense.\n>\n> * Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by \"priority\".  What are you going to do if a \"malicious\" miner decides to go after their profits and order by what makes them the most money. Add \"ordered by priority\" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.\n>\n> If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.\n>\n>\n>\n>\n> -Ryan\n>\n>\n> -------- Original Message --------\n> Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n> Local Time: December 15, 2017 3:42 AM\n> UTC Time: December 15, 2017 9:42 AM\n> From: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\n> To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>\n>\n>\n>\n> I should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?\n>\n> I suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.\n>\n> It has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.\n>\n>\n> If someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?\n>\n> Regards,\n> Damian Williamson\n>\n>\n> ________________________________\n>\n> From: bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org> <bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org>> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>\n> Sent: Friday, 8 December 2017 8:01 AM\n> To: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\n> Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n>\n>\n>\n> Good afternoon,\n>\n> The need for this proposal:\n>\n> We all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.\n>\n> I recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.\n>\n> I argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.\n>\n> Business cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.\n>\n> Under the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.\n>\n> Once there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.\n>\n> I also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.\n>\n> I do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.\n>\n> This great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.\n>\n> I have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.\n>\n> # BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n>\n> ## The problem:\n> Everybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.\n>\n> The current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.\n>\n> Current fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.\n>\n> Bitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.\n>\n> The possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.\n>\n> ## Solution summary:\n> Provide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.\n>\n> Use a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.\n>\n> The curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?\n>\n> **Explanation of the operation of priority:**\n> > If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.\n>\n> >To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.\n>\n> I am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.\n>\n> ## Pros:\n> * Maximizes transaction reliability.\n> * Fully scalable.\n> * Maximizes possibility for consumer and business uptake.\n> * Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.\n> * Market determines fee paid for transaction priority.\n> * Fee recommendations work all the way out to 30 days or greater.\n> * Provides additional block entropy; greater security since there is less probability of predicting the next block.\n>\n> ## Cons:\n> * Could initially lower total transaction fees per block.\n> * Must be first be programmed.\n>\n> ## Solution operation:\n> This is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.\n>\n> 1. Determine the target block size for the current block.\n> 2. Assign a transaction priority to each transaction in the pool.\n> 3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.\n> 5. Solve block.\n> 6. Broadcast the next target block size with the current block when it is solved.\n> 7. Block is received.\n> 8. Block verification process.\n> 9. Accept/reject block based on verification result.\n> 10. Repeat.\n>\n> ## Closing comments:\n> It may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.\n>\n> I implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.\n>\n> Regards,\n> Damian Williamson\n>\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171219/9ab11dee/attachment-0001.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-19T07:51:39",
                "message_text_only": "Thank you for your constructive feedback. I now see that the proposal introduces a potential issue.\n\n\n>Finally in terms of the broad goal, having block size based on the number of transactions is NOT something desirable in the first place, even if it did work. That\u2019s effectively the same as an infinite block size since anyone anywhere can create transactions in the mempool at no cost.\n\n\nDo you have any critical suggestion as to how transaction bandwidth limit could be addressed, it will eventually become an issue if nothing is changed regardless of how high fees go?\n\n\nRegards,\n\nDamian Williamson\n\n\n\n________________________________\nFrom: Mark Friedenbach <mark at friedenbach.org>\nSent: Tuesday, 19 December 2017 3:08 AM\nTo: Damian Williamson\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\nDamian, you seem to be misunderstanding that either\n\n(1) the strong form of your proposal requires validating the commitment to the mempool properties, in which case the mempool becomes consensus critical (an impossible requirement); or\n\n(2) in the weak form where the current block is dependent on the commitment in the last block only it is becomes a miner-selected field they can freely parameterize with no repercussions for setting values totally independent of the actual mempool.\n\nIf you want to make the block size dependent on the properties of the mempool in a consensus critical way, flex cap achieves this. If you want to make the contents or properties of the mempool known to well-connected nodes, weak blocks achieves that. But you can\u2019t stick the mempool in consensus because it fundamentally is not something the nodes have consensus over. That\u2019s a chicken-and-the-egg assumption.\n\nFinally in terms of the broad goal, having block size based on the number of transactions is NOT something desirable in the first place, even if it did work. That\u2019s effectively the same as an infinite block size since anyone anywhere can create transactions in the mempool at no cost.\n\nOn Dec 16, 2017, at 8:14 PM, Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n\nI do not know why people make the leap that the proposal requires a consensus on the transaction pool. It does not.\n\nIt may be helpful to have the discussion from the previous thread linked here.\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015370.html\n\nWhere I speak of validating that a block conforms to the broadcast next block size, I do not propose validating the number broadcast for the next block size itself, only that the next generated block is that size.\n\nRegards,\nDamian Williamson\n\n\n________________________________\nFrom: Damian Williamson <willtech at live.com.au<mailto:willtech at live.com.au>>\nSent: Saturday, 16 December 2017 7:59 AM\nTo: Rhavar\nCc: Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\nThere are really two separate problems to solve.\n\n\n  1.  How does Bitcoin scale with fixed block size?\n  2.  How do we ensure that all valid transactions are eventually included in the blockchain?\n\nThose are the two issues that the proposal attempts to address. It makes sense to resolve these two problems together. Using the proposed system for variable block sizes would solve the first problem but there would still be a whole bunch of never confirming transactions. I am not sure how to reliably solve the second problem at scale without first solving the first.\n\n>* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.\n\nI do not suggest a consensus. Depending on which node solves a block the value for next block size will be different. The consensus would be that blocks will adhere to the next block size value transmitted with the current block. It is easy to verify that the consensus is being adhered to once in place.\n\n>* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.\n\nNot a necessary function, just an effect of using a probability-based distribution.\n\n>* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by \"priority\".  What are you going to do if a \"malicious\" miner decides to go after their profits and order by what makes them the most money. Add \"ordered by priority\" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.\n\nI entirely agree with your sentiment that Bitcoin must be incentive compatible. It is necessary.\n\nIt is in only miners immediate interest to make the most profitable block from the available transaction pool. As with so many other things, it is necessary to partially ignore short-term gain for long-term benefit. It is in miners and everybody's long-term interest to have a reliable transaction service. A busy transaction service that confirms lots of transactions per hour will become more profitable as demand increases and more users are prepared to pay for priority. As it is there is currently no way to fully scale because of the transaction bandwidth limit and that is problematic. If all valid transactions must eventually confirm then there must be a way to resolve that problem.\n\nBitcoin deliberately removes traditional scale by ensuring blocks take ten minutes on average to solve, an ingenious idea and, incentive compatible but, fixed block sizes leaves us with a problem to solve when we want to scale.\n\n>If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.\n\nI am confident that the math to verify blocks based on the proposal can be developed (and I think it will not be too complex for a mathematician with the relevant experience), however, I am nowhere near experienced enough with probability and statistical analysis to do it. Yes, if Bitcoin doesn't then it might make another great opportunity for an altcoin but I am not even nearly interested in promoting any altcoins.\n\nIf not the proposal that I have put forward, then, hopefully, someone can come up with a better solution. The important thing is that the issues are resolved.\n\nRegards,\nDamian Williamson\n\n\n________________________________\nFrom: Rhavar <rhavar at protonmail.com<mailto:rhavar at protonmail.com>>\nSent: Saturday, 16 December 2017 3:38 AM\nTo: Damian Williamson\nCc: Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n> I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?\n\nUnfortunately your proposal is really fundamentally broken, on a few levels. I think you might need to do a bit more research into how bitcoin works before coming up with such improvements =)\n\nBut just some quick notes:\n\n* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.\n\n* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.\n\n* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by \"priority\".  What are you going to do if a \"malicious\" miner decides to go after their profits and order by what makes them the most money. Add \"ordered by priority\" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.\n\nIf you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.\n\n\n\n\n-Ryan\n\n\n-------- Original Message --------\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\nLocal Time: December 15, 2017 3:42 AM\nUTC Time: December 15, 2017 9:42 AM\nFrom: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nTo: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>\n\n\n\nI should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?\n\nI suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.\n\nIt has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.\n\n\nIf someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?\n\nRegards,\nDamian Williamson\n\n\n________________________________\n\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org> <bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org>> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>\nSent: Friday, 8 December 2017 8:01 AM\nTo: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n\nGood afternoon,\n\nThe need for this proposal:\n\nWe all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.\n\nI recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.\n\nI argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.\n\nBusiness cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.\n\nUnder the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.\n\nOnce there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.\n\nI also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.\n\nI do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.\n\nThis great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.\n\nI have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.\n\n# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n## The problem:\nEverybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.\n\nThe current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.\n\nCurrent fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.\n\nBitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.\n\nThe possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.\n\n## Solution summary:\nProvide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.\n\nUse a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.\n\nThe curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?\n\n**Explanation of the operation of priority:**\n> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.\n\n>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.\n\nI am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.\n\n## Pros:\n* Maximizes transaction reliability.\n* Fully scalable.\n* Maximizes possibility for consumer and business uptake.\n* Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.\n* Market determines fee paid for transaction priority.\n* Fee recommendations work all the way out to 30 days or greater.\n* Provides additional block entropy; greater security since there is less probability of predicting the next block.\n\n## Cons:\n* Could initially lower total transaction fees per block.\n* Must be first be programmed.\n\n## Solution operation:\nThis is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.\n\n1. Determine the target block size for the current block.\n2. Assign a transaction priority to each transaction in the pool.\n3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.\n5. Solve block.\n6. Broadcast the next target block size with the current block when it is solved.\n7. Block is received.\n8. Block verification process.\n9. Accept/reject block based on verification result.\n10. Repeat.\n\n## Closing comments:\nIt may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.\n\nI implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.\n\nRegards,\nDamian Williamson\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171219/f24be6fb/attachment-0001.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-22T06:22:40",
                "message_text_only": "If the cash value of Bitcoin was high enough and zero fee transactions were never accepted and not counted when calculating the transaction pool size then I do not think it would be such an issue. Why is it even possible to create zero fee transactions?\n\n\nRegards,\n\nDamian Williamson\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Tuesday, 19 December 2017 6:51 PM\nTo: Mark Friedenbach\nCc: bitcoin-dev at lists.linuxfoundation.org\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n\nThank you for your constructive feedback. I now see that the proposal introduces a potential issue.\n\n\n>Finally in terms of the broad goal, having block size based on the number of transactions is NOT something desirable in the first place, even if it did work. That\u2019s effectively the same as an infinite block size since anyone anywhere can create transactions in the mempool at no cost.\n\n\nDo you have any critical suggestion as to how transaction bandwidth limit could be addressed, it will eventually become an issue if nothing is changed regardless of how high fees go?\n\n\nRegards,\n\nDamian Williamson\n\n\n\n________________________________\nFrom: Mark Friedenbach <mark at friedenbach.org>\nSent: Tuesday, 19 December 2017 3:08 AM\nTo: Damian Williamson\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\nDamian, you seem to be misunderstanding that either\n\n(1) the strong form of your proposal requires validating the commitment to the mempool properties, in which case the mempool becomes consensus critical (an impossible requirement); or\n\n(2) in the weak form where the current block is dependent on the commitment in the last block only it is becomes a miner-selected field they can freely parameterize with no repercussions for setting values totally independent of the actual mempool.\n\nIf you want to make the block size dependent on the properties of the mempool in a consensus critical way, flex cap achieves this. If you want to make the contents or properties of the mempool known to well-connected nodes, weak blocks achieves that. But you can\u2019t stick the mempool in consensus because it fundamentally is not something the nodes have consensus over. That\u2019s a chicken-and-the-egg assumption.\n\nFinally in terms of the broad goal, having block size based on the number of transactions is NOT something desirable in the first place, even if it did work. That\u2019s effectively the same as an infinite block size since anyone anywhere can create transactions in the mempool at no cost.\n\nOn Dec 16, 2017, at 8:14 PM, Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n\nI do not know why people make the leap that the proposal requires a consensus on the transaction pool. It does not.\n\nIt may be helpful to have the discussion from the previous thread linked here.\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015370.html\n\nWhere I speak of validating that a block conforms to the broadcast next block size, I do not propose validating the number broadcast for the next block size itself, only that the next generated block is that size.\n\nRegards,\nDamian Williamson\n\n\n________________________________\nFrom: Damian Williamson <willtech at live.com.au<mailto:willtech at live.com.au>>\nSent: Saturday, 16 December 2017 7:59 AM\nTo: Rhavar\nCc: Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\nThere are really two separate problems to solve.\n\n\n  1.  How does Bitcoin scale with fixed block size?\n  2.  How do we ensure that all valid transactions are eventually included in the blockchain?\n\nThose are the two issues that the proposal attempts to address. It makes sense to resolve these two problems together. Using the proposed system for variable block sizes would solve the first problem but there would still be a whole bunch of never confirming transactions. I am not sure how to reliably solve the second problem at scale without first solving the first.\n\n>* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.\n\nI do not suggest a consensus. Depending on which node solves a block the value for next block size will be different. The consensus would be that blocks will adhere to the next block size value transmitted with the current block. It is easy to verify that the consensus is being adhered to once in place.\n\n>* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.\n\nNot a necessary function, just an effect of using a probability-based distribution.\n\n>* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by \"priority\".  What are you going to do if a \"malicious\" miner decides to go after their profits and order by what makes them the most money. Add \"ordered by priority\" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.\n\nI entirely agree with your sentiment that Bitcoin must be incentive compatible. It is necessary.\n\nIt is in only miners immediate interest to make the most profitable block from the available transaction pool. As with so many other things, it is necessary to partially ignore short-term gain for long-term benefit. It is in miners and everybody's long-term interest to have a reliable transaction service. A busy transaction service that confirms lots of transactions per hour will become more profitable as demand increases and more users are prepared to pay for priority. As it is there is currently no way to fully scale because of the transaction bandwidth limit and that is problematic. If all valid transactions must eventually confirm then there must be a way to resolve that problem.\n\nBitcoin deliberately removes traditional scale by ensuring blocks take ten minutes on average to solve, an ingenious idea and, incentive compatible but, fixed block sizes leaves us with a problem to solve when we want to scale.\n\n>If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.\n\nI am confident that the math to verify blocks based on the proposal can be developed (and I think it will not be too complex for a mathematician with the relevant experience), however, I am nowhere near experienced enough with probability and statistical analysis to do it. Yes, if Bitcoin doesn't then it might make another great opportunity for an altcoin but I am not even nearly interested in promoting any altcoins.\n\nIf not the proposal that I have put forward, then, hopefully, someone can come up with a better solution. The important thing is that the issues are resolved.\n\nRegards,\nDamian Williamson\n\n\n________________________________\nFrom: Rhavar <rhavar at protonmail.com<mailto:rhavar at protonmail.com>>\nSent: Saturday, 16 December 2017 3:38 AM\nTo: Damian Williamson\nCc: Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n> I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?\n\nUnfortunately your proposal is really fundamentally broken, on a few levels. I think you might need to do a bit more research into how bitcoin works before coming up with such improvements =)\n\nBut just some quick notes:\n\n* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.\n\n* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.\n\n* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by \"priority\".  What are you going to do if a \"malicious\" miner decides to go after their profits and order by what makes them the most money. Add \"ordered by priority\" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.\n\nIf you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.\n\n\n\n\n-Ryan\n\n\n-------- Original Message --------\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\nLocal Time: December 15, 2017 3:42 AM\nUTC Time: December 15, 2017 9:42 AM\nFrom: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nTo: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>\n\n\n\nI should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?\n\nI suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.\n\nIt has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.\n\n\nIf someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?\n\nRegards,\nDamian Williamson\n\n\n________________________________\n\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org> <bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org>> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>\nSent: Friday, 8 December 2017 8:01 AM\nTo: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n\nGood afternoon,\n\nThe need for this proposal:\n\nWe all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.\n\nI recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.\n\nI argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.\n\nBusiness cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.\n\nUnder the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.\n\nOnce there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.\n\nI also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.\n\nI do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.\n\nThis great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.\n\nI have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.\n\n# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n## The problem:\nEverybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.\n\nThe current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.\n\nCurrent fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.\n\nBitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.\n\nThe possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.\n\n## Solution summary:\nProvide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.\n\nUse a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.\n\nThe curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?\n\n**Explanation of the operation of priority:**\n> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.\n\n>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.\n\nI am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.\n\n## Pros:\n* Maximizes transaction reliability.\n* Fully scalable.\n* Maximizes possibility for consumer and business uptake.\n* Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.\n* Market determines fee paid for transaction priority.\n* Fee recommendations work all the way out to 30 days or greater.\n* Provides additional block entropy; greater security since there is less probability of predicting the next block.\n\n## Cons:\n* Could initially lower total transaction fees per block.\n* Must be first be programmed.\n\n## Solution operation:\nThis is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.\n\n1. Determine the target block size for the current block.\n2. Assign a transaction priority to each transaction in the pool.\n3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.\n5. Solve block.\n6. Broadcast the next target block size with the current block when it is solved.\n7. Block is received.\n8. Block verification process.\n9. Accept/reject block based on verification result.\n10. Repeat.\n\n## Closing comments:\nIt may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.\n\nI implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.\n\nRegards,\nDamian Williamson\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171222/5a0d006a/attachment-0001.html>"
            },
            {
                "author": "Spartacus Rex",
                "date": "2017-12-22T18:07:49",
                "message_text_only": "Hi Damian,\n\nThought I'd chip in.  This is a hard fork scenario. This system has flaws,\nthey all do.\n\nIf you had a fixed fee per block, so that every txn in that block paid the\nsame fee, that might make it easier to include all txns eventually, as you\nenvisage.\n\nThe fee could be calculated as the average of the amount txns are prepared\nto pay in the last 1000 blocks.\n\nA txn would say ' I'll pay up to X bitcoins ' and as long as that is more\nthan the value required for the block your txn can be added. This is to\nensure you don't pay more than you are willing.  It also ensures that\nputting an enormous fee will not ensure your txn is processed quickly..\n\nCalculating what the outputs are given a variable fee needs a new mechanism\nall of it's own, but I'm sure it's possible.\n\nThe simple fact is that there is currently no known system that works as\nwell as the current system..\n\nBut there are other systems.\n\n\nOn Dec 22, 2017 15:09, \"Damian Williamson via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> If the cash value of Bitcoin was high enough and zero fee transactions\n> were never accepted and not counted when calculating the transaction pool\n> size then I do not think it would be such an issue. Why is it even possible\n> to create zero fee transactions?\n>\n>\n> Regards,\n>\n> Damian Williamson\n>\n> ------------------------------\n> *From:* bitcoin-dev-bounces at lists.linuxfoundation.org <\n> bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian\n> Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n> *Sent:* Tuesday, 19 December 2017 6:51 PM\n> *To:* Mark Friedenbach\n> *Cc:* bitcoin-dev at lists.linuxfoundation.org\n> *Subject:* [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use\n> Transaction Priority For Ordering Transactions In Blocks\n>\n>\n> Thank you for your constructive feedback. I now see that the proposal\n> introduces a potential issue.\n>\n>\n> >Finally in terms of the broad goal, having block size based on the number\n> of transactions is NOT something desirable in the first place, even if it\n> did work. That\u2019s effectively the same as an infinite block size since\n> anyone anywhere can create transactions in the mempool at no cost.\n>\n>\n> Do you have any critical suggestion as to how transaction bandwidth limit\n> could be addressed, it will eventually become an issue if nothing is\n> changed regardless of how high fees go?\n>\n>\n> Regards,\n> Damian Williamson\n>\n>\n>\n> ------------------------------\n> *From:* Mark Friedenbach <mark at friedenbach.org>\n> *Sent:* Tuesday, 19 December 2017 3:08 AM\n> *To:* Damian Williamson\n> *Subject:* Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use\n> Transaction Priority For Ordering Transactions In Blocks\n>\n> Damian, you seem to be misunderstanding that either\n>\n> (1) the strong form of your proposal requires validating the commitment to\n> the mempool properties, in which case the mempool becomes consensus\n> critical (an impossible requirement); or\n>\n> (2) in the weak form where the current block is dependent on the\n> commitment in the last block only it is becomes a miner-selected field they\n> can freely parameterize with no repercussions for setting values totally\n> independent of the actual mempool.\n>\n> If you want to make the block size dependent on the properties of the\n> mempool in a consensus critical way, flex cap achieves this. If you want to\n> make the contents or properties of the mempool known to well-connected\n> nodes, weak blocks achieves that. But you can\u2019t stick the mempool in\n> consensus because it fundamentally is not something the nodes have\n> consensus over. That\u2019s a chicken-and-the-egg assumption.\n>\n> Finally in terms of the broad goal, having block size based on the number\n> of transactions is NOT something desirable in the first place, even if it\n> did work. That\u2019s effectively the same as an infinite block size since\n> anyone anywhere can create transactions in the mempool at no cost.\n>\n> On Dec 16, 2017, at 8:14 PM, Damian Williamson via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> I do not know why people make the leap that the proposal requires a\n> consensus on the transaction pool. It does not.\n>\n> It may be helpful to have the discussion from the previous thread linked\n> here.\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/\n> 2017-December/015370.html\n>\n> Where I speak of validating that a block conforms to the broadcast next\n> block size, I do not propose validating the number broadcast for the next\n> block size itself, only that the next generated block is that size.\n>\n> Regards,\n> Damian Williamson\n>\n>\n> ------------------------------\n> *From:* Damian Williamson <willtech at live.com.au>\n> *Sent:* Saturday, 16 December 2017 7:59 AM\n> *To:* Rhavar\n> *Cc:* Bitcoin Protocol Discussion\n> *Subject:* Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use\n> Transaction Priority For Ordering Transactions In Blocks\n>\n> There are really two separate problems to solve.\n>\n>\n>    1. How does Bitcoin scale with fixed block size?\n>    2. How do we ensure that all valid transactions are eventually\n>    included in the blockchain?\n>\n>\n> Those are the two issues that the proposal attempts to address. It makes\n> sense to resolve these two problems together. Using the proposed system for\n> variable block sizes would solve the first problem but there would still be\n> a whole bunch of never confirming transactions. I am not sure how to\n> reliably solve the second problem at scale without first solving the first.\n>\n> >* Every node has a (potentially) different mempool, you can't use it to\n> decide consensus values like the max block size.\n>\n> I do not suggest a consensus. Depending on which node solves a block the\n> value for next block size will be different. The consensus would be that\n> blocks will adhere to the next block size value transmitted with the\n> current block. It is easy to verify that the consensus is being adhered to\n> once in place.\n>\n> >* Increasing the entropy in a block to make it more unpredictable doesn't\n> really make sense.\n>\n> Not a necessary function, just an effect of using a probability-based\n> distribution.\n>\n> >* Bitcoin should be roughly incentive compatible. Your proposal explicits\n> asks miners to ignore their best interests, and confirm transactions by\n> \"priority\".  What are you going to do if a \"malicious\" miner decides to go\n> after their profits and order by what makes them the most money. Add\n> \"ordered by priority\" as a consensus requirement? And even if you miners\n> can still sort their mempool by fee, and then order the top 1MB by priority.\n>\n> I entirely agree with your sentiment that Bitcoin must be incentive\n> compatible. It is necessary.\n>\n> It is in only miners immediate interest to make the most profitable block\n> from the available transaction pool. As with so many other things, it is\n> necessary to partially ignore short-term gain for long-term benefit. It is\n> in miners and everybody's long-term interest to have a reliable transaction\n> service. A busy transaction service that confirms lots of transactions per\n> hour will become more profitable as demand increases and more users are\n> prepared to pay for priority. As it is there is currently no way to fully\n> scale because of the transaction bandwidth limit and that is problematic.\n> If all valid transactions must eventually confirm then there must be a way\n> to resolve that problem.\n>\n> Bitcoin deliberately removes traditional scale by ensuring blocks take ten\n> minutes on average to solve, an ingenious idea and, incentive compatible\n> but, fixed block sizes leaves us with a problem to solve when we want to\n> scale.\n>\n> >If you could find a good solution that would allow you to know if miners\n> were following your rule or not (and thus ignore it if it doesn't) then you\n> wouldn't even need bitcoin in the first place.\n>\n> I am confident that the math to verify blocks based on the proposal can be\n> developed (and I think it will not be too complex for a mathematician with\n> the relevant experience), however, I am nowhere near experienced enough\n> with probability and statistical analysis to do it. Yes, if Bitcoin doesn't\n> then it might make another great opportunity for an altcoin but I am not\n> even nearly interested in promoting any altcoins.\n>\n>\n> If not the proposal that I have put forward, then, hopefully, someone can\n> come up with a better solution. The important thing is that the issues are\n> resolved.\n>\n> Regards,\n> Damian Williamson\n>\n>\n> ------------------------------\n> *From:* Rhavar <rhavar at protonmail.com>\n> *Sent:* Saturday, 16 December 2017 3:38 AM\n> *To:* Damian Williamson\n> *Cc:* Bitcoin Protocol Discussion\n> *Subject:* Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use\n> Transaction Priority For Ordering Transactions In Blocks\n>\n> > I understand that there would be technical issues to resolve in\n> implementation, but, are there no fundamental errors?\n>\n> Unfortunately your proposal is really fundamentally broken, on a few\n> levels. I think you might need to do a bit more research into how bitcoin\n> works before coming up with such improvements =)\n>\n> But just some quick notes:\n>\n> * Every node has a (potentially) different mempool, you can't use it to\n> decide consensus values like the max block size.\n>\n> * Increasing the entropy in a block to make it more unpredictable doesn't\n> really make sense.\n>\n> * Bitcoin should be roughly incentive compatible. Your proposal explicits\n> asks miners to ignore their best interests, and confirm transactions by\n> \"priority\".  What are you going to do if a \"malicious\" miner decides to go\n> after their profits and order by what makes them the most money. Add\n> \"ordered by priority\" as a consensus requirement? And even if you miners\n> can still sort their mempool by fee, and then order the top 1MB by priority.\n>\n> If you could find a good solution that would allow you to know if miners\n> were following your rule or not (and thus ignore it if it doesn't) then you\n> wouldn't even need bitcoin in the first place.\n>\n>\n>\n>\n> -Ryan\n>\n>\n> -------- Original Message --------\n> Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction\n> Priority For Ordering Transactions In Blocks\n> Local Time: December 15, 2017 3:42 AM\n> UTC Time: December 15, 2017 9:42 AM\n> From: bitcoin-dev at lists.linuxfoundation.org\n> To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\n>\n>\n>\n> I should not take it that the lack of critical feedback to this revised\n> proposal is a glowing endorsement. I understand that there would be\n> technical issues to resolve in implementation, but, are there no\n> fundamental errors?\n>\n> I suppose that it if is difficult to determine how long a transaction has\n> been waiting in the pool then, each node could simply keep track of when a\n> transaction was first seen. This may have implications for a verify\n> routine, however, for example, if a node was offline, how should it\n> differentiate how long each transaction was waiting in that case? If a node\n> was restarted daily would it always think that all transactions had been\n> waiting in the pool less than one day If each node keeps the current\n> transaction pool in a file and updates it, as transactions are included in\n> blocks and, as new transactions appear in the pool, then that would go some\n> way to alleviate the issue, apart from entirely new nodes. There should be\n> no reason the contents of a transaction pool files cannot be shared without\n> agreement as to the transaction pool between nodes, just as nodes\n> transmit new transactions freely.\n>\n> It has been questioned why miners could not cheat. For the question of how\n> many transactions to include in a block, I say it is a standoff and miners\n> will conform to the proposal, not wanting to leave transactions with valid\n> fees standing, and, not wanting to shrink the transaction pool. In any\n> case, if miners shrink the transaction pool then I am not immediately\n> concerned since it provides a more efficient service. For the question of\n> including transactions according to the proposal, I say if it is possible\n> to keep track of how long transactions are waiting in the pool so that they\n> can be included on a probability curve then it is possible to verify that\n> blocks conform to the proposal, since the input is a probability, the\n> output should conform to a probability curve.\n>\n>\n> If someone has the necessary skill, would anyone be willing to develop the\n> math necessary for the proposal?\n>\n> Regards,\n> Damian Williamson\n>\n>\n> ------------------------------\n>\n> *From:* bitcoin-dev-bounces at lists.linuxfoundation.org <bit\n> coin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian\n> Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n> *Sent:* Friday, 8 December 2017 8:01 AM\n> *To:* bitcoin-dev at lists.linuxfoundation.org\n> *Subject:* [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use\n> Transaction Priority For Ordering Transactions In Blocks\n>\n>\n> Good afternoon,\n>\n> The need for this proposal:\n>\n> We all must learn to admit that transaction bandwidth is still lurking as\n> a serious issue for the operation, reliability, safety, consumer\n> acceptance, uptake and, for the value of Bitcoin.\n>\n> I recently sent a payment which was not urgent so; I chose three-day\n> target confirmation from the fee recommendation. That transaction has still\n> not confirmed after now more than six days - even waiting twice as long\n> seems quite reasonable to me. That transaction is a valid transaction; it\n> is not rubbish, junk or, spam. Under the current model with transaction\n> bandwidth limitation, the longer a transaction waits, the less likely it is\n> ever to confirm due to rising transaction numbers and being pushed back by\n> transactions with rising fees.\n>\n> I argue that no transactions are rubbish or junk, only some zero fee\n> transactions might be spam. Having an ever-increasing number of valid\n> transactions that do not confirm as more new transactions with higher fees\n> are created is the opposite of operating a robust, reliable transaction\n> system.\n>\n> Business cannot operate with a model where transactions may or may not\n> confirm. Even a business choosing a modest fee has no guarantee that their\n> valid transaction will not be shuffled down by new transactions to the\n> realm of never confirming after it is created. Consumers also will not\n> accept this model as Bitcoin expands. If Bitcoin cannot be a reliable\n> payment system for confirmed transactions then consumers, by and large,\n> will simply not accept the model once they understand. Bitcoin will be a\n> dirty payment system, and this will kill the value of Bitcoin.\n>\n> Under the current system, a minority of transactions will eventually be\n> the lucky few who have fees high enough to escape being pushed down the\n> list.\n>\n> Once there are more than x transactions (transaction bandwidth limit)\n> every ten minutes, only those choosing twenty-minute confirmation (2\n> blocks) will have initially at most a fifty percent chance of ever having\n> their payment confirm. Presently, not even using fee recommendations can\n> ensure a sufficiently high fee is paid to ensure transaction confirmation.\n>\n> I also argue that the current auction model for limited transaction\n> bandwidth is wrong, is not suitable for a reliable transaction system and,\n> is wrong for Bitcoin. All transactions must confirm in due time. Currently,\n> Bitcoin is not a safe way to send payments.\n>\n> I do not believe that consumers and business are against paying fees, even\n> high fees. What is required is operational reliability.\n>\n> This great issue needs to be resolved for the safety and reliability of\n> Bitcoin. The time to resolve issues in commerce is before they become great\n> big issues. The time to resolve this issue is now. We must have the\n> foresight to identify and resolve problems before they trip us over.\n> Simply doubling block sizes every so often is reactionary and is not a\n> reliable permanent solution. I have written a BIP proposal for a technical\n> solution but, need your help to write it up to an acceptable standard to be\n> a full BIP.\n>\n> I have formatted the following with markdown which is human readable so, I\n> hope nobody minds. I have done as much with this proposal as I feel that I\n> am able so far but continue to take your feedback.\n>\n> # BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering\n> Transactions In Blocks\n>\n> ## The problem:\n> Everybody wants value. Miners want to maximize revenue from fees (and we\n> presume, to minimize block size). Consumers need transaction reliability\n> and, (we presume) want low fees.\n>\n> The current transaction bandwidth limit is a limiting factor for both. As\n> the operational safety of transactions is limited, so is consumer\n> confidence as they realize the issue and, accordingly, uptake is limited.\n> Fees are artificially inflated due to bandwidth limitations while failing\n> to provide a full confirmation service for all transactions.\n>\n> Current fee recommendations provide no satisfaction for transaction\n> reliability and, as Bitcoin scales, this will worsen.\n>\n> Bitcoin must be a fully scalable and reliable service, providing full\n> transaction confirmation for every valid transaction.\n>\n> The possibility to send a transaction with a fee lower than one that is\n> acceptable to allow eventual transaction confirmation should be removed\n> from the protocol and also from the user interface.\n>\n> ## Solution summary:\n> Provide each transaction with an individual transaction priority each time\n> before choosing transactions to include in the current block, the priority\n> being a function of the fee paid (on a curve), and the time waiting in the\n> transaction pool (also on a curve) out to n days (n=60 ?). The transaction\n> priority to serve as the likelihood of a transaction being included in the\n> current block, and for determining the order in which transactions are\n> tried to see if they will be included.\n>\n> Use a target block size. Determine the target block size using; current\n> transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to\n> be included in the current block. Broadcast the next target block size with\n> the current block when it is solved so that nodes know the next target\n> block size for the block that they are building on.\n>\n> The curves used for the priority of transactions would have to be\n> appropriate. Perhaps a mathematician with experience in probability can\n> develop the right formulae. My thinking is a steep curve. I suppose that\n> the probability of all transactions should probably account for a\n> sufficient number of inclusions that the target block size is met although,\n> it may not always be. As a suggestion, consider including some zero fee\n> transactions to pad, highest BTC value first?\n>\n> **Explanation of the operation of priority:**\n> > If transaction priority is, for example, a number between one (low) and\n> one-hundred (high) it can be directly understood as the percentage chance\n> in one-hundred of a transaction being included in the block. Using\n> probability or likelihood infers that there is some function of random. If\n> random (100) < transaction priority then the transaction is included.\n>\n> >To break it down further, if both the fee on a curve value and the time\n> waiting on a curve value are each a number between one and one-hundred, a\n> rudimentary method may be to simply multiply those two numbers, to find the\n> priority number. For example, a middle fee transaction waiting thirty days\n> (if n = 60 days) may have a value of five for each part  (yes, just five,\n> the values are on a curve). When multiplied that will give a priority value\n> of twenty-five, or,  a twenty-five percent chance at that moment of being\n> included in the block; it will likely be included in one of the next four\n> blocks, getting more likely each chance. If it is still not included then\n> the value of time waiting will be higher, making for more probability. A\n> very low fee transaction would have a value for the fee of one. It would\n> not be until near sixty-days that the particular low fee transaction has a\n> high likelihood of being included in the block.\n>\n> I am not concerned with low (or high) transaction fees, the primary reason\n> for addressing the issue is to ensure transactional reliability and\n> scalability while having each transaction confirm in due time.\n>\n> ## Pros:\n> * Maximizes transaction reliability.\n> * Fully scalable.\n> * Maximizes possibility for consumer and business uptake.\n> * Maximizes total fees paid per block without reducing reliability;\n> because of reliability, in time confidence and overall uptake are greater;\n> therefore, more transactions.\n> * Market determines fee paid for transaction priority.\n> * Fee recommendations work all the way out to 30 days or greater.\n> * Provides additional block entropy; greater security since there is less\n> probability of predicting the next block.\n>\n> ## Cons:\n> * Could initially lower total transaction fees per block.\n> * Must be first be programmed.\n>\n> ## Solution operation:\n> This is a simplistic view of the operation. The actual operation will need\n> to be determined in a spec for the programmer.\n>\n> 1. Determine the target block size for the current block.\n> 2. Assign a transaction priority to each transaction in the pool.\n> 3. Select transactions to include in the current block using probability\n> in transaction priority order until the target block size is met.\n> 5. Solve block.\n> 6. Broadcast the next target block size with the current block when it is\n> solved.\n> 7. Block is received.\n> 8. Block verification process.\n> 9. Accept/reject block based on verification result.\n> 10. Repeat.\n>\n> ## Closing comments:\n> It may be possible to verify blocks conform to the proposal by showing\n> that the probability for all transactions included in the block\n> statistically conforms to a probability distribution curve, *if* the\n> individual transaction priority can be recreated. I am not that deep into\n> the mathematics; however, it may also be possible to use a similar method\n> to do this just based on the fee, that statistically, the blocks conform to\n> a fee distribution. Any zero fee transactions would have to be ignored.\n> This solution needs a clever mathematician.\n>\n> I implore, at the very least, that we use some method that validates full\n> transaction reliability and enables scalability of block sizes. If not this\n> proposal, an alternative.\n>\n> Regards,\n> Damian Williamson\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171222/01401d28/attachment-0001.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-24T03:44:26",
                "message_text_only": ">.. This system has flaws, they all do.\n\n\n>The simple fact is that there is currently no known system that works as well as the current system..\n\n\nAlright, but, we seem to agree, the current system also has flaws. The transaction bandwidth limit is a serious issue for transactional reliability.\n\n\nWhat you have proposed is interesting but seems to do nothing for the issue of transaction bandwidth, which seems to be approaching its threshold:\n\nhttps://bitinfocharts.com/comparison/bitcoin-transactions.html\n\n\nRegards,\n\nDamian Williamson\n\n________________________________\nFrom: Spartacus Rex <spartacusrex99 at gmail.com>\nSent: Saturday, 23 December 2017 5:07:49 AM\nTo: Damian Williamson; Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\nHi Damian,\n\nThought I'd chip in.  This is a hard fork scenario. This system has flaws, they all do.\n\nIf you had a fixed fee per block, so that every txn in that block paid the same fee, that might make it easier to include all txns eventually, as you envisage.\n\nThe fee could be calculated as the average of the amount txns are prepared to pay in the last 1000 blocks.\n\nA txn would say ' I'll pay up to X bitcoins ' and as long as that is more than the value required for the block your txn can be added. This is to ensure you don't pay more than you are willing.  It also ensures that putting an enormous fee will not ensure your txn is processed quickly..\n\nCalculating what the outputs are given a variable fee needs a new mechanism all of it's own, but I'm sure it's possible.\n\nThe simple fact is that there is currently no known system that works as well as the current system..\n\nBut there are other systems.\n\n\nOn Dec 22, 2017 15:09, \"Damian Williamson via bitcoin-dev\" <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n\nIf the cash value of Bitcoin was high enough and zero fee transactions were never accepted and not counted when calculating the transaction pool size then I do not think it would be such an issue. Why is it even possible to create zero fee transactions?\n\n\nRegards,\n\nDamian Williamson\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org> <bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org>> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>\nSent: Tuesday, 19 December 2017 6:51 PM\nTo: Mark Friedenbach\nCc: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n\nThank you for your constructive feedback. I now see that the proposal introduces a potential issue.\n\n\n>Finally in terms of the broad goal, having block size based on the number of transactions is NOT something desirable in the first place, even if it did work. That\u2019s effectively the same as an infinite block size since anyone anywhere can create transactions in the mempool at no cost.\n\n\nDo you have any critical suggestion as to how transaction bandwidth limit could be addressed, it will eventually become an issue if nothing is changed regardless of how high fees go?\n\n\nRegards,\n\nDamian Williamson\n\n\n\n________________________________\nFrom: Mark Friedenbach <mark at friedenbach.org<mailto:mark at friedenbach.org>>\nSent: Tuesday, 19 December 2017 3:08 AM\nTo: Damian Williamson\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\nDamian, you seem to be misunderstanding that either\n\n(1) the strong form of your proposal requires validating the commitment to the mempool properties, in which case the mempool becomes consensus critical (an impossible requirement); or\n\n(2) in the weak form where the current block is dependent on the commitment in the last block only it is becomes a miner-selected field they can freely parameterize with no repercussions for setting values totally independent of the actual mempool.\n\nIf you want to make the block size dependent on the properties of the mempool in a consensus critical way, flex cap achieves this. If you want to make the contents or properties of the mempool known to well-connected nodes, weak blocks achieves that. But you can\u2019t stick the mempool in consensus because it fundamentally is not something the nodes have consensus over. That\u2019s a chicken-and-the-egg assumption.\n\nFinally in terms of the broad goal, having block size based on the number of transactions is NOT something desirable in the first place, even if it did work. That\u2019s effectively the same as an infinite block size since anyone anywhere can create transactions in the mempool at no cost.\n\nOn Dec 16, 2017, at 8:14 PM, Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n\nI do not know why people make the leap that the proposal requires a consensus on the transaction pool. It does not.\n\nIt may be helpful to have the discussion from the previous thread linked here.\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015370.html\n\nWhere I speak of validating that a block conforms to the broadcast next block size, I do not propose validating the number broadcast for the next block size itself, only that the next generated block is that size.\n\nRegards,\nDamian Williamson\n\n\n________________________________\nFrom: Damian Williamson <willtech at live.com.au<mailto:willtech at live.com.au>>\nSent: Saturday, 16 December 2017 7:59 AM\nTo: Rhavar\nCc: Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\nThere are really two separate problems to solve.\n\n\n  1.  How does Bitcoin scale with fixed block size?\n  2.  How do we ensure that all valid transactions are eventually included in the blockchain?\n\nThose are the two issues that the proposal attempts to address. It makes sense to resolve these two problems together. Using the proposed system for variable block sizes would solve the first problem but there would still be a whole bunch of never confirming transactions. I am not sure how to reliably solve the second problem at scale without first solving the first.\n\n>* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.\n\nI do not suggest a consensus. Depending on which node solves a block the value for next block size will be different. The consensus would be that blocks will adhere to the next block size value transmitted with the current block. It is easy to verify that the consensus is being adhered to once in place.\n\n>* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.\n\nNot a necessary function, just an effect of using a probability-based distribution.\n\n>* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by \"priority\".  What are you going to do if a \"malicious\" miner decides to go after their profits and order by what makes them the most money. Add \"ordered by priority\" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.\n\nI entirely agree with your sentiment that Bitcoin must be incentive compatible. It is necessary.\n\nIt is in only miners immediate interest to make the most profitable block from the available transaction pool. As with so many other things, it is necessary to partially ignore short-term gain for long-term benefit. It is in miners and everybody's long-term interest to have a reliable transaction service. A busy transaction service that confirms lots of transactions per hour will become more profitable as demand increases and more users are prepared to pay for priority. As it is there is currently no way to fully scale because of the transaction bandwidth limit and that is problematic. If all valid transactions must eventually confirm then there must be a way to resolve that problem.\n\nBitcoin deliberately removes traditional scale by ensuring blocks take ten minutes on average to solve, an ingenious idea and, incentive compatible but, fixed block sizes leaves us with a problem to solve when we want to scale.\n\n>If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.\n\nI am confident that the math to verify blocks based on the proposal can be developed (and I think it will not be too complex for a mathematician with the relevant experience), however, I am nowhere near experienced enough with probability and statistical analysis to do it. Yes, if Bitcoin doesn't then it might make another great opportunity for an altcoin but I am not even nearly interested in promoting any altcoins.\n\nIf not the proposal that I have put forward, then, hopefully, someone can come up with a better solution. The important thing is that the issues are resolved.\n\nRegards,\nDamian Williamson\n\n\n________________________________\nFrom: Rhavar <rhavar at protonmail.com<mailto:rhavar at protonmail.com>>\nSent: Saturday, 16 December 2017 3:38 AM\nTo: Damian Williamson\nCc: Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n> I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?\n\nUnfortunately your proposal is really fundamentally broken, on a few levels. I think you might need to do a bit more research into how bitcoin works before coming up with such improvements =)\n\nBut just some quick notes:\n\n* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.\n\n* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.\n\n* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by \"priority\".  What are you going to do if a \"malicious\" miner decides to go after their profits and order by what makes them the most money. Add \"ordered by priority\" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.\n\nIf you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.\n\n\n\n\n-Ryan\n\n\n-------- Original Message --------\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\nLocal Time: December 15, 2017 3:42 AM\nUTC Time: December 15, 2017 9:42 AM\nFrom: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nTo: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>\n\n\n\nI should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?\n\nI suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.\n\nIt has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.\n\n\nIf someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?\n\nRegards,\nDamian Williamson\n\n\n________________________________\n\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org> <bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org>> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>\nSent: Friday, 8 December 2017 8:01 AM\nTo: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n\nGood afternoon,\n\nThe need for this proposal:\n\nWe all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.\n\nI recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.\n\nI argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.\n\nBusiness cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.\n\nUnder the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.\n\nOnce there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.\n\nI also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.\n\nI do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.\n\nThis great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.\n\nI have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.\n\n# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n## The problem:\nEverybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.\n\nThe current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.\n\nCurrent fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.\n\nBitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.\n\nThe possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.\n\n## Solution summary:\nProvide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.\n\nUse a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.\n\nThe curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?\n\n**Explanation of the operation of priority:**\n> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.\n\n>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.\n\nI am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.\n\n## Pros:\n* Maximizes transaction reliability.\n* Fully scalable.\n* Maximizes possibility for consumer and business uptake.\n* Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.\n* Market determines fee paid for transaction priority.\n* Fee recommendations work all the way out to 30 days or greater.\n* Provides additional block entropy; greater security since there is less probability of predicting the next block.\n\n## Cons:\n* Could initially lower total transaction fees per block.\n* Must be first be programmed.\n\n## Solution operation:\nThis is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.\n\n1. Determine the target block size for the current block.\n2. Assign a transaction priority to each transaction in the pool.\n3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.\n5. Solve block.\n6. Broadcast the next target block size with the current block when it is solved.\n7. Block is received.\n8. Block verification process.\n9. Accept/reject block based on verification result.\n10. Repeat.\n\n## Closing comments:\nIt may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.\n\nI implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.\n\nRegards,\nDamian Williamson\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171224/7a79fb9d/attachment-0001.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-23T01:24:28",
                "message_text_only": "I suppose what I intended is (2) the weak form but, what is essentially needed is (1) the strong form. The answer may be somewhere in-between.\n\n\nI do not see that an entire consensus for the mempool is needed, each node just needs a loose understanding of the average number of non-zero fee transactions in the mempool.\n\n\nAs a pre-rollout, it would be possible to give each node a serial ID and, calculate the average number of non-zero fee transactions from the information it has and, say every ten minutes, distribute information it has about the number of transactions in the mempool. Each node would be able to form its own picture of the average number of non-zero fee transactions in the mempool.\n\n\nAt rollout, this information would be the basis a node would use when a block is solved to provide the next expected block size. This would still not stop cheating by providing especially a number lower than the proposal would allow for, to game the system and hike fees. If miners will not act in the long-term interest of the stability and operation of the system then they should be ignored. If most miners will adhere to the proposal then the average effect would be stability in the operation of the proposal, having a few or even several nodes posting low numbers for the number of transactions expected in the next expected block size would not destroy the operation. If some node posted an insanely high number for next expected block size that resulted in the mempool being emptied then the proposal would be offended but I do not actually care. If no number is posted, just create a block the appropriate size ensure conformity. Nodes that have not adopted the proposal could just continue to create 1MB blocks.\n\n\nActually, the operation could be simplified using the distributed information directly to just create blocks of the appropriate size with no need to provide next block size. Flexible block size.\n\n\nThe proposal should also specify a minimum number of transactions to include for the next block to give at a minimum a 1MB block.\n\n\nI currently have no information on flex cap, do you have a link?\n\n\nRegards,\n\nDamian Williamson\n\n\n________________________________\nFrom: Mark Friedenbach <mark at friedenbach.org>\nSent: Tuesday, 19 December 2017 3:08 AM\nTo: Damian Williamson\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\nDamian, you seem to be misunderstanding that either\n\n(1) the strong form of your proposal requires validating the commitment to the mempool properties, in which case the mempool becomes consensus critical (an impossible requirement); or\n\n(2) in the weak form where the current block is dependent on the commitment in the last block only it is becomes a miner-selected field they can freely parameterize with no repercussions for setting values totally independent of the actual mempool.\n\nIf you want to make the block size dependent on the properties of the mempool in a consensus critical way, flex cap achieves this. If you want to make the contents or properties of the mempool known to well-connected nodes, weak blocks achieves that. But you can\u2019t stick the mempool in consensus because it fundamentally is not something the nodes have consensus over. That\u2019s a chicken-and-the-egg assumption.\n\nFinally in terms of the broad goal, having block size based on the number of transactions is NOT something desirable in the first place, even if it did work. That\u2019s effectively the same as an infinite block size since anyone anywhere can create transactions in the mempool at no cost.\n\nOn Dec 16, 2017, at 8:14 PM, Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n\nI do not know why people make the leap that the proposal requires a consensus on the transaction pool. It does not.\n\nIt may be helpful to have the discussion from the previous thread linked here.\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015370.html\n\nWhere I speak of validating that a block conforms to the broadcast next block size, I do not propose validating the number broadcast for the next block size itself, only that the next generated block is that size.\n\nRegards,\nDamian Williamson\n\n\n________________________________\nFrom: Damian Williamson <willtech at live.com.au<mailto:willtech at live.com.au>>\nSent: Saturday, 16 December 2017 7:59 AM\nTo: Rhavar\nCc: Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\nThere are really two separate problems to solve.\n\n\n  1.  How does Bitcoin scale with fixed block size?\n  2.  How do we ensure that all valid transactions are eventually included in the blockchain?\n\nThose are the two issues that the proposal attempts to address. It makes sense to resolve these two problems together. Using the proposed system for variable block sizes would solve the first problem but there would still be a whole bunch of never confirming transactions. I am not sure how to reliably solve the second problem at scale without first solving the first.\n\n>* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.\n\nI do not suggest a consensus. Depending on which node solves a block the value for next block size will be different. The consensus would be that blocks will adhere to the next block size value transmitted with the current block. It is easy to verify that the consensus is being adhered to once in place.\n\n>* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.\n\nNot a necessary function, just an effect of using a probability-based distribution.\n\n>* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by \"priority\".  What are you going to do if a \"malicious\" miner decides to go after their profits and order by what makes them the most money. Add \"ordered by priority\" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.\n\nI entirely agree with your sentiment that Bitcoin must be incentive compatible. It is necessary.\n\nIt is in only miners immediate interest to make the most profitable block from the available transaction pool. As with so many other things, it is necessary to partially ignore short-term gain for long-term benefit. It is in miners and everybody's long-term interest to have a reliable transaction service. A busy transaction service that confirms lots of transactions per hour will become more profitable as demand increases and more users are prepared to pay for priority. As it is there is currently no way to fully scale because of the transaction bandwidth limit and that is problematic. If all valid transactions must eventually confirm then there must be a way to resolve that problem.\n\nBitcoin deliberately removes traditional scale by ensuring blocks take ten minutes on average to solve, an ingenious idea and, incentive compatible but, fixed block sizes leaves us with a problem to solve when we want to scale.\n\n>If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.\n\nI am confident that the math to verify blocks based on the proposal can be developed (and I think it will not be too complex for a mathematician with the relevant experience), however, I am nowhere near experienced enough with probability and statistical analysis to do it. Yes, if Bitcoin doesn't then it might make another great opportunity for an altcoin but I am not even nearly interested in promoting any altcoins.\n\nIf not the proposal that I have put forward, then, hopefully, someone can come up with a better solution. The important thing is that the issues are resolved.\n\nRegards,\nDamian Williamson\n\n\n________________________________\nFrom: Rhavar <rhavar at protonmail.com<mailto:rhavar at protonmail.com>>\nSent: Saturday, 16 December 2017 3:38 AM\nTo: Damian Williamson\nCc: Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n> I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?\n\nUnfortunately your proposal is really fundamentally broken, on a few levels. I think you might need to do a bit more research into how bitcoin works before coming up with such improvements =)\n\nBut just some quick notes:\n\n* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.\n\n* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.\n\n* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by \"priority\".  What are you going to do if a \"malicious\" miner decides to go after their profits and order by what makes them the most money. Add \"ordered by priority\" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.\n\nIf you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.\n\n\n\n\n-Ryan\n\n\n-------- Original Message --------\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\nLocal Time: December 15, 2017 3:42 AM\nUTC Time: December 15, 2017 9:42 AM\nFrom: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nTo: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>\n\n\n\nI should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?\n\nI suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.\n\nIt has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.\n\n\nIf someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?\n\nRegards,\nDamian Williamson\n\n\n________________________________\n\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org> <bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org>> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>\nSent: Friday, 8 December 2017 8:01 AM\nTo: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n\nGood afternoon,\n\nThe need for this proposal:\n\nWe all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.\n\nI recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.\n\nI argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.\n\nBusiness cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.\n\nUnder the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.\n\nOnce there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.\n\nI also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.\n\nI do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.\n\nThis great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.\n\nI have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.\n\n# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n## The problem:\nEverybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.\n\nThe current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.\n\nCurrent fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.\n\nBitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.\n\nThe possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.\n\n## Solution summary:\nProvide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.\n\nUse a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.\n\nThe curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?\n\n**Explanation of the operation of priority:**\n> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.\n\n>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.\n\nI am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.\n\n## Pros:\n* Maximizes transaction reliability.\n* Fully scalable.\n* Maximizes possibility for consumer and business uptake.\n* Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.\n* Market determines fee paid for transaction priority.\n* Fee recommendations work all the way out to 30 days or greater.\n* Provides additional block entropy; greater security since there is less probability of predicting the next block.\n\n## Cons:\n* Could initially lower total transaction fees per block.\n* Must be first be programmed.\n\n## Solution operation:\nThis is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.\n\n1. Determine the target block size for the current block.\n2. Assign a transaction priority to each transaction in the pool.\n3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.\n5. Solve block.\n6. Broadcast the next target block size with the current block when it is solved.\n7. Block is received.\n8. Block verification process.\n9. Accept/reject block based on verification result.\n10. Repeat.\n\n## Closing comments:\nIt may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.\n\nI implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.\n\nRegards,\nDamian Williamson\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171223/9e2aa96b/attachment-0001.html>"
            },
            {
                "author": "Spartacus Rex",
                "date": "2017-12-24T09:02:09",
                "message_text_only": "..What you have proposed is interesting but seems to do nothing for the\nissue of transaction\nbandwidth, which seems to be approaching its threshold:\n..\n\nThis system just shows one way of changing the way a miner calculates txn\npriority.\n\nA miners should always do what makes him the most money, so an old txn will\nnever get priority if a newer one offering more fees comes along. This is\nwhy some txns will never get confirmation.\n\nIn this system a txn cannot just pay more fees, as you all pay the same\nfees in a block, so an old txn that has a high enough threshold will be\nworth just as much to a miner as any txn coming later on.\n\nThis way you can be sure that your txn will confirm at some point, and not\njust be relegated to the 'never' confirmed pile.\n\n\nOn Dec 24, 2017 03:44, \"Damian Williamson\" <willtech at live.com.au> wrote:\n\n>.. This system has flaws, they all do.\n\n\n>The simple fact is that there is currently no known system that works as\nwell as the current system..\n\n\nAlright, but, we seem to agree, the current system also has flaws. The\ntransaction bandwidth limit is a serious issue for transactional\nreliability.\n\n\nWhat you have proposed is interesting but seems to do nothing for the issue\nof transaction bandwidth, which seems to be approaching its threshold:\n\nhttps://bitinfocharts.com/comparison/bitcoin-transactions.html\n\n\nRegards,\n\nDamian Williamson\n------------------------------\n*From:* Spartacus Rex <spartacusrex99 at gmail.com>\n*Sent:* Saturday, 23 December 2017 5:07:49 AM\n*To:* Damian Williamson; Bitcoin Protocol Discussion\n\n*Subject:* Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use\nTransaction Priority For Ordering Transactions In Blocks\n\nHi Damian,\n\nThought I'd chip in.  This is a hard fork scenario. This system has flaws,\nthey all do.\n\nIf you had a fixed fee per block, so that every txn in that block paid the\nsame fee, that might make it easier to include all txns eventually, as you\nenvisage.\n\nThe fee could be calculated as the average of the amount txns are prepared\nto pay in the last 1000 blocks.\n\nA txn would say ' I'll pay up to X bitcoins ' and as long as that is more\nthan the value required for the block your txn can be added. This is to\nensure you don't pay more than you are willing.  It also ensures that\nputting an enormous fee will not ensure your txn is processed quickly..\n\nCalculating what the outputs are given a variable fee needs a new mechanism\nall of it's own, but I'm sure it's possible.\n\nThe simple fact is that there is currently no known system that works as\nwell as the current system..\n\nBut there are other systems.\n\n\nOn Dec 22, 2017 15:09, \"Damian Williamson via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\nIf the cash value of Bitcoin was high enough and zero fee transactions were\nnever accepted and not counted when calculating the transaction pool size\nthen I do not think it would be such an issue. Why is it even possible to\ncreate zero fee transactions?\n\n\nRegards,\n\nDamian Williamson\n\n------------------------------\n*From:* bitcoin-dev-bounces at lists.linuxfoundation.org <\nbitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian\nWilliamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n*Sent:* Tuesday, 19 December 2017 6:51 PM\n*To:* Mark Friedenbach\n*Cc:* bitcoin-dev at lists.linuxfoundation.org\n*Subject:* [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction\nPriority For Ordering Transactions In Blocks\n\n\nThank you for your constructive feedback. I now see that the proposal\nintroduces a potential issue.\n\n\n>Finally in terms of the broad goal, having block size based on the number\nof transactions is NOT something desirable in the first place, even if it\ndid work. That\u2019s effectively the same as an infinite block size since\nanyone anywhere can create transactions in the mempool at no cost.\n\n\nDo you have any critical suggestion as to how transaction bandwidth limit\ncould be addressed, it will eventually become an issue if nothing is\nchanged regardless of how high fees go?\n\n\nRegards,\nDamian Williamson\n\n\n\n------------------------------\n*From:* Mark Friedenbach <mark at friedenbach.org>\n*Sent:* Tuesday, 19 December 2017 3:08 AM\n*To:* Damian Williamson\n*Subject:* Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use\nTransaction Priority For Ordering Transactions In Blocks\n\nDamian, you seem to be misunderstanding that either\n\n(1) the strong form of your proposal requires validating the commitment to\nthe mempool properties, in which case the mempool becomes consensus\ncritical (an impossible requirement); or\n\n(2) in the weak form where the current block is dependent on the commitment\nin the last block only it is becomes a miner-selected field they can freely\nparameterize with no repercussions for setting values totally independent\nof the actual mempool.\n\nIf you want to make the block size dependent on the properties of the\nmempool in a consensus critical way, flex cap achieves this. If you want to\nmake the contents or properties of the mempool known to well-connected\nnodes, weak blocks achieves that. But you can\u2019t stick the mempool in\nconsensus because it fundamentally is not something the nodes have\nconsensus over. That\u2019s a chicken-and-the-egg assumption.\n\nFinally in terms of the broad goal, having block size based on the number\nof transactions is NOT something desirable in the first place, even if it\ndid work. That\u2019s effectively the same as an infinite block size since\nanyone anywhere can create transactions in the mempool at no cost.\n\nOn Dec 16, 2017, at 8:14 PM, Damian Williamson via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\nI do not know why people make the leap that the proposal requires a\nconsensus on the transaction pool. It does not.\n\nIt may be helpful to have the discussion from the previous thread linked\nhere.\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017\n-December/015370.html\n\nWhere I speak of validating that a block conforms to the broadcast next\nblock size, I do not propose validating the number broadcast for the next\nblock size itself, only that the next generated block is that size.\n\nRegards,\nDamian Williamson\n\n\n------------------------------\n*From:* Damian Williamson <willtech at live.com.au>\n*Sent:* Saturday, 16 December 2017 7:59 AM\n*To:* Rhavar\n*Cc:* Bitcoin Protocol Discussion\n*Subject:* Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use\nTransaction Priority For Ordering Transactions In Blocks\n\nThere are really two separate problems to solve.\n\n\n   1. How does Bitcoin scale with fixed block size?\n   2. How do we ensure that all valid transactions are eventually included\n   in the blockchain?\n\n\nThose are the two issues that the proposal attempts to address. It makes\nsense to resolve these two problems together. Using the proposed system for\nvariable block sizes would solve the first problem but there would still be\na whole bunch of never confirming transactions. I am not sure how to\nreliably solve the second problem at scale without first solving the first.\n\n>* Every node has a (potentially) different mempool, you can't use it to\ndecide consensus values like the max block size.\n\nI do not suggest a consensus. Depending on which node solves a block the\nvalue for next block size will be different. The consensus would be that\nblocks will adhere to the next block size value transmitted with the\ncurrent block. It is easy to verify that the consensus is being adhered to\nonce in place.\n\n>* Increasing the entropy in a block to make it more unpredictable doesn't\nreally make sense.\n\nNot a necessary function, just an effect of using a probability-based\ndistribution.\n\n>* Bitcoin should be roughly incentive compatible. Your proposal explicits\nasks miners to ignore their best interests, and confirm transactions by\n\"priority\".  What are you going to do if a \"malicious\" miner decides to go\nafter their profits and order by what makes them the most money. Add\n\"ordered by priority\" as a consensus requirement? And even if you miners\ncan still sort their mempool by fee, and then order the top 1MB by priority.\n\nI entirely agree with your sentiment that Bitcoin must be incentive\ncompatible. It is necessary.\n\nIt is in only miners immediate interest to make the most profitable block\nfrom the available transaction pool. As with so many other things, it is\nnecessary to partially ignore short-term gain for long-term benefit. It is\nin miners and everybody's long-term interest to have a reliable transaction\nservice. A busy transaction service that confirms lots of transactions per\nhour will become more profitable as demand increases and more users are\nprepared to pay for priority. As it is there is currently no way to fully\nscale because of the transaction bandwidth limit and that is problematic.\nIf all valid transactions must eventually confirm then there must be a way\nto resolve that problem.\n\nBitcoin deliberately removes traditional scale by ensuring blocks take ten\nminutes on average to solve, an ingenious idea and, incentive compatible\nbut, fixed block sizes leaves us with a problem to solve when we want to\nscale.\n\n>If you could find a good solution that would allow you to know if miners\nwere following your rule or not (and thus ignore it if it doesn't) then you\nwouldn't even need bitcoin in the first place.\n\nI am confident that the math to verify blocks based on the proposal can be\ndeveloped (and I think it will not be too complex for a mathematician with\nthe relevant experience), however, I am nowhere near experienced enough\nwith probability and statistical analysis to do it. Yes, if Bitcoin doesn't\nthen it might make another great opportunity for an altcoin but I am not\neven nearly interested in promoting any altcoins.\n\n\nIf not the proposal that I have put forward, then, hopefully, someone can\ncome up with a better solution. The important thing is that the issues are\nresolved.\n\nRegards,\nDamian Williamson\n\n\n------------------------------\n*From:* Rhavar <rhavar at protonmail.com>\n*Sent:* Saturday, 16 December 2017 3:38 AM\n*To:* Damian Williamson\n*Cc:* Bitcoin Protocol Discussion\n*Subject:* Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use\nTransaction Priority For Ordering Transactions In Blocks\n\n> I understand that there would be technical issues to resolve in\nimplementation, but, are there no fundamental errors?\n\nUnfortunately your proposal is really fundamentally broken, on a few\nlevels. I think you might need to do a bit more research into how bitcoin\nworks before coming up with such improvements =)\n\nBut just some quick notes:\n\n* Every node has a (potentially) different mempool, you can't use it to\ndecide consensus values like the max block size.\n\n* Increasing the entropy in a block to make it more unpredictable doesn't\nreally make sense.\n\n* Bitcoin should be roughly incentive compatible. Your proposal explicits\nasks miners to ignore their best interests, and confirm transactions by\n\"priority\".  What are you going to do if a \"malicious\" miner decides to go\nafter their profits and order by what makes them the most money. Add\n\"ordered by priority\" as a consensus requirement? And even if you miners\ncan still sort their mempool by fee, and then order the top 1MB by priority.\n\nIf you could find a good solution that would allow you to know if miners\nwere following your rule or not (and thus ignore it if it doesn't) then you\nwouldn't even need bitcoin in the first place.\n\n\n\n\n-Ryan\n\n\n-------- Original Message --------\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction\nPriority For Ordering Transactions In Blocks\nLocal Time: December 15, 2017 3:42 AM\nUTC Time: December 15, 2017 9:42 AM\nFrom: bitcoin-dev at lists.linuxfoundation.org\nTo: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\n\n\n\nI should not take it that the lack of critical feedback to this revised\nproposal is a glowing endorsement. I understand that there would be\ntechnical issues to resolve in implementation, but, are there no\nfundamental errors?\n\nI suppose that it if is difficult to determine how long a transaction has\nbeen waiting in the pool then, each node could simply keep track of when a\ntransaction was first seen. This may have implications for a verify\nroutine, however, for example, if a node was offline, how should it\ndifferentiate how long each transaction was waiting in that case? If a node\nwas restarted daily would it always think that all transactions had been\nwaiting in the pool less than one day If each node keeps the current\ntransaction pool in a file and updates it, as transactions are included in\nblocks and, as new transactions appear in the pool, then that would go some\nway to alleviate the issue, apart from entirely new nodes. There should be\nno reason the contents of a transaction pool files cannot be shared without\nagreement as to the transaction pool between nodes, just as nodes transmit\nnew transactions freely.\n\nIt has been questioned why miners could not cheat. For the question of how\nmany transactions to include in a block, I say it is a standoff and miners\nwill conform to the proposal, not wanting to leave transactions with valid\nfees standing, and, not wanting to shrink the transaction pool. In any\ncase, if miners shrink the transaction pool then I am not immediately\nconcerned since it provides a more efficient service. For the question of\nincluding transactions according to the proposal, I say if it is possible\nto keep track of how long transactions are waiting in the pool so that they\ncan be included on a probability curve then it is possible to verify that\nblocks conform to the proposal, since the input is a probability, the\noutput should conform to a probability curve.\n\n\nIf someone has the necessary skill, would anyone be willing to develop the\nmath necessary for the proposal?\n\nRegards,\nDamian Williamson\n\n\n------------------------------\n\n*From:* bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin\n-dev-bounces at lists.linuxfoundation.org> on behalf of Damian Williamson via\nbitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n*Sent:* Friday, 8 December 2017 8:01 AM\n*To:* bitcoin-dev at lists.linuxfoundation.org\n*Subject:* [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction\nPriority For Ordering Transactions In Blocks\n\n\nGood afternoon,\n\nThe need for this proposal:\n\nWe all must learn to admit that transaction bandwidth is still lurking as a\nserious issue for the operation, reliability, safety, consumer acceptance,\nuptake and, for the value of Bitcoin.\n\nI recently sent a payment which was not urgent so; I chose three-day target\nconfirmation from the fee recommendation. That transaction has still not\nconfirmed after now more than six days - even waiting twice as long seems\nquite reasonable to me. That transaction is a valid transaction; it is not\nrubbish, junk or, spam. Under the current model with transaction bandwidth\nlimitation, the longer a transaction waits, the less likely it is ever to\nconfirm due to rising transaction numbers and being pushed back by\ntransactions with rising fees.\n\nI argue that no transactions are rubbish or junk, only some zero fee\ntransactions might be spam. Having an ever-increasing number of valid\ntransactions that do not confirm as more new transactions with higher fees\nare created is the opposite of operating a robust, reliable transaction\nsystem.\n\nBusiness cannot operate with a model where transactions may or may not\nconfirm. Even a business choosing a modest fee has no guarantee that their\nvalid transaction will not be shuffled down by new transactions to the\nrealm of never confirming after it is created. Consumers also will not\naccept this model as Bitcoin expands. If Bitcoin cannot be a reliable\npayment system for confirmed transactions then consumers, by and large,\nwill simply not accept the model once they understand. Bitcoin will be a\ndirty payment system, and this will kill the value of Bitcoin.\n\nUnder the current system, a minority of transactions will eventually be the\nlucky few who have fees high enough to escape being pushed down the list.\n\nOnce there are more than x transactions (transaction bandwidth limit) every\nten minutes, only those choosing twenty-minute confirmation (2 blocks) will\nhave initially at most a fifty percent chance of ever having their payment\nconfirm. Presently, not even using fee recommendations can ensure a\nsufficiently high fee is paid to ensure transaction confirmation.\n\nI also argue that the current auction model for limited transaction\nbandwidth is wrong, is not suitable for a reliable transaction system and,\nis wrong for Bitcoin. All transactions must confirm in due time. Currently,\nBitcoin is not a safe way to send payments.\n\nI do not believe that consumers and business are against paying fees, even\nhigh fees. What is required is operational reliability.\n\nThis great issue needs to be resolved for the safety and reliability of\nBitcoin. The time to resolve issues in commerce is before they become great\nbig issues. The time to resolve this issue is now. We must have the\nforesight to identify and resolve problems before they trip us over.\nSimply doubling block sizes every so often is reactionary and is not a\nreliable permanent solution. I have written a BIP proposal for a technical\nsolution but, need your help to write it up to an acceptable standard to be\na full BIP.\n\nI have formatted the following with markdown which is human readable so, I\nhope nobody minds. I have done as much with this proposal as I feel that I\nam able so far but continue to take your feedback.\n\n# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering\nTransactions In Blocks\n\n## The problem:\nEverybody wants value. Miners want to maximize revenue from fees (and we\npresume, to minimize block size). Consumers need transaction reliability\nand, (we presume) want low fees.\n\nThe current transaction bandwidth limit is a limiting factor for both. As\nthe operational safety of transactions is limited, so is consumer\nconfidence as they realize the issue and, accordingly, uptake is limited.\nFees are artificially inflated due to bandwidth limitations while failing\nto provide a full confirmation service for all transactions.\n\nCurrent fee recommendations provide no satisfaction for transaction\nreliability and, as Bitcoin scales, this will worsen.\n\nBitcoin must be a fully scalable and reliable service, providing full\ntransaction confirmation for every valid transaction.\n\nThe possibility to send a transaction with a fee lower than one that is\nacceptable to allow eventual transaction confirmation should be removed\nfrom the protocol and also from the user interface.\n\n## Solution summary:\nProvide each transaction with an individual transaction priority each time\nbefore choosing transactions to include in the current block, the priority\nbeing a function of the fee paid (on a curve), and the time waiting in the\ntransaction pool (also on a curve) out to n days (n=60 ?). The transaction\npriority to serve as the likelihood of a transaction being included in the\ncurrent block, and for determining the order in which transactions are\ntried to see if they will be included.\n\nUse a target block size. Determine the target block size using; current\ntransaction pool size x ( 1 / (144 x n days ) ) = number of transactions to\nbe included in the current block. Broadcast the next target block size with\nthe current block when it is solved so that nodes know the next target\nblock size for the block that they are building on.\n\nThe curves used for the priority of transactions would have to be\nappropriate. Perhaps a mathematician with experience in probability can\ndevelop the right formulae. My thinking is a steep curve. I suppose that\nthe probability of all transactions should probably account for a\nsufficient number of inclusions that the target block size is met although,\nit may not always be. As a suggestion, consider including some zero fee\ntransactions to pad, highest BTC value first?\n\n**Explanation of the operation of priority:**\n> If transaction priority is, for example, a number between one (low) and\none-hundred (high) it can be directly understood as the percentage chance\nin one-hundred of a transaction being included in the block. Using\nprobability or likelihood infers that there is some function of random. If\nrandom (100) < transaction priority then the transaction is included.\n\n>To break it down further, if both the fee on a curve value and the time\nwaiting on a curve value are each a number between one and one-hundred, a\nrudimentary method may be to simply multiply those two numbers, to find the\npriority number. For example, a middle fee transaction waiting thirty days\n(if n = 60 days) may have a value of five for each part  (yes, just five,\nthe values are on a curve). When multiplied that will give a priority value\nof twenty-five, or,  a twenty-five percent chance at that moment of being\nincluded in the block; it will likely be included in one of the next four\nblocks, getting more likely each chance. If it is still not included then\nthe value of time waiting will be higher, making for more probability. A\nvery low fee transaction would have a value for the fee of one. It would\nnot be until near sixty-days that the particular low fee transaction has a\nhigh likelihood of being included in the block.\n\nI am not concerned with low (or high) transaction fees, the primary reason\nfor addressing the issue is to ensure transactional reliability and\nscalability while having each transaction confirm in due time.\n\n## Pros:\n* Maximizes transaction reliability.\n* Fully scalable.\n* Maximizes possibility for consumer and business uptake.\n* Maximizes total fees paid per block without reducing reliability; because\nof reliability, in time confidence and overall uptake are greater;\ntherefore, more transactions.\n* Market determines fee paid for transaction priority.\n* Fee recommendations work all the way out to 30 days or greater.\n* Provides additional block entropy; greater security since there is less\nprobability of predicting the next block.\n\n## Cons:\n* Could initially lower total transaction fees per block.\n* Must be first be programmed.\n\n## Solution operation:\nThis is a simplistic view of the operation. The actual operation will need\nto be determined in a spec for the programmer.\n\n1. Determine the target block size for the current block.\n2. Assign a transaction priority to each transaction in the pool.\n3. Select transactions to include in the current block using probability in\ntransaction priority order until the target block size is met.\n5. Solve block.\n6. Broadcast the next target block size with the current block when it is\nsolved.\n7. Block is received.\n8. Block verification process.\n9. Accept/reject block based on verification result.\n10. Repeat.\n\n## Closing comments:\nIt may be possible to verify blocks conform to the proposal by showing that\nthe probability for all transactions included in the block statistically\nconforms to a probability distribution curve, *if* the individual\ntransaction priority can be recreated. I am not that deep into the\nmathematics; however, it may also be possible to use a similar method to do\nthis just based on the fee, that statistically, the blocks conform to a fee\ndistribution. Any zero fee transactions would have to be ignored. This\nsolution needs a clever mathematician.\n\nI implore, at the very least, that we use some method that validates full\ntransaction reliability and enables scalability of block sizes. If not this\nproposal, an alternative.\n\nRegards,\nDamian Williamson\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171224/a8ce1cb4/attachment-0001.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-26T05:14:14",
                "message_text_only": "I have needed to re-tac my intentions somewhat, there is still much\nwork to be done.\n\nThis is a request for assistance and further discussion of the re-\nrevised proposal. I am sure there are still issues to be resolved.\n\n##\u00a0BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering\nTransactions In Blocks\n\nSchema:\u00a0\u00a0\n##########\u00a0\u00a0\nDocument: BIP Proposal\u00a0\u00a0\nTitle: UTPFOTIB - Use Transaction Priority For Ordering Transactions In\nBlocks\u00a0\u00a0\nDate: 26-12-2017\u00a0\u00a0\nAuthor: Damian Williamson &lt;willtech at live.com.au&gt; \u00a0\nLicence: Creative Commons Attribution-ShareAlike 4.0 International\nLicense.\u00a0\u00a0\nURL: http://thekingjameshrmh.tumblr.com/post/168948530950/bip-proposal-\nutpfotib-use-transaction-priority-for-order\u00a0\u00a0\n##########\u00a0\u00a0\n\n### 1. Abstract\n\nThis document proposes to address the issue of transactional\nreliability in Bitcoin, where valid transactions may be stuck in the\ntransaction pool for extended periods or never confirm.\n\nThere are two key issues to be resolved to achieve this:\n\n1.\u00a0\u00a0The current transaction bandwidth limit.\n2.\u00a0\u00a0The current ad-hoc methods of including transactions in blocks\nresulting in variable and confusing confirmation times for valid\ntransactions, including transactions with a valid fee that may never\nconfirm.\n\nIt is important with any change to protect the value of fees as these\nwill eventually be the only payment that miners receive. Rather than an\nauction model for limited bandwidth, the proposal results in a fee for\npriority service auction model.\n\nIt would not be true to suggest that all feedback received so far has\nbeen entirely positive although, most of it has been constructive.\n\nThe previous threads for this proposal are available here: \u00a0\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/s\nubject.html\n\nIn all parts of this proposal, references to a transaction, a valid\ntransaction, a transaction with a valid fee, a valid fee, etc. is\ndefined as any transaction that is otherwise valid with a fee of at\nleast 0.00001000 BTC/KB as defined as the dust level, interpreting from\nBitcoin Core GUI. Transactions with a fee lower than this rate are\nconsidered dust.\n\nIn all parts of this proposal, dust and zero-fee transactions are\nalways ignored and/or excluded unless specifically mentioned.\n\nIt is generally assumed that miners currently prefer to include\ntransactions with higher fees.\n\n### 2. The need for this proposal\n\nWe all must learn to admit that transaction bandwidth is still lurking\nas a serious issue for the operation, reliability, safety, consumer\nacceptance, uptake and, for the value of Bitcoin.\n\nI recently sent a payment which was not urgent so; I chose three-day\ntarget confirmation from the fee recommendation. That transaction has\nstill not confirmed after now more than six days - even waiting twice\nas long seems quite reasonable to me (note for accuracy: it did\neventually confirm). That transaction is a valid transaction; it is not\nrubbish, junk or, spam. Under the current model with transaction\nbandwidth limitation, the longer a transaction waits, the less likely\nit is ever to confirm due to rising transaction numbers and being\npushed back by transactions with rising fees.\n\nI argue that no transactions with fees above the dust level are rubbish\nor junk, only some zero fee transactions might be spam. Having an ever-\nincreasing number of valid transactions that do not confirm as more new\ntransactions with higher fees are created is the opposite of operating\na robust, reliable transaction system.\n\nBusiness cannot operate with a model where transactions may or may not\nconfirm. Even a business choosing a modest fee has no guarantee that\ntheir valid transaction will not be shuffled down by new transactions\nto the realm of never confirming after it is created. Consumers also\nwill not accept this model as Bitcoin expands. If Bitcoin cannot be a\nreliable payment system for confirmed transactions then consumers, by\nand large, will simply not accept the model once they understand.\nBitcoin will be a dirty payment system, and this will kill the value of\nBitcoin.\n\nUnder the current system, a minority of transactions will eventually be\nthe lucky few who have fees high enough to escape being pushed down the\nlist.\n\nOnce there are more than x transactions (transaction bandwidth limit)\nevery ten minutes, only those choosing twenty-minute confirmation (2\nblocks) from the fee recommendations will have initially at most a\nfifty percent chance of ever having their payment confirm when 2x\ntransactions is reached. Presently, not even using fee recommendations\ncan ensure a sufficiently high fee is paid to ensure transaction\nconfirmation.\n\nI also argue that the current auction model for limited transaction\nbandwidth is wrong, is not suitable for a reliable transaction system\nand, is wrong for Bitcoin. All transactions with valid fees must\nconfirm in due time. Currently, Bitcoin is not a safe way to send\npayments.\n\nI do not believe that consumers and business are against paying fees,\neven high fees. What is required is operational reliability.\n\nThis great issue needs to be resolved for the safety and reliability of\nBitcoin. The time to resolve issues in commerce is before they become\ngreat big issues. The time to resolve this issue is now. We must have\nthe foresight to identify and resolve problems before they trip us\nover.\u00a0\u00a0Simply doubling block sizes every so often is reactionary and is\nnot a reliable permanent solution.\n\nI have written this proposal for a technical solution but, need your\nhelp to write it up to an acceptable standard to be a full BIP.\n\n### 3. The problem\n\nEverybody wants value. Miners want to maximise revenue from fees (and\nwe presume, to minimise block size). Consumers need transaction\nreliability and, (we presume) want low fees.\n\nThe current transaction bandwidth limit is a limiting factor for both.\nAs the operational safety of transactions is limited, so is consumer\nconfidence as they realise the issue and, accordingly, uptake is\nlimited. Fees are artificially inflated due to bandwidth limitations\nwhile failing to provide a full confirmation service for all valid\ntransactions.\n\nCurrent fee recommendations provide no satisfaction for transaction\nreliability and, as Bitcoin scales, this will worsen.\n\nTransactions are included in blocks by miners using whatever basis they\nprefer. We expect that this is usually a fee-based priority. However,\neven transactions with a valid fee may be left in the transaction pool\nfor some time. As transaction bandwidth becomes an issue, not even\nextreme fees can ensure a transaction is processed in a timely manner\nor at all.\n\nBitcoin must be a fully scalable and reliable service, providing full\ntransaction confirmation for every valid transaction.\n\nThe possibility to send a transaction with a fee lower than one that is\nacceptable to allow eventual transaction confirmation should be removed\nfrom the protocol and also from the user interface.\n\n### 4. Solution summary\n\n#### Main solution\n\nProvide each valid transaction in the mempool with an individual\ntransaction priority each time before choosing transactions to include\nin the current block. The priority being a function of the fee (on a\ncurve), and the time waiting in the transaction pool (also on a curve)\nout to n days (n = 60 days ?), and extending past n days. The value for\nfee on a curve may need an upper limit. The transaction priority to\nserve as the likelihood of a transaction being included in the current\nblock, and for determining the order in which transactions are tried to\nsee if they will be included.\n\nNodes will need to keep track of when a transaction is first seen. It\nis satisfactory for each node to do this independently provided the\ninformation survives node restart. If there is a more reliable way to\ndetermine when a transaction was first seen on the network then it\nshould be utilised.\n\nUse a dynamic target block size to make the current block. If the block\nsize is consistently too small then I expect ageing transactions will\nbe overrepresented as a portion of the block contents, to the point\nwhere blocks will only contain the oldest transactions as they age past\nn days. If block size is too large on average then this will shrink the\ntransaction pool. Determine the target block size using; pre-\nrollout(current average valid transaction pool size) x ( 1 / (144 x n\ndays ) ) = number of transactions to be included in the current block.\nThe block created should be a minimum 1MB in size regardless if the\ntarget block size is lower.\n\nNodes that have not yet adopted the proposal will just continue to\ncreate 1MB unordered blocks.\n\nThe default value for mempoolexpiry may in future need to be adjusted\nto match n days or, perhaps using less than n = 14 days may be a more\nsensible approach?\n\nAll block created with dynamic size should be verified to ensure\nconformity to a probability distribution curve resulting from the\npriority method. Since the input is a probability, the output should\nconform to a probability distribution.\n\nThe curves used for the priority of transactions would have to be\nappropriate. Perhaps a mathematician with experience in probability can\ndevelop the right formulae. My thinking is a steep curve. I suppose\nthat the probability of all transactions should probably account for a\nsufficient number of inclusions that the target block size is met on\naverage although, it may not always be. As a suggestion, consider\nincluding some dust or zero-fee transactions to pad if each valid\ntransaction is tried and the target block size is not yet met, highest\nBTC transaction value first?\n\n**Explanation of the operation of priority:**\n\n> If transaction priority is, for example, a number between one (low)\nand one-hundred (high) it can be directly understood as the percentage\nchance in one-hundred of a transaction being included in the block.\nUsing probability or likelihood infers that there is some function of\nrandom. Try the transactions in priority order from highest to lowest,\nif random (100) < transaction priority then the transaction is included\nuntil the target block size is met.\n\n> To break it down further, if both the fee on a curve value and the\ntime waiting on a curve value are each a number between one and one-\nhundred, a rudimentary method may be to simply multiply those two\nnumbers, to find the priority number. For example, a middle fee\ntransaction waiting thirty days (if n = 60 days) may have a value of\nfive for each part\u00a0\u00a0(yes, just five, the values are on a curve). When\nmultiplied that will give a priority value of twenty-five, or, a\ntwenty-five percent chance at that moment of being included in the\nblock; it will likely be included in one of the next four blocks,\ngetting more likely each chance. If it is still not included then the\nvalue of time waiting will be higher, making for more probability. A\nvery low fee transaction would have a value for the fee of one. It\nwould not be until near sixty-days that the particular low fee\ntransaction has a high likelihood of being included in the block.\n\nIn practice it may be more useful to use numbers representative of one-\nhundred for the highest fee priority curve down to a small fraction of\none for the lowest fee and, from one for a newly seen transaction up to\na proportionately high number above one-hundred for the time waiting\ncurve. It is truely beyond my level of math to resolve probability\ncurves accurately without much trial and error.\n\nThe primary reason for addressing the issue is to ensure transactional\nreliability and scalability while having each valid transaction confirm\nin due time.\n\n#### Pros\n\n*\u00a0\u00a0\u00a0Maximizes transaction reliability.\n*\u00a0\u00a0\u00a0Overcomes transaction bandwidth limit.\n*\u00a0\u00a0\u00a0Fully scalable.\n*\u00a0\u00a0\u00a0Maximizes possibility for consumer and business uptake.\n*\u00a0\u00a0\u00a0Maximizes total fees paid per block without reducing reliability;\nbecause of reliability, in time confidence and overall uptake are\ngreater; therefore, more transactions.\n*\u00a0\u00a0\u00a0Market determines fee paid for transaction priority.\n*\u00a0\u00a0\u00a0Fee recommendations work all the way out to 30 days or greater.\n*\u00a0\u00a0\u00a0Provides additional block entropy; greater security since there is\nless probability of predicting the next block. _Although this is not\nnecessary it is a product of the operation of this proposal._\n\n#### Cons\n\n*\u00a0\u00a0\u00a0Could initially lower total transaction fees per block.\n*\u00a0\u00a0\u00a0Must be first be programmed.\n\n#### Pre-rollout\n\nNodes need to have at a minimum a loose understanding of the average\n(since there is no consensus) size of the transaction pool as a\nrequirement to enable future changes to the way blocks are constructed.\n\nA new network service should be constructed to meet this need. This\nservice makes no changes to any existing operation or function of the\nnode. Initially, Bitcoin Core is a suitable candidate.\n\n**The service must:**\n\n*\u00a0\u00a0\u00a0Have an individual temporary (runtime permanent only) Serial Node\nID.\n*\u00a0\u00a0\u00a0Accept communication of the number of valid transactions in the\nmempool of another valid Bitcoin node along with the Serial Node ID of\nthe node whose value is provided.\n*\u00a0\u00a0\u00a0Disconnect the service from any non-Bitcoin node. Bitcoin Core may\nhandle this already?\n*\u00a0\u00a0\u00a0Expire any value not updated for k minutes (k = 30 minutes?).\n*\u00a0\u00a0\u00a0Broadcast all mempool information the node has every m minutes (m =\n10 minutes?), including its own.\n*\u00a0\u00a0\u00a0Nodes own mempool information should not be broadcast or used in\ncalculation until the node has been up long enough for the mempool to\nnormalise for at least o minutes (o = 300 minutes ?)\n*\u00a0\u00a0\u00a0Only new or updated mempool values should be transmitted to the\nsame node. Updated includes updated with no change.\n*\u00a0\u00a0\u00a0All known mempool information must survive node restart.\n*\u00a0\u00a0\u00a0If the nodes own mempool is not normalised and network information\nis not available to calculate an average just display zero.\n*\u00a0\u00a0\u00a0Internally, the average transaction pool size must return the\ncalculated average if an average is available or, if none is available\njust the number of valid transactions in the node's own mempool\nregardless if it is normalised.\n\nBitcoin Core must use all collated information on mempool size to\ncalculate a figure for the average mempool size.\n\nThe calculated figure should be displayed in the appropriate place in\nthe Debug window alongside the text Network average transactions.\n\nConsideration must be given before development of the network bandwidth\nthis would require. All programming must be consistent with the current\noperation and conventions of Bitcoin Core. Methods must work on all\nplatforms.\n\nAs this new service does not affect any existing service or feature of\nBitcoin or Bitcoin Core, this can technically be programmed now and\nincluded in Bitcoin Core at any time.\n\n### 5. Solution operation\n\nThis is a simplistic view of the operation. The actual operation will\nneed to be determined accurately in a spec for the programmer.\n\n1.\u00a0\u00a0Determine the target block size for the current block.\n2.\u00a0\u00a0Assign a transaction priority to each valid transaction in the\nmempool.\n3.\u00a0\u00a0Select transactions to include in the current block using\nprobability in transaction priority order until the target block size\nis met. If target block size is not met, include dust and zero-fee\ntransactions to pad.\n4.\u00a0\u00a0Solve block.\n5.\u00a0\u00a0Broadcast the current block when it is solved.\n6.\u00a0\u00a0Block is received.\n7.\u00a0\u00a0Block verification process.\n8.\u00a0\u00a0Accept/reject block based on verification result.\n9.\u00a0\u00a0Repeat.\n\n### 6. Closing comments\n\nIt may be possible to verify blocks conform to the proposal by showing\nthat the probability for all transactions included in the block\nstatistically conforms to a probability distribution curve, *if* the\nindividual transaction priority can be recreated. I am not that deep\ninto the mathematics; however, it may also be possible to use a similar\nmethod to do this just based on the fee, that statistically, the block\nconforms to a fee distribution. Any dust and zero-fee transactions\nwould have to be ignored. This solution needs a competent mathematician\nwith experience in probability and statistical distribution.\n\nThere has been some concern expressed over spam and very low fee\ntransactions, and an infinite block size resulting. I hope that for\nthose concerned using the dust level addresses the issue, especially as\nthe value of Bitcoin grows.\n\nThis proposal is necessary. I implore, at the very least, that we use\nsome method that validates full transaction reliability and enables\nscalability of Bitcoin. If not this proposal, an alternative.\n\nI have done as much with this proposal as I feel that I am able so far\nbut continue to take your feedback.\n\nRegards,\u00a0\u00a0\nDamian Williamson\n\n[![Creative Commons License](https://i.creativecommons.org/l/by-sa/4.0/\n88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)\u00a0\u00a0\n<span xmlns:dct=\"http://purl.org/dc/terms/\"\nhref=\"http://purl.org/dc/dcmitype/Text\" property=\"dct:title\"\nrel=\"dct:type\">BIP Proposal: UTPFOTIB - Use Transaction Priority For\nOrdering Transactions In Blocks</span> by [Damian Williamson\n&lt;willtech at live.com.au&gt;](http://thekingjameshrmh.tumblr.com/post/1\n68948530950/bip-proposal-utpfotib-use-transaction-priority-for-order)\nis licensed under a [Creative Commons Attribution-ShareAlike 4.0\nInternational License](http://creativecommons.org/licenses/by-sa/4.0/).\nBased on a work at [https://lists.linuxfoundation.org/pipermail/bitcoin\n-dev/2017-\nDecember/015371.html](https://lists.linuxfoundation.org/pipermail/bitco\nin-dev/2017-December/015371.html).\nPermissions beyond the scope of this license may be available at [https\n://opensource.org/licenses/BSD-3-\nClause](https://opensource.org/licenses/BSD-3-Clause)."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2017-12-27T03:55:43",
                "message_text_only": "Good morning Damian,\n\nI see you have modified your proposal to be purely driven by miners, with fullnodes not actually being able to create a strict \"yes-or-no\" answer as to block validity under your rules.  This implies that your rules cannot be enforced and that rational miners will ignore your proposal unless it brings in more money for them.  The fact that your proposal provides some mechanism to increase block size means that miners will be incentivized to falsify data (by making up their own transactions just above your fixed \"dust size\" threshhold whatever that threshhold may be -- and remember, miners get at least 12.5 BTC per block, so they can make a lot of little falsified transactions to justify every block size increase) until the block size increase per block is the maximum possible block size increase.\n\n--\n\nLet me then explain proof-of-work and the arrow of time in Physics.  It may seem a digression, but please, bear with me.\n\nProof-of-work proves that work was performed, and (crucially) that this work was done in the past.\n\nThis is important because of the arrow of time.\n\nIn principle, every physical interaction is reversible.  Visualize a video of two indivisible particles.  The two particles move towards each other, collide, and because of the collision, fly apart. If you ran this video in reverse, or in forward, it would not be distinguishable to you, as an outside observer, whether the video was running in reverse or not.  It seems at some level, time does not exist.\n\nAnd yet time exists.\n\nConsider another video, that of a vase being dropped on a hard surface.  The vase hits the surface and shatters.  Played in reverse, we can judge it as nonsensical: scattered pieces of ceramic spontaneously forming a vase and then flying upwards.  This orients our arrow of time: the arrow of time points from states of the universe where lesser entropy exists (the vase is whole) to where greater entropy exists (the vase is in many pieces).\n\nIndeed, all measures of time are, directly or indirectly, measures of increases in entropy.  Consider a simple hourglass: you place it into a state of low entropy and high energy with most of the sand is in the upper part of the hourglass.  As sand falls, and more of that energy is lost into entropy, you judge that time passes.\n\nConsider a proof-of-work algorithm: you place electrons into a state of low entropy and high energy.  As electrons go through the mining hardware, producing hashes that pass the difficulty requirement, the energy in those electrons is lost into entropy (heat), and from the hashes produced (which proves not only that work was done, but in particular, that entropy increased due to work being done), you judge that time passes.\n\n--\n\nThus, the blockchain itself is already a service that provides a measure of time.  When a block commits to a transaction, then that transaction is known to have existed at that block height, at the latest.\n\nThus one idea, is to have each block commit to some view of the mempool.  If a transaction exists in this mempool-view, then you know that the transaction is at least that old, and can judge the age from this and use this to compute the \"transaction priority\".\n\nUnfortunately, transferring the data to prove that the mempool-view is valid, is equivalent to always sweeping the entire mempool contents per block.  In that case you might as well not have a block size limit.\n\nIn addition, miners may still commit to a falsely-empty mempool and deny that your transaction is old and therefore priority and therefore will simply fill their blocks with transactions that have high feerates rather than high priority.  Thus feerate will still be the ultimate measure.\n\nRather than attempt this, perhaps developers should be encouraged to make use of existing mechanisms, RBF and CPFP, to allow transactions to be sped up by directly manipulating feerates, as priority (by your measure) is not practically computable.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171226/61caf1d1/attachment.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-27T12:29:41",
                "message_text_only": "Good evening ZmnSCPxj,\n\n\nThat you for your considered discussion.\n\n\nAm I wrong to think that any fullnode can validate blocks conform to a probability distribution? In my understanding after adoption of the proposal, any full node could validate all properties that a block has that they now validate, apart from block size, and additionally that the block conforms to a probability distribution. It seems a yes-no result. Let us assume that such a probability distribution exists since the input is a probability.\n\nBefore or after the proposal, miners could falsify transactions if there is a feasible way for them to do this. The introduction of the proposal does not change that fact. At the moment the incentive to falsify transactions is to fill blocks so that real transactions must pay the highest possible fees in the auction for limited transaction bandwidth resulting in a net gain for miners. Simply making bigger blocks serves no economic purpose in itself, since the miners we presume must pay the fees for their falsified transactions, there is no net gain, the fee will be distributed through the pool. Unless, by miners, I may presume we mostly mean mining pools and collusion. Still, where is the gain? It is only the blocks that will be larger with no economic advantage.\n\nIn a fee for priority service auction, there is always limited space in each new block since it represents only a small fraction of the size of the mempool. Presenting fraudulent transactions at the bottom end of the scale has limited effect on the cost of being near the front of the queue, at priority. As the fraudulent transactions age they would be included in blocks presuming the fee is above dust level, but the block size would grow to accommodate them since the valid mempool is larger. The auction for priority still continues uninterrupted at the top of the priority curve. There is nothing stopping a motivated individual now from writing a script to create a million pointless dust transactions per day, flooding the mempool. Even if the fee is above dust level the proposal does not change this but, ensures transactional reliability for valid transactions.\n\nIn an idealist world, all nodes could agree on the state of the mempool. I agree, there is no feasible way currently to hold the mempool to consensus without a network of dedicated mempool servers. As it is, it has been suggested that all long-running nodes will have approximately a similar view of the mempool. Sweeping the entire mempool contents per block would achieve what is required if there was a mempool consensus but since it will just be one node's view of the mempool that will not be the result.\n\nMy speculation is that as a result of the proposal, through increased adoption of Bitcoin over time there would, in fact, be more transactions and greater net fees paid per day. An increased value of BTC that we suppose would follow from increased usage would augment this fee value increase. It surely follows that a more stable and reliable service will have greater consumer and business acceptance, and there it follows that this is in miners financial interest.\n\nI have not considered a maxblocksize since I consider that the mempool can eventually grow infinitely in size just in valid transactions, without even any fraudulent transactions. I suppose that in time it will become necessary to start all new nodes in pruned mode by default due to the onerous storage requirements of the full blockchain. I do not think that the proposed changes alter this.\n\nI am sure that there is much more to write.\n\nRegards,\nDamian Williamson\n\n\n\n________________________________\nFrom: ZmnSCPxj <ZmnSCPxj at protonmail.com>\nSent: Wednesday, 27 December 2017 2:55 PM\nTo: Damian Williamson\nCc: bitcoin-dev at lists.linuxfoundation.org\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\nGood morning Damian,\n\nI see you have modified your proposal to be purely driven by miners, with fullnodes not actually being able to create a strict \"yes-or-no\" answer as to block validity under your rules.  This implies that your rules cannot be enforced and that rational miners will ignore your proposal unless it brings in more money for them.  The fact that your proposal provides some mechanism to increase block size means that miners will be incentivized to falsify data (by making up their own transactions just above your fixed \"dust size\" threshhold whatever that threshhold may be -- and remember, miners get at least 12.5 BTC per block, so they can make a lot of little falsified transactions to justify every block size increase) until the block size increase per block is the maximum possible block size increase.\n\n\n\n--\n\nLet me then explain proof-of-work and the arrow of time in Physics.  It may seem a digression, but please, bear with me.\n\nProof-of-work proves that work was performed, and (crucially) that this work was done in the past.\n\nThis is important because of the arrow of time.\n\nIn principle, every physical interaction is reversible.  Visualize a video of two indivisible particles.  The two particles move towards each other, collide, and because of the collision, fly apart. If you ran this video in reverse, or in forward, it would not be distinguishable to you, as an outside observer, whether the video was running in reverse or not.  It seems at some level, time does not exist.\n\nAnd yet time exists.\n\nConsider another video, that of a vase being dropped on a hard surface.  The vase hits the surface and shatters.  Played in reverse, we can judge it as nonsensical: scattered pieces of ceramic spontaneously forming a vase and then flying upwards.  This orients our arrow of time: the arrow of time points from states of the universe where lesser entropy exists (the vase is whole) to where greater entropy exists (the vase is in many pieces).\n\nIndeed, all measures of time are, directly or indirectly, measures of increases in entropy.  Consider a simple hourglass: you place it into a state of low entropy and high energy with most of the sand is in the upper part of the hourglass.  As sand falls, and more of that energy is lost into entropy, you judge that time passes.\n\nConsider a proof-of-work algorithm: you place electrons into a state of low entropy and high energy.  As electrons go through the mining hardware, producing hashes that pass the difficulty requirement, the energy in those electrons is lost into entropy (heat), and from the hashes produced (which proves not only that work was done, but in particular, that entropy increased due to work being done), you judge that time passes.\n\n--\n\nThus, the blockchain itself is already a service that provides a measure of time.  When a block commits to a transaction, then that transaction is known to have existed at that block height, at the latest.\n\nThus one idea, is to have each block commit to some view of the mempool.  If a transaction exists in this mempool-view, then you know that the transaction is at least that old, and can judge the age from this and use this to compute the \"transaction priority\".\n\nUnfortunately, transferring the data to prove that the mempool-view is valid, is equivalent to always sweeping the entire mempool contents per block.  In that case you might as well not have a block size limit.\n\nIn addition, miners may still commit to a falsely-empty mempool and deny that your transaction is old and therefore priority and therefore will simply fill their blocks with transactions that have high feerates rather than high priority.  Thus feerate will still be the ultimate measure.\n\nRather than attempt this, perhaps developers should be encouraged to make use of existing mechanisms, RBF and CPFP, to allow transactions to be sped up by directly manipulating feerates, as priority (by your measure) is not practically computable.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171227/9f8f65b4/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Damian Williamson",
                "ZmnSCPxj",
                "Rhavar",
                "Chris Riley",
                "Spartacus Rex"
            ],
            "messages_count": 16,
            "total_messages_chars_count": 274609
        }
    },
    {
        "title": "[bitcoin-dev] Sign / Verify message against SegWit P2SH addresses.",
        "thread_messages": [
            {
                "author": "Dan Bryant",
                "date": "2017-12-08T18:25:47",
                "message_text_only": "I know there are posts, and an issue opened against it, but is there anyone\nwriting a BIP for Sign / Verify message against a SegWit address?\n\nI realize it is not a feature in wide use, but I think it still serves an\nimportant purpose, such as when proof of assets are requested.\n\nref: https://github.com/bitcoin/bitcoin/issues/10542\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171208/3315b91a/attachment.html>"
            },
            {
                "author": "Sjors Provoost",
                "date": "2017-12-09T12:57:52",
                "message_text_only": "I would like to see this specifically for P2SH-PWPKH and/or native SegWit bech32 addresses.\n\nUse cases I can think of are \"I'm the whale in charge of these funds, listen to me\" and some form of polling.\n\nIt's nice if funds aren't excluded from these type of functionalities just because they have a complicated redeem script. So something more generic like the Elements implementation / suggestion Greg Maxwell referred to in the Github thread would be nice too.\n\nIs it also useful or possible to sign a message proving you are able to redeem some arbitrary branch in a MAST-like tree of scripts? What about being a minority part of a multisig?\n\nAll these features have privacy trade-offs, as well as perhaps security trade-offs, e.g. when you reveal a public key that was otherwise hidden behind a hash (i.e. if someone were to break secp256k1, they'd first organize a popular poll).\n\nThere's no BIP for the current message signing mechanism either afaik.\n\nSjors\n\n> Op 8 dec. 2017, om 19:25 heeft Dan Bryant via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:\n> \n> I know there are posts, and an issue opened against it, but is there anyone writing a BIP for Sign / Verify message against a SegWit address?\n> \n> I realize it is not a feature in wide use, but I think it still serves an important purpose, such as when proof of assets are requested.\n> \n> ref: https://github.com/bitcoin/bitcoin/issues/10542 <https://github.com/bitcoin/bitcoin/issues/10542>\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171209/621ffb05/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171209/621ffb05/attachment.sig>"
            },
            {
                "author": "Pavol Rusnak",
                "date": "2017-12-19T21:36:45",
                "message_text_only": "On 08/12/17 19:25, Dan Bryant via bitcoin-dev wrote:\n> I know there are posts, and an issue opened against it, but is there\n> anyone writing a BIP for Sign / Verify message against a SegWit address?\n\nDan, are you still planning to write this BIP?\n\n-- \nBest Regards / S pozdravom,\n\nPavol \"stick\" Rusnak\nCTO, SatoshiLabs"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-12-19T21:58:40",
                "message_text_only": "For what it\u2019s worth, I think it would be quite easy to do better than the implied solution of rejiggering the message signing system to support non-P2PKH scripts. Instead, have the signature be an actual bitcoin transaction with inputs that have the script being signed. Use the salted hash of the message being signed as the FORKID as if this were a spin-off with replay protection. This accomplishes three things:\n\n(1) This enables signing by any infrastructure out there \u2014 including hardware wallets and 2FA signing services \u2014 that have enabled support for FORKID signing, which is a wide swath of the ecosystem because of Bitcoin Cash and Bitcoin Gold.\n\n(2) It generalizes the message signing to allow multi-party signing setups as complicated (via sighash, etc.) as those bitcoin transactions allow, using existing and future tools based on Partially Signed Bitcoin Transactions; and\n\n(3) It unifies a single approach for message signing, proof of reserve (where the inputs are actual UTXOs), and off-chain colored coins.\n\nThere\u2019s the issue of size efficiency, but for the single-party message signing application that can be handled by a BIP that specifies a template for constructing the pseudo-transaction and its inputs from a raw script.\n\nMark\n\n> On Dec 19, 2017, at 1:36 PM, Pavol Rusnak via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> On 08/12/17 19:25, Dan Bryant via bitcoin-dev wrote:\n>> I know there are posts, and an issue opened against it, but is there\n>> anyone writing a BIP for Sign / Verify message against a SegWit address?\n> \n> Dan, are you still planning to write this BIP?\n> \n> -- \n> Best Regards / S pozdravom,\n> \n> Pavol \"stick\" Rusnak\n> CTO, SatoshiLabs\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-21T11:19:52",
                "message_text_only": "In all seriousness, being able to sign a message is an important feature whether it is with Bitcoin Core or, with some other method. It is a good feature and it would be worthwhile IMHO to update it for SegWit addresses. I don't know about renewing it altogether, I like the current simplicity.\n\n\nRegards,\n\nDamian Williamson\n\n\n------------------------------------\n\nSometimes I like to sign a message just to verify that is what I have said.\n\n-\n\nBitcoin: 1PMUf9aaQ41M4bgVbCAPVwAeuKvj8CwxJg\n\n------------------------------------\n\nSignature:\nHwJPqyWF0CbdsR7x737HbNIDoRufsrMI5XYQsKZ+MrWCJ6K7imtLY00sTCmSMDigZxRuoxyYZyQUw/lL0m/MV9M=\n\n(Of course, signed messages will verify better usually with plain text and not HTML interpreted email - need a switch for outlook.com to send plaintext.)\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Mark Friedenbach via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Wednesday, 20 December 2017 8:58 AM\nTo: Pavol Rusnak; Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] Sign / Verify message against SegWit P2SH addresses.\n\nFor what it\u2019s worth, I think it would be quite easy to do better than the implied solution of rejiggering the message signing system to support non-P2PKH scripts. Instead, have the signature be an actual bitcoin transaction with inputs that have the script being signed. Use the salted hash of the message being signed as the FORKID as if this were a spin-off with replay protection. This accomplishes three things:\n\n(1) This enables signing by any infrastructure out there \u2014 including hardware wallets and 2FA signing services \u2014 that have enabled support for FORKID signing, which is a wide swath of the ecosystem because of Bitcoin Cash and Bitcoin Gold.\n\n(2) It generalizes the message signing to allow multi-party signing setups as complicated (via sighash, etc.) as those bitcoin transactions allow, using existing and future tools based on Partially Signed Bitcoin Transactions; and\n\n(3) It unifies a single approach for message signing, proof of reserve (where the inputs are actual UTXOs), and off-chain colored coins.\n\nThere\u2019s the issue of size efficiency, but for the single-party message signing application that can be handled by a BIP that specifies a template for constructing the pseudo-transaction and its inputs from a raw script.\n\nMark\n\n> On Dec 19, 2017, at 1:36 PM, Pavol Rusnak via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> On 08/12/17 19:25, Dan Bryant via bitcoin-dev wrote:\n>> I know there are posts, and an issue opened against it, but is there\n>> anyone writing a BIP for Sign / Verify message against a SegWit address?\n>\n> Dan, are you still planning to write this BIP?\n>\n> --\n> Best Regards / S pozdravom,\n>\n> Pavol \"stick\" Rusnak\n> CTO, SatoshiLabs\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/2ae67657/attachment.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-12-21T16:29:13",
                "message_text_only": "It doesn\u2019t matter what it does under the hood. The api could be the same.\n\n> On Dec 21, 2017, at 3:19 AM, Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> In all seriousness, being able to sign a message is an important feature whether it is with Bitcoin Core or, with some other method. It is a good feature and it would be worthwhile IMHO to update it for SegWit addresses. I don't know about renewing it altogether, I like the current simplicity.\n> \n> Regards,\n> Damian Williamson\n> \n> ------------------------------------\n> Sometimes I like to sign a message just to verify that is what I have said.\n> -\n> Bitcoin: 1PMUf9aaQ41M4bgVbCAPVwAeuKvj8CwxJg\n> ------------------------------------\n> Signature:\n> HwJPqyWF0CbdsR7x737HbNIDoRufsrMI5XYQsKZ+MrWCJ6K7imtLY00sTCmSMDigZxRuoxyYZyQUw/lL0m/MV9M=\n> \n> (Of course, signed messages will verify better usually with plain text and not HTML interpreted email - need a switch for outlook.com to send plaintext.)\n> From: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Mark Friedenbach via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n> Sent: Wednesday, 20 December 2017 8:58 AM\n> To: Pavol Rusnak; Bitcoin Protocol Discussion\n> Subject: Re: [bitcoin-dev] Sign / Verify message against SegWit P2SH addresses.\n>  \n> For what it\u2019s worth, I think it would be quite easy to do better than the implied solution of rejiggering the message signing system to support non-P2PKH scripts. Instead, have the signature be an actual bitcoin transaction with inputs that have the script being signed. Use the salted hash of the message being signed as the FORKID as if this were a spin-off with replay protection. This accomplishes three things:\n> \n> (1) This enables signing by any infrastructure out there \u2014 including hardware wallets and 2FA signing services \u2014 that have enabled support for FORKID signing, which is a wide swath of the ecosystem because of Bitcoin Cash and Bitcoin Gold.\n> \n> (2) It generalizes the message signing to allow multi-party signing setups as complicated (via sighash, etc.) as those bitcoin transactions allow, using existing and future tools based on Partially Signed Bitcoin Transactions; and\n> \n> (3) It unifies a single approach for message signing, proof of reserve (where the inputs are actual UTXOs), and off-chain colored coins.\n> \n> There\u2019s the issue of size efficiency, but for the single-party message signing application that can be handled by a BIP that specifies a template for constructing the pseudo-transaction and its inputs from a raw script.\n> \n> Mark\n> \n> > On Dec 19, 2017, at 1:36 PM, Pavol Rusnak via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > \n> > On 08/12/17 19:25, Dan Bryant via bitcoin-dev wrote:\n> >> I know there are posts, and an issue opened against it, but is there\n> >> anyone writing a BIP for Sign / Verify message against a SegWit address?\n> > \n> > Dan, are you still planning to write this BIP?\n> > \n> > -- \n> > Best Regards / S pozdravom,\n> > \n> > Pavol \"stick\" Rusnak\n> > CTO, SatoshiLabs\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/0ae39224/attachment-0001.html>"
            },
            {
                "author": "Jason Dreyzehner",
                "date": "2017-12-21T17:23:49",
                "message_text_only": "You might be interested in this proposal, which is very similar. The repo\ncontains a very basic implementation in typescript:\nhttps://github.com/bitauth/bitauth2017/blob/master/bips/0-bitauth.mediawiki\n\nhttps://github.com/bitauth/bitauth2017/\n\nOn Tue, Dec 19, 2017 at 4:59 PM Mark Friedenbach via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> For what it\u2019s worth, I think it would be quite easy to do better than the\n> implied solution of rejiggering the message signing system to support\n> non-P2PKH scripts. Instead, have the signature be an actual bitcoin\n> transaction with inputs that have the script being signed. Use the salted\n> hash of the message being signed as the FORKID as if this were a spin-off\n> with replay protection. This accomplishes three things:\n>\n> (1) This enables signing by any infrastructure out there \u2014 including\n> hardware wallets and 2FA signing services \u2014 that have enabled support for\n> FORKID signing, which is a wide swath of the ecosystem because of Bitcoin\n> Cash and Bitcoin Gold.\n>\n> (2) It generalizes the message signing to allow multi-party signing setups\n> as complicated (via sighash, etc.) as those bitcoin transactions allow,\n> using existing and future tools based on Partially Signed Bitcoin\n> Transactions; and\n>\n> (3) It unifies a single approach for message signing, proof of reserve\n> (where the inputs are actual UTXOs), and off-chain colored coins.\n>\n> There\u2019s the issue of size efficiency, but for the single-party message\n> signing application that can be handled by a BIP that specifies a template\n> for constructing the pseudo-transaction and its inputs from a raw script.\n>\n> Mark\n>\n> > On Dec 19, 2017, at 1:36 PM, Pavol Rusnak via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >\n> > On 08/12/17 19:25, Dan Bryant via bitcoin-dev wrote:\n> >> I know there are posts, and an issue opened against it, but is there\n> >> anyone writing a BIP for Sign / Verify message against a SegWit address?\n> >\n> > Dan, are you still planning to write this BIP?\n> >\n> > --\n> > Best Regards / S pozdravom,\n> >\n> > Pavol \"stick\" Rusnak\n> > CTO, SatoshiLabs\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/d296ba4f/attachment.html>"
            },
            {
                "author": "Dan Bryant",
                "date": "2017-12-21T22:22:58",
                "message_text_only": "legacy message sign verify BIP to get the ball rolling.\n\nearly draft:\nhttps://github.com/brianddk/bips/blob/legacysignverify/bip-0xyz.mediawiki\n\nOn Tue, Dec 19, 2017 at 3:36 PM, Pavol Rusnak <stick at satoshilabs.com> wrote:\n\n> On 08/12/17 19:25, Dan Bryant via bitcoin-dev wrote:\n> > I know there are posts, and an issue opened against it, but is there\n> > anyone writing a BIP for Sign / Verify message against a SegWit address?\n>\n> Dan, are you still planning to write this BIP?\n>\n> --\n> Best Regards / S pozdravom,\n>\n> Pavol \"stick\" Rusnak\n> CTO, SatoshiLabs\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/ce3abe15/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Sign / Verify message against SegWit P2SH addresses.",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jason Dreyzehner",
                "Dan Bryant",
                "Pavol Rusnak",
                "Damian Williamson",
                "Sjors Provoost",
                "Mark Friedenbach"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 15635
        }
    },
    {
        "title": "[bitcoin-dev] BIP - Dead Man's Switch",
        "thread_messages": [
            {
                "author": "Teweldemedhin Aberra",
                "date": "2017-12-11T17:30:37",
                "message_text_only": "It is estimated that about 4 million of the about 16.4 Bitcoins ever mined\nare lost forever because no one knows the private keys of some Bitcoin\naddresses. This effectively mean there are actually only 14.4 million\nBitcoins in circulation even though 16.4 million are mined. There is no way\nof eliminating the human errors that cause these losses of Bitcoin from\ncirculation, while the number of Bitcoin that will ever be mined is capped\nat 21 million. This means the total number of Bitcoins that are in\ncirculation will eventually become zero, bringing the network to an end.\n\nThe solution this BIP proposes is to implementing a dead man's switch to\nBitcoin addresses. The dead man's switch causes the Bitcoins assigned to\ndormant addresses to automatically expire. A Bitcoin address is deemed\ndormant if it is not used in transactions for some fixed length of time,\nsay ten years.\n\nThe calculation of the miner's reward should take into account the Bitcoins\nthat has expired. This means there is a possibility that miner's reward can\nincrease if sufficient number of Bitcoins expire.\n\nRef:\n\nhttp://fortune.com/2017/11/25/lost-bitcoins/\n\n\n<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>\nVirus-free.\nwww.avast.com\n<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>\n<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/b24d6834/attachment.html>"
            },
            {
                "author": "Douglas Roark",
                "date": "2017-12-11T18:12:02",
                "message_text_only": "With all due respect, this isn't a BIP. It's idle speculation regarding\nwhat one person considers to be a problem and others may not. Please\nread https://github.com/bitcoin/bips/blob/master/bip-0001.mediawiki and\ntry again. Among other things:\n\n- Convince us this is a real issue, and that your data is accurate.\nWho's to say which coins are truly lost? Maybe the people controlling\nthe keys are just laying low, wish to use their coins in 2112, etc.\n- Propose formulas for how the miners will take everything into account,\nand explain why they're acceptable.\n- Write code that implements your ideas.\n\nGood luck!\n\n-- \n---\nDouglas Roark\nCryptocurrency, network security, travel, and art.\nhttps://onename.com/droark\njoroark at vt.edu\nPGP key ID: 26623924\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 895 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/de37c9f0/attachment.sig>"
            },
            {
                "author": "Nick Pudar",
                "date": "2017-12-11T18:12:05",
                "message_text_only": "This topic has come up several times in recent years. While it is well intentioned, it can have devastating outcomes for people that want to save long term. If such a system were implemented, it would force people to move funds around in order to not get nullified. In that process, it introduces multiple opportunities for errors. Cold storage should be able to stay cold. I personally would be apprehensive about implementing this kind of a system.\n\n...via Android\n\n\n\nFrom: Teweldemedhin Aberra via bitcoin-dev\nSent: Monday, December 11, 1:04 PM\nSubject: [bitcoin-dev] BIP - Dead Man's Switch\nTo: bitcoin-dev at lists.linuxfoundation.org\n\n\nIt is estimated that about 4 million of the about 16.4 Bitcoins ever mined are lost forever because no one knows the private keys of some Bitcoin addresses. This effectively mean there are actually only 14.4 million Bitcoins in circulation even though 16.4 million are mined. There is no way of eliminating the human errors that cause these losses of Bitcoin from circulation, while the number of Bitcoin that will ever be mined is capped at 21 million. This means the total number of Bitcoins that are in circulation will eventually become zero, bringing the network to an end.\nThe solution this BIP proposes is to implementing a dead man's switch to Bitcoin addresses. The dead man's switch causes the Bitcoins assigned to dormant addresses to automatically expire. A Bitcoin address is deemed dormant if it is not used in transactions for some fixed length of time, say ten years.\nThe calculation of the miner's reward should take into account the Bitcoins that has expired. This means there is a possibility that miner's reward can increase if sufficient number of Bitcoins expire.\n\nRef:\nhttp://fortune.com/2017/11/25/lost-bitcoins/\n\n\nVirus-free.\n        <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>\nwww.avast.com\n\n\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/37a24fc9/attachment-0001.html>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2017-12-11T18:26:40",
                "message_text_only": "On Dec 11, 2017 10:23, \"Nick Pudar via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\nThis topic has come up several times in recent years. While it is well\nintentioned, it can have devastating outcomes for people that want to save\nlong term. If such a system were implemented, it would force people to move\nfunds around in order to not get nullified. In that process, it introduces\nmultiple opportunities for errors. Cold storage should be able to stay\ncold. I personally would be apprehensive about implementing this kind of a\nsystem.\n\n\nFurthermore, if it rewards miners with funds that are expired, it creates\nterrible incentives. Miners in their best interest could choose to censor\ntransactions that move funds close to their expiration time, to increase\ntheir own future rewards.\n\nCheers,\n\n-- \nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/e43f4baa/attachment.html>"
            },
            {
                "author": "Radoslaw Biernacki",
                "date": "2017-12-11T18:13:26",
                "message_text_only": "Aside from that such change would require a hard fork it also violates one\nof basic rules of bitcoin, which has long term consequences for miners and\nfor whole Bitcoin economy. In short, after altering the supply limit it\nwould not be \"bitcoin\" anymore.\n\nOn Mon, Dec 11, 2017 at 6:30 PM, Teweldemedhin Aberra via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> It is estimated that about 4 million of the about 16.4 Bitcoins ever mined\n> are lost forever because no one knows the private keys of some Bitcoin\n> addresses. This effectively mean there are actually only 14.4 million\n> Bitcoins in circulation even though 16.4 million are mined. There is no way\n> of eliminating the human errors that cause these losses of Bitcoin from\n> circulation, while the number of Bitcoin that will ever be mined is capped\n> at 21 million. This means the total number of Bitcoins that are in\n> circulation will eventually become zero, bringing the network to an end.\n>\n> The solution this BIP proposes is to implementing a dead man's switch to\n> Bitcoin addresses. The dead man's switch causes the Bitcoins assigned to\n> dormant addresses to automatically expire. A Bitcoin address is deemed\n> dormant if it is not used in transactions for some fixed length of time,\n> say ten years.\n>\n> The calculation of the miner's reward should take into account the\n> Bitcoins that has expired. This means there is a possibility that miner's\n> reward can increase if sufficient number of Bitcoins expire.\n>\n> Ref:\n>\n> http://fortune.com/2017/11/25/lost-bitcoins/\n>\n>\n>\n> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon> Virus-free.\n> www.avast.com\n> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>\n> <#m_-612306741899295358_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/82180950/attachment.html>"
            },
            {
                "author": "Chris Riley",
                "date": "2017-12-11T18:28:03",
                "message_text_only": "Hi,\n1. If there are 16.4 million mined and 4 million are lost, that results in\n12.4 million in circulation vs 14.4 million.\n2. Satoshi addressed this as have numerous other people (\nhttps://bitcointalk.org/index.php?topic=198.msg1647#msg1647 ) - lost coins\ndecrease supply, increasing value of the remaining coins.\n3. This assumes this is a problem.  Bitcoin is divisible, 100 million,\npotentially more if necessary. (\nhttps://en.bitcoin.it/wiki/Help:FAQ#How_divisible_are_bitcoins.3F)\n4. Why is it okay to steal bitcoins from people who's bitcoins have been\n\"dormant\" for a fixed period, 10 years in your example?\n5. What happens to bitcoins that, say, Hal Finney still had (if any) and he\nput in cold storage while he is in ultimate cold storage (\nhttps://en.wikipedia.org/wiki/Hal_Finney_(computer_scientist)#Death) ?\nDitto for someone, say, in a coma for 11 years, in jail for 11 years or any\nother similar event?  Or a 20 year old sets aside coins for retirement.\nThe following year, the system is changed, and when he looks again after\nnot paying attention for a decade or two, they are gone.\n6. This encourages censorship by miners for people attempting to move coins.\n7. This has been discussed many times before and everyone is welcome to\nfork bitcoin code and the block chain and convince people to follow this\nchain and code.  Then you can see if you can get many people to agree that\nthis is a good idea.\n\n\n\n\n\n\n\n\nOn Mon, Dec 11, 2017 at 12:30 PM, Teweldemedhin Aberra via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> It is estimated that about 4 million of the about 16.4 Bitcoins ever mined\n> are lost forever because no one knows the private keys of some Bitcoin\n> addresses. This effectively mean there are actually only 14.4 million\n> Bitcoins in circulation even though 16.4 million are mined. There is no way\n> of eliminating the human errors that cause these losses of Bitcoin from\n> circulation, while the number of Bitcoin that will ever be mined is capped\n> at 21 million. This means the total number of Bitcoins that are in\n> circulation will eventually become zero, bringing the network to an end.\n>\n> The solution this BIP proposes is to implementing a dead man's switch to\n> Bitcoin addresses. The dead man's switch causes the Bitcoins assigned to\n> dormant addresses to automatically expire. A Bitcoin address is deemed\n> dormant if it is not used in transactions for some fixed length of time,\n> say ten years.\n>\n> The calculation of the miner's reward should take into account the\n> Bitcoins that has expired. This means there is a possibility that miner's\n> reward can increase if sufficient number of Bitcoins expire.\n>\n> Ref:\n>\n> http://fortune.com/2017/11/25/lost-bitcoins/\n>\n>\n>\n> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon> Virus-free.\n> www.avast.com\n> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>\n> <#m_2495265241835744459_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/bae02d55/attachment-0001.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2017-12-11T18:34:12",
                "message_text_only": "You can implement this already, but only for ~1 year expirations.\n\nIF <normal script> ELSE <1 year> CHECKSEQUENCEVERIFY ENDIF\n\nPerhaps it would make sense to propose a flag extending the range of relative \nlock-times so you can do several years?\n\nLuke\n\n\nOn Monday 11 December 2017 5:30:37 PM Teweldemedhin Aberra via bitcoin-dev \nwrote:\n> It is estimated that about 4 million of the about 16.4 Bitcoins ever mined\n> are lost forever because no one knows the private keys of some Bitcoin\n> addresses. This effectively mean there are actually only 14.4 million\n> Bitcoins in circulation even though 16.4 million are mined. There is no way\n> of eliminating the human errors that cause these losses of Bitcoin from\n> circulation, while the number of Bitcoin that will ever be mined is capped\n> at 21 million. This means the total number of Bitcoins that are in\n> circulation will eventually become zero, bringing the network to an end.\n> \n> The solution this BIP proposes is to implementing a dead man's switch to\n> Bitcoin addresses. The dead man's switch causes the Bitcoins assigned to\n> dormant addresses to automatically expire. A Bitcoin address is deemed\n> dormant if it is not used in transactions for some fixed length of time,\n> say ten years.\n> \n> The calculation of the miner's reward should take into account the Bitcoins\n> that has expired. This means there is a possibility that miner's reward can\n> increase if sufficient number of Bitcoins expire.\n> \n> Ref:\n> \n> http://fortune.com/2017/11/25/lost-bitcoins/\n> \n> \n> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campa\n> ign=sig-email&utm_content=webmail&utm_term=icon> Virus-free.\n> www.avast.com\n> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campa\n> ign=sig-email&utm_content=webmail&utm_term=link>\n> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>"
            },
            {
                "author": "Teweldemedhin Aberra",
                "date": "2017-12-12T01:10:38",
                "message_text_only": "Hi,\nThe only solution other than Dead Man's Switch to avoid gradual loss\nBitcoins in transaction is increasing the divisibiliy of Bitcoins. Then\nBitcoin values will need integer of more than 64 bits. Could that be done\nwith soft fork?\n\nOn Dec 11, 2017 9:42 PM, <bitcoin-dev-request at lists.linuxfoundation.org>\nwrote:\n\n> You can implement this already, but only for ~1 year expirations.\n>\n> IF <normal script> ELSE <1 year> CHECKSEQUENCEVERIFY ENDIF\n>\n> Perhaps it would make sense to propose a flag extending the range of\n> relative\n> lock-times so you can do several years?\n>\n> Luke\n>\n>\n> On Monday 11 December 2017 5:30:37 PM Teweldemedhin Aberra via bitcoin-dev\n> wrote:\n> > It is estimated that about 4 million of the about 16.4 Bitcoins ever\n> mined\n> > are lost forever because no one knows the private keys of some Bitcoin\n> > addresses. This effectively mean there are actually only 14.4 million\n> > Bitcoins in circulation even though 16.4 million are mined. There is no\n> way\n> > of eliminating the human errors that cause these losses of Bitcoin from\n> > circulation, while the number of Bitcoin that will ever be mined is\n> capped\n> > at 21 million. This means the total number of Bitcoins that are in\n> > circulation will eventually become zero, bringing the network to an end.\n> >\n> > The solution this BIP proposes is to implementing a dead man's switch to\n> > Bitcoin addresses. The dead man's switch causes the Bitcoins assigned to\n> > dormant addresses to automatically expire. A Bitcoin address is deemed\n> > dormant if it is not used in transactions for some fixed length of time,\n> > say ten years.\n> >\n> > The calculation of the miner's reward should take into account the\n> Bitcoins\n> > that has expired. This means there is a possibility that miner's reward\n> can\n> > increase if sufficient number of Bitcoins expire.\n> >\n> > Ref:\n> >\n> > http://fortune.com/2017/11/25/lost-bitcoins/\n> >\n> >\n> > <https://www.avast.com/sig-email?utm_medium=email&utm_\n> source=link&utm_campa\n> > ign=sig-email&utm_content=webmail&utm_term=icon> Virus-free.\n> > www.avast.com\n> > <https://www.avast.com/sig-email?utm_medium=email&utm_\n> source=link&utm_campa\n> > ign=sig-email&utm_content=webmail&utm_term=link>\n> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171212/b54aa852/attachment.html>"
            },
            {
                "author": "Ricardo Filipe",
                "date": "2017-12-12T14:02:12",
                "message_text_only": "You can do it on 2nd layer solutions such as the lightning network,\nwith their own format.\nOn the base layer you cannot do it without a hard fork, or it would\nundermine the invariants of bitcoin.\n\n2017-12-12 8:24 GMT+00:00 Teweldemedhin Aberra <teweldemat at gmail.com>:\n> How?\n>\n>\n>\n> From: Ricardo Filipe\n> Sent: Tuesday, December 12, 2017 4:44 AM\n> To: Teweldemedhin Aberra; Bitcoin Protocol Discussion\n> Subject: Re: [bitcoin-dev] BIP - Dead Man's Switch\n>\n>\n>\n> yes\n>\n>\n>\n> 2017-12-12 1:10 GMT+00:00 Teweldemedhin Aberra via bitcoin-dev\n>\n> <bitcoin-dev at lists.linuxfoundation.org>:\n>\n>> Hi,\n>\n>> The only solution other than Dead Man's Switch to avoid gradual loss\n>\n>> Bitcoins in transaction is increasing the divisibiliy of Bitcoins. Then\n>\n>> Bitcoin values will need integer of more than 64 bits. Could that be done\n>\n>> with soft fork?\n>\n>>\n>\n>> On Dec 11, 2017 9:42 PM, <bitcoin-dev-request at lists.linuxfoundation.org>\n>\n>> wrote:\n>\n>>>\n>\n>>> You can implement this already, but only for ~1 year expirations.\n>\n>>>\n>\n>>> IF <normal script> ELSE <1 year> CHECKSEQUENCEVERIFY ENDIF\n>\n>>>\n>\n>>> Perhaps it would make sense to propose a flag extending the range of\n>\n>>> relative\n>\n>>> lock-times so you can do several years?\n>\n>>>\n>\n>>> Luke\n>\n>>>\n>\n>>>\n>\n>>> On Monday 11 December 2017 5:30:37 PM Teweldemedhin Aberra via\n>>> bitcoin-dev\n>\n>>> wrote:\n>\n>>> > It is estimated that about 4 million of the about 16.4 Bitcoins ever\n>\n>>> > mined\n>\n>>> > are lost forever because no one knows the private keys of some Bitcoin\n>\n>>> > addresses. This effectively mean there are actually only 14.4 million\n>\n>>> > Bitcoins in circulation even though 16.4 million are mined. There is no\n>\n>>> > way\n>\n>>> > of eliminating the human errors that cause these losses of Bitcoin from\n>\n>>> > circulation, while the number of Bitcoin that will ever be mined is\n>\n>>> > capped\n>\n>>> > at 21 million. This means the total number of Bitcoins that are in\n>\n>>> > circulation will eventually become zero, bringing the network to an\n>>> > end.\n>\n>>> >\n>\n>>> > The solution this BIP proposes is to implementing a dead man's switch\n>>> > to\n>\n>>> > Bitcoin addresses. The dead man's switch causes the Bitcoins assigned\n>>> > to\n>\n>>> > dormant addresses to automatically expire. A Bitcoin address is deemed\n>\n>>> > dormant if it is not used in transactions for some fixed length of\n>>> > time,\n>\n>>> > say ten years.\n>\n>>> >\n>\n>>> > The calculation of the miner's reward should take into account the\n>\n>>> > Bitcoins\n>\n>>> > that has expired. This means there is a possibility that miner's reward\n>\n>>> > can\n>\n>>> > increase if sufficient number of Bitcoins expire.\n>\n>>> >\n>\n>>> > Ref:\n>\n>>> >\n>\n>>> > http://fortune.com/2017/11/25/lost-bitcoins/\n>\n>>> >\n>\n>>> >\n>\n>>> >\n>\n>>> >\n>>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campa\n>\n>>> > ign=sig-email&utm_content=webmail&utm_term=icon> Virus-free.\n>\n>>> > www.avast.com\n>\n>>> >\n>\n>>> >\n>>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campa\n>\n>>> > ign=sig-email&utm_content=webmail&utm_term=link>\n>\n>>> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>\n>\n>>\n>\n>>\n>\n>> _______________________________________________\n>\n>> bitcoin-dev mailing list\n>\n>> bitcoin-dev at lists.linuxfoundation.org\n>\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>>\n>\n>"
            }
        ],
        "thread_summary": {
            "title": "BIP - Dead Man's Switch",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Nick Pudar",
                "Radoslaw Biernacki",
                "Pieter Wuille",
                "Teweldemedhin Aberra",
                "Luke Dashjr",
                "Ricardo Filipe",
                "Douglas Roark",
                "Chris Riley"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 19216
        }
    },
    {
        "title": "[bitcoin-dev] bitcoin-dev Digest, Vol 31, Issue 22",
        "thread_messages": [
            {
                "author": "Ilan Oh",
                "date": "2017-12-11T18:37:06",
                "message_text_only": "Reply to dead man's switch,\n\nSince this topic as gone un-technical,\n\nPeople can already place a timer on transactions with the script to send\nfunds if not moved for a given period,\n\nAnd people are responsible adults, trying to take ahead of every possible\nfuture human error from the protocol perspective looks more like french\nsocialism than bitcoinism\n\nLe 11 d\u00e9c. 2017 19:32, <bitcoin-dev-request at lists.linuxfoundation.org> a\n\u00e9crit :\n\nSend bitcoin-dev mailing list submissions to\n        bitcoin-dev at lists.linuxfoundation.org\n\nTo subscribe or unsubscribe via the World Wide Web, visit\n        https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\nor, via email, send a message with subject or body 'help' to\n        bitcoin-dev-request at lists.linuxfoundation.org\n\nYou can reach the person managing the list at\n        bitcoin-dev-owner at lists.linuxfoundation.org\n\nWhen replying, please edit your Subject line so it is more specific\nthan \"Re: Contents of bitcoin-dev digest...\"\n\n\nToday's Topics:\n\n   1. Re: BIP - Dead Man's Switch (Radoslaw Biernacki)\n   2. Re: BIP - Dead Man's Switch (Pieter Wuille)\n   3. Re: BIP - Dead Man's Switch (Chris Riley)\n\n\n----------------------------------------------------------------------\n\nMessage: 1\nDate: Mon, 11 Dec 2017 19:13:26 +0100\nFrom: Radoslaw Biernacki <radoslaw.biernacki at gmail.com>\nTo: Teweldemedhin Aberra <teweldemat at gmail.com>,        Bitcoin Protocol\n        Discussion <bitcoin-dev at lists.linuxfoundation.org>\nSubject: Re: [bitcoin-dev] BIP - Dead Man's Switch\nMessage-ID:\n        <CADp3C4vfL8yE4C8T5nU_qpOOLkDP+eMwM_pXmbdB0Nj0vbJHUg at mail.gmail.com>\nContent-Type: text/plain; charset=\"utf-8\"\n\nAside from that such change would require a hard fork it also violates one\nof basic rules of bitcoin, which has long term consequences for miners and\nfor whole Bitcoin economy. In short, after altering the supply limit it\nwould not be \"bitcoin\" anymore.\n\nOn Mon, Dec 11, 2017 at 6:30 PM, Teweldemedhin Aberra via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> It is estimated that about 4 million of the about 16.4 Bitcoins ever mined\n> are lost forever because no one knows the private keys of some Bitcoin\n> addresses. This effectively mean there are actually only 14.4 million\n> Bitcoins in circulation even though 16.4 million are mined. There is no\nway\n> of eliminating the human errors that cause these losses of Bitcoin from\n> circulation, while the number of Bitcoin that will ever be mined is capped\n> at 21 million. This means the total number of Bitcoins that are in\n> circulation will eventually become zero, bringing the network to an end.\n>\n> The solution this BIP proposes is to implementing a dead man's switch to\n> Bitcoin addresses. The dead man's switch causes the Bitcoins assigned to\n> dormant addresses to automatically expire. A Bitcoin address is deemed\n> dormant if it is not used in transactions for some fixed length of time,\n> say ten years.\n>\n> The calculation of the miner's reward should take into account the\n> Bitcoins that has expired. This means there is a possibility that miner's\n> reward can increase if sufficient number of Bitcoins expire.\n>\n> Ref:\n>\n> http://fortune.com/2017/11/25/lost-bitcoins/\n>\n>\n>\n> <https://www.avast.com/sig-email?utm_medium=email&utm_\nsource=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>\nVirus-free.\n> www.avast.com\n> <https://www.avast.com/sig-email?utm_medium=email&utm_\nsource=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>\n> <#m_-612306741899295358_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/\nattachments/20171211/82180950/attachment-0001.html>\n\n------------------------------\n\nMessage: 2\nDate: Mon, 11 Dec 2017 10:26:40 -0800\nFrom: Pieter Wuille <pieter.wuille at gmail.com>\nTo: Nick Pudar <nick at pudar.com>,        Bitcoin Dev\n        <bitcoin-dev at lists.linuxfoundation.org>\nSubject: Re: [bitcoin-dev] BIP - Dead Man's Switch\nMessage-ID:\n        <CAPg+sBi9nYHCcN8ct=_iqWuxDFU1cPwBfbfF8WPX-w+kf6hzfQ at mail.gmail.com>\nContent-Type: text/plain; charset=\"utf-8\"\n\nOn Dec 11, 2017 10:23, \"Nick Pudar via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\nThis topic has come up several times in recent years. While it is well\nintentioned, it can have devastating outcomes for people that want to save\nlong term. If such a system were implemented, it would force people to move\nfunds around in order to not get nullified. In that process, it introduces\nmultiple opportunities for errors. Cold storage should be able to stay\ncold. I personally would be apprehensive about implementing this kind of a\nsystem.\n\n\nFurthermore, if it rewards miners with funds that are expired, it creates\nterrible incentives. Miners in their best interest could choose to censor\ntransactions that move funds close to their expiration time, to increase\ntheir own future rewards.\n\nCheers,\n\n--\nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/\nattachments/20171211/e43f4baa/attachment-0001.html>\n\n------------------------------\n\nMessage: 3\nDate: Mon, 11 Dec 2017 13:28:03 -0500\nFrom: Chris Riley <criley at gmail.com>\nTo: Teweldemedhin Aberra <teweldemat at gmail.com>,        Bitcoin Protocol\n        Discussion <bitcoin-dev at lists.linuxfoundation.org>\nSubject: Re: [bitcoin-dev] BIP - Dead Man's Switch\nMessage-ID:\n        <CAL5BAw1ayaiD07PJ4MRqcKaXdet5KW131en69vbw5gebWTF8nA at mail.gmail.com>\nContent-Type: text/plain; charset=\"utf-8\"\n\nHi,\n1. If there are 16.4 million mined and 4 million are lost, that results in\n12.4 million in circulation vs 14.4 million.\n2. Satoshi addressed this as have numerous other people (\nhttps://bitcointalk.org/index.php?topic=198.msg1647#msg1647 ) - lost coins\ndecrease supply, increasing value of the remaining coins.\n3. This assumes this is a problem.  Bitcoin is divisible, 100 million,\npotentially more if necessary. (\nhttps://en.bitcoin.it/wiki/Help:FAQ#How_divisible_are_bitcoins.3F)\n4. Why is it okay to steal bitcoins from people who's bitcoins have been\n\"dormant\" for a fixed period, 10 years in your example?\n5. What happens to bitcoins that, say, Hal Finney still had (if any) and he\nput in cold storage while he is in ultimate cold storage (\nhttps://en.wikipedia.org/wiki/Hal_Finney_(computer_scientist)#Death) ?\nDitto for someone, say, in a coma for 11 years, in jail for 11 years or any\nother similar event?  Or a 20 year old sets aside coins for retirement.\nThe following year, the system is changed, and when he looks again after\nnot paying attention for a decade or two, they are gone.\n6. This encourages censorship by miners for people attempting to move coins.\n7. This has been discussed many times before and everyone is welcome to\nfork bitcoin code and the block chain and convince people to follow this\nchain and code.  Then you can see if you can get many people to agree that\nthis is a good idea.\n\n\n\n\n\n\n\n\nOn Mon, Dec 11, 2017 at 12:30 PM, Teweldemedhin Aberra via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> It is estimated that about 4 million of the about 16.4 Bitcoins ever mined\n> are lost forever because no one knows the private keys of some Bitcoin\n> addresses. This effectively mean there are actually only 14.4 million\n> Bitcoins in circulation even though 16.4 million are mined. There is no\nway\n> of eliminating the human errors that cause these losses of Bitcoin from\n> circulation, while the number of Bitcoin that will ever be mined is capped\n> at 21 million. This means the total number of Bitcoins that are in\n> circulation will eventually become zero, bringing the network to an end.\n>\n> The solution this BIP proposes is to implementing a dead man's switch to\n> Bitcoin addresses. The dead man's switch causes the Bitcoins assigned to\n> dormant addresses to automatically expire. A Bitcoin address is deemed\n> dormant if it is not used in transactions for some fixed length of time,\n> say ten years.\n>\n> The calculation of the miner's reward should take into account the\n> Bitcoins that has expired. This means there is a possibility that miner's\n> reward can increase if sufficient number of Bitcoins expire.\n>\n> Ref:\n>\n> http://fortune.com/2017/11/25/lost-bitcoins/\n>\n>\n>\n> <https://www.avast.com/sig-email?utm_medium=email&utm_\nsource=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>\nVirus-free.\n> www.avast.com\n> <https://www.avast.com/sig-email?utm_medium=email&utm_\nsource=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>\n> <#m_2495265241835744459_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/\nattachments/20171211/bae02d55/attachment.html>\n\n------------------------------\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n\nEnd of bitcoin-dev Digest, Vol 31, Issue 22\n*******************************************\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/f7f49918/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "bitcoin-dev Digest, Vol 31, Issue 22",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Ilan Oh"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 9789
        }
    },
    {
        "title": "[bitcoin-dev] \"Compressed\" headers stream",
        "thread_messages": [
            {
                "author": "Jim Posen",
                "date": "2017-12-11T20:40:00",
                "message_text_only": "I want to resurrect this thread from August/September because it seems like\na significant improvement for light clients at very little cost. From the\nmailing list, it seems like this got stalled in determining how many more\nbytes could be save in addition to the prev_block.\n\nThe ideas I've gathered from Greg Maxwell's forwarded email are:\n\n1. Omit nBits altogether and have the receiving node determine it from\nchain context.\n2. Include nBits only on headers with a height that is a multiple of 2016\nsince it does not change in between.\n3. Compress nTime to two bytes by using the bounds on allowed values from\nthe consensus rules.\n\nI propose just moving ahead with only the exclusion of the prev_block, as\nIMO the other savings are not worth the added complexity.\n\nFirstly, I don't like the idea of making the net header encoding dependent\non the specific header validation rules that Bitcoin uses (eg. the fact\nthat difficulty is only recalculated every 2016 blocks). This would be\ncoupling together the two layers, breaking net compatibility for some alts,\nand possibly making consensus rule changes even more difficult for a\nsavings with insufficient benefit. So if you buy that argument, I'm not in\nfavor of #2 or #3.\n\nOption 1 is still viable, though it has some downsides. The implementation\nleaks into the validation code, whereas calculating prev_block can occur\njust at the net layer (see implementation below). Also, nodes would now be\n*required* to sync the header chain from the genesis block, whereas they\nhad the option of starting from some checkpoint before.\n\nSo switching gears, I'd like to ask what the best way to actually implement\nthis change is. Solutions I can think of are:\n\n1. New headers command name like \"cmpctheaders\" or \"headersv2\".\n2. Change serialization of existing headers message in a new protocol\nversion.\n3. Change serialization of existing headers message with new service bit.\n\nI wrote up some proof-of-concept implementations in Core a) just omitting\nprev_block\n<https://github.com/bitcoin/bitcoin/compare/master...jimpo:compact-headers>\nand b) omitting nBits as well\n<https://github.com/bitcoin/bitcoin/compare/master...jimpo:compact-headers-difficulty>.\nIf people think a) is reasonable, I'll write up a BIP.\n\n\n> Hi everyone, the Bitcoin headers are probably the most condensed and\n> important piece of data in the world, their demand is expected to grow.\n> When sending a stream of continuous block headers, a common case in IBD and\n> in disconnected clients, I think there is a possible optimization of the\n> transmitted data: The headers after the first could avoid transmitting the\n> previous hash cause the receiver could compute it by double hashing the\n> previous header (an operation he needs to do anyway to verify PoW). In a\n> long stream, for example 2016 headers, the savings in bandwidth are about\n> 32/80 ~= 40% without compressed headers 2016*80=161280 bytes with\n> compressed headers 80+2015*48=96800 bytes What do you think? In\n> OpenTimestamps calendars we are going to use this compression to give\n> lite-client a reasonable secure proofs (a full node give higher security\n> but isn't feasible in all situations, for example for in-browser\n> verification) To speed up sync of a new client Electrum starts with the\n> download of a file <https://headers.electrum.org/blockchain_headers>\n> ~36MB containing the first 477637 headers. For this kind of clients could\n> be useful a common http API with fixed position chunks to leverage http\n> caching. For example /headers/2016/0 returns the headers from the genesis\n> to the 2015 header included while /headers/2016/1 gives the headers from\n> the 2016th to the 4031. Other endpoints could have chunks of 20160 blocks\n> or 201600 such that with about 10 http requests a client could fast sync\n> the headers\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/86e7642f/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2017-12-11T21:04:01",
                "message_text_only": "On Mon, Dec 11, 2017 at 8:40 PM, Jim Posen via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Firstly, I don't like the idea of making the net header encoding dependent\n> on the specific header validation rules that Bitcoin uses (eg. the fact that\n> difficulty is only recalculated every 2016 blocks). This would be coupling\n\nIn the last proposal I recall writing up, there was a one byte flag on\neach header to indicate what was included.\n\nNbits _never_ needs to be sent even with other consensus rules because\nits more or less necessarily a strict function of the prior headers.\nThis still holds in every clone of Bitcoin I'm aware of; sending it\nwith the first header in a group probably makes sense so it can be\nchecked independently.\n\n> with insufficient benefit.\n\nanother >18% reduction in size beyond the removal of prev. is not\ninsubstantial by any means.  I don't think it should lightly be\nignored.\n\nPrev omission itself is not, sadly, magically compatible:  I am quite\nconfident that if there is a bitcoin hardfork it would recover the\nnbits/4-guarenteed always-zero bits of prev to use as extra nonce for\nminers. This has been proposed many times, implemented at least once,\nand the current requirement for mining infrastructure to reach inside\nthe coinbase txn to increment a nonce has been a reliable source of\nfailures.  So I think we'd want to have the encoding able to encode\nleading prev bits.\n\nMany altcoins also change the header structures. If the better thing\nis altcoin incompatible, we should still do it. Doing otherwise would\ncompetitively hobble Bitcoin especially considering the frequent\nrecklessly incompetent moves made by various altcoins and the near\ntotal lack of useful novel development we've seen come out of the\nclones.\n\nProbably the most important change in a new header message wouldn't be\nthe encoding, but it would be changing the fetching mechanism so that\nheader sets could be pulled in parallel, etc.\n\nI would rather not change the serialization of existing messages,\nnodes are going to have to support speaking both messages for a long\ntime, and I think we already want a different protocol flow for\nheaders fetching in any case."
            },
            {
                "author": "Jim Posen",
                "date": "2017-12-11T21:56:08",
                "message_text_only": "On Mon, Dec 11, 2017 at 1:04 PM, Gregory Maxwell <greg at xiph.org> wrote:\n\n> On Mon, Dec 11, 2017 at 8:40 PM, Jim Posen via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > Firstly, I don't like the idea of making the net header encoding\n> dependent\n> > on the specific header validation rules that Bitcoin uses (eg. the fact\n> that\n> > difficulty is only recalculated every 2016 blocks). This would be\n> coupling\n>\n> In the last proposal I recall writing up, there was a one byte flag on\n> each header to indicate what was included.\n>\n>\nIs there a link somewhere to that proposal? The only thing I could find was\nyour forwarded email\n<https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-September/014904.html>\non\nthis thread.\n\n\n> Nbits _never_ needs to be sent even with other consensus rules because\n> its more or less necessarily a strict function of the prior headers.\n> This still holds in every clone of Bitcoin I'm aware of; sending it\n> with the first header in a group probably makes sense so it can be\n> checked independently.\n>\n> > with insufficient benefit.\n>\n> another >18% reduction in size beyond the removal of prev. is not\n> insubstantial by any means.  I don't think it should lightly be\n> ignored.\n>\n>\nOmitting nBits entirely seems reasonable, I wrote up a possible\nimplementation here\n<https://github.com/bitcoin/bitcoin/compare/master...jimpo:compact-headers-difficulty>.\nThe downside is that it is more complex because it leaks into the\nvalidation code. The extra 4 byte savings is certainly nice though.\n\n\n> Prev omission itself is not, sadly, magically compatible:  I am quite\n> confident that if there is a bitcoin hardfork it would recover the\n> nbits/4-guarenteed always-zero bits of prev to use as extra nonce for\n> miners. This has been proposed many times, implemented at least once,\n> and the current requirement for mining infrastructure to reach inside\n> the coinbase txn to increment a nonce has been a reliable source of\n> failures.  So I think we'd want to have the encoding able to encode\n> leading prev bits.\n>\n> Many altcoins also change the header structures. If the better thing\n> is altcoin incompatible, we should still do it. Doing otherwise would\n> competitively hobble Bitcoin especially considering the frequent\n> recklessly incompetent moves made by various altcoins and the near\n> total lack of useful novel development we've seen come out of the\n> clones.\n>\n> Probably the most important change in a new header message wouldn't be\n> the encoding, but it would be changing the fetching mechanism so that\n> header sets could be pulled in parallel, etc.\n>\n> I would rather not change the serialization of existing messages,\n> nodes are going to have to support speaking both messages for a long\n> time, and I think we already want a different protocol flow for\n> headers fetching in any case.\n>\n\nCan you elaborate on how parallel header fetching might work? getheaders\nrequests could probably already be pipelined, where the node requests the\nnext 2,000 headers before processing the current batch (though would make\nsense to check that they are all above min difficulty first).\n\nI'm open to more ideas on how to optimize the header download or design the\nserialization format to be more flexible, but I'm concerned that we forgo a\n40-45% bandwidth savings on the current protocol for a long time because\nsomething better might be possible later on or there might be a hard fork\nthat at some point requires another upgrade. I do recognize that supporting\nmultiple serialization formats simultaneously adds code complexity, but in\nthis case the change seems simple enough to me that the tradeoff is worth\nit.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/995788a9/attachment-0001.html>"
            },
            {
                "author": "Tier Nolan",
                "date": "2017-12-11T22:41:50",
                "message_text_only": "On Mon, Dec 11, 2017 at 9:56 PM, Jim Posen via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Omitting nBits entirely seems reasonable, I wrote up a possible\n> implementation here\n> <https://github.com/bitcoin/bitcoin/compare/master...jimpo:compact-headers-difficulty>.\n> The downside is that it is more complex because it leaks into the\n> validation code. The extra 4 byte savings is certainly nice though.\n>\n\nA compromise would be to have 1 byte indicating the difference since the\nlast header.\n\nSince the exponent doesn't use the full range you could steal bits from\nthere to indicate mode.\n\n- no change\n- mantissa offset (for small changes)\n- full difficulty\n\nThis would support any nBits rule and you say 3 of the 4 bytes.\n\n\n> Can you elaborate on how parallel header fetching might work? getheaders\n> requests could probably already be pipelined, where the node requests the\n> next 2,000 headers before processing the current batch (though would make\n> sense to check that they are all above min difficulty first).\n>\n\nI suggest adding a message where you can ask for the lowest N hashes\nbetween 2 heights on the main chain.\n\nThe reply is an array of {height, header} pairs for the N headers with the\nlowest hash in the specified range.\n\nAll peers should agree on which headers are in the array.  If there is\ndisagreement, then you can at least narrow down on which segment there is\ndisagreement.\n\nIt works kind of like a cut and choose.  You pick one segment of the ones\nhe gave you recursively.\n\nYou can ask a peer for proof for a segment between 2 headers of the form.\n\n- first header + coinbase with merkle branch\n- all headers in the segment\n\nThis proves the segment has the correct height and that all the headers\nlink up.\n\nThere is a method called \"high hash highway\" that allows compact proofs of\ntotal POW.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/76d17ddf/attachment-0001.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2017-12-11T23:11:24",
                "message_text_only": "On Mon, Dec 11, 2017 at 10:41 PM, Tier Nolan via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> There is a method called \"high hash highway\" that allows compact proofs of\n> total POW.\n\nThat provides no security without additional consensus enforced\ncommitments, so I think pretty off-topic for this discussion."
            },
            {
                "author": "Suhas Daftuar",
                "date": "2017-12-12T21:07:11",
                "message_text_only": "Hi,\n\nFirst, thanks for resurrecting this, I agree this is worth pursuing.\n\nOn Mon, Dec 11, 2017 at 4:04 PM, Gregory Maxwell via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> Nbits _never_ needs to be sent even with other consensus rules because\n> its more or less necessarily a strict function of the prior headers.\n> This still holds in every clone of Bitcoin I'm aware of; sending it\n> with the first header in a group probably makes sense so it can be\n> checked independently.\n>\n\nI think it would be nice, though, to not require the consensus-correct\ncalculation of nBits in order to process p2p messages.  For instance, I\nthink there's a use for nBits at the p2p layer for calculating the work on\na chain, which can be used as an anti-DoS measure, even without verifying\nthat the difficulty adjustments are following the consensus rules.\n\nMoreover I think it's a bit messy if the p2p layer depends on intricate\nconsensus rules in order to reconstruct a message -- either we'd need to\ninteract with existing consensus logic in a potentially new way, or we'd\nreimplement the same logic in the p2p layer, neither of which is very\ndesirable imo.\n\nBut I think we should be able to get nearly all the benefit just by\nincluding nBits in any messages where the value is ambiguous; ie we include\nit with the first header in a message, and whenever it changes from the\nprevious header's nBits.\n\nI would rather not change the serialization of existing messages,\n> nodes are going to have to support speaking both messages for a long\n> time, and I think we already want a different protocol flow for\n> headers fetching in any case.\n>\n\nI agree with this.  Specifically the way I envisioned this working is that\nwe could introduce a new 'cmpctheaders'/'getcmpcthdrs' message pair for\nsyncing using this new message type, while leaving the existing\n'headers'/'getheaders' messages unchanged.  So when communicating with\nupgraded peers, we'd never use 'getheaders' messages, and we'd only use\n'headers' messages for potentially announcing new blocks.\n\nOf course, we'll have to support the existing protocol for a long time.\nBut one downside I've discovered from deploying BIP 130, which introduced\nblock announcements via headers messages, is that overloading a 'headers'\nmessage to be either a block announcement or a response to a 'getheaders'\nmessage results in p2p-handling logic which is more complicated than it\nneeds to be.  So splitting off the headers chain-sync functionality to a\nnew message pair seems like a nice side-effect benefit, in the long run.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171212/4baa06b9/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2017-12-13T00:01:32",
                "message_text_only": "On Tue, Dec 12, 2017 at 9:07 PM, Suhas Daftuar <sdaftuar at gmail.com> wrote:\n> But I think we should be able to get nearly all the benefit just by\n> including nBits in any messages where the value is ambiguous; ie we include\n> it with the first header in a message, and whenever it changes from the\n> previous header's nBits.\n\nYes, that is what I was thinking last time we discussed it, just with\neach header include a one byte flag that lets you express:\n\nbit: meaning\n(0) if nbits is the same as last,\n(1) if timestamp is a full field or a small offset, (e.g. two bytes\ndefined as unsigned offset between the last time - 7200 and the new\ntime).\n(2,3,4) if version is the same as the last distinct value .. 7th last,\nor a new 32bit distinct value;\n(5,6) if prev is entirely there, entirely gone, first 4 bytes\nprovided, or first 8 bytes provided. (if provided they override the\ncomputed values).\n\nThat would be 7 bits in total; the 8th could be reserved or use to\nsignal \"more headers follow\" to make the encoding self-delimiting.\n\nThe downside with nbits the same as last as the optimization is that\nif we ever change consensus rules to ones where difficulty management\nworks differently it may be the case that nbits changes every block.\n\nAlternatively, nbits could get a differential encoding that could be\nopted into for small differences-- though I haven't thought much about\nit to see if a one byte difference would be that useful (e.g. can bch\ndifferences usually be expressed with one byte?)\n\nI'm kind of dubious of the consensus layer anti-dos separation:  nbits\nminimum is so low compared to the speed of a mining device, virtually\nany attack that you might do with invalid headers could still be done\nwith headers at the minimum difficulty. But I'm fully willing to\naccept that simpler is better...\n\n\n\n>> I would rather not change the serialization of existing messages,\n>> nodes are going to have to support speaking both messages for a long\n>> time, and I think we already want a different protocol flow for\n>> headers fetching in any case.\n>\n>\n> I agree with this.  Specifically the way I envisioned this working is that\n> we could introduce a new 'cmpctheaders'/'getcmpcthdrs' message pair for\n> syncing using this new message type, while leaving the existing\n> 'headers'/'getheaders' messages unchanged.  So when communicating with\n> upgraded peers, we'd never use 'getheaders' messages, and we'd only use\n> 'headers' messages for potentially announcing new blocks.\n>\n> Of course, we'll have to support the existing protocol for a long time.  But\n> one downside I've discovered from deploying BIP 130, which introduced block\n> announcements via headers messages, is that overloading a 'headers' message\n> to be either a block announcement or a response to a 'getheaders' message\n> results in p2p-handling logic which is more complicated than it needs to be.\n> So splitting off the headers chain-sync functionality to a new message pair\n> seems like a nice side-effect benefit, in the long run.\n>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2017-12-13T00:12:45",
                "message_text_only": "On Tue, Dec 12, 2017 at 9:07 PM, Suhas Daftuar <sdaftuar at gmail.com> wrote:\n> I agree with this.  Specifically the way I envisioned this working is that\n> we could introduce a new 'cmpctheaders'/'getcmpcthdrs' message pair for\n> syncing using this new message type, while leaving the existing\n> 'headers'/'getheaders' messages unchanged.  So when communicating with\n> upgraded peers, we'd never use 'getheaders' messages, and we'd only use\n> 'headers' messages for potentially announcing new blocks.\n\nThe question becomes there-- how should it work.\n\nIn an ideal world, we'd decide what peers to fetch headers from based\non a compact proof of the total work in their chains... but we cannot\nconstruct such proofs in Bitcoin today.\n\nI think that instead of that a weak heuristic is to fetch first from\nthe peers with the tip at the highest difficulty. Then work backwards.\n\nSee: https://en.bitcoin.it/wiki/User:Gmaxwell/Reverse_header-fetching_sync\n\nWhich is the inspiration for the current headers first sync, but\nwithout the reverse part because the protocol didn't permit it: you\ncan't request a linear wad of headers that come before a header. This\nis the thing I was mostly thinking of when I mentioned that we may\nwant to change the interface."
            }
        ],
        "thread_summary": {
            "title": "\"Compressed\" headers stream",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Tier Nolan",
                "Jim Posen",
                "Gregory Maxwell",
                "Suhas Daftuar"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 19433
        }
    },
    {
        "title": "[bitcoin-dev] BIP Proposal: Utilization of bits denomination",
        "thread_messages": [
            {
                "author": "Jimmy Song",
                "date": "2017-12-13T19:46:09",
                "message_text_only": "Hey all,\n\nI am proposing an informational BIP to standardize the term \"bits\". The\nterm has been around a while, but having some formal informational standard\nhelps give structure to how the term is used.\n\nhttps://github.com/jimmysong/bips/blob/unit-bias/bip-unit-bias.mediawiki\n\nEntire BIP included below (mediawiki format) for convenience.\n\nBest,\n\nJimmy\n\n----------\n\n<pre>\n    BIP: ????\n    Title: Utilization of bits denomination\n    Author: Jimmy Song <jaejoon at gmail.com>\n    Comments-URI:  https://github.com/bitcoin/bips/wiki/Comments:BIP-????\n    Status: Draft\n    Type: Informational\n    Created: 2017-12-12\n    License: BSD-2-Clause\n    License-Code: BSD-2\n</pre>\n\n== Abstract ==\nBits is presented here as the standard term for 100 (one hundred) satoshis\nor 1/1,000,000 (one one-millionth) of a bitcoin.\n\n== Motivation ==\nThe bitcoin price has grown over the years and once the price is past\n$10,000 USD or so, bitcoin amounts under $10 USD start having enough\ndecimal places that it's difficult to tell whether the user is off by a\nfactor of 10 or not. Switching the denomination to \"bits\" makes\ncomprehension easier. For example, when BTC is $15,000 USD, $10.50 is a\nsomewhat confusing 0.00067 BTC, versus 670 bits, which is a lot clearer.\n\nAdditonally, reverse comparisons are easier as 67 bits being $1 is easier\nto comprehend for most people than 0.000067 BTC being $1. Similar\ncomparisons can be made to other currencies: 1 yen being 0.8 bits, 1 won\nbeing 0.07 bits and so on.\n\nPotential benefits of utilizing \"bits\" include:\n\n# Reduce user error on small bitcoin amounts.\n# Reduce unit bias for users that want a \"whole\" bitcoin.\n# Allow easier comparisons of prices for most users.\n# Allow easier bi-directional comparisons to fiat currencies.\n# Allows all UTXO amounts to need at most 2 decimal places, which can be\neasier to handle.\n\n== Specification ==\nDefinition: 1 bit = 1/1,000,000 bitcoin.\nPlural of \"bit\" is \"bits\". The terms \"bit\" and \"bits\" are not proper nouns\nand thus should not be capitalized unless used at the start of a sentence,\netc.\n\nAll Bitcoin-denominated items are encouraged to also show the denomination\nin bits, either as the default or as an option.\n\n== Rationale ==\nAs bitcoin grows in price versus fiat currencies, it's important to give\nusers the ability to quickly and accurately calculate prices for\ntransactions, savings and other economic activities. \"Bits\" have been used\nas a denomination within the Bitcoin ecosystem for some time. The idea of\nthis BIP is to formalize this name. Additionally, \"bits\" is likely the only\nother denomination that will be needed for Bitcoin as 0.01 bit = 1 satoshi,\nmeaning that two decimal places will be sufficient to describe any current\nutxo.\n\nExisting terms used in bitcoin such as satoshi, milli-bitcoin (mBTC) and\nbitcoin (BTC) do not conflict as they operate at different orders of\nmagnitude.\n\nThe term micro-bitcoin (\u00b5BTC) can continue to exist in tandem with the term\n\"bits\".\n\n== Backwards Compatibility ==\nSoftware such as the Bitcoin Core GUI currently use the \u00b5BTC denomination\nand can continue to do so. There is no obligation to switch to \"bits\".\n\n== Copyright ==\nThis BIP is licensed under the BSD 2-clause license.\n\n== Credit ==\nIt's hard to ascertain exactly who invented the term \"bits\", but the term\nhas been around for a while and the author of this BIP does not take any\ncredit for inventing the term.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171213/83d9a519/attachment.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2017-12-13T21:36:07",
                "message_text_only": "On Wed, Dec 13, 2017 at 01:46:09PM -0600, Jimmy Song via bitcoin-dev wrote:\n> Hey all,\n> \n> I am proposing an informational BIP to standardize the term \"bits\". The\n> term has been around a while, but having some formal informational standard\n> helps give structure to how the term is used.\n> \n> https://github.com/jimmysong/bips/blob/unit-bias/bip-unit-bias.mediawiki\n\nWallets and other software is already using this term, so I think it's a\ngood idea to ensure its usage is normalized.\n\nThat said, I think the term is unnecessary and confusing given that\nmicrobitcoins provides all of the same advantages and at least two\nadditional advantages:\n\n- Microbitcoins is not a homonym for any other word in English (and\n  probably not in any other language), whereas \"bit\" and \"bits\" have\n  more than a dozen homonyms in English---some of which are quite common\n  in general currency usage, Bitcoin currency usage, or Bitcoin\n  technical usage.\n\n- Microbitcoins trains users to understand SI prefixes, allowing them to\n  easily migrate from one prefix to the next.  This will be important\n  when bitcoin prices rise to $10M USD[1] and the bits denomination has\n  the same problems the millibitcoin denomination has now, but it's also\n  useful in the short term when interacting with users who make very\n  large payments (bitcoin-scale) or very small payments\n  (nanobitcoin-scale).[2]  Maybe a table of scale can emphasize this\n  point:\n\n      Wrong (IMO):        Right (IMO):\n      ---------------     --------------\n      BTC                 BTC\n      mBTC                mBTC\n      bits                \u00b5BTC\n      nBTC                nBTC\n  \n[1] A rise in price to $10M doesn't require huge levels of growth---it\nonly requires time under the assumption that a percentage of bitcoins will\nbe lost every year due to wallet mishaps, failure to inherit bitcoins,\nand other issues that remove bitcoins from circulation.  In other words,\nit's important to remember that Bitcoin is expected to become a\ndeflationary currency and plan accordingly.\n\n[2] Although Bitcoin does not currently support committed\nnanobitcoin-scale payments in the block chain, it can be supported in a\nvariety of ways by offchain systems---including (it is hypothesized)\ntrustless systems based on probabilistic payments.\n\nThanks,\n\n-Dave\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 819 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171213/7d7cdfb6/attachment.sig>"
            },
            {
                "author": "Marcel Jamin",
                "date": "2017-12-14T08:02:44",
                "message_text_only": "On 13 December 2017 at 22:36, David A. Harding via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> - Microbitcoins is not a homonym for any other word in English (and\n>   probably not in any other language), whereas \"bit\" and \"bits\" have\n>   more than a dozen homonyms in English---some of which are quite common\n>   in general currency usage, Bitcoin currency usage, or Bitcoin\n>   technical usage.\n\nReposting /u/BashCo's post on reddit here, for visibility:\n\n---8<---------------------------------------------------------------\n\n> Before anyone says 'bits' are too confusing because it's a computer science term, here's a list of homonyms [https://en.wikipedia.org/wiki/List_of_true_homonyms] that you use every day. Homonyms are fine because our brains are able to interpret language based on context, so it's a non-argument. Also, the term 'bits' was used in reference to money long before 'bits and bytes' came along, and even before the metric system itself.\n\n> https://en.wikipedia.org/wiki/Bit_(money)\n\n> https://en.wikipedia.org/wiki/Spanish_colonial_real\n\n> 'Bits' are superior to mBTC partly because we'll need to transition to bits eventually anyways (one transition is easier than two), but more importantly, bits have two decimal places, matching the format of dozens of other major currencies.\n\n> No other currency has 8 decimal places, or even 4 decimal places. Most of them have 2. Dollars and cents, Bits and satoshis.\n\n> If people actually want this to happen, then they need to train their own brains by switching their wallets and exchange settings to bits. The shift will probably happen eventually, although the major Bitcoin denomination probably isn't going anywhere any time soon, even if the majority of people use 'bits' as a matter of habit.\n\n> 99.99 bits is currently equal to $1.63 USD.\n\n---8<---------------------------------------------------------------\n\n>\n> - Microbitcoins trains users to understand SI prefixes, allowing them to\n>   easily migrate from one prefix to the next.  This will be important\n>   when bitcoin prices rise to $10M USD[1] and the bits denomination has\n>   the same problems the millibitcoin denomination has now, but it's also\n>   useful in the short term when interacting with users who make very\n>   large payments (bitcoin-scale) or very small payments\n>   (nanobitcoin-scale).[2]  Maybe a table of scale can emphasize this\n>   point:\n>\n>       Wrong (IMO):        Right (IMO):\n>       ---------------     --------------\n>       BTC                 BTC\n>       mBTC                mBTC\n>       bits                \u00b5BTC\n>       nBTC                nBTC\n>\n\nI wouldn't expect people to type out \u00b5BTC. I think the best you can\nhope for here is uBTC. As for saying \"microbitcoins\", I can virtually\nguarantee that this will be abbreviated to \"microbits\" and/or\neventually \"bits\" anyway. Bits and sats.\n\n> [1] A rise in price to $10M doesn't require huge levels of growth---it\n> only requires time under the assumption that a percentage of bitcoins will\n> be lost every year due to wallet mishaps, failure to inherit bitcoins,\n> and other issues that remove bitcoins from circulation.  In other words,\n> it's important to remember that Bitcoin is expected to become a\n> deflationary currency and plan accordingly.\n>\n> [2] Although Bitcoin does not currently support committed\n> nanobitcoin-scale payments in the block chain, it can be supported in a\n> variety of ways by offchain systems---including (it is hypothesized)\n> trustless systems based on probabilistic payments.\n>\n> Thanks,\n>\n> -Dave\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Natanael",
                "date": "2017-12-14T22:01:09",
                "message_text_only": "Reposting /u/BashCo's post on reddit here, for visibility:\n\n---8<---------------------------------------------------------------\n\n> Before anyone says 'bits' are too confusing because it's a computer\nscience term, here's a list of homonyms [https://en.wikipedia.org/\nwiki/List_of_true_homonyms] that you use every day. Homonyms are fine\nbecause our brains are able to interpret language based on context, so it's\na non-argument.\n\n\nThis ignores the fact that there exists multiple meanings of bits *within\nthe same context*, and that beginners likely can't tell them apart.\n\nFeel free to try it yourself - talk about Bitcoin \"bits\" of a particular\nvalue with somebody who  doesn't understand Bitcoin. Then explain that the\ncryptography uses 256 bit keys. I would be surprised if you could find\nsomebody who would not be confused by that.\n\nLet's say a website says a song is 24 bits. Was that 24 bit audio\nresolution or 24 bit price? Somebody writes about 256 bit keys, are that\ntheir size or value?\n\nYou guys here can probably tell the difference. Can everybody...? Bits will\ncause confusion, because plenty of people will not be able to tell these\napart. They will not know WHEN to apply one definition or the other.\n\nhttps://www.reddit.com/r/bitcoin/comments/24m3nb/_/ch8gua7\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171214/75a7967d/attachment.html>"
            },
            {
                "author": "Clark Moody",
                "date": "2017-12-14T23:11:17",
                "message_text_only": "An alternative to \"training\" users to understand SI prefixes could be to\nmake 100 satoshi = 1 mu, spelling out the Greek letter.\n\nAlthough the Units <https://en.bitcoin.it/wiki/Units> page on the wiki has\nbeen brought up to argue against naming 10,000 satoshi = 1 finney, I would\nlike to support this designation. It seems to be gaining some popular\nsupport on Twitter & podcasts. So at $10,000 BTC/USD, 1 finney = $1.00. The\nsmallest unit of value would be 0.0001 finney = 1 satoshi. Finney has a\nnatural abbreviation as fin, and 100 mu = 1 finney.\n\nThe Units page also refers to \"bitcent\" as 0.01 BTC, but if a \"bit\" is 100\nsatoshi, then what is a \"bitcent\" in that context?\n\n/bikeshed\n\n@Natanael you're exactly right. There are already multiple uses of \"bits\"\nwithin bitcoin itself.\n\n@Sjors I don't think a redefinition of 'satoshi' is going to happen ;-)\n\n\n\n-Clark\n\nOn Thu, Dec 14, 2017 at 4:01 PM, Natanael via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> Reposting /u/BashCo's post on reddit here, for visibility:\n>\n> ---8<---------------------------------------------------------------\n>\n> > Before anyone says 'bits' are too confusing because it's a computer\n> science term, here's a list of homonyms [https://en.wikipedia.org/wiki\n> /List_of_true_homonyms] that you use every day. Homonyms are fine because\n> our brains are able to interpret language based on context, so it's a\n> non-argument.\n>\n>\n> This ignores the fact that there exists multiple meanings of bits *within\n> the same context*, and that beginners likely can't tell them apart.\n>\n> Feel free to try it yourself - talk about Bitcoin \"bits\" of a particular\n> value with somebody who  doesn't understand Bitcoin. Then explain that the\n> cryptography uses 256 bit keys. I would be surprised if you could find\n> somebody who would not be confused by that.\n>\n> Let's say a website says a song is 24 bits. Was that 24 bit audio\n> resolution or 24 bit price? Somebody writes about 256 bit keys, are that\n> their size or value?\n>\n> You guys here can probably tell the difference. Can everybody...? Bits\n> will cause confusion, because plenty of people will not be able to tell\n> these apart. They will not know WHEN to apply one definition or the other.\n>\n> https://www.reddit.com/r/bitcoin/comments/24m3nb/_/ch8gua7\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171214/73f8b8ef/attachment-0001.html>"
            },
            {
                "author": "Marcel Jamin",
                "date": "2017-12-15T06:27:10",
                "message_text_only": "I think one could make the argument that the only people who talk\nabout and understand 24 bit audio or 256 bit cryptography are the ones\nwho can tell the difference very easily.\n\nTo me, your example seems to try hard to make the case for a problem\nthat won't exist in reality.\n\nBitcoin (BTC), Millibitcoin (mBTC) and Microbitcoin (\u00b5BTC) is the\n>correct< approach. It's tidy, systematic and precise. But that won't\nstop people from using something that's easier to deal with as I just\nhad to google the \u00b5 character again.\n\nLet's also keep in mind that Coinbase has been using \"bits\" as the\ndefault for over 2 years now:\nhttps://blog.coinbase.com/bits-is-the-new-default-and-all-new-users-get-100-bits-for-free-9165f757594b\n\nJust from a linguistic standpoint, chances are we'll end up with bits\nanyway. Why fight it? We don't have a SI prefix educational mandate.\n\nMarcel\n\nOn 14 December 2017 at 23:01, Natanael <natanael.l at gmail.com> wrote:\n>\n> Reposting /u/BashCo's post on reddit here, for visibility:\n>\n> ---8<---------------------------------------------------------------\n>\n>> Before anyone says 'bits' are too confusing because it's a computer\n>> science term, here's a list of homonyms\n>> [https://en.wikipedia.org/wiki/List_of_true_homonyms] that you use every\n>> day. Homonyms are fine because our brains are able to interpret language\n>> based on context, so it's a non-argument.\n>\n>\n> This ignores the fact that there exists multiple meanings of bits *within\n> the same context*, and that beginners likely can't tell them apart.\n>\n> Feel free to try it yourself - talk about Bitcoin \"bits\" of a particular\n> value with somebody who  doesn't understand Bitcoin. Then explain that the\n> cryptography uses 256 bit keys. I would be surprised if you could find\n> somebody who would not be confused by that.\n>\n> Let's say a website says a song is 24 bits. Was that 24 bit audio resolution\n> or 24 bit price? Somebody writes about 256 bit keys, are that their size or\n> value?\n>\n> You guys here can probably tell the difference. Can everybody...? Bits will\n> cause confusion, because plenty of people will not be able to tell these\n> apart. They will not know WHEN to apply one definition or the other.\n>\n> https://www.reddit.com/r/bitcoin/comments/24m3nb/_/ch8gua7\n>\n>"
            },
            {
                "author": "Moral Agent",
                "date": "2017-12-15T18:20:34",
                "message_text_only": ">Bitcoin (BTC), Millibitcoin (mBTC) and Microbitcoin (\u00b5BTC) is the >correct<\napproach. It's tidy, systematic and precise.\n\nThe SI system is great, but it's nice if you pick a base unit that is easy\nfor intuition to comprehend.\n\nIt is a fact that I weigh approximately .000,000,000,000,000,000,000,014\nEarth masses. If we arrived at rough consensus that this was a cumbersome\nway to express the mass of a human, we might then find a group of people\nmaking the superficially sensible proposal that we use SI prefixes and say\nI weigh 14 yoctoearths. This would be tidy, systematic and precise, but\nthat might not be enough to make it the best option. It might be even\nbetter to choose a base unit that human intuition can make sense of, and\nTHEN add prefixes as needed.\n\nI dislike the name \"bits\" but I think 100 satoshis does make a nice base\nunit. If we cannot crowdsource a more inspiring label we may be stuck with\nbits just due to linguistic network effects.\n\n-Ethan\n\n\n\nOn Fri, Dec 15, 2017 at 1:27 AM, Marcel Jamin via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I think one could make the argument that the only people who talk\n> about and understand 24 bit audio or 256 bit cryptography are the ones\n> who can tell the difference very easily.\n>\n> To me, your example seems to try hard to make the case for a problem\n> that won't exist in reality.\n>\n> Bitcoin (BTC), Millibitcoin (mBTC) and Microbitcoin (\u00b5BTC) is the\n> >correct< approach. It's tidy, systematic and precise. But that won't\n> stop people from using something that's easier to deal with as I just\n> had to google the \u00b5 character again.\n>\n> Let's also keep in mind that Coinbase has been using \"bits\" as the\n> default for over 2 years now:\n> https://blog.coinbase.com/bits-is-the-new-default-and-\n> all-new-users-get-100-bits-for-free-9165f757594b\n>\n> Just from a linguistic standpoint, chances are we'll end up with bits\n> anyway. Why fight it? We don't have a SI prefix educational mandate.\n>\n> Marcel\n>\n> On 14 December 2017 at 23:01, Natanael <natanael.l at gmail.com> wrote:\n> >\n> > Reposting /u/BashCo's post on reddit here, for visibility:\n> >\n> > ---8<---------------------------------------------------------------\n> >\n> >> Before anyone says 'bits' are too confusing because it's a computer\n> >> science term, here's a list of homonyms\n> >> [https://en.wikipedia.org/wiki/List_of_true_homonyms] that you use\n> every\n> >> day. Homonyms are fine because our brains are able to interpret language\n> >> based on context, so it's a non-argument.\n> >\n> >\n> > This ignores the fact that there exists multiple meanings of bits *within\n> > the same context*, and that beginners likely can't tell them apart.\n> >\n> > Feel free to try it yourself - talk about Bitcoin \"bits\" of a particular\n> > value with somebody who  doesn't understand Bitcoin. Then explain that\n> the\n> > cryptography uses 256 bit keys. I would be surprised if you could find\n> > somebody who would not be confused by that.\n> >\n> > Let's say a website says a song is 24 bits. Was that 24 bit audio\n> resolution\n> > or 24 bit price? Somebody writes about 256 bit keys, are that their size\n> or\n> > value?\n> >\n> > You guys here can probably tell the difference. Can everybody...? Bits\n> will\n> > cause confusion, because plenty of people will not be able to tell these\n> > apart. They will not know WHEN to apply one definition or the other.\n> >\n> > https://www.reddit.com/r/bitcoin/comments/24m3nb/_/ch8gua7\n> >\n> >\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171215/491a9809/attachment.html>"
            },
            {
                "author": "Rhavar",
                "date": "2017-12-15T18:46:45",
                "message_text_only": "I don't have anything interesting to add, except that I have been using 'bits' on my site for over 3 years. It's a great unit that people quickly adapt to, and it's far more convenient. When dealing with large amounts of money, people have no problem naturally thinking in \"thousand bits\" or \"million bits\" (a bitcoin).\n\nI would highly encourage it to be a default everywhere. Consistency is really important.\n\nAlso slightly unrelated, but the whole \"sat/B\" thing for fees is such a clusterfuck. Half the time it's used as \"vbyte\" and half the time actual bytes. Users are constantly confused because of explorers and wallet and stuff all showing it inconsistently. I would suggest there that there is a \"standard\" of \"bits per kiloweight\" (i.e. how many bits of fees to pay for a transaction that is 1000 weight)\n\n-Ryan\n\n> -------- Original Message --------\n> Subject: Re: [bitcoin-dev] BIP Proposal: Utilization of bits denomination\n> Local Time: December 15, 2017 12:20 PM\n> UTC Time: December 15, 2017 6:20 PM\n> From: bitcoin-dev at lists.linuxfoundation.org\n> To: Marcel Jamin <marcel at jamin.net>, Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\n>\n>>Bitcoin (BTC), Millibitcoin (mBTC) and Microbitcoin (\u00b5BTC) is the >correct< approach. It's tidy, systematic and precise.\n>\n> The SI system is great, but it's nice if you pick a base unit that is easy for intuition to comprehend.\n>\n> It is a fact that I weigh approximately .000,000,000,000,000,000,000,014 Earth masses. If we arrived at rough consensus that this was a cumbersome way to express the mass of a human, we might then find a group of people making the superficially sensible proposal that we use SI prefixes and say I weigh 14 yoctoearths. This would be tidy, systematic and precise, but that might not be enough to make it the best option. It might be even better to choose a base unit that human intuition can make sense of, and THEN add prefixes as needed.\n>\n> I dislike the name \"bits\" but I think 100 satoshis does make a nice base unit. If we cannot crowdsource a more inspiring label we may be stuck with bits just due to linguistic network effects.\n>\n> -Ethan\n>\n> On Fri, Dec 15, 2017 at 1:27 AM, Marcel Jamin via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> I think one could make the argument that the only people who talk\n>> about and understand 24 bit audio or 256 bit cryptography are the ones\n>> who can tell the difference very easily.\n>>\n>> To me, your example seems to try hard to make the case for a problem\n>> that won't exist in reality.\n>>\n>> Bitcoin (BTC), Millibitcoin (mBTC) and Microbitcoin (\u00b5BTC) is the\n>>>correct< approach. It's tidy, systematic and precise. But that won't\n>> stop people from using something that's easier to deal with as I just\n>> had to google the \u00b5 character again.\n>>\n>> Let's also keep in mind that Coinbase has been using \"bits\" as the\n>> default for over 2 years now:\n>> https://blog.coinbase.com/bits-is-the-new-default-and-all-new-users-get-100-bits-for-free-9165f757594b\n>>\n>> Just from a linguistic standpoint, chances are we'll end up with bits\n>> anyway. Why fight it? We don't have a SI prefix educational mandate.\n>>\n>> Marcel\n>>\n>> On 14 December 2017 at 23:01, Natanael <natanael.l at gmail.com> wrote:\n>>>\n>>> Reposting /u/BashCo's post on reddit here, for visibility:\n>>>\n>>> ---8<---------------------------------------------------------------\n>>>\n>>>> Before anyone says 'bits' are too confusing because it's a computer\n>>>> science term, here's a list of homonyms\n>>>> [https://en.wikipedia.org/wiki/List_of_true_homonyms] that you use every\n>>>> day. Homonyms are fine because our brains are able to interpret language\n>>>> based on context, so it's a non-argument.\n>>>\n>>>\n>>> This ignores the fact that there exists multiple meanings of bits *within\n>>> the same context*, and that beginners likely can't tell them apart.\n>>>\n>>> Feel free to try it yourself - talk about Bitcoin \"bits\" of a particular\n>>> value with somebody who  doesn't understand Bitcoin. Then explain that the\n>>> cryptography uses 256 bit keys. I would be surprised if you could find\n>>> somebody who would not be confused by that.\n>>>\n>>> Let's say a website says a song is 24 bits. Was that 24 bit audio resolution\n>>> or 24 bit price? Somebody writes about 256 bit keys, are that their size or\n>>> value?\n>>>\n>>> You guys here can probably tell the difference. Can everybody...? Bits will\n>>> cause confusion, because plenty of people will not be able to tell these\n>>> apart. They will not know WHEN to apply one definition or the other.\n>>>\n>>> https://www.reddit.com/r/bitcoin/comments/24m3nb/_/ch8gua7\n>>>\n>>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171215/375ec903/attachment.html>"
            },
            {
                "author": "Sjors Provoost",
                "date": "2017-12-14T15:52:24",
                "message_text_only": "As much as I love SI standards, \"trains users to understand SI prefixes, allowing them to\neasily migrate from one prefix to the next\" seems unrealistic. The metric system is about to\nhave its 220th birthday and people in the US still don't use it.\n\nIt makes sense to embrace terms that stick. \"bits\" as a formal-yet-informal alias for \u00b5BTC makes sense to me, unless someone can point to another term that's already commonly used.\n\nI'm not too worried about the word bit having other meanings in common language. The word \"bit coin\" was introduced in the English language without a problem. A \"bit\" being 1 millionth of a \"bit coin\" doesn't seem too difficult. It will give a while new meaning to the expression \"a bit expensive\" :-)\n\nRather than nano-bitcoin, I would suggest milli bits.\n\n\nIt's rather unfortunate that 1 satoshi was defined as 10^-8 BTC instead of 10^-9. We could redefine satoshi to 10^-9 BTC. Then we can use kilo-satoshi instead of bits. Then the next step can be satoshi, followed by millisatoshi (you never know).\n\nThe smallest amount that can be handled by bitcoin software under this redefinition would be 10 satoshi rather than 1; mostly a matter of changing some source code comments.\n\nThe only place where I've seen the unit \"satoshi\" used is fee estimators. I think it's still early enough that people aren't terribly attached to the numbers shown on those sites (most people express fees in fiat terms, especially when complaining). We could switch from vbytes to weight units at the same time.\n\nSjors\n\n> Op 13 dec. 2017, om 22:36 heeft David A. Harding via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:\n> \n> On Wed, Dec 13, 2017 at 01:46:09PM -0600, Jimmy Song via bitcoin-dev wrote:\n>> Hey all,\n>> \n>> I am proposing an informational BIP to standardize the term \"bits\". The\n>> term has been around a while, but having some formal informational standard\n>> helps give structure to how the term is used.\n>> \n>> https://github.com/jimmysong/bips/blob/unit-bias/bip-unit-bias.mediawiki\n> \n> Wallets and other software is already using this term, so I think it's a\n> good idea to ensure its usage is normalized.\n> \n> That said, I think the term is unnecessary and confusing given that\n> microbitcoins provides all of the same advantages and at least two\n> additional advantages:\n> \n> - Microbitcoins is not a homonym for any other word in English (and\n>  probably not in any other language), whereas \"bit\" and \"bits\" have\n>  more than a dozen homonyms in English---some of which are quite common\n>  in general currency usage, Bitcoin currency usage, or Bitcoin\n>  technical usage.\n> \n> - Microbitcoins trains users to understand SI prefixes, allowing them to\n>  easily migrate from one prefix to the next.  This will be important\n>  when bitcoin prices rise to $10M USD[1] and the bits denomination has\n>  the same problems the millibitcoin denomination has now, but it's also\n>  useful in the short term when interacting with users who make very\n>  large payments (bitcoin-scale) or very small payments\n>  (nanobitcoin-scale).[2]  Maybe a table of scale can emphasize this\n>  point:\n> \n>      Wrong (IMO):        Right (IMO):\n>      ---------------     --------------\n>      BTC                 BTC\n>      mBTC                mBTC\n>      bits                \u00b5BTC\n>      nBTC                nBTC\n> \n> [1] A rise in price to $10M doesn't require huge levels of growth---it\n> only requires time under the assumption that a percentage of bitcoins will\n> be lost every year due to wallet mishaps, failure to inherit bitcoins,\n> and other issues that remove bitcoins from circulation.  In other words,\n> it's important to remember that Bitcoin is expected to become a\n> deflationary currency and plan accordingly.\n> \n> [2] Although Bitcoin does not currently support committed\n> nanobitcoin-scale payments in the block chain, it can be supported in a\n> variety of ways by offchain systems---including (it is hypothesized)\n> trustless systems based on probabilistic payments.\n> \n> Thanks,\n> \n> -Dave\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171214/b27a9030/attachment.sig>"
            },
            {
                "author": "Daniel McNally",
                "date": "2017-12-13T23:00:02",
                "message_text_only": "I think standardization of this term is a great idea. I second all of\nJimmy's points. I think the analogy of dollars & cents to bits and satoshis\nis easy to grasp, particularly given that satoshis and cents are the\nsmallest tangible units of their respective currencies. It's a concept\nthat's common across cultures and countries as it also applies to pounds\nand pence, pesos and centavos, etc...\n\nTo David's points, I agree that it's not ideal that bit is a homonym for\nother words, but I don't think it's a terrible flaw as context will usually\nmake the meaning clear. I'm actually not in love with the term \"bit,\" but\nrather the idea of a non-SI term for a millionth of a bitcoin. But bit has\nalready caught on to some extent and I can't think of anything better.\n\n\n> - Microbitcoins trains users to understand SI prefixes, allowing them to easily\n> migrate from one prefix to the next.  This will be important when bitcoin\n> prices rise to $10M USD[1] and the bits denomination has the same\n> problems the millibitcoin denomination has now, but it's also useful in\n> the short term when interacting with users who make very large payments\n> (bitcoin-scale) or very small payments (nanobitcoin-scale).[2]\n\n\nI find the SI prefixes to be very user unfriendly. I have plenty of smart\nfriends and family who constantly confuse mega, giga, micro, nano, and so\non. Rather than try to train users, I think we should choose terms that\nwill be easy for them to grasp right away. Even for people fluent in SI\nterms, I think some of the problems regarding unit bias still exist. 500\nmicrobitcoins sounds diminutive and uttering it is a reminder that it's a\nvery small fraction of a larger unit. 500 bits sounds like you have 500 of\nsomething, neat!\n\nI consider \"bits\" to be a term that's quite future proofed. While I won't\ndismiss the possibility of $10M or $100M bitcoins in the not-too-distant\nfuture, there would still be plenty of time for a bit to be a useful\nday-to-day unit. Even at the $10M point, small ticket items like coffee\ncould still be priced at 0.30 bits for example, not bad I'd say.\n\nShould bitcoin ever soar past the $100M mark, it might be time for a new\nterm akin to bits and maybe a hard fork to allow for more decimal places on\nchain. A nanobitcoin could not be transacted with today anyhow. These would\nall be good problems to have.\n\nThanks for reading and thanks to Jimmy for taking the initiative with this\nBIP.\n\nDaniel\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171213/c6e2f0e0/attachment.html>"
            },
            {
                "author": "Tamas Blummer",
                "date": "2017-12-24T04:26:04",
                "message_text_only": "I see further arguments supporting the \u201cbit\" denomination:\n\nhuge benefit:\n\t- amounts denominated in bits fit nicely into legacy database structures and UIs with two decimal places for currency. This change to the usual currrency precision is a huge benefit for integration into existing financial software.\n\nnice to have:\n\t- while fraction prefixes m for 1/1000 and u for 1/1000000 are obvious to engineers and geeks, they are a foreign concept to many. Chances confusing magnitudes would be high if alternative scales were offered.\n\t- bit assigns an easy to comprehend meaning to the second part of the Bitcoin name: I think the term \u201c(a whole) coin\" would quickly catch on as a synonym for a million bits.\n\n\nTamas Blummer"
            }
        ],
        "thread_summary": {
            "title": "BIP Proposal: Utilization of bits denomination",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Daniel McNally",
                "Natanael",
                "Tamas Blummer",
                "David A. Harding",
                "Marcel Jamin",
                "Clark Moody",
                "Jimmy Song",
                "Sjors Provoost",
                "Moral Agent",
                "Rhavar"
            ],
            "messages_count": 11,
            "total_messages_chars_count": 33107
        }
    },
    {
        "title": "[bitcoin-dev] BIP Proposal: Bitcoin nodes could be used as a trusted third party that broadcasts encrypted transactions",
        "thread_messages": [
            {
                "author": "Nathan Broadbent",
                "date": "2017-12-13T22:08:05",
                "message_text_only": "Hello,\n\nI would like propose a way for full Bitcoin nodes to be used as simple\ntrusted third parties (TTPs) [1]. The idea is that parties would work\ntogether to randomly select a Bitcoin node. The parties would then perform\na secure multi-party computation (MPC) [2], where every party has a secret\nvalue that they don't want to share with anyone else. The result of this\ncomputation would be a Bitcoin transaction that was encrypted by the random\nnode's public key. Any of the parties could then send the encrypted\ntransaction to this node. The node would decrypt the transaction and\nbroadcast it to its peers. Nodes would receive a small fee for providing\nthis service.\n\n\n*Mental Poker*\n\nMental Poker [3] is where you play a fair game of poker without the need\nfor a trusted third party who moderates the game. A paper titled \"A Toolbox\nfor Mental Card Games\" [4] describes how you can use MPC to\nplay decentralized poker.\n\nThis works great when you're just playing for fun, but everything falls\napart when you're playing for Bitcoin. The problem is that MPC is not fair,\nbecause one party will always learn the outcome of a computation before\nanyone else. If they find out that they lost the round, they can abort the\ncomputation and prevent anyone else from gaining that information. The\nother players will know what happened, but they can't force the cheater to\nbroadcast the Bitcoin transaction. The game would just be stalled, and\npeople would use their timelock transactions to get their money back.\n\nIn a paper titled \"How to Use Bitcoin to Play Decentralized Poker\" [5], the\nauthors describe how penalties could be used to force players into\nrevealing the outcome. If one player aborts the computation after learning\nthat they lost, they would automatically pay a penalty to the other players.\n\nThere's one big problem with this penalty system: A group of dishonest\nplayers can simply ignore that player and force them to pay the penalty.\nThe outcome of the round doesn't even matter. It would be easy to set up an\narmy of bots that never finishes a round and just collects penalties.\n\n\n*Mental Poker With Random Bitcoin Nodes as TTPs*\n\nThe fairness problem might be solved if a randomly selected Bitcoin node\nserved as a simple TTP. The node could provide a public key, and result of\nthe MPC would then be an *encrypted* Bitcoin transaction that could only be\ndecrypted and broadcast by that randomly selected node. No players would\ngain any information about the outcome until they saw the unconfirmed\ntransaction in the mempool.\n\nThe following example is very long and detailed (as is this whole email!),\nbut it demonstrates all of the functions that a node would need to perform.\n\n\n*Example Protocol*\n\nAlice and Bob choose a random full Bitcoin node that supports this new\nprotocol. (Alice might shuffle all of the IP addresses and send Bob the\nMerkle tree root hash. Bob then picks one index at random, and Alice sends\nBob the full Merkle tree. Now they've both committed to a random node.)\n\nAlice sends the request to the randomly selected node. The node generates a\none-time-use key pair, and encrypts the one-time private key using its\nstatic public key. It also signs \"<one-time-use public key><encrypted\none-time-use private key>\" using its static private key.\n\n*Note: This one-time-use key pair is generated so that Alice and Bob can\nencrypt up to 32 bytes of metadata and send this with the one-time key\nand their encrypted transaction. The node would broadcast the transaction\nand return their decrypted data. Also note that the node would use the same\nstatic key pair as P2P encryption. (BIP151) [6]*\n\nThe node sends Alice the fee amount (maybe 20 Satoshis), an address where\nshe should send the fee, the node's static public key, and the one-time\npublic key / encrypted private key / signature.\n\nAlice sends this data to Bob. Bob connects to the node himself, and fetches\nthe fee and static public key. Bob uses the public key and signature to\nverify that the one-time key pair was generated and signed by this node.\n\nAlice and Bob now play a round of decentralized poker. At the end of the\nround, they use MPC to create an encrypted Bitcoin transaction that sends\nthe money to the winner. The MPC also has an output for the encrypted\nshowdown (the cards that are revealed at the end of the round.)\n\nEither Bob or Alice (or both) now send this encrypted transaction to the\nnode, plus the encrypted showdown, the one-time key data.\n\nThe node then decrypts and verifies the Bitcoin transaction. If it's valid\nand it contains the correct fee output, it broadcasts the transaction to\nits peers. The node also decrypts the one-time private key, and uses the\ndecrypted private key to decrypt the metadata that was sent. The node\nreturns the decrypted metadata to the sender, who now knows the other\nplayer's cards.\n\nNote that one player can still abort the computation and send the encrypted\ntransaction as soon as they have it, which prevents the other player from\nlearning about the cards. A solution could be that the node keeps the\ndecrypted metadata in memory for a short time, and the other player can\naccess that data by sending the one-time-use public key.\n\n\n*Example Protocol Notes:*\n\nThis example only uses a single TTP node. It would be far more secure if\nthe parties randomly select a large number of nodes. The encrypted\ntransaction would contain fee outputs for every node.\n\nShamir's Secret Sharing could be used so that *n* of *t* nodes are needed\nto decrypt the transaction. The MPC could encrypt the individual key parts\nusing each node's public key. The node would either broadcast a fully\ndecrypted transaction, or return a partially decrypted transaction to the\nsender.\n\nPeople might be tempted to use the seed nodes more often, because they're\nhard-coded in the Bitcoin source code. Don't do that. For important\ntransactions, you should just use a large number of TTP nodes (e.g. require\ndecryption by 20 out of 50 randomly selected nodes.)\n\n\n*Real-World Applications*\n\nPeople could anonymously vote on the distribution of funds without\nrevealing their vote to anyone. No-one would know the outcome of the vote\nuntil the transaction was broadcast.\n\nIt would also be possible to create a fully decentralized Bitcoin lottery.\n\n\n\nSorry for the incredibly long email. I hope you found this interesting!\nI've probably made a few mistakes, but I hope I've explained things\nclearly, and I look forward to reading your feedback.\n\n\nBest Regards,\nNathan Broadbent\n\n\n\n*References:*\n\n[1] https://en.wikipedia.org/wiki/Trusted_third_party\n[2] https://en.wikipedia.org/wiki/Secure_multi-party_computation\n[3] https://en.wikipedia.org/wiki/Mental_poker\n[4]\nhttp://www.cs.miami.edu/home/burt/projects/smpc/doc/schindelhauer98toolbox.pdf\n[5] http://people.csail.mit.edu/ranjit/papers/poker.pdf\n[6] https://github.com/bitcoin/bips/blob/master/bip-0151.mediawiki\n\u200c\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171214/c6fe52e8/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP Proposal: Bitcoin nodes could be used as a trusted third party that broadcasts encrypted transactions",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Nathan Broadbent"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 7073
        }
    },
    {
        "title": "[bitcoin-dev] Parallel header download during sync",
        "thread_messages": [
            {
                "author": "Jim Posen",
                "date": "2017-12-15T23:55:16",
                "message_text_only": "One of the ideas that Greg Maxwell brought up in the \"'Compressed' headers\nstream\" thread is the possibility of a header sync mechanism that allowed\nparallel download from multiple peers. With the current getheaders/headers\nsemantics, headers must be downloaded sequentially from genesis. In my\ntesting, I saw that syncing headers directly from a colocated node took <5s\nwhereas syncing normally from network peers takes ~5 min for me, which goes\nto show that 5s is an upper bound on the time to process all headers if\nthey are locally available. So if we can introduce new p2p messages for\nheader sync, what would they look like? Here's one idea.\n\nA new getheadersv2 request would include a start height for the range of\nheaders requested and a commitment to the last block in the chain that you\nwant to download. Then you find N peers that are all on the same chain,\npartition the range of headers from 0 to the chain height minus some\nreasonable reorg safety buffer (~6 blocks), and send download requests in\nparallel. So how do we know that the peers are on the same chain and that\ntheir headers served connect into this chain?\n\nWhen you connect to outbound peers and are in IBD, you will query them for\na Merkle Mountain Range commitment to all headers up to a height X (which\nis 6ish blocks before their start height from the version message). Then\nyou choose the commitment that the majority of the queried peers sent (or\nsome other heuristic), and these become your download peers. Every\ngetheadersv2 request includes the start height, X, and the chain\ncommitment. The headersv2 response messages include all of the headers\nfollowed by a merkle branch linking the last header into the chain\ncommitment. Headers are processed in order as they arrive and if any of the\nheaders are invalid, you can ban/disconnect all peers that committed to it,\ndrop the buffer of later headers and start over.\n\nThat's the basic idea. Here are other details:\n\n- This would require an additional 32-byte MMR commitment for each header\nin memory.\n- When a node receives a headersv2 request and constructs a merkle proof\nfor the last header, it checks against the sent commitment. In the case of\na really deep reorg, that check would fail, and the node can instead\nrespond with an updated commitment hash for that height.\n- Another packet is needed, getheaderchain or something, that a syncing\npeer first sends along with a header locator and an end height. The peer\nresponds with headerchain, which includes the last common header from the\nlocator along with the chain commitment at that height and a merkle branch\nproving inclusion of that header in the chain.\n- Nodes would cache chain commitments for the last ~20 blocks (somewhat\narbitrary), and refuse to serve chain commitments for heights before that.\n\nThoughts? This is a pretty recycled idea, so please point me at prior\nproposals that are similar as well.\n\n-jimpo\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171215/267e7064/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Parallel header download during sync",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jim Posen"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3098
        }
    },
    {
        "title": "[bitcoin-dev] Why not witnessless nodes?",
        "thread_messages": [
            {
                "author": "Kalle Rosenbaum",
                "date": "2017-12-18T08:32:23",
                "message_text_only": "Dear list,\n\nI find it hard to understand why a full node that does initial block\ndownload also must download witnesses if they are going to skip\nverification anyway. If my full node skips signature verification for\nblocks earlier than X, it seems the reasons for downloading the\nwitnesses for those blocks are:\n\n* to be able to send witnesses to other nodes.\n\n* to verify the witness root hash of the blocks\n\nI suppose that it's important to verify the witness root hash because\na bad peer may send me invalid witnesses during initial block\ndownload, and if I don't verify that the witness root hash actually\ncommits to them, I will get banned by peers requesting the blocks from\nme because I send them garbage.\n\nSo both the reasons above (there may be more that I don't know about)\nare actually the same reason: To be able to send witnesses to others\nwithout getting banned.\n\nWhat if a node could chose not to download witnesses and thus chose to\nsend only witnessless blocks to peers. Let's call these nodes\nwitnessless nodes. Note that witnessless nodes are only witnessless\nfor blocks up to X. Everything after X is fully verified.\n\nWitnessless nodes would be able to sync faster because it needs to\ndownload less data to calculate their UTXO set. They would therefore\nmore quickly be able to provide full service to SPV wallets and its\nlocal wallets as well as serving blocks to other witnessless nodes\nwith same or higher assumevalid block. For witnessless nodes with\nlower assumevalid they can serve at least some blocks. It could also\nserve blocks to non-segwit nodes.\n\nDo witnessless nodes risk dividing the network in two parts, one\nwitnessless and one with full nodes, with few connections between the\nparts?\n\nSo basically, what are the reasons not to implement witnessless\nnodes?\n\nThank you,\n/Kalle\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/34624abd/attachment.html>"
            },
            {
                "author": "Ozgur",
                "date": "2017-12-18T12:11:10",
                "message_text_only": "An HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/7c075b9b/attachment.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2017-12-18T12:43:58",
                "message_text_only": "> On Dec 18, 2017, at 03:32, Kalle Rosenbaum via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Dear list,\n> \n> I find it hard to understand why a full node that does initial block\n> download also must download witnesses if they are going to skip verification anyway.\n\nWhy run a full node if you are not going to verify the chain?\n\n> If my full node skips signature verification for\n> blocks earlier than X, it seems the reasons for downloading the\n> witnesses for those blocks are:\n> \n> * to be able to send witnesses to other nodes.\n> \n> * to verify the witness root hash of the blocks\n> \n> I suppose that it's important to verify the witness root hash because\n> a bad peer may send me invalid witnesses during initial block\n> download, and if I don't verify that the witness root hash actually\n> commits to them, I will get banned by peers requesting the blocks from\n> me because I send them garbage.\n> So both the reasons above (there may be more that I don't know about)\n> are actually the same reason: To be able to send witnesses to others\n> without getting banned.\n> \n> What if a node could chose not to download witnesses and thus chose to\n> send only witnessless blocks to peers. Let's call these nodes\n> witnessless nodes. Note that witnessless nodes are only witnessless\n> for blocks up to X. Everything after X is fully verified.\n> \n> Witnessless nodes would be able to sync faster because it needs to\n> download less data to calculate their UTXO set. They would therefore\n> more quickly be able to provide full service to SPV wallets and its\n> local wallets as well as serving blocks to other witnessless nodes\n> with same or higher assumevalid block. For witnessless nodes with\n> lower assumevalid they can serve at least some blocks. It could also\n> serve blocks to non-segwit nodes.\n> \n> Do witnessless nodes risk dividing the network in two parts, one\n> witnessless and one with full nodes, with few connections between the\n> parts?\n> \n> So basically, what are the reasons not to implement witnessless\n> nodes?\n> \n> Thank you,\n> /Kalle\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Kalle Rosenbaum",
                "date": "2017-12-18T13:35:44",
                "message_text_only": "2017-12-18 13:43 GMT+01:00 Eric Voskuil <eric at voskuil.org>:\n\n>\n> > On Dec 18, 2017, at 03:32, Kalle Rosenbaum via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >\n> > Dear list,\n> >\n> > I find it hard to understand why a full node that does initial block\n> > download also must download witnesses if they are going to skip\n> verification anyway.\n>\n> Why run a full node if you are not going to verify the chain?\n>\n\nI meant to say \"I find it hard to understand why a full node that does\ninitial block\ndownload also must download witnesses when it is going to skip verification\nof the witnesses anyway.\"\n\nI'm referring to the \"assumevalid\" feature of Bitcoin Core that skips\nsignature verification up to block X. Or have I misunderstood assumevalid?\n\n/Kalle\n\n\n>\n> > If my full node skips signature verification for\n> > blocks earlier than X, it seems the reasons for downloading the\n> > witnesses for those blocks are:\n> >\n> > * to be able to send witnesses to other nodes.\n> >\n> > * to verify the witness root hash of the blocks\n> >\n> > I suppose that it's important to verify the witness root hash because\n> > a bad peer may send me invalid witnesses during initial block\n> > download, and if I don't verify that the witness root hash actually\n> > commits to them, I will get banned by peers requesting the blocks from\n> > me because I send them garbage.\n> > So both the reasons above (there may be more that I don't know about)\n> > are actually the same reason: To be able to send witnesses to others\n> > without getting banned.\n> >\n> > What if a node could chose not to download witnesses and thus chose to\n> > send only witnessless blocks to peers. Let's call these nodes\n> > witnessless nodes. Note that witnessless nodes are only witnessless\n> > for blocks up to X. Everything after X is fully verified.\n> >\n> > Witnessless nodes would be able to sync faster because it needs to\n> > download less data to calculate their UTXO set. They would therefore\n> > more quickly be able to provide full service to SPV wallets and its\n> > local wallets as well as serving blocks to other witnessless nodes\n> > with same or higher assumevalid block. For witnessless nodes with\n> > lower assumevalid they can serve at least some blocks. It could also\n> > serve blocks to non-segwit nodes.\n> >\n> > Do witnessless nodes risk dividing the network in two parts, one\n> > witnessless and one with full nodes, with few connections between the\n> > parts?\n> >\n> > So basically, what are the reasons not to implement witnessless\n> > nodes?\n> >\n> > Thank you,\n> > /Kalle\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/f5dc0e16/attachment.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2017-12-18T16:19:34",
                "message_text_only": "You can't know (assume) a block is valid unless you have previously validated the block yourself. But in the case where you have, and then intend to rely on it in a future sync, there is no need for witness data for blocks you are not going to validate. So you can just not request it. \n\nHowever you will not be able to provide those blocks to nodes that *are* validating; the client is pruned and therefore not a peer (cannot reciprocate). (An SPV client is similarly not a peer; it is a more deeply pruned client than the witnessless client.)\n\nThere is no other reason that a node requires witness data. SPV clients don't need it as it is neither require it to verify header commitment to transactions nor to extract payment addresses from them.\n\nThe harm to the network by pruning is that eventually it can become harder and even impossible for anyone to validate the chain. But because you are fully validating you individually remain secure, so there is no individual incentive working against this system harm.\n\ne\n\n> On Dec 18, 2017, at 08:35, Kalle Rosenbaum <kalle at rosenbaum.se> wrote:\n> \n> 2017-12-18 13:43 GMT+01:00 Eric Voskuil <eric at voskuil.org>:\n>> \n>> > On Dec 18, 2017, at 03:32, Kalle Rosenbaum via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> >\n>> > Dear list,\n>> >\n>> > I find it hard to understand why a full node that does initial block\n>> > download also must download witnesses if they are going to skip verification anyway.\n>> \n>> Why run a full node if you are not going to verify the chain?\n> \n> I meant to say \"I find it hard to understand why a full node that does initial block\n> download also must download witnesses when it is going to skip verification of the witnesses anyway.\"\n> \n> I'm referring to the \"assumevalid\" feature of Bitcoin Core that skips signature verification up to block X. Or have I misunderstood assumevalid?\n> \n> /Kalle\n>  \n>> \n>> > If my full node skips signature verification for\n>> > blocks earlier than X, it seems the reasons for downloading the\n>> > witnesses for those blocks are:\n>> >\n>> > * to be able to send witnesses to other nodes.\n>> >\n>> > * to verify the witness root hash of the blocks\n>> >\n>> > I suppose that it's important to verify the witness root hash because\n>> > a bad peer may send me invalid witnesses during initial block\n>> > download, and if I don't verify that the witness root hash actually\n>> > commits to them, I will get banned by peers requesting the blocks from\n>> > me because I send them garbage.\n>> > So both the reasons above (there may be more that I don't know about)\n>> > are actually the same reason: To be able to send witnesses to others\n>> > without getting banned.\n>> >\n>> > What if a node could chose not to download witnesses and thus chose to\n>> > send only witnessless blocks to peers. Let's call these nodes\n>> > witnessless nodes. Note that witnessless nodes are only witnessless\n>> > for blocks up to X. Everything after X is fully verified.\n>> >\n>> > Witnessless nodes would be able to sync faster because it needs to\n>> > download less data to calculate their UTXO set. They would therefore\n>> > more quickly be able to provide full service to SPV wallets and its\n>> > local wallets as well as serving blocks to other witnessless nodes\n>> > with same or higher assumevalid block. For witnessless nodes with\n>> > lower assumevalid they can serve at least some blocks. It could also\n>> > serve blocks to non-segwit nodes.\n>> >\n>> > Do witnessless nodes risk dividing the network in two parts, one\n>> > witnessless and one with full nodes, with few connections between the\n>> > parts?\n>> >\n>> > So basically, what are the reasons not to implement witnessless\n>> > nodes?\n>> >\n>> > Thank you,\n>> > /Kalle\n>> > _______________________________________________\n>> > bitcoin-dev mailing list\n>> > bitcoin-dev at lists.linuxfoundation.org\n>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/9a59ee24/attachment-0001.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-12-18T17:30:17",
                "message_text_only": "Sign-to-contract enables some interesting protocols, none of which are in wide use as far as I\u2019m aware. But if they were (and arguably this is an area that should be more developed), then SPV nodes validating these protocols will need access to witness data. If a node is performing IBD with assumevalid set to true, and is also intending to prune history, then there\u2019s no reason to fetch those witnesses as far as I\u2019m aware. But it would be a great disservice to the network for nodes intending to serve SPV clients to prune this portion of the block history. \n\n> On Dec 18, 2017, at 8:19 AM, Eric Voskuil via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> You can't know (assume) a block is valid unless you have previously validated the block yourself. But in the case where you have, and then intend to rely on it in a future sync, there is no need for witness data for blocks you are not going to validate. So you can just not request it. \n> \n> However you will not be able to provide those blocks to nodes that *are* validating; the client is pruned and therefore not a peer (cannot reciprocate). (An SPV client is similarly not a peer; it is a more deeply pruned client than the witnessless client.)\n> \n> There is no other reason that a node requires witness data. SPV clients don't need it as it is neither require it to verify header commitment to transactions nor to extract payment addresses from them.\n> \n> The harm to the network by pruning is that eventually it can become harder and even impossible for anyone to validate the chain. But because you are fully validating you individually remain secure, so there is no individual incentive working against this system harm.\n> \n> e\n> \n> On Dec 18, 2017, at 08:35, Kalle Rosenbaum <kalle at rosenbaum.se <mailto:kalle at rosenbaum.se>> wrote:\n> \n>> 2017-12-18 13:43 GMT+01:00 Eric Voskuil <eric at voskuil.org <mailto:eric at voskuil.org>>:\n>> \n>> > On Dec 18, 2017, at 03:32, Kalle Rosenbaum via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>> >\n>> > Dear list,\n>> >\n>> > I find it hard to understand why a full node that does initial block\n>> > download also must download witnesses if they are going to skip verification anyway.\n>> \n>> Why run a full node if you are not going to verify the chain?\n>> \n>> I meant to say \"I find it hard to understand why a full node that does initial block\n>> download also must download witnesses when it is going to skip verification of the witnesses anyway.\"\n>> \n>> I'm referring to the \"assumevalid\" feature of Bitcoin Core that skips signature verification up to block X. Or have I misunderstood assumevalid?\n>> \n>> /Kalle\n>>  \n>> \n>> > If my full node skips signature verification for\n>> > blocks earlier than X, it seems the reasons for downloading the\n>> > witnesses for those blocks are:\n>> >\n>> > * to be able to send witnesses to other nodes.\n>> >\n>> > * to verify the witness root hash of the blocks\n>> >\n>> > I suppose that it's important to verify the witness root hash because\n>> > a bad peer may send me invalid witnesses during initial block\n>> > download, and if I don't verify that the witness root hash actually\n>> > commits to them, I will get banned by peers requesting the blocks from\n>> > me because I send them garbage.\n>> > So both the reasons above (there may be more that I don't know about)\n>> > are actually the same reason: To be able to send witnesses to others\n>> > without getting banned.\n>> >\n>> > What if a node could chose not to download witnesses and thus chose to\n>> > send only witnessless blocks to peers. Let's call these nodes\n>> > witnessless nodes. Note that witnessless nodes are only witnessless\n>> > for blocks up to X. Everything after X is fully verified.\n>> >\n>> > Witnessless nodes would be able to sync faster because it needs to\n>> > download less data to calculate their UTXO set. They would therefore\n>> > more quickly be able to provide full service to SPV wallets and its\n>> > local wallets as well as serving blocks to other witnessless nodes\n>> > with same or higher assumevalid block. For witnessless nodes with\n>> > lower assumevalid they can serve at least some blocks. It could also\n>> > serve blocks to non-segwit nodes.\n>> >\n>> > Do witnessless nodes risk dividing the network in two parts, one\n>> > witnessless and one with full nodes, with few connections between the\n>> > parts?\n>> >\n>> > So basically, what are the reasons not to implement witnessless\n>> > nodes?\n>> >\n>> > Thank you,\n>> > /Kalle\n>> > _______________________________________________\n>> > bitcoin-dev mailing list\n>> > bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/635995bc/attachment-0001.html>"
            },
            {
                "author": "Kalle Rosenbaum",
                "date": "2017-12-18T21:27:14",
                "message_text_only": "Hi Mark\n\nYes, it seems like sign-to-contract protocols, which I just now briefly\nread about [1][2], may need to use historic witnesses. That raises the\nquestion, what are Bitcoin witnesses for?\n\nTo me it seems witnesses should be regarded as temporary. But it seems both\nrespondents to this thread, Eric and Mark, mean that witnesses are forever.\nI regard witnesses as a way to authenticate updates to the UTXO set, and\nonce buried deep enough in the blockchain, the witness is no longer needed,\nbecause consensus has formed around the UTXO set update.\n\nSuppose a transaction with an invalid witness happens to enter the\nblockchain and gets buried 100000 blocks down with the witness still\navailable. Is the blockchain above it valid? I'd say the blockchain is\nvalid and that it was a bug that the transaction made it into the\nblockchain. We will have to live with such bugs.\n\nAnother way to put it: Suppose that all witnesses from 2017 dissappears\nfrom all nodes in 2020. Is the blockchain still valid? I think so. I would\ncontinue using it without looking back.\n\nWith that approach, I think sign-to-contract protocols has to find ways to\nwork in a witnessless environment. For example, users of such protocols can\nsetup their own archival nodes.\n\nI'd love to hear alternative views on this.\n\nThanks,\n/Kalle\n\n[1]\nhttps://download.wpsoftware.net/bitcoin/wizardry/mw-slides/2017-03-mit-bitcoin-expo/slides.pdf\n[2] https://bitcointalk.org/index.php?topic=893898.msg9861102#msg9861102\n\n2017-12-18 18:30 GMT+01:00 Mark Friedenbach via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org>:\n\n> Sign-to-contract enables some interesting protocols, none of which are in\n> wide use as far as I\u2019m aware. But if they were (and arguably this is an\n> area that should be more developed), then SPV nodes validating these\n> protocols will need access to witness data. If a node is performing IBD\n> with assumevalid set to true, and is also intending to prune history, then\n> there\u2019s no reason to fetch those witnesses as far as I\u2019m aware. But it\n> would be a great disservice to the network for nodes intending to serve SPV\n> clients to prune this portion of the block history.\n>\n>\n> On Dec 18, 2017, at 8:19 AM, Eric Voskuil via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> You can't know (assume) a block is valid unless you have previously\n> validated the block yourself. But in the case where you have, and then\n> intend to rely on it in a future sync, there is no need for witness data\n> for blocks you are not going to validate. So you can just not request it.\n>\n> However you will not be able to provide those blocks to nodes that *are*\n> validating; the client is pruned and therefore not a peer (cannot\n> reciprocate). (An SPV client is similarly not a peer; it is a more deeply\n> pruned client than the witnessless client.)\n>\n> There is no other reason that a node requires witness data. SPV clients\n> don't need it as it is neither require it to verify header commitment to\n> transactions nor to extract payment addresses from them.\n>\n> The harm to the network by pruning is that eventually it can become harder\n> and even impossible for anyone to validate the chain. But because you are\n> fully validating you individually remain secure, so there is no individual\n> incentive working against this system harm.\n>\n> e\n>\n> On Dec 18, 2017, at 08:35, Kalle Rosenbaum <kalle at rosenbaum.se> wrote:\n>\n> 2017-12-18 13:43 GMT+01:00 Eric Voskuil <eric at voskuil.org>:\n>\n>>\n>> > On Dec 18, 2017, at 03:32, Kalle Rosenbaum via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> >\n>> > Dear list,\n>> >\n>> > I find it hard to understand why a full node that does initial block\n>> > download also must download witnesses if they are going to skip\n>> verification anyway.\n>>\n>> Why run a full node if you are not going to verify the chain?\n>>\n>\n> I meant to say \"I find it hard to understand why a full node that does\n> initial block\n> download also must download witnesses when it is going to skip\n> verification of the witnesses anyway.\"\n>\n> I'm referring to the \"assumevalid\" feature of Bitcoin Core that skips\n> signature verification up to block X. Or have I misunderstood assumevalid?\n>\n> /Kalle\n>\n>\n>>\n>> > If my full node skips signature verification for\n>> > blocks earlier than X, it seems the reasons for downloading the\n>> > witnesses for those blocks are:\n>> >\n>> > * to be able to send witnesses to other nodes.\n>> >\n>> > * to verify the witness root hash of the blocks\n>> >\n>> > I suppose that it's important to verify the witness root hash because\n>> > a bad peer may send me invalid witnesses during initial block\n>> > download, and if I don't verify that the witness root hash actually\n>> > commits to them, I will get banned by peers requesting the blocks from\n>> > me because I send them garbage.\n>> > So both the reasons above (there may be more that I don't know about)\n>> > are actually the same reason: To be able to send witnesses to others\n>> > without getting banned.\n>> >\n>> > What if a node could chose not to download witnesses and thus chose to\n>> > send only witnessless blocks to peers. Let's call these nodes\n>> > witnessless nodes. Note that witnessless nodes are only witnessless\n>> > for blocks up to X. Everything after X is fully verified.\n>> >\n>> > Witnessless nodes would be able to sync faster because it needs to\n>> > download less data to calculate their UTXO set. They would therefore\n>> > more quickly be able to provide full service to SPV wallets and its\n>> > local wallets as well as serving blocks to other witnessless nodes\n>> > with same or higher assumevalid block. For witnessless nodes with\n>> > lower assumevalid they can serve at least some blocks. It could also\n>> > serve blocks to non-segwit nodes.\n>> >\n>> > Do witnessless nodes risk dividing the network in two parts, one\n>> > witnessless and one with full nodes, with few connections between the\n>> > parts?\n>> >\n>> > So basically, what are the reasons not to implement witnessless\n>> > nodes?\n>> >\n>> > Thank you,\n>> > /Kalle\n>> > _______________________________________________\n>> > bitcoin-dev mailing list\n>> > bitcoin-dev at lists.linuxfoundation.org\n>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/966989da/attachment-0001.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2017-12-18T21:58:58",
                "message_text_only": "How does one know what consensus has formed (around a UTXO set)?\n\ne\n\n> On Dec 18, 2017, at 16:27, Kalle Rosenbaum via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Hi Mark\n> \n> Yes, it seems like sign-to-contract protocols, which I just now briefly read about [1][2], may need to use historic witnesses. That raises the question, what are Bitcoin witnesses for?\n> \n> To me it seems witnesses should be regarded as temporary. But it seems both respondents to this thread, Eric and Mark, mean that witnesses are forever. I regard witnesses as a way to authenticate updates to the UTXO set, and once buried deep enough in the blockchain, the witness is no longer needed, because consensus has formed around the UTXO set update.\n> \n> Suppose a transaction with an invalid witness happens to enter the blockchain and gets buried 100000 blocks down with the witness still available. Is the blockchain above it valid? I'd say the blockchain is valid and that it was a bug that the transaction made it into the blockchain. We will have to live with such bugs.\n> \n> Another way to put it: Suppose that all witnesses from 2017 dissappears from all nodes in 2020. Is the blockchain still valid? I think so. I would continue using it without looking back.\n> \n> With that approach, I think sign-to-contract protocols has to find ways to work in a witnessless environment. For example, users of such protocols can setup their own archival nodes.\n> \n> I'd love to hear alternative views on this.\n> \n> Thanks,\n> /Kalle\n> \n> [1] https://download.wpsoftware.net/bitcoin/wizardry/mw-slides/2017-03-mit-bitcoin-expo/slides.pdf\n> [2] https://bitcointalk.org/index.php?topic=893898.msg9861102#msg9861102\n> \n> 2017-12-18 18:30 GMT+01:00 Mark Friedenbach via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>:\n>> Sign-to-contract enables some interesting protocols, none of which are in wide use as far as I\u2019m aware. But if they were (and arguably this is an area that should be more developed), then SPV nodes validating these protocols will need access to witness data. If a node is performing IBD with assumevalid set to true, and is also intending to prune history, then there\u2019s no reason to fetch those witnesses as far as I\u2019m aware. But it would be a great disservice to the network for nodes intending to serve SPV clients to prune this portion of the block history. \n>> \n>> \n>>> On Dec 18, 2017, at 8:19 AM, Eric Voskuil via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> \n>>> You can't know (assume) a block is valid unless you have previously validated the block yourself. But in the case where you have, and then intend to rely on it in a future sync, there is no need for witness data for blocks you are not going to validate. So you can just not request it. \n>>> \n>>> However you will not be able to provide those blocks to nodes that *are* validating; the client is pruned and therefore not a peer (cannot reciprocate). (An SPV client is similarly not a peer; it is a more deeply pruned client than the witnessless client.)\n>>> \n>>> There is no other reason that a node requires witness data. SPV clients don't need it as it is neither require it to verify header commitment to transactions nor to extract payment addresses from them.\n>>> \n>>> The harm to the network by pruning is that eventually it can become harder and even impossible for anyone to validate the chain. But because you are fully validating you individually remain secure, so there is no individual incentive working against this system harm.\n>>> \n>>> e\n>>> \n>>>> On Dec 18, 2017, at 08:35, Kalle Rosenbaum <kalle at rosenbaum.se> wrote:\n>>>> \n>>>> 2017-12-18 13:43 GMT+01:00 Eric Voskuil <eric at voskuil.org>:\n>>>>> \n>>>>> > On Dec 18, 2017, at 03:32, Kalle Rosenbaum via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>> >\n>>>>> > Dear list,\n>>>>> >\n>>>>> > I find it hard to understand why a full node that does initial block\n>>>>> > download also must download witnesses if they are going to skip verification anyway.\n>>>>> \n>>>>> Why run a full node if you are not going to verify the chain?\n>>>> \n>>>> I meant to say \"I find it hard to understand why a full node that does initial block\n>>>> download also must download witnesses when it is going to skip verification of the witnesses anyway.\"\n>>>> \n>>>> I'm referring to the \"assumevalid\" feature of Bitcoin Core that skips signature verification up to block X. Or have I misunderstood assumevalid?\n>>>> \n>>>> /Kalle\n>>>>  \n>>>>> \n>>>>> > If my full node skips signature verification for\n>>>>> > blocks earlier than X, it seems the reasons for downloading the\n>>>>> > witnesses for those blocks are:\n>>>>> >\n>>>>> > * to be able to send witnesses to other nodes.\n>>>>> >\n>>>>> > * to verify the witness root hash of the blocks\n>>>>> >\n>>>>> > I suppose that it's important to verify the witness root hash because\n>>>>> > a bad peer may send me invalid witnesses during initial block\n>>>>> > download, and if I don't verify that the witness root hash actually\n>>>>> > commits to them, I will get banned by peers requesting the blocks from\n>>>>> > me because I send them garbage.\n>>>>> > So both the reasons above (there may be more that I don't know about)\n>>>>> > are actually the same reason: To be able to send witnesses to others\n>>>>> > without getting banned.\n>>>>> >\n>>>>> > What if a node could chose not to download witnesses and thus chose to\n>>>>> > send only witnessless blocks to peers. Let's call these nodes\n>>>>> > witnessless nodes. Note that witnessless nodes are only witnessless\n>>>>> > for blocks up to X. Everything after X is fully verified.\n>>>>> >\n>>>>> > Witnessless nodes would be able to sync faster because it needs to\n>>>>> > download less data to calculate their UTXO set. They would therefore\n>>>>> > more quickly be able to provide full service to SPV wallets and its\n>>>>> > local wallets as well as serving blocks to other witnessless nodes\n>>>>> > with same or higher assumevalid block. For witnessless nodes with\n>>>>> > lower assumevalid they can serve at least some blocks. It could also\n>>>>> > serve blocks to non-segwit nodes.\n>>>>> >\n>>>>> > Do witnessless nodes risk dividing the network in two parts, one\n>>>>> > witnessless and one with full nodes, with few connections between the\n>>>>> > parts?\n>>>>> >\n>>>>> > So basically, what are the reasons not to implement witnessless\n>>>>> > nodes?\n>>>>> >\n>>>>> > Thank you,\n>>>>> > /Kalle\n>>>>> > _______________________________________________\n>>>>> > bitcoin-dev mailing list\n>>>>> > bitcoin-dev at lists.linuxfoundation.org\n>>>>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>> \n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> \n>> \n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/f9f579ba/attachment-0001.html>"
            },
            {
                "author": "Kalle Rosenbaum",
                "date": "2017-12-18T20:34:30",
                "message_text_only": "Thanks Eric.\n\nIt would be a pity if early witnesses got lost due to nodes abandoning them\nby running witnessless. But as long as there's at least one accessible\nsource for them left we're OKish. Let's hope we don't get to that point in\nthe near future. As long as Bitcoin Core doesn't implement witnessless\nmode, there's little risk.\n\nWhat do people here think about the benefits and risks with running\nwitnessless?\n\n/Kalle\n\nSent from my Sinclair ZX81\n\nDen 18 dec. 2017 17:19 skrev \"Eric Voskuil\" <eric at voskuil.org>:\n\n> You can't know (assume) a block is valid unless you have previously\n> validated the block yourself. But in the case where you have, and then\n> intend to rely on it in a future sync, there is no need for witness data\n> for blocks you are not going to validate. So you can just not request it.\n>\n> However you will not be able to provide those blocks to nodes that *are*\n> validating; the client is pruned and therefore not a peer (cannot\n> reciprocate). (An SPV client is similarly not a peer; it is a more deeply\n> pruned client than the witnessless client.)\n>\n> There is no other reason that a node requires witness data. SPV clients\n> don't need it as it is neither require it to verify header commitment to\n> transactions nor to extract payment addresses from them.\n>\n> The harm to the network by pruning is that eventually it can become harder\n> and even impossible for anyone to validate the chain. But because you are\n> fully validating you individually remain secure, so there is no individual\n> incentive working against this system harm.\n>\n> e\n>\n> On Dec 18, 2017, at 08:35, Kalle Rosenbaum <kalle at rosenbaum.se> wrote:\n>\n> 2017-12-18 13:43 GMT+01:00 Eric Voskuil <eric at voskuil.org>:\n>\n>>\n>> > On Dec 18, 2017, at 03:32, Kalle Rosenbaum via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> >\n>> > Dear list,\n>> >\n>> > I find it hard to understand why a full node that does initial block\n>> > download also must download witnesses if they are going to skip\n>> verification anyway.\n>>\n>> Why run a full node if you are not going to verify the chain?\n>>\n>\n> I meant to say \"I find it hard to understand why a full node that does\n> initial block\n> download also must download witnesses when it is going to skip\n> verification of the witnesses anyway.\"\n>\n> I'm referring to the \"assumevalid\" feature of Bitcoin Core that skips\n> signature verification up to block X. Or have I misunderstood assumevalid?\n>\n> /Kalle\n>\n>\n>>\n>> > If my full node skips signature verification for\n>> > blocks earlier than X, it seems the reasons for downloading the\n>> > witnesses for those blocks are:\n>> >\n>> > * to be able to send witnesses to other nodes.\n>> >\n>> > * to verify the witness root hash of the blocks\n>> >\n>> > I suppose that it's important to verify the witness root hash because\n>> > a bad peer may send me invalid witnesses during initial block\n>> > download, and if I don't verify that the witness root hash actually\n>> > commits to them, I will get banned by peers requesting the blocks from\n>> > me because I send them garbage.\n>> > So both the reasons above (there may be more that I don't know about)\n>> > are actually the same reason: To be able to send witnesses to others\n>> > without getting banned.\n>> >\n>> > What if a node could chose not to download witnesses and thus chose to\n>> > send only witnessless blocks to peers. Let's call these nodes\n>> > witnessless nodes. Note that witnessless nodes are only witnessless\n>> > for blocks up to X. Everything after X is fully verified.\n>> >\n>> > Witnessless nodes would be able to sync faster because it needs to\n>> > download less data to calculate their UTXO set. They would therefore\n>> > more quickly be able to provide full service to SPV wallets and its\n>> > local wallets as well as serving blocks to other witnessless nodes\n>> > with same or higher assumevalid block. For witnessless nodes with\n>> > lower assumevalid they can serve at least some blocks. It could also\n>> > serve blocks to non-segwit nodes.\n>> >\n>> > Do witnessless nodes risk dividing the network in two parts, one\n>> > witnessless and one with full nodes, with few connections between the\n>> > parts?\n>> >\n>> > So basically, what are the reasons not to implement witnessless\n>> > nodes?\n>> >\n>> > Thank you,\n>> > /Kalle\n>> > _______________________________________________\n>> > bitcoin-dev mailing list\n>> > bitcoin-dev at lists.linuxfoundation.org\n>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/23ed9807/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2017-12-18T20:42:34",
                "message_text_only": "Because it would make no meaningful difference now, and if you are not\ngoing to check the history there are much more efficient things to\ndo-- like not transfer it at all.\n\nOn Mon, Dec 18, 2017 at 8:32 AM, Kalle Rosenbaum via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Dear list,\n>\n> I find it hard to understand why a full node that does initial block\n> download also must download witnesses if they are going to skip\n> verification anyway. If my full node skips signature verification for\n> blocks earlier than X, it seems the reasons for downloading the\n> witnesses for those blocks are:\n>\n> * to be able to send witnesses to other nodes.\n>\n> * to verify the witness root hash of the blocks\n>\n> I suppose that it's important to verify the witness root hash because\n> a bad peer may send me invalid witnesses during initial block\n> download, and if I don't verify that the witness root hash actually\n> commits to them, I will get banned by peers requesting the blocks from\n> me because I send them garbage.\n>\n> So both the reasons above (there may be more that I don't know about)\n> are actually the same reason: To be able to send witnesses to others\n> without getting banned.\n>\n> What if a node could chose not to download witnesses and thus chose to\n> send only witnessless blocks to peers. Let's call these nodes\n> witnessless nodes. Note that witnessless nodes are only witnessless\n> for blocks up to X. Everything after X is fully verified.\n>\n> Witnessless nodes would be able to sync faster because it needs to\n> download less data to calculate their UTXO set. They would therefore\n> more quickly be able to provide full service to SPV wallets and its\n> local wallets as well as serving blocks to other witnessless nodes\n> with same or higher assumevalid block. For witnessless nodes with\n> lower assumevalid they can serve at least some blocks. It could also\n> serve blocks to non-segwit nodes.\n>\n> Do witnessless nodes risk dividing the network in two parts, one\n> witnessless and one with full nodes, with few connections between the\n> parts?\n>\n> So basically, what are the reasons not to implement witnessless\n> nodes?\n>\n> Thank you,\n> /Kalle\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Kalle Rosenbaum",
                "date": "2017-12-18T21:51:40",
                "message_text_only": "Hi Greg,\n\n2017-12-18 21:42 GMT+01:00 Gregory Maxwell <greg at xiph.org>:\n\n> Because it would make no meaningful difference now,\n\n\nSure.\n\n\n> and if you are not\n> going to check the history\n\n\nI'm not going to do any less checks than a node running with assumevalid.\nWell not exactly true, because a node running today with assumevalid will\nverify the witness root hash, right?\n\n\n> there are much more efficient things to\n> do-- like not transfer it at all.\n>\n\nI'm not sure what you are referring to.\n\nThank you\n/Kalle\n\n\n>\n> On Mon, Dec 18, 2017 at 8:32 AM, Kalle Rosenbaum via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > Dear list,\n> >\n> > I find it hard to understand why a full node that does initial block\n> > download also must download witnesses if they are going to skip\n> > verification anyway. If my full node skips signature verification for\n> > blocks earlier than X, it seems the reasons for downloading the\n> > witnesses for those blocks are:\n> >\n> > * to be able to send witnesses to other nodes.\n> >\n> > * to verify the witness root hash of the blocks\n> >\n> > I suppose that it's important to verify the witness root hash because\n> > a bad peer may send me invalid witnesses during initial block\n> > download, and if I don't verify that the witness root hash actually\n> > commits to them, I will get banned by peers requesting the blocks from\n> > me because I send them garbage.\n> >\n> > So both the reasons above (there may be more that I don't know about)\n> > are actually the same reason: To be able to send witnesses to others\n> > without getting banned.\n> >\n> > What if a node could chose not to download witnesses and thus chose to\n> > send only witnessless blocks to peers. Let's call these nodes\n> > witnessless nodes. Note that witnessless nodes are only witnessless\n> > for blocks up to X. Everything after X is fully verified.\n> >\n> > Witnessless nodes would be able to sync faster because it needs to\n> > download less data to calculate their UTXO set. They would therefore\n> > more quickly be able to provide full service to SPV wallets and its\n> > local wallets as well as serving blocks to other witnessless nodes\n> > with same or higher assumevalid block. For witnessless nodes with\n> > lower assumevalid they can serve at least some blocks. It could also\n> > serve blocks to non-segwit nodes.\n> >\n> > Do witnessless nodes risk dividing the network in two parts, one\n> > witnessless and one with full nodes, with few connections between the\n> > parts?\n> >\n> > So basically, what are the reasons not to implement witnessless\n> > nodes?\n> >\n> > Thank you,\n> > /Kalle\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/f5af3a69/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Why not witnessless nodes?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Eric Voskuil",
                "Ozgur",
                "Kalle Rosenbaum",
                "Gregory Maxwell",
                "Mark Friedenbach"
            ],
            "messages_count": 11,
            "total_messages_chars_count": 41053
        }
    },
    {
        "title": "[bitcoin-dev] Clarification about SegWit transaction size and bech32",
        "thread_messages": [
            {
                "author": "Alberto De Luigi",
                "date": "2017-12-18T16:40:08",
                "message_text_only": "Hello guys,\n\nI have a few questions about the SegWit tx size, I'd like to have\nconfirmation about the following statements. Can you correct mistakes or\ninaccuracies? Thank you in advance.\n\n \n\nIn general, SegWit tx costs more than legacy tx (source\nhttps://bitcoincore.org/en/2016/10/28/segwit-costs/):\n\n \n\n*\tCompared to P2PKH, P2WPKH uses 3 fewer bytes (-1%) in the\nscriptPubKey, and the same number of witness bytes as P2PKH scriptSig.\n*\tCompared to P2SH, P2WSH uses 11 additional bytes (6%) in the\nscriptPubKey, and the same number of witness bytes as P2SH scriptSig.\n*\tCompared to P2PKH, P2WPKH/P2SH uses 21 additional bytes (11%), due\nto using 24 bytes in scriptPubKey, 3 fewer bytes in scriptSig than in P2PKH\nscriptPubKey, and the same number of witness bytes as P2PKH scriptSig.\n*\tCompared to P2SH, P2WSH/P2SH uses 35 additional bytes (19%), due to\nusing 24 bytes in scriptPubKey, 11 additional bytes in scriptSig compared to\nP2SH scriptPubKey, and the same number of witness bytes as P2SH scriptSig.\n\n \n\nBut still it is convenient to adopt segwit because you move the bytes to the\nblockweight part, paying smaller fee. In general, a tx with 1 input and 1\noutput is about 190kb. If it's a Segwit tx, 82kb in the non-witness part\n(blocksize), 108 in the witness part (blockweight).\n\nSee source:\n\n4 bytes version\n\n1 byte input count\n\nInput\n\n36 bytes outpoint\n\n1 byte scriptSigLen (0x00)\n\n0 bytes scriptSig\n\n4 bytes sequence\n\n1 byte output count\n\n8 bytes value\n\n1 byte scriptPubKeyLen\n\n22 bytes scriptPubKey (0x0014{20-byte keyhash})\n\n4 bytes locktime\n\nhttps://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactio\nns-what-would-be-the-max-number-of-transaction-confi\n\n \n\nWhich means, if you fill a block entirely with this kind of tx, you can\napproximately double the capacity of the blockchain (blocksize capped to\n1mb, blockweight a little bit more than 2mb)\n\n \n\nMy concern is about segwit adoption by the exchanges. \n\nSegWit transactions cost 10bytes more than legacy transactions for each\noutput (vout is 256 bits instead of 160). Exchanges aggregate tx adding many\noutputs, which is of course something good for bitcoin scalability, since\nthis way we save space and pay less fees.\n\nBut when a tx has at least 10 outputs, using segwit you don't save space,\ninstead:\n\n- the total blockweight is at least 100bytes higher (10bytes x 10 outputs),\nso the blockchain is heavier \n\n- you don't save space inside the blocksize, so you cannot validate more\ntransactions of this kind (with many outputs), nor get cheaper fee\n\n- without cheaper fees exchanges have no incentives for segwit adoption\nbefore they decide to adopt LN\n\n \n\nIn general we can say that using SegWit:\n\n- you decrease the fee only for some specific kind of transactions, and just\nbecause you move some bytes to the blockweight\n\n- you don't save space in the blockchain, on the contrary the total weight\nof the blockchain increases (so it's clear to me why some time ago Luke\ntweeted to not use SegWit unless really necessary... but then it's not clear\nwhy so much haste in promoting BIP148 the 1st august risking a split)\n\n \n\nIf it's all correct, does something change with bech32? I'm reading bech32\nallows to save about 22% of the space. Is this true for whatever kind of tx?\nImmediate benefits of segwit for scalability are only with bech32?\n\n \n\nBech32 is non-compatible with the entire ecosystem (you cannot receive coins\nfrom the quasi-totality of wallets in circulation), I would say it is a hard\nfork. But the bare segwit is really so different? the soft fork is \"soft\"\nfor the reference client Bitcoin Core, but outside you cannot know what\nhappens, there are plenty of implementations (especially frontend\ncustomization) which don't work with segwit and need to upgrade. To upgrade\ntakes a lot of time, especially when services are so crowded and so many new\npeople want to step in. At this point, if bech32 brings only efficiency (but\ncorrect me if it's not so) and it is well planned, it could be a consensual\nupgrade, maybe together with a 2x blocksize? Is there a specific plan for\nsome upgrade in 2018? I personally think it is far easier to reach consensus\non a blocksize increase una tantum rather than a dynamic increase. You\ncannot predict the technology growth: will it be linear, exponential, or\nsuddenly stop for a while, maybe right before a huge innovation? I think a\nhard fork bech32 upgrade + 2x could help a lot in scalability while we test\nLN, and it might be the only way to effectively promote (or should I say\nenforce?) SegWit adoption.\n\n \n\nthank you,\n\nAlberto De Luigi\n\n(.com)\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/c095de60/attachment.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-12-18T17:38:01",
                "message_text_only": "Addresses are entirely a user-interface issue. They don\u2019t factor into the bitcoin protocol at all.\n\nThe bitcoin protocol doesn\u2019t have addresses. It has a generic programmable signature framework called script. Addresses are merely a UI convention for representing common script templates. 1.. addresses and 3\u2026 addresses have script templates that are not as optimal as could be constructed with post-segwit assumptions. The newer bech32 address just uses a different underlying template that achieves better security guarantees (for pay-to-script) or lower fees (for pay-to-pubkey-hash). But this is really a UI/UX issue.\n\nA \u201cfork\u201d in bitcoin-like consensus systems has a very specific meaning. Changing address formats is not a fork, soft or hard.\n\nThere are many benefits to segregated witness. You may find this page helpful:\n\nhttps://bitcoincore.org/en/2016/01/26/segwit-benefits/ <https://bitcoincore.org/en/2016/01/26/segwit-benefits/>\n\n> On Dec 18, 2017, at 8:40 AM, Alberto De Luigi via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Hello guys,\n> I have a few questions about the SegWit tx size, I'd like to have confirmation about the following statements. Can you correct mistakes or inaccuracies? Thank you in advance.\n>  \n> In general, SegWit tx costs more than legacy tx (source https://bitcoincore.org/en/2016/10/28/segwit-costs/ <https://bitcoincore.org/en/2016/10/28/segwit-costs/>):\n>  \n> Compared to P2PKH, P2WPKH uses 3 fewer bytes (-1%) in the scriptPubKey, and the same number of witness bytes as P2PKH scriptSig.\n> Compared to P2SH, P2WSH uses 11 additional bytes (6%) in the scriptPubKey, and the same number of witness bytes as P2SH scriptSig.\n> Compared to P2PKH, P2WPKH/P2SH uses 21 additional bytes (11%), due to using 24 bytes in scriptPubKey, 3 fewer bytes in scriptSig than in P2PKH scriptPubKey, and the same number of witness bytes as P2PKH scriptSig.\n> Compared to P2SH, P2WSH/P2SH uses 35 additional bytes (19%), due to using 24 bytes in scriptPubKey, 11 additional bytes in scriptSig compared to P2SH scriptPubKey, and the same number of witness bytes as P2SH scriptSig.\n>  \n> But still it is convenient to adopt segwit because you move the bytes to the blockweight part, paying smaller fee. In general, a tx with 1 input and 1 output is about 190kb. If it's a Segwit tx, 82kb in the non-witness part (blocksize), 108 in the witness part (blockweight).\n> See source:\n> 4 bytes version\n> 1 byte input count\n> Input\n> 36 bytes outpoint\n> 1 byte scriptSigLen (0x00)\n> 0 bytes scriptSig\n> 4 bytes sequence\n> 1 byte output count\n> 8 bytes value\n> 1 byte scriptPubKeyLen\n> 22 bytes scriptPubKey (0x0014{20-byte keyhash})\n> 4 bytes locktime\n> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactions-what-would-be-the-max-number-of-transaction-confi <https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactions-what-would-be-the-max-number-of-transaction-confi>\n>  \n> Which means, if you fill a block entirely with this kind of tx, you can approximately double the capacity of the blockchain (blocksize capped to 1mb, blockweight a little bit more than 2mb)\n>  \n> My concern is about segwit adoption by the exchanges. \n> SegWit transactions cost 10bytes more than legacy transactions for each output (vout is 256 bits instead of 160). Exchanges aggregate tx adding many outputs, which is of course something good for bitcoin scalability, since this way we save space and pay less fees.\n> But when a tx has at least 10 outputs, using segwit you don't save space, instead:\n> - the total blockweight is at least 100bytes higher (10bytes x 10 outputs), so the blockchain is heavier \n> - you don't save space inside the blocksize, so you cannot validate more transactions of this kind (with many outputs), nor get cheaper fee\n> - without cheaper fees exchanges have no incentives for segwit adoption before they decide to adopt LN\n>  \n> In general we can say that using SegWit:\n> - you decrease the fee only for some specific kind of transactions, and just because you move some bytes to the blockweight\n> - you don\u2019t save space in the blockchain, on the contrary the total weight of the blockchain increases (so it's clear to me why some time ago Luke tweeted to not use SegWit unless really necessary... but then it's not clear why so much haste in promoting BIP148 the 1st august risking a split)\n>  \n> If it's all correct, does something change with bech32? I'm reading bech32 allows to save about 22% of the space. Is this true for whatever kind of tx? Immediate benefits of segwit for scalability are only with bech32?\n>  \n> Bech32 is non-compatible with the entire ecosystem (you cannot receive coins from the quasi-totality of wallets in circulation), I would say it is a hard fork. But the bare segwit is really so different? the soft fork is \"soft\" for the reference client Bitcoin Core, but outside you cannot know what happens, there are plenty of implementations (especially frontend customization) which don\u2019t work with segwit and need to upgrade. To upgrade takes a lot of time, especially when services are so crowded and so many new people want to step in. At this point, if bech32 brings only efficiency (but correct me if it\u2019s not so) and it is well planned, it could be a consensual upgrade, maybe together with a 2x blocksize? Is there a specific plan for some upgrade in 2018? I personally think it is far easier to reach consensus on a blocksize increase una tantum rather than a dynamic increase. You cannot predict the technology growth: will it be linear, exponential, or suddenly stop for a while, maybe right before a huge innovation? I think a hard fork bech32 upgrade + 2x could help a lot in scalability while we test LN, and it might be the only way to effectively promote (or should I say enforce?) SegWit adoption.\n>  \n> thank you,\n> Alberto De Luigi\n> (.com)\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/d9694d67/attachment.html>"
            },
            {
                "author": "mail at albertodeluigi.com",
                "date": "2017-12-18T21:41:18",
                "message_text_only": "Hi Mark,\nthank you. I understand your point, but despite what we define as a \nfork, when a software uses a particular address, it becomes part of the \nrules of that software. If another software doesn't recognize that \naddress as a bitcoin address, then the rules it enforces aren't \ncompatible with the behaviour of the first software. If you send me your \nbitcoins, I can't receive it, exactly like if it was in another chain. \nThis happens even if there isn't such a situation where miners verify \nthat transaction on a chain, while other miners reject it.\n\nIf we want to change the addresses, we need consensus and the coordinate \nupgrade of the entire network. In case we haven't consensus, most of the \nclients cannot send and receive bitcoins, which is a huge problem.\nFor this reason I think it is something we should discuss in order to \nmake a coordinated upgrade, exactly like what we do when we propose a \nfork. And it would be better to do it precisely as a part of a fork, \nlike a 2x (or whatever other upgrade gaining enough consensus)\n\nApart from the proposal of an upgrade to bench32, do you agree with the \nrest of my points? I know segwit is valuable because it fixes tx \nmalleability and so on... thank you for your link, but that wasn't the \npoint I wanted to highlight!\n\nThank you,\nAlberto\n\n\n\n\nIl 2017-12-18 18:38 Mark Friedenbach ha scritto:\n> Addresses are entirely a user-interface issue. They don\u2019t factor\n> into the bitcoin protocol at all.\n> \n> The bitcoin protocol doesn\u2019t have addresses. It has a generic\n> programmable signature framework called script. Addresses are merely a\n> UI convention for representing common script templates. 1.. addresses\n> and 3\u2026 addresses have script templates that are not as optimal as\n> could be constructed with post-segwit assumptions. The newer bech32\n> address just uses a different underlying template that achieves better\n> security guarantees (for pay-to-script) or lower fees (for\n> pay-to-pubkey-hash). But this is really a UI/UX issue.\n> \n> A \u201cfork\u201d in bitcoin-like consensus systems has a very specific\n> meaning. Changing address formats is not a fork, soft or hard.\n> \n> There are many benefits to segregated witness. You may find this page\n> helpful:\n> \n> https://bitcoincore.org/en/2016/01/26/segwit-benefits/ [4]\n> \n>> On Dec 18, 2017, at 8:40 AM, Alberto De Luigi via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> \n>> Hello guys,\n>> I have a few questions about the SegWit tx size, I'd like to have\n>> confirmation about the following statements. Can you correct\n>> mistakes or inaccuracies? Thank you in advance.\n>> \n>> In general, SegWit tx costs more than legacy tx (source\n>> https://bitcoincore.org/en/2016/10/28/segwit-costs/ [1]):\n>> \n>> * Compared to P2PKH, P2WPKH uses 3 fewer bytes (-1%) in the\n>> scriptPubKey, and the same number of witness bytes as P2PKH\n>> scriptSig.\n>> * Compared to P2SH, P2WSH uses 11 additional bytes (6%) in the\n>> scriptPubKey, and the same number of witness bytes as P2SH\n>> scriptSig.\n>> * Compared to P2PKH, P2WPKH/P2SH uses 21 additional bytes (11%),\n>> due to using 24 bytes in scriptPubKey, 3 fewer bytes in scriptSig\n>> than in P2PKH scriptPubKey, and the same number of witness bytes as\n>> P2PKH scriptSig.\n>> * Compared to P2SH, P2WSH/P2SH uses 35 additional bytes (19%), due\n>> to using 24 bytes in scriptPubKey, 11 additional bytes in scriptSig\n>> compared to P2SH scriptPubKey, and the same number of witness bytes\n>> as P2SH scriptSig.\n>> \n>> But still it is convenient to adopt segwit because you move the\n>> bytes to the blockweight part, paying smaller fee. In general, a tx\n>> with 1 input and 1 output is about 190kb. If it's a Segwit tx, 82kb\n>> in the non-witness part (blocksize), 108 in the witness part\n>> (blockweight).\n>> See source:\n>> 4 bytes version\n>> 1 byte input count\n>> Input\n>> 36 bytes outpoint\n>> 1 byte scriptSigLen (0x00)\n>> 0 bytes scriptSig\n>> 4 bytes sequence\n>> 1 byte output count\n>> 8 bytes value\n>> 1 byte scriptPubKeyLen\n>> 22 bytes scriptPubKey (0x0014{20-byte keyhash})\n>> 4 bytes locktime\n>> \n> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactions-what-would-be-the-max-number-of-transaction-confi\n>> [2]\n>> \n>> Which means, if you fill a block entirely with this kind of tx, you\n>> can approximately double the capacity of the blockchain (blocksize\n>> capped to 1mb, blockweight a little bit more than 2mb)\n>> \n>> My concern is about segwit adoption by the exchanges.\n>> SegWit transactions cost 10bytes more than legacy transactions for\n>> each output (vout is 256 bits instead of 160). Exchanges aggregate\n>> tx adding many outputs, which is of course something good for\n>> bitcoin scalability, since this way we save space and pay less fees.\n>> But when a tx has at least 10 outputs, using segwit you don't save\n>> space, instead:\n>> \n>> - the total blockweight is at least 100bytes higher (10bytes x 10\n>> outputs), so the blockchain is heavier\n>> - you don't save space inside the blocksize, so you cannot validate\n>> more transactions of this kind (with many outputs), nor get cheaper\n>> fee\n>> - without cheaper fees exchanges have no incentives for segwit\n>> adoption before they decide to adopt LN\n>> \n>> In general we can say that using SegWit:\n>> - you decrease the fee only for some specific kind of transactions,\n>> and just because you move some bytes to the blockweight\n>> - you don\u2019t save space in the blockchain, on the contrary the\n>> total weight of the blockchain increases (so it's clear to me why\n>> some time ago Luke tweeted to not use SegWit unless really\n>> necessary... but then it's not clear why so much haste in promoting\n>> BIP148 the 1st august risking a split)\n>> \n>> If it's all correct, does something change with bech32? I'm reading\n>> bech32 allows to save about 22% of the space. Is this true for\n>> whatever kind of tx? Immediate benefits of segwit for scalability\n>> are only with bech32?\n>> \n>> Bech32 is non-compatible with the entire ecosystem (you cannot\n>> receive coins from the quasi-totality of wallets in circulation), I\n>> would say it is a hard fork. But the bare segwit is really so\n>> different? the soft fork is \"soft\" for the reference client Bitcoin\n>> Core, but outside you cannot know what happens, there are plenty of\n>> implementations (especially frontend customization) which don\u2019t\n>> work with segwit and need to upgrade. To upgrade takes a lot of\n>> time, especially when services are so crowded and so many new people\n>> want to step in. At this point, if bech32 brings only efficiency\n>> (but correct me if it\u2019s not so) and it is well planned, it could\n>> be a consensual upgrade, maybe together with a 2x blocksize? Is\n>> there a specific plan for some upgrade in 2018? I personally think\n>> it is far easier to reach consensus on a blocksize increase una\n>> tantum rather than a dynamic increase. You cannot predict the\n>> technology growth: will it be linear, exponential, or suddenly stop\n>> for a while, maybe right before a huge innovation? I think a hard\n>> fork bech32 upgrade + 2x could help a lot in scalability while we\n>> test LN, and it might be the only way to effectively promote (or\n>> should I say enforce?) SegWit adoption.\n>> \n>> thank you,\n>> Alberto De Luigi\n>> (.com)_______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev [3]\n> \n> \n> \n> Links:\n> ------\n> [1] https://bitcoincore.org/en/2016/10/28/segwit-costs/\n> [2]\n> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactions-what-would-be-the-max-number-of-transaction-confi\n> [3] https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> [4] https://bitcoincore.org/en/2016/01/26/segwit-benefits/"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-12-18T22:03:44",
                "message_text_only": "Why would I send you coins to anything other than the address you provided to me? If you send me a bech32 address I use the native segwit scripts. If you send me an old address, I do what it specifies instead. The recipient has control over what type of script the payment is sent to, without any ambiguity.\n\n> On Dec 18, 2017, at 1:41 PM, mail at albertodeluigi.com wrote:\n> \n> Hi Mark,\n> thank you. I understand your point, but despite what we define as a fork, when a software uses a particular address, it becomes part of the rules of that software. If another software doesn't recognize that address as a bitcoin address, then the rules it enforces aren't compatible with the behaviour of the first software. If you send me your bitcoins, I can't receive it, exactly like if it was in another chain. This happens even if there isn't such a situation where miners verify that transaction on a chain, while other miners reject it.\n> \n> If we want to change the addresses, we need consensus and the coordinate upgrade of the entire network. In case we haven't consensus, most of the clients cannot send and receive bitcoins, which is a huge problem.\n> For this reason I think it is something we should discuss in order to make a coordinated upgrade, exactly like what we do when we propose a fork. And it would be better to do it precisely as a part of a fork, like a 2x (or whatever other upgrade gaining enough consensus)\n> \n> Apart from the proposal of an upgrade to bench32, do you agree with the rest of my points? I know segwit is valuable because it fixes tx malleability and so on... thank you for your link, but that wasn't the point I wanted to highlight!\n> \n> Thank you,\n> Alberto\n> \n> \n> \n> \n> Il 2017-12-18 18:38 Mark Friedenbach ha scritto:\n>> Addresses are entirely a user-interface issue. They don\u2019t factor\n>> into the bitcoin protocol at all.\n>> The bitcoin protocol doesn\u2019t have addresses. It has a generic\n>> programmable signature framework called script. Addresses are merely a\n>> UI convention for representing common script templates. 1.. addresses\n>> and 3\u2026 addresses have script templates that are not as optimal as\n>> could be constructed with post-segwit assumptions. The newer bech32\n>> address just uses a different underlying template that achieves better\n>> security guarantees (for pay-to-script) or lower fees (for\n>> pay-to-pubkey-hash). But this is really a UI/UX issue.\n>> A \u201cfork\u201d in bitcoin-like consensus systems has a very specific\n>> meaning. Changing address formats is not a fork, soft or hard.\n>> There are many benefits to segregated witness. You may find this page\n>> helpful:\n>> https://bitcoincore.org/en/2016/01/26/segwit-benefits/ [4]\n>>> On Dec 18, 2017, at 8:40 AM, Alberto De Luigi via bitcoin-dev\n>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> Hello guys,\n>>> I have a few questions about the SegWit tx size, I'd like to have\n>>> confirmation about the following statements. Can you correct\n>>> mistakes or inaccuracies? Thank you in advance.\n>>> In general, SegWit tx costs more than legacy tx (source\n>>> https://bitcoincore.org/en/2016/10/28/segwit-costs/ [1]):\n>>> * Compared to P2PKH, P2WPKH uses 3 fewer bytes (-1%) in the\n>>> scriptPubKey, and the same number of witness bytes as P2PKH\n>>> scriptSig.\n>>> * Compared to P2SH, P2WSH uses 11 additional bytes (6%) in the\n>>> scriptPubKey, and the same number of witness bytes as P2SH\n>>> scriptSig.\n>>> * Compared to P2PKH, P2WPKH/P2SH uses 21 additional bytes (11%),\n>>> due to using 24 bytes in scriptPubKey, 3 fewer bytes in scriptSig\n>>> than in P2PKH scriptPubKey, and the same number of witness bytes as\n>>> P2PKH scriptSig.\n>>> * Compared to P2SH, P2WSH/P2SH uses 35 additional bytes (19%), due\n>>> to using 24 bytes in scriptPubKey, 11 additional bytes in scriptSig\n>>> compared to P2SH scriptPubKey, and the same number of witness bytes\n>>> as P2SH scriptSig.\n>>> But still it is convenient to adopt segwit because you move the\n>>> bytes to the blockweight part, paying smaller fee. In general, a tx\n>>> with 1 input and 1 output is about 190kb. If it's a Segwit tx, 82kb\n>>> in the non-witness part (blocksize), 108 in the witness part\n>>> (blockweight).\n>>> See source:\n>>> 4 bytes version\n>>> 1 byte input count\n>>> Input\n>>> 36 bytes outpoint\n>>> 1 byte scriptSigLen (0x00)\n>>> 0 bytes scriptSig\n>>> 4 bytes sequence\n>>> 1 byte output count\n>>> 8 bytes value\n>>> 1 byte scriptPubKeyLen\n>>> 22 bytes scriptPubKey (0x0014{20-byte keyhash})\n>>> 4 bytes locktime\n>> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactions-what-would-be-the-max-number-of-transaction-confi\n>>> [2]\n>>> Which means, if you fill a block entirely with this kind of tx, you\n>>> can approximately double the capacity of the blockchain (blocksize\n>>> capped to 1mb, blockweight a little bit more than 2mb)\n>>> My concern is about segwit adoption by the exchanges.\n>>> SegWit transactions cost 10bytes more than legacy transactions for\n>>> each output (vout is 256 bits instead of 160). Exchanges aggregate\n>>> tx adding many outputs, which is of course something good for\n>>> bitcoin scalability, since this way we save space and pay less fees.\n>>> But when a tx has at least 10 outputs, using segwit you don't save\n>>> space, instead:\n>>> - the total blockweight is at least 100bytes higher (10bytes x 10\n>>> outputs), so the blockchain is heavier\n>>> - you don't save space inside the blocksize, so you cannot validate\n>>> more transactions of this kind (with many outputs), nor get cheaper\n>>> fee\n>>> - without cheaper fees exchanges have no incentives for segwit\n>>> adoption before they decide to adopt LN\n>>> In general we can say that using SegWit:\n>>> - you decrease the fee only for some specific kind of transactions,\n>>> and just because you move some bytes to the blockweight\n>>> - you don\u2019t save space in the blockchain, on the contrary the\n>>> total weight of the blockchain increases (so it's clear to me why\n>>> some time ago Luke tweeted to not use SegWit unless really\n>>> necessary... but then it's not clear why so much haste in promoting\n>>> BIP148 the 1st august risking a split)\n>>> If it's all correct, does something change with bech32? I'm reading\n>>> bech32 allows to save about 22% of the space. Is this true for\n>>> whatever kind of tx? Immediate benefits of segwit for scalability\n>>> are only with bech32?\n>>> Bech32 is non-compatible with the entire ecosystem (you cannot\n>>> receive coins from the quasi-totality of wallets in circulation), I\n>>> would say it is a hard fork. But the bare segwit is really so\n>>> different? the soft fork is \"soft\" for the reference client Bitcoin\n>>> Core, but outside you cannot know what happens, there are plenty of\n>>> implementations (especially frontend customization) which don\u2019t\n>>> work with segwit and need to upgrade. To upgrade takes a lot of\n>>> time, especially when services are so crowded and so many new people\n>>> want to step in. At this point, if bech32 brings only efficiency\n>>> (but correct me if it\u2019s not so) and it is well planned, it could\n>>> be a consensual upgrade, maybe together with a 2x blocksize? Is\n>>> there a specific plan for some upgrade in 2018? I personally think\n>>> it is far easier to reach consensus on a blocksize increase una\n>>> tantum rather than a dynamic increase. You cannot predict the\n>>> technology growth: will it be linear, exponential, or suddenly stop\n>>> for a while, maybe right before a huge innovation? I think a hard\n>>> fork bech32 upgrade + 2x could help a lot in scalability while we\n>>> test LN, and it might be the only way to effectively promote (or\n>>> should I say enforce?) SegWit adoption.\n>>> thank you,\n>>> Alberto De Luigi\n>>> (.com)_______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev [3]\n>> Links:\n>> ------\n>> [1] https://bitcoincore.org/en/2016/10/28/segwit-costs/\n>> [2]\n>> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactions-what-would-be-the-max-number-of-transaction-confi\n>> [3] https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> [4] https://bitcoincore.org/en/2016/01/26/segwit-benefits/\n> \n>"
            },
            {
                "author": "mail at albertodeluigi.com",
                "date": "2017-12-18T22:19:34",
                "message_text_only": "Mark,\nsuppose I am an average user. Give me a bech32 address and ask me to \nsend a few coins there. I am 100% sure you will never receive my coins. \nI will call you back saying: \"Mark, sorry, I tried with three different \nwallets, but it seems what you gave me is not a bitcoin address!\"\n\nMy point is: we want SegWit is used and implemented more and more by the \ncommunity. But if besides malleability fix, the main effect of sw \nadoption is this:\n\n1) The blockahin is heavier (transactions require more space)\n2) the fee is smaller only for some kind of tx\n3) the transactions of the exchanges, which aggregate outputs, would be \nheavier and pay a higher fee using segwit!\n\nthen how can we expect people, exchanges and services to adopt segwit?\n\nThank you,\nAlberto De Luigi\n\n\n\nIl 2017-12-18 23:03 Mark Friedenbach ha scritto:\n> Why would I send you coins to anything other than the address you\n> provided to me? If you send me a bech32 address I use the native\n> segwit scripts. If you send me an old address, I do what it specifies\n> instead. The recipient has control over what type of script the\n> payment is sent to, without any ambiguity.\n> \n>> On Dec 18, 2017, at 1:41 PM, mail at albertodeluigi.com wrote:\n>> \n>> Hi Mark,\n>> thank you. I understand your point, but despite what we define as a \n>> fork, when a software uses a particular address, it becomes part of \n>> the rules of that software. If another software doesn't recognize that \n>> address as a bitcoin address, then the rules it enforces aren't \n>> compatible with the behaviour of the first software. If you send me \n>> your bitcoins, I can't receive it, exactly like if it was in another \n>> chain. This happens even if there isn't such a situation where miners \n>> verify that transaction on a chain, while other miners reject it.\n>> \n>> If we want to change the addresses, we need consensus and the \n>> coordinate upgrade of the entire network. In case we haven't \n>> consensus, most of the clients cannot send and receive bitcoins, which \n>> is a huge problem.\n>> For this reason I think it is something we should discuss in order to \n>> make a coordinated upgrade, exactly like what we do when we propose a \n>> fork. And it would be better to do it precisely as a part of a fork, \n>> like a 2x (or whatever other upgrade gaining enough consensus)\n>> \n>> Apart from the proposal of an upgrade to bench32, do you agree with \n>> the rest of my points? I know segwit is valuable because it fixes tx \n>> malleability and so on... thank you for your link, but that wasn't the \n>> point I wanted to highlight!\n>> \n>> Thank you,\n>> Alberto\n>> \n>> \n>> \n>> \n>> Il 2017-12-18 18:38 Mark Friedenbach ha scritto:\n>>> Addresses are entirely a user-interface issue. They don\u2019t factor\n>>> into the bitcoin protocol at all.\n>>> The bitcoin protocol doesn\u2019t have addresses. It has a generic\n>>> programmable signature framework called script. Addresses are merely \n>>> a\n>>> UI convention for representing common script templates. 1.. addresses\n>>> and 3\u2026 addresses have script templates that are not as optimal as\n>>> could be constructed with post-segwit assumptions. The newer bech32\n>>> address just uses a different underlying template that achieves \n>>> better\n>>> security guarantees (for pay-to-script) or lower fees (for\n>>> pay-to-pubkey-hash). But this is really a UI/UX issue.\n>>> A \u201cfork\u201d in bitcoin-like consensus systems has a very specific\n>>> meaning. Changing address formats is not a fork, soft or hard.\n>>> There are many benefits to segregated witness. You may find this page\n>>> helpful:\n>>> https://bitcoincore.org/en/2016/01/26/segwit-benefits/ [4]\n>>>> On Dec 18, 2017, at 8:40 AM, Alberto De Luigi via bitcoin-dev\n>>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>> Hello guys,\n>>>> I have a few questions about the SegWit tx size, I'd like to have\n>>>> confirmation about the following statements. Can you correct\n>>>> mistakes or inaccuracies? Thank you in advance.\n>>>> In general, SegWit tx costs more than legacy tx (source\n>>>> https://bitcoincore.org/en/2016/10/28/segwit-costs/ [1]):\n>>>> * Compared to P2PKH, P2WPKH uses 3 fewer bytes (-1%) in the\n>>>> scriptPubKey, and the same number of witness bytes as P2PKH\n>>>> scriptSig.\n>>>> * Compared to P2SH, P2WSH uses 11 additional bytes (6%) in the\n>>>> scriptPubKey, and the same number of witness bytes as P2SH\n>>>> scriptSig.\n>>>> * Compared to P2PKH, P2WPKH/P2SH uses 21 additional bytes (11%),\n>>>> due to using 24 bytes in scriptPubKey, 3 fewer bytes in scriptSig\n>>>> than in P2PKH scriptPubKey, and the same number of witness bytes as\n>>>> P2PKH scriptSig.\n>>>> * Compared to P2SH, P2WSH/P2SH uses 35 additional bytes (19%), due\n>>>> to using 24 bytes in scriptPubKey, 11 additional bytes in scriptSig\n>>>> compared to P2SH scriptPubKey, and the same number of witness bytes\n>>>> as P2SH scriptSig.\n>>>> But still it is convenient to adopt segwit because you move the\n>>>> bytes to the blockweight part, paying smaller fee. In general, a tx\n>>>> with 1 input and 1 output is about 190kb. If it's a Segwit tx, 82kb\n>>>> in the non-witness part (blocksize), 108 in the witness part\n>>>> (blockweight).\n>>>> See source:\n>>>> 4 bytes version\n>>>> 1 byte input count\n>>>> Input\n>>>> 36 bytes outpoint\n>>>> 1 byte scriptSigLen (0x00)\n>>>> 0 bytes scriptSig\n>>>> 4 bytes sequence\n>>>> 1 byte output count\n>>>> 8 bytes value\n>>>> 1 byte scriptPubKeyLen\n>>>> 22 bytes scriptPubKey (0x0014{20-byte keyhash})\n>>>> 4 bytes locktime\n>>> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactions-what-would-be-the-max-number-of-transaction-confi\n>>>> [2]\n>>>> Which means, if you fill a block entirely with this kind of tx, you\n>>>> can approximately double the capacity of the blockchain (blocksize\n>>>> capped to 1mb, blockweight a little bit more than 2mb)\n>>>> My concern is about segwit adoption by the exchanges.\n>>>> SegWit transactions cost 10bytes more than legacy transactions for\n>>>> each output (vout is 256 bits instead of 160). Exchanges aggregate\n>>>> tx adding many outputs, which is of course something good for\n>>>> bitcoin scalability, since this way we save space and pay less fees.\n>>>> But when a tx has at least 10 outputs, using segwit you don't save\n>>>> space, instead:\n>>>> - the total blockweight is at least 100bytes higher (10bytes x 10\n>>>> outputs), so the blockchain is heavier\n>>>> - you don't save space inside the blocksize, so you cannot validate\n>>>> more transactions of this kind (with many outputs), nor get cheaper\n>>>> fee\n>>>> - without cheaper fees exchanges have no incentives for segwit\n>>>> adoption before they decide to adopt LN\n>>>> In general we can say that using SegWit:\n>>>> - you decrease the fee only for some specific kind of transactions,\n>>>> and just because you move some bytes to the blockweight\n>>>> - you don\u2019t save space in the blockchain, on the contrary the\n>>>> total weight of the blockchain increases (so it's clear to me why\n>>>> some time ago Luke tweeted to not use SegWit unless really\n>>>> necessary... but then it's not clear why so much haste in promoting\n>>>> BIP148 the 1st august risking a split)\n>>>> If it's all correct, does something change with bech32? I'm reading\n>>>> bech32 allows to save about 22% of the space. Is this true for\n>>>> whatever kind of tx? Immediate benefits of segwit for scalability\n>>>> are only with bech32?\n>>>> Bech32 is non-compatible with the entire ecosystem (you cannot\n>>>> receive coins from the quasi-totality of wallets in circulation), I\n>>>> would say it is a hard fork. But the bare segwit is really so\n>>>> different? the soft fork is \"soft\" for the reference client Bitcoin\n>>>> Core, but outside you cannot know what happens, there are plenty of\n>>>> implementations (especially frontend customization) which don\u2019t\n>>>> work with segwit and need to upgrade. To upgrade takes a lot of\n>>>> time, especially when services are so crowded and so many new people\n>>>> want to step in. At this point, if bech32 brings only efficiency\n>>>> (but correct me if it\u2019s not so) and it is well planned, it could\n>>>> be a consensual upgrade, maybe together with a 2x blocksize? Is\n>>>> there a specific plan for some upgrade in 2018? I personally think\n>>>> it is far easier to reach consensus on a blocksize increase una\n>>>> tantum rather than a dynamic increase. You cannot predict the\n>>>> technology growth: will it be linear, exponential, or suddenly stop\n>>>> for a while, maybe right before a huge innovation? I think a hard\n>>>> fork bech32 upgrade + 2x could help a lot in scalability while we\n>>>> test LN, and it might be the only way to effectively promote (or\n>>>> should I say enforce?) SegWit adoption.\n>>>> thank you,\n>>>> Alberto De Luigi\n>>>> (.com)_______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev [3]\n>>> Links:\n>>> ------\n>>> [1] https://bitcoincore.org/en/2016/10/28/segwit-costs/\n>>> [2]\n>>> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactions-what-would-be-the-max-number-of-transaction-confi\n>>> [3] https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>> [4] https://bitcoincore.org/en/2016/01/26/segwit-benefits/\n>> \n>>"
            },
            {
                "author": "Alberto De Luigi",
                "date": "2017-12-19T13:45:09",
                "message_text_only": "Thank you Gregory,\nso SegWit P2PHK have strictly less weight than P2WPKH, 3 fewer bytes (-1%) no matter the n. of outputs.\nInstead, Segwit P2WPKH/P2SH cost 11% more than P2PHK, while compared to P2SH, SegWit transaction P2WSH and P2WSH/P2SH cost respectively 6% and 19% more space. And it can be much more if outputs are, as you say, an absurd number, which is the case of tx made by an exchange.\n\nI understand there is a rationale for the overhead size. It's transparent from here: https://bitcoincore.org/en/2016/01/26/segwit-benefits\nI don't understand your two points, which are new to me, maybe I lack of some technical details?\n1) outputs were previously undercosted\n2) a great many TXOUTs are putting a serious long term cost on the network\n\nBut independently from that, my point is: does an exchange have economic incentives in adopting SegWit? I think the answer is no.\nDoes SegWit help making bitcoin more scalable? Not until Lightning Network, since transactions just take up more space. \n\nInstead, if bech32 really makes possible to save up to 22% of space (I still need confirmation), it would help a lot in scaling bitcoin. We just need to coordinate the network to bring it on most of the wallets. Since using bech32 everybody will benefit and pay smaller fees there are economic incentives in implementing it. For this reason I think an agreement about a transition to bech32 as default address for every wallet is a highly realistic scenario, while widespread SegWit adoption without bech32 is not, in my opinion, because poor or negative economic incentives (including also the costs companies sustain for development).\n\nI know an agreement is a political matter, should it be discussed elsewhere?\nI think a network upgrade to bech32 addresses requires the same coordination of a hard fork, but.. just a hint: bech32 helps saving space, in the meanwhile we reach widespread segwit adoption. If transition is achieved, we would have blocks of 2mb fulfilled with transactions using bech32, which have a 20% discount. Compared to the current situation of 1.05mb average blocks and 400k tx daily, we could have about 2mb blocks and 960k tx daily...\n\nThank you,\nAlberto De Luigi\n(.com)\n\n\n\n-----Original Message-----\nFrom: Gregory Maxwell [mailto:gmaxwell at gmail.com]\nSent: marted\u00ec 19 dicembre 2017 09:06\nTo: mail at albertodeluigi.com; Bitcoin Protocol Discussion\n<bitcoin-dev at lists.linuxfoundation.org>\nCc: Mark Friedenbach <mark at friedenbach.org>\nSubject: Re: [bitcoin-dev] Clarification about SegWit transaction size and\nbech32\n\nAlberto,\n\nYou are confused about the impact.  Ordinary P2WPKH have strictly less\nweight no matter how many outputs you have.  P2WSH in very output heavy\ntransactions can be more, but this is inherent in the upgrade from\ninadequate 80-bit security to 128-bit security, an intentional\nchange: because outputs were previously _radically_ undercosted in the\nsystem and any party making a great many new TXOUTs are putting a serious\nlong term cost on the network,  and in any case it's except for transactions\nthat make an absurd number of P2WSH outputs at once the difference is pretty\nsmall.\n\nOn Mon, Dec 18, 2017 at 10:19 PM, Alberto De Luigi via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Mark,\n> suppose I am an average user. Give me a bech32 address and ask me to\n> send a few coins there. I am 100% sure you will never receive my\n> coins. I will call you back saying: \"Mark, sorry, I tried with three\n> different wallets, but it seems what you gave me is not a bitcoin\n> address!\"\n>\n> My point is: we want SegWit is used and implemented more and more by\n> the community. But if besides malleability fix, the main effect of sw\n> adoption is this:\n>\n> 1) The blockahin is heavier (transactions require more space)\n> 2) the fee is smaller only for some kind of tx\n> 3) the transactions of the exchanges, which aggregate outputs, would\n> be heavier and pay a higher fee using segwit!\n>\n> then how can we expect people, exchanges and services to adopt segwit?\n>\n> Thank you,\n> Alberto De Luigi\n>\n>\n>\n>\n> Il 2017-12-18 23:03 Mark Friedenbach ha scritto:\n>>\n>> Why would I send you coins to anything other than the address you\n>> provided to me? If you send me a bech32 address I use the native\n>> segwit scripts. If you send me an old address, I do what it specifies\n>> instead. The recipient has control over what type of script the\n>> payment is sent to, without any ambiguity.\n>>\n>>> On Dec 18, 2017, at 1:41 PM, mail at albertodeluigi.com wrote:\n>>>\n>>> Hi Mark,\n>>> thank you. I understand your point, but despite what we define as a\n>>> fork, when a software uses a particular address, it becomes part of\n>>> the rules of that software. If another software doesn't recognize\n>>> that address as a bitcoin address, then the rules it enforces aren't\n>>> compatible with the behaviour of the first software. If you send me\n>>> your bitcoins, I can't receive it, exactly like if it was in another\n>>> chain. This happens even if there isn't such a situation where\n>>> miners verify that transaction on a chain, while other miners reject it.\n>>>\n>>> If we want to change the addresses, we need consensus and the\n>>> coordinate upgrade of the entire network. In case we haven't\n>>> consensus, most of the clients cannot send and receive bitcoins, which\n>>> is a huge problem.\n>>> For this reason I think it is something we should discuss in order\n>>> to make a coordinated upgrade, exactly like what we do when we propose a\n>>> fork.\n>>> And it would be better to do it precisely as a part of a fork, like\n>>> a 2x (or whatever other upgrade gaining enough consensus)\n>>>\n>>> Apart from the proposal of an upgrade to bench32, do you agree with\n>>> the rest of my points? I know segwit is valuable because it fixes tx\n>>> malleability and so on... thank you for your link, but that wasn't\n>>> the point I wanted to highlight!\n>>>\n>>> Thank you,\n>>> Alberto\n>>>\n>>>\n>>>\n>>>\n>>> Il 2017-12-18 18:38 Mark Friedenbach ha scritto:\n>>>>\n>>>> Addresses are entirely a user-interface issue. They don\u2019t factor\n>>>> into the bitcoin protocol at all.\n>>>> The bitcoin protocol doesn\u2019t have addresses. It has a generic\n>>>> programmable signature framework called script. Addresses are\n>>>> merely a UI convention for representing common script templates.\n>>>> 1.. addresses and 3\u2026 addresses have script templates that are not\n>>>> as optimal as could be constructed with post-segwit assumptions.\n>>>> The newer bech32 address just uses a different underlying template\n>>>> that achieves better security guarantees (for pay-to-script) or\n>>>> lower fees (for pay-to-pubkey-hash). But this is really a UI/UX issue.\n>>>> A \u201cfork\u201d in bitcoin-like consensus systems has a very specific\n>>>> meaning. Changing address formats is not a fork, soft or hard.\n>>>> There are many benefits to segregated witness. You may find this\n>>>> page\n>>>> helpful:\n>>>> https://bitcoincore.org/en/2016/01/26/segwit-benefits/ [4]\n>>>>>\n>>>>> On Dec 18, 2017, at 8:40 AM, Alberto De Luigi via bitcoin-dev\n>>>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>> Hello guys,\n>>>>> I have a few questions about the SegWit tx size, I'd like to have\n>>>>> confirmation about the following statements. Can you correct\n>>>>> mistakes or inaccuracies? Thank you in advance.\n>>>>> In general, SegWit tx costs more than legacy tx (source\n>>>>> https://bitcoincore.org/en/2016/10/28/segwit-costs/ [1]):\n>>>>> * Compared to P2PKH, P2WPKH uses 3 fewer bytes (-1%) in the\n>>>>> scriptPubKey, and the same number of witness bytes as P2PKH\n>>>>> scriptSig.\n>>>>> * Compared to P2SH, P2WSH uses 11 additional bytes (6%) in the\n>>>>> scriptPubKey, and the same number of witness bytes as P2SH\n>>>>> scriptSig.\n>>>>> * Compared to P2PKH, P2WPKH/P2SH uses 21 additional bytes (11%),\n>>>>> due to using 24 bytes in scriptPubKey, 3 fewer bytes in scriptSig\n>>>>> than in P2PKH scriptPubKey, and the same number of witness bytes\n>>>>> as P2PKH scriptSig.\n>>>>> * Compared to P2SH, P2WSH/P2SH uses 35 additional bytes (19%), due\n>>>>> to using 24 bytes in scriptPubKey, 11 additional bytes in\n>>>>> scriptSig compared to P2SH scriptPubKey, and the same number of\n>>>>> witness bytes as P2SH scriptSig.\n>>>>> But still it is convenient to adopt segwit because you move the\n>>>>> bytes to the blockweight part, paying smaller fee. In general, a\n>>>>> tx with 1 input and 1 output is about 190kb. If it's a Segwit tx,\n>>>>> 82kb in the non-witness part (blocksize), 108 in the witness part\n>>>>> (blockweight).\n>>>>> See source:\n>>>>> 4 bytes version\n>>>>> 1 byte input count\n>>>>> Input\n>>>>> 36 bytes outpoint\n>>>>> 1 byte scriptSigLen (0x00)\n>>>>> 0 bytes scriptSig\n>>>>> 4 bytes sequence\n>>>>> 1 byte output count\n>>>>> 8 bytes value\n>>>>> 1 byte scriptPubKeyLen\n>>>>> 22 bytes scriptPubKey (0x0014{20-byte keyhash})\n>>>>> 4 bytes locktime\n>>>>\n>>>>\n>>>> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-t\n>>>> ransactions-what-would-be-the-max-number-of-transaction-confi\n>>>>>\n>>>>> [2]\n>>>>> Which means, if you fill a block entirely with this kind of tx,\n>>>>> you can approximately double the capacity of the blockchain\n>>>>> (blocksize capped to 1mb, blockweight a little bit more than 2mb)\n>>>>> My concern is about segwit adoption by the exchanges.\n>>>>> SegWit transactions cost 10bytes more than legacy transactions for\n>>>>> each output (vout is 256 bits instead of 160). Exchanges aggregate\n>>>>> tx adding many outputs, which is of course something good for\n>>>>> bitcoin scalability, since this way we save space and pay less fees.\n>>>>> But when a tx has at least 10 outputs, using segwit you don't save\n>>>>> space, instead:\n>>>>> - the total blockweight is at least 100bytes higher (10bytes x 10\n>>>>> outputs), so the blockchain is heavier\n>>>>> - you don't save space inside the blocksize, so you cannot\n>>>>> validate more transactions of this kind (with many outputs), nor\n>>>>> get cheaper fee\n>>>>> - without cheaper fees exchanges have no incentives for segwit\n>>>>> adoption before they decide to adopt LN In general we can say that\n>>>>> using SegWit:\n>>>>> - you decrease the fee only for some specific kind of\n>>>>> transactions, and just because you move some bytes to the\n>>>>> blockweight\n>>>>> - you don\u2019t save space in the blockchain, on the contrary the\n>>>>> total weight of the blockchain increases (so it's clear to me why\n>>>>> some time ago Luke tweeted to not use SegWit unless really\n>>>>> necessary... but then it's not clear why so much haste in\n>>>>> promoting\n>>>>> BIP148 the 1st august risking a split) If it's all correct, does\n>>>>> something change with bech32? I'm reading\n>>>>> bech32 allows to save about 22% of the space. Is this true for\n>>>>> whatever kind of tx? Immediate benefits of segwit for scalability\n>>>>> are only with bech32?\n>>>>> Bech32 is non-compatible with the entire ecosystem (you cannot\n>>>>> receive coins from the quasi-totality of wallets in circulation),\n>>>>> I would say it is a hard fork. But the bare segwit is really so\n>>>>> different? the soft fork is \"soft\" for the reference client\n>>>>> Bitcoin Core, but outside you cannot know what happens, there are\n>>>>> plenty of implementations (especially frontend customization)\n>>>>> which don\u2019t work with segwit and need to upgrade. To upgrade takes\n>>>>> a lot of time, especially when services are so crowded and so many\n>>>>> new people want to step in. At this point, if bech32 brings only\n>>>>> efficiency (but correct me if it\u2019s not so) and it is well planned,\n>>>>> it could be a consensual upgrade, maybe together with a 2x\n>>>>> blocksize? Is there a specific plan for some upgrade in 2018? I\n>>>>> personally think it is far easier to reach consensus on a\n>>>>> blocksize increase una tantum rather than a dynamic increase. You\n>>>>> cannot predict the technology growth: will it be linear,\n>>>>> exponential, or suddenly stop for a while, maybe right before a\n>>>>> huge innovation? I think a hard fork bech32 upgrade + 2x could\n>>>>> help a lot in scalability while we test LN, and it might be the\n>>>>> only way to effectively promote (or should I say enforce?) SegWit\n>>>>> adoption.\n>>>>> thank you,\n>>>>> Alberto De Luigi\n>>>>> (.com)_______________________________________________\n>>>>> bitcoin-dev mailing list\n>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev [3]\n>>>>\n>>>> Links:\n>>>> ------\n>>>> [1] https://bitcoincore.org/en/2016/10/28/segwit-costs/\n>>>> [2]\n>>>>\n>>>> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-t\n>>>> ransactions-what-would-be-the-max-number-of-transaction-confi\n>>>> [3] https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>> [4] https://bitcoincore.org/en/2016/01/26/segwit-benefits/\n>>>\n>>>\n>>>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            }
        ],
        "thread_summary": {
            "title": "Clarification about SegWit transaction size and bech32",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Alberto De Luigi",
                "mail at albertodeluigi.com",
                "Mark Friedenbach"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 49501
        }
    },
    {
        "title": "[bitcoin-dev] Ivy: a higher-level language targeting Bitcoin Script",
        "thread_messages": [
            {
                "author": "Daniel Robinson",
                "date": "2017-12-18T20:32:17",
                "message_text_only": "Today, we\u2019re releasing Ivy, a prototype higher-level language and\ndevelopment environment for creating custom Bitcoin Script programs. You\ncan see the full announcement here\n<https://blog.chain.com/ivy-for-bitcoin-a-smart-contract-language-that-compiles-to-bitcoin-script-bec06377141a>,\nor check out the docs <https://docs.ivy-lang.org/bitcoin/> and source code\n<https://github.com/ivy-lang/ivy-bitcoin>.\n\nIvy is a simple smart contract language that can compile to Bitcoin Script.\nIt aims to improve on the useability of Bitcoin Script by adding\naffordances like named variables and clauses, static (and domain-specific)\ntypes, and familiar syntax for function calls.\n\nTo try out Ivy, you can use the Ivy Playground for Bitcoin\n<https://ivy-lang.org/bitcoin/>, which allows you to create and test\nsimulated contracts in a sandboxed environment.\n\nThis is prototype software intended for educational and research purposes\nonly. Please don't try to use Ivy to control real or testnet Bitcoins.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/88572040/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Ivy: a higher-level language targeting Bitcoin Script",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Daniel Robinson"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1179
        }
    },
    {
        "title": "[bitcoin-dev] BIP Proposal: Crypto Open Exchange Protocol (COX)",
        "thread_messages": [
            {
                "author": "Nicolas Dorier",
                "date": "2017-12-20T06:28:07",
                "message_text_only": "Hi everyone,\n\nAs some of you know, I am working on a complete open source replacement of\nBitpay for allowing merchant to accept cryptocurrency payments while having\na way to sell automatically.\n\nA crucial, missing part, is fiat conversion. And I figured out a simple\nprotocol that exchanges (or adapters) can implement to allow any merchant\nto cash out BTC in fiat while giving them the freedom to choose their own\npayment processor solution.\n\nThis also have positive impact on scalability: Before, a merchant would\nreceive the bitcoin from the customer then would send to the exchange,\nresulting in two transactions.\nWith this specification, it would be one transaction.\n\nSpecial thanks to anditto and kallewoof for reviewing. I am waiting for\nyour feedback:\n\nGithub link:\nhttps://github.com/NicolasDorier/bips/blob/master/bip-xxx.mediawiki\n\n<pre>\n  BIP: XXX\n  Layer: Applications\n  Title: Crypto Open Exchange Protocol (COX)\n  Author: Nicolas Dorier <nicolas.dorier at gmail.com>\n  Comments-Summary: No comments yet.\n  Comments-URI: https://github.com/bitcoin/bips/wiki/Comments:BIP-XXX\n  Status: Draft\n  Type: Standards Track\n  Created: 2017-12-20\n  License: BSD-3-Clause\n           CC0-1.0\n</pre>\n\n==Abstract==\n\nA simple protocol for decoupling payment processor solutions from exchanges.\n\n==Motivation==\n\nCryptocurrency merchant adoption is mainly driven by availability, ease of\nuse and means of acceptance.\nWe call such solutions `Payment Processors`.\n\nUntil now, payment processing solutions fall into one of the two following\ncategories:\n\n# Self-hosted with the customer paying in cryptocurrency and the merchant\nreceiving it directly.\n# Centralized, coupled with an exchange feature, with the customer paying\nin cryptocurrency to the merchant, and receiving fiat or cryptocurrency on\nhis exchange account.\n\nThe self-hosted solution has two issues:\n\n# The merchant becomes vulnerable to the wild volatility of\ncryptocurrencies.\n# It is wasteful of blockchain space, if the merchant does not pay\nsuppliers in crypto, as they need a second transaction to change to his\nexchange,\n\nThe centralized solution has two issues:\n\n# It locks-in the merchant to a particular payment processor whose\nintentions might not be aligned (e.g. Bitpay who tried to redefine Bitcoin\nas being a different chain, without merchant approval)\n# It has to deal with local regulations (e.g. Bitpay does not provide fiat\nCAD to canadian merchants)\n\nThe goal of this BIP is to specify a simple protocol which makes possible\ndecoupling of payment processors from exchanges.\n\nWe believe this BIP will gather a lot of interest among local exchanges\nwhich do not have the resources to develop their own payment solutions.\n\nTheir customers can decide which payment processor solution they prefer,\nwhile the exchanges give them a way to protect against cryptocurrency\nvolatility.\n\n==Summary==\n\nThe merchant log in to its exchange website, go into \"Address sources\"\nsection of it, an click on \"Create a new address source\".\n\nThe address source creation wizard asks him questions about what to do when\ncrypto currency is sent to this the address source. (Cryptocurrency, Market\nsell order, limit order of past day average etc...)\n\nThe merchant receives an \"address source URI\" which they can input inside\nthe payment processor.\n\nAn exchange compatible with the Crypto Open Exchange Protocol would reply\nto any HTTP POST request to this  \"address source URI\" returning the\nfollowing information (more details in the Specification part)\n\n# A deposit address for accepting a payment\n# The current rate\n# Optional: If the exchange is willing to take the risk of rate\nfluctuation, until when this rate is guaranteed and under which conditions.\n\n<img src=\"bip-xxx/overview.png\"></img>\n\n===Interaction===\n\n* Manny (the \"merchant\") wants to accept Bitcoin payments on his e-commerce\nwebsite.\n* Manny chooses the payment processor \"PROCCO\" which has a powerful plugin\nfor his e-commerce website.\n* Manny is based in Canada and already has an account on the exchange\n\"MYCOIN\" which supports the Crypto Open Exchange Protocol.\n* Manny connects to the exchange website, and creates a new address source.\n* In the configuration screen of the address source, for each payment sent\nto this address source, Manny decides to keep 30% in Bitcoin and place a\nmarket sell order for the remaining 70% of the amount.\n* \"MYCOIN\" creates the address source, and gives the \"address source URI\"\nto the merchant. (e.g. https://example.com/addresssources/abd29ddn92)\n* Manny copies the address source URI and goes inside \"PROCCO\" settings,\nand configures his store to use this address source URI.\n\nNow a customer, Carol, wants to order a brand new phone for 0.01 BTC on\nManny's store and decides to pay in Bitcoin.\n\n* The E-Commerce website plugin requests the creation of an invoice from\nPROCCO.\n* PROCCO queries the \"address source URI\" and retrieves the rate, the\nexpiration of this rate and conditions.\n* PROCCO can now show the Bitcoin Payment Checkout page.\n* Carla pays.\n* PROCCO marks the payment as paid and redirects to the e-commerce website.\n* MYCOIN, under its own policy (typically after 6 confirmations), credits\nManny's account of 0.01 BTC and simultaneously creates a market sell order\nof 0.007 BTC on behalf of Manny.\n\n==Specification==\n\nThe payment processor sends a POST request to the \"address source URI\", the\nresponse from a Crypto Open Exchange Protocol exchange would be:\n\nIf the exchange does not guarantee the rate:\n\n    {\n        \"depositAddress\" : \"13....abd\",\n        \"currencyCode\" : \"CAD\",\n        \"cryptoCurrencyCode\" : \"BTC\",\n        \"rate\" : \"15600\",\n        # When the merchant account get credited on the exchange\n        \"requiredConfirmations\" : blockcount\n    }\n\n\nIf the exchange guarantee the rate:\n\n    {\n        \"depositAddress\" : \"13....abd\",\n        \"currencyCode\" : \"CAD\",\n        \"cryptoCurrencyCode\" : \"BTC\",\n        \"rate\" : \"15600\",\n        \"requiredConfirmations\" : blockcount\n        \"conditions\" :\n        {\n            # When the transaction should be seen on the blockchain to\nguarantee the rate\n            \"receivedBefore\" : timestamp,\n            # When the transaction should be confirmed on the blockchain to\nguarantee the rate\n            \"confirmedBefore\" : timestamp\n        }\n    }\n\n\nThe payment processor is responsible for giving feedback to the customer if\nthe fees of the received transaction are not enough to guarantee the rate.\n\n==Note on adoption==\n\nWhile local exchanges have incentives to implement this simple protocol, it\nis not strictly needed.\n\nAn alternative is to develop an adapter server which expose Crypto Open\nExchange Protocol endpoint and connect to underlying exchange's API.\n\nThe only downside is that the rate can't be guaranteed.\n\n==Copyright==\n\nThis document is dual licensed as BSD 3-clause, and Creative Commons CC0\n1.0 Universal.\n\n\nNicolas,\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171220/d0b0422b/attachment-0001.html>"
            },
            {
                "author": "Dan Libby",
                "date": "2017-12-20T06:50:42",
                "message_text_only": "currencyCode and cryptoCurrencyCode seem to assume that merchants will\nalways want to sell for fiat.  But a merchant might want to sell for\nanother cryptocurrency instead.\n\nWhy not make it more generic, like buySymbol and sellSymbol?\n\n>         \"currencyCode\" : \"CAD\",\n>         \"cryptoCurrencyCode\" : \"BTC\","
            },
            {
                "author": "Sjors Provoost",
                "date": "2017-12-20T08:49:09",
                "message_text_only": "I think this could be quite useful, although I don\u2019t know if it will get adopted. If any such small local exchanges want to weigh in on this proposal, that would help. Same goes for shopping cart integrators, e.g. the folks writing WooCommerce and Shopify plugins.\n\nConsider adding some requirements around the use of SSL and certificate pinning. Can you refer to the kind of best practices Stripe and PayPal recommend? Should some additional shared-secret or cookie / macaroon based authentication be added?\n\nCan you clarify if this integration can run in a browser, or due to security / privacy constraints must be server-to-server?\n\nThough it\u2019s important to remain future-proof by being flexible, leaving the above details to individual implementers is probably going to result in bad things.\n\nWhat are your thoughts on rate limiting vs. privacy? Should a payment source never return the same address even if nothing is paid to it? Otherwise someone could just crawl webshops to create an inventory of payment addresses. A new address every page reload could be a DDOS vector. It also wouldn't be compatible with BIP44 because of its gap limit, although I don\u2019t think that\u2019s a huge problem for exchanges.\n\nCan this be combined with an invoice mechanism similar to Lightning, e.g. where the exchange sends a pre-image to the users wallet (relayed via and retained by the web shop) upon receipt of the funds, which they can then present to the merchant in case something went wrong. Exchanges might be happy to support this protocol, but they don\u2019t want the burden of dealing with user support requests, so having signed invoices could help with that.\n\nI would consider a more specific name like Delegated UTXO or something. \u201cExchange\u201d suggests is more like 0X or Bisq.\n\nSpeaking of Bisq, it would be neat if merchants can rely on random peer to peer counterparties to convert to fiat, so their customer information and revenue figures aren\u2019t in the hands of a single counter party. Obviously that\u2019s a can of worms today, but it would be nice if the protocol was able to support that if one day someone figures out the fraud, compliance and bookkeeping stuff.\n\nFinally, why only exchanges? It could make sense fo shopping cart software to talk to a Bitcoin wallet that\u2019s hosted somewhere else for similar reasons. Right now the best these plugins can do is hold on to an XPUB, and I\u2019ve even seen solutions that just send the customers coins to their own backend wallet and then forward it.\n\nSjors\n\n> Op 20 dec. 2017, om 07:28 heeft Nicolas Dorier via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:\n> \n> Hi everyone,\n> \n> As some of you know, I am working on a complete open source replacement of Bitpay for allowing merchant to accept cryptocurrency payments while having a way to sell automatically.\n> \n> A crucial, missing part, is fiat conversion. And I figured out a simple protocol that exchanges (or adapters) can implement to allow any merchant to cash out BTC in fiat while giving them the freedom to choose their own payment processor solution.\n> \n> This also have positive impact on scalability: Before, a merchant would receive the bitcoin from the customer then would send to the exchange, resulting in two transactions.\n> With this specification, it would be one transaction.\n> \n> Special thanks to anditto and kallewoof for reviewing. I am waiting for your feedback:\n> \n> Github link: https://github.com/NicolasDorier/bips/blob/master/bip-xxx.mediawiki <https://github.com/NicolasDorier/bips/blob/master/bip-xxx.mediawiki>\n> \n> <pre>\n>   BIP: XXX\n>   Layer: Applications\n>   Title: Crypto Open Exchange Protocol (COX)\n>   Author: Nicolas Dorier <nicolas.dorier at gmail.com <mailto:nicolas.dorier at gmail.com>>\n>   Comments-Summary: No comments yet.\n>   Comments-URI: https://github.com/bitcoin/bips/wiki/Comments:BIP-XXX <https://github.com/bitcoin/bips/wiki/Comments:BIP-XXX>\n>   Status: Draft\n>   Type: Standards Track\n>   Created: 2017-12-20\n>   License: BSD-3-Clause\n>            CC0-1.0\n> </pre>\n> \n> ==Abstract==\n> \n> A simple protocol for decoupling payment processor solutions from exchanges.\n> \n> ==Motivation==\n> \n> Cryptocurrency merchant adoption is mainly driven by availability, ease of use and means of acceptance.\n> We call such solutions `Payment Processors`.\n> \n> Until now, payment processing solutions fall into one of the two following categories:\n> \n> # Self-hosted with the customer paying in cryptocurrency and the merchant receiving it directly.\n> # Centralized, coupled with an exchange feature, with the customer paying in cryptocurrency to the merchant, and receiving fiat or cryptocurrency on his exchange account.\n> \n> The self-hosted solution has two issues:\n> \n> # The merchant becomes vulnerable to the wild volatility of cryptocurrencies.\n> # It is wasteful of blockchain space, if the merchant does not pay suppliers in crypto, as they need a second transaction to change to his exchange,\n> \n> The centralized solution has two issues:\n> \n> # It locks-in the merchant to a particular payment processor whose intentions might not be aligned (e.g. Bitpay who tried to redefine Bitcoin as being a different chain, without merchant approval)\n> # It has to deal with local regulations (e.g. Bitpay does not provide fiat CAD to canadian merchants)\n> \n> The goal of this BIP is to specify a simple protocol which makes possible decoupling of payment processors from exchanges.\n> \n> We believe this BIP will gather a lot of interest among local exchanges which do not have the resources to develop their own payment solutions.\n> \n> Their customers can decide which payment processor solution they prefer, while the exchanges give them a way to protect against cryptocurrency volatility.\n> \n> ==Summary==\n> \n> The merchant log in to its exchange website, go into \"Address sources\" section of it, an click on \"Create a new address source\".\n> \n> The address source creation wizard asks him questions about what to do when crypto currency is sent to this the address source. (Cryptocurrency, Market sell order, limit order of past day average etc...)\n> \n> The merchant receives an \"address source URI\" which they can input inside the payment processor.\n> \n> An exchange compatible with the Crypto Open Exchange Protocol would reply to any HTTP POST request to this  \"address source URI\" returning the following information (more details in the Specification part)\n> \n> # A deposit address for accepting a payment\n> # The current rate\n> # Optional: If the exchange is willing to take the risk of rate fluctuation, until when this rate is guaranteed and under which conditions.\n> \n> <img src=\"bip-xxx/overview.png\"></img>\n> \n> ===Interaction===\n> \n> * Manny (the \"merchant\") wants to accept Bitcoin payments on his e-commerce website.\n> * Manny chooses the payment processor \"PROCCO\" which has a powerful plugin for his e-commerce website.\n> * Manny is based in Canada and already has an account on the exchange \"MYCOIN\" which supports the Crypto Open Exchange Protocol.\n> * Manny connects to the exchange website, and creates a new address source.\n> * In the configuration screen of the address source, for each payment sent to this address source, Manny decides to keep 30% in Bitcoin and place a market sell order for the remaining 70% of the amount.\n> * \"MYCOIN\" creates the address source, and gives the \"address source URI\" to the merchant. (e.g. https://example.com/addresssources/abd29ddn92 <https://example.com/addresssources/abd29ddn92>)\n> * Manny copies the address source URI and goes inside \"PROCCO\" settings, and configures his store to use this address source URI.\n> \n> Now a customer, Carol, wants to order a brand new phone for 0.01 BTC on Manny's store and decides to pay in Bitcoin.\n> \n> * The E-Commerce website plugin requests the creation of an invoice from PROCCO.\n> * PROCCO queries the \"address source URI\" and retrieves the rate, the expiration of this rate and conditions.\n> * PROCCO can now show the Bitcoin Payment Checkout page.\n> * Carla pays.\n> * PROCCO marks the payment as paid and redirects to the e-commerce website.\n> * MYCOIN, under its own policy (typically after 6 confirmations), credits Manny's account of 0.01 BTC and simultaneously creates a market sell order of 0.007 BTC on behalf of Manny.\n> \n> ==Specification==\n> \n> The payment processor sends a POST request to the \"address source URI\", the response from a Crypto Open Exchange Protocol exchange would be:\n> \n> If the exchange does not guarantee the rate:\n> \n>     {\n>         \"depositAddress\" : \"13....abd\",\n>         \"currencyCode\" : \"CAD\",\n>         \"cryptoCurrencyCode\" : \"BTC\",\n>         \"rate\" : \"15600\",\n>         # When the merchant account get credited on the exchange\n>         \"requiredConfirmations\" : blockcount\n>     }\n> \n> \n> If the exchange guarantee the rate:\n> \n>     {\n>         \"depositAddress\" : \"13....abd\",\n>         \"currencyCode\" : \"CAD\",\n>         \"cryptoCurrencyCode\" : \"BTC\",\n>         \"rate\" : \"15600\",\n>         \"requiredConfirmations\" : blockcount\n>         \"conditions\" :\n>         {\n>             # When the transaction should be seen on the blockchain to guarantee the rate\n>             \"receivedBefore\" : timestamp,\n>             # When the transaction should be confirmed on the blockchain to guarantee the rate\n>             \"confirmedBefore\" : timestamp\n>         }\n>     }\n> \n> \n> The payment processor is responsible for giving feedback to the customer if the fees of the received transaction are not enough to guarantee the rate.\n> \n> ==Note on adoption==\n> \n> While local exchanges have incentives to implement this simple protocol, it is not strictly needed.\n> \n> An alternative is to develop an adapter server which expose Crypto Open Exchange Protocol endpoint and connect to underlying exchange's API.\n> \n> The only downside is that the rate can't be guaranteed.\n> \n> ==Copyright==\n> \n> This document is dual licensed as BSD 3-clause, and Creative Commons CC0 1.0 Universal.\n> \n> \n> Nicolas,\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171220/ff1cb09d/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171220/ff1cb09d/attachment-0001.sig>"
            },
            {
                "author": "Nicolas Dorier",
                "date": "2017-12-21T08:20:11",
                "message_text_only": "Thanks a lot for the feedback\n\n> I think this could be quite useful, although I don\u2019t know if it will get\nadopted.\n\nThe good part is that it does not have to be adopted by exchanges. If\npopular exchanges do not adopt it, it is trivial to make an adapter service\nwhich translate COX to whatever proprietary API of the exchange.\n\nCollaboration with the exchange is only needed if the exchange wants to\nprovide a service for taking the risk of volatility.\n\n> I have personally been integrating BitPay into a website for payments in\nBTC and like what you are trying to do.  One of the biggest hurdle\u2019s I see\nfor merchants to adopt BitCoin today is the transaction fee.\n\nThis BIP supports alternatives currencies.\n\n>  Can you refer to the kind of best practices Stripe and PayPal recommend?\nShould some additional shared-secret or cookie / macaroon based\nauthentication be added?\n\nYes, I must add guidelines (SSL and how to manage the addresses). I don't\nthink authentication is needed as the merchant is the only one having\naccess to the source URI. This can be considered as a shared secret.\nEven if this secret leaks, no funds are in danger.\n\n> Can you clarify if this integration can run in a browser, or due to\nsecurity / privacy constraints must be server-to-server?\n\nThanks, I need to clarify the scope. But indeed, this is not meant to be\nused by a browser, as merchants will not host their payment processors on\ntheir mobile or browser.\n\n> Though it\u2019s important to remain future-proof by being flexible, leaving\nthe above details to individual implementers is probably going to result in\nbad things.\n\nThanks, I think you are right I should add more recommendations for\nimplementers.\n\n> What are your thoughts on rate limiting vs. privacy? Should a payment\nsource never return the same address even if nothing is paid to it?\nOtherwise someone could just crawl webshops to create an inventory of\npayment addresses. A new address every page reload could be a DDOS vector.\nIt also wouldn't be compatible with BIP44 because of its gap limit,\nalthough I don\u2019t think that\u2019s a huge problem for exchanges.\n\nYou are right, I must introduce a sort of \"order id\" so that one order map\nto exactly one address response.\nThe DDOS vector will then be on the shoulder of the ecommerce website by\npreventing users to create too much orders. (they certainly already do)\n\n> Can this be combined with an invoice mechanism similar to Lightning, e.g.\nwhere the exchange sends a pre-image to the users wallet (relayed via and\nretained by the web shop) upon receipt of the funds, which they can then\npresent to the merchant in case something went wrong. Exchanges might be\nhappy to support this protocol, but they don\u2019t want the burden of dealing\nwith user support requests, so having signed invoices could help with that.\n\nThis protocol can be expanded later for lightning trivially, where the call\nto the address source uri also returns a lightning payment request. (BOLT11)\n\n> Speaking of Bisq, it would be neat if merchants can rely on random peer\nto peer counterparties to convert to fiat, so their customer information\nand revenue figures aren\u2019t in the hands of a single counter party.\nObviously that\u2019s a can of worms today, but it would be nice if the protocol\nwas able to support that if one day someone figures out the fraud,\ncompliance and bookkeeping stuff.\n\nConversion to fiat always need trust, so we must rule out anonymous\nparties. If you want to spread on several trusted party, this can be done\ntransparently at the payment processor level, and does not requires change\nto the protocol.\n\n> Finally, why only exchanges? It could make sense fo shopping cart\nsoftware to talk to a Bitcoin wallet that\u2019s hosted somewhere else for\nsimilar reasons. Right now the best these plugins can do is hold on to an\nXPUB, and I\u2019ve even seen solutions that just send the customers coins to\ntheir own backend wallet and then forward it.\n\nBecause BIP70/XPUB already solves the problem. (Which I already use in\nBTCPay)\nBIP70 is a pain in the ass to implement and does not provide any benefits,\nand it does not define a way for the exchange to communicate a rate\nattached to the bitcoin address, nor define a way to communicate to the\npayment processor the conditions under which they can bear volatility risk.\n\nI will revisit the BIP based on your feedback.\n\nNicolas,\n\nOn Wed, Dec 20, 2017 at 5:49 PM, Sjors Provoost <sjors at sprovoost.nl> wrote:\n\n>\n>\n> I think this could be quite useful, although I don\u2019t know if it will get\n> adopted. If any such small local exchanges want to weigh in on this\n> proposal, that would help. Same goes for shopping cart integrators, e.g.\n> the folks writing WooCommerce and Shopify plugins.\n>\n> Consider adding some requirements around the use of SSL and certificate\n> pinning. Can you refer to the kind of best practices Stripe and PayPal\n> recommend? Should some additional shared-secret or cookie / macaroon based\n> authentication be added?\n>\n> Can you clarify if this integration can run in a browser, or due to\n> security / privacy constraints must be server-to-server?\n>\n> Though it\u2019s important to remain future-proof by being flexible, leaving\n> the above details to individual implementers is probably going to result in\n> bad things.\n>\n> What are your thoughts on rate limiting vs. privacy? Should a payment\n> source never return the same address even if nothing is paid to it?\n> Otherwise someone could just crawl webshops to create an inventory of\n> payment addresses. A new address every page reload could be a DDOS vector.\n> It also wouldn't be compatible with BIP44 because of its gap limit,\n> although I don\u2019t think that\u2019s a huge problem for exchanges.\n>\n> Can this be combined with an invoice mechanism similar to Lightning, e.g.\n> where the exchange sends a pre-image to the users wallet (relayed via and\n> retained by the web shop) upon receipt of the funds, which they can then\n> present to the merchant in case something went wrong. Exchanges might be\n> happy to support this protocol, but they don\u2019t want the burden of dealing\n> with user support requests, so having signed invoices could help with that.\n>\n> I would consider a more specific name like Delegated UTXO or something.\n> \u201cExchange\u201d suggests is more like 0X or Bisq.\n>\n> Speaking of Bisq, it would be neat if merchants can rely on random peer to\n> peer counterparties to convert to fiat, so their customer information and\n> revenue figures aren\u2019t in the hands of a single counter party. Obviously\n> that\u2019s a can of worms today, but it would be nice if the protocol was able\n> to support that if one day someone figures out the fraud, compliance and\n> bookkeeping stuff.\n>\n> Finally, why only exchanges? It could make sense fo shopping cart software\n> to talk to a Bitcoin wallet that\u2019s hosted somewhere else for similar\n> reasons. Right now the best these plugins can do is hold on to an XPUB, and\n> I\u2019ve even seen solutions that just send the customers coins to their own\n> backend wallet and then forward it.\n>\n> Sjors\n>\n> Op 20 dec. 2017, om 07:28 heeft Nicolas Dorier via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:\n>\n> Hi everyone,\n>\n> As some of you know, I am working on a complete open source replacement of\n> Bitpay for allowing merchant to accept cryptocurrency payments while having\n> a way to sell automatically.\n>\n> A crucial, missing part, is fiat conversion. And I figured out a simple\n> protocol that exchanges (or adapters) can implement to allow any merchant\n> to cash out BTC in fiat while giving them the freedom to choose their own\n> payment processor solution.\n>\n> This also have positive impact on scalability: Before, a merchant would\n> receive the bitcoin from the customer then would send to the exchange,\n> resulting in two transactions.\n> With this specification, it would be one transaction.\n>\n> Special thanks to anditto and kallewoof for reviewing. I am waiting for\n> your feedback:\n>\n> Github link: https://github.com/NicolasDorier/bips/blob/\n> master/bip-xxx.mediawiki\n>\n> <pre>\n>   BIP: XXX\n>   Layer: Applications\n>   Title: Crypto Open Exchange Protocol (COX)\n>   Author: Nicolas Dorier <nicolas.dorier at gmail.com>\n>   Comments-Summary: No comments yet.\n>   Comments-URI: https://github.com/bitcoin/bips/wiki/Comments:BIP-XXX\n>   Status: Draft\n>   Type: Standards Track\n>   Created: 2017-12-20\n>   License: BSD-3-Clause\n>            CC0-1.0\n> </pre>\n>\n> ==Abstract==\n>\n> A simple protocol for decoupling payment processor solutions from\n> exchanges.\n>\n> ==Motivation==\n>\n> Cryptocurrency merchant adoption is mainly driven by availability, ease of\n> use and means of acceptance.\n> We call such solutions `Payment Processors`.\n>\n> Until now, payment processing solutions fall into one of the two following\n> categories:\n>\n> # Self-hosted with the customer paying in cryptocurrency and the merchant\n> receiving it directly.\n> # Centralized, coupled with an exchange feature, with the customer paying\n> in cryptocurrency to the merchant, and receiving fiat or cryptocurrency on\n> his exchange account.\n>\n> The self-hosted solution has two issues:\n>\n> # The merchant becomes vulnerable to the wild volatility of\n> cryptocurrencies.\n> # It is wasteful of blockchain space, if the merchant does not pay\n> suppliers in crypto, as they need a second transaction to change to his\n> exchange,\n>\n> The centralized solution has two issues:\n>\n> # It locks-in the merchant to a particular payment processor whose\n> intentions might not be aligned (e.g. Bitpay who tried to redefine Bitcoin\n> as being a different chain, without merchant approval)\n> # It has to deal with local regulations (e.g. Bitpay does not provide fiat\n> CAD to canadian merchants)\n>\n> The goal of this BIP is to specify a simple protocol which makes possible\n> decoupling of payment processors from exchanges.\n>\n> We believe this BIP will gather a lot of interest among local exchanges\n> which do not have the resources to develop their own payment solutions.\n>\n> Their customers can decide which payment processor solution they prefer,\n> while the exchanges give them a way to protect against cryptocurrency\n> volatility.\n>\n> ==Summary==\n>\n> The merchant log in to its exchange website, go into \"Address sources\"\n> section of it, an click on \"Create a new address source\".\n>\n> The address source creation wizard asks him questions about what to do\n> when crypto currency is sent to this the address source. (Cryptocurrency,\n> Market sell order, limit order of past day average etc...)\n>\n> The merchant receives an \"address source URI\" which they can input inside\n> the payment processor.\n>\n> An exchange compatible with the Crypto Open Exchange Protocol would reply\n> to any HTTP POST request to this  \"address source URI\" returning the\n> following information (more details in the Specification part)\n>\n> # A deposit address for accepting a payment\n> # The current rate\n> # Optional: If the exchange is willing to take the risk of rate\n> fluctuation, until when this rate is guaranteed and under which conditions.\n>\n> <img src=\"bip-xxx/overview.png\"></img>\n>\n> ===Interaction===\n>\n> * Manny (the \"merchant\") wants to accept Bitcoin payments on his\n> e-commerce website.\n> * Manny chooses the payment processor \"PROCCO\" which has a powerful plugin\n> for his e-commerce website.\n> * Manny is based in Canada and already has an account on the exchange\n> \"MYCOIN\" which supports the Crypto Open Exchange Protocol.\n> * Manny connects to the exchange website, and creates a new address source.\n> * In the configuration screen of the address source, for each payment sent\n> to this address source, Manny decides to keep 30% in Bitcoin and place a\n> market sell order for the remaining 70% of the amount.\n> * \"MYCOIN\" creates the address source, and gives the \"address source URI\"\n> to the merchant. (e.g. https://example.com/addresssources/abd29ddn92)\n> * Manny copies the address source URI and goes inside \"PROCCO\" settings,\n> and configures his store to use this address source URI.\n>\n> Now a customer, Carol, wants to order a brand new phone for 0.01 BTC on\n> Manny's store and decides to pay in Bitcoin.\n>\n> * The E-Commerce website plugin requests the creation of an invoice from\n> PROCCO.\n> * PROCCO queries the \"address source URI\" and retrieves the rate, the\n> expiration of this rate and conditions.\n> * PROCCO can now show the Bitcoin Payment Checkout page.\n> * Carla pays.\n> * PROCCO marks the payment as paid and redirects to the e-commerce website.\n> * MYCOIN, under its own policy (typically after 6 confirmations), credits\n> Manny's account of 0.01 BTC and simultaneously creates a market sell order\n> of 0.007 BTC on behalf of Manny.\n>\n> ==Specification==\n>\n> The payment processor sends a POST request to the \"address source URI\",\n> the response from a Crypto Open Exchange Protocol exchange would be:\n>\n> If the exchange does not guarantee the rate:\n>\n>     {\n>         \"depositAddress\" : \"13....abd\",\n>         \"currencyCode\" : \"CAD\",\n>         \"cryptoCurrencyCode\" : \"BTC\",\n>         \"rate\" : \"15600\",\n>         # When the merchant account get credited on the exchange\n>         \"requiredConfirmations\" : blockcount\n>     }\n>\n>\n> If the exchange guarantee the rate:\n>\n>     {\n>         \"depositAddress\" : \"13....abd\",\n>         \"currencyCode\" : \"CAD\",\n>         \"cryptoCurrencyCode\" : \"BTC\",\n>         \"rate\" : \"15600\",\n>         \"requiredConfirmations\" : blockcount\n>         \"conditions\" :\n>         {\n>             # When the transaction should be seen on the blockchain to\n> guarantee the rate\n>             \"receivedBefore\" : timestamp,\n>             # When the transaction should be confirmed on the blockchain\n> to guarantee the rate\n>             \"confirmedBefore\" : timestamp\n>         }\n>     }\n>\n>\n> The payment processor is responsible for giving feedback to the customer\n> if the fees of the received transaction are not enough to guarantee the\n> rate.\n>\n> ==Note on adoption==\n>\n> While local exchanges have incentives to implement this simple protocol,\n> it is not strictly needed.\n>\n> An alternative is to develop an adapter server which expose Crypto Open\n> Exchange Protocol endpoint and connect to underlying exchange's API.\n>\n> The only downside is that the rate can't be guaranteed.\n>\n> ==Copyright==\n>\n> This document is dual licensed as BSD 3-clause, and Creative Commons CC0\n> 1.0 Universal.\n>\n>\n> Nicolas,\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/d6e0ce81/attachment-0001.html>"
            },
            {
                "author": "Sjors Provoost",
                "date": "2017-12-21T09:04:44",
                "message_text_only": "Just to clarify two points:\n\n> The good part is that it does not have to be adopted by exchanges. If popular exchanges do not adopt it, it is trivial to make an adapter service which translate COX to whatever proprietary API of the exchange.\n\nBe sure to elaborate on the difference in trust assumptions between a merchant running such an adapter on their own infrastructure vs. trusting a SAAS that sits in between the exchange and the merchants infrastructure.\n\nIn general adapters would create additional risks to think about, depending on how fine-tuned the API key permissions are. E.g. if API keys come with full permissions you don\u2019t want to install an adaptor plugin if your shop is hosted on wordpress.com. PayPal and Stripe make sure their API keys can\u2019t do too much damage in case the merchant shop hosting is compromised.\n\n> > Can this be combined with an invoice mechanism similar to Lightning, e.g. where the exchange sends a pre-image to the users wallet (relayed via and retained by the web shop) upon receipt of the funds, which they can then present to the merchant in case something went wrong. Exchanges might be happy to support this protocol, but they don\u2019t want the burden of dealing with user support requests, so having signed invoices could help with that.\n> \n> This protocol can be expanded later for lightning trivially, where the call to the address source uri also returns a lightning payment request. (BOLT11)\n\nI didn\u2019t mean adding Lightning support (though that would be cool), I mean adding an invoice system to your proposal that is similar to how Lightning invoices work. Right now if the customer pays and the merchant has a poorly functioning shopping cart system, which I\u2019ve seen more often than not, the customer would have to email their transaction id to the merchant, who then needs to login to their exchange to check if that address indeed belongs to them. But a merchant shouldn\u2019t give all their support staff such access, and support staff may not have the right training, or even permission, to assess whether a transaction is cleared (\u201ccomputer says no\").\n\nSo you\u2019d want some sort of signed message as part of the protocol that says \u201cif this transaction ID confirms, this order ID is paid for\u201d.   Although this specific example wouldn\u2019t play well with RBF. So maybe \u201cif the confirmed balance of this address is >= X, this order ID is paid for\u201d, but then the exchange can\u2019t sweep it. So maybe instead you need a callback from the exchange to just tell you when it\u2019s (expected to be) confirmed. BitPay offers merchants various risk settings for this, so that might be worth looking into.\n\nSjors\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/a7167172/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/a7167172/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "BIP Proposal: Crypto Open Exchange Protocol (COX)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Sjors Provoost",
                "Dan Libby",
                "Nicolas Dorier"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 35910
        }
    },
    {
        "title": "[bitcoin-dev] Total fees have almost crossed the block reward",
        "thread_messages": [
            {
                "author": "Melvin Carvalho",
                "date": "2017-12-21T21:30:20",
                "message_text_only": "I asked adam back at hcpp how the block chain would be secured in the long\nterm, once the reward goes away.  The base idea has always been that fees\nwould replace the block reward.\n\nAt that time fees were approximately 10% of the block reward, but have now\nreached 45%, with 50% potentially being crossed soon\n\nhttps://fork.lol/reward/feepct\n\nWhile this bodes well for the long term security of the coin, I think there\nis some legitimate concern that the fee per tx is prohibitive for some use\ncases, at this point in the adoption curve.\n\nObservations of segwit adoption show around 10% at this point\n\nhttp://segwit.party/charts/\n\nWatching the mempool shows that the congestion is at a peak, though it's\nquite possible this will come down over the long weekend.  I wonder if this\nis of concern to some.\n\nhttps://dedi.jochen-hoenicke.de/queue/more/#24h\n\nI thought these data points may be of interest and are mainly FYI.  Though\nif further discussion is deemed appropriate, it would be interesting to\nhear thoughts.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/d2feec02/attachment.html>"
            },
            {
                "author": "Jameson Lopp",
                "date": "2017-12-21T22:02:37",
                "message_text_only": "I'd hope that the incentives are in place to encourage high volume senders\nto be more efficient in their use of block space by batching transactions\nand implementing SegWit, though this may not be the case for providers that\npass transaction fees along to their users.\n\nWe've been trying to be more proactive about outreach regarding efficient\nuse of block space to our own customers at BitGo - when we break down the\ncost savings of implementing a new technique, it generally helps to hasten\ntheir adoption. I suspect that in many cases this is an issue of education\n- we should be more proactive in calling out inefficient uses of block\nspace.\n\nGood resources to bookmark and share:\n\nhttps://bitcointechtalk.com/saving-up-to-80-on-bitcoin-transaction-fees-by-batching-payments-4147ab7009fb\n\nhttps://blog.zebpay.com/how-zebpay-reduced-bitcoin-transaction-fees-a9e24c788598\n\n- Jameson\n\nOn Thu, Dec 21, 2017 at 4:30 PM, Melvin Carvalho via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I asked adam back at hcpp how the block chain would be secured in the long\n> term, once the reward goes away.  The base idea has always been that fees\n> would replace the block reward.\n>\n> At that time fees were approximately 10% of the block reward, but have now\n> reached 45%, with 50% potentially being crossed soon\n>\n> https://fork.lol/reward/feepct\n>\n> While this bodes well for the long term security of the coin, I think\n> there is some legitimate concern that the fee per tx is prohibitive for\n> some use cases, at this point in the adoption curve.\n>\n> Observations of segwit adoption show around 10% at this point\n>\n> http://segwit.party/charts/\n>\n> Watching the mempool shows that the congestion is at a peak, though it's\n> quite possible this will come down over the long weekend.  I wonder if this\n> is of concern to some.\n>\n> https://dedi.jochen-hoenicke.de/queue/more/#24h\n>\n> I thought these data points may be of interest and are mainly FYI.  Though\n> if further discussion is deemed appropriate, it would be interesting to\n> hear thoughts.\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/65f4e581/attachment.html>"
            },
            {
                "author": "Jim Rogers",
                "date": "2017-12-21T22:18:32",
                "message_text_only": "It seems that the exchanges are doing everything that they can to slow things. Not only have the major exchanges not implemented segwit yet, but a bigger, less addressed issue is that they have start applying transfer limits on crypto as well as cash. They do not respond for months to requests to upgrade limits, and this results in many transactions instead of one to transfer crypto to cold storage devices. \n\n \n\nThese issues may self-resolve over time, since I think they are all impacted by KYC and the explosive growth. \n\n \n\n \n\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org [mailto:bitcoin-dev-bounces at lists.linuxfoundation.org] On Behalf Of Jameson Lopp via bitcoin-dev\nSent: Thursday, December 21, 2017 1:03 PM\nTo: Melvin Carvalho <melvincarvalho at gmail.com>; Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\nSubject: Re: [bitcoin-dev] Total fees have almost crossed the block reward\n\n \n\nI'd hope that the incentives are in place to encourage high volume senders to be more efficient in their use of block space by batching transactions and implementing SegWit, though this may not be the case for providers that pass transaction fees along to their users.\n\n \n\nWe've been trying to be more proactive about outreach regarding efficient use of block space to our own customers at BitGo - when we break down the cost savings of implementing a new technique, it generally helps to hasten their adoption. I suspect that in many cases this is an issue of education - we should be more proactive in calling out inefficient uses of block space.\n\n \n\nGood resources to bookmark and share:\n\n \n\nhttps://bitcointechtalk.com/saving-up-to-80-on-bitcoin-transaction-fees-by-batching-payments-4147ab7009fb\n\n \n\nhttps://blog.zebpay.com/how-zebpay-reduced-bitcoin-transaction-fees-a9e24c788598\n\n \n\n- Jameson\n\n \n\nOn Thu, Dec 21, 2017 at 4:30 PM, Melvin Carvalho via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org> > wrote:\n\nI asked adam back at hcpp how the block chain would be secured in the long term, once the reward goes away.  The base idea has always been that fees would replace the block reward.\n\nAt that time fees were approximately 10% of the block reward, but have now reached 45%, with 50% potentially being crossed soon\n\nhttps://fork.lol/reward/feepct\n\nWhile this bodes well for the long term security of the coin, I think there is some legitimate concern that the fee per tx is prohibitive for some use cases, at this point in the adoption curve.\n\nObservations of segwit adoption show around 10% at this point\n\nhttp://segwit.party/charts/\n\nWatching the mempool shows that the congestion is at a peak, though it's quite possible this will come down over the long weekend.  I wonder if this is of concern to some.\n\nhttps://dedi.jochen-hoenicke.de/queue/more/#24h\n\nI thought these data points may be of interest and are mainly FYI.  Though if further discussion is deemed appropriate, it would be interesting to hear thoughts.\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org> \nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n \n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/08b9c9a0/attachment.html>"
            },
            {
                "author": "Michel 'ic' Luczak",
                "date": "2017-12-21T23:15:18",
                "message_text_only": "Hi,\n\nThis is the first time I post on this list.\n\nFirst of all, Thank you Jameson for the interview you gave yesterday, it\u2019s been a model of calm and self-control for all of us.\n\nI deeply believe the high average fees we experience right now are mostly due to the miscalculations of most of the hardware (ledger & trezor) wallets (and probably software too) on the market.\n\nI personally made transactions at the worst period for the Blockchain with less than 40 sat/WU of fees and got confirmed in less than a day.\n\nI think there\u2019s a lot of work to do in used education to make them understand that for a low amount of fees they can still get a transaction confirmed and that\u2019s the POS\u2019 work to make sure the transaction is legit.\n\nRegards, Michel.\n\n> On 21 Dec 2017, at 23:02, Jameson Lopp via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> I'd hope that the incentives are in place to encourage high volume senders to be more efficient in their use of block space by batching transactions and implementing SegWit, though this may not be the case for providers that pass transaction fees along to their users.\n> \n> We've been trying to be more proactive about outreach regarding efficient use of block space to our own customers at BitGo - when we break down the cost savings of implementing a new technique, it generally helps to hasten their adoption. I suspect that in many cases this is an issue of education - we should be more proactive in calling out inefficient uses of block space.\n> \n> Good resources to bookmark and share:\n> \n> https://bitcointechtalk.com/saving-up-to-80-on-bitcoin-transaction-fees-by-batching-payments-4147ab7009fb <https://bitcointechtalk.com/saving-up-to-80-on-bitcoin-transaction-fees-by-batching-payments-4147ab7009fb>\n> \n> https://blog.zebpay.com/how-zebpay-reduced-bitcoin-transaction-fees-a9e24c788598 <https://blog.zebpay.com/how-zebpay-reduced-bitcoin-transaction-fees-a9e24c788598>\n> \n> - Jameson\n> \n> On Thu, Dec 21, 2017 at 4:30 PM, Melvin Carvalho via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> I asked adam back at hcpp how the block chain would be secured in the long term, once the reward goes away.  The base idea has always been that fees would replace the block reward.\n> \n> At that time fees were approximately 10% of the block reward, but have now reached 45%, with 50% potentially being crossed soon\n> \n> https://fork.lol/reward/feepct <https://fork.lol/reward/feepct>\n> \n> While this bodes well for the long term security of the coin, I think there is some legitimate concern that the fee per tx is prohibitive for some use cases, at this point in the adoption curve.\n> \n> Observations of segwit adoption show around 10% at this point\n> \n> http://segwit.party/charts/ <http://segwit.party/charts/>\n> \n> Watching the mempool shows that the congestion is at a peak, though it's quite possible this will come down over the long weekend.  I wonder if this is of concern to some.\n> \n> https://dedi.jochen-hoenicke.de/queue/more/#24h <https://dedi.jochen-hoenicke.de/queue/more/#24h>\n> \n> I thought these data points may be of interest and are mainly FYI.  Though if further discussion is deemed appropriate, it would be interesting to hear thoughts.\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171222/9bafeb37/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2017-12-21T22:44:32",
                "message_text_only": "Personally, I'm pulling out the champaign that market behaviour is\nindeed producing activity levels that can pay for security without\ninflation, and also producing fee paying backlogs needed to stabilize\nconsensus progress as the subsidy declines.\n\nI'd also personally prefer to pay lower fees-- current levels even\nchallenge my old comparison with wire transfer costs-- but we should\nlook most strongly at difficult to forge market signals rather than\njust claims-- segwit usage gives us a pretty good indicator since most\nusers would get a 50-70% fee reduction without even considering the\nsecond order effects from increased capacity.\n\nAs Jameson Lopp notes, more can be done for education though-- perhaps\nthat market signal isn't efficient yet. But we should get it there.\n\nBut even independently of segwit we can also look at other inefficient\ntransaction styles: uncompressed keys, unconfirmed chaining instead of\nsend many batching, fee overpayment, etc... and the message there is\nsimilar.\n\nI've also seen some evidence that a portion of the current high rate\ncongestion is contrived traffic. To the extent that it's true there\nalso should be some relief there soon as the funding for that runs\nout, in addition to expected traffic patterns, difficulty changes,\netc.\n\n\nOn Thu, Dec 21, 2017 at 9:30 PM, Melvin Carvalho via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> I asked adam back at hcpp how the block chain would be secured in the long\n> term, once the reward goes away.  The base idea has always been that fees\n> would replace the block reward.\n>\n> At that time fees were approximately 10% of the block reward, but have now\n> reached 45%, with 50% potentially being crossed soon\n>\n> https://fork.lol/reward/feepct\n>\n> While this bodes well for the long term security of the coin, I think there\n> is some legitimate concern that the fee per tx is prohibitive for some use\n> cases, at this point in the adoption curve.\n>\n> Observations of segwit adoption show around 10% at this point\n>\n> http://segwit.party/charts/\n>\n> Watching the mempool shows that the congestion is at a peak, though it's\n> quite possible this will come down over the long weekend.  I wonder if this\n> is of concern to some.\n>\n> https://dedi.jochen-hoenicke.de/queue/more/#24h\n>\n> I thought these data points may be of interest and are mainly FYI.  Though\n> if further discussion is deemed appropriate, it would be interesting to hear\n> thoughts.\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Paul Iverson",
                "date": "2017-12-21T23:35:28",
                "message_text_only": "I agree with Greg.  What is happening is a cause for celebration: it is the\nmanifestation of our long-desired fee market in action.  That people are\nwilling to pay upwards of $100 per transaction shows the huge demand to\ntransact on the world's most secure ledger. This is what success looks\nlike, folks!\n\nNow that BTC is being phased out as a means of payment nearly everywhere\n(e.g., Steam dropping BTC as a payment option) (to be replaced with the\nmore-suitable LN when ready), I'd propose that we address the stuck\ntransaction issue by making replace-by-fee (RBF) ubiquitous.  Why not make\nevery transaction RBF by default, and then encourage via outreach and\neducation other wallet developers to do the same?\n\nThe frustration with BTC today is less so the high-fees (people realize\non-chain transactions in a secure decentralized ledger are necessarily\ncostly) but by the feeling of helplessness when their transaction is\nstuck.  Being able to easily bump a transaction's fee for users who are in\na hurry would go a long way to improving the user experience.\n\nPaul.\n\n\nOn Thu, Dec 21, 2017 at 2:44 PM, Gregory Maxwell via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Personally, I'm pulling out the champaign that market behaviour is\n> indeed producing activity levels that can pay for security without\n> inflation, and also producing fee paying backlogs needed to stabilize\n> consensus progress as the subsidy declines.\n>\n> I'd also personally prefer to pay lower fees-- current levels even\n> challenge my old comparison with wire transfer costs-- but we should\n> look most strongly at difficult to forge market signals rather than\n> just claims-- segwit usage gives us a pretty good indicator since most\n> users would get a 50-70% fee reduction without even considering the\n> second order effects from increased capacity.\n>\n> As Jameson Lopp notes, more can be done for education though-- perhaps\n> that market signal isn't efficient yet. But we should get it there.\n>\n> But even independently of segwit we can also look at other inefficient\n> transaction styles: uncompressed keys, unconfirmed chaining instead of\n> send many batching, fee overpayment, etc... and the message there is\n> similar.\n>\n> I've also seen some evidence that a portion of the current high rate\n> congestion is contrived traffic. To the extent that it's true there\n> also should be some relief there soon as the funding for that runs\n> out, in addition to expected traffic patterns, difficulty changes,\n> etc.\n>\n>\n> On Thu, Dec 21, 2017 at 9:30 PM, Melvin Carvalho via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > I asked adam back at hcpp how the block chain would be secured in the\n> long\n> > term, once the reward goes away.  The base idea has always been that fees\n> > would replace the block reward.\n> >\n> > At that time fees were approximately 10% of the block reward, but have\n> now\n> > reached 45%, with 50% potentially being crossed soon\n> >\n> > https://fork.lol/reward/feepct\n> >\n> > While this bodes well for the long term security of the coin, I think\n> there\n> > is some legitimate concern that the fee per tx is prohibitive for some\n> use\n> > cases, at this point in the adoption curve.\n> >\n> > Observations of segwit adoption show around 10% at this point\n> >\n> > http://segwit.party/charts/\n> >\n> > Watching the mempool shows that the congestion is at a peak, though it's\n> > quite possible this will come down over the long weekend.  I wonder if\n> this\n> > is of concern to some.\n> >\n> > https://dedi.jochen-hoenicke.de/queue/more/#24h\n> >\n> > I thought these data points may be of interest and are mainly FYI.\n> Though\n> > if further discussion is deemed appropriate, it would be interesting to\n> hear\n> > thoughts.\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/57708e63/attachment.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-12-22T00:30:52",
                "message_text_only": "Every transaction is replace-by-fee capable already. Opt-in replace by fee as specified in BIP 125 is a fiction that held sway only while the income from fees or fee replacement was so much smaller than subsidy.\n\n> On Dec 21, 2017, at 3:35 PM, Paul Iverson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> I agree with Greg.  What is happening is a cause for celebration: it is the manifestation of our long-desired fee market in action.  That people are willing to pay upwards of $100 per transaction shows the huge demand to transact on the world's most secure ledger. This is what success looks like, folks!\n> \n> Now that BTC is being phased out as a means of payment nearly everywhere (e.g., Steam dropping BTC as a payment option) (to be replaced with the more-suitable LN when ready), I'd propose that we address the stuck transaction issue by making replace-by-fee (RBF) ubiquitous.  Why not make every transaction RBF by default, and then encourage via outreach and education other wallet developers to do the same?  \n> \n> The frustration with BTC today is less so the high-fees (people realize on-chain transactions in a secure decentralized ledger are necessarily costly) but by the feeling of helplessness when their transaction is stuck.  Being able to easily bump a transaction's fee for users who are in a hurry would go a long way to improving the user experience.  \n> \n> Paul.\n> \n> \n> On Thu, Dec 21, 2017 at 2:44 PM, Gregory Maxwell via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> Personally, I'm pulling out the champaign that market behaviour is\n> indeed producing activity levels that can pay for security without\n> inflation, and also producing fee paying backlogs needed to stabilize\n> consensus progress as the subsidy declines.\n> \n> I'd also personally prefer to pay lower fees-- current levels even\n> challenge my old comparison with wire transfer costs-- but we should\n> look most strongly at difficult to forge market signals rather than\n> just claims-- segwit usage gives us a pretty good indicator since most\n> users would get a 50-70% fee reduction without even considering the\n> second order effects from increased capacity.\n> \n> As Jameson Lopp notes, more can be done for education though-- perhaps\n> that market signal isn't efficient yet. But we should get it there.\n> \n> But even independently of segwit we can also look at other inefficient\n> transaction styles: uncompressed keys, unconfirmed chaining instead of\n> send many batching, fee overpayment, etc... and the message there is\n> similar.\n> \n> I've also seen some evidence that a portion of the current high rate\n> congestion is contrived traffic. To the extent that it's true there\n> also should be some relief there soon as the funding for that runs\n> out, in addition to expected traffic patterns, difficulty changes,\n> etc.\n> \n> \n> On Thu, Dec 21, 2017 at 9:30 PM, Melvin Carvalho via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> > I asked adam back at hcpp how the block chain would be secured in the long\n> > term, once the reward goes away.  The base idea has always been that fees\n> > would replace the block reward.\n> >\n> > At that time fees were approximately 10% of the block reward, but have now\n> > reached 45%, with 50% potentially being crossed soon\n> >\n> > https://fork.lol/reward/feepct <https://fork.lol/reward/feepct>\n> >\n> > While this bodes well for the long term security of the coin, I think there\n> > is some legitimate concern that the fee per tx is prohibitive for some use\n> > cases, at this point in the adoption curve.\n> >\n> > Observations of segwit adoption show around 10% at this point\n> >\n> > http://segwit.party/charts/ <http://segwit.party/charts/>\n> >\n> > Watching the mempool shows that the congestion is at a peak, though it's\n> > quite possible this will come down over the long weekend.  I wonder if this\n> > is of concern to some.\n> >\n> > https://dedi.jochen-hoenicke.de/queue/more/#24h <https://dedi.jochen-hoenicke.de/queue/more/#24h>\n> >\n> > I thought these data points may be of interest and are mainly FYI.  Though\n> > if further discussion is deemed appropriate, it would be interesting to hear\n> > thoughts.\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n> >\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/d675d05f/attachment-0001.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2017-12-22T01:15:46",
                "message_text_only": "On Fri, Dec 22, 2017 at 12:30 AM, Mark Friedenbach via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Every transaction is replace-by-fee capable already. Opt-in replace by fee\n> as specified in BIP 125 is a fiction that held sway only while the income\n> from fees or fee replacement was so much smaller than subsidy.\n\nThe distinction is does a next fee replacement hit the next block 99%\nof the time or does it do so with 10% probability each successive\nblock that the original remains unconfirmed; eventually converging to\nthe same 99% but only after a non-trivial additional delay.  As a\nresult it's still useful to flip it on.\n\nI believe electrum has been defaulting to opt-in without any big problems.\n\nThere was discussion in the bitcoin core weekly irc meeting today\nabout defaulting it on.  Some expressed the view that perhaps it\nshould be left off by default for the RPC because some industrial\nusers but I'm of the view that those users are both most likely to\nwant it on and also the most able to see it in the release notes and\nchange their settings."
            }
        ],
        "thread_summary": {
            "title": "Total fees have almost crossed the block reward",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Michel 'ic' Luczak",
                "Jim Rogers",
                "Gregory Maxwell",
                "Paul Iverson",
                "Mark Friedenbach",
                "Melvin Carvalho",
                "Jameson Lopp"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 24387
        }
    },
    {
        "title": "[bitcoin-dev] BIP for Legacy Sign Verify functions",
        "thread_messages": [
            {
                "author": "Dan Bryant",
                "date": "2017-12-21T22:26:25",
                "message_text_only": "https://github.com/brianddk/bips/blob/legacysignverify/bip-0xyz.mediawiki\n\nAlthough this is a well established functionality, it has never been\npublished in a BIP.  My proposal is simply to provide a reference point for\nfuture expansion of these capabilities into new address schemes.\n\nOriginal reference thread [Sign / Verify message against SegWit P2SH\naddresses]\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/1407a823/attachment.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2017-12-21T23:09:05",
                "message_text_only": "On Thursday 21 December 2017 10:26:25 PM Dan Bryant via bitcoin-dev wrote:\n> https://github.com/brianddk/bips/blob/legacysignverify/bip-0xyz.mediawiki\n\nIt's not even correct... Your first \"verify message\" step is not possible; you \ncan't get a public key from an address.\n\nWhat is actually done, is using the signature + message to perform key \nrecovery, to extract the public key of the signer, and then hashing that and \ncomparing it to the address provided.\n\n> Although this is a well established functionality, it has never been\n> published in a BIP.  My proposal is simply to provide a reference point for\n> future expansion of these capabilities into new address schemes.\n\nNew schemes should probably NOT be based on the current one.\n\nLuke"
            },
            {
                "author": "Dan Bryant",
                "date": "2017-12-21T23:21:24",
                "message_text_only": "Thank you... I've updated.\n\n> New schemes should probably NOT be based on the current one.\n\nFair enough... I still think there are those who would still like an\nexisting sign/verify BIP to reference.\n\nOn Thu, Dec 21, 2017 at 5:09 PM, Luke Dashjr <luke at dashjr.org> wrote:\n\n> On Thursday 21 December 2017 10:26:25 PM Dan Bryant via bitcoin-dev wrote:\n> > https://github.com/brianddk/bips/blob/legacysignverify/\n> bip-0xyz.mediawiki\n>\n> It's not even correct... Your first \"verify message\" step is not possible;\n> you\n> can't get a public key from an address.\n>\n> What is actually done, is using the signature + message to perform key\n> recovery, to extract the public key of the signer, and then hashing that\n> and\n> comparing it to the address provided.\n>\n> > Although this is a well established functionality, it has never been\n> > published in a BIP.  My proposal is simply to provide a reference point\n> for\n> > future expansion of these capabilities into new address schemes.\n>\n> New schemes should probably NOT be based on the current one.\n>\n> Luke\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/9543aa61/attachment-0001.html>"
            },
            {
                "author": "Aymeric Vitte",
                "date": "2017-12-22T10:29:13",
                "message_text_only": "Le 22/12/2017 \u00e0 00:09, Luke Dashjr via bitcoin-dev a \u00e9crit\u00a0:\n> What is actually done, is using the signature + message to perform key \n> recovery, to extract the public key of the signer, and then hashing that and \n> comparing it to the address provided.\nI already posted about this, then what is doing the pubkey in sigscript\nfor standard p2pkh transactions? (this was not the case some time ago)\n\n-- \nBitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions\nZcash wallets made simple: https://github.com/Ayms/zcash-wallets\nBitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets\nGet the torrent dynamic blocklist: http://peersm.com/getblocklist\nCheck the 10 M passwords list: http://peersm.com/findmyass\nAnti-spies and private torrents, dynamic blocklist: http://torrent-live.org\nPeersm : http://www.peersm.com\ntorrent-live: https://github.com/Ayms/torrent-live\nnode-Tor : https://www.github.com/Ayms/node-Tor\nGitHub : https://www.github.com/Ayms"
            },
            {
                "author": "Aymeric Vitte",
                "date": "2017-12-22T23:06:20",
                "message_text_only": "Scriptsig not \"sigscript\" below\n\nNow you must answer this question, because this is what we call a hard fork\n\n\nLe 22/12/2017 \u00e0 11:29, Aymeric Vitte a \u00e9crit\u00a0:\n>\n> Le 22/12/2017 \u00e0 00:09, Luke Dashjr via bitcoin-dev a \u00e9crit\u00a0:\n>> What is actually done, is using the signature + message to perform key \n>> recovery, to extract the public key of the signer, and then hashing that and \n>> comparing it to the address provided.\n> I already posted about this, then what is doing the pubkey in sigscript\n> for standard p2pkh transactions? (this was not the case some time ago)\n>\n\n-- \nBitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions\nZcash wallets made simple: https://github.com/Ayms/zcash-wallets\nBitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets\nGet the torrent dynamic blocklist: http://peersm.com/getblocklist\nCheck the 10 M passwords list: http://peersm.com/findmyass\nAnti-spies and private torrents, dynamic blocklist: http://torrent-live.org\nPeersm : http://www.peersm.com\ntorrent-live: https://github.com/Ayms/torrent-live\nnode-Tor : https://www.github.com/Ayms/node-Tor\nGitHub : https://www.github.com/Ayms"
            }
        ],
        "thread_summary": {
            "title": "BIP for Legacy Sign Verify functions",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Dan Bryant",
                "Luke Dashjr",
                "Aymeric Vitte"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 4675
        }
    },
    {
        "title": "[bitcoin-dev] what do you think about having a maximum fee rate?",
        "thread_messages": [
            {
                "author": "oscar",
                "date": "2017-12-22T08:26:12",
                "message_text_only": "Hello,\nI'm not a bitcoin developer, but I'd like to receive feedback on what\nI think is a serious problem. Hope I'm not wasting your time.\nI'm also sure this was already discussed, but google doesn't give me\nany good result.\n\nLet me explain: I think that the current incentive system doesn't\nreally align with the way miners are distributed (not very\ndecentralized, due to pools and huge asic producers).\nI think big miners are incentivized to spam the network with low(ish)\nfee transactions, thereby forcing regular users into paying extremely\nhigh fees to be able to get their transactions confirmed.\n\nObviously this is the result of insufficient mining decentralization,\nbut as I will try to show, such an attack could be profitable even if\nyou are controlling just 5-10% of the hashing power, which could\nalways be easy for a big player and with some collusion.\n\nLet's look at some numbers: https://i.imgur.com/sCn4eDG.png\n\nThese are 10 blocks mined yesterday, and they all have rewards hugely\nexceeding the normal 12.5 mining output. Even taking the lowest value\nof 20, it's a nice 60% extra profit for the miner. Let's say you\ncontrol 10% of the hashing power, and you spam enough transactions to\nfill 144 blocks (1 day's worth) at 50 satoshi/byte, losing just 72 BTC\nin fees.\n\n(blocksize-in-bytes * fee-per-byte * Nblocks)/satoshis-in-btc => (1e6\n* 50 * 144)/1e8 => 72\n\nAt the same time you will discover about 144*0.1=14.4 blocks per day.\nAssuming the situation we see in the previous screenshot is what\nhappens when you have a mempool bigger than one day's worth of blocks,\nyou would get 20-12.5=7.5 extra BTC per block, which is 14.4*7.5=108\nBTC, given your investment of 72 to spam the mempool. 32 btc extra\nprofit.\n\nThe big assumption here is that spamming 1 day of backlog in the\n50satoshi/b range will get people to compete enough to push 7.5 btc of\nfees in each block, but:\n\n* https://jochen-hoenicke.de/queue/#30d this seems to confirm that\nabout half the mempool is in the 50satoshi/b range or less.\n* https://blockchain.info/pools there are miners that control more than 10%\n* if you get enough new real transactions, it's not necessary to spam\na full 144 blocks worth each day, probably just ~50 would be enough,\ncutting the spam cost substantially\n* other miners could be playing the same game, helping you spam and\nfurther reduce the costs of the attack\n* you actually get 10% of the fees back by avoiding mining your spam\ntransactions in your own blocks\n* most of the spam transactions won't actually end up in blocks if\nthere is enough pressure coming from real usage\n\nThis seems to indicate that you would actually get much higher profit\nmargins than my estimates. **PLEASE** correct me if my calculations or\nmy assumptions are wrong.\n\nYou might also say that doing this would force users out of the\nsystem, decreasing the value of btc and disincentivizing miners from\ncontinuing. On the other hand, a backlogged mempool could create the\nimpression of high(er) usage and increase scarcity by slowing down\nmovements, which could actually push the price upwards.\n\nOf course, it's impossible to prove that this is happening. But the\nfact that it is profitable makes me believe that it is happening.\n\nI see some solutions to this, all with their own downsides:\n\n- increasing block size every time there is sustained pressure\nthis attack wouldn't work, but the downsides have already been\ndiscussed to death.\n\n- change POW\nNot clear it would fix this, aside from stimulating terrible\ninfighting. Controlling 5 to 10% of the hashing power seems too easy,\nand I don't think it would be practical to change pow every time that\nhappens, as it would prevent the development of a solid POW support.\n\n- protocol level MAX transaction fee\nI personally think this would totally invalidate the attack by making\nthe spam more expensive than the fees you would recover.\nThere already is a minimum fee accepted by the nodes, at 1 satoshi per\nbyte. The maximum fee could be N times the minimum, maybe 100-200.\nMeaning a maximum of 1-2btc in total fee rewards when the block size\nis 1mb. Of course the actual values need more analysis, but 2btc -\ntogether with the deflationary structure - seems enough to continue\nmotivating miners, without giving unfair advantage.\n\nYes, this would make it impossible to spend your way out of a\ncongested mempool. But if the mempool stays congested after this\nchange, you could have a bigger confidence that it's coming from real\nusage or from someone willfully burning money, making a block size\nincrease much more justified.\n\nHope to hear your opinion,\nhave a nice day.\n\noscar"
            },
            {
                "author": "oscar",
                "date": "2017-12-24T13:59:23",
                "message_text_only": "On Sun, Dec 24, 2017 at 2:13 AM, Damian Williamson <willtech at live.com.au> wrote:\n> If all transactions pay the proposed max then fee there are still going to\n> be an awful lot of never confirming transactions once the transaction\n> bandwidth limit is surpassed\n\nYes obviously. That would be the unequivocal sign that it's time to\nbump the block size.\n\nWhy not just bump now then? My main worry is that wasting space should\nnot be profitable for anybody. If it is, it's an encouragement to\nwaste space, and imho we have such an encouragement in place.\n\nFees should be allowed to get high enough as to discourage wasteful\nusage of blockchain space, but not high enough as to make it\n*profitable* to waste space, if you are a sufficiently big miner. The\nfact that it is now profitable, and that such big miners exist, makes\nme believe that a lot of blockchain space is wasted on purpose.\n\n> This is what I have been working on as an alternative:\n>\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015371.html\n\nI read your proposal, but the value that I see in mine is that it is\nextremely simple. It would be trivial to have nodes stop propagating\ntransactions with fees over the max, and miners can trivially reject\nblocks where coinbase > block reward + max fee rate * block size, if\nthey are on board.\n\nIt would also be quite simple to adapt wallets, given that the fee\nrange is fixed. If nodes had an rpc method giving you some mempool\nstatistics, it would also be simple to correctly recommend fees\naccording to the time expected to first confirmation.\n\nSure, at some point, if there is real congestion, it would just start\nalways recommending the max fee. Again, this means that it's time to\nbump the block size. I think this is ultimately unavoidable, but I\nunderstand the reservations, and I agree that increasing the block\nsize without incentivizing efficient usage would be counterproductive.\nI think the current fees are certainly incentivizing efficient usage\nto users, but not to miners. My (maybe naive) idea is that it would be\npossible to find an appropriate maximum fee value that would move\nthings towards efficient usage by both users and big miners.\n\nThis would work very well if coupled with some proposals I've read to\nslowly increase the block size with a process similar to difficulty\nadjustment, like adding 100kb if 95% of the last 2016 blocks were\nfull. Without max fees, a big miner could easily destroy this strategy\nby always applying just enough pressure as to always skyrocket fees\nand profit, while the blocksize slowly increases.\n\nThe way I see it, unbounded fees together with small blocks and big\nminers introduce a terrible flaw in the incentives equilibrium.\nI would really like an open discussion on this topic."
            }
        ],
        "thread_summary": {
            "title": "what do you think about having a maximum fee rate?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "oscar"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 7390
        }
    },
    {
        "title": "[bitcoin-dev]  what do you think about having a maximum fee rate?",
        "thread_messages": [
            {
                "author": "Damian Williamson",
                "date": "2017-12-24T01:13:27",
                "message_text_only": "If all transactions pay the proposed max then fee there are still going to be an awful lot of never confirming transactions once the transaction bandwidth limit is surpassed, as I suppose that it roughly is now:\n\nhttps://bitinfocharts.com/comparison/bitcoin-transactions.html\n\n\nThis is what I have been working on as an alternative:\n\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015371.html\n\n\nThere is a previous thread, linked later on in the linked thread.\n\n\nRegards,\n\nDamian Williamson\n\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of oscar via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Friday, 22 December 2017 7:26:12 PM\nTo: bitcoin-dev at lists.linuxfoundation.org\nSubject: [bitcoin-dev] what do you think about having a maximum fee rate?\n\nHello,\nI'm not a bitcoin developer, but I'd like to receive feedback on what\nI think is a serious problem. Hope I'm not wasting your time.\nI'm also sure this was already discussed, but google doesn't give me\nany good result.\n\nLet me explain: I think that the current incentive system doesn't\nreally align with the way miners are distributed (not very\ndecentralized, due to pools and huge asic producers).\nI think big miners are incentivized to spam the network with low(ish)\nfee transactions, thereby forcing regular users into paying extremely\nhigh fees to be able to get their transactions confirmed.\n\nObviously this is the result of insufficient mining decentralization,\nbut as I will try to show, such an attack could be profitable even if\nyou are controlling just 5-10% of the hashing power, which could\nalways be easy for a big player and with some collusion.\n\nLet's look at some numbers: https://i.imgur.com/sCn4eDG.png\n\n[https://i.imgur.com/sCn4eDG.png]\n\n\nThese are 10 blocks mined yesterday, and they all have rewards hugely\nexceeding the normal 12.5 mining output. Even taking the lowest value\nof 20, it's a nice 60% extra profit for the miner. Let's say you\ncontrol 10% of the hashing power, and you spam enough transactions to\nfill 144 blocks (1 day's worth) at 50 satoshi/byte, losing just 72 BTC\nin fees.\n\n(blocksize-in-bytes * fee-per-byte * Nblocks)/satoshis-in-btc => (1e6\n* 50 * 144)/1e8 => 72\n\nAt the same time you will discover about 144*0.1=14.4 blocks per day.\nAssuming the situation we see in the previous screenshot is what\nhappens when you have a mempool bigger than one day's worth of blocks,\nyou would get 20-12.5=7.5 extra BTC per block, which is 14.4*7.5=108\nBTC, given your investment of 72 to spam the mempool. 32 btc extra\nprofit.\n\nThe big assumption here is that spamming 1 day of backlog in the\n50satoshi/b range will get people to compete enough to push 7.5 btc of\nfees in each block, but:\n\n* https://jochen-hoenicke.de/queue/#30d this seems to confirm that\n[https://jochen-hoenicke.de/queue/mempool-20170608.png]<https://jochen-hoenicke.de/queue/#30d>\n\nJohoe's Mempool Size Statistics - jochen-hoenicke.de/queue<https://jochen-hoenicke.de/queue/#30d>\njochen-hoenicke.de\nThis page displays the number and size of the unconfirmed bitcoin transactions, also known as the transactions in the mempool. It gives a real-time view and shows how ...\n\n\nabout half the mempool is in the 50satoshi/b range or less.\n* https://blockchain.info/pools there are miners that control more than 10%\nBitcoin Hashrate Distribution - Blockchain.info<https://blockchain.info/pools>\nblockchain.info\nA pie chart showing the hashrate distribution between the major bitcoin mining pools - Blockchain\n\n\n* if you get enough new real transactions, it's not necessary to spam\na full 144 blocks worth each day, probably just ~50 would be enough,\ncutting the spam cost substantially\n* other miners could be playing the same game, helping you spam and\nfurther reduce the costs of the attack\n* you actually get 10% of the fees back by avoiding mining your spam\ntransactions in your own blocks\n* most of the spam transactions won't actually end up in blocks if\nthere is enough pressure coming from real usage\n\nThis seems to indicate that you would actually get much higher profit\nmargins than my estimates. **PLEASE** correct me if my calculations or\nmy assumptions are wrong.\n\nYou might also say that doing this would force users out of the\nsystem, decreasing the value of btc and disincentivizing miners from\ncontinuing. On the other hand, a backlogged mempool could create the\nimpression of high(er) usage and increase scarcity by slowing down\nmovements, which could actually push the price upwards.\n\nOf course, it's impossible to prove that this is happening. But the\nfact that it is profitable makes me believe that it is happening.\n\nI see some solutions to this, all with their own downsides:\n\n- increasing block size every time there is sustained pressure\nthis attack wouldn't work, but the downsides have already been\ndiscussed to death.\n\n- change POW\nNot clear it would fix this, aside from stimulating terrible\ninfighting. Controlling 5 to 10% of the hashing power seems too easy,\nand I don't think it would be practical to change pow every time that\nhappens, as it would prevent the development of a solid POW support.\n\n- protocol level MAX transaction fee\nI personally think this would totally invalidate the attack by making\nthe spam more expensive than the fees you would recover.\nThere already is a minimum fee accepted by the nodes, at 1 satoshi per\nbyte. The maximum fee could be N times the minimum, maybe 100-200.\nMeaning a maximum of 1-2btc in total fee rewards when the block size\nis 1mb. Of course the actual values need more analysis, but 2btc -\ntogether with the deflationary structure - seems enough to continue\nmotivating miners, without giving unfair advantage.\n\nYes, this would make it impossible to spend your way out of a\ncongested mempool. But if the mempool stays congested after this\nchange, you could have a bigger confidence that it's coming from real\nusage or from someone willfully burning money, making a block size\nincrease much more justified.\n\nHope to hear your opinion,\nhave a nice day.\n\noscar\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\nbitcoin-dev Info Page - Linux Foundation<https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\nlists.linuxfoundation.org\nBitcoin development and protocol discussion. This list is lightly moderated. - No offensive posts, no personal attacks. - Posts must concern development of bitcoin ...\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171224/3a73592f/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "what do you think about having a maximum fee rate?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Damian Williamson"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 6795
        }
    },
    {
        "title": "[bitcoin-dev] BIP 176: Utilization of bits denomination",
        "thread_messages": [
            {
                "author": "sumBTC",
                "date": "2017-12-23T19:05:20",
                "message_text_only": "Why not use \"coinbit\". A bitcoin is equal to 1 million coinbits.\n\nA bit could then be seen/used as an abbreviation of coinbit."
            }
        ],
        "thread_summary": {
            "title": "BIP 176: Utilization of bits denomination",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "sumBTC"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 126
        }
    },
    {
        "title": "[bitcoin-dev] BIP 177: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks",
        "thread_messages": [
            {
                "author": "Damian Williamson",
                "date": "2017-12-24T02:57:38",
                "message_text_only": "BIP 177: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n\nThis BIP proposes to address the issue of transactional reliability in Bitcoin, where valid transactions may be stuck in the mempool for extended periods.\n\n\nThere are two key issues to be resolved:\n\n\n  1.  The current transaction bandwidth limit.\n  2.  The current ad-hoc methods of including transactions in blocks resulting in variable and confusing confirmation times for valid transactions, including transactions with a valid fee that may never confirm.\n\n\nIt is important with any change to protect the value of fees as these will eventually be the only payment that miners receive. Rather than an auction model for limited bandwidth, the proposal results in a stable fee for priority service auction model.\n\n\nI will post the full proposal up on to my blog in the coming days and, re-review incorporating feedback that I have received on and off thread. It would not be true to suggest that all feedback received has been entirely positive although, most of it has been constructive.\n\n\nThe previous threads for this BIP are available here:\n\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/subject.html\n\n\nRegards,\n\nDamian Williamson\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171224/1f991190/attachment-0001.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2017-12-24T07:21:24",
                "message_text_only": "BIP 177 is NOT assigned. Do not self-assign BIP numbers!\n\nPlease read BIP 2:\n\n    https://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki\n\nLuke\n\n\nOn Sunday 24 December 2017 2:57:38 AM Damian Williamson via bitcoin-dev wrote:\n> BIP 177: UTPFOTIB - Use Transaction Priority For Ordering Transactions In\n> Blocks\n> \n> \n> This BIP proposes to address the issue of transactional reliability in\n> Bitcoin, where valid transactions may be stuck in the mempool for extended\n> periods.\n> \n> \n> There are two key issues to be resolved:\n> \n> \n>   1.  The current transaction bandwidth limit.\n>   2.  The current ad-hoc methods of including transactions in blocks\n> resulting in variable and confusing confirmation times for valid\n> transactions, including transactions with a valid fee that may never\n> confirm.\n> \n> \n> It is important with any change to protect the value of fees as these will\n> eventually be the only payment that miners receive. Rather than an auction\n> model for limited bandwidth, the proposal results in a stable fee for\n> priority service auction model.\n> \n> \n> I will post the full proposal up on to my blog in the coming days and,\n> re-review incorporating feedback that I have received on and off thread.\n> It would not be true to suggest that all feedback received has been\n> entirely positive although, most of it has been constructive.\n> \n> \n> The previous threads for this BIP are available here:\n> \n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/subje\n> ct.html\n> \n> \n> Regards,\n> \n> Damian Williamson"
            },
            {
                "author": "Damian Williamson",
                "date": "2017-12-24T22:20:50",
                "message_text_only": "My mistake, apologies all.\n\n\n - I honestly thought everyone just took the next available number and published up their BIP's.\n\n\nAnd, I see you have something of a master list.\n\n\nAs a suggestion, would it be worth considering linking to some of that information in the list welcome email? Web search is not always your friend for locating everything relevant.\n\n\nRegards,\n\nDamian Williamson\n\n________________________________\nFrom: Luke Dashjr <luke at dashjr.org>\nSent: Sunday, 24 December 2017 6:21:24 PM\nTo: Damian Williamson\nCc: bitcoin-dev at lists.linuxfoundation.org\nSubject: Re: [bitcoin-dev] BIP 177: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\nBIP 177 is NOT assigned. Do not self-assign BIP numbers!\n\nPlease read BIP 2:\n\n    https://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki\n[https://avatars0.githubusercontent.com/u/528860?s=400&v=4]<https://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki>\n\nbips/bip-0002.mediawiki at master \u00b7 bitcoin/bips \u00b7 GitHub<https://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki>\ngithub.com\nAbstract. A Bitcoin Improvement Proposal (BIP) is a design document providing information to the Bitcoin community, or describing a new feature for Bitcoin or its ...\n\n\n\nLuke\n\n\nOn Sunday 24 December 2017 2:57:38 AM Damian Williamson via bitcoin-dev wrote:\n> BIP 177: UTPFOTIB - Use Transaction Priority For Ordering Transactions In\n> Blocks\n>\n>\n> This BIP proposes to address the issue of transactional reliability in\n> Bitcoin, where valid transactions may be stuck in the mempool for extended\n> periods.\n>\n>\n> There are two key issues to be resolved:\n>\n>\n>   1.  The current transaction bandwidth limit.\n>   2.  The current ad-hoc methods of including transactions in blocks\n> resulting in variable and confusing confirmation times for valid\n> transactions, including transactions with a valid fee that may never\n> confirm.\n>\n>\n> It is important with any change to protect the value of fees as these will\n> eventually be the only payment that miners receive. Rather than an auction\n> model for limited bandwidth, the proposal results in a stable fee for\n> priority service auction model.\n>\n>\n> I will post the full proposal up on to my blog in the coming days and,\n> re-review incorporating feedback that I have received on and off thread.\n> It would not be true to suggest that all feedback received has been\n> entirely positive although, most of it has been constructive.\n>\n>\n> The previous threads for this BIP are available here:\n>\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/subje\n> ct.html\n>\n>\n> Regards,\n>\n> Damian Williamson\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171224/8e260a6c/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP 177: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Damian Williamson",
                "Luke Dashjr"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 5811
        }
    },
    {
        "title": "[bitcoin-dev] Bravo Charlie One: Branding Bech32",
        "thread_messages": [
            {
                "author": "nullius",
                "date": "2017-12-25T21:21:57",
                "message_text_only": "I here record for the devs a thought I had a few days ago on the Bitcoin \nForum about BIP 173 Bech32 addresses.  I\u2019ve heard Greg Maxwell say that \n\u201cBech32 is designed for human use and basically nothing else\u201d; so I hope \nI be not untoward in considering the following human-friendliness \nenhancement to entwine with the technical ambit of this list.  This MAY \nbe suitable for mention in an informative specification, or informative \nsection thereof.\n\nTo help gain user familiarity with and acceptance of the \nerror-correcting, case-insensitive Bitcoin addresses of the future, I \npropose a need for what I think marketers call \u201cbranding\u201d.  The best \nbranding is that which derives naturally from some intrinsic quality of \na thing; wherefore I look to what may perhaps be a bit of serendipity in \nthe specification.\n\nI expect that in practical use, one of the great advantages of Bech32 \naddresses will be the relative ease of communicating them \naloud\u2014especially over the phone.  In similar circumstances, when trying \nto convey unusual names or pseudorandom strings, I\u2019ve found radio \nalphabets to work well at their intended purpose.  And when reading \nBech32 Bitcoin addresses in the most popular radio alphabet, they will \nalways start with a catchy phrase:  \u201cBravo Charlie One\u201d.\n\nThat\u2019s memorable, $SEARCH-able, and yet also one of those unique, \notherwise meaningless phrases which gets marketers excited.  Keeping to \na word triplet, I hereby submit for consideration as the official \nnickname for Bech32 Bitcoin use:  \u201cBravo Charlie Addresses\u201d.  These are \nthe Bitcoin addresses with the magic words, suitable for a motto:  \n\u201cBravo Charlie One means money.\u201d  Add a logo \u00e0 la Segwit\u2019s, and raise \nuser awareness of this exciting new technology!\n\nBeyond the branding issue, recommendations for Bitcoin spelling-alphabet \nuse in English and other languages may perhaps be a suitable matter for \nsuch standardization as would facilitate coherent user documentation.  I \ninvite discussion.\n\nOf course, this branding only applies directly to Bitcoin Bech32 \naddresses.  The BIP 173 authors were gracious to make the standard \ngenerally adaptable; and it has already seen some uptake amongst \naltcoins.  I myself am now contemplating how Bech32 would be a superior \nhuman-facing format for key fingerprints for PGP, SSH, and even TLS, \nwith HRPs of \u201cpgp\u201d, \u201cssh\u201d, \u201ctls\u201d, etc. and some appropriate means of \nembedding the key type just as \u201cbc\u201d embeds the witness version.  There \nis an urgent general need for a specification which reduces the inherent \npain of wetware in handling pseudorandom strings; and I do think that \nanything which familiarizes users with Bech32 in a specific use will be \nbeneficial to Bech32 adoption generally.\n\nTo celebrate, as seen in my sig, I created for myself a new Bravo \nCharlie Address which expresses that I am pleased:  Now, I have an \nerror-correcting, case-insensitive address which can receive only \ngenuine Bitcoin cash money.  Because \u201cBravo Charlie One means money.\u201d\n\nHere\u2019s to the Bitcoin address format of the future!\n\n-- \nnullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\nBitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n\u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\nNo!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 228 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171225/b743b321/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Bravo Charlie One: Branding Bech32",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "nullius"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3687
        }
    },
    {
        "title": "[bitcoin-dev] Hash Graph - Applied to BTC?",
        "thread_messages": [
            {
                "author": "Tim-Hinnerk Heuer",
                "date": "2017-12-27T12:09:17",
                "message_text_only": "Is it possible to make a hard fork of Bitcoin that implements Hash Graph?\nIs this legal as Hash Graph is proprietary licensed? Even though the\nlicense does not agree with open source, the algorithm is open and\npotentially could be implemented while still giving value to \"old\" crypto\ncurrency tokens and keys.\n\nBitcoin to scale to billions if not trillions of transactions per second.\n\nIt is known that Bitcoin has a scaling problem. 6 transactions per second\nis not enough to sustain a global economy. Lightning promises to solve this\nbut it's still not implemented fully?!\n\nI transferred a small amount of BTC to Ethereum and it took several days on\na small priority.\n\nJust a simple Wallet (Coinomi).\n\nHave installed a full Bitcoin wallet but tried also easier to use\nimplementations such as Jaxx and Coinomi.\n\nI'm happy to do some coding as I am a programmer, but haven't had any\nnotable experience with implementing crypto algorithms before. However, I\nhave plenty of experience implementing algorithms.\n\nNo debug log at this time.\n\n\nRegards,\n\nTim\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171227/9d22877d/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Hash Graph - Applied to BTC?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Tim-Hinnerk Heuer"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1234
        }
    },
    {
        "title": "[bitcoin-dev] Transaction aging to relieve user concerns.",
        "thread_messages": [
            {
                "author": "Dan Bryant",
                "date": "2017-12-28T19:55:01",
                "message_text_only": "I was considering starting a BIP, but wanted to ask the thread if anything\nlike this was already done or in the works.  My proposal is to expand the\nTXN format to include chain-height (block number) in the TXN.  This would\nallow nodes / miners to age the TXN and choose (optionally) not to\nrebroadcast it after a certain age threshold.  Currently (as I understand\nit), nodes and miners keep effectively a \"seen-list\" of TXNs and age them\nbased upon when they were last seen.  This is very effective as it reduces\nTXN size and frees the TXN from having to declare its age.  The downside to\nthis is that those TXNs could be broadcast forever, assuming (big assume)\nthat the UTXO never got spent.\n\nThe goal here is not to enhance the protocol... if anything this would\nincrease TXN cost as it would add a few bytes to it.  The goal here is to\nmake it easier for users to know with better certainty when an TXN is going\nto age out.  Obviously RBF is a better solution, but there may be some\ninstances when a user wants to effectively cancel a TXN.\n\nPossible abuse vectors might include:\n\n* Bad party broadcasting a low fee TXN at the edge of the age-out threshold\nand trying to get goods, realizing the TXN will age out at the very next\nblock.\n\nIf this proposal might be something that core would entertain in a BIP\nproposal I'll start drafting something.  If there are suggestions about\nwhere to place the block number to have minimal impact and ensure backward\ncompatibility, that would be great to.  If this is simply silly and should\nnot be entertained, no harm there either.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171228/8dd7f6b2/attachment.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-12-28T20:49:38",
                "message_text_only": "However users can\u2019t know with any certainty whether transactions will \u201cage out\u201d as indicated, since this is only relay policy. Exceeding the specified timeout doesn\u2019t prevent a miner from including it in the chain, and therefore doesn\u2019t really provide any actionable information.\n\n> On Dec 28, 2017, at 11:55 AM, Dan Bryant via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> The goal here is to make it easier for users to know with better certainty when an TXN is going to age out"
            }
        ],
        "thread_summary": {
            "title": "Transaction aging to relieve user concerns.",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Dan Bryant",
                "Mark Friedenbach"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 2259
        }
    },
    {
        "title": "[bitcoin-dev] Single signature for all transactions in a block?",
        "thread_messages": [
            {
                "author": "CANNON",
                "date": "2017-12-31T23:39:17",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nI had a question relating to scaling and privacy enhancements.\nI believe that segwit combined with aggregated signatures\nand coinjoin can potentially achieve such. The idea is to\nuse aggregated signatures in conjunction with coinjoin. So\nthat all inputs of a coinjoin transaction would have a single\nsignature vastly decreasing size while having privacy at the\nsame time. If majority of transactions in a block did this I\nassume that significant more transactions could be fit into a\nblock? However the question I have, with the extra blockspace\nmade possible by segwit, is this extra blockspace limited to only\nwitness data or can it be used for transaction data such as the\nscenario I have described here?\n\n- --\nCannon\nPGP Fingerprint: 2BB5 15CD 66E7 4E28 45DC 6494 A5A2 2879 3F06 E832 \nEmail: cannon at cannon-ciota.info\n\nNOTICE: ALL EMAIL CORRESPONDENCE NOT SIGNED/ENCRYPTED WITH PGP SHOULD \nBE CONSIDERED POTENTIALLY FORGED, AND NOT PRIVATE.\n-----BEGIN PGP SIGNATURE-----\n\niQIcBAEBCgAGBQJaSXSNAAoJEAYDai9lH2mwRy4QAMqhl6UWNqRy7ziDuxukm+nZ\njWtjyc8G38b9r9Nya13/GslHWeEDdSmma6e7afFMVX1y9Qj+t0EZDJVlMMy8JRZr\nzDmSdXDxStNv6T+L3NVbSOBhdP+1MpcsvAAs3yd0Nl5cxfBF87ArHlXMbTLJF86S\n1gijI4pg3x83tDg/Di6gf9BHk2oXGDc4vraF6LsMDTfQmp7S8pivnswaaEyb6etH\n39ei6L3wkV7LvTmA2onCAB8vZtTuARhNuLTYSPfH5LAC4hha2bOCXci3p4Mz4qh3\nU4LqUnuYVR8nYOFFsrfhKggN3kptVWhrbDAoHR2fLoYDmfbMkqUdyjdmmc2Rvlgm\neMJvpG91dYb+Q6JqTrar6DH+XSvoOVSWnBLe8Uwf4AnzGxMUpkTDzkyaBxGq4K1u\nVv2Yg808KwA47MKKpvKSckB350YAq9Cr276Lq/giUrxmS1gOyDKDjm1e3yFLM+6d\nNancAwgnp17q43FwSX44cT0ISxk9USnWVhaKDQjSGK8MnirkZ1vuu2SshEW1AVhm\n44Bt5nQdLmJDw7rqwkjv66sxofXvmCAnPD+p4yiVyfLNZ7OKw6XNcKm3zKAch2Fy\nfefWbZnw0yEA3IhNPiMZOSv/YnwTtfzpFUNuTCtLehs+3Xkp0bl72JDz0HRVYbHM\nRbsrLp60rD5kuJBq5dl7\n=3gku\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "Bryan Bishop",
                "date": "2017-12-31T23:46:57",
                "message_text_only": "On Sun, Dec 31, 2017 at 5:39 PM, CANNON via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> I had a question relating to scaling and privacy enhancements.\n> I believe that segwit combined with aggregated signatures\n> and coinjoin can potentially achieve such. The idea is to\n> use aggregated signatures in conjunction with coinjoin. So\n> that all inputs of a coinjoin transaction would have a single\n> signature vastly decreasing size while having privacy at the\n> same time. If majority of transactions in a block did this I\n> assume that significant more transactions could be fit into a\n> block?\n\n\nHere are some resources to read regarding signature aggregation and\nscalability:\n\nhttps://diyhpl.us/wiki/transcripts/bitcoin-core-dev-tech/2017-09-06-signature-aggregation/\nhttps://diyhpl.us/wiki/transcripts/gmaxwell-2017-08-28-deep-dive-bitcoin-core-v0.15/#signature-aggregation\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/milan/schnorr-signatures/\nhttps://bitcoincore.org/en/2017/03/23/schnorr-signature-aggregation/\nhttps://bitcointalk.org/index.php?topic=1377298.0\nhttps://bitcoincore.org/logs/2016-05-zurich-meeting-notes.html\nhttps://github.com/sipa/secp256k1/blob/968e2f415a5e764d159ee03e95815ea11460854e/src/modules/schnorr/schnorr.md\nhttps://diyhpl.us/wiki/transcripts/2016-july-bitcoin-developers-miners-meeting/dan-boneh/\n\n- Bryan\nhttp://heybryan.org/\n1 512 203 0507\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171231/515a6708/attachment.html>"
            },
            {
                "author": "Rhavar",
                "date": "2017-12-31T23:49:15",
                "message_text_only": "The key to understanding how it works is to stop thinking in terms of a block size limit, but rather a block weight limit. 1 byte of witness data counts as 1 weight, the rest counts for 4 weight. A block must be less than 4 million weight. There's no separate limits at all, so any saving in the witness space (e.g. through signature aggregation) is useful for both witness/non-witness data.\n\n-Ryan\n\n> -------- Original Message --------\n> Subject: [bitcoin-dev] Single signature for all transactions in a block?\n> Local Time: December 31, 2017 5:39 PM\n> UTC Time: December 31, 2017 11:39 PM\n> From: bitcoin-dev at lists.linuxfoundation.org\n> To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\n>\n> -----BEGIN PGP SIGNED MESSAGE-----\n> Hash: SHA512\n>\n> I had a question relating to scaling and privacy enhancements.\n> I believe that segwit combined with aggregated signatures\n> and coinjoin can potentially achieve such. The idea is to\n> use aggregated signatures in conjunction with coinjoin. So\n> that all inputs of a coinjoin transaction would have a single\n> signature vastly decreasing size while having privacy at the\n> same time. If majority of transactions in a block did this I\n> assume that significant more transactions could be fit into a\n> block? However the question I have, with the extra blockspace\n> made possible by segwit, is this extra blockspace limited to only\n> witness data or can it be used for transaction data such as the\n> scenario I have described here?\n>\n> ---------------------------------------------------------------\n>\n> Cannon\n> PGP Fingerprint: 2BB5 15CD 66E7 4E28 45DC 6494 A5A2 2879 3F06 E832\n> Email: cannon at cannon-ciota.info\n>\n> NOTICE: ALL EMAIL CORRESPONDENCE NOT SIGNED/ENCRYPTED WITH PGP SHOULD\n> BE CONSIDERED POTENTIALLY FORGED, AND NOT PRIVATE.\n> -----BEGIN PGP SIGNATURE-----\n>\n> iQIcBAEBCgAGBQJaSXSNAAoJEAYDai9lH2mwRy4QAMqhl6UWNqRy7ziDuxukm+nZ\n> jWtjyc8G38b9r9Nya13/GslHWeEDdSmma6e7afFMVX1y9Qj+t0EZDJVlMMy8JRZr\n> zDmSdXDxStNv6T+L3NVbSOBhdP+1MpcsvAAs3yd0Nl5cxfBF87ArHlXMbTLJF86S\n> 1gijI4pg3x83tDg/Di6gf9BHk2oXGDc4vraF6LsMDTfQmp7S8pivnswaaEyb6etH\n> 39ei6L3wkV7LvTmA2onCAB8vZtTuARhNuLTYSPfH5LAC4hha2bOCXci3p4Mz4qh3\n> U4LqUnuYVR8nYOFFsrfhKggN3kptVWhrbDAoHR2fLoYDmfbMkqUdyjdmmc2Rvlgm\n> eMJvpG91dYb+Q6JqTrar6DH+XSvoOVSWnBLe8Uwf4AnzGxMUpkTDzkyaBxGq4K1u\n> Vv2Yg808KwA47MKKpvKSckB350YAq9Cr276Lq/giUrxmS1gOyDKDjm1e3yFLM+6d\n> NancAwgnp17q43FwSX44cT0ISxk9USnWVhaKDQjSGK8MnirkZ1vuu2SshEW1AVhm\n> 44Bt5nQdLmJDw7rqwkjv66sxofXvmCAnPD+p4yiVyfLNZ7OKw6XNcKm3zKAch2Fy\n> fefWbZnw0yEA3IhNPiMZOSv/YnwTtfzpFUNuTCtLehs+3Xkp0bl72JDz0HRVYbHM\n> RbsrLp60rD5kuJBq5dl7\n> =3gku\n> -----END PGP SIGNATURE-----\n> ---------------------------------------------------------------\n>\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171231/3562c354/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Single signature for all transactions in a block?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Bryan Bishop",
                "Rhavar",
                "CANNON"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 6416
        }
    }
]