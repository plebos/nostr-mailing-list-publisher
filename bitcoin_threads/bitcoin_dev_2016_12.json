[
    {
        "title": "[bitcoin-dev] New BIP: Hardfork warning system",
        "thread_messages": [
            {
                "author": "Johnson Lau",
                "date": "2016-12-01T17:20:31",
                "message_text_only": "This BIP defines a change in consensus rules regarding to block nVersion, and define a concept of generalized block header to implement a hardfork warning system for full nodes and light nodes.\n\nFor better formatting, visit github\nhttps://github.com/jl2012/bips/blob/hfwarning/bip-hfwarning.mediawiki\n\n\n\nBIP: ?\nTitle: Hardfork warning system\nAuthor: Johnson Lau <jl2012 at xbt.hk>\nStatus: Draft\nType: Standard\nCreated: 2016-12-01\n\nAbstract\n\nThis BIP defines a change in consensus rules regarding to block nVersion, and define a concept of generalized block header to implement a hardfork warning system for full nodes and light nodes.\n\nMotivation\n\nSoftfork and hardfork are the 2 majors categories of consensus rules change. Generally, softforks make some previously valid blocks invalid, while hardforks make some previously invalid blocks valid. Bitcoin has successfully introduced a number of new functions through softforks. A built-in warning system is also available in many implementations to warn users for the activation of any unknown softforks.\n\nSome features, however, may not be easily introduced with a softfork. Examples include expanding maximum block resources limits, and changing the average block time interval. When such features are implemented with a hardfork, existing full node implementations would consider such blocks as invalid, and may even ban a peer for relaying such blocks. They are effectively blind to such hardfork rule changes, leaving users to unknowingly transact on a system with potentially different token value. On the other hand, light nodes may blindly follow a hardfork with unknown rule changes and lose the right to choose the previous system.\n\nThis BIP defines a change in consensus rules regarding to block nVersion, and define a concept of generalized block header to implement a hardfork warning system for full nodes and light nodes.\n\nDefinitions\n\nValid block\nA block that satisfies all the consensus rules being enforced by a bitcoin protocol implementation. An implementation may intentionally (e.g. a light node) or unintentionally (e.g. unaware of a softfork) not enforcing any part of the current netwrok rules.\n\nValid blockchain\nA blockchain constituting of only valid blocks.\n\nBest valid blockchain\nThe valid blockchain with highest total proof-of-work.\n\nValid blockchain fork\nA valid blockchain sharing a common ancestral block with the best valid blockchain, but with less total proof-of-work\n\nGeneralized block header\nAny serialized hexadecimal data with exactly 80 bytes (byte 0 to byte 79). The bytes 4 to 35 are the double-SHA256 hash of another generalized block header. The bytes 72 to 75 are nBits, the target of this generalized block header encoded in the same way as normal bitcoin block header. The 2 most significant bits of the byte 3 are the hardfork notification bits. The semantics of other data in a generalized block header is not defined in any general way. It should be noted that a normal bitcoin block header is a special case of generalized block header.\n\nGeneralized block header chain\nA chain of generalized block header. A header chain of valid blocks is a special case of a generalized block header chain.\n\n\nSpecifications\n\n\nBlock nVersion softfork\n\nA softfork is deployed to restrict the valid value of block nVersion. Upon activation, any block with the second highest nVersion bit set becomes invalid (nVersion & 0x40000000)\n\nThis softfork will be deployed by \"version bits\" BIP9 with the name \"hfbit\" and using bit 2.\n\nFor Bitcoin mainnet, the BIP9 starttime will be midnight TBC UTC (Epoch timestamp TBC) and BIP9 timeout will be midnight TBC UTC (Epoch timestamp TBC).\n\nFor Bitcoin testnet, the BIP9 starttime will be midnight TBC UTC (Epoch timestamp TBC) and BIP9 timeout will be midnight TBC UTC (Epoch timestamp TBC).\n\nAny bitcoin implementation (full nodes and light nodes) supporting this softfork should also implement a hardfork warning system described below.\n\n\nValidation of generalized block header\n\nA bitcoin protocol implementation should consider a generalized block header as valid if it satisfies all of the following criteria:\n\n\t\u2022 It is a descendant of the header of a valid block in a valid blockchain (the best valid blockchain or a valid blockchain fork).\n\t\u2022 It satisfies the proof-of-work requirement: its double-SHA256 value MUST be smaller than its target (encoded as nBits).\n\t\u2022 Its target MUST NOT be greater than the target of its last ancestral valid block by more than 1024 times. An implementation may decide to use a different threshold (or dynamic threshold), depending on its tolerance against potential DoS attacks by generating many low difficulty headers. However, if the value is set too low, a hardfork with lower difficulty may not be detected.[1]\nIn general, a bitcoin protocol implementation should keep an index of all known generalized block header chains, along with the valid blockchain(s). However, if a generalized block header chain is grown on top of a very old valid block, with total proof-of-work much lower than the current best valid bloackchain, it may be safely discarded.\n\n\nHardfork warning system in full nodes\n\nHardfork with unknown rules\nIf a generalized block header chain with non-trivial total proof-of-work is emerging, and is not considered as a valid blockchain, a hardfork with unknown rules may be happening.\n\nA wallet implementation should issue a warning to its users and stop processing incoming and outgoing transactions, until further instructions are given. It should not attempt to conduct transactions on or otherwise interpreting any block data of the hardfork with unknown rules.\n\nA mining implementation should issue a warning to its operator. Until further instructions are given, it may either stop mining, or ignore the hardfork with unknown rules. It should not attempt to confirm a generalized block header with unknown rules.\n\nSetting of one or both hardfork notification bits is, as defined by BIP34 and this BIP, a hardfork, and should be considered as an indication of a planned hardfork. If a hardfork with unknown rules is happening without any hardfork notification bits set, it is probably an accidental consensus failure, such as the March 2013 fork due to a block database bug (BIP50), and the July 2015 fork following the BIP66 activation.[2]\n\n\nHardfork with multiple valid blockchains\nIf a valid blockchain fork is emerging with non-trivial total proof-of-work, a consensus disagreement may be happening among different miners.\n\nA wallet implementation should issue a warning to its users and stop processing incoming and outgoing transactions, until further instructions are given.\n\nA mining implementation should issue a warning to its operator. Until further instructions are given, it may either stop mining, or mine on top of the best valid chain by its own standard.\n\nHardfork warning system in light nodes\n\nLight node (usually wallet implementations) is any bitcoin protocol implementations that intentionally not fully enforcing the network rules. As an important part of the hardfork warning system, a light node should observe the hardfork notification bits in block header, along with any other rules it opts to validate. If any of the hardfork notification bits is set, it should issue a warning to its users and stop processing incoming and outgoing transactions, until further instructions are given. It should not attempt to conduct transactions on or otherwise interpreting any block data of the hardfork blockchain, even if it might be able to decode the block data.\n\n\nApplications\n\nHardfork notification bits\nThere are 2 hardfork notification bits defined in this BIP. The higher bit has been forbidden since BIP34, and the lower bit is disabled by this BIP. For nodes supporting this BIP, the semantics of the 2 bits are the same: a hardfork is happening. For legacy node, however, setting the higher bit would make them fail to follow the hardforking chain. In a soft-hardfork design (described below), the lower notification bit should be used.\nThe hardfork warning system is able to detect the following types of hardforks:\n\nSoft-hardfork (with the lower hardfork notification bit)\nA soft-hardfork is a technique to implement a hardfork by pretending to create blocks with only a zero output value coinbase transaction, and commit the real transaction Merkle root in the coinbase scriptSig field. With the lower hardfork notification bit set, a node following this BIP will consider this as a hardfork and enter the safe mode, while a legacy node not following this BIP will be effectively broken due to seeing the continuously empty blockchain.\n\nRedefining the nTime field\nAs the warning system does not interpret the nTime field, redefining it through a hardfork would be detectable. For example, overflow may be allowed to overcome the year 2106 problem.\n\nRedefining the Merkle root hash field and changing block content validation rules\nThe 32-byte Merkle root hash could be redefined, for example, with a different hashing algorithm. Any block resources limitation and transaction validation rules may also be changed. All such hardforks would be detected by the warning system.\n\nChanging average block interval or difficulty reset\nSince the warning system is not bound to a particular proof-of-work target adjustment schedule, a hardfork changing the average block interval or resetting the difficulty will be detectable.\n\nIntroducing secondary proof-of-work\nIntroducing secondary proof-of-work (with non-SHA256 algorithm or fixing the block withholding attack against mining pools) may be detectable, as long as the generalized block header format is preserved.\n\nAccidental hardfork\nAn accidental hardfork may be detectable, if the generalized block headers in both forks are valid but no hardfork notification bit is set.\n\n\nLimitations\n\nThe only function of this system is to inform the users that a hardfork might be happening and prompt for further instructions. It does not guarantee that the hardfork will be successful and not end up with two permanent incompatible forks. This requires broad consensus of the whole community and is not solvable with technical means alone.\n\nThe following types of hardfork are not detectable with this warning system:\n\n\t\u2022 Changing of proof-of-work algorithm\n\t\u2022 Changing the encoding of previous block header hash or nBits\n\t\u2022 A coercive soft-hardfork without setting any hardfork notification bit\n\n\nBackward compatibility\n\nThe softfork described in the BIP would only affect miners. As the disabled nVersion bit is never used in the main network, it is unlikely that any miner would unintentionally find an invalid block due to the new rules.\n\nBIP9 is disabled when any of the hardfork notification bits is set, which may interrupt any ongoing softfork support signalling process. Developers should pay attention to this when desinging a hardfork. For example, they may redefine the counting of signal, or move the signalling bitfield to a different location.\n\nLegacy nodes would not be benefited from this softfork and warning system. However, no additional risks are introduced to legacy node either.\n\n\nReference implementation\n\nTo be done\n\n\nFootnotes\n\n\n\t\u2022 ^ Please note that a hardfork may have lower difficulty but higher total proof-of-work, such as by decreasing the average block interval.\n\t\u2022 ^ In the March 2013 fork, pre-0.8 full nodes would see that as a hardfork with unknown rules, while light nodes and 0.8.0 full nodes would see that as multiple valid blockchains. In the July 2015 fork, BIP66-complying full nodes would see that as a hardfok with unknown rules, while legacy full nodes would see that as multiple valid blockchains.\n\n\nCopyright\n\nThis document is placed in the public domain."
            },
            {
                "author": "Tom Zander",
                "date": "2016-12-01T18:51:56",
                "message_text_only": "I am failing to see how you actually will detect a hard fork with this \nsystem.\n\nMaybe its because of this sentence not being very clear to me;\n \u00abIf a generalized block header chain with non-trivial total proof-of-work\n   is emerging\u00bb\n\nAlso, can you explain what you are actually trying to accomplish?\n\nI want to point out that the following part from your motivation is \nincorrect. A full node would reject a hard forked chain (by definition), \nthere is no risk of them transacting on it.\n\n\u00abWhen such features are implemented with a hardfork, existing full node \nimplementations would consider such blocks as invalid, and may even ban a \npeer for relaying such blocks. They are effectively blind to such hardfork \nrule changes, leaving users to unknowingly transact on a system with \npotentially different token value. \u00bb\n\n\n\nOn Friday, 2 December 2016 01:20:31 CET Johnson Lau via bitcoin-dev wrote:\n> This BIP defines a change in consensus rules regarding to block nVersion,\n> and define a concept of generalized block header to implement a hardfork\n> warning system for full nodes and light nodes.\n> \n> For better formatting, visit github\n> https://github.com/jl2012/bips/blob/hfwarning/bip-hfwarning.mediawiki\n> \n> \n> \n> BIP: ?\n> Title: Hardfork warning system\n> Author: Johnson Lau <jl2012 at xbt.hk>\n> Status: Draft\n> Type: Standard\n> Created: 2016-12-01\n> \n> Abstract\n> \n> This BIP defines a change in consensus rules regarding to block nVersion,\n> and define a concept of generalized block header to implement a hardfork\n> warning system for full nodes and light nodes.\n> \n> Motivation\n> \n> Softfork and hardfork are the 2 majors categories of consensus rules\n> change. Generally, softforks make some previously valid blocks invalid,\n> while hardforks make some previously invalid blocks valid. Bitcoin has\n> successfully introduced a number of new functions through softforks. A\n> built-in warning system is also available in many implementations to warn\n> users for the activation of any unknown softforks.\n> \n> Some features, however, may not be easily introduced with a softfork.\n> Examples include expanding maximum block resources limits, and changing\n> the average block time interval. When such features are implemented with\n> a hardfork, existing full node implementations would consider such blocks\n> as invalid, and may even ban a peer for relaying such blocks. They are\n> effectively blind to such hardfork rule changes, leaving users to\n> unknowingly transact on a system with potentially different token value.\n> On the other hand, light nodes may blindly follow a hardfork with unknown\n> rule changes and lose the right to choose the previous system.\n> \n> This BIP defines a change in consensus rules regarding to block nVersion,\n> and define a concept of generalized block header to implement a hardfork\n> warning system for full nodes and light nodes.\n> \n> Definitions\n> \n> Valid block\n> A block that satisfies all the consensus rules being enforced by a bitcoin\n> protocol implementation. An implementation may intentionally (e.g. a\n> light node) or unintentionally (e.g. unaware of a softfork) not enforcing\n> any part of the current netwrok rules.\n> \n> Valid blockchain\n> A blockchain constituting of only valid blocks.\n> \n> Best valid blockchain\n> The valid blockchain with highest total proof-of-work.\n> \n> Valid blockchain fork\n> A valid blockchain sharing a common ancestral block with the best valid\n> blockchain, but with less total proof-of-work\n> \n> Generalized block header\n> Any serialized hexadecimal data with exactly 80 bytes (byte 0 to byte 79).\n> The bytes 4 to 35 are the double-SHA256 hash of another generalized block\n> header. The bytes 72 to 75 are nBits, the target of this generalized\n> block header encoded in the same way as normal bitcoin block header. The\n> 2 most significant bits of the byte 3 are the hardfork notification bits.\n> The semantics of other data in a generalized block header is not defined\n> in any general way. It should be noted that a normal bitcoin block header\n> is a special case of generalized block header.\n> \n> Generalized block header chain\n> A chain of generalized block header. A header chain of valid blocks is a\n> special case of a generalized block header chain.\n> \n> \n> Specifications\n> \n> \n> Block nVersion softfork\n> \n> A softfork is deployed to restrict the valid value of block nVersion. Upon\n> activation, any block with the second highest nVersion bit set becomes\n> invalid (nVersion & 0x40000000)\n> \n> This softfork will be deployed by \"version bits\" BIP9 with the name\n> \"hfbit\" and using bit 2.\n> \n> For Bitcoin mainnet, the BIP9 starttime will be midnight TBC UTC (Epoch\n> timestamp TBC) and BIP9 timeout will be midnight TBC UTC (Epoch timestamp\n> TBC).\n> \n> For Bitcoin testnet, the BIP9 starttime will be midnight TBC UTC (Epoch\n> timestamp TBC) and BIP9 timeout will be midnight TBC UTC (Epoch timestamp\n> TBC).\n> \n> Any bitcoin implementation (full nodes and light nodes) supporting this\n> softfork should also implement a hardfork warning system described below.\n> \n> \n> Validation of generalized block header\n> \n> A bitcoin protocol implementation should consider a generalized block\n> header as valid if it satisfies all of the following criteria:\n> \n> \t\u2022 It is a descendant of the header of a valid block in a valid \nblockchain\n> (the best valid blockchain or a valid blockchain fork). \u2022 It satisfies\n> the proof-of-work requirement: its double-SHA256 value MUST be smaller\n> than its target (encoded as nBits). \u2022 Its target MUST NOT be greater than\n> the target of its last ancestral valid block by more than 1024 times. An\n> implementation may decide to use a different threshold (or dynamic\n> threshold), depending on its tolerance against potential DoS attacks by\n> generating many low difficulty headers. However, if the value is set too\n> low, a hardfork with lower difficulty may not be detected.[1] In general,\n> a bitcoin protocol implementation should keep an index of all known\n> generalized block header chains, along with the valid blockchain(s).\n> However, if a generalized block header chain is grown on top of a very\n> old valid block, with total proof-of-work much lower than the current\n> best valid bloackchain, it may be safely discarded.\n> \n> \n> Hardfork warning system in full nodes\n> \n> Hardfork with unknown rules\n> If a generalized block header chain with non-trivial total proof-of-work\n> is emerging, and is not considered as a valid blockchain, a hardfork with\n> unknown rules may be happening.\n> \n> A wallet implementation should issue a warning to its users and stop\n> processing incoming and outgoing transactions, until further instructions\n> are given. It should not attempt to conduct transactions on or otherwise\n> interpreting any block data of the hardfork with unknown rules.\n> \n> A mining implementation should issue a warning to its operator. Until\n> further instructions are given, it may either stop mining, or ignore the\n> hardfork with unknown rules. It should not attempt to confirm a\n> generalized block header with unknown rules.\n> \n> Setting of one or both hardfork notification bits is, as defined by BIP34\n> and this BIP, a hardfork, and should be considered as an indication of a\n> planned hardfork. If a hardfork with unknown rules is happening without\n> any hardfork notification bits set, it is probably an accidental\n> consensus failure, such as the March 2013 fork due to a block database\n> bug (BIP50), and the July 2015 fork following the BIP66 activation.[2]\n> \n> \n> Hardfork with multiple valid blockchains\n> If a valid blockchain fork is emerging with non-trivial total\n> proof-of-work, a consensus disagreement may be happening among different\n> miners.\n> \n> A wallet implementation should issue a warning to its users and stop\n> processing incoming and outgoing transactions, until further instructions\n> are given.\n> \n> A mining implementation should issue a warning to its operator. Until\n> further instructions are given, it may either stop mining, or mine on top\n> of the best valid chain by its own standard.\n> \n> Hardfork warning system in light nodes\n> \n> Light node (usually wallet implementations) is any bitcoin protocol\n> implementations that intentionally not fully enforcing the network rules.\n> As an important part of the hardfork warning system, a light node should\n> observe the hardfork notification bits in block header, along with any\n> other rules it opts to validate. If any of the hardfork notification bits\n> is set, it should issue a warning to its users and stop processing\n> incoming and outgoing transactions, until further instructions are given.\n> It should not attempt to conduct transactions on or otherwise\n> interpreting any block data of the hardfork blockchain, even if it might\n> be able to decode the block data.\n> \n> \n> Applications\n> \n> Hardfork notification bits\n> There are 2 hardfork notification bits defined in this BIP. The higher bit\n> has been forbidden since BIP34, and the lower bit is disabled by this\n> BIP. For nodes supporting this BIP, the semantics of the 2 bits are the\n> same: a hardfork is happening. For legacy node, however, setting the\n> higher bit would make them fail to follow the hardforking chain. In a\n> soft-hardfork design (described below), the lower notification bit should\n> be used. The hardfork warning system is able to detect the following\n> types of hardforks:\n> \n> Soft-hardfork (with the lower hardfork notification bit)\n> A soft-hardfork is a technique to implement a hardfork by pretending to\n> create blocks with only a zero output value coinbase transaction, and\n> commit the real transaction Merkle root in the coinbase scriptSig field.\n> With the lower hardfork notification bit set, a node following this BIP\n> will consider this as a hardfork and enter the safe mode, while a legacy\n> node not following this BIP will be effectively broken due to seeing the\n> continuously empty blockchain.\n> \n> Redefining the nTime field\n> As the warning system does not interpret the nTime field, redefining it\n> through a hardfork would be detectable. For example, overflow may be\n> allowed to overcome the year 2106 problem.\n> \n> Redefining the Merkle root hash field and changing block content\n> validation rules The 32-byte Merkle root hash could be redefined, for\n> example, with a different hashing algorithm. Any block resources\n> limitation and transaction validation rules may also be changed. All such\n> hardforks would be detected by the warning system.\n> \n> Changing average block interval or difficulty reset\n> Since the warning system is not bound to a particular proof-of-work target\n> adjustment schedule, a hardfork changing the average block interval or\n> resetting the difficulty will be detectable.\n> \n> Introducing secondary proof-of-work\n> Introducing secondary proof-of-work (with non-SHA256 algorithm or fixing\n> the block withholding attack against mining pools) may be detectable, as\n> long as the generalized block header format is preserved.\n> \n> Accidental hardfork\n> An accidental hardfork may be detectable, if the generalized block headers\n> in both forks are valid but no hardfork notification bit is set.\n> \n> \n> Limitations\n> \n> The only function of this system is to inform the users that a hardfork\n> might be happening and prompt for further instructions. It does not\n> guarantee that the hardfork will be successful and not end up with two\n> permanent incompatible forks. This requires broad consensus of the whole\n> community and is not solvable with technical means alone.\n> \n> The following types of hardfork are not detectable with this warning\n> system:\n> \n> \t\u2022 Changing of proof-of-work algorithm\n> \t\u2022 Changing the encoding of previous block header hash or nBits\n> \t\u2022 A coercive soft-hardfork without setting any hardfork notification bit\n> \n> \n> Backward compatibility\n> \n> The softfork described in the BIP would only affect miners. As the\n> disabled nVersion bit is never used in the main network, it is unlikely\n> that any miner would unintentionally find an invalid block due to the new\n> rules.\n> \n> BIP9 is disabled when any of the hardfork notification bits is set, which\n> may interrupt any ongoing softfork support signalling process. Developers\n> should pay attention to this when desinging a hardfork. For example, they\n> may redefine the counting of signal, or move the signalling bitfield to a\n> different location.\n> \n> Legacy nodes would not be benefited from this softfork and warning system.\n> However, no additional risks are introduced to legacy node either.\n> \n> \n> Reference implementation\n> \n> To be done\n> \n> \n> Footnotes\n> \n> \n> \t\u2022 ^ Please note that a hardfork may have lower difficulty but higher\n> total proof-of-work, such as by decreasing the average block interval. \u2022\n> ^ In the March 2013 fork, pre-0.8 full nodes would see that as a hardfork\n> with unknown rules, while light nodes and 0.8.0 full nodes would see that\n> as multiple valid blockchains. In the July 2015 fork, BIP66-complying\n> full nodes would see that as a hardfok with unknown rules, while legacy\n> full nodes would see that as multiple valid blockchains.\n> \n> \n> Copyright\n> \n> This document is placed in the public domain.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n\n-- \nTom Zander\nBlog: https://zander.github.io\nVlog: https://vimeo.com/channels/tomscryptochannel"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-12-01T20:44:06",
                "message_text_only": "On Thursday, December 01, 2016 5:20:31 PM Johnson Lau via bitcoin-dev wrote:\n> Any bitcoin implementation (full nodes and light nodes) supporting this\n> softfork should also implement a hardfork warning system described below.\n\nI think this \"should\" needs to be a \"must\" be make this useful.\n\n> Hardfork with unknown rules\n> If a generalized block header chain with non-trivial total proof-of-work is\n> emerging, and is not considered as a valid blockchain, a hardfork with\n> unknown rules may be happening.\n> \n> A wallet implementation should issue a warning to its users and stop\n> processing incoming and outgoing transactions, until further instructions\n> are given. It should not attempt to conduct transactions on or otherwise\n> interpreting any block data of the hardfork with unknown rules.\n\nThis seems too unclear. Specifically, if an invalid chain with *equivalent or \nbetter* work than the best valid chain exists, nodes ought to treat all blocks \nfollowing the common chain (between the better-invalid and best-valid chains) \nas suspect.\n\nSo if we have two chains:\n\n    A->B->C->D (valid)\n    A->B->X->Y (invalid)\n\nThe node should consider block B as the tip until the valid chain becomes and \nstays longer than the invalid one.\n\n> A mining implementation should issue a warning to its operator. Until\n> further instructions are given, it may either stop mining, or ignore the\n> hardfork with unknown rules. It should not attempt to confirm a\n> generalized block header with unknown rules.\n\nI think we need to decide more specifically which behaviour is sane here.\n\n> Hardfork warning system in light nodes\n> \n> Light node (usually wallet implementations) is any bitcoin protocol\n> implementations that intentionally not fully enforcing the network rules.\n> As an important part of the hardfork warning system, a light node should\n> observe the hardfork notification bits in block header, along with any\n> other rules it opts to validate. If any of the hardfork notification bits\n> is set, it should issue a warning to its users and stop processing\n> incoming and outgoing transactions, until further instructions are given.\n> It should not attempt to conduct transactions on or otherwise interpreting\n> any block data of the hardfork blockchain, even if it might be able to\n> decode the block data.\n\nLight nodes should probably not be specified here differently than full nodes. \nIf they detect an invalid block through *any* means, they should react the \nsame as a full node would.\n\n> Redefining the Merkle root hash field and changing block content validation\n> rules The 32-byte Merkle root hash could be redefined, for example, with a\n> different hashing algorithm. Any block resources limitation and\n> transaction validation rules may also be changed. All such hardforks would\n> be detected by the warning system.\n\nNote, some changes may be needed to current nodes for this to work. I think at \nthis time this would cause a \"deserialisation\" error, and not accept NOR \nreject the block...\n\n> Introducing secondary proof-of-work\n> Introducing secondary proof-of-work (with non-SHA256 algorithm or fixing\n> the block withholding attack against mining pools) may be detectable, as\n> long as the generalized block header format is preserved.\n\nNot necessarily. A secondary PoW might drastically change the measurement of \nwork. Fixing block withholding may result in block hashes that meet a preimage \nrather than bits directly. I think it may be important to fix the latter \nproblem for this BIP.\n\n> Accidental hardfork\n> An accidental hardfork may be detectable, if the generalized block headers\n> in both forks are valid but no hardfork notification bit is set.\n\nProbably best to not call this a hardfork, since it is a break without \nconsensus.\n\nLuke"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2016-12-02T01:42:46",
                "message_text_only": "We can already warn users of a hardfork when a block is invalid (at\nleast) because of the highest bit in nVersion (as you say, because it\nis forbidden since bip34 was deployed). It seems the softfork serves\nonly to warn about soft-hardforks, assuming it chooses to use this\nmechanism (which a malicious soft hardfork may not do). In fact, you\ncould reuse another of the prohibited bits to signal a soft-hardfork\nwhile distinguishing it from a regular hardfork. And this will also\nserve for old nodes that have not upgraded to the softfork. But, wait,\nif you signal a soft-hardfork with an invalid bit, it's not a\nsoft-hardfork anymore, is it? It's simply a hardfork.\nYour softfork would result in soft hardforks being hardforks for nodes\nthat upgraded to this softfork, but softforks for older nodes.\nIs this the intended behaviour? if so, why?\n\nI would rather have a simpler BIP that doesn't require a softfork\n(whether it recommends soft-hardforks to use one of the currently\ninvalid bits, but a different one than from hardforks or not, but I\nalso don't see the reason why soft-hardforks should appear as invalid\nblocks for older nodes instead of using regular softfork warning\n[besides, in this case, after the \"unkown softfork\" warning you will\nget only empty blocks, which may make you suspicious])."
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-12-02T04:18:21",
                "message_text_only": "On Friday, December 02, 2016 1:42:46 AM Jorge Tim\u00f3n via bitcoin-dev wrote:\n> We can already warn users of a hardfork when a block is invalid (at\n> least) because of the highest bit in nVersion (as you say, because it\n> is forbidden since bip34 was deployed).\n\nThe difference is that right now, full nodes will happily follow a shorter \nbest-valid chain. This BIP would require them to hold back at the best-common \nblock between the best-valid chain and the invalid chain, forcing the user to \nmake a decision whether to reject the invalid chain permanently, or upgrade to \na version which can understand that chain as valid.\n\n> It seems the softfork serves only to warn about soft-hardforks, assuming it\n> chooses to use this mechanism (which a malicious soft hardfork may not do).\n\nNote: a malicious \"SHF\" is not a SHF at all, but an \"evil fork\".\n\n> In fact, you could reuse another of the prohibited bits to signal a soft-\n> hardfork while distinguishing it from a regular hardfork. And this will also\n> serve for old nodes that have not upgraded to the softfork. But, wait,\n> if you signal a soft-hardfork with an invalid bit, it's not a\n> soft-hardfork anymore, is it? It's simply a hardfork.\n\nNodes implementing this BIP will see it as a simple hardfork, but will \nintentionally provide equivalent behaviour as older nodes which see it as a \nsoft-hardfork. In other words, all [compatible] hardforks will now behave like \na soft-hardfork without any special DMMS design.\n\nIf Bitcoin's eventual hardfork is far enough down the road (such that no nodes \nremain from before this BIP are adopted), the SHF design could be safely done \naway with entirely. And either way, it makes it easier to resist an un-\nconsented-to hardfork.\n\nLuke"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2016-12-02T06:35:36",
                "message_text_only": "On Fri, Dec 2, 2016 at 5:18 AM, Luke Dashjr <luke at dashjr.org> wrote:\n> On Friday, December 02, 2016 1:42:46 AM Jorge Tim\u00f3n via bitcoin-dev wrote:\n>> We can already warn users of a hardfork when a block is invalid (at\n>> least) because of the highest bit in nVersion (as you say, because it\n>> is forbidden since bip34 was deployed).\n>\n> The difference is that right now, full nodes will happily follow a shorter\n> best-valid chain. This BIP would require them to hold back at the best-common\n> block between the best-valid chain and the invalid chain, forcing the user to\n> make a decision whether to reject the invalid chain permanently, or upgrade to\n> a version which can understand that chain as valid.\n\nOk, so the goal of the softfork then is to hold on is there is to\n\"hold on\" on the most-work valid chain while there's an even-more-work\ninvalid chain and for new nodes force a response from the user. This\ncould be clearer in the motivation section.\n\nWe can still notify and force a response from the user with a single\ninvalid block (or N, or W accumulated work). Note that we don't need\nto \"hold on\" while waiting for the user's response. Therefore I insist\nthere could be a PIB with all the recommended warnings but not\nsoftfork (which this one could extend from).\n\nThinking as a full node user, I'm not sure I want my node to \"hold on\"\non validating new valid blocks just because there's some \"longest\"\ninvalid chain out there and I may chose to follow that instead later.\nBefore paying or copying another address to receive, I would\ndefinitely would want the warning though.\n\nParticularly as a miner (not that I'm one), I think validationless\nmining shows us that some miners prefer to throw energy to the abyss\nof validation uncertainty rather than stop their mining hardware.\nWhat if when I give the response to the system I decide to pass on the\nHF but it means my hardware have been not mining in the valid chain\nfor hours?\nI would account that as \"money lost thanks to a 'friendly' interface\".\nSpecially if we're talking about a controversial hardfork.\n\nIf we're talking about an uncontroversial hardfork, I would definitely\nprefer BIP9 coordination.\nI would prefer to receive the warning when, say, 30% of the hashrate\nis supporting an unknown change to the consensus rules (regardless of\nit being a softfork or a hardfork, which I don't know yet until the hf\nbit is used because the change is unknown to me), way before I need to\ndecide what branch to mine.\n\nIn fact, if I was a miner but not a user at the same time, after\nknowing about the unknown hardfork and if I consider the hardfork to\nbe potentially controversial, I would try to coordinate with exchanges\n(and pools if no solo mining) to be able to write a program that\nchooses the chain likely to be most profitable depending on difficulty\nand price feeds for every block.\n\nIn the case of a SHF, even more reason to keep mining on the old\nchain, perhaps I mine one empty block (assuming that's a rule in the\nSHF) out of luck, or maybe I should just start mining empty blocks\nwhenever I see the SHF bit active for a block whose chain keeps\ngrowing.\nPerhaps for a SHF we should use a valid bit instead of an invalid one\n(clearing all possible fears with old and older nodes perceiving SHFs\ndifferently as HFs and SFs respectively). We can trivially make old an\nolder nodes coincide in their perception of good-willing SHFs as\neither HFs or SFs as we wish. Choosing divergence of perception from\nthe 2 versions we're considering makes no sense to me.\nI'm reserving my judgement for which one I prefer just in case there's\nactually an advantage in this divergence, but I've missed it.\n\n>> It seems the softfork serves only to warn about soft-hardforks, assuming it\n>> chooses to use this mechanism (which a malicious soft hardfork may not do).\n>\n> Note: a malicious \"SHF\" is not a SHF at all, but an \"evil fork\".\n\nTerminology, I think you get my point. I'm all for formalizing\ndefinitions but please let's not slow down discussion unnecessarily.\nI'm fine saying \"evil fork\" instead of \"malicious SHF\" if you prefer\nthat, but they're just the same thing.\n\n>> In fact, you could reuse another of the prohibited bits to signal a soft-\n>> hardfork while distinguishing it from a regular hardfork. And this will also\n>> serve for old nodes that have not upgraded to the softfork. But, wait,\n>> if you signal a soft-hardfork with an invalid bit, it's not a\n>> soft-hardfork anymore, is it? It's simply a hardfork.\n>\n> Nodes implementing this BIP will see it as a simple hardfork, but will\n> intentionally provide equivalent behaviour as older nodes which see it as a\n> soft-hardfork. In other words, all [compatible] hardforks will now behave like\n> a soft-hardfork without any special DMMS design.\n\nRight, and those same mechanisms could be implemented using one of the\nalready prohibited bits (for example, just like the higher weight bit\nin nHeight, the lowest value one was prohibited when BIP34 was\nactivated).\nThere's no need to invalidate another bit in the softfork (repeat: bit\n1 got invalidated when bip34 was activated as well; or we could just\nuse a valid bit for SHFs).\n\n> If Bitcoin's eventual hardfork is far enough down the road (such that no nodes\n> remain from before this BIP are adopted), the SHF design could be safely done\n> away with entirely. And either way, it makes it easier to resist an un-\n> consented-to hardfork.\n\nRight, I'm also under the assumption that a HF (or a SHF) would give\nplenty of/enough time (to be defined, I suggest at least 1 year but we\nreally shouldn't get into this in this thread) in their\nBIP9Deployment::nStartTime (or equivalent if BIP9 is not reused for\nHF/SHF). Otherwise I would consider any HF or SHF controversial in\nitself regardless of what it does (for not giving enough time to users\nto adapt).\nTherefore we can assume that all the warnings would be deployed in\nadvance to any HF or SHF, with or without a previous softfork.\n\nI strongly disagree that the proposed softfork \"[makes] it easier to\nresist an un-consented-to hardfork\". If anything, it makes it easier\nto disrupt the old network if it doesn't fully consent to the HF. For\n\"un-consented-to SHFs\" (or \"evil HFs\" if you prefer) I don't think\nit's a safe to assume they will use an invalid bit to signal their\nintend. At least if I was an \"evil softhardforker\" just interested in\ndisruption, I wouldn't do it (just like if I was an \"evil hardforker\"\nI wouldn't use the normal hardfork bit)."
            }
        ],
        "thread_summary": {
            "title": "New BIP: Hardfork warning system",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jorge Tim\u00f3n",
                "Luke Dashjr",
                "Tom Zander",
                "Johnson Lau"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 38551
        }
    },
    {
        "title": "[bitcoin-dev] Forcenet: an experimental network with a new header format",
        "thread_messages": [
            {
                "author": "Johnson Lau",
                "date": "2016-12-04T19:34:00",
                "message_text_only": "Based on Luke Dashjr\u2019s code and BIP: https://github.com/luke-jr/bips/blob/bip-mmhf/bip-mmhf.mediawiki , I created an experimental network to show how a new header format may be implemented.\n\nBasically, the header hash is calculated in a way that non-upgrading nodes would see it as a block with only the coinbase tx and zero output value. They are effectively broken as they won\u2019t see any transactions confirmed. This allows rewriting most of the rules related to block and transaction validity. Such technique has different names like soft-hardfork, firmfork, evil softfork, and could be itself a controversial topic. However, I\u2019d rather not to focus on its soft-hardfork property, as that would be trivial to turn this into a true hardfork (e.g. setting the sign bit in block nVersion, or setting the most significant bit in the dummy coinbase nLockTime)\n\nInstead of its soft-HF property, I think the more interesting thing is the new header format. The current bitcoin header has only 80 bytes. It provides only 32bits of nonce space and is far not enough for ASICs. It also provides no room for committing to additional data. Therefore, people are forced to put many different data in the coinbase transaction, such as merge-mining commitments, and the segwit commitment. It is not a ideal solution, especially for light wallets.\n\nFollowing the practice of segwit development of making a experimental network (segnet), I made something similar and call it the Forcenet (as it forces legacy nodes to follow the post-fork chain)\n\nThe header of forcenet is mostly described in Luke\u2019s BIP, but I have made some amendments as I implemented it. The format is (size in parentheses; little endian):\n\nHeight (4), BIP9 signalling field (4), hardfork signalling field (3), merge-mining hard fork signalling field (1), prev hash (32), timestamp (4), nonce1 (4), nonce2 (4), nonce3 (compactSize + variable), Hash TMR (32), Hash WMR (32), total tx size (8) , total tx weight (8), total sigops (8), number of tx (4), merkle branches leading to header C (compactSize + 32 bit hashes)\n\nIn addition to increasing the max block size, I also showed how the calculation and validation of witness commitment may be changed with a new header. For example, since the commitment is no longer in the coinbase tx, we don\u2019t need to use a 0000\u2026.0000 hash for the coinbase tx like in BIP141.\n\nSomething not yet done:\n1. The new merkle root algorithm described in the MMHF BIP\n2. The nTxsSigops has no meaning currently\n3. Communication with legacy nodes. This version can\u2019t talk to legacy nodes through the P2P network, but theoretically they could be linked up with a bridge node\n4. A new block weight definition to provide incentives for slowing down UTXO growth\n5. Many other interesting hardfork ideas, and softfork ideas that works better with a header redesign\n\nFor easier testing, forcenet has the following parameters:\n\nHardfork at block 200\nSegwit is always activated\n1 minutes block with 40000 (prefork) and 80000 (postfork) weight limit\n50 blocks coinbase maturity\n21000 blocks halving\n144 blocks retarget\n\nHow to join: codes at https://github.com/jl2012/bitcoin/tree/forcenet1 , start with \"bitcoind \u2014forcenet\" .\nConnection: I\u2019m running a node at 8333.info with default port (38901)\nMining: there is only basic internal mining support. Limited GBT support is theoretically possible but needs more hacking. To use the internal miner, writeup a shell script to repeatedly call \u201cbitcoin-cli \u2014forcenet generate 1\u201d\nNew RPC commands: getlegacyblock and getlegacyblockheader, which generates blocks and headers that are compatible with legacy nodes.\n\nThis is largely work-in-progress so expect a reset every couple weeks\n\njl2012\n\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 671 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161205/126aae21/attachment.sig>"
            },
            {
                "author": "adiabat",
                "date": "2016-12-04T20:00:00",
                "message_text_only": "Interesting stuff! I have some comments, mostly about the header.\n\nThe header of forcenet is mostly described in Luke\u2019s BIP, but I have made\n> some amendments as I implemented it. The format is (size in parentheses;\n> little endian):\n>\n> Height (4), BIP9 signalling field (4), hardfork signalling field (3),\n> merge-mining hard fork signalling field (1), prev hash (32), timestamp (4),\n> nonce1 (4), nonce2 (4), nonce3 (compactSize + variable), Hash TMR (32),\n> Hash WMR (32), total tx size (8) , total tx weight (8), total sigops (8),\n> number of tx (4), merkle branches leading to header C (compactSize + 32 bit\n> hashes)\n>\n\nFirst, I'd really rather not have variable length fields in the header.\nIt's so much nicer to just have a fixed size.\n\nIs having both TMR and WMR really needed?  As segwit would be required with\nthis header type, and the WMR covers a superset of the data that the TMR\ndoes, couldn't you get rid of the TMR?  The only disadvantage I can see is\nthat light clients may want a merkle proof of a transaction without having\nto download the witnesses for that transaction.  This seems pretty minor,\nespecially as once they're convinced of block inclusion they can discard\nthe witness data, and also the tradeoff is that light clients will have to\ndownload and store and extra 32 bytes per block, likely offsetting any\nsavings from omitting witness data.\n\nThe other question is that there's a bit that's redundant: height is also\ncommitted to in the coinbase tx via bip 34 (speaking of which, if there's a\nhard-fork, how about reverting bip 34 and committing to the height with\ncoinbase tx nlocktime instead?)\n\nTotal size / weight / number of txs also feels pretty redundant.  Not a lot\nof space but it's hard to come up with a use for them.  Number of tx could\nbe useful if you want to send all the leaves of a merkle tree, but you\ncould also do that by committing to the depth of the merkle tree in the\nheader, which is 1 byte.\n\nAlso how about making timestamp 8 bytes?  2106 is coming up soon :)\n\nMaybe this is too nit-picky; maybe it's better to put lots of stuff in for\ntesting the forcenet and then take out all the stuff that wasn't used or\nhad issues as it progresses.\n\nThanks and looking forward to trying out forcenet!\n\n-Tadge\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161204/43fe8311/attachment.html>"
            },
            {
                "author": "Hampus Sj\u00f6berg",
                "date": "2016-12-04T20:37:39",
                "message_text_only": "> Also how about making timestamp 8 bytes?  2106 is coming up soon :)\n\nAFAICT this was fixed in this commit:\nhttps://github.com/jl2012/bitcoin/commit/fa80b48bb4237b110ceffe11edc14c8130672cd2#diff-499d7ee7998a27095063ed7b4dd7c119R200\n\n\n2016-12-04 21:00 GMT+01:00 adiabat via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org>:\n\n> Interesting stuff! I have some comments, mostly about the header.\n>\n> The header of forcenet is mostly described in Luke\u2019s BIP, but I have made\n>> some amendments as I implemented it. The format is (size in parentheses;\n>> little endian):\n>>\n>> Height (4), BIP9 signalling field (4), hardfork signalling field (3),\n>> merge-mining hard fork signalling field (1), prev hash (32), timestamp (4),\n>> nonce1 (4), nonce2 (4), nonce3 (compactSize + variable), Hash TMR (32),\n>> Hash WMR (32), total tx size (8) , total tx weight (8), total sigops (8),\n>> number of tx (4), merkle branches leading to header C (compactSize + 32 bit\n>> hashes)\n>>\n>\n> First, I'd really rather not have variable length fields in the header.\n> It's so much nicer to just have a fixed size.\n>\n> Is having both TMR and WMR really needed?  As segwit would be required\n> with this header type, and the WMR covers a superset of the data that the\n> TMR does, couldn't you get rid of the TMR?  The only disadvantage I can see\n> is that light clients may want a merkle proof of a transaction without\n> having to download the witnesses for that transaction.  This seems pretty\n> minor, especially as once they're convinced of block inclusion they can\n> discard the witness data, and also the tradeoff is that light clients will\n> have to download and store and extra 32 bytes per block, likely offsetting\n> any savings from omitting witness data.\n>\n> The other question is that there's a bit that's redundant: height is also\n> committed to in the coinbase tx via bip 34 (speaking of which, if there's a\n> hard-fork, how about reverting bip 34 and committing to the height with\n> coinbase tx nlocktime instead?)\n>\n> Total size / weight / number of txs also feels pretty redundant.  Not a\n> lot of space but it's hard to come up with a use for them.  Number of tx\n> could be useful if you want to send all the leaves of a merkle tree, but\n> you could also do that by committing to the depth of the merkle tree in the\n> header, which is 1 byte.\n>\n> Also how about making timestamp 8 bytes?  2106 is coming up soon :)\n>\n> Maybe this is too nit-picky; maybe it's better to put lots of stuff in for\n> testing the forcenet and then take out all the stuff that wasn't used or\n> had issues as it progresses.\n>\n> Thanks and looking forward to trying out forcenet!\n>\n> -Tadge\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161204/77223c7c/attachment.html>"
            },
            {
                "author": "Tom Zander",
                "date": "2016-12-05T11:58:54",
                "message_text_only": "On Sunday, 4 December 2016 21:37:39 CET Hampus Sj\u00f6berg via bitcoin-dev \nwrote:\n> > Also how about making timestamp 8 bytes?  2106 is coming up soon \n> \n> AFAICT this was fixed in this commit:\n> https://github.com/jl2012/bitcoin/commit/\nfa80b48bb4237b110ceffe11edc14c813\n> 0672cd2#diff-499d7ee7998a27095063ed7b4dd7c119R200\n\nThat commit hacks around it, a new block header fixes it. Subtle difference.\n\n-- \nTom Zander\nBlog: https://zander.github.io\nVlog: https://vimeo.com/channels/tomscryptochannel"
            },
            {
                "author": "Johnson Lau",
                "date": "2016-12-14T11:01:58",
                "message_text_only": "There is no reason to use a timestamp beyond 4 bytes. Just let it overflow. If a blockchain is stopped for more than 2^31 seconds, it\u2019s just dead.\n\n> On 5 Dec 2016, at 19:58, Tom Zander via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> On Sunday, 4 December 2016 21:37:39 CET Hampus Sj\u00f6berg via bitcoin-dev \n> wrote:\n>>> Also how about making timestamp 8 bytes?  2106 is coming up soon \n>> \n>> AFAICT this was fixed in this commit:\n>> https://github.com/jl2012/bitcoin/commit/\n> fa80b48bb4237b110ceffe11edc14c813\n>> 0672cd2#diff-499d7ee7998a27095063ed7b4dd7c119R200\n> \n> That commit hacks around it, a new block header fixes it. Subtle difference.\n> \n> -- \n> Tom Zander\n> Blog: https://zander.github.io\n> Vlog: https://vimeo.com/channels/tomscryptochannel\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-12-14T11:07:14",
                "message_text_only": "On Wednesday, December 14, 2016 11:01:58 AM Johnson Lau via bitcoin-dev wrote:\n> There is no reason to use a timestamp beyond 4 bytes.\n\nActually, there is: lock times... my overflow solution doesn't have a solution \nto that. :x"
            },
            {
                "author": "Johnson Lau",
                "date": "2016-12-14T11:12:45",
                "message_text_only": "> On 14 Dec 2016, at 19:07, Luke Dashjr <luke at dashjr.org> wrote:\n> \n> On Wednesday, December 14, 2016 11:01:58 AM Johnson Lau via bitcoin-dev wrote:\n>> There is no reason to use a timestamp beyond 4 bytes.\n> \n> Actually, there is: lock times... my overflow solution doesn't have a solution \n> to that. :x\n\n\nYou could steal a few bits form tx nVersion through a softfork"
            },
            {
                "author": "Johnson Lau",
                "date": "2016-12-14T11:11:29",
                "message_text_only": "> On 5 Dec 2016, at 04:00, adiabat <rx at awsomnet.org> wrote:\n> \n> Interesting stuff! I have some comments, mostly about the header.\n> \n> The header of forcenet is mostly described in Luke\u2019s BIP, but I have made some amendments as I implemented it. The format is (size in parentheses; little endian):\n> \n> Height (4), BIP9 signalling field (4), hardfork signalling field (3), merge-mining hard fork signalling field (1), prev hash (32), timestamp (4), nonce1 (4), nonce2 (4), nonce3 (compactSize + variable), Hash TMR (32), Hash WMR (32), total tx size (8) , total tx weight (8), total sigops (8), number of tx (4), merkle branches leading to header C (compactSize + 32 bit hashes)\n> \n> First, I'd really rather not have variable length fields in the header.  It's so much nicer to just have a fixed size.\n> \n> Is having both TMR and WMR really needed?  As segwit would be required with this header type, and the WMR covers a superset of the data that the TMR does, couldn't you get rid of the TMR?  The only disadvantage I can see is that light clients may want a merkle proof of a transaction without having to download the witnesses for that transaction.  This seems pretty minor, especially as once they're convinced of block inclusion they can discard the witness data, and also the tradeoff is that light clients will have to download and store and extra 32 bytes per block, likely offsetting any savings from omitting witness data.\n> \n\nI foresee there will be 2 types of headers under this system: the 80 bytes short header and the variable length full header. Short headers are enough to link everything up. SPV needs the full header only if they are interested in any tx in a block. \n\n> The other question is that there's a bit that's redundant: height is also committed to in the coinbase tx via bip 34 (speaking of which, if there's a hard-fork, how about reverting bip 34 and committing to the height with coinbase tx nlocktime instead?)\n\nyou could omit the transmission of nHeight, as it is implied (saving 4bytes). Storing nHeight of headers is what every full and SPV nodes would do anyway\n\n\n> \n> Total size / weight / number of txs also feels pretty redundant.  Not a lot of space but it's hard to come up with a use for them.  Number of tx could be useful if you want to send all the leaves of a merkle tree, but you could also do that by committing to the depth of the merkle tree in the header, which is 1 byte.\n\nYes, I agree with you that these are not particularly useful. Sum tree is more useful but it has other problems (see my other reply)\n\nRelated discussion: https://github.com/jl2012/bitcoin/commit/69e613bfb0f777c8dcd2576fe1c2541ee7a17208 <https://github.com/jl2012/bitcoin/commit/69e613bfb0f777c8dcd2576fe1c2541ee7a17208>\n> \n> Also how about making timestamp 8 bytes?  2106 is coming up soon :)\n\nNo need. See my other reply\n\n> \n> Maybe this is too nit-picky; maybe it's better to put lots of stuff in for testing the forcenet and then take out all the stuff that wasn't used or had issues as it progresses.\n> \n> Thanks and looking forward to trying out forcenet!\n> \n> -Tadge\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161214/fcada227/attachment-0001.html>"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-12-10T21:29:09",
                "message_text_only": "On Sun, Dec 4, 2016 at 7:34 PM, Johnson Lau via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Something not yet done:\n> 1. The new merkle root algorithm described in the MMHF BIP\n>\n\nAny new merkle algorithm should use a sum tree for partial validation and\nfraud proofs.\n\nIs there something special about 216 bits?  I guess at most 448 bits total\nmeans only one round of SHA256.  16 bits for flags would give 216 for each\nchild.\n\nEven better would be to make the protocol extendable.  Allow blocks to\nindicate new trees and legacy nodes would just ignore the extra ones.  If\nBitcoin supported that then the segregated witness tree could have been\nadded as a easier soft fork.\n\nThe sum-tree could be added later as an extra tree.\n\n\n> 3. Communication with legacy nodes. This version can\u2019t talk to legacy\n> nodes through the P2P network, but theoretically they could be linked up\n> with a bridge node\n>\n\nThe bridge would only need to transfer the legacy blocks which are coinbase\nonly, so very little data.\n\n\n> 5. Many other interesting hardfork ideas, and softfork ideas that works\n> better with a header redesign\n>\n\nThat is very true.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161210/f53e0cac/attachment.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-12-10T21:41:57",
                "message_text_only": "On Saturday, December 10, 2016 9:29:09 PM Tier Nolan via bitcoin-dev wrote:\n> On Sun, Dec 4, 2016 at 7:34 PM, Johnson Lau via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > Something not yet done:\n> > 1. The new merkle root algorithm described in the MMHF BIP\n> \n> Any new merkle algorithm should use a sum tree for partial validation and\n> fraud proofs.\n\nPR welcome.\n\n> Is there something special about 216 bits?  I guess at most 448 bits total\n> means only one round of SHA256.  16 bits for flags would give 216 for each\n> child.\n\nSee https://github.com/luke-jr/bips/blob/bip-mmhf/bip-mmhf.mediawiki#Merkle_tree_algorithm\n\nBut yes, the 448 bits total target is to optimise the tree-building.\n\n> Even better would be to make the protocol extendable.  Allow blocks to\n> indicate new trees and legacy nodes would just ignore the extra ones.  If\n> Bitcoin supported that then the segregated witness tree could have been\n> added as a easier soft fork.\n\nIt already is. This is a primary goal of the new protocol.\n\n> The sum-tree could be added later as an extra tree.\n\nAdding new trees means more hashing to validate blocks, so it'd be better to \nkeep it at a minimum.\n\nLuke"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-12-11T16:40:30",
                "message_text_only": "On Sat, Dec 10, 2016 at 9:41 PM, Luke Dashjr <luke at dashjr.org> wrote:\n\n> On Saturday, December 10, 2016 9:29:09 PM Tier Nolan via bitcoin-dev wrote:\n> > Any new merkle algorithm should use a sum tree for partial validation and\n> > fraud proofs.\n>\n> PR welcome.\n>\n\nFair enough.  It is pretty basic.\n\nhttps://github.com/luke-jr/bips/pull/2\n\nIt sums up sigops, block size, block cost (that is \"weight\" right?) and\nfees.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161211/0455d03e/attachment.html>"
            },
            {
                "author": "Johnson Lau",
                "date": "2016-12-14T10:55:39",
                "message_text_only": "I think the biggest problem of sum tree is the lack of flexibility to redefine the values with softforks. For example, in the future we may want to define a new CHECKSIG with witness script version 1. That would be counted as a SigOp. Without a sum tree design, that\u2019d be easy as we could just define new SigOp through a softfork (e.g. the introduction of P2SH SigOp, and the witness v0 SigOp). In a sum tree, however, since the nSigOp is implied, any redefinition requires either a hardfork or a new sum tree (and the original sum tree becomes a placebo for old nodes. So every softfork of this type creates a new tree)\n\nSimilarly, we may have secondary witness in the future, and the tx weight would be redefined with a softfork. We will face the same problem with a sum tree\n\nThe only way to fix this is to explicitly commit to the weight and nSigOp, and the committed value must be equal to or larger than the real value. Only in this way we could redefine it with softfork. However, that means each tx will have an overhead of 16 bytes (if two int64 are used)\n\nYou could find related discussion here: https://github.com/jl2012/bitcoin/commit/69e613bfb0f777c8dcd2576fe1c2541ee7a17208 <https://github.com/jl2012/bitcoin/commit/69e613bfb0f777c8dcd2576fe1c2541ee7a17208>\n\nMaybe we could make this optional: for nodes running exactly the same rules, they could omit the weight and nSigOp value in transmission. To talk to legacy nodes, they need to transmit the newly defined weight and nSigOp. But this makes script upgrade much complex.\n\n\n> On 12 Dec 2016, at 00:40, Tier Nolan via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> \n> On Sat, Dec 10, 2016 at 9:41 PM, Luke Dashjr <luke at dashjr.org <mailto:luke at dashjr.org>> wrote:\n> On Saturday, December 10, 2016 9:29:09 PM Tier Nolan via bitcoin-dev wrote:\n> > Any new merkle algorithm should use a sum tree for partial validation and\n> > fraud proofs.\n> \n> PR welcome.\n> \n> Fair enough.  It is pretty basic.\n> \n> https://github.com/luke-jr/bips/pull/2 <https://github.com/luke-jr/bips/pull/2>\n> \n> It sums up sigops, block size, block cost (that is \"weight\" right?) and fees.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161214/3efb104f/attachment.html>"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-12-14T12:52:14",
                "message_text_only": "On Wed, Dec 14, 2016 at 10:55 AM, Johnson Lau <jl2012 at xbt.hk> wrote:\n\n> In a sum tree, however, since the nSigOp is implied, any redefinition\n> requires either a hardfork or a new sum tree (and the original sum tree\n> becomes a placebo for old nodes. So every softfork of this type creates a\n> new tree)\n>\n\nThat's a good point.\n\n\n> The only way to fix this is to explicitly commit to the weight and nSigOp,\n> and the committed value must be equal to or larger than the real value.\n> Only in this way we could redefine it with softfork. However, that means\n> each tx will have an overhead of 16 bytes (if two int64 are used)\n>\n\nThe weight and sigop count could be transmitted as variable length\nintegers.  That would be around 2 bytes for the sigops and 3 bytes for the\nweight, per transaction.\n\nIt would mean that the block format would have to include the raw\ntransaction, \"extra\"/tree information and witness data for each transaction.\n\nOn an unrelated note, the two costs could be combined into a unified cost.\nFor example, a sigop could have equal cost to 250 bytes.  This would make\nit easier for miners to decide what to charge.\n\nOn the other hand, CPU cost and storage/network costs are not completely\ninterchangeable.\n\nIs there anything that would need to be summed fees, raw tx size, weight\nand sigops that the greater or equal rule wouldn't cover?\n\nOn 12 Dec 2016, at 00:40, Tier Nolan via bitcoin-dev <bitcoin-dev at lists.\nlinuxfoundation.org> wrote:\n\n\nOn Sat, Dec 10, 2016 at 9:41 PM, Luke Dashjr <luke at dashjr.org> wrote:\n\n> On Saturday, December 10, 2016 9:29:09 PM Tier Nolan via bitcoin-dev wrote:\n> > Any new merkle algorithm should use a sum tree for partial validation and\n> > fraud proofs.\n>\n> PR welcome.\n>\n\nFair enough.  It is pretty basic.\n\nhttps://github.com/luke-jr/bips/pull/2\n\nIt sums up sigops, block size, block cost (that is \"weight\" right?) and\nfees.\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161214/42189554/attachment.html>"
            },
            {
                "author": "Johnson Lau",
                "date": "2016-12-14T15:45:37",
                "message_text_only": "I think that\u2019s too much tech debt just for softforkability.\n\nThe better way would be making the sum tree as an independent tree with a separate commitment, and define a special type of softfork (e.g. a special BIP9 bit). When the softfork is activated, the legacy full node will stop validating the sum tree. This doesn\u2019t really degrade the security by more than a normal softfork, as the legacy full node would still validate the total weight and nSigOp based on its own rules. The only purpose of the sum tree is to help SPV nodes to validate. This way we could even completely redefine the structure and data committed in the sum tree.\n\nI\u2019d like to combine the size weight and sigOp weight, but not sure if we could. The current size weight limit is 4,000,000 and sigop limit is 80,000. It\u2019s 50:1. If we maintain this ratio, and define\nweight = n * (total size +  3 * base size) + sigop , with n = 50\na block may have millions of sigops which is totally unacceptable.\n\nOn the other hand, if we make n too low, we may allow either too few sigop, or a too big block size.\n\nSignature aggregation will make this a bigger problem as one signature may spend thousands of sigop\n\n\n\n> On 14 Dec 2016, at 20:52, Tier Nolan <tier.nolan at gmail.com> wrote:\n> \n> \n> \n> On Wed, Dec 14, 2016 at 10:55 AM, Johnson Lau <jl2012 at xbt.hk <mailto:jl2012 at xbt.hk>> wrote:\n> In a sum tree, however, since the nSigOp is implied, any redefinition requires either a hardfork or a new sum tree (and the original sum tree becomes a placebo for old nodes. So every softfork of this type creates a new tree)\n> \n> That's a good point.\n>  \n> The only way to fix this is to explicitly commit to the weight and nSigOp, and the committed value must be equal to or larger than the real value. Only in this way we could redefine it with softfork. However, that means each tx will have an overhead of 16 bytes (if two int64 are used)\n> \n> The weight and sigop count could be transmitted as variable length integers.  That would be around 2 bytes for the sigops and 3 bytes for the weight, per transaction.\n> \n> It would mean that the block format would have to include the raw transaction, \"extra\"/tree information and witness data for each transaction.\n> \n> On an unrelated note, the two costs could be combined into a unified cost.  For example, a sigop could have equal cost to 250 bytes.  This would make it easier for miners to decide what to charge.\n> \n> On the other hand, CPU cost and storage/network costs are not completely interchangeable.\n> \n> Is there anything that would need to be summed fees, raw tx size, weight and sigops that the greater or equal rule wouldn't cover?\n> \n> On 12 Dec 2016, at 00:40, Tier Nolan via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>> \n>> On Sat, Dec 10, 2016 at 9:41 PM, Luke Dashjr <luke at dashjr.org <mailto:luke at dashjr.org>> wrote:\n>> On Saturday, December 10, 2016 9:29:09 PM Tier Nolan via bitcoin-dev wrote:\n>> > Any new merkle algorithm should use a sum tree for partial validation and\n>> > fraud proofs.\n>> \n>> PR welcome.\n>> \n>> Fair enough.  It is pretty basic.\n>> \n>> https://github.com/luke-jr/bips/pull/2 <https://github.com/luke-jr/bips/pull/2>\n>> \n>> It sums up sigops, block size, block cost (that is \"weight\" right?) and fees.\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n> \n> \n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161214/14889378/attachment.html>"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-12-14T16:26:58",
                "message_text_only": "On Wed, Dec 14, 2016 at 3:45 PM, Johnson Lau <jl2012 at xbt.hk> wrote:\n\n> I think that\u2019s too much tech debt just for softforkability.\n>\n> The better way would be making the sum tree as an independent tree with a\n> separate commitment, and define a special type of softfork (e.g. a special\n> BIP9 bit).\n>\n\nOne of the problems with fraud proofs is withholding by miners.  It is\nimportant that proof of publication/archive nodes check that the miners are\nactually publishing their blocks.\n\nIf you place the data in another tree, then care needs to be taken that the\nmerkle path information can be obtained for that tree.\n\nIf an SPV node asks for a run of transactions from an archive node, then\nthe archive node can give the merkle branch for all of those transactions.\nThe archive node inherently has to check that tree.\n\nThe question is if there is a way to show that data is not available, but\nwithout opening up the network to DOS.  If enough people run full nodes\nthen this isn't a problem.\n\n>\n> When the softfork is activated, the legacy full node will stop validating\n> the sum tree. This doesn\u2019t really degrade the security by more than a\n> normal softfork, as the legacy full node would still validate the total\n> weight and nSigOp based on its own rules. The only purpose of the sum tree\n> is to help SPV nodes to validate. This way we could even completely\n> redefine the structure and data committed in the sum tree.\n>\n\nSeems reasonable.  I think the soft-fork would have to have a timeout\nbefore actually activating.  That would give SPV clients time to switch\nover.\n\nThat could happen before the vote though, so it isn't essential.  The SPV\nclients would have to support both trees and then switch mode.  Ensuring\nthat SPV nodes actually bother would be helped by proving that the network\nactually intends to soft fork.\n\nThe SPV client just has to check that every block has at least one of the\ncommitments that it accepts so that it can understand fraud proofs.\n\n\n>\n> I\u2019d like to combine the size weight and sigOp weight, but not sure if we\n> could. The current size weight limit is 4,000,000 and sigop limit is\n> 80,000. It\u2019s 50:1. If we maintain this ratio, and define\n> weight = n * (total size +  3 * base size) + sigop , with n = 50\n> a block may have millions of sigops which is totally unacceptable.\n>\n\nYou multiplied by the wrong term.\n\nweight = total size +  3 * base size + n * sigop , with n = 50\n\nweight for max block = 8,000,000\n\nThat gives a maximum of 8,000,000 / 50 = 160,000 sigops.\n\nTo get that you would need zero transaction length.  You could get close if\nyou have transactions that just repeat OP_CHECKSIG over and over (or maybe\nsomething with OP_CHECKMULTISIG).\n\n\n>\n> On the other hand, if we make n too low, we may allow either too few\n> sigop, or a too big block size.\n>\n> Signature aggregation will make this a bigger problem as one signature may\n> spend thousands of sigop\n>\n>\n>\n> On 14 Dec 2016, at 20:52, Tier Nolan <tier.nolan at gmail.com> wrote:\n>\n>\n>\n> On Wed, Dec 14, 2016 at 10:55 AM, Johnson Lau <jl2012 at xbt.hk> wrote:\n>\n>> In a sum tree, however, since the nSigOp is implied, any redefinition\n>> requires either a hardfork or a new sum tree (and the original sum tree\n>> becomes a placebo for old nodes. So every softfork of this type creates a\n>> new tree)\n>>\n>\n> That's a good point.\n>\n>\n>> The only way to fix this is to explicitly commit to the weight and\n>> nSigOp, and the committed value must be equal to or larger than the real\n>> value. Only in this way we could redefine it with softfork. However, that\n>> means each tx will have an overhead of 16 bytes (if two int64 are used)\n>>\n>\n> The weight and sigop count could be transmitted as variable length\n> integers.  That would be around 2 bytes for the sigops and 3 bytes for the\n> weight, per transaction.\n>\n> It would mean that the block format would have to include the raw\n> transaction, \"extra\"/tree information and witness data for each transaction.\n>\n> On an unrelated note, the two costs could be combined into a unified\n> cost.  For example, a sigop could have equal cost to 250 bytes.  This would\n> make it easier for miners to decide what to charge.\n>\n> On the other hand, CPU cost and storage/network costs are not completely\n> interchangeable.\n>\n> Is there anything that would need to be summed fees, raw tx size, weight\n> and sigops that the greater or equal rule wouldn't cover?\n>\n> On 12 Dec 2016, at 00:40, Tier Nolan via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>\n> On Sat, Dec 10, 2016 at 9:41 PM, Luke Dashjr <luke at dashjr.org> wrote:\n>\n>> On Saturday, December 10, 2016 9:29:09 PM Tier Nolan via bitcoin-dev\n>> wrote:\n>> > Any new merkle algorithm should use a sum tree for partial validation\n>> and\n>> > fraud proofs.\n>>\n>> PR welcome.\n>>\n>\n> Fair enough.  It is pretty basic.\n>\n> https://github.com/luke-jr/bips/pull/2\n>\n> It sums up sigops, block size, block cost (that is \"weight\" right?) and\n> fees.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161214/9774c7f0/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Forcenet: an experimental network with a new header format",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "adiabat",
                "Hampus Sj\u00f6berg",
                "Tom Zander",
                "Johnson Lau",
                "Tier Nolan",
                "Luke Dashjr"
            ],
            "messages_count": 15,
            "total_messages_chars_count": 32003
        }
    },
    {
        "title": "[bitcoin-dev] Managing block size the same way we do difficulty (aka Block75)",
        "thread_messages": [
            {
                "author": "t. khan",
                "date": "2016-12-05T15:27:32",
                "message_text_only": "BIP Proposal - Managing Bitcoin\u2019s block size the same way we do difficulty\n(aka Block75)\n\nThe every two-week adjustment of difficulty has proven to be a reasonably\neffective and predictable way of managing how quickly blocks are mined.\nBitcoin needs a reasonably effective and predictable way of managing the\nmaximum block size.\n\nIt\u2019s clear at this point that human beings should not be involved in the\ndetermination of max block size, just as they\u2019re not involved in deciding\nthe difficulty.\n\nInstead of setting an arbitrary max block size (1MB, 2MB, 8MB, etc.) or\npassing the decision to miners/pool operators, the max block size should be\nadjusted every two weeks (2016 blocks) using a system similar to how\ndifficulty is calculated.\n\nPut another way: let\u2019s stop thinking about what the max block size should\nbe and start thinking about how full we want the average block to be\nregardless of size. Over the last year, we\u2019ve had averages of 75% or\nhigher, so aiming for 75% full seems reasonable, hence naming this concept\n\u2018Block75\u2019.\n\nThe target capacity over 2016 blocks would be 75%. If the last 2016 blocks\nare more than 75% full, add the difference to the max block size. Like this:\n\nMAX_BLOCK_BASE_SIZE = 1000000\nTARGET_CAPACITY = 750000\nAVERAGE_OVER_CAP = average block size of last 2016 blocks minus\nTARGET_CAPACITY\n\nTo check if a block is valid, \u2264 (MAX_BLOCK_BASE_SIZE + AVERAGE_OVER_CAP)\n\nFor example, if the last 2016 blocks are 85% full (average block is 850\nKB), add 10% to the max block size. The new max block size would be 1,100\nKB until the next 2016 blocks are mined, then reset and recalculate. The\n1,000,000 byte limit that exists currently would remain, but would\neffectively be the minimum max block size.\n\nAnother two weeks goes by, the last 2016 blocks are again 85% full, but now\nthat means they average 935 KB out of the 1,100 KB max block size. This is\n93.5% of the 1,000,000 byte limit, so 18.5% would be added to that to make\nthe new max block size of 1,185 KB.\n\nAnother two weeks passes. This time, the average block is 1,050 KB. The new\nmax block size is calculated to 1,300 KB (as blocks were 105% full, minus\nthe 75% capacity target, so 30% added to max block size).\n\nRepeat every 2016 blocks, forever.\n\nIf Block75 had been applied at the difficulty adjustment on November 18th,\nthe max block size would have been 1,080KB, as the average block during\nthat period was 83% full, so 8% is added to the 1,000KB limit. The current\nsize, after the December 2nd adjustment would be 1,150K.\n\nBlock75 would allow the max block size to grow (or shrink) in response to\ntransaction volume, and does so predictably, reasonably quickly, and in a\nmethod that prevents wild swings in block size or transaction fees. It\nattempts to keep blocks at 75% total capacity over each two week period,\nthe same way difficulty tries to keep blocks mined every ten minutes. It\nalso keeps blocks as small as possible.\n\nThoughts?\n\n-t.k.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161205/c24d6c6d/attachment.html>"
            },
            {
                "author": "s7r",
                "date": "2016-12-10T10:44:31",
                "message_text_only": "t. khan via bitcoin-dev wrote:\n> BIP Proposal - Managing Bitcoin\u2019s block size the same way we do\n> difficulty (aka Block75)\n> \n> The every two-week adjustment of difficulty has proven to be a\n> reasonably effective and predictable way of managing how quickly blocks\n> are mined. Bitcoin needs a reasonably effective and predictable way of\n> managing the maximum block size.\n> \n> It\u2019s clear at this point that human beings should not be involved in the\n> determination of max block size, just as they\u2019re not involved in\n> deciding the difficulty.\n> \n> Instead of setting an arbitrary max block size (1MB, 2MB, 8MB, etc.) or\n> passing the decision to miners/pool operators, the max block size should\n> be adjusted every two weeks (2016 blocks) using a system similar to how\n> difficulty is calculated.\n> \n> Put another way: let\u2019s stop thinking about what the max block size\n> should be and start thinking about how full we want the average block to\n> be regardless of size. Over the last year, we\u2019ve had averages of 75% or\n> higher, so aiming for 75% full seems reasonable, hence naming this\n> concept \u2018Block75\u2019.\n> \n> The target capacity over 2016 blocks would be 75%. If the last 2016\n> blocks are more than 75% full, add the difference to the max block size.\n> Like this:\n> \n> MAX_BLOCK_BASE_SIZE = 1000000\n> TARGET_CAPACITY = 750000\n> AVERAGE_OVER_CAP = average block size of last 2016 blocks minus\n> TARGET_CAPACITY\n> \n> To check if a block is valid, \u2264 (MAX_BLOCK_BASE_SIZE + AVERAGE_OVER_CAP)\n> \n> For example, if the last 2016 blocks are 85% full (average block is 850\n> KB), add 10% to the max block size. The new max block size would be\n> 1,100 KB until the next 2016 blocks are mined, then reset and\n> recalculate. The 1,000,000 byte limit that exists currently would\n> remain, but would effectively be the minimum max block size. \n> \n> Another two weeks goes by, the last 2016 blocks are again 85% full, but\n> now that means they average 935 KB out of the 1,100 KB max block size.\n> This is 93.5% of the 1,000,000 byte limit, so 18.5% would be added to\n> that to make the new max block size of 1,185 KB.\n> \n> Another two weeks passes. This time, the average block is 1,050 KB. The\n> new max block size is calculated to 1,300 KB (as blocks were 105% full,\n> minus the 75% capacity target, so 30% added to max block size).\n> \n> Repeat every 2016 blocks, forever.\n> \n> If Block75 had been applied at the difficulty adjustment on November\n> 18th, the max block size would have been 1,080KB, as the average block\n> during that period was 83% full, so 8% is added to the 1,000KB limit.\n> The current size, after the December 2nd adjustment would be 1,150K.\n> \n> Block75 would allow the max block size to grow (or shrink) in response\n> to transaction volume, and does so predictably, reasonably quickly, and\n> in a method that prevents wild swings in block size or transaction fees.\n> It attempts to keep blocks at 75% total capacity over each two week\n> period, the same way difficulty tries to keep blocks mined every ten\n> minutes. It also keeps blocks as small as possible.\n> \n> Thoughts?\n> \n> -t.k.\n> \n\nI like the idea. It is good wrt growing the max. block size\nautomatically without human action, but the main problem (or question)\nis not how to grow this number, it is what number can the network\nhandle, considering both miners and users. While disk space requirements\nmight not be a big problem, block propagation time is. The time required\nfor a block to propagate in the network (or at least to all the miners)\nis directly dependent of its size.  If blocks take too much time to\npropagate in the network, the orphan rate will increase in unpredictable\nways. For example if the internet speed in China is worse than in\nEurope, and miners in China have more than 50% of the hashing power,\nblocks mined by European miners might get orphaned.\n\nThe system as described can also be gamed, by filling the network with\ntransactions. Miners have the monetary interest to include as many\ntransactions as possible in a block in order to collect the fees.\nRegardless how you think about it, there has to be a maximum block size\nthat the network will allow as a consensus rule. Increasing it\ndynamically based on transaction volume will reach a point where the\nnumber got big enough that it broke things. Bitcoin, because its\nfundamental design, can scale by using offchain solutions.\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 488 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161210/c231038d/attachment.sig>"
            },
            {
                "author": "Hampus Sj\u00f6berg",
                "date": "2016-12-10T12:05:22",
                "message_text_only": "> While disk space requirements might not be a big problem, block\npropagation time is\n\nIs block propagation time really still a problem? Compact blocks and FIBRE\nshould help here.\n\n> Bitcoin, because its fundamental design, can scale by using offchain\nsolutions.\n\nI agree.\nHowever, I believe that on-chain scaling will be needed regardless of which\noff-chain solution gains popularity.\n\n2016-12-10 11:44 GMT+01:00 s7r via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org>:\n\n> t. khan via bitcoin-dev wrote:\n> > BIP Proposal - Managing Bitcoin\u2019s block size the same way we do\n> > difficulty (aka Block75)\n> >\n> > The every two-week adjustment of difficulty has proven to be a\n> > reasonably effective and predictable way of managing how quickly blocks\n> > are mined. Bitcoin needs a reasonably effective and predictable way of\n> > managing the maximum block size.\n> >\n> > It\u2019s clear at this point that human beings should not be involved in the\n> > determination of max block size, just as they\u2019re not involved in\n> > deciding the difficulty.\n> >\n> > Instead of setting an arbitrary max block size (1MB, 2MB, 8MB, etc.) or\n> > passing the decision to miners/pool operators, the max block size should\n> > be adjusted every two weeks (2016 blocks) using a system similar to how\n> > difficulty is calculated.\n> >\n> > Put another way: let\u2019s stop thinking about what the max block size\n> > should be and start thinking about how full we want the average block to\n> > be regardless of size. Over the last year, we\u2019ve had averages of 75% or\n> > higher, so aiming for 75% full seems reasonable, hence naming this\n> > concept \u2018Block75\u2019.\n> >\n> > The target capacity over 2016 blocks would be 75%. If the last 2016\n> > blocks are more than 75% full, add the difference to the max block size.\n> > Like this:\n> >\n> > MAX_BLOCK_BASE_SIZE = 1000000\n> > TARGET_CAPACITY = 750000\n> > AVERAGE_OVER_CAP = average block size of last 2016 blocks minus\n> > TARGET_CAPACITY\n> >\n> > To check if a block is valid, \u2264 (MAX_BLOCK_BASE_SIZE + AVERAGE_OVER_CAP)\n> >\n> > For example, if the last 2016 blocks are 85% full (average block is 850\n> > KB), add 10% to the max block size. The new max block size would be\n> > 1,100 KB until the next 2016 blocks are mined, then reset and\n> > recalculate. The 1,000,000 byte limit that exists currently would\n> > remain, but would effectively be the minimum max block size.\n> >\n> > Another two weeks goes by, the last 2016 blocks are again 85% full, but\n> > now that means they average 935 KB out of the 1,100 KB max block size.\n> > This is 93.5% of the 1,000,000 byte limit, so 18.5% would be added to\n> > that to make the new max block size of 1,185 KB.\n> >\n> > Another two weeks passes. This time, the average block is 1,050 KB. The\n> > new max block size is calculated to 1,300 KB (as blocks were 105% full,\n> > minus the 75% capacity target, so 30% added to max block size).\n> >\n> > Repeat every 2016 blocks, forever.\n> >\n> > If Block75 had been applied at the difficulty adjustment on November\n> > 18th, the max block size would have been 1,080KB, as the average block\n> > during that period was 83% full, so 8% is added to the 1,000KB limit.\n> > The current size, after the December 2nd adjustment would be 1,150K.\n> >\n> > Block75 would allow the max block size to grow (or shrink) in response\n> > to transaction volume, and does so predictably, reasonably quickly, and\n> > in a method that prevents wild swings in block size or transaction fees.\n> > It attempts to keep blocks at 75% total capacity over each two week\n> > period, the same way difficulty tries to keep blocks mined every ten\n> > minutes. It also keeps blocks as small as possible.\n> >\n> > Thoughts?\n> >\n> > -t.k.\n> >\n>\n> I like the idea. It is good wrt growing the max. block size\n> automatically without human action, but the main problem (or question)\n> is not how to grow this number, it is what number can the network\n> handle, considering both miners and users. While disk space requirements\n> might not be a big problem, block propagation time is. The time required\n> for a block to propagate in the network (or at least to all the miners)\n> is directly dependent of its size.  If blocks take too much time to\n> propagate in the network, the orphan rate will increase in unpredictable\n> ways. For example if the internet speed in China is worse than in\n> Europe, and miners in China have more than 50% of the hashing power,\n> blocks mined by European miners might get orphaned.\n>\n> The system as described can also be gamed, by filling the network with\n> transactions. Miners have the monetary interest to include as many\n> transactions as possible in a block in order to collect the fees.\n> Regardless how you think about it, there has to be a maximum block size\n> that the network will allow as a consensus rule. Increasing it\n> dynamically based on transaction volume will reach a point where the\n> number got big enough that it broke things. Bitcoin, because its\n> fundamental design, can scale by using offchain solutions.\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161210/0eae6a60/attachment.html>"
            },
            {
                "author": "t. khan",
                "date": "2016-12-11T00:26:01",
                "message_text_only": "Miners 'gaming' the Block75 system -\nThere is no financial incentive for miners to attempt to game the Block75\nsystem. Even if it were attempted and assuming the goal was to create\nbigger blocks, the maximum possible increase would be 25% over the previous\nblock size. And, that size would only last for two weeks before readjusting\ndown. It would cost them more in transaction fees to stuff the network than\nthey could ever make up. To game the system, they'd have to game it forever\nwith no possibility of profit.\n\nBlocks would get too big -\nEventually, blocks would get too big, but only if bandwidth stopped\nincreasing and the cost of disk space stopped decreasing. Otherwise, the\nincremental adjustments made by Block75 (especially in combination with\nSegWit) wouldn't break anyone's connection or result in significantly more\norphaned blocks.\n\nThe frequent and small adjustments made by Block75 have the added benefit\nof being more easily adapted to, both psychologically and technologically,\nwith regards to miners/node operators.\n\n-t.k\n\nOn Sat, Dec 10, 2016 at 5:44 AM, s7r via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> t. khan via bitcoin-dev wrote:\n> > BIP Proposal - Managing Bitcoin\u2019s block size the same way we do\n> > difficulty (aka Block75)\n> >\n> > The every two-week adjustment of difficulty has proven to be a\n> > reasonably effective and predictable way of managing how quickly blocks\n> > are mined. Bitcoin needs a reasonably effective and predictable way of\n> > managing the maximum block size.\n> >\n> > It\u2019s clear at this point that human beings should not be involved in the\n> > determination of max block size, just as they\u2019re not involved in\n> > deciding the difficulty.\n> >\n> > Instead of setting an arbitrary max block size (1MB, 2MB, 8MB, etc.) or\n> > passing the decision to miners/pool operators, the max block size should\n> > be adjusted every two weeks (2016 blocks) using a system similar to how\n> > difficulty is calculated.\n> >\n> > Put another way: let\u2019s stop thinking about what the max block size\n> > should be and start thinking about how full we want the average block to\n> > be regardless of size. Over the last year, we\u2019ve had averages of 75% or\n> > higher, so aiming for 75% full seems reasonable, hence naming this\n> > concept \u2018Block75\u2019.\n> >\n> > The target capacity over 2016 blocks would be 75%. If the last 2016\n> > blocks are more than 75% full, add the difference to the max block size.\n> > Like this:\n> >\n> > MAX_BLOCK_BASE_SIZE = 1000000\n> > TARGET_CAPACITY = 750000\n> > AVERAGE_OVER_CAP = average block size of last 2016 blocks minus\n> > TARGET_CAPACITY\n> >\n> > To check if a block is valid, \u2264 (MAX_BLOCK_BASE_SIZE + AVERAGE_OVER_CAP)\n> >\n> > For example, if the last 2016 blocks are 85% full (average block is 850\n> > KB), add 10% to the max block size. The new max block size would be\n> > 1,100 KB until the next 2016 blocks are mined, then reset and\n> > recalculate. The 1,000,000 byte limit that exists currently would\n> > remain, but would effectively be the minimum max block size.\n> >\n> > Another two weeks goes by, the last 2016 blocks are again 85% full, but\n> > now that means they average 935 KB out of the 1,100 KB max block size.\n> > This is 93.5% of the 1,000,000 byte limit, so 18.5% would be added to\n> > that to make the new max block size of 1,185 KB.\n> >\n> > Another two weeks passes. This time, the average block is 1,050 KB. The\n> > new max block size is calculated to 1,300 KB (as blocks were 105% full,\n> > minus the 75% capacity target, so 30% added to max block size).\n> >\n> > Repeat every 2016 blocks, forever.\n> >\n> > If Block75 had been applied at the difficulty adjustment on November\n> > 18th, the max block size would have been 1,080KB, as the average block\n> > during that period was 83% full, so 8% is added to the 1,000KB limit.\n> > The current size, after the December 2nd adjustment would be 1,150K.\n> >\n> > Block75 would allow the max block size to grow (or shrink) in response\n> > to transaction volume, and does so predictably, reasonably quickly, and\n> > in a method that prevents wild swings in block size or transaction fees.\n> > It attempts to keep blocks at 75% total capacity over each two week\n> > period, the same way difficulty tries to keep blocks mined every ten\n> > minutes. It also keeps blocks as small as possible.\n> >\n> > Thoughts?\n> >\n> > -t.k.\n> >\n>\n> I like the idea. It is good wrt growing the max. block size\n> automatically without human action, but the main problem (or question)\n> is not how to grow this number, it is what number can the network\n> handle, considering both miners and users. While disk space requirements\n> might not be a big problem, block propagation time is. The time required\n> for a block to propagate in the network (or at least to all the miners)\n> is directly dependent of its size.  If blocks take too much time to\n> propagate in the network, the orphan rate will increase in unpredictable\n> ways. For example if the internet speed in China is worse than in\n> Europe, and miners in China have more than 50% of the hashing power,\n> blocks mined by European miners might get orphaned.\n>\n> The system as described can also be gamed, by filling the network with\n> transactions. Miners have the monetary interest to include as many\n> transactions as possible in a block in order to collect the fees.\n> Regardless how you think about it, there has to be a maximum block size\n> that the network will allow as a consensus rule. Increasing it\n> dynamically based on transaction volume will reach a point where the\n> number got big enough that it broke things. Bitcoin, because its\n> fundamental design, can scale by using offchain solutions.\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161210/e1899177/attachment-0001.html>"
            },
            {
                "author": "James Hilliard",
                "date": "2016-12-11T00:40:25",
                "message_text_only": "Miners in general are naturally incentivized to always mine max size\nblocks to maximize transaction fees simply because there is very\nlittle marginal cost to including extra transactions(there will always\nbe a transaction backlog of some sort available to mine since demand\nfor block space is effectively unbounded as fees approach 0 and they\ncan even mine their own transactions without any fees). This proposal\nwould almost certainly cause runaway block size growth and encourage\nmuch more miner centralization.\n\nOn Sat, Dec 10, 2016 at 6:26 PM, t. khan via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Miners 'gaming' the Block75 system -\n> There is no financial incentive for miners to attempt to game the Block75\n> system. Even if it were attempted and assuming the goal was to create bigger\n> blocks, the maximum possible increase would be 25% over the previous block\n> size. And, that size would only last for two weeks before readjusting down.\n> It would cost them more in transaction fees to stuff the network than they\n> could ever make up. To game the system, they'd have to game it forever with\n> no possibility of profit.\n>\n> Blocks would get too big -\n> Eventually, blocks would get too big, but only if bandwidth stopped\n> increasing and the cost of disk space stopped decreasing. Otherwise, the\n> incremental adjustments made by Block75 (especially in combination with\n> SegWit) wouldn't break anyone's connection or result in significantly more\n> orphaned blocks.\n>\n> The frequent and small adjustments made by Block75 have the added benefit of\n> being more easily adapted to, both psychologically and technologically, with\n> regards to miners/node operators.\n>\n> -t.k\n>\n> On Sat, Dec 10, 2016 at 5:44 AM, s7r via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> t. khan via bitcoin-dev wrote:\n>> > BIP Proposal - Managing Bitcoin\u2019s block size the same way we do\n>> > difficulty (aka Block75)\n>> >\n>> > The every two-week adjustment of difficulty has proven to be a\n>> > reasonably effective and predictable way of managing how quickly blocks\n>> > are mined. Bitcoin needs a reasonably effective and predictable way of\n>> > managing the maximum block size.\n>> >\n>> > It\u2019s clear at this point that human beings should not be involved in the\n>> > determination of max block size, just as they\u2019re not involved in\n>> > deciding the difficulty.\n>> >\n>> > Instead of setting an arbitrary max block size (1MB, 2MB, 8MB, etc.) or\n>> > passing the decision to miners/pool operators, the max block size should\n>> > be adjusted every two weeks (2016 blocks) using a system similar to how\n>> > difficulty is calculated.\n>> >\n>> > Put another way: let\u2019s stop thinking about what the max block size\n>> > should be and start thinking about how full we want the average block to\n>> > be regardless of size. Over the last year, we\u2019ve had averages of 75% or\n>> > higher, so aiming for 75% full seems reasonable, hence naming this\n>> > concept \u2018Block75\u2019.\n>> >\n>> > The target capacity over 2016 blocks would be 75%. If the last 2016\n>> > blocks are more than 75% full, add the difference to the max block size.\n>> > Like this:\n>> >\n>> > MAX_BLOCK_BASE_SIZE = 1000000\n>> > TARGET_CAPACITY = 750000\n>> > AVERAGE_OVER_CAP = average block size of last 2016 blocks minus\n>> > TARGET_CAPACITY\n>> >\n>> > To check if a block is valid, \u2264 (MAX_BLOCK_BASE_SIZE + AVERAGE_OVER_CAP)\n>> >\n>> > For example, if the last 2016 blocks are 85% full (average block is 850\n>> > KB), add 10% to the max block size. The new max block size would be\n>> > 1,100 KB until the next 2016 blocks are mined, then reset and\n>> > recalculate. The 1,000,000 byte limit that exists currently would\n>> > remain, but would effectively be the minimum max block size.\n>> >\n>> > Another two weeks goes by, the last 2016 blocks are again 85% full, but\n>> > now that means they average 935 KB out of the 1,100 KB max block size.\n>> > This is 93.5% of the 1,000,000 byte limit, so 18.5% would be added to\n>> > that to make the new max block size of 1,185 KB.\n>> >\n>> > Another two weeks passes. This time, the average block is 1,050 KB. The\n>> > new max block size is calculated to 1,300 KB (as blocks were 105% full,\n>> > minus the 75% capacity target, so 30% added to max block size).\n>> >\n>> > Repeat every 2016 blocks, forever.\n>> >\n>> > If Block75 had been applied at the difficulty adjustment on November\n>> > 18th, the max block size would have been 1,080KB, as the average block\n>> > during that period was 83% full, so 8% is added to the 1,000KB limit.\n>> > The current size, after the December 2nd adjustment would be 1,150K.\n>> >\n>> > Block75 would allow the max block size to grow (or shrink) in response\n>> > to transaction volume, and does so predictably, reasonably quickly, and\n>> > in a method that prevents wild swings in block size or transaction fees.\n>> > It attempts to keep blocks at 75% total capacity over each two week\n>> > period, the same way difficulty tries to keep blocks mined every ten\n>> > minutes. It also keeps blocks as small as possible.\n>> >\n>> > Thoughts?\n>> >\n>> > -t.k.\n>> >\n>>\n>> I like the idea. It is good wrt growing the max. block size\n>> automatically without human action, but the main problem (or question)\n>> is not how to grow this number, it is what number can the network\n>> handle, considering both miners and users. While disk space requirements\n>> might not be a big problem, block propagation time is. The time required\n>> for a block to propagate in the network (or at least to all the miners)\n>> is directly dependent of its size.  If blocks take too much time to\n>> propagate in the network, the orphan rate will increase in unpredictable\n>> ways. For example if the internet speed in China is worse than in\n>> Europe, and miners in China have more than 50% of the hashing power,\n>> blocks mined by European miners might get orphaned.\n>>\n>> The system as described can also be gamed, by filling the network with\n>> transactions. Miners have the monetary interest to include as many\n>> transactions as possible in a block in order to collect the fees.\n>> Regardless how you think about it, there has to be a maximum block size\n>> that the network will allow as a consensus rule. Increasing it\n>> dynamically based on transaction volume will reach a point where the\n>> number got big enough that it broke things. Bitcoin, because its\n>> fundamental design, can scale by using offchain solutions.\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Bram Cohen",
                "date": "2016-12-11T01:07:06",
                "message_text_only": "Miners individually have an incentive to include every transaction they can\nwhen they mine a block, but they also sometimes have an incentive to\ncollectively cooperate to reduce throughput to make more money as a group.\nUnder schemes where limits can be adjusted both possibilities must be taken\ninto account.\n\nOn Sat, Dec 10, 2016 at 4:40 PM, James Hilliard via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Miners in general are naturally incentivized to always mine max size\n> blocks to maximize transaction fees simply because there is very\n> little marginal cost to including extra transactions(there will always\n> be a transaction backlog of some sort available to mine since demand\n> for block space is effectively unbounded as fees approach 0 and they\n> can even mine their own transactions without any fees). This proposal\n> would almost certainly cause runaway block size growth and encourage\n> much more miner centralization.\n>\n> On Sat, Dec 10, 2016 at 6:26 PM, t. khan via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > Miners 'gaming' the Block75 system -\n> > There is no financial incentive for miners to attempt to game the Block75\n> > system. Even if it were attempted and assuming the goal was to create\n> bigger\n> > blocks, the maximum possible increase would be 25% over the previous\n> block\n> > size. And, that size would only last for two weeks before readjusting\n> down.\n> > It would cost them more in transaction fees to stuff the network than\n> they\n> > could ever make up. To game the system, they'd have to game it forever\n> with\n> > no possibility of profit.\n> >\n> > Blocks would get too big -\n> > Eventually, blocks would get too big, but only if bandwidth stopped\n> > increasing and the cost of disk space stopped decreasing. Otherwise, the\n> > incremental adjustments made by Block75 (especially in combination with\n> > SegWit) wouldn't break anyone's connection or result in significantly\n> more\n> > orphaned blocks.\n> >\n> > The frequent and small adjustments made by Block75 have the added\n> benefit of\n> > being more easily adapted to, both psychologically and technologically,\n> with\n> > regards to miners/node operators.\n> >\n> > -t.k\n> >\n> > On Sat, Dec 10, 2016 at 5:44 AM, s7r via bitcoin-dev\n> > <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>\n> >> t. khan via bitcoin-dev wrote:\n> >> > BIP Proposal - Managing Bitcoin\u2019s block size the same way we do\n> >> > difficulty (aka Block75)\n> >> >\n> >> > The every two-week adjustment of difficulty has proven to be a\n> >> > reasonably effective and predictable way of managing how quickly\n> blocks\n> >> > are mined. Bitcoin needs a reasonably effective and predictable way of\n> >> > managing the maximum block size.\n> >> >\n> >> > It\u2019s clear at this point that human beings should not be involved in\n> the\n> >> > determination of max block size, just as they\u2019re not involved in\n> >> > deciding the difficulty.\n> >> >\n> >> > Instead of setting an arbitrary max block size (1MB, 2MB, 8MB, etc.)\n> or\n> >> > passing the decision to miners/pool operators, the max block size\n> should\n> >> > be adjusted every two weeks (2016 blocks) using a system similar to\n> how\n> >> > difficulty is calculated.\n> >> >\n> >> > Put another way: let\u2019s stop thinking about what the max block size\n> >> > should be and start thinking about how full we want the average block\n> to\n> >> > be regardless of size. Over the last year, we\u2019ve had averages of 75%\n> or\n> >> > higher, so aiming for 75% full seems reasonable, hence naming this\n> >> > concept \u2018Block75\u2019.\n> >> >\n> >> > The target capacity over 2016 blocks would be 75%. If the last 2016\n> >> > blocks are more than 75% full, add the difference to the max block\n> size.\n> >> > Like this:\n> >> >\n> >> > MAX_BLOCK_BASE_SIZE = 1000000\n> >> > TARGET_CAPACITY = 750000\n> >> > AVERAGE_OVER_CAP = average block size of last 2016 blocks minus\n> >> > TARGET_CAPACITY\n> >> >\n> >> > To check if a block is valid, \u2264 (MAX_BLOCK_BASE_SIZE +\n> AVERAGE_OVER_CAP)\n> >> >\n> >> > For example, if the last 2016 blocks are 85% full (average block is\n> 850\n> >> > KB), add 10% to the max block size. The new max block size would be\n> >> > 1,100 KB until the next 2016 blocks are mined, then reset and\n> >> > recalculate. The 1,000,000 byte limit that exists currently would\n> >> > remain, but would effectively be the minimum max block size.\n> >> >\n> >> > Another two weeks goes by, the last 2016 blocks are again 85% full,\n> but\n> >> > now that means they average 935 KB out of the 1,100 KB max block size.\n> >> > This is 93.5% of the 1,000,000 byte limit, so 18.5% would be added to\n> >> > that to make the new max block size of 1,185 KB.\n> >> >\n> >> > Another two weeks passes. This time, the average block is 1,050 KB.\n> The\n> >> > new max block size is calculated to 1,300 KB (as blocks were 105%\n> full,\n> >> > minus the 75% capacity target, so 30% added to max block size).\n> >> >\n> >> > Repeat every 2016 blocks, forever.\n> >> >\n> >> > If Block75 had been applied at the difficulty adjustment on November\n> >> > 18th, the max block size would have been 1,080KB, as the average block\n> >> > during that period was 83% full, so 8% is added to the 1,000KB limit.\n> >> > The current size, after the December 2nd adjustment would be 1,150K.\n> >> >\n> >> > Block75 would allow the max block size to grow (or shrink) in response\n> >> > to transaction volume, and does so predictably, reasonably quickly,\n> and\n> >> > in a method that prevents wild swings in block size or transaction\n> fees.\n> >> > It attempts to keep blocks at 75% total capacity over each two week\n> >> > period, the same way difficulty tries to keep blocks mined every ten\n> >> > minutes. It also keeps blocks as small as possible.\n> >> >\n> >> > Thoughts?\n> >> >\n> >> > -t.k.\n> >> >\n> >>\n> >> I like the idea. It is good wrt growing the max. block size\n> >> automatically without human action, but the main problem (or question)\n> >> is not how to grow this number, it is what number can the network\n> >> handle, considering both miners and users. While disk space requirements\n> >> might not be a big problem, block propagation time is. The time required\n> >> for a block to propagate in the network (or at least to all the miners)\n> >> is directly dependent of its size.  If blocks take too much time to\n> >> propagate in the network, the orphan rate will increase in unpredictable\n> >> ways. For example if the internet speed in China is worse than in\n> >> Europe, and miners in China have more than 50% of the hashing power,\n> >> blocks mined by European miners might get orphaned.\n> >>\n> >> The system as described can also be gamed, by filling the network with\n> >> transactions. Miners have the monetary interest to include as many\n> >> transactions as possible in a block in order to collect the fees.\n> >> Regardless how you think about it, there has to be a maximum block size\n> >> that the network will allow as a consensus rule. Increasing it\n> >> dynamically based on transaction volume will reach a point where the\n> >> number got big enough that it broke things. Bitcoin, because its\n> >> fundamental design, can scale by using offchain solutions.\n> >>\n> >>\n> >> _______________________________________________\n> >> bitcoin-dev mailing list\n> >> bitcoin-dev at lists.linuxfoundation.org\n> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >>\n> >\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161210/d2b72e8b/attachment-0001.html>"
            },
            {
                "author": "s7r",
                "date": "2016-12-11T17:11:10",
                "message_text_only": "t. khan wrote:\n> Miners 'gaming' the Block75 system - \n> There is no financial incentive for miners to attempt to game the\n> Block75 system. Even if it were attempted and assuming the goal was to\n> create bigger blocks, the maximum possible increase would be 25% over\n> the previous block size. And, that size would only last for two weeks\n> before readjusting down. It would cost them more in transaction fees to\n> stuff the network than they could ever make up. To game the system,\n> they'd have to game it forever with no possibility of profit.\n> \n\nThis is an incentive, if few miners agree to create a large conglomerate\nthat will ultimately control the network.\n\nYou miss something obvious that makes this attack actually free of cost.\nNothing will \"cost them more in transaction fees\". A miner can create\nthousands of transactions paying to himself, and not broadcast them to\nthe network, but hold them and include them in the blocks he mines. The\nfees are collected by him because transactions are included in a block\nthat he mined and the left amount is in another wallet of the same\nperson. Repeat this continuously to fill blocks.\n\n\n> Blocks would get too big - \n> Eventually, blocks would get too big, but only if bandwidth stopped\n> increasing and the cost of disk space stopped decreasing. Otherwise, the\n> incremental adjustments made by Block75 (especially in combination with\n> SegWit) wouldn't break anyone's connection or result in significantly\n> more orphaned blocks.\n> \n\nTopology and bandwidth speed / hash rate of the network cannot be\ncontrolled - if we make assumptions about these it might have terrible\nconsequences.\n\nEven if we take in consideration that bandwidth will only grow and disk\nspace will only cost less (which is not something we can safely assume,\nby the way) the hard limit max. block size cannot grow to unlimited\nvalue (even if the growth happens over time). There is also a validation\ncost in time for each block, for the health of the network any node\nshould be able to download _and_ validate a block, before next block\ngets mined.\n\nYou said in another post that a permanent solution is preferred, rather\nthan kicking the can down the road. I fully agree, as well as many\nothers reading this list, but the permanent solution doesn't necessarily\nhave to be increasing the max block size dynamically.\n\nIf you think about it the other way around, dynamically growing the max\nblock size is also kicking the can down the road ... just without having\nto touch it and get dust on the boot ;)\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 488 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161211/6af3a1eb/attachment-0001.sig>"
            },
            {
                "author": "t. khan",
                "date": "2016-12-11T19:55:34",
                "message_text_only": "On Sun, Dec 11, 2016 at 12:11 PM, s7r <s7r at sky-ip.org> wrote:\n\n>\n> This is an incentive, if few miners agree to create a large conglomerate\n> that will ultimately control the network.\n>\n> You miss something obvious that makes this attack actually free of cost.\n> Nothing will \"cost them more in transaction fees\". A miner can create\n> thousands of transactions paying to himself, and not broadcast them to\n> the network, but hold them and include them in the blocks he mines. The\n> fees are collected by him because transactions are included in a block\n> that he mined and the left amount is in another wallet of the same\n> person. Repeat this continuously to fill blocks.\n>\n\nNo, that wasn't overlooked. Miners could indeed stuff their own blocks for\nfree, but they can't stuff blocks mined by others for free.\n\nIn the hypothetical scenario where there is a single mining pool which\nmines most (if not all) of the blocks, we would have much larger problems\nthan their ability to raise the max block size gradually. Even if they were\nable to fill 100% of the blocks for an entire year, the max block size for\nthat 2016 block period would be 7.25MB (not accounting for SegWit). After\nthe whole year they would have made no extra profit vs doing nothing. And\nas soon as they stopped this scheme, block size would spring back to it's\nnatural level.\n\nThe good news is, this scenario has never happened and even when we've come\nremotely close (when ASICs first shipped), the situation was temporary. The\nodds of this happening in the future and persisting long enough to have any\nmajor effect with Block75 are very close to zero.\n\n\n> Topology and bandwidth speed / hash rate of the network cannot be\n> controlled - if we make assumptions about these it might have terrible\n> consequences.\n>\n> Even if we take in consideration that bandwidth will only grow and disk\n> space will only cost less (which is not something we can safely assume,\n> by the way) the hard limit max. block size cannot grow to unlimited\n> value (even if the growth happens over time). There is also a validation\n> cost in time for each block, for the health of the network any node\n> should be able to download _and_ validate a block, before next block\n> gets mined.\n>\n> You said in another post that a permanent solution is preferred, rather\n> than kicking the can down the road. I fully agree, as well as many\n> others reading this list, but the permanent solution doesn't necessarily\n> have to be increasing the max block size dynamically.\n>\n\nIncreasing *and* decreasing max block size dynamically. Block75 is\nself-correcting, whereas any solution with hardcoded limits can't correct\nwithout human intervention and would rely on our ability to predict the\nfuture (which as you pointed out, we can't do). Therefore, any solution\nthat's not dynamic cannot be permanent.\n\nAdditionally, the frequent and gradual changes in max block size would\nallow us to see any consequences well in advance (years probably).\n\n\n> If you think about it the other way around, dynamically growing the max\n> block size is also kicking the can down the road ... just without having\n> to touch it and get dust on the boot ;)\n\n\nNot having to touch it again = permanent solution. ;)\n\nIt would be helpful if some others would run the numbers on how Block75\nwould adjust the block size over time:\n\nnew max block size = 1000kb + (average block size over last 2016 blocks -\n750kb)\n\n-t.k.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161211/cb598cfa/attachment.html>"
            },
            {
                "author": "James Hilliard",
                "date": "2016-12-11T20:31:05",
                "message_text_only": "What's most likely to happen is miners will max out the blocks they\nmine simply to try and get as many transaction fees as possible like\nthey are doing right now(there will be a backlog of transactions at\nany block size). Having the block size double every year would likely\ncause major problems and this proposal allows over a 7x increase it\nseems.\n\nThe main problem with this proposal I think is that users effectively\nhave no way to stop the miners from increasing block size\ncontinuously.\n\nOn Sun, Dec 11, 2016 at 1:55 PM, t. khan via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> On Sun, Dec 11, 2016 at 12:11 PM, s7r <s7r at sky-ip.org> wrote:\n>>\n>>\n>> This is an incentive, if few miners agree to create a large conglomerate\n>> that will ultimately control the network.\n>>\n>> You miss something obvious that makes this attack actually free of cost.\n>> Nothing will \"cost them more in transaction fees\". A miner can create\n>> thousands of transactions paying to himself, and not broadcast them to\n>> the network, but hold them and include them in the blocks he mines. The\n>> fees are collected by him because transactions are included in a block\n>> that he mined and the left amount is in another wallet of the same\n>> person. Repeat this continuously to fill blocks.\n>\n>\n> No, that wasn't overlooked. Miners could indeed stuff their own blocks for\n> free, but they can't stuff blocks mined by others for free.\n>\n> In the hypothetical scenario where there is a single mining pool which mines\n> most (if not all) of the blocks, we would have much larger problems than\n> their ability to raise the max block size gradually. Even if they were able\n> to fill 100% of the blocks for an entire year, the max block size for that\n> 2016 block period would be 7.25MB (not accounting for SegWit). After the\n> whole year they would have made no extra profit vs doing nothing. And as\n> soon as they stopped this scheme, block size would spring back to it's\n> natural level.\n>\n> The good news is, this scenario has never happened and even when we've come\n> remotely close (when ASICs first shipped), the situation was temporary. The\n> odds of this happening in the future and persisting long enough to have any\n> major effect with Block75 are very close to zero.\n>\n>>\n>> Topology and bandwidth speed / hash rate of the network cannot be\n>> controlled - if we make assumptions about these it might have terrible\n>> consequences.\n>>\n>> Even if we take in consideration that bandwidth will only grow and disk\n>> space will only cost less (which is not something we can safely assume,\n>> by the way) the hard limit max. block size cannot grow to unlimited\n>> value (even if the growth happens over time). There is also a validation\n>> cost in time for each block, for the health of the network any node\n>> should be able to download _and_ validate a block, before next block\n>> gets mined.\n>>\n>> You said in another post that a permanent solution is preferred, rather\n>> than kicking the can down the road. I fully agree, as well as many\n>> others reading this list, but the permanent solution doesn't necessarily\n>> have to be increasing the max block size dynamically.\n>\n>\n> Increasing *and* decreasing max block size dynamically. Block75 is\n> self-correcting, whereas any solution with hardcoded limits can't correct\n> without human intervention and would rely on our ability to predict the\n> future (which as you pointed out, we can't do). Therefore, any solution\n> that's not dynamic cannot be permanent.\n>\n> Additionally, the frequent and gradual changes in max block size would allow\n> us to see any consequences well in advance (years probably).\n>\n>>\n>> If you think about it the other way around, dynamically growing the max\n>> block size is also kicking the can down the road ... just without having\n>> to touch it and get dust on the boot ;)\n>\n>\n> Not having to touch it again = permanent solution. ;)\n>\n> It would be helpful if some others would run the numbers on how Block75\n> would adjust the block size over time:\n>\n> new max block size = 1000kb + (average block size over last 2016 blocks -\n> 750kb)\n>\n> -t.k.\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "t. khan",
                "date": "2016-12-11T21:40:21",
                "message_text_only": "On Sun, Dec 11, 2016 at 3:31 PM, James Hilliard <james.hilliard1 at gmail.com>\nwrote:\n\n> What's most likely to happen is miners will max out the blocks they\n> mine simply to try and get as many transaction fees as possible like\n> they are doing right now(there will be a backlog of transactions at\n> any block size). Having the block size double every year would likely\n> cause major problems and this proposal allows over a 7x increase it\n> seems.\n\n\nBlock75 is not exponential scaling. It's true the max theoretical increase\nin the first year would be 7x, but the next year would be a max of 2x, and\nthe next could only increase by 50% and so on.\n\nHowever, to reach the max in the first year: 1) ALL blocks would have to be\n100% full and 2) transactions would have to increase at the same rate. We'd\nhave to be doing 2.1 million transactions a day within a year to make that\nhappen, and would therefore need blocks to be that big.\n\nRealistically, max block size will grow (and shrink) at a much slower rate\n... even more so with SegWit.\n\n\n>  The main problem with this proposal I think is that users effectively\n\nhave no way to stop the miners from increasing block size\n> continuously.\n\n\nYes they could, simply by not sending transactions. Users don't care at all\nabout block size. They just want their transactions to be fast and\nrelatively cheap.\n\n-t.k.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161211/3af4ea5c/attachment.html>"
            },
            {
                "author": "Bram Cohen",
                "date": "2016-12-11T21:53:46",
                "message_text_only": "On Sun, Dec 11, 2016 at 1:40 PM, t. khan via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> Block75 is not exponential scaling. It's true the max theoretical increase\n> in the first year would be 7x, but the next year would be a max of 2x, and\n> the next could only increase by 50% and so on.\n>\n\nWith those limits there's very little reason to not simply have a fixed\nschedule. Blocks are likely to all be full in the future anyway, with a\nreal fee market, and the idea that miners will be held back on block sizes\nfor worry about propagation delay is a myth, and even if it were true it\nwould favor collective pooling a lot, which would be a very bad thing.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161211/ea9bb129/attachment.html>"
            },
            {
                "author": "James Hilliard",
                "date": "2016-12-11T21:55:55",
                "message_text_only": "I think the main thing you're missing is that there will always be\ntransactions available to mine simply because demand for blockspace is\neffectively unbounded as fees approach 0. Nodes generally have a\nstatic mempool size and dynamic minrelaytxfee nowadays so as\ntransactions get mined lower fee transactions get accepted into the\nmempool. An individual opting to not send a transaction would not make\nthe blocks smaller simply because there will always be other\ntransactions available(it would really only have an effect on the\ntransaction fees needed to get mined).\n\nOn Sun, Dec 11, 2016 at 3:40 PM, t. khan <teekhan42 at gmail.com> wrote:\n>\n> On Sun, Dec 11, 2016 at 3:31 PM, James Hilliard <james.hilliard1 at gmail.com>\n> wrote:\n>>\n>> What's most likely to happen is miners will max out the blocks they\n>> mine simply to try and get as many transaction fees as possible like\n>> they are doing right now(there will be a backlog of transactions at\n>> any block size). Having the block size double every year would likely\n>> cause major problems and this proposal allows over a 7x increase it\n>> seems.\n>\n>\n> Block75 is not exponential scaling. It's true the max theoretical increase\n> in the first year would be 7x, but the next year would be a max of 2x, and\n> the next could only increase by 50% and so on.\n>\n> However, to reach the max in the first year: 1) ALL blocks would have to be\n> 100% full and 2) transactions would have to increase at the same rate. We'd\n> have to be doing 2.1 million transactions a day within a year to make that\n> happen, and would therefore need blocks to be that big.\n>\n> Realistically, max block size will grow (and shrink) at a much slower rate\n> ... even more so with SegWit.\n>\n>>\n>>  The main problem with this proposal I think is that users effectively\n>>\n>> have no way to stop the miners from increasing block size\n>> continuously.\n>\n>\n> Yes they could, simply by not sending transactions. Users don't care at all\n> about block size. They just want their transactions to be fast and\n> relatively cheap.\n>\n> -t.k."
            },
            {
                "author": "t. khan",
                "date": "2016-12-11T22:30:34",
                "message_text_only": "The assumption you're making is incorrect. There is not an infinite number\nof low-fee transactions.\n\nYes, the average fee will go down compared to today with Block75, but this\nwill balance itself between demand and the minimum fee miners are willing\nto accept (not zero).\n\nFor example, add 200kb to today's max block size. How does that affect fees?\n(200kb would likely be the first increase if Block75 activated today)\n\n-t.k.\n\nOn Sun, Dec 11, 2016 at 4:55 PM, James Hilliard <james.hilliard1 at gmail.com>\nwrote:\n\n> I think the main thing you're missing is that there will always be\n> transactions available to mine simply because demand for blockspace is\n> effectively unbounded as fees approach 0. Nodes generally have a\n> static mempool size and dynamic minrelaytxfee nowadays so as\n> transactions get mined lower fee transactions get accepted into the\n> mempool. An individual opting to not send a transaction would not make\n> the blocks smaller simply because there will always be other\n> transactions available(it would really only have an effect on the\n> transaction fees needed to get mined).\n>\n> On Sun, Dec 11, 2016 at 3:40 PM, t. khan <teekhan42 at gmail.com> wrote:\n> >\n> > On Sun, Dec 11, 2016 at 3:31 PM, James Hilliard <\n> james.hilliard1 at gmail.com>\n> > wrote:\n> >>\n> >> What's most likely to happen is miners will max out the blocks they\n> >> mine simply to try and get as many transaction fees as possible like\n> >> they are doing right now(there will be a backlog of transactions at\n> >> any block size). Having the block size double every year would likely\n> >> cause major problems and this proposal allows over a 7x increase it\n> >> seems.\n> >\n> >\n> > Block75 is not exponential scaling. It's true the max theoretical\n> increase\n> > in the first year would be 7x, but the next year would be a max of 2x,\n> and\n> > the next could only increase by 50% and so on.\n> >\n> > However, to reach the max in the first year: 1) ALL blocks would have to\n> be\n> > 100% full and 2) transactions would have to increase at the same rate.\n> We'd\n> > have to be doing 2.1 million transactions a day within a year to make\n> that\n> > happen, and would therefore need blocks to be that big.\n> >\n> > Realistically, max block size will grow (and shrink) at a much slower\n> rate\n> > ... even more so with SegWit.\n> >\n> >>\n> >>  The main problem with this proposal I think is that users effectively\n> >>\n> >> have no way to stop the miners from increasing block size\n> >> continuously.\n> >\n> >\n> > Yes they could, simply by not sending transactions. Users don't care at\n> all\n> > about block size. They just want their transactions to be fast and\n> > relatively cheap.\n> >\n> > -t.k.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161211/8822ce40/attachment-0001.html>"
            },
            {
                "author": "Andrew Johnson",
                "date": "2016-12-11T20:38:27",
                "message_text_only": "\"You miss something obvious that makes this attack actually free of cost.\nNothing will \"cost them more in transaction fees\". A miner can create\nthousands of transactions paying to himself, and not broadcast them to\nthe network, but hold them and include them in the blocks he mines. The\nfees are collected by him because transactions are included in a block\nthat he mined and the left amount is in another wallet of the same\nperson. Repeat this continuously to fill blocks.\"\n\nThis is easily detectable as long as the network isn't heavily\npartitioned(which is an assumption we make today in order for transaction\npropagation to work reliably as well as for xThin and CompactBlocks to work\neffectively to reduce block transmission time).  Other miners would have an\nincentive to intentionally orphan blocks that contained a large number of\ntransactions that their nodes were unaware of.\n\nI don't think this sort of attack would last long.  Even later when\nsubsidies are drastically reduced, you would still lose out on significant\ngenuine fee revenue if your orphan rate increased even 10%(one out of ten\nof your poison blocks intentionally orphaned by another miner).\n\nOn Dec 11, 2016 11:12 AM, \"s7r via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n t. khan wrote:\n> Miners 'gaming' the Block75 system -\n> There is no financial incentive for miners to attempt to game the\n> Block75 system. Even if it were attempted and assuming the goal was to\n> create bigger blocks, the maximum possible increase would be 25% over\n> the previous block size. And, that size would only last for two weeks\n> before readjusting down. It would cost them more in transaction fees to\n> stuff the network than they could ever make up. To game the system,\n> they'd have to game it forever with no possibility of profit.\n>\n\nThis is an incentive, if few miners agree to create a large conglomerate\nthat will ultimately control the network.\n\nYou miss something obvious that makes this attack actually free of cost.\nNothing will \"cost them more in transaction fees\". A miner can create\nthousands of transactions paying to himself, and not broadcast them to\nthe network, but hold them and include them in the blocks he mines. The\nfees are collected by him because transactions are included in a block\nthat he mined and the left amount is in another wallet of the same\nperson. Repeat this continuously to fill blocks.\n\n\n> Blocks would get too big -\n> Eventually, blocks would get too big, but only if bandwidth stopped\n> increasing and the cost of disk space stopped decreasing. Otherwise, the\n> incremental adjustments made by Block75 (especially in combination with\n> SegWit) wouldn't break anyone's connection or result in significantly\n> more orphaned blocks.\n>\n\nTopology and bandwidth speed / hash rate of the network cannot be\ncontrolled - if we make assumptions about these it might have terrible\nconsequences.\n\nEven if we take in consideration that bandwidth will only grow and disk\nspace will only cost less (which is not something we can safely assume,\nby the way) the hard limit max. block size cannot grow to unlimited\nvalue (even if the growth happens over time). There is also a validation\ncost in time for each block, for the health of the network any node\nshould be able to download _and_ validate a block, before next block\ngets mined.\n\nYou said in another post that a permanent solution is preferred, rather\nthan kicking the can down the road. I fully agree, as well as many\nothers reading this list, but the permanent solution doesn't necessarily\nhave to be increasing the max block size dynamically.\n\nIf you think about it the other way around, dynamically growing the max\nblock size is also kicking the can down the road ... just without having\nto touch it and get dust on the boot ;)\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161211/ba48b60f/attachment-0001.html>"
            },
            {
                "author": "s7r",
                "date": "2016-12-11T23:22:53",
                "message_text_only": "Andrew Johnson wrote:\n> \"You miss something obvious that makes this attack actually free of cost.\n> Nothing will \"cost them more in transaction fees\". A miner can create\n> thousands of transactions paying to himself, and not broadcast them to\n> the network, but hold them and include them in the blocks he mines. The\n> fees are collected by him because transactions are included in a block\n> that he mined and the left amount is in another wallet of the same\n> person. Repeat this continuously to fill blocks.\"\n> \n> This is easily detectable as long as the network isn't heavily\n> partitioned(which is an assumption we make today in order for\n> transaction propagation to work reliably as well as for xThin and\n> CompactBlocks to work effectively to reduce block transmission time). \n> Other miners would have an incentive to intentionally orphan blocks that\n> contained a large number of transactions that their nodes were unaware of.\n> \n> I don't think this sort of attack would last long.  Even later when\n> subsidies are drastically reduced, you would still lose out on\n> significant genuine fee revenue if your orphan rate increased even\n> 10%(one out of ten of your poison blocks intentionally orphaned by\n> another miner).\n> \n\nI disagree.\n\nI didn't say this is impossible to detect, but it is hard to act against\nit. One miner orphaning the block intentionally is very unlikely if that\nminer acts rationally. It would only make sense if 51% of the hash rate\nwould intentionally orphan it. Otherwise the miner who intentionally\norphans a valid block, let's say block X, has to continue to mine one in\nits place on top of block X-1, and by the time he finds one:\n\na) his block X' is rejected by other miners because they already have a\nvalid block X on top of which they already started to mine;\n\nb) block X+1 was already found and broadcasted, so the miner who\norphaned X intentionally is on the shorter chain ignored by the network.\n\nSo, one miner cannot do anything about it. Even a pool cannot do\nanything about it, because the loss is greater. You need 51% of the hash\nrate to intentionally orphan it, and all the miners forming 51% need to\nbe colluding and know for sure that every one will intentionally orphan\nthe said block, otherwise there's a huge risk of loss for who does it.\nNobody would gamble to do this (I am not sure if gambling is the right\nword, since the loss is 100% sure here). But, we are not discussing 51%\nattacks because those are a different topic.\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 488 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161212/952907bb/attachment.sig>"
            },
            {
                "author": "James MacWhyte",
                "date": "2016-12-18T21:53:57",
                "message_text_only": "Hi All,\n\nI'm coming late to the party. I like the Block75 proposal.\n\nMultiple people have said miners would/could stuff blocks with insincere\ntransactions to increase the block size, but it was never adequately\nexplained what they would gain from this. If there aren't enough legitimate\ntransactions to fill up the block, where do you plan to earn extra income\nonce the block is bigger?\n\nMiners would be incentivized to include as many legitimate transactions as\npossible, but if propagation time is as big an issue as some of you have\nsaid it is, miners would also be incentivized to keep their blocks small\nenough to propagate. So why not give them the choice? Once the block size\ngets too big to propagate effectively, miners would be naturally\nincentivized to limit how much data they put in each block, finding the\nperfect balance.\n\nIn my opinion, none of the downsides presented so far have been a good\nargument. Risk of a 51% attack is not unique to this proposal, saying \"we\ncould also do that with hardcoded limits\" doesn't actually point out any\nproblem with this proposal, and miners already have the ability to add or\nwithhold transactions from their blocks.\n\nWe trust our miners to serve us by acting in their own best interests, and\nthis proposal simply gives them more options for doing that. If anyone can\nmake a strong argument against that would earn top marks in a high school\ndebate class, I'd love to hear it!\n\nJames\n\nOn Sun, Dec 11, 2016 at 3:23 PM s7r via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Andrew Johnson wrote:\n> > \"You miss something obvious that makes this attack actually free of cost.\n> > Nothing will \"cost them more in transaction fees\". A miner can create\n> > thousands of transactions paying to himself, and not broadcast them to\n> > the network, but hold them and include them in the blocks he mines. The\n> > fees are collected by him because transactions are included in a block\n> > that he mined and the left amount is in another wallet of the same\n> > person. Repeat this continuously to fill blocks.\"\n> >\n> > This is easily detectable as long as the network isn't heavily\n> > partitioned(which is an assumption we make today in order for\n> > transaction propagation to work reliably as well as for xThin and\n> > CompactBlocks to work effectively to reduce block transmission time).\n> > Other miners would have an incentive to intentionally orphan blocks that\n> > contained a large number of transactions that their nodes were unaware\n> of.\n> >\n> > I don't think this sort of attack would last long.  Even later when\n> > subsidies are drastically reduced, you would still lose out on\n> > significant genuine fee revenue if your orphan rate increased even\n> > 10%(one out of ten of your poison blocks intentionally orphaned by\n> > another miner).\n> >\n>\n> I disagree.\n>\n> I didn't say this is impossible to detect, but it is hard to act against\n> it. One miner orphaning the block intentionally is very unlikely if that\n> miner acts rationally. It would only make sense if 51% of the hash rate\n> would intentionally orphan it. Otherwise the miner who intentionally\n> orphans a valid block, let's say block X, has to continue to mine one in\n> its place on top of block X-1, and by the time he finds one:\n>\n> a) his block X' is rejected by other miners because they already have a\n> valid block X on top of which they already started to mine;\n>\n> b) block X+1 was already found and broadcasted, so the miner who\n> orphaned X intentionally is on the shorter chain ignored by the network.\n>\n> So, one miner cannot do anything about it. Even a pool cannot do\n> anything about it, because the loss is greater. You need 51% of the hash\n> rate to intentionally orphan it, and all the miners forming 51% need to\n> be colluding and know for sure that every one will intentionally orphan\n> the said block, otherwise there's a huge risk of loss for who does it.\n> Nobody would gamble to do this (I am not sure if gambling is the right\n> word, since the loss is 100% sure here). But, we are not discussing 51%\n> attacks because those are a different topic.\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161218/f08a63d8/attachment-0001.html>"
            },
            {
                "author": "Tom Harding",
                "date": "2016-12-19T01:42:38",
                "message_text_only": "James,\n\nI share your conviction that miners are the natural gatekeepers of the\nmaximum block size.\n\nThe trouble I see with Block75 is that linear growth won't work forever.\nAlso, by reading actual and not miners' preferred max blocksize, this\nproposal is sensitive to randomness in block timing and tx rate, and so\nincentivizes miners to manipulate their block content unnaturally in\neither the up or down direction to influence the calculation. \n\nThe EB/AD scheme of Bitcoin Unlimited recognizes implementation of the\nmax blocksize by miners, who publish their preferred max blocksize. But\nit expects forks of unpredictable (probably short) length as network\nbehavior evolves.\n\nBIP100, which also recognizes miner implementation of the max blocksize,\nbut has a change support threshold, and like Block75 defines the timing\nof max blocksize increases, looks superior to me.\n\n\nOn 12/18/2016 1:53 PM, James MacWhyte via bitcoin-dev wrote:\n> Hi All,\n>\n> I'm coming late to the party. I like the Block75 proposal.\n>\n> Multiple people have said miners would/could stuff blocks with\n> insincere transactions to increase the block size, but it was never\n> adequately explained what they would gain from this. If there aren't\n> enough legitimate transactions to fill up the block, where do you plan\n> to earn extra income once the block is bigger?\n>\n> Miners would be incentivized to include as many legitimate\n> transactions as possible, but if propagation time is as big an issue\n> as some of you have said it is, miners would also be incentivized to\n> keep their blocks small enough to propagate. So why not give them the\n> choice? Once the block size gets too big to propagate effectively,\n> miners would be naturally incentivized to limit how much data they put\n> in each block, finding the perfect balance.\n>\n> In my opinion, none of the downsides presented so far have been a good\n> argument. Risk of a 51% attack is not unique to this proposal, saying\n> \"we could also do that with hardcoded limits\" doesn't actually point\n> out any problem with this proposal, and miners already have the\n> ability to add or withhold transactions from their blocks.\n>\n> We trust our miners to serve us by acting in their own best interests,\n> and this proposal simply gives them more options for doing that. If\n> anyone can make a strong argument against that would earn top marks in\n> a high school debate class, I'd love to hear it!\n>\n> James\n>"
            },
            {
                "author": "Bram Cohen",
                "date": "2016-12-10T23:12:25",
                "message_text_only": "On Mon, Dec 5, 2016 at 7:27 AM, t. khan via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> Put another way: let\u2019s stop thinking about what the max block size should\n> be and start thinking about how full we want the average block to be\n> regardless of size. Over the last year, we\u2019ve had averages of 75% or\n> higher, so aiming for 75% full seems reasonable, hence naming this concept\n> \u2018Block75\u2019.\n>\n\nThat's effectively making the blocksize limit completely uncapped and only\npreventing spikes, and even in the case of spikes it doesn't differentiate\nbetween 'real' traffic and low value spam attacks. It suffers from the same\nfundamental problems as bitcoin unlimited: There are in the end no\ntransaction fees, and inevitably some miners will want to impose some cap\non block size for practical purposes, resulting in a fork.\n\nDifficulty adjustment works because there's a clear goal of having a\ncertain rate of making new blocks. Without a target to attempt automatic\nadjustment makes no sense.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161210/01c100f5/attachment.html>"
            },
            {
                "author": "t. khan",
                "date": "2016-12-11T00:52:58",
                "message_text_only": "Agreed, the clear goal of 10 minutes per block is why the difficulty\nadjustment works well. Blocks averaging 75% full is the clear goal of the\ndescribed method. That's the target to attempt.\n\nUnder Block75, there will still be full blocks. There will still be\ntransaction fees and a fee market. The fees will be lower than they are now\nof course.\n\nHardcoding a cap will inevitably become a roadblock (again), and we'll be\nback in the same position as we are now. Permanent solutions are preferred.\n\nOn Sat, Dec 10, 2016 at 6:12 PM, Bram Cohen <bram at bittorrent.com> wrote:\n\n> On Mon, Dec 5, 2016 at 7:27 AM, t. khan via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>>\n>> Put another way: let\u2019s stop thinking about what the max block size should\n>> be and start thinking about how full we want the average block to be\n>> regardless of size. Over the last year, we\u2019ve had averages of 75% or\n>> higher, so aiming for 75% full seems reasonable, hence naming this concept\n>> \u2018Block75\u2019.\n>>\n>\n> That's effectively making the blocksize limit completely uncapped and only\n> preventing spikes, and even in the case of spikes it doesn't differentiate\n> between 'real' traffic and low value spam attacks. It suffers from the same\n> fundamental problems as bitcoin unlimited: There are in the end no\n> transaction fees, and inevitably some miners will want to impose some cap\n> on block size for practical purposes, resulting in a fork.\n>\n> Difficulty adjustment works because there's a clear goal of having a\n> certain rate of making new blocks. Without a target to attempt automatic\n> adjustment makes no sense.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161210/fff14476/attachment.html>"
            },
            {
                "author": "Daniele Pinna",
                "date": "2016-12-10T12:23:49",
                "message_text_only": "We have models for estimating the probability that a block is orphaned\ngiven average network bandwidth and block size.\n\nThe question is, do we have objective measures of these two quantities?\nCouldn't we target an orphan_rate < max_rate?\n\n\n\nOn Dec 10, 2016 1:01 PM, <bitcoin-dev-request at lists.linuxfoundation.org>\nwrote:\n\nSend bitcoin-dev mailing list submissions to\n        bitcoin-dev at lists.linuxfoundation.org\n\nTo subscribe or unsubscribe via the World Wide Web, visit\n        https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\nor, via email, send a message with subject or body 'help' to\n        bitcoin-dev-request at lists.linuxfoundation.org\n\nYou can reach the person managing the list at\n        bitcoin-dev-owner at lists.linuxfoundation.org\n\nWhen replying, please edit your Subject line so it is more specific\nthan \"Re: Contents of bitcoin-dev digest...\"\n\n\nToday's Topics:\n\n   1. Managing block size the same way we do difficulty (aka\n      Block75) (t. khan)\n   2. Re: Managing block size the same way we do difficulty (aka\n      Block75) (s7r)\n\n\n----------------------------------------------------------------------\n\nMessage: 1\nDate: Mon, 5 Dec 2016 10:27:32 -0500\nFrom: \"t. khan\" <teekhan42 at gmail.com>\nTo: bitcoin-dev at lists.linuxfoundation.org\nSubject: [bitcoin-dev] Managing block size the same way we do\n        difficulty      (aka Block75)\nMessage-ID:\n        <CAGCNRJqdu7DMC+AMR4mYKRAYStRMKVGqbnjtEfmzcoeMij5u=A at mail.gmail.com>\nContent-Type: text/plain; charset=\"utf-8\"\n\nBIP Proposal - Managing Bitcoin?s block size the same way we do difficulty\n(aka Block75)\n\nThe every two-week adjustment of difficulty has proven to be a reasonably\neffective and predictable way of managing how quickly blocks are mined.\nBitcoin needs a reasonably effective and predictable way of managing the\nmaximum block size.\n\nIt?s clear at this point that human beings should not be involved in the\ndetermination of max block size, just as they?re not involved in deciding\nthe difficulty.\n\nInstead of setting an arbitrary max block size (1MB, 2MB, 8MB, etc.) or\npassing the decision to miners/pool operators, the max block size should be\nadjusted every two weeks (2016 blocks) using a system similar to how\ndifficulty is calculated.\n\nPut another way: let?s stop thinking about what the max block size should\nbe and start thinking about how full we want the average block to be\nregardless of size. Over the last year, we?ve had averages of 75% or\nhigher, so aiming for 75% full seems reasonable, hence naming this concept\n?Block75?.\n\nThe target capacity over 2016 blocks would be 75%. If the last 2016 blocks\nare more than 75% full, add the difference to the max block size. Like this:\n\nMAX_BLOCK_BASE_SIZE = 1000000\nTARGET_CAPACITY = 750000\nAVERAGE_OVER_CAP = average block size of last 2016 blocks minus\nTARGET_CAPACITY\n\nTo check if a block is valid, ? (MAX_BLOCK_BASE_SIZE + AVERAGE_OVER_CAP)\n\nFor example, if the last 2016 blocks are 85% full (average block is 850\nKB), add 10% to the max block size. The new max block size would be 1,100\nKB until the next 2016 blocks are mined, then reset and recalculate. The\n1,000,000 byte limit that exists currently would remain, but would\neffectively be the minimum max block size.\n\nAnother two weeks goes by, the last 2016 blocks are again 85% full, but now\nthat means they average 935 KB out of the 1,100 KB max block size. This is\n93.5% of the 1,000,000 byte limit, so 18.5% would be added to that to make\nthe new max block size of 1,185 KB.\n\nAnother two weeks passes. This time, the average block is 1,050 KB. The new\nmax block size is calculated to 1,300 KB (as blocks were 105% full, minus\nthe 75% capacity target, so 30% added to max block size).\n\nRepeat every 2016 blocks, forever.\n\nIf Block75 had been applied at the difficulty adjustment on November 18th,\nthe max block size would have been 1,080KB, as the average block during\nthat period was 83% full, so 8% is added to the 1,000KB limit. The current\nsize, after the December 2nd adjustment would be 1,150K.\n\nBlock75 would allow the max block size to grow (or shrink) in response to\ntransaction volume, and does so predictably, reasonably quickly, and in a\nmethod that prevents wild swings in block size or transaction fees. It\nattempts to keep blocks at 75% total capacity over each two week period,\nthe same way difficulty tries to keep blocks mined every ten minutes. It\nalso keeps blocks as small as possible.\n\nThoughts?\n\n-t.k.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/\nattachments/20161205/c24d6c6d/attachment-0001.html>\n\n------------------------------\n\nMessage: 2\nDate: Sat, 10 Dec 2016 12:44:31 +0200\nFrom: s7r <s7r at sky-ip.org>\nTo: bitcoin-dev at lists.linuxfoundation.org\nSubject: Re: [bitcoin-dev] Managing block size the same way we do\n        difficulty (aka Block75)\nMessage-ID: <c318f76d-0904-2e1b-453b-60179f8209bb at sky-ip.org>\nContent-Type: text/plain; charset=\"utf-8\"\n\nt. khan via bitcoin-dev wrote:\n> BIP Proposal - Managing Bitcoin?s block size the same way we do\n> difficulty (aka Block75)\n>\n> The every two-week adjustment of difficulty has proven to be a\n> reasonably effective and predictable way of managing how quickly blocks\n> are mined. Bitcoin needs a reasonably effective and predictable way of\n> managing the maximum block size.\n>\n> It?s clear at this point that human beings should not be involved in the\n> determination of max block size, just as they?re not involved in\n> deciding the difficulty.\n>\n> Instead of setting an arbitrary max block size (1MB, 2MB, 8MB, etc.) or\n> passing the decision to miners/pool operators, the max block size should\n> be adjusted every two weeks (2016 blocks) using a system similar to how\n> difficulty is calculated.\n>\n> Put another way: let?s stop thinking about what the max block size\n> should be and start thinking about how full we want the average block to\n> be regardless of size. Over the last year, we?ve had averages of 75% or\n> higher, so aiming for 75% full seems reasonable, hence naming this\n> concept ?Block75?.\n>\n> The target capacity over 2016 blocks would be 75%. If the last 2016\n> blocks are more than 75% full, add the difference to the max block size.\n> Like this:\n>\n> MAX_BLOCK_BASE_SIZE = 1000000\n> TARGET_CAPACITY = 750000\n> AVERAGE_OVER_CAP = average block size of last 2016 blocks minus\n> TARGET_CAPACITY\n>\n> To check if a block is valid, ? (MAX_BLOCK_BASE_SIZE + AVERAGE_OVER_CAP)\n>\n> For example, if the last 2016 blocks are 85% full (average block is 850\n> KB), add 10% to the max block size. The new max block size would be\n> 1,100 KB until the next 2016 blocks are mined, then reset and\n> recalculate. The 1,000,000 byte limit that exists currently would\n> remain, but would effectively be the minimum max block size.\n>\n> Another two weeks goes by, the last 2016 blocks are again 85% full, but\n> now that means they average 935 KB out of the 1,100 KB max block size.\n> This is 93.5% of the 1,000,000 byte limit, so 18.5% would be added to\n> that to make the new max block size of 1,185 KB.\n>\n> Another two weeks passes. This time, the average block is 1,050 KB. The\n> new max block size is calculated to 1,300 KB (as blocks were 105% full,\n> minus the 75% capacity target, so 30% added to max block size).\n>\n> Repeat every 2016 blocks, forever.\n>\n> If Block75 had been applied at the difficulty adjustment on November\n> 18th, the max block size would have been 1,080KB, as the average block\n> during that period was 83% full, so 8% is added to the 1,000KB limit.\n> The current size, after the December 2nd adjustment would be 1,150K.\n>\n> Block75 would allow the max block size to grow (or shrink) in response\n> to transaction volume, and does so predictably, reasonably quickly, and\n> in a method that prevents wild swings in block size or transaction fees.\n> It attempts to keep blocks at 75% total capacity over each two week\n> period, the same way difficulty tries to keep blocks mined every ten\n> minutes. It also keeps blocks as small as possible.\n>\n> Thoughts?\n>\n> -t.k.\n>\n\nI like the idea. It is good wrt growing the max. block size\nautomatically without human action, but the main problem (or question)\nis not how to grow this number, it is what number can the network\nhandle, considering both miners and users. While disk space requirements\nmight not be a big problem, block propagation time is. The time required\nfor a block to propagate in the network (or at least to all the miners)\nis directly dependent of its size.  If blocks take too much time to\npropagate in the network, the orphan rate will increase in unpredictable\nways. For example if the internet speed in China is worse than in\nEurope, and miners in China have more than 50% of the hashing power,\nblocks mined by European miners might get orphaned.\n\nThe system as described can also be gamed, by filling the network with\ntransactions. Miners have the monetary interest to include as many\ntransactions as possible in a block in order to collect the fees.\nRegardless how you think about it, there has to be a maximum block size\nthat the network will allow as a consensus rule. Increasing it\ndynamically based on transaction volume will reach a point where the\nnumber got big enough that it broke things. Bitcoin, because its\nfundamental design, can scale by using offchain solutions.\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 488 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/\nattachments/20161210/c231038d/attachment-0001.sig>\n\n------------------------------\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n\nEnd of bitcoin-dev Digest, Vol 19, Issue 4\n******************************************\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161210/1747b6c1/attachment-0001.html>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2016-12-10T17:39:57",
                "message_text_only": "On Sat, Dec 10, 2016 at 4:23 AM, Daniele Pinna via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> We have models for estimating the probability that a block is orphaned\n> given average network bandwidth and block size.\n>\n> The question is, do we have objective measures of these two quantities?\n> Couldn't we target an orphan_rate < max_rate?\n>\n\nModels can predict orphan rate given block size and network/hashrate\ntopology, but you can't control the topology (and things like FIBRE hide\nthe effect of block size on this as well). The result is that if you're\npurely optimizing for minimal orphan rate, you can end up with a single\n(conglomerate of) pools producing all the blocks. Such a setup has no\npropagation delay at all, and as a result can always achieve 0 orphans.\n\nCheers,\n\n-- \nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161210/edca6d6b/attachment.html>"
            },
            {
                "author": "Daniele Pinna",
                "date": "2016-12-11T03:17:45",
                "message_text_only": "How is the adverse scenario you describe different from a plain old 51%\nattack? Each proposed protocol change  where 51% or more  of the network\ncan potentially game the rules and break the system should be considered\njust as acceptable/unacceptable as another.\n\nThere comes a point where some form of basic honesty must be assumed on\nbehalf of participants benefiting from the system working properly and\nreliably.\n\nAfterall, what magic line of code prohibits all miners from simultaneously\nturning all their equipment off...  just because?\n\nMaybe this 'one':\n\n\"As long as a majority of CPU power is controlled by nodes that are not\ncooperating to attack the network, they'll generate the longest chain and\noutpace attackers. The network itself requires minimal structure.\"\n\nIs there such a thing as an unrecognizable 51% attack?  One where the\nremaining 49% get dragged in against their will?\n\nDaniele\n\nOn Dec 10, 2016 6:39 PM, \"Pieter Wuille\" <pieter.wuille at gmail.com> wrote:\n\n> On Sat, Dec 10, 2016 at 4:23 AM, Daniele Pinna via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> We have models for estimating the probability that a block is orphaned\n>> given average network bandwidth and block size.\n>>\n>> The question is, do we have objective measures of these two quantities?\n>> Couldn't we target an orphan_rate < max_rate?\n>>\n>\n> Models can predict orphan rate given block size and network/hashrate\n> topology, but you can't control the topology (and things like FIBRE hide\n> the effect of block size on this as well). The result is that if you're\n> purely optimizing for minimal orphan rate, you can end up with a single\n> (conglomerate of) pools producing all the blocks. Such a setup has no\n> propagation delay at all, and as a result can always achieve 0 orphans.\n>\n> Cheers,\n>\n> --\n> Pieter\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161211/53c05206/attachment.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-12-11T05:29:08",
                "message_text_only": "The presumption of the mining aspect of the Bitcoin security model is that the mining majority is a broadly distributed set of independent people, not one person who controls a majority of the hash power. \n\nYou seem to have overlooked a qualifier in your Satoshi quote: \"...by nodes that are not cooperating to attack the network\". A single miner with majority hash power is of course cooperating with himself. At that point the question of whether he is attacking the network is moot, it's his network.\n\nI believe that Pieter's point is that a system optimized for orphan rate may in effect be optimized for a single entity providing all double spend protection. That works directly against the central principle of Bitcoin security. The security of the money is a function of the number of independent miners and sellers.\n\ne\n\n> On Dec 10, 2016, at 7:17 PM, Daniele Pinna via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> How is the adverse scenario you describe different from a plain old 51% attack? Each proposed protocol change  where 51% or more  of the network can potentially game the rules and break the system should be considered just as acceptable/unacceptable as another. \n> \n> There comes a point where some form of basic honesty must be assumed on behalf of participants benefiting from the system working properly and reliably. \n> \n> Afterall, what magic line of code prohibits all miners from simultaneously turning all their equipment off...  just because? \n> \n> Maybe this 'one':\n> \n> \"As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they'll generate the longest chain and outpace attackers. The network itself requires minimal structure.\"\n> \n> Is there such a thing as an unrecognizable 51% attack?  One where the remaining 49% get dragged in against their will? \n> \n> Daniele \n> \n>> On Dec 10, 2016 6:39 PM, \"Pieter Wuille\" <pieter.wuille at gmail.com> wrote:\n>>> On Sat, Dec 10, 2016 at 4:23 AM, Daniele Pinna via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> We have models for estimating the probability that a block is orphaned given average network bandwidth and block size. \n>>> \n>>> The question is, do we have objective measures of these two quantities? Couldn't we target an orphan_rate < max_rate? \n>> \n>> Models can predict orphan rate given block size and network/hashrate topology, but you can't control the topology (and things like FIBRE hide the effect of block size on this as well). The result is that if you're purely optimizing for minimal orphan rate, you can end up with a single (conglomerate of) pools producing all the blocks. Such a setup has no propagation delay at all, and as a result can always achieve 0 orphans.\n>> \n>> Cheers,\n>> \n>> -- \n>> Pieter\n>> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161210/3220d8fc/attachment.html>"
            },
            {
                "author": "Adam Back",
                "date": "2016-12-11T09:21:01",
                "message_text_only": "Well I think empirical game-theory observed on the network involves more\ntypes of strategy than honest vs dishonest.  At least 4, maybe 5 types of\nstrategy and I would argue lumping the strategies together results in\nincorrect game theory conclusions and predictions.\n\nA) altruistic players (protocol following by principle to be good network\ncitizens, will forgo incremental profits to aid network health) eg aim to\ndecentralize hashrate, will mine stuck transactions for free, run pools\nwith zero fee, put more effort into custom spam filtering, tend to be power\nusers, or long term invested etc.\n\nB) honest players (protocol following but non-altruistic or just\nlazy/asleep run default software, but still leaving some dishonest profit\nuntaken). Eg reject spy mining, but no charitable actions, will not\nretaliate in kind to semi-honest zero sum attacks that reduce their profits.\n\nC) semi-honest (will violate protocol if their attack can be plausibly\ndeniable or argued to be not hugely damaging to network security). Eg spy\nmining, centralised pools increasing other miners orphan rates.\n\nD) rational players (will violate the protocol for profit: will not overtly\nsteal from users via double spends, but anything short particularly\ndisadvantaging other miners even if it results in centralisation is treated\nas fair game) eg selfish mining. Would increase block size by filling with\npay to self transactions, if it increased orphans for others.\n\nE) dishonest players (aka hyper-rational: will actually steal from users\nprobabilistically if possible, not as worried about detection). Eg double\nspend and probabilistic double spends (against onchain gambling games).\nWould DDoS competing pools.\n\nIn part the strategies depend on investment horizon, it is long term\nrational for altruistic behavior to forgo incremental short term profit to\nimprove user experience.  Hyper-rational to buy votes in a \"ends justify\nmeans\" mentality though fortunately most network players are not dishonest.\n\nSo called meta-incentive (unwillingness to risk hurting bitcoin due to\nintended long term ho dling coins or ASICs) can also explain bias towards\nhonest or altruistic strategies.\n\nRenting too much hashrate is risky as it can avoid the meta-incentive and\nincrease rational or dishonest strategies.\n\nIn particular re differentiating from 51% attack so long as > 50% are\nsemi-honest, honest or altruistic it won't happen.  It would seem actually\nthat > 66-75% are because we have not seen selfish mining on the network.\nThough I think conveniently slow block publication by some players in the\n60% spy mining semi-honest cartel was seen for a while, the claim has been\nit was short-lived and due to technical issue.\n\nIt would be interesting to try to categorise and estimate the network %\nengaging in each strategy.  I think the information is mostly known.\n\nAdam\n\nOn Dec 11, 2016 03:22, \"Daniele Pinna via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> How is the adverse scenario you describe different from a plain old 51%\n> attack? Each proposed protocol change  where 51% or more  of the network\n> can potentially game the rules and break the system should be considered\n> just as acceptable/unacceptable as another.\n>\n> There comes a point where some form of basic honesty must be assumed on\n> behalf of participants benefiting from the system working properly and\n> reliably.\n>\n> Afterall, what magic line of code prohibits all miners from simultaneously\n> turning all their equipment off...  just because?\n>\n> Maybe this 'one':\n>\n> \"As long as a majority of CPU power is controlled by nodes that are not\n> cooperating to attack the network, they'll generate the longest chain and\n> outpace attackers. The network itself requires minimal structure.\"\n>\n> Is there such a thing as an unrecognizable 51% attack?  One where the\n> remaining 49% get dragged in against their will?\n>\n> Daniele\n>\n> On Dec 10, 2016 6:39 PM, \"Pieter Wuille\" <pieter.wuille at gmail.com> wrote:\n>\n>> On Sat, Dec 10, 2016 at 4:23 AM, Daniele Pinna via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> We have models for estimating the probability that a block is orphaned\n>>> given average network bandwidth and block size.\n>>>\n>>> The question is, do we have objective measures of these two quantities?\n>>> Couldn't we target an orphan_rate < max_rate?\n>>>\n>>\n>> Models can predict orphan rate given block size and network/hashrate\n>> topology, but you can't control the topology (and things like FIBRE hide\n>> the effect of block size on this as well). The result is that if you're\n>> purely optimizing for minimal orphan rate, you can end up with a single\n>> (conglomerate of) pools producing all the blocks. Such a setup has no\n>> propagation delay at all, and as a result can always achieve 0 orphans.\n>>\n>> Cheers,\n>>\n>> --\n>> Pieter\n>>\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161211/eca9fad8/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Managing block size the same way we do difficulty (aka Block75)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Eric Voskuil",
                "Andrew Johnson",
                "Adam Back",
                "s7r",
                "t. khan",
                "Hampus Sj\u00f6berg",
                "Daniele Pinna",
                "James Hilliard",
                "James MacWhyte",
                "Bram Cohen",
                "Pieter Wuille",
                "Tom Harding"
            ],
            "messages_count": 24,
            "total_messages_chars_count": 90578
        }
    },
    {
        "title": "[bitcoin-dev] Handing over the torch of qsafe",
        "thread_messages": [
            {
                "author": "Alonzo Coeus",
                "date": "2016-12-11T15:50:03",
                "message_text_only": "An HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161211/237b1190/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Handing over the torch of qsafe",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Alonzo Coeus"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 142
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Currency",
        "thread_messages": [
            {
                "author": "Ben West",
                "date": "2016-12-13T11:13:24",
                "message_text_only": "Hello all;\nis there any number or id that determine uniquely the BTC value.\notherwise; is there any hash or address or key that when found we could say\nthis is my 50BTC or my 20BTC ?.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161213/11cf7031/attachment.html>"
            },
            {
                "author": "Henning Kopp",
                "date": "2016-12-14T08:00:51",
                "message_text_only": "Hi Ben,\n\nnot sure if this is the right mailing list for that. I think it rather\nbelongs to bitcoin-discuss.\n\nAnd I am also not sure if I understand your question. What you may\nmean is the private key of a user. If you find this, you can spend his\nfunds and also prove that you own the funds.\n\nDepending on your level of understanding of Bitcoin, this blogpost may\nbe insightful for you:\nhttp://www.michaelnielsen.org/ddi/how-the-bitcoin-protocol-actually-works/\n\nAll the best\nHenning\n\n\nOn Tue, Dec 13, 2016 at 11:13:24AM +0000, Ben West via bitcoin-dev wrote:\n> Hello all;\n> is there any number or id that determine uniquely the BTC value.\n> otherwise; is there any hash or address or key that when found we could say\n> this is my 50BTC or my 20BTC ?.\n\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n\n-- \nHenning Kopp\nInstitute of Distributed Systems\nUlm University, Germany\n\nOffice: O27 - 3402\nPhone: +49 731 50-24138\nWeb: http://www.uni-ulm.de/in/vs/~kopp"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Currency",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Henning Kopp",
                "Ben West"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 1462
        }
    },
    {
        "title": "[bitcoin-dev] BIP - Block75 - Managing max block size as we do difficulty",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2016-12-15T01:48:23",
                "message_text_only": "Please use ASCII quotes in the Title. It is also too long (max size 44 \ncharacters).\n\nAdd missing headers:\n  Layer: Consensus (hard fork)\n  Comments-Summary: No comments yet.\n  Comments-URI: TBD\n  Status: Draft\n  Type: Standards Track\n  License: PD\n\nIt must be made at least technically sound. The BIP talks about adjusting the \nmaximum block size, but the specification only affects MAX_BLOCK_BASE_SIZE, \nwhich does not actually affect the max block size at all. Either the \nspecification needs to implement the described goal (adjusting max block size) \nor the motivation needs to be adjusted to explain why MAX_BLOCK_BASE_SIZE is \nbeing adjusted.\n\nIt is missing a section on Backward Compatibility. This should address at \nleast the fact that this is *NOT* backward compatible, and ideally propose a \nmechanism for establishing agreement from the entire community for its \ndeployment. Similarly, there is talk of 75%, but the algorithm presented does \nnot in fact implement 75%.\n\nFinally, I am about to set BIP 2 to Active, so it would be preferable to \nchoose a copyright license from the choices in BIP 2.\n\nWhen you're ready, feel free to open a pull request on \nhttps://github.com/bitcoin/bips/ with the BIP in mediawiki format, named:\n    bip-tkhan-block75.mediawiki\n\nThanks,\n\nLuke\n\n\nOn Wednesday, December 14, 2016 7:55:20 PM t. khan wrote:\n> Hi Luke,\n> \n> Following is a BIP for submission. Please let me know if any\n> modifications/additions are required.\n> \n> Thank you,\n> \n> -t.k.\n> \n> --------\n> \n> BIP: ??\n> Title: \u2018Block75\u2019 - Managing max block size the same way we do difficulty\n> Author: t.khan <teekhan42 at gmail.com>\n> Created: 2016-12-13\n> \n> \n> Abstract\n> Automatic adjustment of max block size with the target of keeping blocks\n> 75% full, based on the average block size of the previous 2016 blocks. This\n> would be done on the same schedule as difficulty.\n> \n> \n> Motivation\n> The every two-week and automatic adjustment of difficulty has proven to be\n> a reasonably effective and predictable way of managing how quickly blocks\n> are mined. It works well because humans aren\u2019t involved,  except for\n> setting the original target of a 10 minute per block average, and therefore\n> it isn\u2019t political or contentious. It\u2019s simply a response to changing\n> network resources.\n> \n> Bitcoin needs a reasonably effective and predictable way of managing the\n> maximum block size, which both allows moderate growth and keeps max block\n> size as small as possible, thereby preventing wild swings in max block size\n> or transaction fees.\n> \n> It\u2019s clear at this point that human beings should not be involved in the\n> determination of max block size, just as they\u2019re not involved in deciding\n> the difficulty. Any solution to block size scaling which sets an arbitrary\n> max block size (1MB, 2MB, 8MB, etc.) is by its very design a temporary\n> solution and should be avoided. Any solution which passes the decision on\n> to miners/pool operators for a vote will, by its very design, be political\n> and contentious and should be avoided.\n> \n> A permanent solution that is simply a response to changing transaction\n> volumes is the goal of Block75.\n> \n> \n> Specification\n> The max block size would be recalculated every 2016 blocks, along with\n> difficulty, using this simple formula:\n> \n> new max block size = 1,000KB + (average size of last 2016 blocks - 750KB)\n> \n> Further details:\n> \n> MAX_BLOCK_BASE_SIZE = 1000000 //this line stays the same\n> TARGET_CAPACITY = 750000 //new line representing 75%\n> \n> AVERAGE_OVER_CAP = average block size of last 2016 blocks minus\n> TARGET_CAPACITY\n> \n> To check if a block is valid, \u2264 (MAX_BLOCK_BASE_SIZE + AVERAGE_OVER_CAP)\n> \n> \n> Rationale\n> The 75% full block target was selected as it represents the middle ground\n> between blocks being too small (average 100% full) and blocks being\n> unnecessarily large (average 50% full). It can absorb short-term spikes in\n> transaction volume of up to 33% and also limits the growth of max block\n> size to 250KB over the previous period.\n> \n> The 2016 blocks (two week) period was selected as it has been shown to be\n> reasonably adaptive to changing network resources. The frequent and gradual\n> adjustments that result from this will be relatively easy for miners and\n> node operators to predict and adapt to, as any unforeseen consequences will\n> be visible well in advance. It also minimizes any effect a malicious party\n> could have in an attempt to manipulate block size.\n> \n> Copyright\n> This work is placed in the public domain."
            }
        ],
        "thread_summary": {
            "title": "BIP - Block75 - Managing max block size as we do difficulty",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Luke Dashjr"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4532
        }
    },
    {
        "title": "[bitcoin-dev] Planned Obsolescence",
        "thread_messages": [
            {
                "author": "jg at 112bit.com",
                "date": "2016-12-15T03:38:09",
                "message_text_only": "Today according to the stats at https://bitnodes.21.co/nodes/ the top 10 \nBitcoin running node versions are:\n\n1.\n_Version Satoshi:0.13.1\n_Nodes 2071\n_38.97%\n\n\n2.\n_Version Satoshi:0.12.1\n_Nodes 1022\n_19.23%\n\n\n3.\nSatoshi:0.13.0\n_Nodes 604\n_11.36%\n\n\n4.\nBitcoin Unlimited:0.12.1\n_Nodes 373\n_7.02%\n\n\n5.\nSatoshi:0.11.2\n_Nodes 183\n_3.44%\n\n\n6.\nSatoshi:0.12.0\n_Nodes 131\n_2.46%\n\n\n7. Satoshi:0.13.99\n_Nodes 122\n_2.30%\n\n\n8.\nSatoshi:0.11.0\n_Nodes 87\n_1.64%\n\n\n9.\nBTCC:0.13.1\n_Nodes 53\n_1.00%\n\n\n10.\nSatoshi:0.10.2\n_Nodes 52\n_0.98%\n\n\nOther\n_Nodes 617\n_11.61%\n\n\nThere are 75 different versions of visible nodes on the network.\n\nMore than 30% of the nodes running Bitcoin Core are running versions \nolder than 0.13.0.\n\nFor reasons I am unable to determine a significant number of node \noperators do not upgrade their clients.\n\nI also know newer versions require the same or fewer hardware resources \nto run than the same network requirements as older versions of the \nclient.\n\nOlder node versions may generate issues because some upgrades will make \nseveral of the nodes running older protocol versions obsolete and or \nincompatible. There may be other hard to predict behaviors on older \nversions of the client.\n\nIn order to avoid such wide fragmentation of \"Bitcoin Core\u201d node \nversions and to help there be a more predictable protocol improvement \nprocess, I consider it worth it to analyze introducing some planned \nobsolescence in each new version. In the last year we had 4 new versions \nso if each version is valid for about 1 year (52560 blocks) this may be \na reasonable time frame for node operators to upgrade. If a node does \nnot upgrade it will stop working instead of participating in the network \nwith an outdated protocol version.\n\nThese changes may also simplify the developer's jobs in some cases by \navoiding them having to deal with ancient versions of the client.\n\nRegards\nJuan Garavaglia"
            },
            {
                "author": "Aymeric Vitte",
                "date": "2016-12-15T18:12:02",
                "message_text_only": "Maybe there are still some advantages but I don't know why this is not\nconsidered as a major issue by the bitcoin community for the future and\nwhy this looks to be never discussed:\n\n- the size of the bitcoin network in terms of full nodes is ridiculous\nand this is continuously decreasing, we cannot consider the bitcoin\nnetwork as a decentralized p2p network, what you are proposing is\nlogical but will of course amplify the problem\n\n>For reasons I am unable to determine a significant number of node\noperators do not upgrade their clients.\n\nWhy should they? What is the incentive for people to run full nodes and\nupgrade? FYI I am part of the 2071 0.13.1 nodes for some good reasons\nbut will just shut it down when I am done, same for zcash (which as a\nmatter of fact I upgraded today since by some chance I noticed some\nupdates I was not aware of neither notified, just running it because I\nneed it from time to time and just don't kill it so I don't have to wait\nfor the restart process, maybe others are doing the same or just forgot\nthat they were running a full node)\n\nBecause, again, why should I or we maintain it/them?\n\nI have looked at the proposals in the past (as well as the incentive\nprogram) to reward those that are running full nodes but only found a\nvery few, never implemented (or even considered)\n\nThis is the very same for proposals allowing to start a full node from\nzero in an acceptable timeframe (ie not 10 days in my case)\n\nIf the consensus is not to solve those two points and have a bitcoin\nnetwork controlled then it would be interesting to know why, so people\ndon't waste time trying to find solutions\n\nSatoshi himself predicted that the full nodes will get centralized, I\nthink it's wrong, or in that case the bitcoin network cannot pretend to\nbe a decentralized immutable system (can be compared then to the Tor\nnetwork which does not pretend to be decentralized, because it is\ncentralized, and in addition does not encourage small nodes)\n\nPS: IMHO the email notificiation system makes it difficult to follow\nwhom is answering to whom/what on this list compared to other lists\n\n-- \nZcash wallets made simple: https://github.com/Ayms/zcash-wallets\nBitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets\nGet the torrent dynamic blocklist: http://peersm.com/getblocklist\nCheck the 10 M passwords list: http://peersm.com/findmyass\nAnti-spies and private torrents, dynamic blocklist: http://torrent-live.org\nPeersm : http://www.peersm.com\ntorrent-live: https://github.com/Ayms/torrent-live\nnode-Tor : https://www.github.com/Ayms/node-Tor\nGitHub : https://www.github.com/Ayms"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2016-12-15T18:48:47",
                "message_text_only": "On Thu, Dec 15, 2016 at 4:38 AM, Juan Garavaglia via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Older node versions may generate issues because some upgrades will make\n> several of the nodes running older protocol versions obsolete and or\n> incompatible. There may be other hard to predict behaviors on older versions\n> of the client.\n\nHard to predict or not, you can't force people to run newer software.\n\n> In order to avoid such wide fragmentation of \"Bitcoin Core\u201d node versions\n> and to help there be a more predictable protocol improvement process, I\n> consider it worth it to analyze introducing some planned obsolescence in\n> each new version. In the last year we had 4 new versions so if each version\n> is valid for about 1 year (52560 blocks) this may be a reasonable time frame\n> for node operators to upgrade. If a node does not upgrade it will stop\n> working instead of participating in the network with an outdated protocol\n> version.\n\nWhen you introduce anti-features like this in free software they can\nbe trivially removed and they likely will.\n\n> These changes may also simplify the developer's jobs in some cases by\n> avoiding them having to deal with ancient versions of the client.\n\nThere's a simpler solution for this which is what is being done now:\nstop maintaining and giving support for older versions.\nThere's limited resources and developers are rarely interested in\nfixing bugs for very old versions. Users shouldn't expect things to be\nbackported to old versions (if developers do it and there's enough\ntesting, there's no reason not to do more releases of old versions, it\nis just rarely the case)."
            },
            {
                "author": "Angel Leon",
                "date": "2016-12-15T22:25:04",
                "message_text_only": "Perhaps if there were a message that would nag your stdout or log output\nletting you know there's a new version available, or N more versions\navailable and that you might be missing out on X security patches, Y\nprotocol improvements, depending on how far back you are, you'd be tempted\nto upgrade, works for me in Ubuntu every time I log to my servers and I see\nhow far behind I am in terms of available updates.\n\nOther thing done in open source projects to encourage updates, is to\nautomatically distribute (download) the patches and let the node operator\nknow an update has been downloaded for them, and let them know they're just\none step away from applying such update.\nWe do this for our bittorrent client. We don't ever want to do automatic\nupgrades of our network, however, we want to make it painless to update.\n\nFor Bitcoin this could be done for the official binary distribution, would\nnot be an option for those that build from source.\n\nOn Thu, Dec 15, 2016 at 11:49 AM Jorge Tim\u00f3n via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Thu, Dec 15, 2016 at 4:38 AM, Juan Garavaglia via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > Older node versions may generate issues because some upgrades will make\n> > several of the nodes running older protocol versions obsolete and or\n> > incompatible. There may be other hard to predict behaviors on older\n> versions\n> > of the client.\n>\n> Hard to predict or not, you can't force people to run newer software.\n>\n> > In order to avoid such wide fragmentation of \"Bitcoin Core\u201d node versions\n> > and to help there be a more predictable protocol improvement process, I\n> > consider it worth it to analyze introducing some planned obsolescence in\n> > each new version. In the last year we had 4 new versions so if each\n> version\n> > is valid for about 1 year (52560 blocks) this may be a reasonable time\n> frame\n> > for node operators to upgrade. If a node does not upgrade it will stop\n> > working instead of participating in the network with an outdated protocol\n> > version.\n>\n> When you introduce anti-features like this in free software they can\n> be trivially removed and they likely will.\n>\n> > These changes may also simplify the developer's jobs in some cases by\n> > avoiding them having to deal with ancient versions of the client.\n>\n> There's a simpler solution for this which is what is being done now:\n> stop maintaining and giving support for older versions.\n> There's limited resources and developers are rarely interested in\n> fixing bugs for very old versions. Users shouldn't expect things to be\n> backported to old versions (if developers do it and there's enough\n> testing, there's no reason not to do more releases of old versions, it\n> is just rarely the case).\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161215/9eb2ae06/attachment.html>"
            },
            {
                "author": "Ethan Heilman",
                "date": "2016-12-15T22:44:55",
                "message_text_only": "I assume this has been well discussed in at some point in the Bitcoin\ncommunity, so I apologize if I'm repeating old ideas.\n\nProblem exploitable nodes:\nIt is plausible that people running these versions of bitcoind may not\nbe applying patches. Thus, these nodes may be vulnerable to known\nexploits. I would hope none of these nodes are gateway nodes for\nminers, web wallets or exchanges. How difficult would it be to crawl\nthe network to find vulnerable nodes and exploit them? What percentage\nof the network is running vulnerable versions of bitcoind?\n\nProblem eclipsable nodes:\nCurrently a bitcoind node disconnects from any node with a version\nbelow MIN_PEER_PROTO_VERSION. Such nodes become be ripe for an eclipse\nattack because they are partitioned from the newer nodes, especially\nwhen they are \"freshly obsolete\". I have not examined how protocol\nversioning works in detail so I could be missing something.\n\nOne option could be that after a grace period:\n1. to still connect to obsolete nodes and even to transmit blockheaders,\n2. but to stop sending the full-blocks and transactions to these\nnodes, thereby alerting the operator that something is wrong and\ncausing them to upgrade.\nIt may make sense to create this as a rule, if your longest chain\nconsists of only blockheaders and no one will tell you the\ntransactions for over 1000 blocks you are obsolete, spit out an error\nmessage and shutdown.\n\nThis would not address the issue of alt-coins which are forked from\nold vulnerable versions of bitcoind, but that is probably out of\nscope.\n\nOn Thu, Dec 15, 2016 at 1:48 PM, Jorge Tim\u00f3n via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> On Thu, Dec 15, 2016 at 4:38 AM, Juan Garavaglia via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> Older node versions may generate issues because some upgrades will make\n>> several of the nodes running older protocol versions obsolete and or\n>> incompatible. There may be other hard to predict behaviors on older versions\n>> of the client.\n>\n> Hard to predict or not, you can't force people to run newer software.\n>\n>> In order to avoid such wide fragmentation of \"Bitcoin Core\u201d node versions\n>> and to help there be a more predictable protocol improvement process, I\n>> consider it worth it to analyze introducing some planned obsolescence in\n>> each new version. In the last year we had 4 new versions so if each version\n>> is valid for about 1 year (52560 blocks) this may be a reasonable time frame\n>> for node operators to upgrade. If a node does not upgrade it will stop\n>> working instead of participating in the network with an outdated protocol\n>> version.\n>\n> When you introduce anti-features like this in free software they can\n> be trivially removed and they likely will.\n>\n>> These changes may also simplify the developer's jobs in some cases by\n>> avoiding them having to deal with ancient versions of the client.\n>\n> There's a simpler solution for this which is what is being done now:\n> stop maintaining and giving support for older versions.\n> There's limited resources and developers are rarely interested in\n> fixing bugs for very old versions. Users shouldn't expect things to be\n> backported to old versions (if developers do it and there's enough\n> testing, there's no reason not to do more releases of old versions, it\n> is just rarely the case).\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Matt Corallo",
                "date": "2016-12-18T10:34:43",
                "message_text_only": "One thing which hasn't been addressed yet in this thread is developer centralization. Unlike other applications we want to ensure that it's not only possible for users to refuse an upgrade, but easy. While this by no means lessens the retirement that users run up to date software for security reasons, finding the right line to draw is difficult. \n\nMatt\n\nOn December 15, 2016 2:44:55 PM PST, Ethan Heilman via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>I assume this has been well discussed in at some point in the Bitcoin\n>community, so I apologize if I'm repeating old ideas.\n>\n>Problem exploitable nodes:\n>It is plausible that people running these versions of bitcoind may not\n>be applying patches. Thus, these nodes may be vulnerable to known\n>exploits. I would hope none of these nodes are gateway nodes for\n>miners, web wallets or exchanges. How difficult would it be to crawl\n>the network to find vulnerable nodes and exploit them? What percentage\n>of the network is running vulnerable versions of bitcoind?\n>\n>Problem eclipsable nodes:\n>Currently a bitcoind node disconnects from any node with a version\n>below MIN_PEER_PROTO_VERSION. Such nodes become be ripe for an eclipse\n>attack because they are partitioned from the newer nodes, especially\n>when they are \"freshly obsolete\". I have not examined how protocol\n>versioning works in detail so I could be missing something.\n>\n>One option could be that after a grace period:\n>1. to still connect to obsolete nodes and even to transmit\n>blockheaders,\n>2. but to stop sending the full-blocks and transactions to these\n>nodes, thereby alerting the operator that something is wrong and\n>causing them to upgrade.\n>It may make sense to create this as a rule, if your longest chain\n>consists of only blockheaders and no one will tell you the\n>transactions for over 1000 blocks you are obsolete, spit out an error\n>message and shutdown.\n>\n>This would not address the issue of alt-coins which are forked from\n>old vulnerable versions of bitcoind, but that is probably out of\n>scope.\n>\n>On Thu, Dec 15, 2016 at 1:48 PM, Jorge Tim\u00f3n via bitcoin-dev\n><bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> On Thu, Dec 15, 2016 at 4:38 AM, Juan Garavaglia via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> Older node versions may generate issues because some upgrades will\n>make\n>>> several of the nodes running older protocol versions obsolete and or\n>>> incompatible. There may be other hard to predict behaviors on older\n>versions\n>>> of the client.\n>>\n>> Hard to predict or not, you can't force people to run newer software.\n>>\n>>> In order to avoid such wide fragmentation of \"Bitcoin Core\u201d node\n>versions\n>>> and to help there be a more predictable protocol improvement\n>process, I\n>>> consider it worth it to analyze introducing some planned\n>obsolescence in\n>>> each new version. In the last year we had 4 new versions so if each\n>version\n>>> is valid for about 1 year (52560 blocks) this may be a reasonable\n>time frame\n>>> for node operators to upgrade. If a node does not upgrade it will\n>stop\n>>> working instead of participating in the network with an outdated\n>protocol\n>>> version.\n>>\n>> When you introduce anti-features like this in free software they can\n>> be trivially removed and they likely will.\n>>\n>>> These changes may also simplify the developer's jobs in some cases\n>by\n>>> avoiding them having to deal with ancient versions of the client.\n>>\n>> There's a simpler solution for this which is what is being done now:\n>> stop maintaining and giving support for older versions.\n>> There's limited resources and developers are rarely interested in\n>> fixing bugs for very old versions. Users shouldn't expect things to\n>be\n>> backported to old versions (if developers do it and there's enough\n>> testing, there's no reason not to do more releases of old versions,\n>it\n>> is just rarely the case).\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>_______________________________________________\n>bitcoin-dev mailing list\n>bitcoin-dev at lists.linuxfoundation.org\n>https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Chris Riley",
                "date": "2016-12-18T20:50:53",
                "message_text_only": "I agree that finding the right line is difficult and purposefully crippling\n(too strong a term?) the software is not necessarily the best way to\nencourage long term adoption.\n\nFor example, I ran version 0.3.x from July/August 2010 for several years on\na miner without upgrading to anything higher than the 0.3.24 release since\nthe usage pattern on that machine didn't require it.  It might have been to\nthe ~0.7.0 release, I am not sure when I finally upgraded it.  On a machine\nthat had my wallet, I kept it updated, but forcing upgrades may not be the\nbest plan given that hard forks should be few and far between.  Security\nupdates, are important, but leaving it up to the operator of the node to\ndetermine when to upgrade is an important feature.\n\nChris\n\n\nOn Sun, Dec 18, 2016 at 5:34 AM, Matt Corallo via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> One thing which hasn't been addressed yet in this thread is developer\n> centralization. Unlike other applications we want to ensure that it's not\n> only possible for users to refuse an upgrade, but easy. While this by no\n> means lessens the retirement that users run up to date software for\n> security reasons, finding the right line to draw is difficult.\n>\n> Matt\n>\n> On December 15, 2016 2:44:55 PM PST, Ethan Heilman via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >I assume this has been well discussed in at some point in the Bitcoin\n> >community, so I apologize if I'm repeating old ideas.\n> >\n> >Problem exploitable nodes:\n> >It is plausible that people running these versions of bitcoind may not\n> >be applying patches. Thus, these nodes may be vulnerable to known\n> >exploits. I would hope none of these nodes are gateway nodes for\n> >miners, web wallets or exchanges. How difficult would it be to crawl\n> >the network to find vulnerable nodes and exploit them? What percentage\n> >of the network is running vulnerable versions of bitcoind?\n> >\n> >Problem eclipsable nodes:\n> >Currently a bitcoind node disconnects from any node with a version\n> >below MIN_PEER_PROTO_VERSION. Such nodes become be ripe for an eclipse\n> >attack because they are partitioned from the newer nodes, especially\n> >when they are \"freshly obsolete\". I have not examined how protocol\n> >versioning works in detail so I could be missing something.\n> >\n> >One option could be that after a grace period:\n> >1. to still connect to obsolete nodes and even to transmit\n> >blockheaders,\n> >2. but to stop sending the full-blocks and transactions to these\n> >nodes, thereby alerting the operator that something is wrong and\n> >causing them to upgrade.\n> >It may make sense to create this as a rule, if your longest chain\n> >consists of only blockheaders and no one will tell you the\n> >transactions for over 1000 blocks you are obsolete, spit out an error\n> >message and shutdown.\n> >\n> >This would not address the issue of alt-coins which are forked from\n> >old vulnerable versions of bitcoind, but that is probably out of\n> >scope.\n> >\n> >On Thu, Dec 15, 2016 at 1:48 PM, Jorge Tim\u00f3n via bitcoin-dev\n> ><bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >> On Thu, Dec 15, 2016 at 4:38 AM, Juan Garavaglia via bitcoin-dev\n> >> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>> Older node versions may generate issues because some upgrades will\n> >make\n> >>> several of the nodes running older protocol versions obsolete and or\n> >>> incompatible. There may be other hard to predict behaviors on older\n> >versions\n> >>> of the client.\n> >>\n> >> Hard to predict or not, you can't force people to run newer software.\n> >>\n> >>> In order to avoid such wide fragmentation of \"Bitcoin Core\u201d node\n> >versions\n> >>> and to help there be a more predictable protocol improvement\n> >process, I\n> >>> consider it worth it to analyze introducing some planned\n> >obsolescence in\n> >>> each new version. In the last year we had 4 new versions so if each\n> >version\n> >>> is valid for about 1 year (52560 blocks) this may be a reasonable\n> >time frame\n> >>> for node operators to upgrade. If a node does not upgrade it will\n> >stop\n> >>> working instead of participating in the network with an outdated\n> >protocol\n> >>> version.\n> >>\n> >> When you introduce anti-features like this in free software they can\n> >> be trivially removed and they likely will.\n> >>\n> >>> These changes may also simplify the developer's jobs in some cases\n> >by\n> >>> avoiding them having to deal with ancient versions of the client.\n> >>\n> >> There's a simpler solution for this which is what is being done now:\n> >> stop maintaining and giving support for older versions.\n> >> There's limited resources and developers are rarely interested in\n> >> fixing bugs for very old versions. Users shouldn't expect things to\n> >be\n> >> backported to old versions (if developers do it and there's enough\n> >> testing, there's no reason not to do more releases of old versions,\n> >it\n> >> is just rarely the case).\n> >> _______________________________________________\n> >> bitcoin-dev mailing list\n> >> bitcoin-dev at lists.linuxfoundation.org\n> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >_______________________________________________\n> >bitcoin-dev mailing list\n> >bitcoin-dev at lists.linuxfoundation.org\n> >https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161218/8ef11efb/attachment.html>"
            },
            {
                "author": "Alice Wonder",
                "date": "2016-12-18T20:07:36",
                "message_text_only": "On 12/14/2016 07:38 PM, Juan Garavaglia via bitcoin-dev wrote:\n\n>\n> For reasons I am unable to determine a significant number of node\n> operators do not upgrade their clients.\n\nI almost did not update to 0.13.0 because the test suite was failing due \nto python errors. How to fix them was posted on bitcointalk.\n\n0.13.1 came with new python errors in the test suite. So I just said \nfuck it.\n\nWhen the test suite actually works in my fairly standard environment \n(CentOS) in the distributed release, I will upgrade.\n\nUntil then, I'm not jumping through hoops to make the test suite work \nand I'm not running clients that haven't passed the test suite so that's \nwhy I almost didn't update to 0.13.0 and haven't updated since."
            },
            {
                "author": "Matt Corallo",
                "date": "2016-12-19T02:22:21",
                "message_text_only": "Please do report bugs to https://github.com/bitcoin/bitcoin . If you never report them of course they won't get fixed. I'm not aware of test suite failures and know a bunch of folks who use CentOS, though not sure how many develop on it.\n\nOn December 18, 2016 12:07:36 PM PST, Alice Wonder via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>On 12/14/2016 07:38 PM, Juan Garavaglia via bitcoin-dev wrote:\n>\n>>\n>> For reasons I am unable to determine a significant number of node\n>> operators do not upgrade their clients.\n>\n>I almost did not update to 0.13.0 because the test suite was failing\n>due \n>to python errors. How to fix them was posted on bitcointalk.\n>\n>0.13.1 came with new python errors in the test suite. So I just said \n>fuck it.\n>\n>When the test suite actually works in my fairly standard environment \n>(CentOS) in the distributed release, I will upgrade.\n>\n>Until then, I'm not jumping through hoops to make the test suite work \n>and I'm not running clients that haven't passed the test suite so\n>that's \n>why I almost didn't update to 0.13.0 and haven't updated since.\n>_______________________________________________\n>bitcoin-dev mailing list\n>bitcoin-dev at lists.linuxfoundation.org\n>https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Btc Drak",
                "date": "2016-12-19T06:39:46",
                "message_text_only": "Maybe something trivial like lack of Python 3 dependency on older CentOS\nbuilds?\n\nOn Mon, Dec 19, 2016 at 2:22 AM, Matt Corallo via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Please do report bugs to https://github.com/bitcoin/bitcoin . If you\n> never report them of course they won't get fixed. I'm not aware of test\n> suite failures and know a bunch of folks who use CentOS, though not sure\n> how many develop on it.\n>\n> On December 18, 2016 12:07:36 PM PST, Alice Wonder via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >On 12/14/2016 07:38 PM, Juan Garavaglia via bitcoin-dev wrote:\n> >\n> >>\n> >> For reasons I am unable to determine a significant number of node\n> >> operators do not upgrade their clients.\n> >\n> >I almost did not update to 0.13.0 because the test suite was failing\n> >due\n> >to python errors. How to fix them was posted on bitcointalk.\n> >\n> >0.13.1 came with new python errors in the test suite. So I just said\n> >fuck it.\n> >\n> >When the test suite actually works in my fairly standard environment\n> >(CentOS) in the distributed release, I will upgrade.\n> >\n> >Until then, I'm not jumping through hoops to make the test suite work\n> >and I'm not running clients that haven't passed the test suite so\n> >that's\n> >why I almost didn't update to 0.13.0 and haven't updated since.\n> >_______________________________________________\n> >bitcoin-dev mailing list\n> >bitcoin-dev at lists.linuxfoundation.org\n> >https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161219/0236de0f/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Planned Obsolescence",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Chris Riley",
                "Aymeric Vitte",
                "Angel Leon",
                "Jorge Tim\u00f3n",
                "Btc Drak",
                "Ethan Heilman",
                "Matt Corallo",
                "jg at 112bit.com",
                "Alice Wonder"
            ],
            "messages_count": 10,
            "total_messages_chars_count": 26738
        }
    },
    {
        "title": "[bitcoin-dev] Python test suite failures (was Re: Planned Obsolescence)",
        "thread_messages": [
            {
                "author": "Douglas Roark",
                "date": "2016-12-18T20:51:00",
                "message_text_only": "On 2016/12/18 12:07, Alice Wonder via bitcoin-dev wrote:\n> I almost did not update to 0.13.0 because the test suite was failing due\n> to python errors. How to fix them was posted on bitcointalk.\n> \n> 0.13.1 came with new python errors in the test suite. So I just said\n> fuck it.\n> \n> When the test suite actually works in my fairly standard environment\n> (CentOS) in the distributed release, I will upgrade.\n\nCan you post more info about the problems you're seeing, how you fixed\nthem, your environment, etc., or at least post an issue on Github? I'm\nsure somebody would be happy to help. Some info on how to reproduce the\nproblems would be very helpful. :)\n\nThanks.\n\n-- \n---\nDouglas Roark\nCryptocurrency, network security, travel, and art.\nhttps://onename.com/droark\njoroark at vt.edu\nPGP key ID: 26623924\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 842 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161218/89f0aa67/attachment.sig>"
            },
            {
                "author": "Alice Wonder",
                "date": "2016-12-19T08:13:51",
                "message_text_only": "On 12/18/2016 12:51 PM, Douglas Roark via bitcoin-dev wrote:\n> On 2016/12/18 12:07, Alice Wonder via bitcoin-dev wrote:\n>> I almost did not update to 0.13.0 because the test suite was failing due\n>> to python errors. How to fix them was posted on bitcointalk.\n>>\n>> 0.13.1 came with new python errors in the test suite. So I just said\n>> fuck it.\n>>\n>> When the test suite actually works in my fairly standard environment\n>> (CentOS) in the distributed release, I will upgrade.\n>\n> Can you post more info about the problems you're seeing, how you fixed\n> them, your environment, etc., or at least post an issue on Github? I'm\n> sure somebody would be happy to help. Some info on how to reproduce the\n> problems would be very helpful. :)\n>\n> Thanks.\n\nFor 0.13.0 I had to do\n\nexport LANG=en_US.utf8\n\nbefore running the test suite. I build in clean chroot build environment \nto avoid accidental linking to non-standard libraries, and in that \nenvironment the LANG is normally set to C as LANG normally doesn't \nmatter for compiling software that is expected to run regardless of what \nthe LANG is.\n\nThat I believe was fixed in 0.13.1.\n\nIn 0.13.1 the error is\n\n\nRunning test/bitcoin-util-test.py...\nTraceback (most recent call last):\n   File \"./test/bitcoin-util-test.py\", line 12, in <module>\n     \"bitcoin-util-test.json\",buildenv)\n   File \"/builddir/build/BUILD/bitcoin-0.13.1/src/test/bctest.py\", line \n54, in bctester\n     bctest(testDir, testObj, buildenv.exeext)\n   File \"/builddir/build/BUILD/bitcoin-0.13.1/src/test/bctest.py\", line \n26, in bctest\n     outputData = open(testDir + \"/\" + outputFn).read()\nFileNotFoundError: [Errno 2] No such file or directory: \n'./test/data/blanktx.json'\nmake[3]: *** [check-local] Error 1\nmake[3]: Leaving directory `/builddir/build/BUILD/bitcoin-0.13.1/src'\nmake[2]: *** [check-am] Error 2\nmake[2]: Leaving directory `/builddir/build/BUILD/bitcoin-0.13.1/src'\nmake[1]: *** [check-recursive] Error 1\nmake[1]: Leaving directory `/builddir/build/BUILD/bitcoin-0.13.1/src'\nmake: *** [check-recursive] Error 1\n\n0.13.0 test works just fine (once the LANG is set to something utf8)"
            },
            {
                "author": "Marco Falke",
                "date": "2016-12-21T18:33:14",
                "message_text_only": "> In 0.13.1 the error is\n>\n>\n> Running test/bitcoin-util-test.py...\n> Traceback (most recent call last):\n>   File \"./test/bitcoin-util-test.py\", line 12, in <module>\n>     \"bitcoin-util-test.json\",buildenv)\n>   File \"/builddir/build/BUILD/bitcoin-0.13.1/src/test/bctest.py\", line 54,\n> in bctester\n>     bctest(testDir, testObj, buildenv.exeext)\n>   File \"/builddir/build/BUILD/bitcoin-0.13.1/src/test/bctest.py\", line 26,\n> in bctest\n>     outputData = open(testDir + \"/\" + outputFn).read()\n> FileNotFoundError: [Errno 2] No such file or directory:\n> './test/data/blanktx.json'\n\n\nThis was a known problem on the *master* branch. If you still\nencounter any issues on the current 0.13.2 release candidate, please\nlet us know in https://github.com/bitcoin/bitcoin/issues/9394. (Make\nsure to include the version of centos you are running)"
            }
        ],
        "thread_summary": {
            "title": "Python test suite failures (was Re: Planned Obsolescence)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Douglas Roark",
                "Alice Wonder",
                "Marco Falke"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 4042
        }
    },
    {
        "title": "[bitcoin-dev] Multisig with hashes instead of pubkeys",
        "thread_messages": [
            {
                "author": "Andrew",
                "date": "2016-12-22T18:29:07",
                "message_text_only": "Hi\n\nIs there a worked out scriptPubKey for doing multisig with just hashes\nof the participants? I think it is doable and it is more secure to a\ncompromised ECDSA. I'm thinking something like this for the\nscriptPubKey:\n 2 OP_SWAP OP_SWAP OP_SWAP OP_DUP OP_HASH160 <pubKeyHash1>\nOP_EQUALVERIFY OP_DUP OP_HASH160 <pubKeyHash2> OP_EQUALVERIFY OP_DUP\nOP_HASH160 <pubKeyHash3> OP_EQUALVERIFY 3 OP_CHECKMULTISIG\n\nand <sigs><pubkeys> for the scriptSig\n\nCan anyone confirm or send me a link to the worked out script?\n\nThanks\n\n-- \nPGP: B6AC 822C 451D 6304 6A28  49E9 7DB7 011C D53B 5647"
            },
            {
                "author": "Nick ODell",
                "date": "2016-12-23T17:35:49",
                "message_text_only": "The first issue is that doing two OP_SWAP's in a row will just return\nyou to the original state. The second issue is that all of them end up\nhashing the same key, so anyone on the network can spend this output.\n(See https://en.bitcoin.it/wiki/Script for a good resource on opcodes\nand what each of them do. There are also a few simulators floating\naround, but I can't recommend any in particular.)\n\nThird, if you're concerned about exposing public keys, why not use a\nP2SH script? That won't expose your public keys until you spend from\nit.\n\nOn Thu, Dec 22, 2016 at 11:29 AM, Andrew via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Hi\n>\n> Is there a worked out scriptPubKey for doing multisig with just hashes\n> of the participants? I think it is doable and it is more secure to a\n> compromised ECDSA. I'm thinking something like this for the\n> scriptPubKey:\n>  2 OP_SWAP OP_SWAP OP_SWAP OP_DUP OP_HASH160 <pubKeyHash1>\n> OP_EQUALVERIFY OP_DUP OP_HASH160 <pubKeyHash2> OP_EQUALVERIFY OP_DUP\n> OP_HASH160 <pubKeyHash3> OP_EQUALVERIFY 3 OP_CHECKMULTISIG\n>\n> and <sigs><pubkeys> for the scriptSig\n>\n> Can anyone confirm or send me a link to the worked out script?\n>\n> Thanks\n>\n> --\n> PGP: B6AC 822C 451D 6304 6A28  49E9 7DB7 011C D53B 5647\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Matthew Roberts",
                "date": "2016-12-23T18:21:43",
                "message_text_only": "The following won't be directly applicable to your question without some\nkind of tremendous hacking on your part: but in cryptography there is\nactually a way to sign a message using only hash functions.\n\nIf you're interested look up the definition for \"Lamport Signatures.\" It's\nan algorithm for masking the bits of a message by exchanging a table of\nhashes prior to signing and then revealing the \"secrets\" behind said hashes\nin such a way that you can selectively mask the bits of the message hash\nthat you're wishing to sign.\n\nIt's actually a really cool algorithm and probably the most elegant thing\nI've ever seen in the way of digital signatures - and besides just being\nsomething that's really cool: Lamport Signatures have the advantage of\nbeing quantum safe too (if you care about that kind of thing.)\n\nTo actually answer your question indirectly: you would use a consensus\nsystem that understands Lamport signature operations in the \"scriptPubKey\"\n(Ethereum could probably do this now.) And note that as Nick ODell has\nalready said: using the hashes alone in this scheme won't work since the\nmoment you publish the transactions with said hash secrets anyone is then\nfree to pluck out those values and double spend the original transaction to\na new destination (and this is actually the reason why Peter Todd's\nproof-of-hash collision scheme in Bitcoin is insecure but still allows us\nto incentivize whether or not there may be a flaw with the recent SHA\nalgorithms.)\n\nRegarding hash protected M of N multi-sig: there is already a similar smart\ncontract algorithm called \"atomic cross-chain contracts\" that relies on\nhash values to be released as part of the protocol to swap coins across\nblockchains but said algorithm also uses ECDSA public keys to prevent the\ntransactions from being double-spent. So in Bitcoin Multi-sig using hash\nvalues will work - though you still need to include an ECDSA pub key to\nprotect them from attackers on the network.\n\n(I hope this helps. You didn't say much about the intended use-case for\nthis.)\n\nOn Fri, Dec 23, 2016 at 4:29 AM, Andrew via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi\n>\n> Is there a worked out scriptPubKey for doing multisig with just hashes\n> of the participants? I think it is doable and it is more secure to a\n> compromised ECDSA. I'm thinking something like this for the\n> scriptPubKey:\n>  2 OP_SWAP OP_SWAP OP_SWAP OP_DUP OP_HASH160 <pubKeyHash1>\n> OP_EQUALVERIFY OP_DUP OP_HASH160 <pubKeyHash2> OP_EQUALVERIFY OP_DUP\n> OP_HASH160 <pubKeyHash3> OP_EQUALVERIFY 3 OP_CHECKMULTISIG\n>\n> and <sigs><pubkeys> for the scriptSig\n>\n> Can anyone confirm or send me a link to the worked out script?\n>\n> Thanks\n>\n> --\n> PGP: B6AC 822C 451D 6304 6A28  49E9 7DB7 011C D53B 5647\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161224/1926b5e7/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Multisig with hashes instead of pubkeys",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Nick ODell",
                "Andrew",
                "Matthew Roberts"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 5142
        }
    }
]