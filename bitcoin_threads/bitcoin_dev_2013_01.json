[
    {
        "title": "[Bitcoin-development] Draft BIP for Bloom filtering",
        "thread_messages": [
            {
                "author": "Mike Hearn",
                "date": "2013-01-10T15:21:14",
                "message_text_only": "Here's a quick update on where we're up to.\n\nThanks to Matts excellent work, I was able to test his bitcoinj and\nbitcoin-qt work together today. There are a few minor tweaks needed,\nbut I feel like we're maybe a week away from having all the code in a\nmergeable state. Here is the remaining work:\n\n- There are a couple of bugfixes needed on the bitcoinj side: the\nfallback to downloading full blocks is problematic and needs to be\ndeleted, there's an API change we want\n\n- Adjust the default FP rate requested by BCJ to be 0.0001, this is\nappropriate for the latest blocks in the chain and yields 0-5 false\npositives per block\n\n- Introduce a new part to the filter protocol that allows clients to\ncontrol auto-expansion. This turned out to be very volatile, we saw\njumps from 0-3 FPs per block to 500 in the space of 1 block, perhaps\nif a SatoshiDice transaction got into the filter. A simple yes/no flag\ncan suffice for now, but a better solution would be for the client to\nsubmit templates for output scripts that would trigger auto-adding the\nmatched outpoint - autoexpansion is only needed in the case where the\ninput script doesn't contain any predictable data. For pay-to-address\nand P2SH it does, so expansion doesn't help. Matt said he'd hopefully\ntry to look at this soon.\n\nWith auto-expansion disabled, the FP rate adjusted and a bugfix on the\nbcj side I was able to sync a wallet using a bloom filtered chain.\n\nAlthough it's tight, I think this work should go into 0.8 - it'll be\nmuch more compelling to advertise it this way, we can say \"Upgrade to\n0.8 and help network performance for everyone\". And in the case that\nwe discover a showstopper problem, we just don't deploy the code that\nuses the new messages into clients."
            },
            {
                "author": "Matt Corallo",
                "date": "2013-01-11T03:59:11",
                "message_text_only": "On Thu, 2013-01-10 at 16:21 +0100, Mike Hearn wrote:\n> Here's a quick update on where we're up to.\n> \n> Thanks to Matts excellent work, I was able to test his bitcoinj and\n> bitcoin-qt work together today. There are a few minor tweaks needed,\n> but I feel like we're maybe a week away from having all the code in a\n> mergeable state. Here is the remaining work:\n> \n> - There are a couple of bugfixes needed on the bitcoinj side: the\n> fallback to downloading full blocks is problematic and needs to be\n> deleted, there's an API change we want\nFirst of the two is done.\n> \n> - Adjust the default FP rate requested by BCJ to be 0.0001, this is\n> appropriate for the latest blocks in the chain and yields 0-5 false\n> positives per block\nIs a part of the larger API changes mentioned above.\n> \n> - Introduce a new part to the filter protocol that allows clients to\n> control auto-expansion. This turned out to be very volatile, we saw\n> jumps from 0-3 FPs per block to 500 in the space of 1 block, perhaps\n> if a SatoshiDice transaction got into the filter. A simple yes/no flag\n> can suffice for now, but a better solution would be for the client to\n> submit templates for output scripts that would trigger auto-adding the\n> matched outpoint - autoexpansion is only needed in the case where the\n> input script doesn't contain any predictable data. For pay-to-address\n> and P2SH it does, so expansion doesn't help. Matt said he'd hopefully\n> try to look at this soon.\nThe flags mentioned have been implemented, both to disable\nautoexpansion, enable it for all outputs, enable for only pay to pubkey\noutputs (the most likely use-case), or use a set of templates.  The\nmatched templates part isn't properly tested and I would like comments\non that part (see the last few commits at\nhttps://github.com/bitcoin/bitcoin/pull/1795).\n> \n> With auto-expansion disabled, the FP rate adjusted and a bugfix on the\n> bcj side I was able to sync a wallet using a bloom filtered chain.\n> \n> Although it's tight, I think this work should go into 0.8 - it'll be\n> much more compelling to advertise it this way, we can say \"Upgrade to\n> 0.8 and help network performance for everyone\". And in the case that\n> we discover a showstopper problem, we just don't deploy the code that\n> uses the new messages into clients.\nIve been missing lately, when is 0.8 targeted for freeze?\n\nMatt"
            },
            {
                "author": "Jeff Garzik",
                "date": "2013-01-11T05:02:47",
                "message_text_only": "On Thu, Jan 10, 2013 at 10:59 PM, Matt Corallo <bitcoin-list at bluematt.me> wrote:\n> Ive been missing lately, when is 0.8 targeted for freeze?\n\n0.8rc1 will probably happen when the core ultraprune/leveldb stuff is stable.\n\n-- \nJeff Garzik\nexMULTI, Inc.\njgarzik at exmulti.com"
            },
            {
                "author": "Mike Hearn",
                "date": "2013-01-11T14:11:44",
                "message_text_only": "I did some very rough initial performance tests.\n\nSyncing from a local peer gives me about 50 blocks per second in the\nlater parts of the chain (post SD), which is about a 10-20x speedup\nover what I could do before. This is on a MacBook Pro. But at those\npoints it's clearly bottlenecked by bitcoind which has saturated its\nCPU core. This makes sense - the filtering is much more server than\nclient intensive because every transaction in every block has to be\nloaded and checked.\n\nI think filtering can be fairly well parallelized on the server side.\nSo the current 10-20x speedup could potentially be larger if the\nserver becomes more efficient at scanning and filtering blocks. It's\nstill a very nice win for now, especially bandwidth wise. And if Matt\nmakes the mempool command filtered it solves a common usability\nproblem as well.\n\nOnce we get this code in, merged and rolled out I think what we need\nfor bloom v2 is clear:\n\n - Multi-thread the filtering process in bitcoind so transactions can\nbe checked in parallel. A 4-core server would then get 4x faster at\nfiltering blocks and assuming it's not too busy doing other stuff we\ncould maybe sync at more like 200 blocks per second, which is cool ...\nmore than a days worth of history for each second of syncing.\n\n - Make the client smarter so the FP rate is adapted during the sync\nprocess. An FP rate that makes sense post-SD results in no false\npositives pre-SD, more or less.\n\n - Make the client shard its wallet keys over multiple peers, for\nbetter privacy.\n\n - Make the client suck down filtered blocks in parallel from multiple\npeers, for better speed.\n\nAs it seems the bottleneck for chain sync is now CPU time, the latter\npoint may be the most important from a practical perspective.\n\nOn Fri, Jan 11, 2013 at 6:02 AM, Jeff Garzik <jgarzik at exmulti.com> wrote:\n> On Thu, Jan 10, 2013 at 10:59 PM, Matt Corallo <bitcoin-list at bluematt.me> wrote:\n>> Ive been missing lately, when is 0.8 targeted for freeze?\n>\n> 0.8rc1 will probably happen when the core ultraprune/leveldb stuff is stable.\n>\n> --\n> Jeff Garzik\n> exMULTI, Inc.\n> jgarzik at exmulti.com"
            },
            {
                "author": "Mike Hearn",
                "date": "2013-01-11T14:13:15",
                "message_text_only": "Oh, one last stat - syncing the entire chain with a wallet containing\ntwo keys and a 0.0001 FP rate (one or two FPs every 5 blocks or so)\nresulted in a download of about 46mb of data.\n\nOn Fri, Jan 11, 2013 at 3:11 PM, Mike Hearn <mike at plan99.net> wrote:\n> I did some very rough initial performance tests.\n>\n> Syncing from a local peer gives me about 50 blocks per second in the\n> later parts of the chain (post SD), which is about a 10-20x speedup\n> over what I could do before. This is on a MacBook Pro. But at those\n> points it's clearly bottlenecked by bitcoind which has saturated its\n> CPU core. This makes sense - the filtering is much more server than\n> client intensive because every transaction in every block has to be\n> loaded and checked.\n>\n> I think filtering can be fairly well parallelized on the server side.\n> So the current 10-20x speedup could potentially be larger if the\n> server becomes more efficient at scanning and filtering blocks. It's\n> still a very nice win for now, especially bandwidth wise. And if Matt\n> makes the mempool command filtered it solves a common usability\n> problem as well.\n>\n> Once we get this code in, merged and rolled out I think what we need\n> for bloom v2 is clear:\n>\n>  - Multi-thread the filtering process in bitcoind so transactions can\n> be checked in parallel. A 4-core server would then get 4x faster at\n> filtering blocks and assuming it's not too busy doing other stuff we\n> could maybe sync at more like 200 blocks per second, which is cool ...\n> more than a days worth of history for each second of syncing.\n>\n>  - Make the client smarter so the FP rate is adapted during the sync\n> process. An FP rate that makes sense post-SD results in no false\n> positives pre-SD, more or less.\n>\n>  - Make the client shard its wallet keys over multiple peers, for\n> better privacy.\n>\n>  - Make the client suck down filtered blocks in parallel from multiple\n> peers, for better speed.\n>\n> As it seems the bottleneck for chain sync is now CPU time, the latter\n> point may be the most important from a practical perspective.\n>\n> On Fri, Jan 11, 2013 at 6:02 AM, Jeff Garzik <jgarzik at exmulti.com> wrote:\n>> On Thu, Jan 10, 2013 at 10:59 PM, Matt Corallo <bitcoin-list at bluematt.me> wrote:\n>>> Ive been missing lately, when is 0.8 targeted for freeze?\n>>\n>> 0.8rc1 will probably happen when the core ultraprune/leveldb stuff is stable.\n>>\n>> --\n>> Jeff Garzik\n>> exMULTI, Inc.\n>> jgarzik at exmulti.com"
            },
            {
                "author": "Mike Hearn",
                "date": "2013-01-16T10:43:55",
                "message_text_only": "Matts latest code has been tested by Andreas and seems to work\ncorrectly. He had to extend the client a bit to refresh the filter\nevery 25k blocks because even with the extra flag, eventually the\nfilter degrades into uselessness, but it did still improve the\nsituation quite a bit.\n\nBecause it's unit tested, been reviewed by me several times, has an\ninteroperable implementation that has also been tested by Andreas in a\nbuild of his smartphone app,  I'm going to ACK the current code and\nrequest that it be merged in to 0.8. What do you say Gavin?\n\nThe next step after that would be profiling. It's a big performance\nimprovement for SPV clients already, but not as much as I anticipated.\nI suspect there's a simple bottleneck or missed optimization\nsomewhere. But that can obviously come post-0.8"
            },
            {
                "author": "Matt Corallo",
                "date": "2013-01-16T15:00:47",
                "message_text_only": "Actually, there is one more minor algorithmic change I would like to\nmake to the way the hash function is computed really quick before it\ngets merged, I'll have that finished up by the end of today.\n\nMatt\n\nOn Wed, 2013-01-16 at 11:43 +0100, Mike Hearn wrote:\n> Matts latest code has been tested by Andreas and seems to work\n> correctly. He had to extend the client a bit to refresh the filter\n> every 25k blocks because even with the extra flag, eventually the\n> filter degrades into uselessness, but it did still improve the\n> situation quite a bit.\n> \n> Because it's unit tested, been reviewed by me several times, has an\n> interoperable implementation that has also been tested by Andreas in a\n> build of his smartphone app,  I'm going to ACK the current code and\n> request that it be merged in to 0.8. What do you say Gavin?\n> \n> The next step after that would be profiling. It's a big performance\n> improvement for SPV clients already, but not as much as I anticipated.\n> I suspect there's a simple bottleneck or missed optimization\n> somewhere. But that can obviously come post-0.8"
            },
            {
                "author": "Mike Hearn",
                "date": "2013-01-18T16:38:45",
                "message_text_only": "I'm thinking we should actually make the change we talked about before\nand have the filtered block sent before the transaction data.\n\nFor one, it's not intuitive (API wise) that you'd get a callback\nsaying \"new pending tx\" immediately before another callback saying \"tx\nwas confirmed\", but that's what the current setup makes most natural.\nTo fix it we'd have to notice that a tx message wasn't requested by\nus, buffer it, and wait for the corresponding filteredblock message.\nIt seems cleaner to receive a filteredblock and then for any tx that\nmatches it, attach it to the FilteredBlock object and wait until it is\nfull up, then pass it to the wallet code all at once.\n\nAnother issue is that to risk analyze unconfirmed transactions you\nreally have to download all dependencies. That has to be triggered by\nseeing an unconfirmed transaction. It's dumb to start this process for\na tx that is actually in the chain, so you need to have some notion of\nwhether it came from a filtered block anyway. I only realized this\ntoday.\n\nI think when we discussed this before, the justification for having it\nwork the current way was that it was simpler to integrate with the SPV\nclient code if it was done this way around. But I don't think it's\nreally simpler. There are enough odd side effects of doing it this\nway, that I feel it'd be better to tweak the protocol now whilst we\nhave the chance.\n\nOn Wed, Jan 16, 2013 at 4:00 PM, Matt Corallo <bitcoin-list at bluematt.me> wrote:\n> Actually, there is one more minor algorithmic change I would like to\n> make to the way the hash function is computed really quick before it\n> gets merged, I'll have that finished up by the end of today.\n>\n> Matt\n>\n> On Wed, 2013-01-16 at 11:43 +0100, Mike Hearn wrote:\n>> Matts latest code has been tested by Andreas and seems to work\n>> correctly. He had to extend the client a bit to refresh the filter\n>> every 25k blocks because even with the extra flag, eventually the\n>> filter degrades into uselessness, but it did still improve the\n>> situation quite a bit.\n>>\n>> Because it's unit tested, been reviewed by me several times, has an\n>> interoperable implementation that has also been tested by Andreas in a\n>> build of his smartphone app,  I'm going to ACK the current code and\n>> request that it be merged in to 0.8. What do you say Gavin?\n>>\n>> The next step after that would be profiling. It's a big performance\n>> improvement for SPV clients already, but not as much as I anticipated.\n>> I suspect there's a simple bottleneck or missed optimization\n>> somewhere. But that can obviously come post-0.8\n>\n>"
            },
            {
                "author": "Andreas Schildbach",
                "date": "2013-01-19T09:51:04",
                "message_text_only": "Matt, I saw your commit and immediately started using it for testing.\nNow I think the bitcoinj side needs some love because not one\ntransaction is being confirmed (all just pending) when replaying the\nblockchain.\n\n\nOn 01/18/2013 05:38 PM, Mike Hearn wrote:\n> I'm thinking we should actually make the change we talked about before\n> and have the filtered block sent before the transaction data.\n> \n> For one, it's not intuitive (API wise) that you'd get a callback\n> saying \"new pending tx\" immediately before another callback saying \"tx\n> was confirmed\", but that's what the current setup makes most natural.\n> To fix it we'd have to notice that a tx message wasn't requested by\n> us, buffer it, and wait for the corresponding filteredblock message.\n> It seems cleaner to receive a filteredblock and then for any tx that\n> matches it, attach it to the FilteredBlock object and wait until it is\n> full up, then pass it to the wallet code all at once.\n> \n> Another issue is that to risk analyze unconfirmed transactions you\n> really have to download all dependencies. That has to be triggered by\n> seeing an unconfirmed transaction. It's dumb to start this process for\n> a tx that is actually in the chain, so you need to have some notion of\n> whether it came from a filtered block anyway. I only realized this\n> today.\n> \n> I think when we discussed this before, the justification for having it\n> work the current way was that it was simpler to integrate with the SPV\n> client code if it was done this way around. But I don't think it's\n> really simpler. There are enough odd side effects of doing it this\n> way, that I feel it'd be better to tweak the protocol now whilst we\n> have the chance.\n> \n> On Wed, Jan 16, 2013 at 4:00 PM, Matt Corallo <bitcoin-list at bluematt.me> wrote:\n>> Actually, there is one more minor algorithmic change I would like to\n>> make to the way the hash function is computed really quick before it\n>> gets merged, I'll have that finished up by the end of today.\n>>\n>> Matt\n>>\n>> On Wed, 2013-01-16 at 11:43 +0100, Mike Hearn wrote:\n>>> Matts latest code has been tested by Andreas and seems to work\n>>> correctly. He had to extend the client a bit to refresh the filter\n>>> every 25k blocks because even with the extra flag, eventually the\n>>> filter degrades into uselessness, but it did still improve the\n>>> situation quite a bit.\n>>>\n>>> Because it's unit tested, been reviewed by me several times, has an\n>>> interoperable implementation that has also been tested by Andreas in a\n>>> build of his smartphone app,  I'm going to ACK the current code and\n>>> request that it be merged in to 0.8. What do you say Gavin?\n>>>\n>>> The next step after that would be profiling. It's a big performance\n>>> improvement for SPV clients already, but not as much as I anticipated.\n>>> I suspect there's a simple bottleneck or missed optimization\n>>> somewhere. But that can obviously come post-0.8\n>>\n>>\n> \n> ------------------------------------------------------------------------------\n> Master HTML5, CSS3, ASP.NET, MVC, AJAX, Knockout.js, Web API and\n> much more. Get web development skills now with LearnDevNow -\n> 350+ hours of step-by-step video tutorials by Microsoft MVPs and experts.\n> SALE $99.99 this month only -- learn more at:\n> http://p.sf.net/sfu/learnmore_122812\n>"
            },
            {
                "author": "Mike Hearn",
                "date": "2013-01-30T11:09:55",
                "message_text_only": "Andreas has uploaded Android builds that use the new bloom filtering and\npeer selection code (also, dependency analysis of transactions).\n\nThe performance gain is very cool. The app feels dramatically faster to\nstart up and sync. Because the app syncs on charge when I opened it around\nlunchtime it had only 7 hours of data to sync (42 blocks) and it brought up\n6 peer connections, found a 0.7.99 node and synced all in <2 seconds. That\nwas on wifi.\n\nThe next lowest hanging perf fruit is almost certainly to optimize disk\naccesses. Flash on Android devices seems to be much slower than laptop\nflash storage, and current bitcoinj is very inefficient in how it writes\n(one write per block header!). This matters a lot when doing fast catchup\nfor first time users.\n\nThe BIP is now a little bit stale, but only slightly.\n\n\nOn Wed, Jan 16, 2013 at 4:00 PM, Matt Corallo <bitcoin-list at bluematt.me>wrote:\n\n> Actually, there is one more minor algorithmic change I would like to\n> make to the way the hash function is computed really quick before it\n> gets merged, I'll have that finished up by the end of today.\n>\n> Matt\n>\n> On Wed, 2013-01-16 at 11:43 +0100, Mike Hearn wrote:\n> > Matts latest code has been tested by Andreas and seems to work\n> > correctly. He had to extend the client a bit to refresh the filter\n> > every 25k blocks because even with the extra flag, eventually the\n> > filter degrades into uselessness, but it did still improve the\n> > situation quite a bit.\n> >\n> > Because it's unit tested, been reviewed by me several times, has an\n> > interoperable implementation that has also been tested by Andreas in a\n> > build of his smartphone app,  I'm going to ACK the current code and\n> > request that it be merged in to 0.8. What do you say Gavin?\n> >\n> > The next step after that would be profiling. It's a big performance\n> > improvement for SPV clients already, but not as much as I anticipated.\n> > I suspect there's a simple bottleneck or missed optimization\n> > somewhere. But that can obviously come post-0.8\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20130130/0408881f/attachment.html>"
            },
            {
                "author": "Mike Hearn",
                "date": "2013-01-30T11:13:14",
                "message_text_only": "Sorry, to clarify, these are test builds available here:\n\n\nhttps://code.google.com/p/bitcoin-wallet/downloads/detail?name=bitcoin-wallet-2.39_bitcoinj0.7.apk&can=2&q=\n\nIt's not on the Play store yet. It probably makes sense to release after\nsome more testing and after Bitcoin 0.8 comes out, as otherwise there's a\nrisk that 0.7 snapshot nodes will get overloaded.\n\n\nOn Wed, Jan 30, 2013 at 12:09 PM, Mike Hearn <mike at plan99.net> wrote:\n\n> Andreas has uploaded Android builds that use the new bloom filtering and\n> peer selection code (also, dependency analysis of transactions).\n>\n> The performance gain is very cool. The app feels dramatically faster to\n> start up and sync. Because the app syncs on charge when I opened it around\n> lunchtime it had only 7 hours of data to sync (42 blocks) and it brought up\n> 6 peer connections, found a 0.7.99 node and synced all in <2 seconds. That\n> was on wifi.\n>\n> The next lowest hanging perf fruit is almost certainly to optimize disk\n> accesses. Flash on Android devices seems to be much slower than laptop\n> flash storage, and current bitcoinj is very inefficient in how it writes\n> (one write per block header!). This matters a lot when doing fast catchup\n> for first time users.\n>\n> The BIP is now a little bit stale, but only slightly.\n>\n>\n> On Wed, Jan 16, 2013 at 4:00 PM, Matt Corallo <bitcoin-list at bluematt.me>wrote:\n>\n>> Actually, there is one more minor algorithmic change I would like to\n>> make to the way the hash function is computed really quick before it\n>> gets merged, I'll have that finished up by the end of today.\n>>\n>> Matt\n>>\n>> On Wed, 2013-01-16 at 11:43 +0100, Mike Hearn wrote:\n>> > Matts latest code has been tested by Andreas and seems to work\n>> > correctly. He had to extend the client a bit to refresh the filter\n>> > every 25k blocks because even with the extra flag, eventually the\n>> > filter degrades into uselessness, but it did still improve the\n>> > situation quite a bit.\n>> >\n>> > Because it's unit tested, been reviewed by me several times, has an\n>> > interoperable implementation that has also been tested by Andreas in a\n>> > build of his smartphone app,  I'm going to ACK the current code and\n>> > request that it be merged in to 0.8. What do you say Gavin?\n>> >\n>> > The next step after that would be profiling. It's a big performance\n>> > improvement for SPV clients already, but not as much as I anticipated.\n>> > I suspect there's a simple bottleneck or missed optimization\n>> > somewhere. But that can obviously come post-0.8\n>>\n>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20130130/bb050d2a/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Draft BIP for Bloom filtering",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Jeff Garzik",
                "Mike Hearn",
                "Matt Corallo",
                "Andreas Schildbach"
            ],
            "messages_count": 11,
            "total_messages_chars_count": 21655
        }
    },
    {
        "title": "[Bitcoin-development] BitCoin and MinorFs/AppArmor",
        "thread_messages": [
            {
                "author": "Rob Meijer",
                "date": "2013-01-10T17:41:21",
                "message_text_only": "My efforts on MinorFs2 have been stalled for a large period of time\n(resulting from the fact that I was writing it in Python and Google\npulling the plug on its codesearch server showed me that Python was a\nlanguage that I hadn't sufficiently mastered. Recently, after almost a\nyear of reluctance at starting from scratch, I finaly set myself to\nrewriting what I had done so far in C++ and to continue development.\n\nYesterday I've also started at a library for making the usage of MinorFs\nby applications like Bitcoin more convenient. The idea is that LibMinorFs\nwill become a simple to use library for making applications\nMinorFs2-aware.\n\nI would like to ask if the bitcoin developers would be open to using\nthis library within bitcoin for making BitCoin MinorFs2 aware, allowing it\nto store things like the BitCoin purse in a private directory that is not\navailable to other unrelated (potentially trojan) processes running under\nthe same uid.\n\nThe API is defined in the inc/minorfs/ directory and the usage shown in\nsrc/testmain.cpp\n\nhttps://github.com/pibara/LibMinorFs2\n\nBoth the library and the filesystems are still far from being done, but I\nwould like to know if you guys would be open to a pull-request that would\nincorporate a copy of this library into Bitcoin, making BitCoin use\nprivate storage when available, implemented using the above API.\n\nPlease let me know what you think.\n\nRob\n\n\n\nOn Fri, August 26, 2011 08:48, Rob Meijer wrote:\n> A few years ago I wrote a least authority based set of filesystems named\n> MinorFs that worked closely together with AppArmor (suse/ubuntu) to give '\n> pseudo persistent processes' their own private but decomposable and\n> delegatable piece of filesystem storage:\n>\n> http://www.linuxjournal.com/magazine/minorfs\n> http://www.capibara.com/blog/2011/05/25/taming-mutable-state-for-file-systems/\n>\n> Currently there is only one perfect fit for MinorFs and that's the stack\n> AppArmor/MinorFs/E-language-persistent-application. There are some close\n> fits like running ssh without a passphrase (\n> http://minorfs.polacanthus.net/wiki/Ssh_private_keys_without_passphrase )\n> but these require lots of manual fiddling by the user to get working. The\n> ssh trick would probably work with bitcoin, but as you can see from the\n> link above, it would be rather cumbersome.\n>\n> I am trying to get specs together for rewriting MinorFs (in Python) in a\n> way that would make it easy and natural for application developers that\n> want their application to be able to protect user data (like bitcoin\n> wallets) from mallware running under the same uid as that user.\n>\n> Currently minorfs granularity is hard fixed to that of the 'pseudo\n> persistent process', and that granularity is determined as described in\n> the following link:\n>\n> http://minorfs.polacanthus.net/wiki/Pseudo_persistent_process\n>\n> When using pseudo persistent processes, you basically end up with\n> file-system storage that follows almost all of the modeling principles of\n> the object capability model. This is great when designing a least\n> authority program from scratch and writing it in the (object capability)\n> e-language using its persistence facilities.\n>\n> Given however that I don't expect bitcoin, openssh, chrome, firefox, or\n> any other application that would benefit from what MinorFs provides to be\n> rewritten in E, it seems like the next version of MinorFs should give up\n> on the purity of its least authority model, and take an approach that\n> better suits common development languages and practices.\n>\n> With bitcoin being a project that could benefit most from what MinorFs has\n> to offer, I would like to ask bitcoin developers to think about what\n> attributes from the current granularity level (pseudo persistent process)\n> should be kept, what attributes should be dropped, and what properties\n> should be added to arrive at an 'id' that is the best fit for granularity\n> of persistent private storage for bitcoin.\n>\n> I really want to accommodate bitcoin developer needs in this, so all input\n> that helps me help you guys to get the next MinorFs version to accommodate\n> your needs to a level that code to use MinorFs where available can be\n> added to bitcoin, would be extremely welcome.\n>\n> Let me know what you think,\n>\n> Rob\n>\n>\n> ------------------------------------------------------------------------------\n> EMC VNX: the world's simplest storage, starting under $10K\n> The only unified storage solution that offers unified management\n> Up to 160% more powerful than alternatives and 25% more efficient.\n> Guaranteed. http://p.sf.net/sfu/emc-vnx-dev2dev\n> _______________________________________________\n> Bitcoin-development mailing list\n> Bitcoin-development at lists.sourceforge.net\n> https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n>\n>"
            }
        ],
        "thread_summary": {
            "title": "BitCoin and MinorFs/AppArmor",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Rob Meijer"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4799
        }
    },
    {
        "title": "[Bitcoin-development] Proposal: make the private key for testnet genesis block public",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2013-01-14T10:44:47",
                "message_text_only": "As the title says.\n\nBasically on testnet we should give people the chance to test how their\ncode handles attempts to spend the genesis block coinbase, as well as\nother tx's made to the genesis block address. After all, potentially\nSatoshi is still out there, still has that key, and still may cause\nexactly that situation himself.\n\nSo Gavin, if you have the private key for testnet3's coinbase, I'm\nasking you to release it, and otherwise fix this for the eventual\ntestnet4\n\nOf course, obviously you can test this case yourself with a private\ntestnet, but it'd be good if people we forced to test this case against\ntheir will...\n\n-- \n'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20130114/f1bde735/attachment.sig>"
            },
            {
                "author": "Jeff Garzik",
                "date": "2013-01-14T18:07:28",
                "message_text_only": "On Mon, Jan 14, 2013 at 5:44 AM, Peter Todd <pete at petertodd.org> wrote:\n> Basically on testnet we should give people the chance to test how their\n> code handles attempts to spend the genesis block coinbase, as well as\n> other tx's made to the genesis block address. After all, potentially\n> Satoshi is still out there, still has that key, and still may cause\n> exactly that situation himself.\n\nACK\n\n-- \nJeff Garzik\nexMULTI, Inc.\njgarzik at exmulti.com"
            },
            {
                "author": "Gavin Andresen",
                "date": "2013-01-14T18:31:59",
                "message_text_only": "The testnet3 genesis block is identical to the main network genesis\nblock, except it has a different timestamp and nonce.\n\nSo its coinbase pays to the same public key as the main network. I\ndon't have that private key.\n\nGood idea for testnet4, whenever that happens, though.\n\n-- \n--\nGavin Andresen"
            }
        ],
        "thread_summary": {
            "title": "Proposal: make the private key for testnet genesis block public",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Jeff Garzik",
                "Gavin Andresen",
                "Peter Todd"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 1688
        }
    },
    {
        "title": "[Bitcoin-development] message dissemination",
        "thread_messages": [
            {
                "author": "Amir Taaki",
                "date": "2013-01-14T18:56:52",
                "message_text_only": "cool paper: http://phys.org/news/2013-01-algorithm-message-dissemination-decentralized-networks.html#jCp"
            }
        ],
        "thread_summary": {
            "title": "message dissemination",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Amir Taaki"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 104
        }
    },
    {
        "title": "[Bitcoin-development] Testnet DNS seed",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2013-01-24T07:01:03",
                "message_text_only": "I setup a testnet DNS seed using Pieter Wuille's bitcoin-seeder, with\nsome simple modifications for testnet. It's at\ntestnet-seed.bitcoin.petertodd.org I also created\nstatic-testnet-seed.bitcoin.petertodd.org which currently has a single A\nrecord pointing to a testnet node I'm running to bootstrap the seeder\nitself.\n\nEverything is running on a dedicated Amazon EC2 micro instance. Just\nIPv4 is supported right now as EC2 doesn't support IPv6; even tunnels\nare broken. I also haven't setup tor yet. I can do both if there is\ndemand.\n\nI guess the next step is to create a new strTestNetDNSSeed in the\nsatoshi client, although it'd be better if at least one more person had\na testnet seed to include in the list. Probably best to leave IRC\nenabled too.\n\nAlso, FWIW, it looks like the pnSeed list is way out of date...\n\nPieter: Have you written any start/stop/monitoring scripts for the\nseeder? My mods are at git://github.com/petertodd/bitcoin-seeder.git in\nthe \"testnet\" branch. I'll send you a pull request once it's had some\ntesting.\n\n-- \n'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20130124/66f666dd/attachment.sig>"
            },
            {
                "author": "Jeff Garzik",
                "date": "2013-01-26T02:23:28",
                "message_text_only": "On Thu, Jan 24, 2013 at 2:01 AM, Peter Todd <pete at petertodd.org> wrote:\n> Everything is running on a dedicated Amazon EC2 micro instance. Just\n> IPv4 is supported right now as EC2 doesn't support IPv6; even tunnels\n> are broken. I also haven't setup tor yet. I can do both if there is\n> demand.\n\nHow long do you plan to run this?  Indefinitely [presuming there is\ninterest and users]?\n\n> I guess the next step is to create a new strTestNetDNSSeed in the\n> satoshi client, although it'd be better if at least one more person had\n\nNo objection\n\n> a testnet seed to include in the list. Probably best to leave IRC\n> enabled too.\n\nYes, IRC must remain enabled\n\n\n> Also, FWIW, it looks like the pnSeed list is way out of date...\n\nYes.  Usually nanotube does the update when poked.  That can happen,\nor something different.\n\nA nice alternative might be a simple script that transforms Pieter's\nseeds.txt into pnSeed[]\n\n\n\n-- \nJeff Garzik\nexMULTI, Inc.\njgarzik at exmulti.com"
            },
            {
                "author": "Peter Todd",
                "date": "2013-01-27T10:27:52",
                "message_text_only": "On Fri, Jan 25, 2013 at 09:23:28PM -0500, Jeff Garzik wrote:\n> On Thu, Jan 24, 2013 at 2:01 AM, Peter Todd <pete at petertodd.org> wrote:\n> > Everything is running on a dedicated Amazon EC2 micro instance. Just\n> > IPv4 is supported right now as EC2 doesn't support IPv6; even tunnels\n> > are broken. I also haven't setup tor yet. I can do both if there is\n> > demand.\n> \n> How long do you plan to run this?  Indefinitely [presuming there is\n> interest and users]?\n\nIndefinitely. It's a pretty cheap thing to run, about $7.5/month. If\nanyone else wants I can give them a machine image copy easily too.\n\n> > Also, FWIW, it looks like the pnSeed list is way out of date...\n> \n> Yes.  Usually nanotube does the update when poked.  That can happen,\n> or something different.\n> \n> A nice alternative might be a simple script that transforms Pieter's\n> seeds.txt into pnSeed[]\n\nseed.txt? You mean the dumpfile produced by bitcoin-seeder? That has\nuptime info, although only a months worth if I understand it correctly.\n\npnSeed probably should be filtered with SORB's dynamic ip list or\nsimilar too, and additionally add an expiry time. (1 year?)\n\n-- \n'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20130127/8429c990/attachment.sig>"
            },
            {
                "author": "Jeff Garzik",
                "date": "2013-01-27T16:14:02",
                "message_text_only": "On Sun, Jan 27, 2013 at 5:27 AM, Peter Todd <pete at petertodd.org> wrote:\n> On Fri, Jan 25, 2013 at 09:23:28PM -0500, Jeff Garzik wrote:\n>> On Thu, Jan 24, 2013 at 2:01 AM, Peter Todd <pete at petertodd.org> wrote:\n>> > Everything is running on a dedicated Amazon EC2 micro instance. Just\n>> > IPv4 is supported right now as EC2 doesn't support IPv6; even tunnels\n>> > are broken. I also haven't setup tor yet. I can do both if there is\n>> > demand.\n>>\n>> How long do you plan to run this?  Indefinitely [presuming there is\n>> interest and users]?\n>\n> Indefinitely. It's a pretty cheap thing to run, about $7.5/month. If\n> anyone else wants I can give them a machine image copy easily too.\n\nCool.  ACK on adding your seed to the ref client.\n\n>> > Also, FWIW, it looks like the pnSeed list is way out of date...\n>>\n>> Yes.  Usually nanotube does the update when poked.  That can happen,\n>> or something different.\n>>\n>> A nice alternative might be a simple script that transforms Pieter's\n>> seeds.txt into pnSeed[]\n>\n> seed.txt? You mean the dumpfile produced by bitcoin-seeder? That has\n\nCorrect.\n\n> uptime info, although only a months worth if I understand it correctly.\n>\n> pnSeed probably should be filtered with SORB's dynamic ip list or\n> similar too, and additionally add an expiry time. (1 year?)\n\nThat's fine.  The main point was to create something scripted and\nrepeatable.  Then pnSeed[] becomes easier to maintain _and_ easier to\naudit.  Right now it is a bit opaque with a list of hex constants.  A\nscript or makefile rule could do\n\n     cd src\n     ../contrib/gen-seeds.py > seeds.h\n\nand seeds might look like\n\n  #ifndef __SEEDS_AUTOGEN_H__ etc.\n\n  unsigned int pnSeed[] = {\n    0xABCD1234, /* IP addr 12.34.56.78 */\n  };\n\nI think Satoshi liked them opaque and not easily searchable, so\nprinting the readable IP address in a comment may not be desired.\nAnyway, that output would make updating the list more transparent and\neasy to maintain.\n\n-- \nJeff Garzik\nexMULTI, Inc.\njgarzik at exmulti.com"
            },
            {
                "author": "Pieter Wuille",
                "date": "2013-01-27T16:18:43",
                "message_text_only": "On Sun, Jan 27, 2013 at 05:27:52AM -0500, Peter Todd wrote:\n> seed.txt? You mean the dumpfile produced by bitcoin-seeder? That has\n> uptime info, although only a months worth if I understand it correctly.\n\nIt has information about all non-banned IPs that were ever connected to\nsuccesfully. The connectability% is a decaying average, with a time \nconstant of up to a month, though.\n\nI have a script ready which combines one or more seeds.txt's data into a\npnSeed[] array C source code, by the way. I'll add it to the repository.\n\n-- \nPieter"
            }
        ],
        "thread_summary": {
            "title": "Testnet DNS seed",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Jeff Garzik",
                "Pieter Wuille",
                "Peter Todd"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 6311
        }
    }
]