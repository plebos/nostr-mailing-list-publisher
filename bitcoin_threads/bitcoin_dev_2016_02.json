[
    {
        "title": "[bitcoin-dev] Segwit Upgrade Procedures & Block Extension Data",
        "thread_messages": [
            {
                "author": "Pieter Wuille",
                "date": "2016-02-01T16:55:03",
                "message_text_only": "On Thu, Jan 28, 2016 at 7:51 PM, Peter Todd via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> A few notes on upgrade procedures associated with segregated witnesses:\n\n> While Pieter Wuille's segwit branch(1) doesn't yet implement a fix for\n> the above problem, the obvious thing to do is to add a new service bit\n> such as NODE_SEGWIT, and/or bump the protocol version, and for outgoing\n> peers only connect to peers with segwit support.\n\nAgree, I've merged the changes to switch to a service bit instead.\nWe'll need further changes to prefer connecting to segwit nodes.\n\n> Segwit isn't going to be the last thing that adds new block data. For\n> example, my own prev-block-proof proposal(3) requires that blocks commit\n> to another tree, which itself is calculated using a nonce that must be\n> passed along with the block data. (U)TXO commitments are another\n> possible future example.\n\n> Unfortunately, this means that the next soft-fork upgrade to add\n> additional data will have the above relaying problem all over again!\n> Even a minimal upgrade adding a new commitment - like my\n> prev-block-proof proposal - needs to at least add another nonce for\n> future upgrades. In addition to having to upgrade full nodes, this also\n> requires systems like the relay network to upgrade, even though they may\n> not themselves otherwise need to care about the contents of blocks.\n\nThose are good arguments for making the witness data more extensible.\n>\n> A more subtle implication of this problem is how do you handle parallel\n> upgrades, as proposed by BIP9? Splitting the P2P network into\n> non-upgraded nodes, and a much smaller group of upgraded nodes, is bad\n> enough when done every once in a awhile. How does this look with more\n> frequent upgrades, not necessarily done by teams that are working\n> closely with each other?\n\nI don't expect that changes that add more data to be relayed with\nblocks will be frequent, though I certainly agree there may be some.\n\n> Proposal: Unvalidated Block Extension Data\n> ==========================================\n\n(snip)\n\nThis will need a backward-incompatible change to the current segwit\nchange anyway, so at the risk of more bikeshedding, let me propose\ngoing a bit further:\n\n* The coinbase scriptSig gets a second number push (similar to the\ncurrent BIP34 height push), which pushes a number O. O is a byte\noffset inside the coinbase transaction (excluding its witness data)\nthat points to a 32-byte hash H. This is more flexible and more\ncompact than what we have now (a suggestion by jl2012).\n* H is the root of a Merkle tree, whose leaves are the hashes of the\ncoinbase witness's stack items.\n* Item 0 of the coinbase witness stack must be 32 bytes, and must be\nequal to the witness tree root.\n* No further restrictions on the rest of the stack items; these can be\nused for future commitments.\n\n> A significant design consideration is that if arbitrary data can be\n> added, it is very likely that miners will make use of that ability for\n> non-Bitcoin purposes; we've already run into problems deploying segwit\n> itself because of pools using the coinbase space for advertising and\n> merge-mining. Avoiding this problem is easiest with a merkelized\n> key:value mapping, with the ability to use collision-resistant ID's as\n> keys (e.g. UUID).\n\nI agree with the concern, but I don't really understand how this idea solves it.\n\n-- \nPieter"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-02-01T19:29:32",
                "message_text_only": "On Mon, Feb 1, 2016 at 4:55 PM, Pieter Wuille via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> * The coinbase scriptSig gets a second number push (similar to the\n> current BIP34 height push), which pushes a number O. O is a byte\n> offset inside the coinbase transaction (excluding its witness data)\n> that points to a 32-byte hash H. This is more flexible and more\n> compact than what we have now (a suggestion by jl2012).\n>\n\nSo, the script sig is  \"<height> <offset> ..... <H>\"?\n\nWhy is this just not the offset in the extra nonce?\n\n> A significant design consideration is that if arbitrary data can be\n> > added, it is very likely that miners will make use of that ability for\n> > non-Bitcoin purposes;\n> I agree with the concern, but I don't really understand how this idea\n> solves it.\n>\n>\nIt could be enforced that the data in the coinbase witness stack has a\nfixed number of entries, which depends on the block version number.\nVersion 5 blocks would only have 1 entry.\n\nThis would mean a soft-fork could be used to add new entries in the stack.\n<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>\nThis\nemail has been sent from a virus-free computer protected by Avast.\nwww.avast.com\n<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>\n<#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160201/f637261b/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Segwit Upgrade Procedures & Block Extension Data",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Tier Nolan",
                "Pieter Wuille"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 4998
        }
    },
    {
        "title": "[bitcoin-dev] SegWit GBT updates",
        "thread_messages": [
            {
                "author": "Cory Fields",
                "date": "2016-02-01T18:41:06",
                "message_text_only": "Thanks for getting this started, Luke.\n\nNoticeably absent here is the \"default_witness_commitment\" key, as\nadded by the current reference implementation[0].\n\nI assume (please correct me if I'm wrong) that this has been omitted\nfor the sake of having clients create the commitment themselves as\nopposed to having it provided to them.\n\nI don't think that the two approaches (providing the default\ncommitment for the complete tx set as well as the ability to create it\nfrom chosen transactions) are at odds with each-other, rather it\nmerely allows for a simpler approach for those who are taking tx's\nas-is from bitcoind. It's obviously important for the clients to be\nable to chose tx's and create commitments as they desire, but it's\nequally important to allow for simpler use-cases.\n\nThe issue in particular here is that a non-trivial burden is thrust\nupon mining software, increasing the odds of bugs in the process. I'd\nlike to point out that this is not a theoretical argument. I've\nalready fixed a handful of bugs relating to serialization or\ncommitment creation in the mining/pool software that I've worked on\nfor segwit [1][2][3][4]. Asking them to handle more serialization and\ncalculation of complex structures needlessly increases the complexity\nfor zero benefit in the case where the tx's are to be used as-is.\n\nI'll PR this change to the BIP, as I can't really come up with an\nargument against. At worst, it can simply be ignored.\n\n[0]: https://github.com/sipa/bitcoin/blob/segwit/src/rpcmining.cpp#L590\n[1]: https://github.com/bitcoin/libblkmaker/commit/22f6e42844aa14ed0037ebf12a734f07e63533d7\n[2]: https://github.com/bitcoin/libblkmaker/commit/15e2c35bf69c997488e37147cf062dfa925b4912\n[3]: https://github.com/bitcoin/libblkmaker/commit/9a5799891e0f3590779b8e5a993a7b306088e2fa\n[4]: https://github.com/theuni/ckpool/commit/7d84b1d76b39591cc1c1ef495ebec513cb19a08e\n\nRegards,\nCory\n\nOn Sat, Jan 30, 2016 at 1:50 PM, Luke Dashjr via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> I've completed an initial draft of a BIP for updating getblocktemplate for\n> segregated witness here:\n>     https://github.com/luke-jr/bips/blob/segwit_gbt/bip-segwit-gbt.mediawiki\n>\n> Please review and comment (especially with regard to the changes in the\n> sigoplimits handling).\n>\n> (Note: libblkmaker's reference implementation is at this time incompatible\n> with the \"last output\" rule in this BIP.)\n>\n> Thanks,\n>\n> Luke\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-01T19:46:23",
                "message_text_only": "On Monday, February 01, 2016 6:41:06 PM Cory Fields wrote:\n> Noticeably absent here is the \"default_witness_commitment\" key, as\n> added by the current reference implementation[0].\n> \n> I assume (please correct me if I'm wrong) that this has been omitted\n> for the sake of having clients create the commitment themselves as\n> opposed to having it provided to them.\n> \n> I don't think that the two approaches (providing the default\n> commitment for the complete tx set as well as the ability to create it\n> from chosen transactions) are at odds with each-other, rather it\n> merely allows for a simpler approach for those who are taking tx's\n> as-is from bitcoind. It's obviously important for the clients to be\n> able to chose tx's and create commitments as they desire, but it's\n> equally important to allow for simpler use-cases.\n\nAllowing for simpler cases both encourages the lazy case, and enables pools to \nrequire miners use it. It also complicates the server-side implementation \nsomewhat, and could in some cases make it more vulnerable to DoS attacks. Keep \nin mind that GBT is not merely a bitcoind protocol, but is used between\npool<->miner as well... For now, it makes sense to leave \n\"default_witness_commitment\" as a bitcoind-specific extension to encourage \nadoption, but it seems better to leave it out of the standard protocol. Let me \nknow if this makes sense or if I'm overlooking something.\n\n> The issue in particular here is that a non-trivial burden is thrust\n> upon mining software, increasing the odds of bugs in the process. \n\nIt can always use libblkmaker to handle the \"heavy lifting\"... In any case, \nthe calculation for the commitment isn't significantly more than what it must \nalready do for the stripped merkle tree.\n\n> I'd like to point out that this is not a theoretical argument. I've\n> already fixed a handful of bugs relating to serialization or\n> commitment creation in the mining/pool software that I've worked on\n> for segwit [1][2][3][4].\n\nThat's not really fair IMO. I wrote the libblkmaker branch prior to even \nreading the SegWit BIPs or code, and without a way to test it. It's only to be \nexpected there are bugs that get fixed in first-try testing.\n\n> [4]:\n> https://github.com/theuni/ckpool/commit/7d84b1d76b39591cc1c1ef495ebec513cb\n> 19a08e\n\nI'm pretty sure this commit is actually /introducing/ a bug in working (albeit \nugly) code. The height, while always positive, is serialised as a signed \nnumber, so 0x80 needs to be two bytes: 80 00.\n\nLuke"
            },
            {
                "author": "Cory Fields",
                "date": "2016-02-01T21:43:33",
                "message_text_only": "On Mon, Feb 1, 2016 at 2:46 PM, Luke Dashjr <luke at dashjr.org> wrote:\n> On Monday, February 01, 2016 6:41:06 PM Cory Fields wrote:\n>> Noticeably absent here is the \"default_witness_commitment\" key, as\n>> added by the current reference implementation[0].\n>>\n>> I assume (please correct me if I'm wrong) that this has been omitted\n>> for the sake of having clients create the commitment themselves as\n>> opposed to having it provided to them.\n>>\n>> I don't think that the two approaches (providing the default\n>> commitment for the complete tx set as well as the ability to create it\n>> from chosen transactions) are at odds with each-other, rather it\n>> merely allows for a simpler approach for those who are taking tx's\n>> as-is from bitcoind. It's obviously important for the clients to be\n>> able to chose tx's and create commitments as they desire, but it's\n>> equally important to allow for simpler use-cases.\n>\n> Allowing for simpler cases both encourages the lazy case, and enables pools to\n> require miners use it. It also complicates the server-side implementation\n> somewhat, and could in some cases make it more vulnerable to DoS attacks. Keep\n> in mind that GBT is not merely a bitcoind protocol, but is used between\n> pool<->miner as well... For now, it makes sense to leave\n> \"default_witness_commitment\" as a bitcoind-specific extension to encourage\n> adoption, but it seems better to leave it out of the standard protocol. Let me\n> know if this makes sense or if I'm overlooking something.\n>\n\nI think that's a bit of a loaded answer. What's to keep a pool from\nbuilding its own commitment and requiring miners to use that? I don't\nsee how providing the known-working commitment for the\npassed-in-hashes allows the pool/miner to do anything they couldn't\nalready, with the exception of skipping some complexity. Please don't\nconfuse encouraging with enabling.\n\nWhat's the DoS vector here?\n\n>> The issue in particular here is that a non-trivial burden is thrust\n>> upon mining software, increasing the odds of bugs in the process.\n>\n> It can always use libblkmaker to handle the \"heavy lifting\"... In any case,\n> the calculation for the commitment isn't significantly more than what it must\n> already do for the stripped merkle tree.\n\nAgreed. However for the sake of initial adoption, it's much easier to\nhave a known-correct value to use. Even if it's just for the sake of\nchecking against.\n\n>\n>> I'd like to point out that this is not a theoretical argument. I've\n>> already fixed a handful of bugs relating to serialization or\n>> commitment creation in the mining/pool software that I've worked on\n>> for segwit [1][2][3][4].\n>\n> That's not really fair IMO. I wrote the libblkmaker branch prior to even\n> reading the SegWit BIPs or code, and without a way to test it. It's only to be\n> expected there are bugs that get fixed in first-try testing.\n\nI didn't mean this as an insult/attack, quite the opposite actually.\nThanks for doing the integration :)\n\nI was merely pointing out how easy it is to introduce subtle bugs here.\n\n>\n>> [4]:\n>> https://github.com/theuni/ckpool/commit/7d84b1d76b39591cc1c1ef495ebec513cb\n>> 19a08e\n>\n> I'm pretty sure this commit is actually /introducing/ a bug in working (albeit\n> ugly) code. The height, while always positive, is serialised as a signed\n> number, so 0x80 needs to be two bytes: 80 00.\n\nYou're right, thanks. The current code breaks on heights of (for ex)\n16513. I'll fix up my changes to take the sign bit into account.\n\nHeh, that only reinforces my point above about introducing bugs :p\n\n>\n> Luke"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-01T23:08:34",
                "message_text_only": "On Monday, February 01, 2016 9:43:33 PM Cory Fields wrote:\n> On Mon, Feb 1, 2016 at 2:46 PM, Luke Dashjr <luke at dashjr.org> wrote:\n> > Allowing for simpler cases both encourages the lazy case, and enables\n> > pools to require miners use it. It also complicates the server-side\n> > implementation somewhat, and could in some cases make it more vulnerable\n> > to DoS attacks. Keep in mind that GBT is not merely a bitcoind protocol,\n> > but is used between pool<->miner as well... For now, it makes sense to\n> > leave\n> > \"default_witness_commitment\" as a bitcoind-specific extension to\n> > encourage adoption, but it seems better to leave it out of the standard\n> > protocol. Let me know if this makes sense or if I'm overlooking\n> > something.\n> \n> I think that's a bit of a loaded answer. What's to keep a pool from\n> building its own commitment and requiring miners to use that? I don't\n> see how providing the known-working commitment for the\n> passed-in-hashes allows the pool/miner to do anything they couldn't\n> already, with the exception of skipping some complexity. Please don't\n> confuse encouraging with enabling.\n\nMaking it simpler to do a centralised implementation than a decentralised one, \nis both enabling and encouraging. GBT has always been designed to make it \ndifficult to do in a centralised manner.\n\n> What's the DoS vector here?\n\nIt's more work for the pool to provide it, similar to the \"midstate\" field was \nwith getwork. Someone performing a DoS needs to do less work to force the pool \nto do complex calculations (unless the same transaction tree / commitment is \nused for all miners, which would be an unfortunate limitation).\n\n> >> The issue in particular here is that a non-trivial burden is thrust\n> >> upon mining software, increasing the odds of bugs in the process.\n> > \n> > It can always use libblkmaker to handle the \"heavy lifting\"... In any\n> > case, the calculation for the commitment isn't significantly more than\n> > what it must already do for the stripped merkle tree.\n> \n> Agreed. However for the sake of initial adoption, it's much easier to\n> have a known-correct value to use. Even if it's just for the sake of\n> checking against.\n\nSure, I'm not suggesting we remove this from bitcoind (probably the only place \nthat makes initial adoption easier).\n\n> >> [4]:\n> >> https://github.com/theuni/ckpool/commit/7d84b1d76b39591cc1c1ef495ebec513\n> >> cb 19a08e\n> > \n> > I'm pretty sure this commit is actually /introducing/ a bug in working\n> > (albeit ugly) code. The height, while always positive, is serialised as\n> > a signed number, so 0x80 needs to be two bytes: 80 00.\n> \n> You're right, thanks. The current code breaks on heights of (for ex)\n> 16513. I'll fix up my changes to take the sign bit into account.\n\nI'm curious what bug it was fixing? Was it overwriting data beyond the number?\n\nLuke"
            },
            {
                "author": "Cory Fields",
                "date": "2016-02-02T01:40:49",
                "message_text_only": "On Mon, Feb 1, 2016 at 6:08 PM, Luke Dashjr <luke at dashjr.org> wrote:\n> On Monday, February 01, 2016 9:43:33 PM Cory Fields wrote:\n>> On Mon, Feb 1, 2016 at 2:46 PM, Luke Dashjr <luke at dashjr.org> wrote:\n>> > Allowing for simpler cases both encourages the lazy case, and enables\n>> > pools to require miners use it. It also complicates the server-side\n>> > implementation somewhat, and could in some cases make it more vulnerable\n>> > to DoS attacks. Keep in mind that GBT is not merely a bitcoind protocol,\n>> > but is used between pool<->miner as well... For now, it makes sense to\n>> > leave\n>> > \"default_witness_commitment\" as a bitcoind-specific extension to\n>> > encourage adoption, but it seems better to leave it out of the standard\n>> > protocol. Let me know if this makes sense or if I'm overlooking\n>> > something.\n>>\n>> I think that's a bit of a loaded answer. What's to keep a pool from\n>> building its own commitment and requiring miners to use that? I don't\n>> see how providing the known-working commitment for the\n>> passed-in-hashes allows the pool/miner to do anything they couldn't\n>> already, with the exception of skipping some complexity. Please don't\n>> confuse encouraging with enabling.\n>\n> Making it simpler to do a centralised implementation than a decentralised one,\n> is both enabling and encouraging. GBT has always been designed to make it\n> difficult to do in a centralised manner.\n>\n\nBut your suggestion is \"use libblkmaker\" which will build the trees\nfor me. By that logic, isn't libblkmaker making a centralized\nimplementation easier? Shouldn't that usage be discouraged as well?\nAnd along those lines, shouldn't the fact that it's used as a pool <->\nminer protocol be discouraged rather than touted as a feature?\n\nI don't wish to sound hostile, I'm just trying follow the logic. I\ncan't rationalize why GBT shouldn't expose the commitment that it\nknows to be correct (when paired with the transactions it provides),\npurely to make things difficult.\n\n>> What's the DoS vector here?\n>\n> It's more work for the pool to provide it, similar to the \"midstate\" field was\n> with getwork. Someone performing a DoS needs to do less work to force the pool\n> to do complex calculations (unless the same transaction tree / commitment is\n> used for all miners, which would be an unfortunate limitation).\n\nIt's being provided to them. And if they're using a modified set of\ntx's, they'll need to re-calculate it in order to verify the result\nanyway. I suspect I'm not understanding this argument.\n\n>\n>> >> The issue in particular here is that a non-trivial burden is thrust\n>> >> upon mining software, increasing the odds of bugs in the process.\n>> >\n>> > It can always use libblkmaker to handle the \"heavy lifting\"... In any\n>> > case, the calculation for the commitment isn't significantly more than\n>> > what it must already do for the stripped merkle tree.\n>>\n>> Agreed. However for the sake of initial adoption, it's much easier to\n>> have a known-correct value to use. Even if it's just for the sake of\n>> checking against.\n>\n> Sure, I'm not suggesting we remove this from bitcoind (probably the only place\n> that makes initial adoption easier).\n>\n\nHow about exposing it as a feature/capability, then? That way pools\ncan expect it from bitcoind, but won't be required to expose it\ndownstream.\n\n>> >> [4]:\n>> >> https://github.com/theuni/ckpool/commit/7d84b1d76b39591cc1c1ef495ebec513\n>> >> cb 19a08e\n>> >\n>> > I'm pretty sure this commit is actually /introducing/ a bug in working\n>> > (albeit ugly) code. The height, while always positive, is serialised as\n>> > a signed number, so 0x80 needs to be two bytes: 80 00.\n>>\n>> You're right, thanks. The current code breaks on heights of (for ex)\n>> 16513. I'll fix up my changes to take the sign bit into account.\n>\n> I'm curious what bug it was fixing? Was it overwriting data beyond the number?\n\nUsing 16513 as an example:\n\nserialized by bitcoind: 0x028140\nserialized by ckpool: 0x03814000\n\nckpool works because blocks after 32768 end up looking the same, but\nit will break again at 2113664.\n\n>\n> Luke"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-02T02:30:55",
                "message_text_only": "On Tuesday, February 02, 2016 1:40:49 AM Cory Fields wrote:\n> On Mon, Feb 1, 2016 at 6:08 PM, Luke Dashjr <luke at dashjr.org> wrote:\n> > On Monday, February 01, 2016 9:43:33 PM Cory Fields wrote:\n> >> On Mon, Feb 1, 2016 at 2:46 PM, Luke Dashjr <luke at dashjr.org> wrote:\n> >> > Allowing for simpler cases both encourages the lazy case, and enables\n> >> > pools to require miners use it. It also complicates the server-side\n> >> > implementation somewhat, and could in some cases make it more\n> >> > vulnerable to DoS attacks. Keep in mind that GBT is not merely a\n> >> > bitcoind protocol, but is used between pool<->miner as well... For\n> >> > now, it makes sense to leave\n> >> > \"default_witness_commitment\" as a bitcoind-specific extension to\n> >> > encourage adoption, but it seems better to leave it out of the\n> >> > standard protocol. Let me know if this makes sense or if I'm\n> >> > overlooking something.\n> >> \n> >> I think that's a bit of a loaded answer. What's to keep a pool from\n> >> building its own commitment and requiring miners to use that? I don't\n> >> see how providing the known-working commitment for the\n> >> passed-in-hashes allows the pool/miner to do anything they couldn't\n> >> already, with the exception of skipping some complexity. Please don't\n> >> confuse encouraging with enabling.\n> > \n> > Making it simpler to do a centralised implementation than a decentralised\n> > one, is both enabling and encouraging. GBT has always been designed to\n> > make it difficult to do in a centralised manner.\n> \n> But your suggestion is \"use libblkmaker\" which will build the trees\n> for me. By that logic, isn't libblkmaker making a centralized\n> implementation easier? Shouldn't that usage be discouraged as well?\n\nlibblkmaker is miner-side; right now it implies the miner using the templates \nas-is (perhaps after verifying the transactions meet some criteria), but it is \nthe miner who is making that decision, not the pool.\n\n> And along those lines, shouldn't the fact that it's used as a pool <->\n> miner protocol be discouraged rather than touted as a feature?\n\n???\n\n> >> What's the DoS vector here?\n> > \n> > It's more work for the pool to provide it, similar to the \"midstate\"\n> > field was with getwork. Someone performing a DoS needs to do less work\n> > to force the pool to do complex calculations (unless the same\n> > transaction tree / commitment is used for all miners, which would be an\n> > unfortunate limitation).\n> \n> It's being provided to them. And if they're using a modified set of\n> tx's, they'll need to re-calculate it in order to verify the result\n> anyway. I suspect I'm not understanding this argument.\n\nThe DoS is against the pool, not the miner. You'd attack by pretending to be \n100000 new miners per second, and the pool then needs to calculate a witness \ncommitment for each one. It's a lot cheaper to just serialise and send the \ntransaction list.\n\n> >> >> The issue in particular here is that a non-trivial burden is thrust\n> >> >> upon mining software, increasing the odds of bugs in the process.\n> >> > \n> >> > It can always use libblkmaker to handle the \"heavy lifting\"... In any\n> >> > case, the calculation for the commitment isn't significantly more than\n> >> > what it must already do for the stripped merkle tree.\n> >> \n> >> Agreed. However for the sake of initial adoption, it's much easier to\n> >> have a known-correct value to use. Even if it's just for the sake of\n> >> checking against.\n> > \n> > Sure, I'm not suggesting we remove this from bitcoind (probably the only\n> > place that makes initial adoption easier).\n> \n> How about exposing it as a feature/capability, then? That way pools\n> can expect it from bitcoind, but won't be required to expose it\n> downstream.\n\nImplementation-specific things aren't standards. And besides, they really \n*shouldn't* expect it from bitcoind; it's simply a reasonable compromise to \nprovide it encourage adoption of SegWit. Once SegWit is live, there is no more \nvalue to doing so.\n\nLuke"
            }
        ],
        "thread_summary": {
            "title": "SegWit GBT updates",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Luke Dashjr",
                "Cory Fields"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 19594
        }
    },
    {
        "title": "[bitcoin-dev] BIP Process: Status, comments, and copyright licenses",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2016-02-01T22:53:16",
                "message_text_only": "I've completed an initial draft of a BIP that provides clarifications on the \nStatus field for BIPs, as well as adding the ability for public comments on \nthem, and expanding the list of allowable BIP licenses.\n\nhttps://github.com/luke-jr/bips/blob/bip-biprevised/bip-biprevised.mediawiki\n\nI plan to open discussion of making this BIP an Active status (along with BIP \n123) a month after initial revisions have completed. Please provide any \nobjections now, so I can try to address them now and enable consensus to be \nreached.\n\nThanks,\n\nLuke"
            },
            {
                "author": "Dave Scotese",
                "date": "2016-02-02T05:50:29",
                "message_text_only": "The section that starts \"Should two software projects need to release\"\naddresses issues that are difficult to ascertain from what is written\nthere.  I'll take a stab at what it means:\n\nWould bitcoin be better off if multiple applications provided their own\nimplementations of API/RPC and corresponding application layer BIPs?\n\n   - While there is only one such application, its UI will be the obvious\n   standard and confusion in usability will be avoided.\n   - Any more than a single such application will benefit from the\n   coordination encouraged and aided by this BIP and BIP 123.\n\n\"To avoid doubt: comments and status are unrelated metrics to judge a BIP,\nand neither should be directly influencing the other.\" makes more sense to\nme as \"To avoid doubt: comments and status are intended to be unrelated\nmetrics. Any influence of one over the other indicates a deviation from\ntheir intended use.\"  This can be expanded with a simple example: \"In other\nwords, a BIP having  the status 'Rejected' is no reason not to write\nadditional comments about it.  Likewise, overwhelming support for a BIP in\nits comments section doesn't change the requirements for the 'Accepted' or\n'Active' status.\"\n\nSince the Bitcoin Wiki can be updated with comments from other places, I\nthink the author of a BIP should be allowed to specify other Internet\nlocations for comments.  So \"link to a Bitcoin Wiki page\" could instead be\n\"link to a comments page (strongly recommended to be in the Bitcoin\nWiki)\".  Also, under \"Will BIP comments be censored or limited to\nparticular participants/\"experts\"?\" You could add:\n\n   - The author of a BIP may indicate any commenting URL they wish.  The\n   Bitcoin Wiki is merely a recommendation, though a very strong one.\n\n\nOn Mon, Feb 1, 2016 at 2:53 PM, Luke Dashjr via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I've completed an initial draft of a BIP that provides clarifications on\n> the\n> Status field for BIPs, as well as adding the ability for public comments on\n> them, and expanding the list of allowable BIP licenses.\n>\n>\n> https://github.com/luke-jr/bips/blob/bip-biprevised/bip-biprevised.mediawiki\n>\n> I plan to open discussion of making this BIP an Active status (along with\n> BIP\n> 123) a month after initial revisions have completed. Please provide any\n> objections now, so I can try to address them now and enable consensus to be\n> reached.\n>\n> Thanks,\n>\n> Luke\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n\n-- \nI like to provide some work at no charge to prove my value. Do you need a\ntechie?\nI own Litmocracy <http://www.litmocracy.com> and Meme Racing\n<http://www.memeracing.net> (in alpha).\nI'm the webmaster for The Voluntaryist <http://www.voluntaryist.com> which\nnow accepts Bitcoin.\nI also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n\"He ought to find it more profitable to play by the rules\" - Satoshi\nNakamoto\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160201/b5dacb35/attachment.html>"
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-02-02T15:58:21",
                "message_text_only": "On Mon, Feb 1, 2016 at 5:53 PM, Luke Dashjr via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I've completed an initial draft of a BIP that provides clarifications on\n> the\n> Status field for BIPs, as well as adding the ability for public comments on\n> them, and expanding the list of allowable BIP licenses.\n>\n>\n> https://github.com/luke-jr/bips/blob/bip-biprevised/bip-biprevised.mediawiki\n>\n> I plan to open discussion of making this BIP an Active status (along with\n> BIP\n> 123) a month after initial revisions have completed. Please provide any\n> objections now, so I can try to address them now and enable consensus to be\n> reached.\n>\n\n\nI like the more concrete definitions of the various statuses.\n\nI don't like the definition of \"consensus\".  I think the definition\ndescribed gives too much centralized control to whoever controls the\nmailing list and the wiki.\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160202/e4d356b4/attachment.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2016-02-02T17:38:59",
                "message_text_only": "In the section https://github.com/luke-jr/bips/blob/bip-biprevised/bip-biprevised.mediawiki#formally-defining-consensus\n\nCan we please find another term for the \"consensus\" here (which is\noften confused with \"consensus rules\", \"consensus code\" etc)?\nIn BIP99 I used the term \"uncontroversial\", but I'm happy to change it\nto something else if that helps us moving away from consistently using\nthe same term for two related but very different concepts.\n\"nearly universal acceptance\", \"ecosystem-harmonious\"...seriously,\nalmost anything would be better than keep overloading \"consensus\"..."
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-02T19:41:24",
                "message_text_only": "On Tuesday, February 02, 2016 5:38:59 PM Jorge Tim\u00f3n wrote:\n> In the section\n> https://github.com/luke-jr/bips/blob/bip-biprevised/bip-biprevised.mediawi\n> ki#formally-defining-consensus\n> \n> Can we please find another term for the \"consensus\" here (which is\n> often confused with \"consensus rules\", \"consensus code\" etc)?\n> In BIP99 I used the term \"uncontroversial\", but I'm happy to change it\n> to something else if that helps us moving away from consistently using\n> the same term for two related but very different concepts.\n> \"nearly universal acceptance\", \"ecosystem-harmonious\"...seriously,\n> almost anything would be better than keep overloading \"consensus\"...\n\n\"Uncontroversial\" doesn't really express the correct idea.\n\nThere has been a lot of confusion over \"consensus rules/code\" anyway, so while \nwe're on the subject of terminology, I would suggest we change *that* use of \n\"consensus\" instead to clear up the confusion. It would probably work quite \nwell to rename it to \"concord rules/code\", and leave \"consensus\" for \ndescribing the actual process by which humans agree on changes to the concord.\n\nAnyone else have any thoughts on this subject?\n\nLuke\n\n(Note Core currently has \"consensus\" only 249 times, most of which are simply \nidentifier names, so it would be trivial to make this change.)"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-02T19:08:19",
                "message_text_only": "On Tuesday, February 02, 2016 3:58:21 PM Gavin Andresen wrote:\n> I don't like the definition of \"consensus\".  I think the definition\n> described gives too much centralized control to whoever controls the\n> mailing list and the wiki.\n\nHow can I improve this? Inevitably, every medium of communications will be \ncontrolled by someone (even if unmoderated, it becomes effectively controlled \nby trolls who spam it with garbage).\n\nI think it's important to note that this is also only for updating the status \nof BIPs, and is not in any way relevant to such proposals *actually* being \naccepted. So if the BIP process were to breakdown on this or any other point, \nit isn't somehow controlling the actual reality. To explicitly clarify this \npoint, I have added to the end of the section:\n    \"These criteria are considered objective ways to observe the de facto\n     adoption of the BIP, and are not to be used as reasons to oppose or\n     reject a BIP. Should a BIP become actually and unambiguously adopted\n     despite not meeting the criteria outlined here, it should still be\n     updated to Final status.\"\nDoes that help?\n\nThanks,\n\nLuke"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-04T04:15:46",
                "message_text_only": "On Monday, February 01, 2016 10:53:16 PM Luke Dashjr via bitcoin-dev wrote:\n> I've completed an initial draft of a BIP that provides clarifications on\n> the Status field for BIPs, as well as adding the ability for public\n> comments on them, and expanding the list of allowable BIP licenses.\n\nThis has moved to:\n\nhttps://github.com/luke-jr/bips/blob/bip-biprevised/bip-0002.mediawiki\n\nVarious changes have been made based on initial input.\nFurther review and re-review is of course welcome.\n\nLuke"
            },
            {
                "author": "Ryan Grant",
                "date": "2016-02-04T17:45:38",
                "message_text_only": "On Thu, Feb 4, 2016 at 12:15 AM, Luke Dashjr via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Various changes have been made based on initial input.\n> Further review and re-review is of course welcome.\n\nThese recent edits definitely guide us towards less hard feelings when\ncomments are offered, without excessive policy structure.\n\n[BIP 2:]\n> A process BIP may change status from Draft to Active when it\n> achieves rough consensus on the mailing list.\n\nIs this mix of wiki and mailing list intentional?  If so, the wiki\ntalk page is meant to be a self-curated permanent record of support\nand dissent, but second-order reply commentary might fall either on\nthe wiki or the mailing list?\n\nMediawiki offers watchlists on a polling model, and there is some\nemail support [1], but it would be nice of a BIP author to at least\ngather new/edited comment titles and report them to bitcoin-dev once a\nweek, during review.  Someone has to stare at the diffs.\n\n  [1] https://www.mediawiki.org/wiki/Manual:Page_change_notification\n\nBIP 2 should ask that all current and future forums that BIP authors\nmight choose for review have indisputable records of moderation and\nuser edits.\n\nIs dump.bitcoin.it a sufficient public record of contentious\nmoderation or user cross-comment editing?  It seems like as long as\nthe wiki as a whole is verifiable, it would suffice."
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-04T21:17:30",
                "message_text_only": "On Thursday, February 04, 2016 5:45:38 PM Ryan Grant wrote:\n> [BIP 2:]\n> > A process BIP may change status from Draft to Active when it\n> > achieves rough consensus on the mailing list.\n> \n> Is this mix of wiki and mailing list intentional?  If so, the wiki\n> talk page is meant to be a self-curated permanent record of support\n> and dissent, but second-order reply commentary might fall either on\n> the wiki or the mailing list?\n\nThe wiki page is meant to be a place to leave comments recommending or \ndiscouraging adoption of a completed BIP, after discussion is over. For \nexample, many people seem to think BIP 38 is a good idea simply because it is \na Final BIP, whereas in general we would want to discourage using it since it \ncannot really be used safely.\n\nAll review itself ought to remain on the ML.\n\n> BIP 2 should ask that all current and future forums that BIP authors\n> might choose for review have indisputable records of moderation and\n> user edits.\n\nIs this necessary considering the author-chosen forum may only be *in addition \nto* the Bitcoin Wiki?\n\n> Is dump.bitcoin.it a sufficient public record of contentious\n> moderation or user cross-comment editing?  It seems like as long as\n> the wiki as a whole is verifiable, it would suffice.\n\nIt should be everything except accounts/passwords.\n\nLuke"
            },
            {
                "author": "Ryan Grant",
                "date": "2016-02-05T00:09:09",
                "message_text_only": "On Thu, Feb 4, 2016 at 5:17 PM, Luke Dashjr <luke at dashjr.org> wrote:\n> All review itself ought to remain on the ML.\n\n> the author-chosen forum may only be *in addition\n> to* the Bitcoin Wiki?\n\nAhh, much better.  Thank you.\n\nFWIW, this is the phrase that confused me:\n[BIP 2:] If a BIP is not yet completed, reviewers should [...]"
            },
            {
                "author": "Ryan Grant",
                "date": "2016-02-02T06:35:07",
                "message_text_only": "On Mon, Feb 1, 2016 at 6:53 PM, Luke Dashjr via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Please provide any\n> objections now, so I can try to address them now and enable consensus to be\n> reached.\n\nFor section \"Formally defining consensus\",\n\nWhere objections were not deemed substantiated by the community, clear\nreasoning must be offered.\n\nFor section \"BIP Comments\",\n\nComments should be solicited on the bitcoin-dev mailing list, and\nsummarized fairly in the wiki; with notice of summarization and time\nfor suggesting edits on the mailing list.  Wiki registration and\nmonitoring should not be a required hurdle to participation."
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-02T07:54:29",
                "message_text_only": "On Tuesday, February 02, 2016 5:50:29 AM Dave Scotese wrote:\n> The section that starts \"Should two software projects need to release\"\n> addresses issues that are difficult to ascertain from what is written\n> there.  I'll take a stab at what it means:\n> \n> Would bitcoin be better off if multiple applications provided their own\n> implementations of API/RPC and corresponding application layer BIPs?\n> \n>    - While there is only one such application, its UI will be the obvious\n>    standard and confusion in usability will be avoided.\n>    - Any more than a single such application will benefit from the\n>    coordination encouraged and aided by this BIP and BIP 123.\n\nThe original question is intended to answer both: a) why only one \nimplementation is insufficient for Final status, and b) why two is sufficient.\n\nIf every application had its own BIP (how I understand your version), none of \nthem would be standards and it wouldn't make sense to have a BIP at all - just \nproject documentation would be sufficient.\n\n> \"To avoid doubt: comments and status are unrelated metrics to judge a BIP,\n> and neither should be directly influencing the other.\" makes more sense to\n> me as \"To avoid doubt: comments and status are intended to be unrelated\n> metrics. Any influence of one over the other indicates a deviation from\n> their intended use.\"  This can be expanded with a simple example: \"In other\n> words, a BIP having  the status 'Rejected' is no reason not to write\n> additional comments about it.  Likewise, overwhelming support for a BIP in\n> its comments section doesn't change the requirements for the 'Accepted' or\n> 'Active' status.\"\n\nExtending this to \"influence\" is probably too far - after all, comments may \ndiscourage implementations, which can very well result in the Status \neventually becoming Rejected rather than Final. How about:\n\n\"To avoid doubt: comments and status are intended to be unrelated metrics. In \nother words, a BIP having the status 'Rejected' is no reason to write (or not \nwrite) additional comments about it, nor would a status of 'Final' preclude \ncomments discouraging [further] implementation. Likewise, overwhelming support \nfor a BIP in its comments section doesn't change the requirements for the \n'Final' or 'Active' status.\"\n\n> Since the Bitcoin Wiki can be updated with comments from other places, I\n> think the author of a BIP should be allowed to specify other Internet\n> locations for comments.  So \"link to a Bitcoin Wiki page\" could instead be\n> \"link to a comments page (strongly recommended to be in the Bitcoin\n> Wiki)\". \n\nHmm, I wonder if this could be too easily abuse to discourage comments \n(because the commenter does not wish to register with yet another forum), \nand/or censor negative comments (because the author has made his own forum \nspecifically for the purpose).\n\nOn Tuesday, February 02, 2016 6:35:07 AM you wrote:\n> For section \"Formally defining consensus\",\n> \n> Where objections were not deemed substantiated by the community, clear\n> reasoning must be offered.\n\nI have integrated this into the draft.\n\n> For section \"BIP Comments\",\n> \n> Comments should be solicited on the bitcoin-dev mailing list, and\n> summarized fairly in the wiki; with notice of summarization and time\n> for suggesting edits on the mailing list.  Wiki registration and\n> monitoring should not be a required hurdle to participation.\n\nThe intent is for the commenter to edit the wiki page himself. I have updated \nit to reflect this.\n\nLuke"
            },
            {
                "author": "Dave Scotese",
                "date": "2016-02-02T16:00:03",
                "message_text_only": "On Mon, Feb 1, 2016 at 11:54 PM, Luke Dashjr <luke at dashjr.org> wrote:\n\n> On Tuesday, February 02, 2016 5:50:29 AM Dave Scotese wrote:\n> > The section that starts \"Should two software projects need to release\"\n> > addresses issues that are difficult to ascertain from what is written\n> > there.  I'll take a stab at what it means:\n> >\n> > Would bitcoin be better off if multiple applications provided their own\n> > implementations of API/RPC and corresponding application layer BIPs?\n> >\n> >    - While there is only one such application, its UI will be the obvious\n> >    standard and confusion in usability will be avoided.\n> >    - Any more than a single such application will benefit from the\n> >    coordination encouraged and aided by this BIP and BIP 123.\n>\n> The original question is intended to answer both: a) why only one\n> implementation is insufficient for Final status, and b) why two is\n> sufficient.\n>\n> If every application had its own BIP (how I understand your version), none\n> of\n> them would be standards and it wouldn't make sense to have a BIP at all -\n> just\n> project documentation would be sufficient.\n>\n> > \"To avoid doubt: comments and status are unrelated metrics to judge a\n> BIP,\n> > and neither should be directly influencing the other.\" makes more sense\n> to\n> > me as \"To avoid doubt: comments and status are intended to be unrelated\n> > metrics. Any influence of one over the other indicates a deviation from\n> > their intended use.\"  This can be expanded with a simple example: \"In\n> other\n> > words, a BIP having  the status 'Rejected' is no reason not to write\n> > additional comments about it.  Likewise, overwhelming support for a BIP\n> in\n> > its comments section doesn't change the requirements for the 'Accepted'\n> or\n> > 'Active' status.\"\n>\n> Extending this to \"influence\" is probably too far - after all, comments may\n> discourage implementations, which can very well result in the Status\n> eventually becoming Rejected rather than Final. How about:\n>\n> \"To avoid doubt: comments and status are intended to be unrelated metrics.\n> In\n> other words, a BIP having the status 'Rejected' is no reason to write (or\n> not\n> write) additional comments about it, nor would a status of 'Final' preclude\n> comments discouraging [further] implementation. Likewise, overwhelming\n> support\n> for a BIP in its comments section doesn't change the requirements for the\n> 'Final' or 'Active' status.\"\n>\n\nYes, that is much better.  The mention of \"only one is insufficient\" and\n\"two are sufficient\" in the bullets clarifies them well too.\n\n\n>\n> > Since the Bitcoin Wiki can be updated with comments from other places, I\n> > think the author of a BIP should be allowed to specify other Internet\n> > locations for comments.  So \"link to a Bitcoin Wiki page\" could instead\n> be\n> > \"link to a comments page (strongly recommended to be in the Bitcoin\n> > Wiki)\".\n>\n> Hmm, I wonder if this could be too easily abuse to discourage comments\n> (because the commenter does not wish to register with yet another forum),\n> and/or censor negative comments (because the author has made his own forum\n> specifically for the purpose).\n>\n\nBIP acceptance hinges on accessibility and discussion.  Wherever discussion\nhappens, someone can mention the Wiki page they created to sidestep such an\nunfortunate abuse.  I have always been in favor of allowing people to do\nstupid things simply because that helps them learn not to do them.  The\nresult is often some (at least slight) embarrassment of the bad actor and a\nlesson for everyone paying attention.  The censorship of BitcoinXT\ndiscussion had this effect and has softened the enthusiasm many had for...\nlet's call it: guarding against their own cognitive dissonance through\ncensorship and intimidation.\n\nIn fact this last item is probably what raised a flag for me when thinking\nabout the specification that they should \"link to a Bitcoin Wiki page with\na summary tone of the comments.\" I have too often seen great discussions of\ncontroversy lose a lot of valuable input because they lived in an\nenvironment controlled by someone who let bias infect their moderation\ndecisions.  I know that even I might do that, so encouraging others to have\naccess to my competitors feels right.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160202/bd961260/attachment-0001.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-03T00:03:31",
                "message_text_only": "On Tuesday, February 02, 2016 11:28:40 PM Dave Scotese wrote:\n> How about \"defining\" (rules, code, etc.) Such code and rules define what\n> bitcoin is.  It does require consensus and it ends up being a concord, but\n> all that can come after the fact (just as it did after bitcoin was first\n> released to the public).\n\nThe difficulty is that this BIP needs to refer to three different context of \nconsensus:\n\n1. Consensus (stated) among developers for changes in the BIP Process.\n2. Economic consensus (potential and stated) to veto a soft-fork by an\n   intended \"firing\" of the set of miners if they choose to enforce it.\n3. (Actual) consensus in economic adoption of changed rules, to determine the\n   success of a hard-fork (after the fact).\n4. The set of rules currently established as (defining) Bitcoin, enforced by\n   an (actual) consensus of economically-relevant nodes.\n\nContext 3 can be disambiguated with \"adoption consensus\", and context 4 with \n\"consensus rules\" and/or \"consensus protocol\", but I don't see a clear \nsolution that covers all four contexts, and even sharing the word \"consensus\" \nfor them may be confusing.\n\nIn addition, usage of the word \"consensus\" for context 4 has proven confusing \nto users. For example, recently users misinterpreted the \"Consensus\" label \nused in context 4 as implying that the idea itself had in fact achieved \nconsensus among some group of decision-makers (similar to context 1, but not \nnecessarily the group being \"developers\").\n\nI don't know a good way to make this completely clear, so suggestions are more \nthan welcome.\n\nLuke"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2016-02-03T00:59:58",
                "message_text_only": "It  is true that are many levels of consensus and that term itself is\nnot incorrect for any of the meanings.\nMaybe we should try to start distinguishing between different types of\n\"consensus\".\nIn BIP99 the only concepts that are needed are \"consensus rules\" and\n\"adoption consensus\" (aka \"community consensus\", \"full node runners\nconsenusus\", \"monetary users consenusus\", \"economic\nsuper-ultra-majority\", not sure if any of them or all of them, that's\nstill a placeholder in bip99 for\n<everything_thats_needed_for_an_uncontroversial_hardfork_apart_from_the_hardfork_new_rules_being_uncontroversial>\n[ie safe deployment requirements for an uncontroversial hardfork, just\nlike we have for uncontroversial softforks]).\nWhatever term and defintion we chose for this concept, it has to be\nneutral to whether the consensus rule changes are can be deployed as a\nsoftfork or only as a hardfork [although we have had many\nhardfork-to-softfork re-designs in the past and I agree that there\nwill be more, some people including @petertodd suspect that SF=HF, but\nhaven't been able to prove it yet], or otherwise we're implicitly\ngiving miners a power of unilaterally changing some consensus rules\nthat they don't have, for users can't never be denied from the right\nto validate whatever rules they chose, just like an old radio receiver\nmachine owner cannot be forced to listen any channel in particular.\nThe \"consensus rules\" are in some sense the id of a theoretical\ncommunication channel, and should not be confused with a real-life\nprocess for how users should coordinate to \"upgrade\" to a new channel\n(which is what BIP99 is about) or how we can objectively know whether\na proposed changed has had \"adoption consensus\" or not, which is what\nthis BIP is about.\n\nBut yeah, suggestions totally welcomed for a replacement for \"adoption\nconsensus\".\n\n On Tue, Feb 2, 2016 at 8:41 PM, Luke Dashjr <luke at dashjr.org> wrote:\n> (Note Core currently has \"consensus\" only 249 times, most of which are simply\n> identifier names, so it would be trivial to make this change.)\n\nI'm afraid this would be horribly expensive in development hours for\nnot good enough reason and I must nack.\n\nOn Wed, Feb 3, 2016 at 1:03 AM, Luke Dashjr <luke at dashjr.org> wrote:\n> On Tuesday, February 02, 2016 11:28:40 PM Dave Scotese wrote:\n>> How about \"defining\" (rules, code, etc.) Such code and rules define what\n>> bitcoin is.  It does require consensus and it ends up being a concord, but\n>> all that can come after the fact (just as it did after bitcoin was first\n>> released to the public).\n>\n> The difficulty is that this BIP needs to refer to three different context of\n> consensus:\n>\n> 1. Consensus (stated) among developers for changes in the BIP Process.\n> 2. Economic consensus (potential and stated) to veto a soft-fork by an\n>    intended \"firing\" of the set of miners if they choose to enforce it.\n> 3. (Actual) consensus in economic adoption of changed rules, to determine the\n>    success of a hard-fork (after the fact).\n> 4. The set of rules currently established as (defining) Bitcoin, enforced by\n>    an (actual) consensus of economically-relevant nodes.\n>\n> Context 3 can be disambiguated with \"adoption consensus\", and context 4 with\n> \"consensus rules\" and/or \"consensus protocol\", but I don't see a clear\n> solution that covers all four contexts, and even sharing the word \"consensus\"\n> for them may be confusing.\n>\n> In addition, usage of the word \"consensus\" for context 4 has proven confusing\n> to users. For example, recently users misinterpreted the \"Consensus\" label\n> used in context 4 as implying that the idea itself had in fact achieved\n> consensus among some group of decision-makers (similar to context 1, but not\n> necessarily the group being \"developers\").\n>\n> I don't know a good way to make this completely clear, so suggestions are more\n> than welcome.\n>\n> Luke"
            }
        ],
        "thread_summary": {
            "title": "BIP Process: Status, comments, and copyright licenses",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Ryan Grant",
                "Dave Scotese",
                "Jorge Tim\u00f3n",
                "Luke Dashjr",
                "Gavin Andresen"
            ],
            "messages_count": 15,
            "total_messages_chars_count": 25432
        }
    },
    {
        "title": "[bitcoin-dev] [BIP Draft] Allow zero value OP_RETURN in Payment Protocol",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2016-02-02T17:03:57",
                "message_text_only": "On Tue, Jan 26, 2016 at 09:44:48AM -0800, Toby Padilla via bitcoin-dev wrote:\n> I really don't like the idea of policing other people's use of the\n> protocol. If a transaction pays its fee and has a greater than dust value,\n> it makes no sense to object to it.\n\nI'll point out that getting a BIP for a feature is *not* a hard\nrequirement for deployment. I'd encourage you to go write up your BIP\ndocument, give it a non-numerical name for ease of reference, and lobby\nwallet vendors to implement it.\n\nWhile I'll refrain from commenting on whether or not I think the feature\nitself is a good idea, I really don't want people to get the impression\nthat we're gatekeepers for how people choose use Bitcoin.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n000000000000000008320874843f282f554aa2436290642fcfa81e5a01d78698\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160202/6ed32172/attachment.sig>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2016-02-02T17:16:30",
                "message_text_only": "On Feb 2, 2016 18:04, \"Peter Todd via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> On Tue, Jan 26, 2016 at 09:44:48AM -0800, Toby Padilla via bitcoin-dev\nwrote:\n> > I really don't like the idea of policing other people's use of the\n> > protocol. If a transaction pays its fee and has a greater than dust\nvalue,\n> > it makes no sense to object to it.\n>\n> I'll point out that getting a BIP for a feature is *not* a hard\n> requirement for deployment. I'd encourage you to go write up your BIP\n> document, give it a non-numerical name for ease of reference, and lobby\n> wallet vendors to implement it.\n>\n> While I'll refrain from commenting on whether or not I think the feature\n> itself is a good idea, I really don't want people to get the impression\n> that we're gatekeepers for how people choose use Bitcoin.\n\nI'll go further: whatever people have commented here and elsewhere about\nthis feature (myself included) are personal opinions on the feature itself,\nin the hope you take the concerns into account.\n\nThese comments are not a judgement on whether this should be accepted as a\nBIP. Specifically, the BIP editor should accept a BIP even if he personally\ndislikes the ideas in it, when the criteria are satisfied.\n\nBeyond that, having a BIP accepted does not mean wallets have to implement\nit. That's up to the individual wallet authors/maintainers.\n\n-- \nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160202/1e70ea91/attachment.html>"
            },
            {
                "author": "Toby Padilla",
                "date": "2016-02-02T17:27:58",
                "message_text_only": "My BIP was ultimately accepted, it's number 74\n\nhttps://github.com/bitcoin/bips/blob/master/bip-0074.mediawiki\n\nThe editor did not agree with it, and I suspect would comment against it\nwith his new proposed BIP :)\n\nI really appreciated that despite his vehement disagreement, he assigned\nthe BIP. It seems like the process worked great. There was deep vetting,\nlots of back and forth and the editor put aside his personal opinions to\naccept the BIP.\n\nThat being said...\n\nThe mailing list is a problem. I'm still on moderation only. I have no idea\nif this message will go through and when it will go through. I totally\nunderstand the desire to keep the conversation level high, but when people\nwho *are* whitelisted can quickly post multiple heated arguments against\nyou (publicly) and you can't respond, then that starts to look very\ncentralized and discouraging.\n\nI would agree with Gavin on the other thread about the proposed BIP\ncommenting BIP. Putting more decision power behind a moderated mailing list\nand wiki doesn't seem like a good idea.\n\nOn Tue, Feb 2, 2016 at 9:16 AM, Pieter Wuille <pieter.wuille at gmail.com>\nwrote:\n\n> On Feb 2, 2016 18:04, \"Peter Todd via bitcoin-dev\" <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >\n> > On Tue, Jan 26, 2016 at 09:44:48AM -0800, Toby Padilla via bitcoin-dev\n> wrote:\n> > > I really don't like the idea of policing other people's use of the\n> > > protocol. If a transaction pays its fee and has a greater than dust\n> value,\n> > > it makes no sense to object to it.\n> >\n> > I'll point out that getting a BIP for a feature is *not* a hard\n> > requirement for deployment. I'd encourage you to go write up your BIP\n> > document, give it a non-numerical name for ease of reference, and lobby\n> > wallet vendors to implement it.\n> >\n> > While I'll refrain from commenting on whether or not I think the feature\n> > itself is a good idea, I really don't want people to get the impression\n> > that we're gatekeepers for how people choose use Bitcoin.\n>\n> I'll go further: whatever people have commented here and elsewhere about\n> this feature (myself included) are personal opinions on the feature itself,\n> in the hope you take the concerns into account.\n>\n> These comments are not a judgement on whether this should be accepted as a\n> BIP. Specifically, the BIP editor should accept a BIP even if he personally\n> dislikes the ideas in it, when the criteria are satisfied.\n>\n> Beyond that, having a BIP accepted does not mean wallets have to implement\n> it. That's up to the individual wallet authors/maintainers.\n>\n> --\n> Pieter\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160202/2685c93f/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-02-02T17:38:49",
                "message_text_only": "On Tue, Feb 02, 2016 at 09:27:58AM -0800, Toby Padilla wrote:\n> The mailing list is a problem. I'm still on moderation only. I have no idea\n> if this message will go through and when it will go through. I totally\n> understand the desire to keep the conversation level high, but when people\n> who *are* whitelisted can quickly post multiple heated arguments against\n> you (publicly) and you can't respond, then that starts to look very\n> centralized and discouraging.\n\nEveryone is on moderation only in this mailing list, myself included.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n000000000000000008320874843f282f554aa2436290642fcfa81e5a01d78698\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160202/77121ca4/attachment.sig>"
            },
            {
                "author": "Toby Padilla",
                "date": "2016-02-02T17:41:35",
                "message_text_only": "Then the moderation is being unevenly applied. Luke commented against my\nBIP multiple times right after it was published but it took hours for my\nresponses to go through and I had to track people down on IRC to ask about\nit:\n\nhttp://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-January/thread.html\n\nOn Tue, Feb 2, 2016 at 9:38 AM, Peter Todd <pete at petertodd.org> wrote:\n\n> On Tue, Feb 02, 2016 at 09:27:58AM -0800, Toby Padilla wrote:\n> > The mailing list is a problem. I'm still on moderation only. I have no\n> idea\n> > if this message will go through and when it will go through. I totally\n> > understand the desire to keep the conversation level high, but when\n> people\n> > who *are* whitelisted can quickly post multiple heated arguments against\n> > you (publicly) and you can't respond, then that starts to look very\n> > centralized and discouraging.\n>\n> Everyone is on moderation only in this mailing list, myself included.\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n> 000000000000000008320874843f282f554aa2436290642fcfa81e5a01d78698\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160202/2582a2cf/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-02-02T19:12:09",
                "message_text_only": "On Tue, Feb 02, 2016 at 09:41:35AM -0800, Toby Padilla wrote:\n> Then the moderation is being unevenly applied. Luke commented against my\n> BIP multiple times right after it was published but it took hours for my\n> responses to go through and I had to track people down on IRC to ask about\n> it:\n> \n> http://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-January/thread.html\n\nKeep in mind that actual human beings need to hit the approve button on\nyour posts; quite likely Luke happened to respond when those humans were\navailable, and you didn't. I personally had to do the exact same thing\nthe other day with one of my posts.\n\nModeration is an unfortunate thing to need, but this list is read by\nliterally hundreds of busy people, many of whome have had to unsubscribe\nat various points in the past due to a lack of moderation. I wish we had\na better solution, but that's what we have. We're also not along in\nusing fairly agressive moderation, for example the\ncryptography at metzdowd.com mailing list where Bitcoin was originally\nannounced uses manual approval moderation on all messages as well;\nthere's also an unmoderated offshoot of it, cryptography at randombit.net\n\n(and feel free to start an unmoderated version of bitcoin-dev!)\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n000000000000000008320874843f282f554aa2436290642fcfa81e5a01d78698\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160202/63e7cb64/attachment.sig>"
            },
            {
                "author": "Toby Padilla",
                "date": "2016-02-02T19:22:10",
                "message_text_only": "I think it would be helpful to clarify this in the list documentation.\nRight now there's a bunch of conflicting information.\n\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev states:\n\n\"*Greylisting Notice*\nYour first post to this list may be delayed by 5+ minutes due to Greylisting\n<https://en.wikipedia.org/wiki/Greylisting>. Subsequent posts should go\nthrough without delay.\"\n\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-October/011591.html\nstates:\n\n\"Everyone starts moderated, and the mod bit gets cleared as they post. It\ngets set again if someone notices or reports a violation.\"\n\nOn Tue, Feb 2, 2016 at 11:12 AM, Peter Todd <pete at petertodd.org> wrote:\n\n> On Tue, Feb 02, 2016 at 09:41:35AM -0800, Toby Padilla wrote:\n> > Then the moderation is being unevenly applied. Luke commented against my\n> > BIP multiple times right after it was published but it took hours for my\n> > responses to go through and I had to track people down on IRC to ask\n> about\n> > it:\n> >\n> >\n> http://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-January/thread.html\n>\n> Keep in mind that actual human beings need to hit the approve button on\n> your posts; quite likely Luke happened to respond when those humans were\n> available, and you didn't. I personally had to do the exact same thing\n> the other day with one of my posts.\n>\n> Moderation is an unfortunate thing to need, but this list is read by\n> literally hundreds of busy people, many of whome have had to unsubscribe\n> at various points in the past due to a lack of moderation. I wish we had\n> a better solution, but that's what we have. We're also not along in\n> using fairly agressive moderation, for example the\n> cryptography at metzdowd.com mailing list where Bitcoin was originally\n> announced uses manual approval moderation on all messages as well;\n> there's also an unmoderated offshoot of it, cryptography at randombit.net\n>\n> (and feel free to start an unmoderated version of bitcoin-dev!)\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n> 000000000000000008320874843f282f554aa2436290642fcfa81e5a01d78698\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160202/9808fdc5/attachment.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-02T19:14:17",
                "message_text_only": "On Tuesday, February 02, 2016 5:16:30 PM Pieter Wuille via bitcoin-dev wrote:\n> On Feb 2, 2016 18:04, \"Peter Todd via bitcoin-dev\" <\n> \n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > On Tue, Jan 26, 2016 at 09:44:48AM -0800, Toby Padilla via bitcoin-dev\n> \n> wrote:\n> > > I really don't like the idea of policing other people's use of the\n> > > protocol. If a transaction pays its fee and has a greater than dust\n> \n> value,\n> \n> > > it makes no sense to object to it.\n> > \n> > I'll point out that getting a BIP for a feature is *not* a hard\n> > requirement for deployment. I'd encourage you to go write up your BIP\n> > document, give it a non-numerical name for ease of reference, and lobby\n> > wallet vendors to implement it.\n> > \n> > While I'll refrain from commenting on whether or not I think the feature\n> > itself is a good idea, I really don't want people to get the impression\n> > that we're gatekeepers for how people choose use Bitcoin.\n> \n> I'll go further: whatever people have commented here and elsewhere about\n> this feature (myself included) are personal opinions on the feature itself,\n> in the hope you take the concerns into account.\n> \n> These comments are not a judgement on whether this should be accepted as a\n> BIP. Specifically, the BIP editor should accept a BIP even if he personally\n> dislikes the ideas in it, when the criteria are satisfied.\n> \n> Beyond that, having a BIP accepted does not mean wallets have to implement\n> it. That's up to the individual wallet authors/maintainers.\n\nAgree with both Peter and Pieter. Note that BIP 74 was assigned to this \nproposal last Friday.\n\nLuke"
            },
            {
                "author": "Peter Todd",
                "date": "2016-02-02T17:07:52",
                "message_text_only": "On Tue, Jan 26, 2016 at 09:41:01AM -0800, Toby Padilla via bitcoin-dev wrote:\n> The wording is a little strange and I think it *should* work as you state,\n> but Bitcoin Core will actually reject any output that has zero value (even\n> a single OP_RETURN output -- I just tested again to make sure).\n> \n> Here's the blocking code:\n> \n> https://github.com/bitcoin/bitcoin/blob/master/src/qt/paymentserver.cpp#L584\n> \n> I agree that this should be made more clear in my BIP though, I'll clean up\n> the language.\n\nNote that because the dust limit is ignored completely for OP_RETURN\noutputs, you can work around this by setting the OP_RETURN outputs to 1\nsatoshi instead.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n000000000000000008320874843f282f554aa2436290642fcfa81e5a01d78698\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160202/00a7da0d/attachment-0001.sig>"
            }
        ],
        "thread_summary": {
            "title": "Allow zero value OP_RETURN in Payment Protocol",
            "categories": [
                "bitcoin-dev",
                "BIP Draft"
            ],
            "authors": [
                "Pieter Wuille",
                "Luke Dashjr",
                "Peter Todd",
                "Toby Padilla"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 14243
        }
    },
    {
        "title": "[bitcoin-dev] Hardfork bit BIP",
        "thread_messages": [
            {
                "author": "jl2012",
                "date": "2016-02-04T17:14:49",
                "message_text_only": "https://github.com/bitcoin/bips/pull/317\n\nABSTRACT\n\nThis document specifies a proposed change to the semantics of the sign\nbit of the \"version\" field in Bitcoin block headers, as a mechanism to\nindicate a hardfork is deployed. It alleviates certain risks related to\na hardfork by introducing an explicit \"point of no return\" in the\nblockchain. This is a general mechanism which should be employed by any\nplanned hardfork in the future. \n\n [1]MOTIVATION\n\nHardforks in Bitcoin are usually considered as difficult and risky,\nbecause: \n\n \t* Hardforks require not only support of miners, but also, most\nimportantly, supermajority support of the Bitcoin economy. As a result,\nsoftfork deployment mechanisms described in BIP 34 [2] or BIP 9 [3] are\nnot enough for introducing hardforks safely.\n \t* Full nodes and SPV nodes following original consensus rules may not\nbe aware of the deployment of a hardfork. They may stick to an\neconomic-minority fork and unknowingly accept devalued legacy tokens.\n \t* In the case which the original consensus rules are also valid under\nthe new consensus rules, users following the new chain may unexpectedly\nreorg back to the original chain if it grows faster than the new one.\nPeople may find their confirmed transactions becoming unconfirmed and\nlose money.\n\nThe first issue involves soliciting support for a hardfork proposal,\nwhich is more a political topic than a technical one. This proposal aims\nat alleviating the risks related to the second and third issues. It\nshould be employed by any planned hardfork in the future.\n\n [4]DEFINITIONS\n\nSee BIP99 [5] \n\n [6]SPECIFICATION\n\nHARDFORK BIT The sign bit in nVersion is defined as the hardfork bit.\nCurrently, blocks with this header bit setting to 1 are invalid, since\nBIP65 [7] interprets nVersion as a signed number and requires it to be \u2265\n4. Among the 640 bits in the block header, this is the only one which is\nfixed and serves no purpose, and therefore the best way to indicate the\ndeployment of a hardfork. \n\nFLAG BLOCK Any planned hardfork must have one and only one flag block\nwhich is the \"point of no return\". To ensure monotonicity, flag block\nshould be determined by block height, or as the first block with\nGetMedianTimePast() greater than a threshold. Other mechanisms could be\ndifficult for SPV nodes to follow. The height/time threshold could be a\npredetermined value or relative to other events (e.g. 10000 blocks / 100\ndays after 95% of miner support). The exact mechanism is out of the\nscope of this BIP. No matter what mechanism is used, the threshold is\nconsensus critical. It must be publicly verifiable with only blockchain\ndata, and preferably SPV-friendly (i.e. verifiable with block headers\nonly, without downloading any transaction). \n\nFlag block is constructed in a way that nodes with the original\nconsensus rules must reject. On the other hand, nodes with the new\nconsensus rules must reject a block if it is not a flag block while it\nis supposed to be. To achieve these goals, the flag block must \n\n \t* have the hardfork bit setting to 1, and\n \t* follow any other rules required by the hardfork\n\nIf these conditions are not fully satisfied, upgraded nodes shall reject\nthe block.\n\nThe hardfork bit must be turned off in the successors of the flag block,\nuntil the deployment of the next hardfork. \n\nAlthough a hardfork is officially deployed when flag block is generated,\nthe exact behavioural change is out of the scope of this BIP. For\nexample, a hardfork may not be fully active until certain time after the\nflag block. \n\nCONCURRENT HARDFORK PROPOSALS To avoid confusion and unexpected\nbehaviour, a flag block should normally signify the deployment of only\none hardfork. Therefore, a hardfork proposal has to make sure that its\nflag block threshold is not clashing with other ongoing hardfork\nproposals. \n\nIn the case that the version bits mechanism is used in deploying a\nhardfork, height of the flag block should take a value of32N + B, where\nN is a positive integer and B is the position of bit B defined in BIP9\n[8]. This guarantees that no clash may happen with another hardfork\nproposal using BIP9. \n\nUNCONTROVERSIAL SUBTLE HARDFORKS Hardforks may sometimes be totally\nuncontroversial and make barely noticeable change (BIP50 [9], for\nexample). In such cases, the use of hardfork bit may not be needed as it\nmay cause unnecessary disruption. The risk and benefit should be\nevaluated case-by-case. \n\nAUTOMATIC WARNING SYSTEM When a flag block for an unknown hardfork is\nfound on the network, full nodes and SPV nodes should alert their users\nand/or stop accepting/sending transactions. It should be noted that the\nwarning system could become a denial-of-service vector if the attacker\nis willing to give up the block reward. Therefore, the warning may be\nissued only if a few blocks are built on top of the flag block in a\nreasonable time frame. This will in turn increase the risk in case of a\nreal planned hardfork so it is up to the wallet programmers to decide\nthe optimal strategy. Human warning system (e.g. the emergency alert\nsystem in Bitcoin Core) could fill the gap. \n\n [10]COMPATIBILITY\n\nAs a mechanism to indicate hardfork deployment, this BIP breaks backward\ncompatibility intentionally. However, without further changes in the\nblock header format, full nodes and SPV nodes could still verify the\nProof-of-Work of a flag block and its successors. \n\nHARDFORK INVOLVING CHANGE IN BLOCK HEADER FORMAT If a hardfork involves\na new block header format, the original format should still be used for\nthe flag block and a reasonable period afterwards, to make sure existing\nnodes realize that an unknown hardfork has been deployed. \n\nVERSION BITS This proposal is also compatible with the BIP9. The version\nbits mechanism could be employed to measure miner support towards a\nhardfork proposal, and to determine the height or time threshold of the\nflag block. Also, miners of the flag block may still cast votes for\nother concurrent softfork or hardfork proposals as normal. \n\nPOINT OF NO RETURN After the flag block is generated, a miner may\nsupport either the original rules or the new rules, but not both. It is\nnot possible for miners in one fork to attack or overtake the other fork\nwithout giving up the mining reward of their preferred fork. \n\n [11]COPYRIGHT\n\nThis document is placed in the public domain. \n\nLinks:\n------\n[1]\nhttps://github.com/jl2012/bips/blob/hardforkbit/hardforkbit.mediawiki#motivation\n[2] https://github.com/jl2012/bips/blob/hardforkbit/bip-0034.mediawiki\n[3] https://github.com/jl2012/bips/blob/hardforkbit/bip-0009.mediawiki\n[4]\nhttps://github.com/jl2012/bips/blob/hardforkbit/hardforkbit.mediawiki#definitions\n[5] https://github.com/jl2012/bips/blob/hardforkbit/bip-0099.mediawiki\n[6]\nhttps://github.com/jl2012/bips/blob/hardforkbit/hardforkbit.mediawiki#specification\n[7] https://github.com/jl2012/bips/blob/hardforkbit/bip-0065.mediawiki\n[8]\nhttps://github.com/jl2012/bips/blob/hardforkbit/bip-0009.mediawiki#Mechanism\n[9] https://github.com/jl2012/bips/blob/hardforkbit/bip-0050.mediawiki\n[10]\nhttps://github.com/jl2012/bips/blob/hardforkbit/hardforkbit.mediawiki#compatibility\n[11]\nhttps://github.com/jl2012/bips/blob/hardforkbit/hardforkbit.mediawiki#copyright\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160204/d4208f4f/attachment.html>"
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-02-04T17:36:06",
                "message_text_only": "This BIP is unnecessary, in my opinion.\n\nI'm going to take issue with items (2) and (3) that are the motivation for\nthis BIP:\n\n\" 2. Full nodes and SPV nodes following original consensus rules may not be\naware of the deployment of a hardfork. They may stick to an\neconomic-minority fork and unknowingly accept devalued legacy tokens.\"\n\nIf a hardfork is deployed by increasing the version number in blocks (as is\ndone for soft forks), then there is no risk-- Full and SPV nodes should\nnotice that they are seeing up-version blocks and warn the user that they\nare using obsolete software.\n\nIt doesn't matter if the software is obsolete because of hard or soft fork,\nthe difference in risks between those two cases will not be understood by\nthe typical full node or SPV node user.\n\n\" 3. In the case which the original consensus rules are also valid under\nthe new consensus rules, users following the new chain may unexpectedly\nreorg back to the original chain if it grows faster than the new one.\nPeople may find their confirmed transactions becoming unconfirmed and lose\nmoney.\"\n\nIf a hard or soft fork uses a 'grace period' (as described in BIP 9 or BIP\n101) then there is essentially no risk that a reorg will happen past the\ntriggering block. A block-chain re-org of two thousand or more blocks on\nthe main Bitcoin chain is unthinkable-- the economic chaos would be\nmassive, and the reaction to such a drastic (and extremely unlikely) event\nwould certainly be a hastily imposed checkpoint to get everybody back onto\nthe chain that everybody was using for economic transactions.\n\n\nSince I don't agree with the motivations for this BIP, I don't think the\nproposed mechanism (a negative-version-number-block) is necessary. And\nsince it would simply add more consensus-level code, I believe the\nkeep-it-simple principle applies.\n\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160204/ae4f4cab/attachment.html>"
            },
            {
                "author": "jl2012",
                "date": "2016-02-04T17:56:42",
                "message_text_only": "Gavin Andresen \u65bc 2016-02-04 12:36 \u5beb\u5230:\n> This BIP is unnecessary, in my opinion.\n> \n> I'm going to take issue with items (2) and (3) that are the motivation\n> for this BIP:\n> \n> \" 2. Full nodes and SPV nodes following original consensus rules may\n> not be aware of the deployment of a hardfork. They may stick to an\n> economic-minority fork and unknowingly accept devalued legacy tokens.\"\n> \n> If a hardfork is deployed by increasing the version number in blocks\n> (as is done for soft forks), then there is no risk-- Full and SPV\n> nodes should notice that they are seeing up-version blocks and warn\n> the user that they are using obsolete software.\n> \n> It doesn't matter if the software is obsolete because of hard or soft\n> fork, the difference in risks between those two cases will not be\n> understood by the typical full node or SPV node user.\n\nThanks for your comments.\n\nIn the case of a softfork, as long as an user waits for a few \nconfirmations, the risk of money loss is very low. In the worst case \nthey run a full node with SPV security. In the case of a hardfork, the \nconsequence of failing to upgrade to the economic majority fork *is* \nfatal, even if an user waits for 1000 confirmations. Not to mention the \nrisk of having 2 economically active forks. That's why wallets should \nSTOP accepting and sending tx after a hardfork bit is detected and wait \nfor users' instructions.\n\n> \" 3. In the case which the original consensus rules are also valid\n> under the new consensus rules, users following the new chain may\n> unexpectedly reorg back to the original chain if it grows faster than\n> the new one. People may find their confirmed transactions becoming\n> unconfirmed and lose money.\"\n> \n> If a hard or soft fork uses a 'grace period' (as described in BIP 9 or\n> BIP 101) then there is essentially no risk that a reorg will happen\n> past the triggering block. A block-chain re-org of two thousand or\n> more blocks on the main Bitcoin chain is unthinkable-- the economic\n> chaos would be massive, and the reaction to such a drastic (and\n> extremely unlikely) event would certainly be a hastily imposed\n> checkpoint to get everybody back onto the chain that everybody was\n> using for economic transactions.\n\nNo, the \"triggering block\" you mentioned is NOT where the hardfork \nstarts. Using BIP101 as an example, the hardfork starts when the first \n >1MB is mined. For people who failed to upgrade, the \"grace period\" is always zero, which is the moment they realize a hardfork.\n\n\n> Since I don't agree with the motivations for this BIP, I don't think\n> the proposed mechanism (a negative-version-number-block) is necessary.\n> And since it would simply add more consensus-level code, I believe the\n> keep-it-simple principle applies.\n> \n> --\n> \n> --\n> Gavin Andresen"
            },
            {
                "author": "Bryan Bishop",
                "date": "2016-02-04T18:00:49",
                "message_text_only": "On Thu, Feb 4, 2016 at 11:56 AM, jl2012 via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> past the triggering block. A block-chain re-org of two thousand or\n>> more blocks on the main Bitcoin chain is unthinkable-- the economic\n>> chaos would be massive, and the reaction to such a drastic (and\n>> extremely unlikely) event would certainly be a hastily imposed\n>> checkpoint to get everybody back onto the chain that everybody was\n>> using for economic transactions.\n>>\n>\n> No, the \"triggering block\" you mentioned is NOT where the hardfork starts.\n> Using BIP101 as an example, the hardfork starts when the first >1MB is\n> mined. For people who failed to upgrade, the \"grace period\" is always zero,\n> which is the moment they realize a hardfork.\n>\n\nAre there any plans written down anywhere about the \"hastily imposed\ncheckpoint\" scenario? As far as I know, we would have to check-point on\nboth blockchains because of the way that hard-forks work (creating two\nseparate chains and/or networks). Nothing about this should be an\n\"emergency\", we have all the time in the world to prepare a safe and\nresponsible way to upgrade the network without unilaterally\ndeclaring obsolescence.\n\n- Bryan\nhttp://heybryan.org/\n1 512 203 0507\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160204/21af804f/attachment.html>"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-02-04T18:24:31",
                "message_text_only": "On Thu, Feb 4, 2016 at 5:56 PM, jl2012 via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> No, the \"triggering block\" you mentioned is NOT where the hardfork starts.\n> Using BIP101 as an example, the hardfork starts when the first >1MB is\n> mined. For people who failed to upgrade, the \"grace period\" is always zero,\n> which is the moment they realize a hardfork.\n\n\nClients have to update in some way to get the benefit of this right?\n\nAn SPV client which fully validated the header chain would simply reject\nthe hard forking header.  Last time I checked, the Bitcoinj SPV wallet\nignored the version bits, and just followed the longest chain.  Is that\nstill the case?\n\nIn fact, does Core enforce the 95% rule for the soft-forks before checking\nfor long forks?  I am assuming that it happens when checking headers rather\nthan when checking full blocks.\n<https://www.avast.com/sig-email> This email has been sent from a\nvirus-free computer protected by Avast.\nwww.avast.com <https://www.avast.com/sig-email>\n<#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160204/d79be3a8/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-02-04T18:19:35",
                "message_text_only": "On Thu, Feb 04, 2016 at 12:36:06PM -0500, Gavin Andresen via bitcoin-dev wrote:\n> This BIP is unnecessary, in my opinion.\n> \n> I'm going to take issue with items (2) and (3) that are the motivation for\n> this BIP:\n> \n> \" 2. Full nodes and SPV nodes following original consensus rules may not be\n> aware of the deployment of a hardfork. They may stick to an\n> economic-minority fork and unknowingly accept devalued legacy tokens.\"\n> \n> If a hardfork is deployed by increasing the version number in blocks (as is\n> done for soft forks), then there is no risk-- Full and SPV nodes should\n> notice that they are seeing up-version blocks and warn the user that they\n> are using obsolete software.\n\n1) There is no way to guarantee that nodes will see those blocks, and\nthe current network behavior works against such guarantees even in the\nnon-adversarial case.\n\n2) I know of no currently deployed SPV wallet software that warns users\nabout unknown block versions anyway.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n000000000000000008320874843f282f554aa2436290642fcfa81e5a01d78698\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160204/a5e24fde/attachment.sig>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-04T18:29:11",
                "message_text_only": "On Thursday, February 04, 2016 5:14:49 PM jl2012 via bitcoin-dev wrote:\n> ABSTRACT\n> \n> This document specifies a proposed change to the semantics of the sign\n> bit of the \"version\" field in Bitcoin block headers, as a mechanism to\n> indicate a hardfork is deployed.\n\nDisagree with treating the \"version\" field as a number, in BIP 9 or this BIP \nwhich reinterpret it as a bit vector.\n\n> Among the 640 bits in the block header, this is the only one which is\n> fixed and serves no purpose, ...\n\nMinor nit (not relevant to actual proposal): This is not true. There are over \n32 other bits (part of the \"previous-block\" field) which also serve no \npurpose.\n\n> FLAG BLOCK Any planned hardfork must have one and only one flag block\n> which is the \"point of no return\". To ensure monotonicity, flag block\n> should be determined by block height, or as the first block with\n> GetMedianTimePast() greater than a threshold. Other mechanisms could be\n> difficult for SPV nodes to follow. The height/time threshold could be a\n> predetermined value or relative to other events (e.g. 10000 blocks / 100\n> days after 95% of miner support). The exact mechanism is out of the\n> scope of this BIP. No matter what mechanism is used, the threshold is\n> consensus critical. It must be publicly verifiable with only blockchain\n> data, and preferably SPV-friendly (i.e. verifiable with block headers\n> only, without downloading any transaction).\n\nWith the current codebase, it is significantly easier to trigger on the block \ntimestamp rather than its height or median-time-past. Using either of the \nlatter would require refactoring of CBlockIndex. As a hard-fork, even if the \nrules are ineffective for a few blocks following the forking point, using the \nhardfork version bit in this BIP would still ensure a clean break. While I \nagree that median-time-past and height are superior methods that ought to be \nused for hardforks, an emergency hardfork may need to avoid them for \nsimplicity, and I don't think they need to be mandated as such in this BIP.\n\n> Although a hardfork is officially deployed when flag block is generated, ...\n\nI would avoid implying the hardfork can be \"officially deployed\" without \nactual adoption.\n\n> AUTOMATIC WARNING SYSTEM When a flag block for an unknown hardfork is\n> found on the network, full nodes and SPV nodes should alert their users\n> and/or stop accepting/sending transactions. It should be noted that the\n> warning system could become a denial-of-service vector if the attacker\n> is willing to give up the block reward. Therefore, the warning may be\n> issued only if a few blocks are built on top of the flag block in a\n> reasonable time frame. This will in turn increase the risk in case of a\n> real planned hardfork so it is up to the wallet programmers to decide\n> the optimal strategy. Human warning system (e.g. the emergency alert\n> system in Bitcoin Core) could fill the gap.\n\nThis seems vulnerable to DoS attacks by rejected hardforks.\n\n> VERSION BITS This proposal is also compatible with the BIP9. The version\n> bits mechanism could be employed to measure miner support towards a\n> hardfork proposal, and to determine the height or time threshold of the\n> flag block. Also, miners of the flag block may still cast votes for\n> other concurrent softfork or hardfork proposals as normal.\n\nRather not imply BIP 9 should be used for hardforks, or that miners have any \nvoice in the decision. This is already a serious misconception.\n\n> POINT OF NO RETURN After the flag block is generated, a miner may\n> support either the original rules or the new rules, but not both. It is\n> not possible for miners in one fork to attack or overtake the other fork\n> without giving up the mining reward of their preferred fork.\n\nThis is not actually desirable, and would suggest a possible reason *not* to \ncomply with this BIP. A legitimate hardfork would never have two continued \nsets of rules for miners to choose from.\n\nLuke"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2016-02-05T10:20:28",
                "message_text_only": "On Feb 4, 2016 19:29, \"Luke Dashjr via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> On Thursday, February 04, 2016 5:14:49 PM jl2012 via bitcoin-dev wrote:\n> > ABSTRACT\n> >\n> > This document specifies a proposed change to the semantics of the sign\n> > bit of the \"version\" field in Bitcoin block headers, as a mechanism to\n> > indicate a hardfork is deployed.\n>\n> Disagree with treating the \"version\" field as a number, in BIP 9 or this\nBIP\n> which reinterpret it as a bit vector.\n\nI don't interpret this as \"treating version bits as a number\" it is just\nbeing explained which bit we're talking about. Could you propose some\nconcrete rephrasing instead of leaving the task of somehow solving this\nvague and subtle concern to the author?\n\n> > FLAG BLOCK Any planned hardfork must have one and only one flag block\n> > which is the \"point of no return\". To ensure monotonicity, flag block\n> > should be determined by block height, or as the first block with\n> > GetMedianTimePast() greater than a threshold. Other mechanisms could be\n> > difficult for SPV nodes to follow. The height/time threshold could be a\n> > predetermined value or relative to other events (e.g. 10000 blocks / 100\n> > days after 95% of miner support). The exact mechanism is out of the\n> > scope of this BIP. No matter what mechanism is used, the threshold is\n> > consensus critical. It must be publicly verifiable with only blockchain\n> > data, and preferably SPV-friendly (i.e. verifiable with block headers\n> > only, without downloading any transaction).\n>\n> With the current codebase, it is significantly easier to trigger on the\nblock\n> timestamp rather than its height or median-time-past. Using either of the\n> latter would require refactoring of CBlockIndex. As a hard-fork, even if\nthe\n> rules are ineffective for a few blocks following the forking point, using\nthe\n> hardfork version bit in this BIP would still ensure a clean break. While I\n> agree that median-time-past and height are superior methods that ought to\nbe\n> used for hardforks, an emergency hardfork may need to avoid them for\n> simplicity, and I don't think they need to be mandated as such in this\nBIP.\n\nI very much disagree with \"significant\" and in any case it depends on the\nhardfork: the changes required can still be quite minimal in all cases and\nit should never be a problem, even for emergency hardforks. In emergency,\nwe could for example just a new global (we have many already anyway),\nalthough activeChain.tip () is already there and one can simply get the\nlast height or median time from there.\n\n> > VERSION BITS This proposal is also compatible with the BIP9. The version\n> > bits mechanism could be employed to measure miner support towards a\n> > hardfork proposal, and to determine the height or time threshold of the\n> > flag block. Also, miners of the flag block may still cast votes for\n> > other concurrent softfork or hardfork proposals as normal.\n>\n> Rather not imply BIP 9 should be used for hardforks, or that miners have\nany\n> voice in the decision. This is already a serious misconception.\n\nThis is consistent with bip99, which recommends bip9 for deploying\nuncontroversial hardforks.\n\n> > POINT OF NO RETURN After the flag block is generated, a miner may\n> > support either the original rules or the new rules, but not both. It is\n> > not possible for miners in one fork to attack or overtake the other fork\n> > without giving up the mining reward of their preferred fork.\n>\n> This is not actually desirable, and would suggest a possible reason *not*\nto\n> comply with this BIP. A legitimate hardfork would never have two continued\n> sets of rules for miners to choose from.\n\nControversial hardforks (as defined bip9) always have the potential to\ncreate two chains that survive for unbounded amounts of time (maybe\nforever) as discussed in one of the few threads of the bitcoin discuss\nmailing list.\nOf course, BIP99 cannot say anything general about the \"legitimacy\" of all\ncontroversial hardforks since ASIC-reset hardforks, for example, are\ncontroversial hardforks by definition in the context of bip99 (and the\ndefinitions in bip99 seem to apply to this bip). BIP99 can only warn about\nthe dangers and risks of controversial hardforks but at some point (let's\nhope never) a controversial hardfork may be required to save the system\nfrom some evil (say, evil miners blacklisting via softforking out the\nminers that don't  blacklist or something) and that controversial hardfork\nwould be legitimate (at least to the eyes of some).\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160205/75a17e18/attachment-0001.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2016-02-04T19:36:58",
                "message_text_only": "On Thu, Feb 4, 2016 at 5:14 PM, jl2012 via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> https://github.com/bitcoin/bips/pull/317\n\nI think this is a good idea, and I've independently proposed it in the past.\n\nI agree with most of luke's language nitpicks.\n\nIt could, however, be pointed out that the version number flag is not\nsufficient in the deployed network, because many clients also do not\nvalidate the version field, due to a disinterest in security great\nenough to not implement anything around height-in-coinbase.\n\nSo to fully achieve the intended effect using the highest bit of prev\nwould currently be much more effective."
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-02-04T22:15:41",
                "message_text_only": "It is always possible I'm being dense, but I still don't understand how\nthis proposal makes a chain-forking situation better for anybody.\n\nIf there are SPV clients that don't pay attention to versions in block\nheaders, then setting the block version negative doesn't directly help\nthem, they will ignore it in any case.\n\nIf the worry is full nodes that are not upgraded, then a block with a\nnegative version number will, indeed, fork them off the the chain, in\nexactly the same way a block with new hard-forking consensus rules would.\nAnd with the same consequences (if there is any hashpower not paying\nattention, then a worthless minority chain might continue on with the old\nrules).\n\nIf the worry is not-upgraded SPV clients connecting to the old,\nnot-upgraded full nodes, I don't see how this proposed BIP helps.\n\nI think a much better idea than this proposed BIP would be a BIP that\nrecommends that SPV clients to pay attention to block version numbers in\nthe headers that they download, and warn if there is a soft OR hard fork\nthat they don't know about.\n\nIt is also a very good idea for SPV clients to pay attention to timestamps\nin the block headers that the receive, and to warn if blocks were generated\neither much slower or faster than statistically likely. Doing that (as\nBitcoin Core already does) will mitigate Sybil attacks in general.\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160204/58242583/attachment.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2016-02-05T09:58:36",
                "message_text_only": "Concept ACK. I've been talking about adding this to BIP99 since before\nscaling bitcoin Hong Kong, so it will be nice to have a BIP to just point\nto. Also I hadn't thought about concurrent deployment of 2 hardforks, nice.\n\nOn Feb 4, 2016 23:30, \"Gavin Andresen via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> If the worry is full nodes that are not upgraded, then a block with a\nnegative version number will, indeed, fork them off the the chain, in\nexactly the same way a block with new hard-forking consensus rules would.\nAnd with the same consequences (if there is any hashpower not paying\nattention, then a worthless minority chain might continue on with the old\nrules).\n\nAdditionally, a warning or special error could be thrown when a block is\nrejected due to the hardfork bit being activated.\n\n> I think a much better idea than this proposed BIP would be a BIP that\nrecommends that SPV clients to pay attention to block version numbers in\nthe headers that they download, and warn if there is a soft OR hard fork\nthat they don't know about.\n\nAlthough I agree this PR should include such warning/error recommendations,\nSPV nodes can't tell whether a change is a hardfork or a softfork just by\nlooking at the version bits, even in the case of uncontroversial hardforks\ndeployed with bip9 as recommended by bip99. For controversial hardforks\nwhere bip9 should NOT be used for deployment, setting the hardfork bit is\neven more important.\n\n> It is also a very good idea for SPV clients to pay attention to\ntimestamps in the block headers that the receive, and to warn if blocks\nwere generated either much slower or faster than statistically likely.\nDoing that (as Bitcoin Core already does) will mitigate Sybil attacks in\ngeneral.\n\nThis seems out of the scope of this PR.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160205/ca469b50/attachment.html>"
            },
            {
                "author": "jl2012 at xbt.hk",
                "date": "2016-02-07T19:27:48",
                "message_text_only": "From: Gavin Andresen [mailto:gavinandresen at gmail.com] \nSent: Friday, 5 February, 2016 06:16\nTo: Gregory Maxwell <greg at xiph.org>\nCc: jl2012 <jl2012 at xbt.hk>; Bitcoin Dev <bitcoin-dev at lists.linuxfoundation.org>\nSubject: Re: [bitcoin-dev] Hardfork bit BIP\n\n>It is always possible I'm being dense, but I still don't understand how this proposal makes a chain-forking situation better for anybody.\n\n>If there are SPV clients that don't pay attention to versions in block headers, then setting the block version negative doesn't directly help them, they will ignore it in any case.\n\nIt is unfortunate SPV clients are not following that. However, they SHOULD follow that. It becomes a self fulfilling prophecy if we decide not to do that if SPV are not following that.\n\n>If the worry is full nodes that are not upgraded, then a block with a negative version number will, indeed, fork them off the the chain, in exactly the same way a block with new hard-forking consensus rules would. And with the same consequences (if there is any hashpower not paying attention, then a worthless minority chain might continue on with the old rules).\n\nIt will distinguish between a planned hardfork and an accidental hardfork, and full nodes may react differently. Particularly, a planned unknown hardfork is a strong indication that the original chain has become economic minority and the non-upgraded full node should stop accepting incoming tx immediately.\n\n>If the worry is not-upgraded SPV clients connecting to the old, not-upgraded full nodes, I don't see how this proposed BIP helps.\n\nSame for not-upgraded full nodes following not-upgraded full nodes. Anyway, the header with enough PoW should still be propagated.\n\n>I think a much better idea than this proposed BIP would be a BIP that recommends that SPV clients to pay attention to block version numbers in the headers that they download, and warn if there is a soft OR hard fork that they don't know about.\n\nNormal version number only suggests softforks, which is usually not a concern for SPV clients. An unknown hardfork is a completely different story as the values of the forks are completely unknown.\n\n>It is also a very good idea for SPV clients to pay attention to timestamps in the block headers that the receive, and to warn if blocks were generated either much slower or faster than statistically likely. Doing that (as Bitcoin Core already does) will mitigate Sybil attacks in general.\n\nYes, they should.\n\n-- \n--\nGavin Andresen"
            },
            {
                "author": "Gavin",
                "date": "2016-02-07T20:20:27",
                "message_text_only": "> On Feb 7, 2016, at 2:27 PM, <jl2012 at xbt.hk> <jl2012 at xbt.hk> wrote:\n> \n> Normal version number only suggests softforks, which is usually not a concern for SPV clients.\n\nSoft forks affect the security of low-confirmation (zero or one) transactions sent to SPV wallets even more than hard forks, and because many users and businesses choose convenience over airtight security I would argue transaction validation rule changes are a VERY big concern for lightweight clients."
            },
            {
                "author": "Anthony Towns",
                "date": "2016-02-08T02:44:32",
                "message_text_only": "On Sun, Feb 07, 2016 at 03:20:27PM -0500, Gavin via bitcoin-dev wrote:\n> > On Feb 7, 2016, at 2:27 PM, <jl2012 at xbt.hk> <jl2012 at xbt.hk> wrote:\n> > Normal version number only suggests softforks, which is usually not a concern for SPV clients.\n> Soft forks affect the security of low-confirmation (zero or one) transactions sent to SPV wallets even more than hard forks,\n\nThis isn't true for soft-forks that only forbid transactions that would\nalready be rejected for forwarding and mining due to being non-standard.\n\n> and because many users and businesses choose convenience over airtight security I would argue transaction validation rule changes are a VERY big concern for lightweight clients.\n\nI agree on that point; but ensuring soft-forks only affect non-standard\ntransactions already addresses that concern in every way I've been able\nto discover.\n\nCheers,\naj"
            }
        ],
        "thread_summary": {
            "title": "Hardfork bit BIP",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Bryan Bishop",
                "Gavin",
                "Anthony Towns",
                "Peter Todd",
                "Tier Nolan",
                "Jorge Tim\u00f3n",
                "Luke Dashjr",
                "Gregory Maxwell",
                "Gavin Andresen",
                "jl2012 at xbt.hk",
                "jl2012"
            ],
            "messages_count": 14,
            "total_messages_chars_count": 32932
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Core 0.12.0 release candidate 3 available",
        "thread_messages": [
            {
                "author": "Wladimir J. van der Laan",
                "date": "2016-02-05T11:30:24",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nBinaries for bitcoin Core version 0.12.0rc3 are available from:\n\n    https://bitcoin.org/bin/bitcoin-core-0.12.0/test/\n\nSource code can be found on github under the signed tag\n\n    https://github.com/bitcoin/bitcoin/tree/v0.12.0rc3\n\nThis is a release candidate for a new major version release, bringing new\nfeatures, bug fixes, as well as other improvements.\n\nPreliminary release notes for the release can be found here:\n\n    https://github.com/bitcoin/bitcoin/blob/0.12/doc/release-notes.md\n\nRelease candidates are test versions for releases. When no critical problems\nare found, this release candidate will be tagged as 0.12.0.\n\nDiff since rc2:\n- - #7440 `c76bfff` Rename permitrbf to mempoolreplacement and provide minimal string-list forward compatibility\n- - #7415 `cb83beb` net: Hardcoded seeds update January 2016\n- - #7438 `e2d9a58` Do not absolutely protect local peers; decide group ties based on time\n- - #7439 `86755bc` Add whitelistforcerelay to control forced relaying. [#7099 redux]\n- - #7424 `aa26ee0` Add security/export checks to gitian and fix current failures\n- - #7384 `294f432` [qt] Peertable: Increase SUBVERSION_COLUMN_WIDTH\n\nAlso, a new certificate was used to sign the Windows installer, which should solve\nWin7 compatibility issues.\n\nThanks to the gitian builders for keeping up so quickly, thanks\nto them there are executables so quickly after tagging.\n\nPlease report bugs using the issue tracker at github:\n\n    https://github.com/bitcoin/bitcoin/issues\n\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1\n\niQEcBAEBCgAGBQJWtIe6AAoJEHSBCwEjRsmmuX0IAJP7JJ4OozZZ5psY7QF35ouV\nE0Vxws470pFyn+iFvz1OwLbeSyhIiLvR1xHZCrFkLbt5vrolJGILQb5xWaFfqDVv\nuXIPDzbQ+mJ/cPr2BXWrkjkVC33TBuwiLGethDDb4xlQhSki79EvZqbTkhIz7HxX\njrW8d+zUq+2pOilhqDyZGlzCRhQOZI6W+TFwo4jEunZN+m1BSD2/vhVxIZQzP6jf\nVt6xw23SFbTH+b9dY3Skho/A+gdXSitVpYmDttbOlcIX4AQ7lUmsaqFeaV4z92d+\nYqipqLiNkGqXdEYFikyQgM24J4fYm4htZhTBg5y5W8tsIWO6z36tUXVBxmqq6A0=\n=mevA\n-----END PGP SIGNATURE-----"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Core 0.12.0 release candidate 3 available",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Wladimir J. van der Laan"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2005
        }
    },
    {
        "title": "[bitcoin-dev] BIP draft: Hard fork opt-in mechanism for SPV nodes",
        "thread_messages": [
            {
                "author": "jl2012",
                "date": "2016-02-05T18:40:57",
                "message_text_only": "BIP draft: Hard fork opt-in mechanism for SPV nodes:\nhttps://github.com/bitcoin/bips/pull/320\n\nThis is a supplement, instead of a replacement, of the hardfork bit BIP:\nhttps://github.com/bitcoin/bips/pull/317\n\nThey solves different problems:\n\nThe hardfork bit tells full and SPV that a planned hardfork (instead of\na softfork) has happened.\n\nThis BIP makes sure SPV nodes won't lose any money in a hardfork, even\nif they do not check the hardfork bit.\n\n---------------------\n\nBIP: ?\nTitle: Hard fork opt-in mechanism for SPV nodes\nAuthor: Johnson Lau <jl2012 at xbt.hk>\nStatus: Draft\nType: Standard Track\nCreated: 2016-02-05\n\nABSTRACT\n\nThis document specifies a new algorithm for the transaction commitment\nin block header, to ensure that SPV nodes will not automatically follow\na planned hard fork without explicit opt-in consent. \n\n [1]MOTIVATION\n\nA hard fork in Bitcoin is a consensus rule change where previously\ninvalid blocks become valid. For the operators of fully validating\nnodes, migration to the new fork requires conscious actions. However,\nthis may not be true for SPV node, as many consensus rules are\ntransparent to them. SPV nodes may follow the chain with most\nproof-of-work, even if the operators do not agree with the economical or\nideological properties of the chain. \n\nBy specifying a new algorithm for the transaction commitment in block\nheader, migration to the new fork requires explicit opt-in consent for\nSPV nodes. It is expected that this proposal will be implemented with\nother backward-incompatible consensus rule changes at the same time. \n\n [2]SPECIFICATION\n\nThe calculation of Merkle root remains unchanged. Instead of directly\ncommitting the Merkle root to the header, we commit \n\n Double-SHA256(zero|merkle_root|zero)\n\nwhere zero is 0x0000....0000 with 32 bytes. \n\n [3]RATIONALE\n\nSince the header structure is not changed, non-upgraded SPV nodes will\nstill be able to verify the proof-of-work of the new chain, and they\nwill follow the new chain if it has most proof-of-work. However, they\nwill not be able to the accept any incoming transactions on the new\nchain since they cannot verify them with the new commitment format. At\nthe same time, SPV nodes will not accept any new transactions on the old\nchain, as they find it has less proof-of-work. Effectively, SPV nodes\nstop accepting any transactions, until their operators take further\nactions. \n\nZero-padding is applied before and after the merkle_root, so it is not\npossible to circumvent the rule change with any current implementations,\neven for faulty ones. \n\nA future hard fork should change the padding value to stop non-upgraded\nSPV nodes from processing new transactions. \n\nHard forks may sometimes be totally uncontroversial and make barely\nnoticeable change (BIP50 [4], for example). In such cases, changing the\npadding value may not be needed as it may cause unnecessary disruption.\nThe risk and benefit should be evaluated case-by-case. \n\n [5]COMPATIBILITY\n\nAs a mechanism to indicate hard fork deployment, this BIP breaks\nbackward compatibility intentionally. However, without further changes\nin the block header format, non-upgraded full nodes and SPV nodes could\nstill verify the proof-of-work of upgraded blocks. \n\nINTERACTION WITH FRAUD PROOF SYSTEM A fraud proof system is full nodes\nthat will generate compact proofs to testify invalid blocks on the\nblockchain, verifiable by SPV nodes. Hard forks without any malicious\nintention may also be considered as a \"fraud\" among non-upgraded nodes.\nThis may not be desirable, as the SPV node may accept devalued tokens on\nthe old chain with less proof-of-work. With this BIP, non-upgraded SPV\nnodes will always believe the new chain is valid (since they cannot\nverify any fraud proof), while cannot be defrauded as they will not see\nany incoming transactions. \n\n [6]COPYRIGHT\n\nThis document is placed in the public domain. \n\nLinks:\n------\n[1]\nhttps://github.com/jl2012/bips/blob/merkleroot/spvoptinhf.mediawiki#motivation\n[2]\nhttps://github.com/jl2012/bips/blob/merkleroot/spvoptinhf.mediawiki#specification\n[3]\nhttps://github.com/jl2012/bips/blob/merkleroot/spvoptinhf.mediawiki#rationale\n[4] https://github.com/jl2012/bips/blob/merkleroot/bip-0050.mediawiki\n[5]\nhttps://github.com/jl2012/bips/blob/merkleroot/spvoptinhf.mediawiki#compatibility\n[6]\nhttps://github.com/jl2012/bips/blob/merkleroot/spvoptinhf.mediawiki#copyright\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160205/df2b2606/attachment.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-05T23:25:14",
                "message_text_only": "Soft-hardforks have the same behaviour for both SPV and full nodes.\nI don't see the point in making this SPV-only \"middle layer\"...\n\nOn Friday, February 05, 2016 6:40:57 PM jl2012 via bitcoin-dev wrote:\n> BIP draft: Hard fork opt-in mechanism for SPV nodes:\n> https://github.com/bitcoin/bips/pull/320\n> \n> This is a supplement, instead of a replacement, of the hardfork bit BIP:\n> https://github.com/bitcoin/bips/pull/317\n> \n> They solves different problems:\n> \n> The hardfork bit tells full and SPV that a planned hardfork (instead of\n> a softfork) has happened.\n> \n> This BIP makes sure SPV nodes won't lose any money in a hardfork, even\n> if they do not check the hardfork bit.\n> \n> ---------------------\n> \n> BIP: ?\n> Title: Hard fork opt-in mechanism for SPV nodes\n> Author: Johnson Lau <jl2012 at xbt.hk>\n> Status: Draft\n> Type: Standard Track\n> Created: 2016-02-05\n> \n> ABSTRACT\n> \n> This document specifies a new algorithm for the transaction commitment\n> in block header, to ensure that SPV nodes will not automatically follow\n> a planned hard fork without explicit opt-in consent.\n> \n>  [1]MOTIVATION\n> \n> A hard fork in Bitcoin is a consensus rule change where previously\n> invalid blocks become valid. For the operators of fully validating\n> nodes, migration to the new fork requires conscious actions. However,\n> this may not be true for SPV node, as many consensus rules are\n> transparent to them. SPV nodes may follow the chain with most\n> proof-of-work, even if the operators do not agree with the economical or\n> ideological properties of the chain.\n> \n> By specifying a new algorithm for the transaction commitment in block\n> header, migration to the new fork requires explicit opt-in consent for\n> SPV nodes. It is expected that this proposal will be implemented with\n> other backward-incompatible consensus rule changes at the same time.\n> \n>  [2]SPECIFICATION\n> \n> The calculation of Merkle root remains unchanged. Instead of directly\n> committing the Merkle root to the header, we commit\n> \n>  Double-SHA256(zero|merkle_root|zero)\n> \n> where zero is 0x0000....0000 with 32 bytes.\n> \n>  [3]RATIONALE\n> \n> Since the header structure is not changed, non-upgraded SPV nodes will\n> still be able to verify the proof-of-work of the new chain, and they\n> will follow the new chain if it has most proof-of-work. However, they\n> will not be able to the accept any incoming transactions on the new\n> chain since they cannot verify them with the new commitment format. At\n> the same time, SPV nodes will not accept any new transactions on the old\n> chain, as they find it has less proof-of-work. Effectively, SPV nodes\n> stop accepting any transactions, until their operators take further\n> actions.\n> \n> Zero-padding is applied before and after the merkle_root, so it is not\n> possible to circumvent the rule change with any current implementations,\n> even for faulty ones.\n> \n> A future hard fork should change the padding value to stop non-upgraded\n> SPV nodes from processing new transactions.\n> \n> Hard forks may sometimes be totally uncontroversial and make barely\n> noticeable change (BIP50 [4], for example). In such cases, changing the\n> padding value may not be needed as it may cause unnecessary disruption.\n> The risk and benefit should be evaluated case-by-case.\n> \n>  [5]COMPATIBILITY\n> \n> As a mechanism to indicate hard fork deployment, this BIP breaks\n> backward compatibility intentionally. However, without further changes\n> in the block header format, non-upgraded full nodes and SPV nodes could\n> still verify the proof-of-work of upgraded blocks.\n> \n> INTERACTION WITH FRAUD PROOF SYSTEM A fraud proof system is full nodes\n> that will generate compact proofs to testify invalid blocks on the\n> blockchain, verifiable by SPV nodes. Hard forks without any malicious\n> intention may also be considered as a \"fraud\" among non-upgraded nodes.\n> This may not be desirable, as the SPV node may accept devalued tokens on\n> the old chain with less proof-of-work. With this BIP, non-upgraded SPV\n> nodes will always believe the new chain is valid (since they cannot\n> verify any fraud proof), while cannot be defrauded as they will not see\n> any incoming transactions.\n> \n>  [6]COPYRIGHT\n> \n> This document is placed in the public domain.\n> \n> Links:\n> ------\n> [1]\n> https://github.com/jl2012/bips/blob/merkleroot/spvoptinhf.mediawiki#motivat\n> ion [2]\n> https://github.com/jl2012/bips/blob/merkleroot/spvoptinhf.mediawiki#specifi\n> cation [3]\n> https://github.com/jl2012/bips/blob/merkleroot/spvoptinhf.mediawiki#rationa\n> le [4] https://github.com/jl2012/bips/blob/merkleroot/bip-0050.mediawiki\n> [5]\n> https://github.com/jl2012/bips/blob/merkleroot/spvoptinhf.mediawiki#compati\n> bility [6]\n> https://github.com/jl2012/bips/blob/merkleroot/spvoptinhf.mediawiki#copyrig\n> ht"
            }
        ],
        "thread_summary": {
            "title": "BIP draft: Hard fork opt-in mechanism for SPV nodes",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Luke Dashjr",
                "jl2012"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 9363
        }
    },
    {
        "title": "[bitcoin-dev] BIP proposal: Increase block size limit to 2 megabytes",
        "thread_messages": [
            {
                "author": "Gavin Andresen",
                "date": "2016-02-05T20:51:08",
                "message_text_only": "This has been reviewed by merchants, miners and exchanges for a couple of\nweeks, and has been implemented and tested as part of the Bitcoin Classic\nand Bitcoin XT implementations.\n\nConstructive feedback welcome; argument about whether or not it is a good\nidea to roll out a hard fork now will be unproductive, so I vote we don't\ngo there.\n\nDraft BIP:\n  https://github.com/gavinandresen/bips/blob/bump2mb/bip-bump2mb.mediawiki\n\nSummary:\n  Increase block size limit to 2,000,000 bytes.\n  After 75% hashpower support then 28-day grace period.\n  With accurate sigop counting, but existing sigop limit (20,000)\n  And a new, high limit on signature hashing\n\nBlog post walking through the code:\n  http://gavinandresen.ninja/a-guided-tour-of-the-2mb-fork\n\nBlog post on a couple of the constants chosen:\n  http://gavinandresen.ninja/seventyfive-twentyeight\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160205/75a2eca2/attachment.html>"
            },
            {
                "author": "Yifu Guo",
                "date": "2016-02-05T22:36:09",
                "message_text_only": "\"We can look at the adoption of the last major Bitcoin core release to\nguess how long it might take people to upgrade. 0.11.0 was released on 12\nJuly, 2015. Twenty eight days later, about 38% of full nodes were running\nthat release. Three months later, about 50% of the network was running that\nrelease, and six months later about 66% of the network was running some\nflavor of 0.11.\"\n\nOn what grounds do you think it is reasonable to assume that this update\nwill roll out 6x faster than previous data suggested, as oppose to your own\nobservation of 66% adoption in 6 month. or do you believe 38% node\nupgrade-coverage ( in 28 days ) on the network for a hard fork is good\nenough?\n\nThere are no harm in choosing a longer grace period but picking one short\nas 28 days you risk on alienating the nodes who do not upgrade with the\naggressive upgrade timeline you proposed.\n\n\n\nOn Fri, Feb 5, 2016 at 3:51 PM, Gavin Andresen via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> This has been reviewed by merchants, miners and exchanges for a couple of\n> weeks, and has been implemented and tested as part of the Bitcoin Classic\n> and Bitcoin XT implementations.\n>\n> Constructive feedback welcome; argument about whether or not it is a good\n> idea to roll out a hard fork now will be unproductive, so I vote we don't\n> go there.\n>\n> Draft BIP:\n>   https://github.com/gavinandresen/bips/blob/bump2mb/bip-bump2mb.mediawiki\n>\n> Summary:\n>   Increase block size limit to 2,000,000 bytes.\n>   After 75% hashpower support then 28-day grace period.\n>   With accurate sigop counting, but existing sigop limit (20,000)\n>   And a new, high limit on signature hashing\n>\n> Blog post walking through the code:\n>   http://gavinandresen.ninja/a-guided-tour-of-the-2mb-fork\n>\n> Blog post on a couple of the constants chosen:\n>   http://gavinandresen.ninja/seventyfive-twentyeight\n>\n> --\n> --\n> Gavin Andresen\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n\n\n-- \n*Yifu Guo*\n*\"Life is an everlasting self-improvement.\"*\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160205/e9662b77/attachment.html>"
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-02-07T17:09:46",
                "message_text_only": "As I feared, request on feedback for this specific BIP has devolved into a\ngeneral debate about the merits of soft-forks versus hard-forks (versus\nsemi-hard Kosher Free Range forks...).\n\nI've replied to several people privately off-list to not waste people's\ntime rehashing arguments that have been argued to death in the past.\n\nI do want to briefly address all of the concerns that stem from \"what if a\nsignificant fraction of hashpower (e.g. 25%) stick with the 1mb branch of\nthe chain.\"\n\nProof of work cannot be spoofed. If there is very little (a few percent) of\nhashpower mining a minority chain, confirmations on that chain take orders\nof magnitude longer.  I wrote about why the incentives are extremely strong\nfor only the stronger branch to survive here:\n http://gavinandresen.ninja/minority-branches\n\n... the debate about whether or not that is correct doesn't belong here in\nbitcoin-dev, in my humble opinion.\n\nAll of the security concerns I have seen flow from an assumption that\nsignificant hashpower continues on the weaker branch. The BIP that is under\ndiscussion assumes that analysis is correct. I have not seen any evidence\nthat it is not correct; all experience with previous forks (of both Bitcoin\nand altcoins) is that the stronger branch survives and the weaker branch\nvery quickly dies.\n\n\nAs for the argument that creating and testing a patch for Core would take\nlonger than 28 days:\n\nThe glib answer is \"people should just run Classic, then.\"\n\nA less glib answer is it would be trivial to create a patch for Core that\naccepted a more proof-of-work chain with larger blocks, but refused to mine\nlarger blocks.\n\nThat would be a trivial patch that would require very little testing\n(extensive testing of 8 and 20mb blocks has already been done), and perhaps\nwould be the best compromise until we can agree on a permanent solution\nthat eliminates the arbitrary, contentious limits.\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160207/8f19d8d9/attachment.html>"
            },
            {
                "author": "Btc Drak",
                "date": "2016-02-05T23:04:09",
                "message_text_only": "On Fri, Feb 5, 2016 at 8:51 PM, Gavin Andresen via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> This has been reviewed by merchants, miners and exchanges for a couple of\n> weeks, and has been implemented and tested as part of the Bitcoin Classic\n> and Bitcoin XT implementations.\n>\n> Constructive feedback welcome; argument about whether or not it is a good\n> idea to roll out a hard fork now will be unproductive, so I vote we don't\n> go there.\n>\n> Draft BIP:\n>   https://github.com/gavinandresen/bips/blob/bump2mb/bip-bump2mb.mediawiki\n>\n> Summary:\n>   Increase block size limit to 2,000,000 bytes.\n>   After 75% hashpower support then 28-day grace period.\n>   With accurate sigop counting, but existing sigop limit (20,000)\n>   And a new, high limit on signature hashing\n>\n> Blog post walking through the code:\n>   http://gavinandresen.ninja/a-guided-tour-of-the-2mb-fork\n>\n> Blog post on a couple of the constants chosen:\n>   http://gavinandresen.ninja/seventyfive-twentyeight\n>\n\nIt's great to finally see a BIP, although seems strange to ask for feedback\nafter releasing binaries.\n\nIn any case, the issue isn't about \"whether or not it is a good idea to\nroll out a hard fork\", the question has always been about how to do safe\nhard fork deployment and what the technological requirements are for doing\nso. Your BIP/blogs do not actually address any of this. 75% miner\nsignalling with a 28 day flag day thereafter gives virtually no time for\nthe entire ecosystem to migrate and is widely considered unsafe. It's\nplainly obvious that an entire ecosystem of 5000 full nodes cannot be\nprepared in a month.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160205/0c3d2ed8/attachment-0001.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-06T00:12:25",
                "message_text_only": "On Friday, February 05, 2016 8:51:08 PM Gavin Andresen via bitcoin-dev wrote:\n> Blog post on a couple of the constants chosen:\n>   http://gavinandresen.ninja/seventyfive-twentyeight\n\nCan you put this in the BIP's Rationale section (which appears to be mis-named \n\"Discussion\" in the current draft)?\n\n> Signature operations in un-executed branches of a Script are not counted\n> OP_CHECKMULTISIG evaluations are counted accurately; if the signature for a\n> 1-of-20 OP_CHECKMULTISIG is satisified by the public key nearest the top\n> of the execution stack, it is counted as one signature operation. If it is\n> satisfied by the public key nearest the bottom of the execution stack, it\n> is counted as twenty signature operations. Signature operations involving\n> invalidly encoded signatures or public keys are not counted towards the\n> limit\n\nThese seem like they will break static analysis entirely. That was a noted \nreason for creating BIP 16 to replace BIP 12. Is it no longer a concern? Would \nit make sense to require scripts to commit to the total accurate-sigop count \nto fix this?\n\n> The amount of data hashed to compute signature hashes is limited to\n> 1,300,000,000 bytes per block.\n\nThe rationale for this wasn't in your blog post. I assume it's based on the \ncurrent theoretical max at 1 MB blocks? Even a high-end PC would probably take \n40-80 seconds just for the hashing, however - maybe a lower limit would be \nbest?\n\n> Miners express their support for this BIP by ...\n\nBut miners don't get to decide hardforks. How does the economy express their \nsupport for it? What happens if miners trigger it without consent from the \neconomy?\n\nIf you are intent on using the version bits to trigger the hardfork, I suggest \nrephrasing this such that miners should only enable the bit when they have \nindependently confirmed economic support (this means implementations need a \nconfig option that defaults to off).\n\n> SPV (simple payment validation) wallets are compatible with this change.\n\nWould prefer if this is corrected to \"Light clients\" or something. Actual SPV \nwallets do not exist at this time, and would not be compatible with a \nhardfork.\n\n> In the short term, an increase is needed to continue the current economic\n> policies with regards to fees and block space, matching market expectations\n> and preventing market disruption.\n\nIMO this sentence is the most controversial part of your draft, and it \nwouldn't suffer a loss to remove it (or at least make it subjective).\n\nI would also prefer to see any hardfork:\n\n1. Address at least the simple tasks on the hardfork wishlist (eg, enable some\n   disabled opcodes; fix P2SH for N-of->15 multisig; etc).\n2. Be deployed as a soft-hardfork so as not to leave old nodes entirely\n   insecure.\n\nLuke"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2016-02-06T03:14:03",
                "message_text_only": "If it is to be uncontroversial and everybody will upgrade, there's no\nfear of a \"veto power\" and there's no good reason not to wait for 95%\nblock version signaling for deployment coordination, ideally using\nbip9.\nBut that's for chosing the exact block where to start. The grace\nperiod to give time to all users to upgrade should be before and not\nafter miner's final confirmation: that simplifies and accelerates\nthings. Assuming we chose a grace period that is really adequate,\nnearly 100% of miners will have likely upgraded long before everyone\n(since miners are a subset of \"everyone\"). If that is not the case and\nminers happen to be the latest to upgrade, using bip9 after the grace\nperiod (aka starting median-time/height) will make sure the hardfork\ndoesn't get activated without 95% of the miners having upgraded.\n\n28 days seems extremely short (specially if the grace period comes\nfirst), some people have suggested one year for simple hardforks like\nthis one.\n\nOn Sat, Feb 6, 2016 at 1:12 AM, Luke Dashjr via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> On Friday, February 05, 2016 8:51:08 PM Gavin Andresen via bitcoin-dev wrote:\n>> Blog post on a couple of the constants chosen:\n>>   http://gavinandresen.ninja/seventyfive-twentyeight\n>\n> Can you put this in the BIP's Rationale section (which appears to be mis-named\n> \"Discussion\" in the current draft)?\n>\n>> Signature operations in un-executed branches of a Script are not counted\n>> OP_CHECKMULTISIG evaluations are counted accurately; if the signature for a\n>> 1-of-20 OP_CHECKMULTISIG is satisified by the public key nearest the top\n>> of the execution stack, it is counted as one signature operation. If it is\n>> satisfied by the public key nearest the bottom of the execution stack, it\n>> is counted as twenty signature operations. Signature operations involving\n>> invalidly encoded signatures or public keys are not counted towards the\n>> limit\n>\n> These seem like they will break static analysis entirely. That was a noted\n> reason for creating BIP 16 to replace BIP 12. Is it no longer a concern? Would\n> it make sense to require scripts to commit to the total accurate-sigop count\n> to fix this?\n>\n>> The amount of data hashed to compute signature hashes is limited to\n>> 1,300,000,000 bytes per block.\n>\n> The rationale for this wasn't in your blog post. I assume it's based on the\n> current theoretical max at 1 MB blocks? Even a high-end PC would probably take\n> 40-80 seconds just for the hashing, however - maybe a lower limit would be\n> best?\n>\n>> Miners express their support for this BIP by ...\n>\n> But miners don't get to decide hardforks. How does the economy express their\n> support for it? What happens if miners trigger it without consent from the\n> economy?\n>\n> If you are intent on using the version bits to trigger the hardfork, I suggest\n> rephrasing this such that miners should only enable the bit when they have\n> independently confirmed economic support (this means implementations need a\n> config option that defaults to off).\n>\n>> SPV (simple payment validation) wallets are compatible with this change.\n>\n> Would prefer if this is corrected to \"Light clients\" or something. Actual SPV\n> wallets do not exist at this time, and would not be compatible with a\n> hardfork.\n>\n>> In the short term, an increase is needed to continue the current economic\n>> policies with regards to fees and block space, matching market expectations\n>> and preventing market disruption.\n>\n> IMO this sentence is the most controversial part of your draft, and it\n> wouldn't suffer a loss to remove it (or at least make it subjective).\n>\n> I would also prefer to see any hardfork:\n>\n> 1. Address at least the simple tasks on the hardfork wishlist (eg, enable some\n>    disabled opcodes; fix P2SH for N-of->15 multisig; etc).\n> 2. Be deployed as a soft-hardfork so as not to leave old nodes entirely\n>    insecure.\n>\n> Luke\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-02-06T15:37:30",
                "message_text_only": "Responding to \"28 days is not long enough\" :\n\nI keep seeing this claim made with no evidence to back it up.  As I said, I\nsurveyed several of the biggest infrastructure providers and the btcd lead\ndeveloper and they all agree \"28 days is plenty of time.\"\n\nFor individuals... why would it take somebody longer than 28 days to either\ndownload and restart their bitcoind, or to patch and then re-run (the patch\ncan be a one-line change MAX_BLOCK_SIZE from 1000000 to 2000000)?\n\nFor the Bitcoin Core project:  I'm well aware of how long it takes to roll\nout new binaries, and 28 days is plenty of time.\n\nI suspect there ARE a significant percentage of un-maintained full nodes--\nprobably 30 to 40%. Losing those nodes will not be a problem, for three\nreasons:\n1) The network could shrink by 60% and it would still have plenty of open\nconnection slots\n2) People are committing to spinning up thousands of supports-2mb-nodes\nduring the grace period.\n3) We could wait a year and pick up maybe 10 or 20% more.\n\nI strongly disagree with the statement that there is no cost to a longer\ngrace period. There is broad agreement that a capacity increase is needed\nNOW.\n\nTo bring it back to bitcoin-dev territory:  are there any TECHNICAL\narguments why an upgrade would take a business or individual longer than 28\ndays?\n\n\nResponding to Luke's message:\n\nOn Sat, Feb 6, 2016 at 1:12 AM, Luke Dashjr via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > On Friday, February 05, 2016 8:51:08 PM Gavin Andresen via bitcoin-dev\n> wrote:\n> >> Blog post on a couple of the constants chosen:\n> >>   http://gavinandresen.ninja/seventyfive-twentyeight\n> >\n> > Can you put this in the BIP's Rationale section (which appears to be\n> mis-named\n> > \"Discussion\" in the current draft)?\n>\n\nI'll rename the section and expand it a little. I think standards documents\nlike BIPs should be concise, though (written for implementors), so I'm not\ngoing to recreate the entire blog post there.\n\n\n> >\n> >> Signature operations in un-executed branches of a Script are not counted\n> >> OP_CHECKMULTISIG evaluations are counted accurately; if the signature\n> for a\n> >> 1-of-20 OP_CHECKMULTISIG is satisified by the public key nearest the top\n> >> of the execution stack, it is counted as one signature operation. If it\n> is\n> >> satisfied by the public key nearest the bottom of the execution stack,\n> it\n> >> is counted as twenty signature operations. Signature operations\n> involving\n> >> invalidly encoded signatures or public keys are not counted towards the\n> >> limit\n> >\n> > These seem like they will break static analysis entirely. That was a\n> noted\n> > reason for creating BIP 16 to replace BIP 12. Is it no longer a concern?\n> Would\n> > it make sense to require scripts to commit to the total accurate-sigop\n> count\n> > to fix this?\n>\n\nAfter implementing static counting and accurate counting... I was wrong.\nAccurate/dynamic counting/limiting is quick and simple and can be\ncompletely safe (the counting code can be told the limit and can\n\"early-out\" validation).\n\nI think making scripts commit to a total accurate sigop count is a bad\nidea-- it would make multisignature signing more complicated for zero\nbenefit.  E.g. if you're circulating a partially signed transaction to that\nmust be signed by 2 of 5 people, you can end up with a transaction that\nrequires 2, 3, 4, or 5 signature operations to validate (depending on which\npublic keys are used to do the signing).  The first signer might have no\nidea who else would sign and wouldn't know the accurate sigop count.\n\n\n> >\n> >> The amount of data hashed to compute signature hashes is limited to\n> >> 1,300,000,000 bytes per block.\n> >\n> > The rationale for this wasn't in your blog post. I assume it's based on\n> the\n> > current theoretical max at 1 MB blocks? Even a high-end PC would\n> probably take\n> > 40-80 seconds just for the hashing, however - maybe a lower limit would\n> be\n> > best?\n>\n\nIt is slightly more hashing than was required to validate block number\n364,422.\n\nThere are a couple of advantages to a very high limit:\n\n1) When the fork is over, special-case code for dealing with old blocks can\nbe eliminated, because all old blocks satisfy the new limit.\n\n2) More importantly, if the limit is small enough it might get hit by\nstandard transactions, then block creation code (CreateNewBlock() /\ngetblocktemplate / or some external transaction-assembling software) will\nhave to solve an even more complicated bin-packing problem to optimize for\nfees paid.\n\nIn practice, the 20,000 sigop limit will always be reached before\nMAX_BLOCK_SIGHASH.\n\n\n\n> >\n> >> Miners express their support for this BIP by ...\n> >\n> > But miners don't get to decide hardforks. How does the economy express\n> their\n> > support for it? What happens if miners trigger it without consent from\n> the\n> > economy?\n>\n\n\"The economy\" does support this.\n\n\n\n> >\n> > If you are intent on using the version bits to trigger the hardfork, I\n> suggest\n> > rephrasing this such that miners should only enable the bit when they\n> have\n> > independently confirmed economic support (this means implementations\n> need a\n> > config option that defaults to off).\n>\n\nHappy to add words about economic majority.\n\nClassic will not implement a command-line option (the act of running\nClassic is \"I opt in\"), but happy to add one for a pull request to Core,\nassuming Core would not see such a pull request as having any hostile\nintent.\n\n\n>\n> >> SPV (simple payment validation) wallets are compatible with this change.\n> >\n> > Would prefer if this is corrected to \"Light clients\" or something.\n> Actual SPV\n> > wallets do not exist at this time, and would not be compatible with a\n> > hardfork.\n>\n\nIs there an explanation of SPV versus \"Light Client\" written somewhere more\npermanent than a reddit comment or forum post that I can point to?\n\n\n> >\n> >> In the short term, an increase is needed to continue the current\n> economic\n> >> policies with regards to fees and block space, matching market\n> expectations\n> >> and preventing market disruption.\n> >\n> > IMO this sentence is the most controversial part of your draft, and it\n> > wouldn't suffer a loss to remove it (or at least make it subjective).\n>\n\nHappy to remove.\n\n\n> > I would also prefer to see any hardfork:\n> >\n> > 1. Address at least the simple tasks on the hardfork wishlist (eg,\n> enable some\n> >    disabled opcodes; fix P2SH for N-of->15 multisig; etc).\n>\n\nThose would be separate BIPs. (according to BIP 1, smaller is better)\n\nAfter this 2MB bump, I agree we need to agree on a process for the next\nhard fork to avoid all of the unnecessary drama.\n\n> 2. Be deployed as a soft-hardfork so as not to leave old nodes entirely\n> >    insecure.\n>\n\nI haven't been paying attention to all of the\n\"soft-hardfork/hard-softfork/etc\" terminology so have no idea what you\nmean. Is THAT written up somewhere?\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160206/7c874b34/attachment.html>"
            },
            {
                "author": "Adam Back",
                "date": "2016-02-06T17:01:49",
                "message_text_only": "Hi Gavin\n\nIt would probably be a good idea to have a security considerations\nsection, also, is there a list of which exchange, library, wallet,\npool, stats server, hardware etc you have tested this change against?\n\nDo you have a rollback plan in the event the hard-fork triggers via\nfalse voting as seemed to be prevalent during XT?  (Or rollback just\nas contingency if something unforseen goes wrong).\n\nHow do you plan to monitor and manage security through the hard-fork?\n\nAdam\n\nOn 6 February 2016 at 16:37, Gavin Andresen via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Responding to \"28 days is not long enough\" :\n>\n> I keep seeing this claim made with no evidence to back it up.  As I said, I\n> surveyed several of the biggest infrastructure providers and the btcd lead\n> developer and they all agree \"28 days is plenty of time.\"\n>\n> For individuals... why would it take somebody longer than 28 days to either\n> download and restart their bitcoind, or to patch and then re-run (the patch\n> can be a one-line change MAX_BLOCK_SIZE from 1000000 to 2000000)?\n>\n> For the Bitcoin Core project:  I'm well aware of how long it takes to roll\n> out new binaries, and 28 days is plenty of time.\n>\n> I suspect there ARE a significant percentage of un-maintained full nodes--\n> probably 30 to 40%. Losing those nodes will not be a problem, for three\n> reasons:\n> 1) The network could shrink by 60% and it would still have plenty of open\n> connection slots\n> 2) People are committing to spinning up thousands of supports-2mb-nodes\n> during the grace period.\n> 3) We could wait a year and pick up maybe 10 or 20% more.\n>\n> I strongly disagree with the statement that there is no cost to a longer\n> grace period. There is broad agreement that a capacity increase is needed\n> NOW.\n>\n> To bring it back to bitcoin-dev territory:  are there any TECHNICAL\n> arguments why an upgrade would take a business or individual longer than 28\n> days?\n>\n>\n> Responding to Luke's message:\n>\n>> On Sat, Feb 6, 2016 at 1:12 AM, Luke Dashjr via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> > On Friday, February 05, 2016 8:51:08 PM Gavin Andresen via bitcoin-dev\n>> > wrote:\n>> >> Blog post on a couple of the constants chosen:\n>> >>   http://gavinandresen.ninja/seventyfive-twentyeight\n>> >\n>> > Can you put this in the BIP's Rationale section (which appears to be\n>> > mis-named\n>> > \"Discussion\" in the current draft)?\n>\n>\n> I'll rename the section and expand it a little. I think standards documents\n> like BIPs should be concise, though (written for implementors), so I'm not\n> going to recreate the entire blog post there.\n>\n>>\n>> >\n>> >> Signature operations in un-executed branches of a Script are not\n>> >> counted\n>> >> OP_CHECKMULTISIG evaluations are counted accurately; if the signature\n>> >> for a\n>> >> 1-of-20 OP_CHECKMULTISIG is satisified by the public key nearest the\n>> >> top\n>> >> of the execution stack, it is counted as one signature operation. If it\n>> >> is\n>> >> satisfied by the public key nearest the bottom of the execution stack,\n>> >> it\n>> >> is counted as twenty signature operations. Signature operations\n>> >> involving\n>> >> invalidly encoded signatures or public keys are not counted towards the\n>> >> limit\n>> >\n>> > These seem like they will break static analysis entirely. That was a\n>> > noted\n>> > reason for creating BIP 16 to replace BIP 12. Is it no longer a concern?\n>> > Would\n>> > it make sense to require scripts to commit to the total accurate-sigop\n>> > count\n>> > to fix this?\n>\n>\n> After implementing static counting and accurate counting... I was wrong.\n> Accurate/dynamic counting/limiting is quick and simple and can be completely\n> safe (the counting code can be told the limit and can \"early-out\"\n> validation).\n>\n> I think making scripts commit to a total accurate sigop count is a bad\n> idea-- it would make multisignature signing more complicated for zero\n> benefit.  E.g. if you're circulating a partially signed transaction to that\n> must be signed by 2 of 5 people, you can end up with a transaction that\n> requires 2, 3, 4, or 5 signature operations to validate (depending on which\n> public keys are used to do the signing).  The first signer might have no\n> idea who else would sign and wouldn't know the accurate sigop count.\n>\n>>\n>> >\n>> >> The amount of data hashed to compute signature hashes is limited to\n>> >> 1,300,000,000 bytes per block.\n>> >\n>> > The rationale for this wasn't in your blog post. I assume it's based on\n>> > the\n>> > current theoretical max at 1 MB blocks? Even a high-end PC would\n>> > probably take\n>> > 40-80 seconds just for the hashing, however - maybe a lower limit would\n>> > be\n>> > best?\n>\n>\n> It is slightly more hashing than was required to validate block number\n> 364,422.\n>\n> There are a couple of advantages to a very high limit:\n>\n> 1) When the fork is over, special-case code for dealing with old blocks can\n> be eliminated, because all old blocks satisfy the new limit.\n>\n> 2) More importantly, if the limit is small enough it might get hit by\n> standard transactions, then block creation code (CreateNewBlock() /\n> getblocktemplate / or some external transaction-assembling software) will\n> have to solve an even more complicated bin-packing problem to optimize for\n> fees paid.\n>\n> In practice, the 20,000 sigop limit will always be reached before\n> MAX_BLOCK_SIGHASH.\n>\n>\n>>\n>> >\n>> >> Miners express their support for this BIP by ...\n>> >\n>> > But miners don't get to decide hardforks. How does the economy express\n>> > their\n>> > support for it? What happens if miners trigger it without consent from\n>> > the\n>> > economy?\n>\n>\n> \"The economy\" does support this.\n>\n>\n>>\n>> >\n>> > If you are intent on using the version bits to trigger the hardfork, I\n>> > suggest\n>> > rephrasing this such that miners should only enable the bit when they\n>> > have\n>> > independently confirmed economic support (this means implementations\n>> > need a\n>> > config option that defaults to off).\n>\n>\n> Happy to add words about economic majority.\n>\n> Classic will not implement a command-line option (the act of running Classic\n> is \"I opt in\"), but happy to add one for a pull request to Core, assuming\n> Core would not see such a pull request as having any hostile intent.\n>\n>\n>> >\n>> >> SPV (simple payment validation) wallets are compatible with this\n>> >> change.\n>> >\n>> > Would prefer if this is corrected to \"Light clients\" or something.\n>> > Actual SPV\n>> > wallets do not exist at this time, and would not be compatible with a\n>> > hardfork.\n>\n>\n> Is there an explanation of SPV versus \"Light Client\" written somewhere more\n> permanent than a reddit comment or forum post that I can point to?\n>\n>>\n>> >\n>> >> In the short term, an increase is needed to continue the current\n>> >> economic\n>> >> policies with regards to fees and block space, matching market\n>> >> expectations\n>> >> and preventing market disruption.\n>> >\n>> > IMO this sentence is the most controversial part of your draft, and it\n>> > wouldn't suffer a loss to remove it (or at least make it subjective).\n>\n>\n> Happy to remove.\n>\n>>\n>> > I would also prefer to see any hardfork:\n>> >\n>> > 1. Address at least the simple tasks on the hardfork wishlist (eg,\n>> > enable some\n>> >    disabled opcodes; fix P2SH for N-of->15 multisig; etc).\n>\n>\n> Those would be separate BIPs. (according to BIP 1, smaller is better)\n>\n> After this 2MB bump, I agree we need to agree on a process for the next hard\n> fork to avoid all of the unnecessary drama.\n>\n>> > 2. Be deployed as a soft-hardfork so as not to leave old nodes entirely\n>> >    insecure.\n>\n>\n> I haven't been paying attention to all of the\n> \"soft-hardfork/hard-softfork/etc\" terminology so have no idea what you mean.\n> Is THAT written up somewhere?\n>\n> --\n> --\n> Gavin Andresen\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-02-06T17:45:14",
                "message_text_only": "On Sat, Feb 6, 2016 at 12:01 PM, Adam Back <adam at cypherspace.org> wrote:\n\n>\n> It would probably be a good idea to have a security considerations\n> section\n\n\nContaining what?  I'm not aware of any security considerations that are any\ndifferent from any other consensus rules change.\n\n(I can write a blog post summarizing our slack discussion of SPV security\nimmediately after the first greater-than-1mb-block if you like).\n\n\n\n> , also, is there a list of which exchange, library, wallet,\n> pool, stats server, hardware etc you have tested this change against?\n>\n\nThat testing is happening by the exchange, library, wallet, etc providers\nthemselves. There is a list on the Classic home page:\n\nhttps://bitcoinclassic.com/\n\n\n>\n> Do you have a rollback plan in the event the hard-fork triggers via\n> false voting as seemed to be prevalent during XT?  (Or rollback just\n> as contingency if something unforseen goes wrong).\n>\n\nThe only voting in this BIP is done by the miners, and that cannot be faked.\n\nAre you talking about people spinning up pseudo-full-nodes that fake the\nuser-agent?\n\nAs I said, there are people who have said they will spin up thousands of\nfull nodes to help prevent possible Sybil attacks which would become\nmarginally easier to accomplish immediately after the first >1mb block was\nproduced and full nodes that hadn't upgraded were left behind.\n\nWould Blockstream be willing to help out by running a dozen or two extra\nfull nodes?\n\nI can't imagine any even-remotely-likely sequence of events that would\nrequire a rollback, can you be more specific about what you are imagining?\nMiners suddenly getting cold feet?\n\n\n> How do you plan to monitor and manage security through the hard-fork?\n>\n\nI don't plan to monitor or manage anything; the Bitcoin network is\nself-monitoring and self-managing. Services like statoshi.info will do the\nmonitoring, and miners and people and businesses will manage the network,\nas they do every day.\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160206/e60b5b0c/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-02-06T21:11:58",
                "message_text_only": "On Sat, Feb 06, 2016 at 12:45:14PM -0500, Gavin Andresen via bitcoin-dev wrote:\n> On Sat, Feb 6, 2016 at 12:01 PM, Adam Back <adam at cypherspace.org> wrote:\n> \n> >\n> > It would probably be a good idea to have a security considerations\n> > section\n> \n> \n> Containing what?  I'm not aware of any security considerations that are any\n> different from any other consensus rules change.\n\nI covered the security considerations unique to hard-forks on my blog:\n\nhttps://petertodd.org/2016/soft-forks-are-safer-than-hard-forks\n\n> > , also, is there a list of which exchange, library, wallet,\n> > pool, stats server, hardware etc you have tested this change against?\n> >\n> \n> That testing is happening by the exchange, library, wallet, etc providers\n> themselves. There is a list on the Classic home page:\n> \n> https://bitcoinclassic.com/\n\nHow do we know any of this testing is actually being performed? I don't\ncurrently know of any concrete testing actually done.\n\n> > Do you have a rollback plan in the event the hard-fork triggers via\n> > false voting as seemed to be prevalent during XT?  (Or rollback just\n> > as contingency if something unforseen goes wrong).\n> >\n> \n> The only voting in this BIP is done by the miners, and that cannot be faked.\n\nAre you unaware of Not Bitcoin XT?\n\nhttps://bitcointalk.org/index.php?topic=1154520.0\n\n> I can't imagine any even-remotely-likely sequence of events that would\n> require a rollback, can you be more specific about what you are imagining?\n> Miners suddenly getting cold feet?\n\nSee above.\n\nAlso, as the two coins are separate currencies and can easily trade\nagainst each other in a 75%/25% split, it would be easy for the price to\ndiverge and hashing power to move.\n\nIn fact, I've been asked multiple times now by exchanges and other\nplayers in this ecosystem for technical advice on how to split coins\nacross the chains effectively (easily done with nLockTime). Notably, the\nexchanges who have asked me this - who hold customer funds on their\nbehalf - have informed me that their legal advice was that the\npost-hard-fork coins are legally speaking separate currencies, and\ncustomers must be given the opportunity to transact in them separately\nif they choose too.  Obviously, with a 75%/25% split, while block times\non the other chain will be slower, the chain is still quite useful and\nnearly as secure as the main chain against 51% attack; why I personally\nhave suggested a 99% threshold:\n\nhttp://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-January/012309.html\n\n(remember that the threshold can always be soft-forked down)\n\nIt's also notable that millions of dollars of Bitcoin are voting agsast\nthe fork on the proof-of-stake voting site Bitcoinocracy.com While\nobviously not comprehensive, the fact that a relatively obscure site\nlike it can achieve participation like that, even without an easy to use\nuser friendly interface.\n\n> > How do you plan to monitor and manage security through the hard-fork?\n> >\n> \n> I don't plan to monitor or manage anything; the Bitcoin network is\n> self-monitoring and self-managing. Services like statoshi.info will do the\n> monitoring, and miners and people and businesses will manage the network,\n> as they do every day.\n\nPlease provide details on exactly how that's going to happen.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n000000000000000008320874843f282f554aa2436290642fcfa81e5a01d78698\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160206/53df43e4/attachment.sig>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-02-06T21:24:19",
                "message_text_only": "On Sat, Feb 06, 2016 at 04:11:58PM -0500, Peter Todd via bitcoin-dev wrote:\n> On Sat, Feb 06, 2016 at 12:45:14PM -0500, Gavin Andresen via bitcoin-dev wrote:\n> > On Sat, Feb 6, 2016 at 12:01 PM, Adam Back <adam at cypherspace.org> wrote:\n> > \n> > >\n> > > It would probably be a good idea to have a security considerations\n> > > section\n> > \n> > \n> > Containing what?  I'm not aware of any security considerations that are any\n> > different from any other consensus rules change.\n> \n> I covered the security considerations unique to hard-forks on my blog:\n> \n> https://petertodd.org/2016/soft-forks-are-safer-than-hard-forks\n\nOh, and to be 100% clear, I should say those are only *some of* the\nunique security considerations - for starters the article is mainly\ntalking about uncontroversial hard-forks, and doesn't even delve into\neconomic attacks among other omissions. It's just an introductory\narticle.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n000000000000000008320874843f282f554aa2436290642fcfa81e5a01d78698\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160206/848a2fc9/attachment.sig>"
            },
            {
                "author": "Samson Mow",
                "date": "2016-02-09T05:11:56",
                "message_text_only": "Gavin, please don't quote that list on the Classic website. It's horribly\ninaccurate and misleading to the general public.\n\n> That testing is happening by the exchange, library, wallet, etc providers\n> themselves. There is a list on the Classic home page:\n>\n> https://bitcoinclassic.com/\n\nI know for a fact that most companies you list there have no intention to\nrun Classic, much less test it. You should not mix support for 2MB with\nsupport for Classic, or if people say they welcome a fork, to mean they\nsupport Classic.\n\nOn Sun, Feb 7, 2016 at 5:11 AM, Peter Todd via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Sat, Feb 06, 2016 at 12:45:14PM -0500, Gavin Andresen via bitcoin-dev\n> wrote:\n> > On Sat, Feb 6, 2016 at 12:01 PM, Adam Back <adam at cypherspace.org> wrote:\n> >\n> > >\n> > > It would probably be a good idea to have a security considerations\n> > > section\n> >\n> >\n> > Containing what?  I'm not aware of any security considerations that are\n> any\n> > different from any other consensus rules change.\n>\n> I covered the security considerations unique to hard-forks on my blog:\n>\n> https://petertodd.org/2016/soft-forks-are-safer-than-hard-forks\n>\n> > > , also, is there a list of which exchange, library, wallet,\n> > > pool, stats server, hardware etc you have tested this change against?\n> > >\n> >\n> > That testing is happening by the exchange, library, wallet, etc providers\n> > themselves. There is a list on the Classic home page:\n> >\n> > https://bitcoinclassic.com/\n>\n> How do we know any of this testing is actually being performed? I don't\n> currently know of any concrete testing actually done.\n>\n> > > Do you have a rollback plan in the event the hard-fork triggers via\n> > > false voting as seemed to be prevalent during XT?  (Or rollback just\n> > > as contingency if something unforseen goes wrong).\n> > >\n> >\n> > The only voting in this BIP is done by the miners, and that cannot be\n> faked.\n>\n> Are you unaware of Not Bitcoin XT?\n>\n> https://bitcointalk.org/index.php?topic=1154520.0\n>\n> > I can't imagine any even-remotely-likely sequence of events that would\n> > require a rollback, can you be more specific about what you are\n> imagining?\n> > Miners suddenly getting cold feet?\n>\n> See above.\n>\n> Also, as the two coins are separate currencies and can easily trade\n> against each other in a 75%/25% split, it would be easy for the price to\n> diverge and hashing power to move.\n>\n> In fact, I've been asked multiple times now by exchanges and other\n> players in this ecosystem for technical advice on how to split coins\n> across the chains effectively (easily done with nLockTime). Notably, the\n> exchanges who have asked me this - who hold customer funds on their\n> behalf - have informed me that their legal advice was that the\n> post-hard-fork coins are legally speaking separate currencies, and\n> customers must be given the opportunity to transact in them separately\n> if they choose too.  Obviously, with a 75%/25% split, while block times\n> on the other chain will be slower, the chain is still quite useful and\n> nearly as secure as the main chain against 51% attack; why I personally\n> have suggested a 99% threshold:\n>\n>\n> http://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-January/012309.html\n>\n> (remember that the threshold can always be soft-forked down)\n>\n> It's also notable that millions of dollars of Bitcoin are voting agsast\n> the fork on the proof-of-stake voting site Bitcoinocracy.com While\n> obviously not comprehensive, the fact that a relatively obscure site\n> like it can achieve participation like that, even without an easy to use\n> user friendly interface.\n>\n> > > How do you plan to monitor and manage security through the hard-fork?\n> > >\n> >\n> > I don't plan to monitor or manage anything; the Bitcoin network is\n> > self-monitoring and self-managing. Services like statoshi.info will do\n> the\n> > monitoring, and miners and people and businesses will manage the network,\n> > as they do every day.\n>\n> Please provide details on exactly how that's going to happen.\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n> 000000000000000008320874843f282f554aa2436290642fcfa81e5a01d78698\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160209/021a7b73/attachment.html>"
            },
            {
                "author": "David Thomson",
                "date": "2016-02-06T21:28:22",
                "message_text_only": "Gavin,\n\nI saw this in your blog post:\n\n\"Miners producing up-version blocks is a coordination mechanism. Other coordination mechanisms are possible\u2013 there could be a centrally determined \u201cflag day\u201d or \u201cflag block\u201d when everybody (or almost everybody) agrees that a change will happen.\"\n\nCan you describe this a bit more? How would either a \"flag day\" or \"flag block\" work as an alternative and why did you decide against them?\n\nMore thoughts and questions inline, thanks!\n\nOn Feb 6, 2016, at 12:45 PM, Gavin Andresen via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>> On Sat, Feb 6, 2016 at 12:01 PM, Adam Back <adam at cypherspace.org> wrote:\n>> \n>> It would probably be a good idea to have a security considerations\n>> section\n> \n> Containing what?  I'm not aware of any security considerations that are any different from any other consensus rules change.\n\nCan you explain and justify why that is the case? It would be nice to see that rationale laid out more fully as to why it's no different.\n\n> \n> (I can write a blog post summarizing our slack discussion of SPV security immediately after the first greater-than-1mb-block if you like).\n\nI'm not familiar with the context of your slack discussion, but why would you wait to summarize that only after the first-greater-than-1mb-block?\n\n> \n>  \n>> , also, is there a list of which exchange, library, wallet,\n>> pool, stats server, hardware etc you have tested this change against?\n> \n> That testing is happening by the exchange, library, wallet, etc providers themselves. There is a list on the Classic home page:\n> \n> https://bitcoinclassic.com/\n\nIs there a way to provide more transparency and visibility into that process and level of readiness? Is there an expectation of certain levels of readiness here before certain other things happen? I was thinking it would be really useful to have a visual timeline of events associated with all of this. Maybe you could add that to one of your web pages?\n\n>  \n>> \n>> Do you have a rollback plan in the event the hard-fork triggers via\n>> false voting as seemed to be prevalent during XT?  (Or rollback just\n>> as contingency if something unforseen goes wrong).\n> \n> The only voting in this BIP is done by the miners, and that cannot be faked.\n> \n> Are you talking about people spinning up pseudo-full-nodes that fake the user-agent?\n> \n> As I said, there are people who have said they will spin up thousands of full nodes to help prevent possible Sybil attacks which would become marginally easier to accomplish immediately after the first >1mb block was produced and full nodes that hadn't upgraded were left behind.\n> \n> Would Blockstream be willing to help out by running a dozen or two extra full nodes?\n> \n> I can't imagine any even-remotely-likely sequence of events that would require a rollback, can you be more specific about what you are imagining?  Miners suddenly getting cold feet?\n\nWell that, but also past performance isn't an indication of future performance, necessarily. They might have gone out of business, to give one example. There is surely assumed self-interest, but I have also seen rumors floating around of this being used as an arbitrage opportunity. Would suck to imagine that ever happening, but since this seems like it's being managed on more handshake type of deals (or conversations), are there any legal documents backing those commitments up? Or is that definitely overkill?\n\nMaybe it's worth documenting the full range of possible series of events and then their presumed level of unlikelihood? \"What can go wrong will go wrong\", \"Black Swan\" events, type of considerations. :) Often when people discuss unlikely things like crypto being broken, it's like, \"Assuming processing power of x, increasing at a rate of x, and a known age of the universe of x, it would take a billion times the known length of the universe for that to happen\".\n\nCertainly not everything fits so easily into that framing, but it would be really helpful to see the \"what could possibly go wrong\" things fully enumerated.\n\nThanks!!\n\nDave\n\n>  \n>> How do you plan to monitor and manage security through the hard-fork?\n> \n> I don't plan to monitor or manage anything; the Bitcoin network is self-monitoring and self-managing. Services like statoshi.infowill do the monitoring, and miners and people and businesses will manage the network, as they do every day.\n> \n> -- \n> --\n> Gavin Andresen\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160206/2046ce79/attachment-0001.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-02-06T22:22:21",
                "message_text_only": "On Sat, Feb 06, 2016 at 10:37:30AM -0500, Gavin Andresen via bitcoin-dev wrote:\n> 2) People are committing to spinning up thousands of supports-2mb-nodes\n> during the grace period.\n\nWhy wouldn't an attacker be able to counter-sybil-attack that effort?\n\nWho are these people?\n\n\nOn Sat, Feb 06, 2016 at 12:45:14PM -0500, Gavin Andresen via bitcoin-dev wrote:\n> Would Blockstream be willing to help out by running a dozen or two extra\n> full nodes?\n\nI'll remind everyone that Bitcoin Core does not condone participation in\nnetwork attacks to push controversial protcol changes through. I also\nchecked with Adam Back, who confirmed Blockstream as a company shares\nthose views.\n\n\nFor those readers unfamiliar with Sybil attacks, basically what the\nabove does is prevents nodes from being able to finding peers with\naccurate information about what blockchains exist - the above can be\nused to prevent nodes from learning about the longest chain for\ninstance, or the existance of substantial support for a minority chain.\nThis is why we've advocated giving users sufficient time to actively\nopt-in to protocol changes.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n000000000000000008320874843f282f554aa2436290642fcfa81e5a01d78698\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160206/7a096cda/attachment.sig>"
            },
            {
                "author": "Chris Priest",
                "date": "2016-02-07T18:49:39",
                "message_text_only": "Segwit requires work from exchanges, wallets and services in order for\nadoption to happen. This is because segwit changes the rules regarding\nthe Transaction data structure. A blocksize increase does not change\nthe Transaction rules at all. The blocksize increase is a change to\nthe Block structure. Most wallets these days are Block agnostic.\n\nEssentially, if a client has been built using a library that abstracts\naway the block, then that client's *code* does not need to be updated\nto handle this blocksize limit change. An example is any service using\nthe Bitcore javascript library. Any wallet built using Bitcore does\nnot need any changes to handle a blocksize upgrade. I have one project\nthat is live that was built using Bitcore. Before, during, and after\nthe fork, I do not need to lift a finger *codewise* to keep my project\nstill working. Same goes for projects that are built using\npybitcointools, as well as probably a few other libraries.\n\nA wallet using Bitcore also has to work in tandem with a blockchan\napi. Bitcore itself does not provide any blockchain data, you have to\nget that somewhere else, such as a Node API. That API has to be based\non a Node that is following the upgraded chain. My wallet for instance\nis built on top of Bitpay Insight. If bitpay doesn't upgrade their\nNode to follow the 2MB chain, then I must either...\n\n1) Change my wallet to use my own Bitpay Insight. (Insight is open\nsource, so you can host you own using any Node client you want)\n2) Switch to another API, such as Toshi or Bockr.io, or\nBlokchain.Info, or ... (there are dozens to choose from)\n\nA blockchain service such as a blockexplorer does need to be upgraded\nto handle a blocksize hardfork. The only work required is updating\ntheir node software so that the MAX_BLOCKSIZE parameter is set to 2MB.\nThis can be done by either changing the source code themselves, or by\ninstalling an alternate client such as XT, Classic, or Unlimited.\n\nOn 2/6/16, Adam Back via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Hi Gavin\n>\n> It would probably be a good idea to have a security considerations\n> section, also, is there a list of which exchange, library, wallet,\n> pool, stats server, hardware etc you have tested this change against?\n>\n> Do you have a rollback plan in the event the hard-fork triggers via\n> false voting as seemed to be prevalent during XT?  (Or rollback just\n> as contingency if something unforseen goes wrong).\n>\n> How do you plan to monitor and manage security through the hard-fork?\n>\n> Adam\n>\n> On 6 February 2016 at 16:37, Gavin Andresen via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> Responding to \"28 days is not long enough\" :\n>>\n>> I keep seeing this claim made with no evidence to back it up.  As I said,\n>> I\n>> surveyed several of the biggest infrastructure providers and the btcd\n>> lead\n>> developer and they all agree \"28 days is plenty of time.\"\n>>\n>> For individuals... why would it take somebody longer than 28 days to\n>> either\n>> download and restart their bitcoind, or to patch and then re-run (the\n>> patch\n>> can be a one-line change MAX_BLOCK_SIZE from 1000000 to 2000000)?\n>>\n>> For the Bitcoin Core project:  I'm well aware of how long it takes to\n>> roll\n>> out new binaries, and 28 days is plenty of time.\n>>\n>> I suspect there ARE a significant percentage of un-maintained full\n>> nodes--\n>> probably 30 to 40%. Losing those nodes will not be a problem, for three\n>> reasons:\n>> 1) The network could shrink by 60% and it would still have plenty of open\n>> connection slots\n>> 2) People are committing to spinning up thousands of supports-2mb-nodes\n>> during the grace period.\n>> 3) We could wait a year and pick up maybe 10 or 20% more.\n>>\n>> I strongly disagree with the statement that there is no cost to a longer\n>> grace period. There is broad agreement that a capacity increase is needed\n>> NOW.\n>>\n>> To bring it back to bitcoin-dev territory:  are there any TECHNICAL\n>> arguments why an upgrade would take a business or individual longer than\n>> 28\n>> days?\n>>\n>>\n>> Responding to Luke's message:\n>>\n>>> On Sat, Feb 6, 2016 at 1:12 AM, Luke Dashjr via bitcoin-dev\n>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> > On Friday, February 05, 2016 8:51:08 PM Gavin Andresen via bitcoin-dev\n>>> > wrote:\n>>> >> Blog post on a couple of the constants chosen:\n>>> >>   http://gavinandresen.ninja/seventyfive-twentyeight\n>>> >\n>>> > Can you put this in the BIP's Rationale section (which appears to be\n>>> > mis-named\n>>> > \"Discussion\" in the current draft)?\n>>\n>>\n>> I'll rename the section and expand it a little. I think standards\n>> documents\n>> like BIPs should be concise, though (written for implementors), so I'm\n>> not\n>> going to recreate the entire blog post there.\n>>\n>>>\n>>> >\n>>> >> Signature operations in un-executed branches of a Script are not\n>>> >> counted\n>>> >> OP_CHECKMULTISIG evaluations are counted accurately; if the signature\n>>> >> for a\n>>> >> 1-of-20 OP_CHECKMULTISIG is satisified by the public key nearest the\n>>> >> top\n>>> >> of the execution stack, it is counted as one signature operation. If\n>>> >> it\n>>> >> is\n>>> >> satisfied by the public key nearest the bottom of the execution\n>>> >> stack,\n>>> >> it\n>>> >> is counted as twenty signature operations. Signature operations\n>>> >> involving\n>>> >> invalidly encoded signatures or public keys are not counted towards\n>>> >> the\n>>> >> limit\n>>> >\n>>> > These seem like they will break static analysis entirely. That was a\n>>> > noted\n>>> > reason for creating BIP 16 to replace BIP 12. Is it no longer a\n>>> > concern?\n>>> > Would\n>>> > it make sense to require scripts to commit to the total accurate-sigop\n>>> > count\n>>> > to fix this?\n>>\n>>\n>> After implementing static counting and accurate counting... I was wrong.\n>> Accurate/dynamic counting/limiting is quick and simple and can be\n>> completely\n>> safe (the counting code can be told the limit and can \"early-out\"\n>> validation).\n>>\n>> I think making scripts commit to a total accurate sigop count is a bad\n>> idea-- it would make multisignature signing more complicated for zero\n>> benefit.  E.g. if you're circulating a partially signed transaction to\n>> that\n>> must be signed by 2 of 5 people, you can end up with a transaction that\n>> requires 2, 3, 4, or 5 signature operations to validate (depending on\n>> which\n>> public keys are used to do the signing).  The first signer might have no\n>> idea who else would sign and wouldn't know the accurate sigop count.\n>>\n>>>\n>>> >\n>>> >> The amount of data hashed to compute signature hashes is limited to\n>>> >> 1,300,000,000 bytes per block.\n>>> >\n>>> > The rationale for this wasn't in your blog post. I assume it's based\n>>> > on\n>>> > the\n>>> > current theoretical max at 1 MB blocks? Even a high-end PC would\n>>> > probably take\n>>> > 40-80 seconds just for the hashing, however - maybe a lower limit\n>>> > would\n>>> > be\n>>> > best?\n>>\n>>\n>> It is slightly more hashing than was required to validate block number\n>> 364,422.\n>>\n>> There are a couple of advantages to a very high limit:\n>>\n>> 1) When the fork is over, special-case code for dealing with old blocks\n>> can\n>> be eliminated, because all old blocks satisfy the new limit.\n>>\n>> 2) More importantly, if the limit is small enough it might get hit by\n>> standard transactions, then block creation code (CreateNewBlock() /\n>> getblocktemplate / or some external transaction-assembling software) will\n>> have to solve an even more complicated bin-packing problem to optimize\n>> for\n>> fees paid.\n>>\n>> In practice, the 20,000 sigop limit will always be reached before\n>> MAX_BLOCK_SIGHASH.\n>>\n>>\n>>>\n>>> >\n>>> >> Miners express their support for this BIP by ...\n>>> >\n>>> > But miners don't get to decide hardforks. How does the economy express\n>>> > their\n>>> > support for it? What happens if miners trigger it without consent from\n>>> > the\n>>> > economy?\n>>\n>>\n>> \"The economy\" does support this.\n>>\n>>\n>>>\n>>> >\n>>> > If you are intent on using the version bits to trigger the hardfork, I\n>>> > suggest\n>>> > rephrasing this such that miners should only enable the bit when they\n>>> > have\n>>> > independently confirmed economic support (this means implementations\n>>> > need a\n>>> > config option that defaults to off).\n>>\n>>\n>> Happy to add words about economic majority.\n>>\n>> Classic will not implement a command-line option (the act of running\n>> Classic\n>> is \"I opt in\"), but happy to add one for a pull request to Core, assuming\n>> Core would not see such a pull request as having any hostile intent.\n>>\n>>\n>>> >\n>>> >> SPV (simple payment validation) wallets are compatible with this\n>>> >> change.\n>>> >\n>>> > Would prefer if this is corrected to \"Light clients\" or something.\n>>> > Actual SPV\n>>> > wallets do not exist at this time, and would not be compatible with a\n>>> > hardfork.\n>>\n>>\n>> Is there an explanation of SPV versus \"Light Client\" written somewhere\n>> more\n>> permanent than a reddit comment or forum post that I can point to?\n>>\n>>>\n>>> >\n>>> >> In the short term, an increase is needed to continue the current\n>>> >> economic\n>>> >> policies with regards to fees and block space, matching market\n>>> >> expectations\n>>> >> and preventing market disruption.\n>>> >\n>>> > IMO this sentence is the most controversial part of your draft, and it\n>>> > wouldn't suffer a loss to remove it (or at least make it subjective).\n>>\n>>\n>> Happy to remove.\n>>\n>>>\n>>> > I would also prefer to see any hardfork:\n>>> >\n>>> > 1. Address at least the simple tasks on the hardfork wishlist (eg,\n>>> > enable some\n>>> >    disabled opcodes; fix P2SH for N-of->15 multisig; etc).\n>>\n>>\n>> Those would be separate BIPs. (according to BIP 1, smaller is better)\n>>\n>> After this 2MB bump, I agree we need to agree on a process for the next\n>> hard\n>> fork to avoid all of the unnecessary drama.\n>>\n>>> > 2. Be deployed as a soft-hardfork so as not to leave old nodes\n>>> > entirely\n>>> >    insecure.\n>>\n>>\n>> I haven't been paying attention to all of the\n>> \"soft-hardfork/hard-softfork/etc\" terminology so have no idea what you\n>> mean.\n>> Is THAT written up somewhere?\n>>\n>> --\n>> --\n>> Gavin Andresen\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2016-02-06T17:09:21",
                "message_text_only": "On Feb 6, 2016 16:37, \"Gavin Andresen\" <gavinandresen at gmail.com> wrote:\n>\n> Responding to \"28 days is not long enough\" :\n\nAny thoughts on the \"95% better than 75%\" and \"grace period before miner\ncoordination instead of after\" comments ?\n\n> I suspect there ARE a significant percentage of un-maintained full\nnodes-- probably 30 to 40%. Losing those nodes will not be a problem, for\nthree reasons:\n\nNone of the reasons you list say anything about the fact that \"being lost\"\n(kicked out of the network) is a problem for those node's users.\n\n> I strongly disagree with the statement that there is no cost to a longer\ngrace period.\n\nI didn't say that.\n\n> To bring it back to bitcoin-dev territory:  are there any TECHNICAL\narguments why an upgrade would take a business or individual longer than 28\ndays?\n\nTheir own software stack may require more work to integrate the new rules\nor their resources may not be immediately available to focus on this within\n28 days they hadn't planned.\n\nI believe it wold be less controversial to chose something that nobody can\ndeny is more than plenty of time for everyone  to implement the changes\nlike, say, 1 year. I wouldn't personally oppose to something shorter like 6\nmonths for really simple changes, but I don't see how 28 can ever be\nconsidered uncontroversial and safe for everyone. Just trying to help in\nremoving controversy from the PR, but if you still think 28 can be safe and\nuncontroversial, feel free to ignore these comments on the concrete length\nand please let me know what you think about the other points I raised.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160206/567808a2/attachment.html>"
            },
            {
                "author": "Tom Zander",
                "date": "2016-02-06T17:25:21",
                "message_text_only": "On Saturday, February 06, 2016 06:09:21 PM Jorge Tim\u00f3n via bitcoin-dev wrote:\n> None of the reasons you list say anything about the fact that \"being lost\"\n> (kicked out of the network) is a problem for those node's users.\n\nThat's because its not.\n\nIf you have a node that is \"old\" your node will stop getting new blocks. \nThe node will essentially just say \"x-hours behind\" with \"x\" getting larger \nevery hour. Funds don't get confirmed. etc.\n\nAfter upgrading the software they will see the new reality of the network.\n\nNobody said its a problem, because its not.\n\n-- \nTom Zander"
            },
            {
                "author": "Chris Priest",
                "date": "2016-02-06T20:22:30",
                "message_text_only": "Its mostly a problem for exchanges and miners. Those entities need to\nbe on the network 100% of the time because they are using the network\n100% of the time. A normal wallet user isn't taking payments every few\nminutes like the exchanges are. \"Getting booted off the network\" is\nnot something to worry about for normal wallet users.\n\nIf miners aren't up to date, that is the biggest problem. A sudden\ndrop in hashpower will effect the network for all users, including\nnormal wallet users (by them having to wait longer for confirmations).\nMiners must not be booted off the network ever. Hashpower voting is\nthe best way to make sure this never happens.\n\nOn 2/6/16, Tom Zander via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> On Saturday, February 06, 2016 06:09:21 PM Jorge Tim\u00f3n via bitcoin-dev\n> wrote:\n>> None of the reasons you list say anything about the fact that \"being\n>> lost\"\n>> (kicked out of the network) is a problem for those node's users.\n>\n> That's because its not.\n>\n> If you have a node that is \"old\" your node will stop getting new blocks.\n> The node will essentially just say \"x-hours behind\" with \"x\" getting larger\n>\n> every hour. Funds don't get confirmed. etc.\n>\n> After upgrading the software they will see the new reality of the network.\n>\n> Nobody said its a problem, because its not.\n>\n> --\n> Tom Zander\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-06T20:46:39",
                "message_text_only": "On Saturday, February 06, 2016 5:25:21 PM Tom Zander via bitcoin-dev wrote:\n> On Saturday, February 06, 2016 06:09:21 PM Jorge Tim\u00f3n via bitcoin-dev \nwrote:\n> > None of the reasons you list say anything about the fact that \"being\n> > lost\" (kicked out of the network) is a problem for those node's users.\n> \n> That's because its not.\n> \n> If you have a node that is \"old\" your node will stop getting new blocks.\n> The node will essentially just say \"x-hours behind\" with \"x\" getting larger\n> every hour. Funds don't get confirmed. etc.\n\nUntil someone decides to attack you. Then you'll get 6, 10, maybe more blocks \nconfirming a large 10000 BTC payment. If you're just a normal end user (or \nperhaps an automated system), you'll figure that payment is good and \nirreversibly hand over the title to the house.\n\nLuke"
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-02-07T14:16:02",
                "message_text_only": "On Sat, Feb 6, 2016 at 3:46 PM, Luke Dashjr via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Saturday, February 06, 2016 5:25:21 PM Tom Zander via bitcoin-dev wrote:\n> > On Saturday, February 06, 2016 06:09:21 PM Jorge Tim\u00f3n via bitcoin-dev\n> wrote:\n> > > None of the reasons you list say anything about the fact that \"being\n> > > lost\" (kicked out of the network) is a problem for those node's users.\n> >\n> > That's because its not.\n> >\n> > If you have a node that is \"old\" your node will stop getting new blocks.\n> > The node will essentially just say \"x-hours behind\" with \"x\" getting\n> larger\n> > every hour. Funds don't get confirmed. etc.\n>\n> Until someone decides to attack you. Then you'll get 6, 10, maybe more\n> blocks\n> confirming a large 10000 BTC payment. If you're just a normal end user (or\n> perhaps an automated system), you'll figure that payment is good and\n> irreversibly hand over the title to the house.\n>\n\nThere will be approximately zero percentage of hash power left on the\nweaker branch of the fork, based on past soft-fork adoption by miners (they\nupgrade VERY quickly from 75% to over 95%).\n\nSo it will take a week to get 6 confirmations.\n\nIf you are a full node, you are warned that your software is obsolete and\nyou must upgrade.\n\nIf you are a lightweight node, it SHOULD tell you something is wrong, but\neven if it doesn't, given that people running lightweight nodes run them so\nthey don't have to be connected to the network 24/7, it is very likely\nduring that week you disconnect and reconnect to the network several times.\nAnd every time you do that you increase your chances that you will connect\nto full nodes on the majority branch of the chain, where you will be told\nabout the double-spend.\n\nAll of that is assuming that there is no OTHER mitigation done. DNS seeds\nshould avoid reporting nodes that look like they are in the middle of\ninitial block download (that are at a block height significantly behind the\nrest of the network), for example.\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160207/7956ed21/attachment.html>"
            },
            {
                "author": "Alex Morcos",
                "date": "2016-02-07T15:06:06",
                "message_text_only": "I apologize if this discussion should be moved to -discuss, I'll let the\nmoderators decide, I've copied both.\n\nAnd Gavin, I apologize for picking on you here, because certainly this\ncarelessness in how people represent \"facts\" applies to both sides, but\nmuch of this discussion really infuriates me.\nI believe it is completely irresponsible for you to state:\n\"There will be approximately zero percentage of hash power left on the\nweaker branch of the fork, based on past soft-fork adoption by miners\"\nSure, the rest of the technical community is capable of evaluating that for\nthemselves, but your statements are considered authoritative by much larger\naudience.  In truth, no one has any idea what would happen if the proposed\nClassic hard fork activated with 75% right now.  There is some chance you\nare right, but there is a very legitimate possibility that a concerted\neffort would arise to maintain a minority fork or perhaps if miners don't\nsee nearly a complete switch over, many of them might themselves reverse\nthe fork if they think it would be easier to achieve consensus that way.\nWe as a community have never been in such a situation before and it\nbehooves us to speak honestly and directly about the uncertainty of the\nsituation.\n\nAnd the back and forth discussion over your BIP has been in large part a\ncharade.  People asking why you aren't picking 95% know very well why you\naren't, but lets have an honest discussion of what the risks and in your\nmind potential benefits of 75% are.   Important debate about parameters of\nyour BIP get lost because we're sniping at each other about known\ndisagreements.  For instance, I strongly believe 28 days is far too short.\nI think its extremely unlikely that those who are opposed to a contentious\nhard fork will do the development work to prepare for it as that may only\nmake it more likely to happen.  Thus if you did achieve activation with\n75%, its almost impossible to imagine that if Bitcoin Core decided to come\nalong (as opposed to pursuing a minority fork) that they'd have the time to\ndevelop and test the patch and roll it out to wide adoption.   If the goal\nof your attempt is that any minority that disagreed will \"choose\" to follow\nthe majority branch, then you'd be much more likely to achieve that by\ngiving them time to decide that's what they wanted and roll out the\nsoftware to do so.\n\n\n\n\nOn Sun, Feb 7, 2016 at 9:16 AM, Gavin Andresen via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Sat, Feb 6, 2016 at 3:46 PM, Luke Dashjr via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> On Saturday, February 06, 2016 5:25:21 PM Tom Zander via bitcoin-dev\n>> wrote:\n>> > On Saturday, February 06, 2016 06:09:21 PM Jorge Tim\u00f3n via bitcoin-dev\n>> wrote:\n>> > > None of the reasons you list say anything about the fact that \"being\n>> > > lost\" (kicked out of the network) is a problem for those node's users.\n>> >\n>> > That's because its not.\n>> >\n>> > If you have a node that is \"old\" your node will stop getting new blocks.\n>> > The node will essentially just say \"x-hours behind\" with \"x\" getting\n>> larger\n>> > every hour. Funds don't get confirmed. etc.\n>>\n>> Until someone decides to attack you. Then you'll get 6, 10, maybe more\n>> blocks\n>> confirming a large 10000 BTC payment. If you're just a normal end user (or\n>> perhaps an automated system), you'll figure that payment is good and\n>> irreversibly hand over the title to the house.\n>>\n>\n> There will be approximately zero percentage of hash power left on the\n> weaker branch of the fork, based on past soft-fork adoption by miners (they\n> upgrade VERY quickly from 75% to over 95%).\n>\n> So it will take a week to get 6 confirmations.\n>\n> If you are a full node, you are warned that your software is obsolete and\n> you must upgrade.\n>\n> If you are a lightweight node, it SHOULD tell you something is wrong, but\n> even if it doesn't, given that people running lightweight nodes run them so\n> they don't have to be connected to the network 24/7, it is very likely\n> during that week you disconnect and reconnect to the network several times.\n> And every time you do that you increase your chances that you will connect\n> to full nodes on the majority branch of the chain, where you will be told\n> about the double-spend.\n>\n> All of that is assuming that there is no OTHER mitigation done. DNS seeds\n> should avoid reporting nodes that look like they are in the middle of\n> initial block download (that are at a block height significantly behind the\n> rest of the network), for example.\n>\n> --\n> --\n> Gavin Andresen\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160207/b8871116/attachment-0001.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-02-07T16:54:23",
                "message_text_only": "On Sun, Feb 07, 2016 at 10:06:06AM -0500, Alex Morcos via bitcoin-dev wrote:\n> And the back and forth discussion over your BIP has been in large part a\n> charade.  People asking why you aren't picking 95% know very well why you\n> aren't, but lets have an honest discussion of what the risks and in your\n\nEh, lets not put words into people's mouths. I personally don't\nunderstand why Gavin is using 75% in the manner that he is, given there\nare many better alternatives, even if you don't think you can get ~100%\nhashing power support.\n\n> mind potential benefits of 75% are.   Important debate about parameters of\n> your BIP get lost because we're sniping at each other about known\n> disagreements.  For instance, I strongly believe 28 days is far too short.\n\nNote that the grace period adds a significant amount of complexity to\nthe implementation; a much simpler alternative is to just use a hashing\npower activated change with a very high threshold - 99% or so - with a\nminimum activation date some point reasonably far into the future.\n\nAlso the way the grace period is implemented means that if support\n*drops* after 75% is reached, the hardfork still activates (I haven't\nactually tested this, so I may be misunderstanding the code). Obviously,\nthis is a dangerous situation, and an easy way for miners to \"poison the\nwell\" and disruptively force the fork to be rescheduled without actually\nattacking the coin (nothing wrong with changing your mind! and pool\ndistribution may change anyway).\n\nAgain, a simple high % miner consensus fork with a reasonable minimum\nactivation time avoids all these problems, with far less code\ncomplexity.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n00000000000000000711a9829e87ba8ea548f1793950893043a5dc56893dc1dc\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160207/2fbb3c34/attachment.sig>"
            },
            {
                "author": "Anthony Towns",
                "date": "2016-02-07T15:19:27",
                "message_text_only": "On Sun, Feb 07, 2016 at 09:16:02AM -0500, Gavin Andresen via bitcoin-dev wrote:\n> There will be approximately zero percentage of hash power left on the\n> weaker branch of the fork, based on past soft-fork adoption by miners (they\n> upgrade VERY quickly from 75% to over 95%).\n\nThe stated reasoning for 75% versus 95% is \"because it gives \"veto power\"\nto a single big solo miner or mining pool\". But if a 20% miner wants to\n\"veto\" the upgrade, with a 75% threshold, they could instead simply use\ntheir hashpower to vote for an upgrade, but then not mine anything on\nthe new chain. At that point there'd be as little as 55% mining the new\n2MB chain with 45% of hashpower remaining on the old chain. That'd be 18\nminute blocks versus 22 minute blocks, which doesn't seem like much of\na difference in practice, and at that point hashpower could plausibly\nend up switching almost entirely back to the original consensus rules\nprior to the grace period ending.\n\nWith a non-consensus fork, I think you need to expect people involved to\npotentially act in ways that aren't very gentlemanly, and guard against\nit if you want the fork to be anything other than a huge mess.\n\nCheers,\naj"
            },
            {
                "author": "Jonathan Toomim",
                "date": "2016-02-07T17:10:39",
                "message_text_only": "On Feb 7, 2016, at 7:19 AM, Anthony Towns via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> The stated reasoning for 75% versus 95% is \"because it gives \"veto power\"\n> to a single big solo miner or mining pool\". But if a 20% miner wants to\n> \"veto\" the upgrade, with a 75% threshold, they could instead simply use\n> their hashpower to vote for an upgrade, but then not mine anything on\n> the new chain. At that point there'd be as little as 55% mining the new\n> 2MB chain with 45% of hashpower remaining on the old chain. That'd be 18\n> minute blocks versus 22 minute blocks, which doesn't seem like much of\n> a difference in practice, and at that point hashpower could plausibly\n> end up switching almost entirely back to the original consensus rules\n> prior to the grace period ending.\n\n\nKeep in mind that within a single difficulty adjustment period, the difficulty of mining a block on either chain will be identical. Even if the value of a 1MB branch coin is $100 and the hashrate on the 1 MB branch is 100 PH/s, and the value of a 2 MB branch coin is $101 and the hashrate on the 2 MB branch is 1000 PH/s, the rational thing for a miner to do (for the first adjustment period) is to mine on the 2 MB branch, because the miner would earn 1% more on that branch.\n\nSo you're assuming that 25% of the hashrate chooses to remain on the minority version during the grace period, and that 20% chooses to switch back to the minority side. The fork happens. One branch has 1 MB blocks every 22 minutes, and the other branch has 2 MB blocks every 18 minutes. The first branch cannot handle the pre-fork transaction volume, as it only has 45% of the capacity that it had pre-fork. The second one can, as it has 111% of the pre-fork capacity. This makes the 1 MB branch much less usable than the 2 MB branch, which in turn causes the market value of newly minted coins on that branch to fall, which in turn causes miners to switch to the more profitable 2MB branch. This exacerbates the usability difference, which exacerbates the price difference, etc. Having two competing chains with equal hashrate using the same PoW function and nearly equal features is not a stable state. Positive feedback loops exist to make the vast majority of the users and the hashrate join one side.\n\nBasically, any miners who stick to the minority branch are going to lose a lot of money.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160207/d2b9d665/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 496 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160207/d2b9d665/attachment-0001.sig>"
            },
            {
                "author": "jl2012 at xbt.hk",
                "date": "2016-02-07T17:24:25",
                "message_text_only": "You are making a very na\u00efve assumption that miners are just looking for\nprofit for the next second. Instead, they would try to optimize their short\nterm and long term ROI. It is also well known that some miners would mine at\na loss, even not for ideological reasons, if they believe that their action\nis beneficial to the network and will provide long term ROI. It happened\nafter the last halving in 2012. Without any immediate price appreciation,\nthe hashing rate decreased by only less than 10%\n\n \n\nhttp://bitcoin.sipa.be/speed-ever.png\n\n \n\n \n\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org\n[mailto:bitcoin-dev-bounces at lists.linuxfoundation.org] On Behalf Of Jonathan\nToomim via bitcoin-dev\nSent: Monday, 8 February, 2016 01:11\nTo: Anthony Towns <aj at erisian.com.au>\nCc: bitcoin-dev at lists.linuxfoundation.org\nSubject: Re: [bitcoin-dev] BIP proposal: Increase block size limit to 2\nmegabytes\n\n \n\n \n\nOn Feb 7, 2016, at 7:19 AM, Anthony Towns via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org\n<mailto:bitcoin-dev at lists.linuxfoundation.org> > wrote:\n\n\n\n\n\nThe stated reasoning for 75% versus 95% is \"because it gives \"veto power\"\nto a single big solo miner or mining pool\". But if a 20% miner wants to\n\"veto\" the upgrade, with a 75% threshold, they could instead simply use\ntheir hashpower to vote for an upgrade, but then not mine anything on\nthe new chain. At that point there'd be as little as 55% mining the new\n2MB chain with 45% of hashpower remaining on the old chain. That'd be 18\nminute blocks versus 22 minute blocks, which doesn't seem like much of\na difference in practice, and at that point hashpower could plausibly\nend up switching almost entirely back to the original consensus rules\nprior to the grace period ending.\n\n \n\nKeep in mind that within a single difficulty adjustment period, the\ndifficulty of mining a block on either chain will be identical. Even if the\nvalue of a 1MB branch coin is $100 and the hashrate on the 1 MB branch is\n100 PH/s, and the value of a 2 MB branch coin is $101 and the hashrate on\nthe 2 MB branch is 1000 PH/s, the rational thing for a miner to do (for the\nfirst adjustment period) is to mine on the 2 MB branch, because the miner\nwould earn 1% more on that branch.\n\n \n\nSo you're assuming that 25% of the hashrate chooses to remain on the\nminority version during the grace period, and that 20% chooses to switch\nback to the minority side. The fork happens. One branch has 1 MB blocks\nevery 22 minutes, and the other branch has 2 MB blocks every 18 minutes. The\nfirst branch cannot handle the pre-fork transaction volume, as it only has\n45% of the capacity that it had pre-fork. The second one can, as it has 111%\nof the pre-fork capacity. This makes the 1 MB branch much less usable than\nthe 2 MB branch, which in turn causes the market value of newly minted coins\non that branch to fall, which in turn causes miners to switch to the more\nprofitable 2MB branch. This exacerbates the usability difference, which\nexacerbates the price difference, etc. Having two competing chains with\nequal hashrate using the same PoW function and nearly equal features is not\na stable state. Positive feedback loops exist to make the vast majority of\nthe users and the hashrate join one side.\n\n \n\nBasically, any miners who stick to the minority branch are going to lose a\nlot of money.\n\n \n\n \n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160208/4325182f/attachment.html>"
            },
            {
                "author": "Jonathan Toomim",
                "date": "2016-02-07T17:56:48",
                "message_text_only": "On Feb 7, 2016, at 9:24 AM, jl2012 at xbt.hk wrote:\n\n> You are making a very na\u00efve assumption that miners are just looking for profit for the next second. Instead, they would try to optimize their short term and long term ROI. It is also well known that some miners would mine at a loss, even not for ideological reasons, if they believe that their action is beneficial to the network and will provide long term ROI. It happened after the last halving in 2012. Without any immediate price appreciation, the hashing rate decreased by only less than 10%\n> \n\n\nIn 2012, revenue dropped by about 50% instantaneously. That does not mean that profitability became negative.\n\nThe difficulty at the time of the halving was about 3M. The exchange rate was about $12. A common miner at the time was the Radeon 6970, which performed about 350 Mh/s on 200 W for about 1.75 Mh/J. A computer with 4 6970s would use about 1 kW of power, once AC/DC losses and CPU overhead are taken into account. This 1 kW rig would have earned about $0.22/kWh before the halving, and $0.11/kWh after the halving. Since it's not hard to find electricity cheaper than $0.11/kWh, the hashrate didn't drop much.\n\nIt's a common misconception that the mining hashrate increases until an equilibrium is reached, and nobody is making a profit any longer. However, this is not true. The hashrate stops increasing when the expected operating profit over a reasonable time frame is no longer greater than the hardware cost, not when the operating profit approaches zero. For example, an S7 right now costs a little over $1000. If I don't expect to earn more than $1000 in operating profit over the next year or two with an S7, then I won't buy one.\n\nRight now, an S7 earns about $190/month and costs about $60/month to operate, for a profit of $120/month. After the halving, revenue would drop to $95/month (or less, depending on difficulty and exchange rate), leaving profit at about $35/month. The $120/month profit is good enough motivation to buy hardware now, and the $35/month would be good enough motivation to keep running hardware after the halving.\n\nI know in advance when the halvings are coming. There's going to be one in about 5 months, for example. I'm going to stop buying miners before the halving even if they're very profitable for a month because I don't want to be stuck with hardware that won't reach 100% return on investment (ROI).\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160207/cc038b30/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 496 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160207/cc038b30/attachment-0001.sig>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-07T21:01:13",
                "message_text_only": "On Sunday, February 07, 2016 2:16:02 PM Gavin Andresen wrote:\n> On Sat, Feb 6, 2016 at 3:46 PM, Luke Dashjr via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > On Saturday, February 06, 2016 5:25:21 PM Tom Zander via bitcoin-dev \nwrote:\n> > > If you have a node that is \"old\" your node will stop getting new\n> > > blocks. The node will essentially just say \"x-hours behind\" with \"x\"\n> > > getting larger every hour. Funds don't get confirmed. etc.\n> > \n> > Until someone decides to attack you. Then you'll get 6, 10, maybe more\n> > blocks confirming a large 10000 BTC payment. If you're just a normal end\n> > user (or perhaps an automated system), you'll figure that payment is good\n> > and irreversibly hand over the title to the house.\n> \n> There will be approximately zero percentage of hash power left on the\n> weaker branch of the fork, based on past soft-fork adoption by miners (they\n> upgrade VERY quickly from 75% to over 95%).\n\nI'm assuming there are literally ZERO miners left on the weaker branch.\nThe attacker in this scenario simply rents hashing for a few days in advance \nto build his fake chain, then broadcasts the blocks to the unsuspecting \nmerchant at ~10 block intervals so it looks like everything is working normal \nagain. There are lots of mining rental services out there, and miners quite \noften do not care to avoid selling hashrate to the highest bidder regardless \nof what they're mining. 10 blocks worth costs a little more than 250 BTC - \nsoon, that will be 125 BTC.\n\nLuke"
            },
            {
                "author": "Steven Pine",
                "date": "2016-02-07T21:33:13",
                "message_text_only": "Is it me or did Gavin ignore Yifu's direct questions? In case you missed it\nGavin --\n\n~\n\"We can look at the adoption of the last major Bitcoin core release to\nguess how long it might take people to upgrade. 0.11.0 was released on 12\nJuly, 2015. Twenty eight days later, about 38% of full nodes were running\nthat release. Three months later, about 50% of the network was running that\nrelease, and six months later about 66% of the network was running some\nflavor of 0.11.\"\n\nOn what grounds do you think it is reasonable to assume that this update\nwill roll out 6x faster than previous data suggested, as oppose to your own\nobservation of 66% adoption in 6 month. or do you believe 38% node\nupgrade-coverage (in 28 days ) on the network for a hard fork is good\nenough?\n\nThere are no harm in choosing a longer grace period but picking one short\nas 28 days you risk on alienating the nodes who do not upgrade with the\naggressive upgrade timeline you proposed.\n~~\n\nWhen Gavin writes \"Responding to \"28 days is not long enough\" :\n\nI keep seeing this claim made with no evidence to back it up.  As I said, I\nsurveyed several of the biggest infrastructure providers and the btcd lead\ndeveloper and they all agree \"28 days is plenty of time.\"\n\nFor individuals... why would it take somebody longer than 28 days to either\ndownload and restart their bitcoind, or to patch and then re-run (the patch\ncan be a one-line change MAX_BLOCK_SIZE from 1000000 to 2000000)?\"\n\n~~\n\nIsn't Yifu's comment, evidence, the very best sort of evidence, it isn't\npropositional a priori logic, but empirical evidence that. As for why\npeople take longer, who knows, we simply know from passed experience that\nit in fact does take longer.\n\nIt's extremely frustrating to read Gavin's comments, it's hard to believe\nhe is engaging in earnest discussion.\n\nOn Sun, Feb 7, 2016 at 4:01 PM, Luke Dashjr via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Sunday, February 07, 2016 2:16:02 PM Gavin Andresen wrote:\n> > On Sat, Feb 6, 2016 at 3:46 PM, Luke Dashjr via bitcoin-dev <\n> > bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > > On Saturday, February 06, 2016 5:25:21 PM Tom Zander via bitcoin-dev\n> wrote:\n> > > > If you have a node that is \"old\" your node will stop getting new\n> > > > blocks. The node will essentially just say \"x-hours behind\" with \"x\"\n> > > > getting larger every hour. Funds don't get confirmed. etc.\n> > >\n> > > Until someone decides to attack you. Then you'll get 6, 10, maybe more\n> > > blocks confirming a large 10000 BTC payment. If you're just a normal\n> end\n> > > user (or perhaps an automated system), you'll figure that payment is\n> good\n> > > and irreversibly hand over the title to the house.\n> >\n> > There will be approximately zero percentage of hash power left on the\n> > weaker branch of the fork, based on past soft-fork adoption by miners\n> (they\n> > upgrade VERY quickly from 75% to over 95%).\n>\n> I'm assuming there are literally ZERO miners left on the weaker branch.\n> The attacker in this scenario simply rents hashing for a few days in\n> advance\n> to build his fake chain, then broadcasts the blocks to the unsuspecting\n> merchant at ~10 block intervals so it looks like everything is working\n> normal\n> again. There are lots of mining rental services out there, and miners quite\n> often do not care to avoid selling hashrate to the highest bidder\n> regardless\n> of what they're mining. 10 blocks worth costs a little more than 250 BTC -\n> soon, that will be 125 BTC.\n>\n> Luke\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n\n-- \nSteven Pine\n(510) 517-7075\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160207/3d005df7/attachment.html>"
            },
            {
                "author": "Corey Haddad",
                "date": "2016-02-07T22:04:32",
                "message_text_only": "We don't have any evidence of how fast nodes will upgrade when faced with\nan impending hard fork, but it seems like a very safe assumption that the\nupgrade pace will be significantly faster.  The hard fork case it is:\n\"upgrade or be kicked off the network\".  In the previous cases it has been,\n\"here's the latest and greatest, give it a go!\".  Also, there will be\nalerts sent out warning people of the situation, prompting them to take\naction.\n\nIt is unclear if this will translate into more or less than 6x the adoption\nspeed of previous instances, but the idea that it would be faster is\nsolid.  28 days is aggressive, but again, it is only 28 days from when the\nfork triggers.  Compatible software is already available for anyone who\nwants to prepare.\n\nIt is also of significance that this proposed fork, and this debate, has\nbeen going on for many, many months.  If someone proposed a forking concept\ntoday, wrote the BIP tomorrow, deployed it next week, miners adopted it\ninstantly, and 28 days later it was the flag day, those 28 days would be in\na different context.  There is no surprise here.\n\nOn Sun, Feb 7, 2016 at 1:33 PM, Steven Pine via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Is it me or did Gavin ignore Yifu's direct questions? In case you missed\n> it Gavin --\n>\n> ~\n> \"We can look at the adoption of the last major Bitcoin core release to\n> guess how long it might take people to upgrade. 0.11.0 was released on 12\n> July, 2015. Twenty eight days later, about 38% of full nodes were running\n> that release. Three months later, about 50% of the network was running\n> that release, and six months later about 66% of the network was running\n> some flavor of 0.11.\"\n>\n> On what grounds do you think it is reasonable to assume that this update\n> will roll out 6x faster than previous data suggested, as oppose to your own\n> observation of 66% adoption in 6 month. or do you believe 38% node\n> upgrade-coverage (in 28 days ) on the network for a hard fork is good\n> enough?\n>\n> There are no harm in choosing a longer grace period but picking one short\n> as 28 days you risk on alienating the nodes who do not upgrade with the\n> aggressive upgrade timeline you proposed.\n> ~~\n>\n> When Gavin writes \"Responding to \"28 days is not long enough\" :\n>\n> I keep seeing this claim made with no evidence to back it up.  As I said,\n> I surveyed several of the biggest infrastructure providers and the btcd\n> lead developer and they all agree \"28 days is plenty of time.\"\n>\n> For individuals... why would it take somebody longer than 28 days to\n> either download and restart their bitcoind, or to patch and then re-run\n> (the patch can be a one-line change MAX_BLOCK_SIZE from 1000000 to\n> 2000000)?\"\n>\n> ~~\n>\n> Isn't Yifu's comment, evidence, the very best sort of evidence, it isn't\n> propositional a priori logic, but empirical evidence that. As for why\n> people take longer, who knows, we simply know from passed experience that\n> it in fact does take longer.\n>\n> It's extremely frustrating to read Gavin's comments, it's hard to believe\n> he is engaging in earnest discussion.\n>\n> On Sun, Feb 7, 2016 at 4:01 PM, Luke Dashjr via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> On Sunday, February 07, 2016 2:16:02 PM Gavin Andresen wrote:\n>> > On Sat, Feb 6, 2016 at 3:46 PM, Luke Dashjr via bitcoin-dev <\n>> > bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> > > On Saturday, February 06, 2016 5:25:21 PM Tom Zander via bitcoin-dev\n>> wrote:\n>> > > > If you have a node that is \"old\" your node will stop getting new\n>> > > > blocks. The node will essentially just say \"x-hours behind\" with \"x\"\n>> > > > getting larger every hour. Funds don't get confirmed. etc.\n>> > >\n>> > > Until someone decides to attack you. Then you'll get 6, 10, maybe more\n>> > > blocks confirming a large 10000 BTC payment. If you're just a normal\n>> end\n>> > > user (or perhaps an automated system), you'll figure that payment is\n>> good\n>> > > and irreversibly hand over the title to the house.\n>> >\n>> > There will be approximately zero percentage of hash power left on the\n>> > weaker branch of the fork, based on past soft-fork adoption by miners\n>> (they\n>> > upgrade VERY quickly from 75% to over 95%).\n>>\n>> I'm assuming there are literally ZERO miners left on the weaker branch.\n>> The attacker in this scenario simply rents hashing for a few days in\n>> advance\n>> to build his fake chain, then broadcasts the blocks to the unsuspecting\n>> merchant at ~10 block intervals so it looks like everything is working\n>> normal\n>> again. There are lots of mining rental services out there, and miners\n>> quite\n>> often do not care to avoid selling hashrate to the highest bidder\n>> regardless\n>> of what they're mining. 10 blocks worth costs a little more than 250 BTC -\n>> soon, that will be 125 BTC.\n>>\n>> Luke\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n>\n>\n> --\n> Steven Pine\n> (510) 517-7075\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160207/db587ac0/attachment.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-06T20:36:23",
                "message_text_only": "On Saturday, February 06, 2016 3:37:30 PM Gavin Andresen wrote:\n> I suspect there ARE a significant percentage of un-maintained full nodes--\n\nDo you have evidence these are intentionally unmaintained, and not users who \nhave simply not had time to review and decide on upgrading?\n\n> There is broad agreement that a capacity increase is needed NOW.\n\nIf so, it is only based on misinformation. I am concerned you are implying \nthis conclusion is true. When I spoke with you maybe a year ago with my \nconcerns that block size might grow too fast, you suggested that the miners \ncould be trusted to not increase the block size until necessary (which is not \nlikely to be any time soon, despite the massive misinformation campaigns out \nthere).\n\n> On Sat, Feb 6, 2016 at 1:12 AM, Luke Dashjr via bitcoin-dev\n> > > > Miners express their support for this BIP by ...\n> > > \n> > > But miners don't get to decide hardforks. How does the economy\n> > > express their support for it? What happens if miners trigger it\n> > > without consent from the economy?\n> \n> \"The economy\" does support this.\n\nI have seen evidence which suggests the contrary. For example:\n    https://twitter.com/barrysilbert/status/694911989701861376\n\n\nWhere is yours?\n\n> > If you are intent on using the version bits to trigger the\n> > hardfork, I suggest rephrasing this such that miners should\n> > only enable the bit when they have independently confirmed\n> > economic support (this means implementations need a config\n> > option that defaults to off).\n> \n> Happy to add words about economic majority.\n> \n> Classic will not implement a command-line option (the act of running\n> Classic is \"I opt in\"), but happy to add one for a pull request to Core,\n> assuming Core would not see such a pull request as having any hostile\n> intent.\n\nBut this isn't about the miner opting in, it is about the miner *observing \neconomic support* for the change. I have successfully downloaded Bitcoin \nClassic's beta binaries without ANY warning that by running it, I am \nexpressing that I believe the economy has approved of a hardfork.\n\n> > > SPV (simple payment validation) wallets are compatible with this\n> > > change.\n> > \n> > Would prefer if this is corrected to \"Light clients\" or something.\n> > Actual SPV wallets do not exist at this time, and would not be\n> > compatible with a hardfork.\n> \n> Is there an explanation of SPV versus \"Light Client\" written somewhere more\n> permanent than a reddit comment or forum post that I can point to?\n\nNot that I am aware of. (But both reddit comments and forum posts have  \noutlived many other posts, such as blogs, so I'm not sure why to exclude them \nspecifically...)\n\nIn any case, since SPV nodes don't exist, there is probably no real need to \naddress them. Everyone will know what \"light client\" means.\n \n> > I would also prefer to see any hardfork:\n> > 2. Be deployed as a soft-hardfork so as not to leave old nodes entirely\n> > insecure.\n> \n> I haven't been paying attention to all of the\n> \"soft-hardfork/hard-softfork/etc\" terminology so have no idea what you\n> mean. Is THAT written up somewhere?\n\nWorking on a BIP draft for it, but it's not ready for publication yet. The \nbasic idea is to turn the merkle root in the block header into simply a hash \nof a second block header, which is constructed to parse as a valid empty \ngeneration transaction under the old rules. Thus, old nodes see the forked \nblockchain as valid with continually growing work on it, but as if the blocks \nwere all empty. This protects them from attackers mining a short blockchain \nthey perceive as valid.\n\nLuke"
            },
            {
                "author": "Jannes Faber",
                "date": "2016-02-07T05:21:00",
                "message_text_only": "On 6 Feb 2016 4:41 p.m., \"Gavin Andresen via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Responding to \"28 days is not long enough\" :\n>\n> I keep seeing this claim made with no evidence to back it up.  As I said,\nI surveyed several of the biggest infrastructure providers and the btcd\nlead developer and they all agree \"28 days is plenty of time.\"\n\n28 days doesn't sound like enough for exchanges and others holding 3rd\nparty coins. They will have to start untangling the Bitcoins from\nclassiccoins immediately, while pausing all withdrawals. They *must* be\nable to send their customers both coins as separate withdrawals. If not,\nthat amounts to theft of their customers funds.\n\n(Note that the above describes the honest exchanges. Imagine the dishonest\nones that simply steal the classiccoins from their customers and sell them\nfor their own profit.)\n\nThe only other option is guaranteeing customers both coins in one\ntransaction, which they can't.\n\nSurely you can't expect small entities to start putting in massive man\nhours into this even before the hard fork has been triggered? Or even big\nentities to have all that implemented and tested within *20* working days?\n\n--\nJannes\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160207/1c6a2ee5/attachment.html>"
            },
            {
                "author": "Jonathan Toomim",
                "date": "2016-02-07T18:55:52",
                "message_text_only": "On Feb 6, 2016, at 9:21 PM, Jannes Faber via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> They *must* be able to send their customers both coins as separate withdrawals.\n> \nSupporting the obsolete chain is unnecessary. Such support has not been offered in any cryptocurrency hard fork before, as far as I know. I do not see why it should start now.\n> If not, that amounts to theft of their customers funds.\n> \nIf they announce their planned behavior before the fork, I do not see any ethical or legal issues.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160207/e4c61e53/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 496 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160207/e4c61e53/attachment.sig>"
            },
            {
                "author": "Patrick Strateman",
                "date": "2016-02-07T19:03:54",
                "message_text_only": "I would expect that custodians who fail to produce coins on both sides\nof a fork in response to depositor requests will find themselves in\nserious legal trouble.\n\nEspecially if the price moves against either fork.\n\nOn 02/07/2016 10:55 AM, Jonathan Toomim via bitcoin-dev wrote:\n>\n> On Feb 6, 2016, at 9:21 PM, Jannes Faber via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org\n> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>\n>> They *must* be able to send their customers both coins as separate\n>> withdrawals.\n>>\n> Supporting the obsolete chain is unnecessary. Such support has not\n> been offered in any cryptocurrency hard fork before, as far as I know.\n> I do not see why it should start now.\n>>\n>> If not, that amounts to theft of their customers funds.\n>>\n> If they announce their planned behavior before the fork, I do not see\n> any ethical or legal issues. \n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Trevin Hofmann",
                "date": "2016-02-07T19:19:44",
                "message_text_only": "Patrick,\n\nI would say that a company's terms of service should include their position\non this issue. It does not seem reasonable that they all are required to\nprovide access to coins on every single fork. Are custodial wallet users\nalso entitled to Clam, Zcash, and Decred, and others?\n\nRegardless, I think this thread should be about the technical merits of the\nBIP. Discussion of hard forks would be better held elsewhere.\n\nOn Sun, Feb 7, 2016 at 1:03 PM, Patrick Strateman via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I would expect that custodians who fail to produce coins on both sides\n> of a fork in response to depositor requests will find themselves in\n> serious legal trouble.\n>\n> Especially if the price moves against either fork.\n>\n> On 02/07/2016 10:55 AM, Jonathan Toomim via bitcoin-dev wrote:\n> >\n> > On Feb 6, 2016, at 9:21 PM, Jannes Faber via bitcoin-dev\n> > <bitcoin-dev at lists.linuxfoundation.org\n> > <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> >\n> >> They *must* be able to send their customers both coins as separate\n> >> withdrawals.\n> >>\n> > Supporting the obsolete chain is unnecessary. Such support has not\n> > been offered in any cryptocurrency hard fork before, as far as I know.\n> > I do not see why it should start now.\n> >>\n> >> If not, that amounts to theft of their customers funds.\n> >>\n> > If they announce their planned behavior before the fork, I do not see\n> > any ethical or legal issues.\n> >\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160207/df1374d3/attachment.html>"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-02-07T20:29:42",
                "message_text_only": "On Sun, Feb 7, 2016 at 7:03 PM, Patrick Strateman via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I would expect that custodians who fail to produce coins on both sides\n> of a fork in response to depositor requests will find themselves in\n> serious legal trouble.\n>\n\nIf the exchange uses an UTXO from before the fork to pay their clients,\nthen they are guaranteed to count as paying on all forks.  The exchange\ndoesn't need to specifically pay out for each fork.\n\nAs long as the exchange doesn't accidently double spend an output, even\nchange addresses are valid.\n\nIt is handling post-fork deposits where the problem can occur.  If they\nonly receive coins on one fork, then that should cause the client to be\ncredited with funds on both forks.\n\nThe easiest thing would be to refuse to accept deposits for a while\nbefore/after the fork happens.\n<https://www.avast.com/sig-email> This email has been sent from a\nvirus-free computer protected by Avast.\nwww.avast.com <https://www.avast.com/sig-email>\n<#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160207/9f4b728c/attachment-0001.html>"
            },
            {
                "author": "Yifu Guo",
                "date": "2016-02-09T13:59:01",
                "message_text_only": "Happy Lunar New Year Everyone!\n\nGavin,\n\n> I suspect there ARE a significant percentage of un-maintained full\n> nodes-- probably 30 to 40%. Losing those nodes will not be a problem, for\n> three reasons:\n\n\nThe notion of large set ( 30% to 40% ) of un-maintained full nodes are not\nevident on the network. below is data based on a personal snap shot taken\naround Dec, 2015. with the following assumptions.\n1) nodes running non standard version strings are considered a preference\nby the node operator and are not included.\n2) nodes below 0.10 are counted as so called \"un-maintained\" even though\nthey also can be a choice of the node operator.\n\nSatoshi:0.9.3, 105\nSatoshi:0.8.6, 74\nSatoshi:0.9.1, 49\nSatoshi:0.9.2.1, 42\nSatoshi:0.8.5, 39\nSatoshi:0.8.1, 35\nSatoshi:0.9.5, 14\nSatoshi:0.8.3, 12\nSatoshi:0.9.4, 10\nSatoshi:0.9.99, 10\nSatoshi:0.9.0, 5\nSatoshi:0.9.2, 5\nSatoshi:0.8.0, 4\nSatoshi:0.8.99, 1\nSatoshi:0.8.4, 1\n\nThere are 406 nodes total that falls under the un-maintained category,\nwhich is below 10% of the network.\nLuke also have some data here that shows similar results.\nhttp://luke.dashjr.org/programs/bitcoin/files/charts/versions.txt\n\n> The network could shrink by 60% and it would still have plenty of open\n> connection slots\n\n\nI'm afraid we have to agree to disagree if you think dropping support for\n60% of the nodes on the network when rolling out an upgrade is the sane\ndefault.\n\n>\n> > People are committing to spinning up thousands of supports-2mb-nodes\n> during the grace period.\n\n\nthousands of nodes?! where did you get this figure? who are these people?\n*Please* elaborate.\n\n> We could wait a year and pick up maybe 10 or 20% more.\n\n\nI don't understand this statement at all, please explicate.\n\n-- \n*Yifu Guo*\n*\"Life is an everlasting self-improvement.\"*\n\nOn Sat, Feb 6, 2016 at 10:37 AM, Gavin Andresen via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Responding to \"28 days is not long enough\" :\n>\n> I keep seeing this claim made with no evidence to back it up.  As I said,\n> I surveyed several of the biggest infrastructure providers and the btcd\n> lead developer and they all agree \"28 days is plenty of time.\"\n>\n> For individuals... why would it take somebody longer than 28 days to\n> either download and restart their bitcoind, or to patch and then re-run\n> (the patch can be a one-line change MAX_BLOCK_SIZE from 1000000 to 2000000)?\n>\n> For the Bitcoin Core project:  I'm well aware of how long it takes to roll\n> out new binaries, and 28 days is plenty of time.\n>\n> I suspect there ARE a significant percentage of un-maintained full nodes--\n> probably 30 to 40%. Losing those nodes will not be a problem, for three\n> reasons:\n> 1) The network could shrink by 60% and it would still have plenty of open\n> connection slots\n> 2) People are committing to spinning up thousands of supports-2mb-nodes\n> during the grace period.\n> 3) We could wait a year and pick up maybe 10 or 20% more.\n>\n> I strongly disagree with the statement that there is no cost to a longer\n> grace period. There is broad agreement that a capacity increase is needed\n> NOW.\n>\n> To bring it back to bitcoin-dev territory:  are there any TECHNICAL\n> arguments why an upgrade would take a business or individual longer than 28\n> days?\n>\n>\n> Responding to Luke's message:\n>\n> On Sat, Feb 6, 2016 at 1:12 AM, Luke Dashjr via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> > On Friday, February 05, 2016 8:51:08 PM Gavin Andresen via bitcoin-dev\n>> wrote:\n>> >> Blog post on a couple of the constants chosen:\n>> >>   http://gavinandresen.ninja/seventyfive-twentyeight\n>> >\n>> > Can you put this in the BIP's Rationale section (which appears to be\n>> mis-named\n>> > \"Discussion\" in the current draft)?\n>>\n>\n> I'll rename the section and expand it a little. I think standards\n> documents like BIPs should be concise, though (written for implementors),\n> so I'm not going to recreate the entire blog post there.\n>\n>\n>> >\n>> >> Signature operations in un-executed branches of a Script are not\n>> counted\n>> >> OP_CHECKMULTISIG evaluations are counted accurately; if the signature\n>> for a\n>> >> 1-of-20 OP_CHECKMULTISIG is satisified by the public key nearest the\n>> top\n>> >> of the execution stack, it is counted as one signature operation. If\n>> it is\n>> >> satisfied by the public key nearest the bottom of the execution stack,\n>> it\n>> >> is counted as twenty signature operations. Signature operations\n>> involving\n>> >> invalidly encoded signatures or public keys are not counted towards the\n>> >> limit\n>> >\n>> > These seem like they will break static analysis entirely. That was a\n>> noted\n>> > reason for creating BIP 16 to replace BIP 12. Is it no longer a\n>> concern? Would\n>> > it make sense to require scripts to commit to the total accurate-sigop\n>> count\n>> > to fix this?\n>>\n>\n> After implementing static counting and accurate counting... I was wrong.\n> Accurate/dynamic counting/limiting is quick and simple and can be\n> completely safe (the counting code can be told the limit and can\n> \"early-out\" validation).\n>\n> I think making scripts commit to a total accurate sigop count is a bad\n> idea-- it would make multisignature signing more complicated for zero\n> benefit.  E.g. if you're circulating a partially signed transaction to that\n> must be signed by 2 of 5 people, you can end up with a transaction that\n> requires 2, 3, 4, or 5 signature operations to validate (depending on which\n> public keys are used to do the signing).  The first signer might have no\n> idea who else would sign and wouldn't know the accurate sigop count.\n>\n>\n>> >\n>> >> The amount of data hashed to compute signature hashes is limited to\n>> >> 1,300,000,000 bytes per block.\n>> >\n>> > The rationale for this wasn't in your blog post. I assume it's based on\n>> the\n>> > current theoretical max at 1 MB blocks? Even a high-end PC would\n>> probably take\n>> > 40-80 seconds just for the hashing, however - maybe a lower limit would\n>> be\n>> > best?\n>>\n>\n> It is slightly more hashing than was required to validate block number\n> 364,422.\n>\n> There are a couple of advantages to a very high limit:\n>\n> 1) When the fork is over, special-case code for dealing with old blocks\n> can be eliminated, because all old blocks satisfy the new limit.\n>\n> 2) More importantly, if the limit is small enough it might get hit by\n> standard transactions, then block creation code (CreateNewBlock() /\n> getblocktemplate / or some external transaction-assembling software) will\n> have to solve an even more complicated bin-packing problem to optimize for\n> fees paid.\n>\n> In practice, the 20,000 sigop limit will always be reached before\n> MAX_BLOCK_SIGHASH.\n>\n>\n>\n>> >\n>> >> Miners express their support for this BIP by ...\n>> >\n>> > But miners don't get to decide hardforks. How does the economy express\n>> their\n>> > support for it? What happens if miners trigger it without consent from\n>> the\n>> > economy?\n>>\n>\n> \"The economy\" does support this.\n>\n>\n>\n>> >\n>> > If you are intent on using the version bits to trigger the hardfork, I\n>> suggest\n>> > rephrasing this such that miners should only enable the bit when they\n>> have\n>> > independently confirmed economic support (this means implementations\n>> need a\n>> > config option that defaults to off).\n>>\n>\n> Happy to add words about economic majority.\n>\n> Classic will not implement a command-line option (the act of running\n> Classic is \"I opt in\"), but happy to add one for a pull request to Core,\n> assuming Core would not see such a pull request as having any hostile\n> intent.\n>\n>\n> >\n>> >> SPV (simple payment validation) wallets are compatible with this\n>> change.\n>> >\n>> > Would prefer if this is corrected to \"Light clients\" or something.\n>> Actual SPV\n>> > wallets do not exist at this time, and would not be compatible with a\n>> > hardfork.\n>>\n>\n> Is there an explanation of SPV versus \"Light Client\" written somewhere\n> more permanent than a reddit comment or forum post that I can point to?\n>\n>\n>> >\n>> >> In the short term, an increase is needed to continue the current\n>> economic\n>> >> policies with regards to fees and block space, matching market\n>> expectations\n>> >> and preventing market disruption.\n>> >\n>> > IMO this sentence is the most controversial part of your draft, and it\n>> > wouldn't suffer a loss to remove it (or at least make it subjective).\n>>\n>\n> Happy to remove.\n>\n>\n>> > I would also prefer to see any hardfork:\n>> >\n>> > 1. Address at least the simple tasks on the hardfork wishlist (eg,\n>> enable some\n>> >    disabled opcodes; fix P2SH for N-of->15 multisig; etc).\n>>\n>\n> Those would be separate BIPs. (according to BIP 1, smaller is better)\n>\n> After this 2MB bump, I agree we need to agree on a process for the next\n> hard fork to avoid all of the unnecessary drama.\n>\n> > 2. Be deployed as a soft-hardfork so as not to leave old nodes entirely\n>> >    insecure.\n>>\n>\n> I haven't been paying attention to all of the\n> \"soft-hardfork/hard-softfork/etc\" terminology so have no idea what you\n> mean. Is THAT written up somewhere?\n>\n> --\n> --\n> Gavin Andresen\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160209/4029590c/attachment-0001.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2016-02-07T11:37:57",
                "message_text_only": "On Fri, Feb 05, 2016 at 03:51:08PM -0500, Gavin Andresen via bitcoin-dev wrote:\n> Constructive feedback welcome; [...]\n> Summary:\n>   Increase block size limit to 2,000,000 bytes.\n>   With accurate sigop counting, but existing sigop limit (20,000)\n>   And a new, high limit on signature hashing\n\nTo me, it seems absurd to have a hardfork but not take the opportunity\nto combine these limits into a single weighted sum.\n\nI'd suggest:\n\n   0.5*blocksize + 50*accurate_sigops + 0.001*sighash < 2,000,000\n\nThat provides worst case blocksize of 4MB, worst case sigops of 40,000\nand worst case sighash bytes of 2GB. Given the separate limit on sighash\nbytes and the improvements from libsecp256k1 I think 40k sigops should\nbe fine, but I'm happy to be corrected.\n\nFor a regular transaction, of say 380 bytes with 2 sigops and hashing\nabout 800 bytes, that uses up about 291 units of the limit, meaning\nthat if a block was full of transactions of that form, the limit would\nbe 6872 tx or 2.6MB per block (along with 13.7k sigops and ~5.5MB hashed\nfor signatures).  Those weightings could probably be improved by doing\nsome detailed analysis and measurements, but I think they're pretty\nreasonable for round figures.\n\nThe main advantage is that it would prevent blocks being cheaply filled\nup due to hitting one of the secondary limits but only paying for the\ncontribution to the primary limit (presumably block size), which avoids\ndenial of service spam attacks.\n\nI think having the limit take UTXO increase (or decrease) into effect\nwould be helpful too; but I don't have a specific suggestion. If it's\njust a matter of making the limit stronger (eg adding \"0.25*max(0,change\nin UTXO bytes)\" to the formula on the left, but not changing the limit on\nthe right), that would be a soft-forking change that could be introduced\nlater, and maybe that's fine.\n\nIf there was time to actually iterate on this proposal, rather than an\napparent aim to get it out the door in the next month or two, I think it\nwould be good to also design it so that the parameters of the weighted\nsum could be adjusted by a soft-fork in future rather than requiring a\nhard fork every time a limit's reached, or a weighting can be relaxed.\nBut I don't think that's feasible to design within a few weeks, so I\nthink it's off the table given the activation goal.\n\nCheers,\naj"
            },
            {
                "author": "Steven Pine",
                "date": "2016-02-07T22:25:40",
                "message_text_only": "I agree that it seems like a safe assumption that adoption would be faster,\nwhether it is \"very safe\" and \"significantly faster\", whether it will be 6\ntimes faster, all of those assumptions seems significantly less safe and\nrobust to me.\n\nThe nature of the bitcoin protocol, that it is a decentralized census based\nprotocol involving currency, suggests to me that roll out schedules ought\nto be conservative with a minimum of assumptions. In light of the most\nrecent protocol upgrade, 6 months for this hard fork seems to me to be the\nmost conservative time frame with the fewest assumptions.\n\nAs for why it needs to be so fast, ie what are the dangers of it being as\nslow as 6 months?\n\nGavin writes:\n\n\"I strongly disagree with the statement that there is no cost to a longer\ngrace period. There is broad agreement that a capacity increase is needed\nNOW.\"\n\n~~\n\"Broad agreement\", that really seems to be another assumption, the fact\nthat the debate has been as long and acrimonious as it has been suggests\nthat there isn't broad agreement. Also, resorting to \"SHOUTING\" doesn't win\nany favors when it comes to engaging in reasonable discussion om the\ntechnical merits of a proposal.\n\n\n\nOn Sun, Feb 7, 2016 at 5:04 PM, Corey Haddad <corey3 at gmail.com> wrote:\n\n> We don't have any evidence of how fast nodes will upgrade when faced with\n> an impending hard fork, but it seems like a very safe assumption that the\n> upgrade pace will be significantly faster.  The hard fork case it is:\n> \"upgrade or be kicked off the network\".  In the previous cases it has been,\n> \"here's the latest and greatest, give it a go!\".  Also, there will be\n> alerts sent out warning people of the situation, prompting them to take\n> action.\n>\n> It is unclear if this will translate into more or less than 6x the\n> adoption speed of previous instances, but the idea that it would be faster\n> is solid.  28 days is aggressive, but again, it is only 28 days from when\n> the fork triggers.  Compatible software is already available for anyone who\n> wants to prepare.\n>\n> It is also of significance that this proposed fork, and this debate, has\n> been going on for many, many months.  If someone proposed a forking concept\n> today, wrote the BIP tomorrow, deployed it next week, miners adopted it\n> instantly, and 28 days later it was the flag day, those 28 days would be in\n> a different context.  There is no surprise here.\n>\n> On Sun, Feb 7, 2016 at 1:33 PM, Steven Pine via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Is it me or did Gavin ignore Yifu's direct questions? In case you missed\n>> it Gavin --\n>>\n>> ~\n>> \"We can look at the adoption of the last major Bitcoin core release to\n>> guess how long it might take people to upgrade. 0.11.0 was released on 12\n>> July, 2015. Twenty eight days later, about 38% of full nodes were\n>> running that release. Three months later, about 50% of the network was\n>> running that release, and six months later about 66% of the network was\n>> running some flavor of 0.11.\"\n>>\n>> On what grounds do you think it is reasonable to assume that this update\n>> will roll out 6x faster than previous data suggested, as oppose to your own\n>> observation of 66% adoption in 6 month. or do you believe 38% node\n>> upgrade-coverage (in 28 days ) on the network for a hard fork is good\n>> enough?\n>>\n>> There are no harm in choosing a longer grace period but picking one short\n>> as 28 days you risk on alienating the nodes who do not upgrade with the\n>> aggressive upgrade timeline you proposed.\n>> ~~\n>>\n>> When Gavin writes \"Responding to \"28 days is not long enough\" :\n>>\n>> I keep seeing this claim made with no evidence to back it up.  As I said,\n>> I surveyed several of the biggest infrastructure providers and the btcd\n>> lead developer and they all agree \"28 days is plenty of time.\"\n>>\n>> For individuals... why would it take somebody longer than 28 days to\n>> either download and restart their bitcoind, or to patch and then re-run\n>> (the patch can be a one-line change MAX_BLOCK_SIZE from 1000000 to\n>> 2000000)?\"\n>>\n>> ~~\n>>\n>> Isn't Yifu's comment, evidence, the very best sort of evidence, it isn't\n>> propositional a priori logic, but empirical evidence that. As for why\n>> people take longer, who knows, we simply know from passed experience that\n>> it in fact does take longer.\n>>\n>> It's extremely frustrating to read Gavin's comments, it's hard to believe\n>> he is engaging in earnest discussion.\n>>\n>> On Sun, Feb 7, 2016 at 4:01 PM, Luke Dashjr via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> On Sunday, February 07, 2016 2:16:02 PM Gavin Andresen wrote:\n>>> > On Sat, Feb 6, 2016 at 3:46 PM, Luke Dashjr via bitcoin-dev <\n>>> > bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> > > On Saturday, February 06, 2016 5:25:21 PM Tom Zander via bitcoin-dev\n>>> wrote:\n>>> > > > If you have a node that is \"old\" your node will stop getting new\n>>> > > > blocks. The node will essentially just say \"x-hours behind\" with\n>>> \"x\"\n>>> > > > getting larger every hour. Funds don't get confirmed. etc.\n>>> > >\n>>> > > Until someone decides to attack you. Then you'll get 6, 10, maybe\n>>> more\n>>> > > blocks confirming a large 10000 BTC payment. If you're just a normal\n>>> end\n>>> > > user (or perhaps an automated system), you'll figure that payment is\n>>> good\n>>> > > and irreversibly hand over the title to the house.\n>>> >\n>>> > There will be approximately zero percentage of hash power left on the\n>>> > weaker branch of the fork, based on past soft-fork adoption by miners\n>>> (they\n>>> > upgrade VERY quickly from 75% to over 95%).\n>>>\n>>> I'm assuming there are literally ZERO miners left on the weaker branch.\n>>> The attacker in this scenario simply rents hashing for a few days in\n>>> advance\n>>> to build his fake chain, then broadcasts the blocks to the unsuspecting\n>>> merchant at ~10 block intervals so it looks like everything is working\n>>> normal\n>>> again. There are lots of mining rental services out there, and miners\n>>> quite\n>>> often do not care to avoid selling hashrate to the highest bidder\n>>> regardless\n>>> of what they're mining. 10 blocks worth costs a little more than 250 BTC\n>>> -\n>>> soon, that will be 125 BTC.\n>>>\n>>> Luke\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>\n>>\n>>\n>> --\n>> Steven Pine\n>> (510) 517-7075\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>\n\n\n-- \nSteven Pine\n(510) 517-7075\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160207/4f03a475/attachment-0001.html>"
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-02-09T16:54:14",
                "message_text_only": "On Tue, Feb 9, 2016 at 8:59 AM, Yifu Guo <yifu at coinapex.com> wrote:\n\n>\n> There are 406 nodes total that falls under the un-maintained category,\n> which is below 10% of the network.\n> Luke also have some data here that shows similar results.\n> http://luke.dashjr.org/programs/bitcoin/files/charts/versions.txt\n>\n\nI love seeing data!  I was considering 0.10 nodes as 'unmaintained' because\nit has been a long time since the 0.11 release.\n\n\n>\n> > The network could shrink by 60% and it would still have plenty of open\n>> connection slots\n>\n>\n> I'm afraid we have to agree to disagree if you think dropping support for\n> 60% of the nodes on the network when rolling out an upgrade is the sane\n> default.\n>\n\nThat is my estimate of the worst-case-- not 'sane default.'\n\nMy point is that even if the number of nodes shrank by 60%, we would not\nsee any issues (SPV nodes would still have no problem finding a full node\nto connect to, full nodes would not have any problem connecting to each\nother, and we would not be significantly more vulnerable to Sybil attacks\nor \"governments get together and try to ban running a full node\" attacks).\n\n\n\n>\n>> > People are committing to spinning up thousands of supports-2mb-nodes\n>> during the grace period.\n>\n>\n> thousands of nodes?! where did you get this figure? who are these people?\n> *Please* elaborate.\n>\n\nThere are over a thousand people subscribed to the Classic slack channel,\nmany of whom have privately told me they are willing and able to run an\nextra node or three (or a hundred-and-eleven) once there is a final release.\n\nI'm not going to name names, because\n a) these were private communications, and\n b) risk of death threats, extortion, doxxing, DoS attacks, etc.  Those\nrisks aren't theoretical, they are very real.\n\nTo be clear: I will discourage and publicly condemn anybody who runs\n'pseudo nodes' or plans to spin up lots of nodes to try to influence the\ndebate. The only legitimate reason to run extra nodes is to fill in a\npossible gap in total node count that might be caused by old, unmaintained\nnodes that stop serving blocks because the rest of the network has upgraded.\n\n\n> We could wait a year and pick up maybe 10 or 20% more.\n>\n>\n> I don't understand this statement at all, please explicate.\n>\n\nThe adoption curve for a new major release is exponential: lots of adoption\nin the first 30 days or so, then it rapidly tapers off.  Given that\npeople's nodes will be alerting them that they must upgrade, and given that\nevery source of Bitcoin news will probably be covering the miner adoption\nvote like it was a presidential election, I expect the adoption curve for\nthe 2mb bump to be steeper than we've ever seen.  So my best guess is\n70-80% of nodes will upgrade within 30 days of the miner voting hitting 50%\nof blocks and triggering the automatic 'version obsolete; upgrade required'\nwarning.\n\nWait a year, and my guess is you might reach another 10-20% (80 to\n90-something percent).\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160209/b0a9c9b8/attachment.html>"
            },
            {
                "author": "David Vorick",
                "date": "2016-02-10T06:14:13",
                "message_text_only": ">  I love seeing data!  I was considering 0.10 nodes as 'unmaintained'\nbecause it has been a long time since the 0.11 release.\n\nhttps://packages.gentoo.org/packages/net-p2p/bitcoin-qt\n\nThe Gentoo package manager still has 0.10.2 as the most recent stable\nversion. Getting a later version of the software on a gentoo setup requires\nexplicitly telling the package manger to grab a later version. I don't know\nwhat percent of nodes are Gentoo 0.10.2, but I think it's evidence that\n0.10 should not be considered 'unmaintained'. People who update their\nsoftware regularly will be running 0.10 on Gentoo.\n\n> many of whom have privately told me they are willing and able to run an\nextra node or three (or a hundred-and-eleven) once there is a final release.\n\nI'm not clear on the utility of more nodes. Perhaps there is significant\nconcern about SPV nodes getting enough bandwidth or the network struggling\nfrom the load? Generally though, I believe that when people talk about the\ndeteriorating full node count they are talking about a reduction in\ndecentralization. Full nodes are a weak indicator of how likely something\nlike a change in consensus rules is to get caught, or how many people you\nwould need to open communication with / extort in order to be able to force\nrules upon the network. Having a person spin up multiple nodes doesn't\naddress either of those concerns, which in my understanding is what most\npeople care about. My personal concern is with the percentage of the\neconomy that is dependent on trusting the full nodes they are connected to,\nand the overall integrity of that trust. (IE how likely is it that my SPV\nnode is going to lie to me about whether or not I've received a payment).\n\nI will also point out that lots of people will promise things when they are\nseeking political change. I don't know what percentage of promised nodes\nwould actually be spun up, but I'm guessing that it's going to be\nsignificantly less than 100%. I have similar fears for companies that claim\nthey have tested their infrastructure for supporting 2MB blocks. Talk is\ncheap.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160210/2aed4f42/attachment.html>"
            },
            {
                "author": "Patrick Shirkey",
                "date": "2016-02-10T06:36:05",
                "message_text_only": "On Wed, February 10, 2016 5:14 pm, David Vorick via bitcoin-dev wrote:\n>>  I love seeing data!  I was considering 0.10 nodes as 'unmaintained'\n> because it has been a long time since the 0.11 release.\n>\n> https://packages.gentoo.org/packages/net-p2p/bitcoin-qt\n>\n> The Gentoo package manager still has 0.10.2 as the most recent stable\n> version. Getting a later version of the software on a gentoo setup\n> requires\n> explicitly telling the package manger to grab a later version. I don't\n> know\n> what percent of nodes are Gentoo 0.10.2, but I think it's evidence that\n> 0.10 should not be considered 'unmaintained'. People who update their\n> software regularly will be running 0.10 on Gentoo.\n>\n>> many of whom have privately told me they are willing and able to run an\n> extra node or three (or a hundred-and-eleven) once there is a final\n> release.\n>\n> I'm not clear on the utility of more nodes. Perhaps there is significant\n> concern about SPV nodes getting enough bandwidth or the network struggling\n> from the load? Generally though, I believe that when people talk about the\n> deteriorating full node count they are talking about a reduction in\n> decentralization. Full nodes are a weak indicator of how likely something\n> like a change in consensus rules is to get caught, or how many people you\n> would need to open communication with / extort in order to be able to\n> force\n> rules upon the network. Having a person spin up multiple nodes doesn't\n> address either of those concerns, which in my understanding is what most\n> people care about. My personal concern is with the percentage of the\n> economy that is dependent on trusting the full nodes they are connected\n> to,\n> and the overall integrity of that trust. (IE how likely is it that my SPV\n> node is going to lie to me about whether or not I've received a payment).\n>\n> I will also point out that lots of people will promise things when they\n> are\n> seeking political change. I don't know what percentage of promised nodes\n> would actually be spun up, but I'm guessing that it's going to be\n> significantly less than 100%. I have similar fears for companies that\n> claim\n> they have tested their infrastructure for supporting 2MB blocks. Talk is\n> cheap.\n>\n\nThis is a good point. The rollout procedure needs to be fully tested\n*before* any changes are enforced.\n\nHas anyone provided conclusive results on system load demands with an\nincrease to 2MB? Extrapolating further to higher blocksizes will also be\nuseful to get an idea of the scope of the problem. If the system does jump\nto 2MB it is unlikely that will be the ultimate limit so 4, 8, 16 etc...\nshould also be quantified.\n\nWe already hear of the high system load (energy/cost) requirements* for\nnodes under the current blocksize which appears to have created a barrier\nto entry for a lot of miners. If increasing to 2MB makes it even more\nexpensive in terms of hardware and energy costs to run a node that will\nconsolidate the nodes into the control of a few wealthy parties who can\nafford to run the most powerful hardware. Conversely if the increase helps\nthe system and individual nodes run more efficiently then that would be a\nbig incentive for miners to upgrade.\n\n\n* (these reports might be false/wrong/propaganda)\n\n\n\n--\nPatrick Shirkey\nBoost Hardware Ltd"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-02-10T12:58:01",
                "message_text_only": "On Wed, Feb 10, 2016 at 6:14 AM, David Vorick via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I'm not clear on the utility of more nodes. Perhaps there is significant\n> concern about SPV nodes getting enough bandwidth or the network struggling\n> from the load?\n>\n\nIt is unfortunate that when pruning is activated, the NODE_NETWORK bit is\ncleared.  This means that supporting SPV clients means running full nodes\nwithout pruning.  OTOH, a pruning node could support SPV clients that sync\nmore often than once every few days, especially if it stores a few GB of\nblock data.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160210/ab949fb1/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP proposal: Increase block size limit to 2 megabytes",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Patrick Shirkey",
                "Anthony Towns",
                "Trevin Hofmann",
                "Tier Nolan",
                "Jonathan Toomim",
                "Corey Haddad",
                "David Vorick",
                "Adam Back",
                "Samson Mow",
                "Peter Todd",
                "Jorge Tim\u00f3n",
                "Btc Drak",
                "David Thomson",
                "Yifu Guo",
                "Steven Pine",
                "Patrick Strateman",
                "Chris Priest",
                "Tom Zander",
                "Luke Dashjr",
                "Jannes Faber",
                "Gavin Andresen",
                "jl2012 at xbt.hk",
                "Alex Morcos"
            ],
            "messages_count": 42,
            "total_messages_chars_count": 131596
        }
    },
    {
        "title": "[bitcoin-dev] Gavin: A Response to Your Forking BIP",
        "thread_messages": [
            {
                "author": "Bryan Bishop",
                "date": "2016-02-06T17:34:02",
                "message_text_only": "On Sat, Feb 6, 2016 at 9:37 AM, Gavin Andresen wrote:\n\n> Responding to \"28 days is not long enough\" :\n>\n\nGavin,\n\nThank you for the emails. Bitcoin Core has been working with the Bitcoin\necosystem on developing and now testing a new capacity increasing feature\ncalled segregated witness (segwit). Segregated witness is a voluntary,\nmutually backwards-compatible capacity upgrade for the Bitcoin system.\nMany, many hundreds of millions of dollars of Bitcoin value have flowed\nthrough soft-forked upgrades to the Bitcoin system, representing upgrades\nfrom across the entire ecosystem and the entire Bitcoin network, over\nmultiple years including BIP 12, BIP 16, BIP 17, BIP 30, BIP 34, BIP 42,\nBIP 62, BIP 65, BIP 66, etc. So that\u2019s the context from which I have been\napproaching your hard-fork ideas for the past year.\n\nBenefits of segregated witness\nhttps://bitcoincore.org/en/2016/01/26/segwit-benefits/\n\nEcosystem buy-in and support for segregated witness continues to grow:\nhttps://bitcoincore.org/en/segwit_adoption/\n\nThere is also a segwit testnet which everyone is encouraged to investigate\nand develop against-- companies love them some testing, after all:\nhttps://bitcoincore.org/en/2016/01/21/launch_segwit_testnet/\n\nA plan for Bitcoin Core capacity increases was put forward and can be found\nhere:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-December/011865.html\nhttps://bitcoincore.org/en/2015/12/23/capacity-increases-faq/\n\nWith respect, the question should not be \"is 28 days enough time for anyone\nto roll out new binaries\", it's instead a question of \"how long does it\ntake someone to agree to upgrade to these new incompatible rules\".\n\nIf Bitcoin users don't want to upgrade to incompatible rules right now, why\nwould they agree when 10% of the hashpower is setting some flag in a block?\nWhy would they change their minds at 20%? 90%? I am not saying here that\nhard-forks should never be attempted, although we need as an ecosystem to\ndevelop much more rigor and a more data-driven approach, and while that\nmight be hard to define exactly, as was once said by regulators, \u201cI know it\nwhen I see it\u201d. Companies in the financial sector give a year or more\nbefore deprecating old APIs even after the new one has been up and running\nconcurrently and well proven, and would not shut off their old one in order\nto get adoption of the new one.\n\nAre we OK with some percent of the Bitcoin ecosystem not agreeing with the\nexisting rules? What would that mean? Are you willing to maintain two\nseparate networks, and if not, would you please document this in your BIP?\nDeprecation timeline and emergency procedures?? Should we include\nrationalizations for not using a new address prefix? In the event of a\npartial hard-fork where two chains exist, wouldn't it make more sense to\nhave the new chain use a new address prefix? Using a new address prefix\ncould conceivably serve to minimize the impact of what almost looks like an\nintentionally constructed y2k-bug type of event for the ecosystem.\n\nI suspect that soft-fork upgrades have in the past tolerated _less_ rigor\naround planning because voluntary soft-fork upgrading does not\nintentionally break backwards-compatibility. Over time I expect that even\nsoft-fork upgrades will have much more planning, but again, it seems that\nincompatible changes require much more rigor. If the sky is truly falling\naccording to your pronouncements, then there are millions if not billions\nof dollars of value on the line which are being risked from lack of\nengineering rigor without a well documented procedure, and suggesting that\nwe agree on that \"next time\" is not going to create the results that meet\nyour or anyone else\u2019s desire. Much more, we need to signal to the broader\necosystem and world that we are serious, mature and ready for business.\n\nRegarding your request for definitions about soft-hard forks and\ngeneralized soft-forks, you can find some definitions over here:\nhttp://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-December/012173.html\nhttp://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-December/012172.html\n\nAbout hard-forks you may be interested in reading and internalizing,\nhttps://github.com/bitcoin/bips/blob/master/bip-0099.mediawiki\n\nThis was an interesting exploration of soft-forks and hard-forks:\nhttps://petertodd.org/2016/soft-forks-are-safer-than-hard-forks\n\nOn the security of soft-forks\nhttp://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-December/012014.html\n\nAre soft-forks misnamed?\nhttp://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-September/011266.html\n\n- Bryan\nhttp://heybryan.org/\n1 512 203 0507\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160206/3017ee42/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Gavin: A Response to Your Forking BIP",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Bryan Bishop"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4820
        }
    },
    {
        "title": "[bitcoin-dev] Pre-BIP Growth Soft-hardfork",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2016-02-07T09:52:31",
                "message_text_only": "Here's a draft BIP I wrote almost a year ago. I'm going to look into revising \nand completing it soon, and would welcome any suggestions for doing so.\n\nThis hardfork BIP aims to accomplish a few important things:\n- Finally deploying proper merge-mining as Satoshi suggested before he left.\n- Expanding the nonce space miners can scan in-chip, avoiding expensive\n  calculations on the host controller as blocks get larger.\n- Provide a way to safely deploy hardforks without risking leaving old nodes\n  vulnerable to attack.\n\nhttps://github.com/luke-jr/bips/blob/bip-mmhf/bip-mmhf.mediawiki\n\nLuke"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-02-07T13:18:52",
                "message_text_only": "This is a specific implementation of the \"nuclear option\" soft fork (or\n\"firm-fork\").\n\nThe problem with any hard-fork (like) change is that there is an incentive\nto add as much as possible and then the process gets bogged down.\n\nSince the POW is based on the header 1, you could make header 3\nexpandable.  This would allow adding new fields later.\n\nThis could be used for other block commitments.  This would save having to\nmake the merkle tree a sum tree immediately.  At a later time, the sum-tree\nroot could be added. (I think you also need to commit the path to the first\nentry in the sum-tree, in order to get compact proofs).  There could be\nseparate sum-trees for each counter (sigops, block size, tx count, sighash?)\n\nHaving a dedicated hard fork and soft fork counter is a good idea.  There\nshould also be a field for parallel soft forks.  Incrementing the soft fork\ncounter could set the bitfield soft forks back to zero.  Ideally, each soft\nfork would have a yes and no bit.  If > 50% vote No, then it fails adoption.\n\nThe effect of this change is that nodes react to hard forks by stalling the\nchain.  The hard fork counter means that the new rules could be that nodes\nshould do that going forward for all new hard forks.\n\n- soft fork (bitfield or count) => warn user that a soft fork has happened\n- hard fork count increase => warn user that update is required and don't\nprocess any more blocks\n\nThis means that header3 should be kept as simple as possible.\n\n   - 2 bytes: hardfork block version\n   - 2 bytes: softfork block version\n   - 4 bytes: softfork bitfields\n   - 32 byte: hash(header4)\n\nHeader4 and everything else in the block could be changed when a hard fork\nhappens.  The merged mining rules and header3 would be fixed.\n\nI think confirmation counts should be based on even numbers, i.e. 3800 of\n4000, but that is an aesthetic issue and doesn't really matter.\n\nA section on recommendations for the different client types would be useful.\n\nIf 1000 of the last 2000 blocks are votes for a hard fork, then warn the\nuser that a hard fork is being considered\n\nIf 4000 of the last 4463 blocks are votes for a hard fork, then warn the\nuser that a hard fork is likely to occur within the next few days\n\nIf a hard fork happens:\n\n- shut down transaction processing\n- inform the user that a hard fork has happened\n\nNon-upgraded miners could blacklist the hard forking block and keep mining\non their own chain.  Their chain would never reach the threshold to trigger\nthe hard fork.  It would max out at 4323 blocks of the last 4463.\n\nIronically, if users did this, it would defeat some of the benefit of using\nthe hard fork field.\n\nUsers should definitely be given the option of accepting or rejecting the\nhard fork.  Otherwise, miners can hard-fork at will, which isn't desirable.\n<https://www.avast.com/sig-email> This email has been sent from a\nvirus-free computer protected by Avast.\nwww.avast.com <https://www.avast.com/sig-email>\n<#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160207/4f6fd01b/attachment.html>"
            },
            {
                "author": "jl2012 at xbt.hk",
                "date": "2016-02-07T17:53:53",
                "message_text_only": "This looks very interesting. The first time implementing it might be more\npainful but that will make subsequent hardforks a lot easier.\n\nDo you think it's good to include the median timestamp of the past 11 blocks\nafter the block height in coinbase? That would make it easier to use it as\nactivation threshold of consensus rule changes.\n\nFor the witness commitment, it will also be treated as a merge mined\ncommitment?\n\nIt is also good to emphasize that it is the responsibility of miners, not\ndevs, to ensure that the hardfork is accepted by the supermajority of the\neconomy.\n\n\n-----Original Message-----\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org\n[mailto:bitcoin-dev-bounces at lists.linuxfoundation.org] On Behalf Of Luke\nDashjr via bitcoin-dev\nSent: Sunday, 7 February, 2016 17:53\nTo: Bitcoin Dev <bitcoin-dev at lists.linuxfoundation.org>\nSubject: [bitcoin-dev] Pre-BIP Growth Soft-hardfork\n\nHere's a draft BIP I wrote almost a year ago. I'm going to look into\nrevising and completing it soon, and would welcome any suggestions for doing\nso.\n\nThis hardfork BIP aims to accomplish a few important things:\n- Finally deploying proper merge-mining as Satoshi suggested before he left.\n- Expanding the nonce space miners can scan in-chip, avoiding expensive\n  calculations on the host controller as blocks get larger.\n- Provide a way to safely deploy hardforks without risking leaving old nodes\n  vulnerable to attack.\n\nhttps://github.com/luke-jr/bips/blob/bip-mmhf/bip-mmhf.mediawiki\n\nLuke\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            }
        ],
        "thread_summary": {
            "title": "Pre-BIP Growth Soft-hardfork",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "jl2012 at xbt.hk",
                "Tier Nolan",
                "Luke Dashjr"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 5443
        }
    },
    {
        "title": "[bitcoin-dev] Making a 2MB blocksize hardfork safer",
        "thread_messages": [
            {
                "author": "Anthony Towns",
                "date": "2016-02-07T15:25:40",
                "message_text_only": "Hello world,\n\nThe core roadmap calls for having patches at the ready for\nimplementing hardforking blocksize increases [0]. However, at least\nto my understanding, is that the deployment of segregated witness has\na significant impact on what a hardforking blocksize increase should\nlook like -- with segwit, the increase in the blocksize may have to\nbe traded off against decreasing the witness discount; without segwit,\nalternative changes might need to be made to provide some of the other\nbenefits of segwit without segwit (in particular, additional limits to\nprevent hashing massive amounts of data when checking sigs or to reduce\nworst-case UTXO growth).\n\nI don't personally have any real concerns that segregated witness will be\ntoo complicated to implement and release by April, and given how quickly\nCLTV rolled out, my guess is it will be usable prior to the block reward\nhalving. I'm also not terribly worried about fees rising significantly,\nor that there will be a \"fee event\" [1] or \"market disruption\" -- fees\ndon't seem to be rising even with the spam attacks we've seen, and all\nthe problems with transactions not confirming that I've been able to see\nso far seem to be due either to people trying to do free transactions,\nfees not being calculated based on transaction size, or not checking\nfor dust outputs, all of which are things that can be dealt with by\nindividual wallets. [2]\n\nBut those are guesses and opinions, and I think it makes sense to have\na backup plan if everything goes horribly wrong -- someone discovers\na problem with segwit that requires major rearchitecturing to fix and\nwon't happen until 2017, eg.\n\nTo me, Gavin's BIP [3] and the Bitcoin Classic approach don't seem like\na good backup plan; but I don't see why they couldn't be *made* into a\ngood plan. In particular, if segwit turns out too hard to actually deploy\nsafely, I think Gavin's patchset -- an increase to ~2MB, coupled with\naccurate counting and limiting of sighash bytes, and pretty much nothing\nelse -- is about the right set of *technical* things to do as a backup plan.\n\nSo the following are my suggestions for making Gavin's BIP workable\nprocedurally/politically as a backup plan. But that said, I don't know\nif this is even remotely acceptable politically; I'm just following\nbitcoin as a hobby and I don't have any backchannel contacts in mining\nor bitcoin startups or anything.\n\n1. Level of supermajority\n=========================\n\nFirst, it was reported that the Chinese miners came up with a 2MB\nblocksize plan in late January [4], with the following summarised plan:\n\n]  If:\n]    1: Blocks are full\n]    2: Core proposal is <2MB\n]    3: Classic proposal have not gained consensus\n]  Then:\n]    Under the 90% hash power condition, switch from a 1MB limit to a\n]    2MB limit to deal with the block size problem.\n\nThe summary also expresses concerns about segwit deployment; that it\nmakes significant changes, and that any issues with reliability may have\nmajor impact. Those seem like valid concerns to me; though if they are\nnot addressed directly, then I expect miners will simply not enable the\nsegwit soft-fork until they are.\n\nI think the only change to make this match Gavin's code for Bitcoin\nClassic then is to require 90% hashpower support rather than 75%. I think\nthat can be easily done by a soft-forking change where miners reject any\nblock with a Classic vote (ie a version of 0x10000000) if the block height\nis cleanly divisible by 6 [5]. As this is a soft-forking change, and one\nthat's only relevant until either Classic activates or the 2MB hardfork\nattempt is permanently aborted on 2018-01-01, it seems like it could\neasily be deployed prior to either segwit or Classic voting beginning.\n\n2. Activation Time\n==================\n\nThe activation time for Gavin's BIP is very short -- 1000 blocks for\nvoting could be as short as 6 days, followed by 28 days grace period.\nI haven't seen any indication that there is an immediate crisis, or\nthat there will be one in the next few months; and the fact that the\nBIP does not expire for two years seems to indicate it's not a short\nterm issue. Allowing three to six months before attempting to activate\nthe hardfork seems like it would still provide plenty of opportunity to\naddress the issue quickly, and would also mean there was time to see if\nthe segwit rollout worked as planned.\n\nThat also could be enforced by a soft-fork: eg having a rule that until\nthe median time past is 2015-05-27, any block voting for the 2MB hardfork\nwill be rejected, would ensure the hard fork was not activated until\n1st of July. A slightly more complicated rule, eg only rejecting the\nblocks if the last three decimal digits of its height was 500 or greater,\nwould allow support to be measured in the leadup to possible activation,\nwithout any risk of activation happening early.\n\n3. Upgrade encouragement\n========================\n\nI think there's three ways the 2MB hardfork could go: (a) not ever being\nactivated at all, similar to XT; (b) being activated with effective\nconsensus, where everyone switches to the hard-fork, whether happily\nor not; or (c) being activated, but with the old chain being actively\nmined and used on an ongoing, long-term basis.\n\nIf the 2MB blocksize hardfork is deployed as a fallback after segwit\ndeployment has failed, or determined to be much more complicated than\ncurrently believed, then it seems like (c) would be a pretty undesirable\noutcome.\n\nThe only way I can see of avoiding/discouraging (c) is to have the new\nhardfork be merge-minable with the existing chain, and having every\nblock in the new chain also commit to a merged-mined empty block on the\nold chain, so that as long as the new chain has more hashpower than the\nold chain, the longest valid old chain will have no outgoing payments\nafter the hardfork activates. (That requirement could probably be safely\ndropped after some number of blocks, perhaps 25000 or 6 months?)\n\nAlternatively, if the old blockchain has 10% or less hashpower remaining\n(due to the 90% activation above), then the new chain has 9x the\nhashpower. Perhaps a rule such that every 8th block in the hard-forked\nchain must include an OP_RETURN in the coinbase that provides a valid,\nempty block for the old chain. With a 90%/10% split, this would ensure\nthat the empty chain had more work than any other attempt at extending\nit. However at the next difficulty change for the old chain (decreasing\nby a factor of 4, presumably), I think they'd have to be mined every\nsecond block rather than every 8th, and by the second difficulty change,\nwould need to be mined every block; otherwise I think 10% of hashpower\ncould catch up in chain-work. (Again, the requirement could probably be\ndropped entirely after 6 months, or similar)\n\nI believe this latter approach could be implemented as a soft-fork on\ntop of Gavin's BIP / Bitcoin Classic, provided activation was at 90% [7].\n\nIn this scenario, it would be possible for miners to simply sell empty\nblocks on the old chain once they find them, so finding an empty block\nfor the old chain could plausibly be independent of finding the new\nblock for the new chain.\n\n\nConclusion\n==========\n\nI think those three changes, which all should be implementable as\nsoft-forks compatible with Gavin's current code (the first two only\nrelevant prior to activation; the last only relevant after activation),\nwould mitigate what I see as the biggest risks of classic:\n\n - low-consensus/controversial activation\n - short preparation time, and resulting uncertainty and pressure\n - non-trivial chance of old chain remaining active after activation\n - miners' and core's plans being ignored [8]\n\nAnd I think that would make this BIP (for me) a workable backup plan in\nthe event segwit doesn't work as planned. And for a multi-billion dollar\nservice, backup plans seem like a worthwhile thing to have, even if it's\nhighly unlikely it will actually get used.\n\nHowever, these are all ideas where the benefits are basically \"political\"\nrather than \"technical\", and I have no idea if the above *actually* makes\nsense... And I guess trying to establish that is probably off-topic for\nbitcoin-dev anyway? Anyway, as a consequence I've no idea if a write up\nas a BIP and/or patches to implement any/all of the above as soft-forks\nfor classic/core that could be activated would be interesting for anyone,\nand beyond posting about the ideas here, no idea how to find out. It\nseemed like an interesting thought experiment to me, anyway. Apologies\nin advance if it turns out I'm alone in that :)\n\nCheers,\naj\n\n[0] \"Finally--at some point the capacity increases from the above may not\n    be enough.  Delivery on [various improvements], and other advances\n    in technology will reduce the risk and therefore controversy around\n    moderate block size increase proposals (such as 2/4/8 rescaled to\n    respect segwit's increase). Bitcoin will be able to move forward\n    with these increases when improvements and understanding render\n    their risks widely acceptable relative to the risks of not deploying\n    them. In Bitcoin Core we should keep patches ready to implement them\n    as the need and the will arises, ...\"\n\n    https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-December/011865.html\n    via https://bitcoincore.org/en/2015/12/23/capacity-increases-faq/\n\n[1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-December/011973.html\n\n[2] I do think that, without segwit or a blocksize increase, there will be\n    a discontinuity for venture funded bitcoin companies, because the\n    transactions per second metric will become capped by the end of\n    2016. I've argued that at:\n\n    http://lists.linuxfoundation.org/pipermail/bitcoin-discuss/2016-January/000042.html\n\n    but I have not seen anyone from the a VC-backed bitcoin company\n    actually confirm that's a concern, so perhaps it isn't something\n    worth worrying about even there.\n\n[3] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-February/012358.html\n    https://github.com/gavinandresen/bips/blob/bump2mb/bip-bump2mb.mediawiki\n\n[4] https://blog.bitmex.com/translation-of-chinese-miner-consensus-meeting/\n\n[5] In that case, if 90% of miners by hashpower actually support the BIP,\n    that would imply that 1/6th of blocks artificially don't vote for\n    it, but 90% of the remaining 5/6th of blocks do, and 90% of 5/6th\n    gives the 75% activation threshold specified in Gavin's BIP.\n\n[6] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-December/012069.html\n\n[7] With activation at 75%, you'd need to dedicate 1/3rd of hashpower\n    to mining empty old blocks to stay in the lead, which would then mean\n    the hashpower for the new proof-of-work would only be half what it\n    had previously been, and you'd end up with blocks taking 20 minutes\n    on the new chain, and at least every second block including an empty\n    block on the old chain. You could probably fix this by having the\n    difficulty artificially halve when the hardfork activates though.\n\n[8] Miners agree to 90% majority, code comes out with 75% majority. In\n    December, core announces plans to deploy segwit with 1.6x capacity\n    increase by April; Classic appears in January planning to do a hard\n    fork with 2x capacity increase in/around March."
            }
        ],
        "thread_summary": {
            "title": "Making a 2MB blocksize hardfork safer",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Anthony Towns"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 11292
        }
    },
    {
        "title": "[bitcoin-dev] On Hardforks in the Context of SegWit",
        "thread_messages": [
            {
                "author": "Matt Corallo",
                "date": "2016-02-08T19:26:48",
                "message_text_only": "Hi all,\n\nI believe we, today, have a unique opportunity to begin to close the\nbook on the short-term scaling debate.\n\nFirst a little background. The scaling debate that has been gripping the\nBitcoin community for the past half year has taken an interesting turn\nin 2016. Until recently, there have been two distinct camps - one\nproposing a significant change to the consensus-enforced block size\nlimit to allow for more on-blockchain transactions and the other\nopposing such a change, suggesting instead that scaling be obtained by\nadding more flexible systems on top of the blockchain. At this point,\nhowever, the entire Bitcoin community seems to have unified around a\nsingle vision - roughly 2MB of transactions per block, whether via\nSegregated Witness or via a hard fork, is something that can be both\ntechnically supported and which adds more headroom before second-layer\ntechnologies must be in place. Additionally, it seems that the vast\nmajority of the community agrees that segregated witness should be\nimplemented in the near future and that hard forks will be a necessity\nat some point, and I don't believe it should be controversial that, as\nwe have never done a hard fork before, gaining experience by working\ntowards a hard fork now is a good idea.\n\nWith the apparent agreement in the community, it is incredibly\ndisheartening that there is still so much strife, creating a toxic\nenvironment in which developers are not able to work, companies are\nworried about their future ability to easily move Bitcoins, and\ninvestors are losing confidence. The way I see it, this broad\nunification of visions across all parts of the community places the\nburden of selecting the most technically-sound way to achieve that\nvision squarely on the development community.\n\nSadly, the strife is furthered by the huge risks involved in a hard fork\nin the presence of strife, creating a toxic cycle which prevents a safe\nhard fork. While there has been talk of doing an \"emergency hardfork\" as\nan option, and while I do believe this is possible, it is not something\nthat will be easy, especially for something as controversial as rising\nfees. Given that we have never done a hard fork before, being very\ncareful and deliberate in doing so is critical, and the technical\ncommunity working together to plan for all of the things that might go\nwrong is key to not destroying significant value.\n\nAs such, I'd like to ask everyone involved to take this opportunity to\n\"reset\", forgive past aggressions, and return the technical debates to\ntechnical forums (ie here, IRC, etc).\n\nAs what a hard fork should look like in the context of segwit has never\n(!) been discussed in any serious sense, I'd like to kick off such a\ndiscussion with a (somewhat) specific proposal.\n\nFirst some design notes:\n* I think a key design feature should be taking this opportunity to add\nsmall increases in decentralization pressure, where possible.\n* Due to the several non-linear validation time issues in transaction\nvalidation which are fixed by SegWit's signature-hashing changes, I\nstrongly believe any hard fork proposal which changes the block size\nshould rely on SegWit's existence.\n* As with any hard fork proposal, its easy to end up pulling in hundreds\nof small fixes for any number of protocol annoyances. In order to avoid\ndoing this, we should try hard to stick with a few simple changes.\n\nHere is a proposed outline (to activate only after SegWit and with the\ncurrently-proposed version of SegWit):\n\n1) The segregated witness discount is changed from 75% to 50%. The block\nsize limit (ie transactions + witness/2) is set to 1.5MB. This gives a\nmaximum block size of 3MB and a \"network-upgraded\" block size of roughly\n2.1MB. This still significantly discounts script data which is kept out\nof the UTXO set, while keeping the maximum-sized block limited.\n\n2) In order to prevent significant blowups in the cost to validate\npessimistic blocks, we must place additional limits on the size of many\nnon-segwit transactions. scriptPubKeys are now limited to 100 bytes in\nsize and may not contain OP_CODESEPARATOR, scriptSigs must be push-only\n(ie no non-push opcodes), and transactions are only allowed to contain\nup to 20 non-segwit inputs. Together these limits limit\ntotal-bytes-hashed in block validation to under 200MB without any\npossibility of making existing outputs unspendable and without adding\nadditional per-block limits which make transaction-selection-for-mining\ndifficult in the face of attacks or non-standard transactions. Though\n200MB of hashing (roughly 2 seconds of hash-time on my high-end\nworkstation) is pretty strongly centralizing, limiting transactions to\nfewer than 20 inputs seems arbitrarily low.\n\nAlong similar lines, we may wish to switch MAX_BLOCK_SIGOPS from\n1-per-50-bytes across the entire block to a per-transaction limit which\nis slightly looser (though not too much looser - even with libsecp256k1\n1-per-50-bytes represents 2 seconds of single-threaded validation in\njust sigops on my high-end workstation).\n\n3) Move SegWit's generic commitments from an OP_RETURN output to a\nsecond branch in the merkle tree. Depending on the timeline this may be\nsomething to skip - once there is tooling for dealing with the extra\nOP_RETURN output as a generic commitment, the small efficiency gain for\napplications checking the witness of only one transaction or checking a\nnon-segwit commitment may not be worth it.\n\n4) Instead of requiring the first four bytes of the previous block hash\nfield be 0s, we allow them to contain any value. This allows Bitcoin\nmining hardware to reduce the required logic, making it easier to\nproduce competitive hardware [1].\n\nI'll deliberately leave discussion of activation method out of this\nproposal. Both jl2012 and Luke-Jr recently begun some discussions about\nmethods for activation on this list, and I'd love to see those continue.\nIf folks think a hard fork should go ahead without SPV clients having a\nsay, we could table #4, or activate #4 a year or two after 1-3 activate.\n\n\n[1] Simpler here may not be entirely true. There is potential for\noptimization if you brute force the SHA256 midstate, but if nothing\nelse, this will prevent there being a strong incentive to use the\nversion field as nonce space. This may need more investigation, as we\nmay wish to just set the minimum difficulty higher so that we can add\nmore than 4 nonce-bytes.\n\n\n\n\nObviously we cannot reasonably move forward with a hard fork as long as\nthe contention in the community continues. Still, I'm confident\ncontinuing to work towards SegWit as a 2MB-ish soft-fork in the short\nterm with some plans on what a hard fork should look like if we can form\nbroad consensus can go a long way to resolving much of the contention\nwe've seen."
            },
            {
                "author": "jl2012 at xbt.hk",
                "date": "2016-02-08T20:37:36",
                "message_text_only": "Thanks for this proposal. Just some quick response:\n\n1. The segwit hardfork (BIP HF) could be deployed with BIP141 (segwit\nsoftfork). BIP141 doesn't need grace period. BIP HF will have around 1 year\nof grace period.\n\n2. Threshold is 95%. Using 4 versoin bits: a) BIP 141; b) BIP HF; c) BIP 141\nif BIP HF has already got 95%; d) BIP HF if BIP141 has already got 95%.\nVoting a and c (or b and d) at the same time is invalid. BIP 141 is\nactivated if a>95% or (a+c>95% and b+d>95%). BIP HF is activated if b>95% or\n(a+c>95% and b+d>95%).\n\n3. Fix time warp attack: this may break some SPV implementation\n\n4. Limiting non-segwit inputs may make some existing signed tx invalid. My\nproposal is: a) count the number of non-segwit sigop in a tx, including\nthose in unexecuted branch (sigop); b) measure the tx size without scripgSig\n(size); c) a new rule is SUM(sigop*size) < some_value . This allows\ncalculation without actually running the script.\n\n\n-----Original Message-----\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org\n[mailto:bitcoin-dev-bounces at lists.linuxfoundation.org] On Behalf Of Matt\nCorallo via bitcoin-dev\nSent: Tuesday, 9 February, 2016 03:27\nTo: Bitcoin Dev <bitcoin-dev at lists.linuxfoundation.org>\nSubject: [bitcoin-dev] On Hardforks in the Context of SegWit\n\nHi all,\n\nI believe we, today, have a unique opportunity to begin to close the book on\nthe short-term scaling debate.\n\nFirst a little background. The scaling debate that has been gripping the\nBitcoin community for the past half year has taken an interesting turn in\n2016. Until recently, there have been two distinct camps - one proposing a\nsignificant change to the consensus-enforced block size limit to allow for\nmore on-blockchain transactions and the other opposing such a change,\nsuggesting instead that scaling be obtained by adding more flexible systems\non top of the blockchain. At this point, however, the entire Bitcoin\ncommunity seems to have unified around a single vision - roughly 2MB of\ntransactions per block, whether via Segregated Witness or via a hard fork,\nis something that can be both technically supported and which adds more\nheadroom before second-layer technologies must be in place. Additionally, it\nseems that the vast majority of the community agrees that segregated witness\nshould be implemented in the near future and that hard forks will be a\nnecessity at some point, and I don't believe it should be controversial\nthat, as we have never done a hard fork before, gaining experience by\nworking towards a hard fork now is a good idea.\n\nWith the apparent agreement in the community, it is incredibly disheartening\nthat there is still so much strife, creating a toxic environment in which\ndevelopers are not able to work, companies are worried about their future\nability to easily move Bitcoins, and investors are losing confidence. The\nway I see it, this broad unification of visions across all parts of the\ncommunity places the burden of selecting the most technically-sound way to\nachieve that vision squarely on the development community.\n\nSadly, the strife is furthered by the huge risks involved in a hard fork in\nthe presence of strife, creating a toxic cycle which prevents a safe hard\nfork. While there has been talk of doing an \"emergency hardfork\" as an\noption, and while I do believe this is possible, it is not something that\nwill be easy, especially for something as controversial as rising fees.\nGiven that we have never done a hard fork before, being very careful and\ndeliberate in doing so is critical, and the technical community working\ntogether to plan for all of the things that might go wrong is key to not\ndestroying significant value.\n\nAs such, I'd like to ask everyone involved to take this opportunity to\n\"reset\", forgive past aggressions, and return the technical debates to\ntechnical forums (ie here, IRC, etc).\n\nAs what a hard fork should look like in the context of segwit has never\n(!) been discussed in any serious sense, I'd like to kick off such a\ndiscussion with a (somewhat) specific proposal.\n\nFirst some design notes:\n* I think a key design feature should be taking this opportunity to add\nsmall increases in decentralization pressure, where possible.\n* Due to the several non-linear validation time issues in transaction\nvalidation which are fixed by SegWit's signature-hashing changes, I strongly\nbelieve any hard fork proposal which changes the block size should rely on\nSegWit's existence.\n* As with any hard fork proposal, its easy to end up pulling in hundreds of\nsmall fixes for any number of protocol annoyances. In order to avoid doing\nthis, we should try hard to stick with a few simple changes.\n\nHere is a proposed outline (to activate only after SegWit and with the\ncurrently-proposed version of SegWit):\n\n1) The segregated witness discount is changed from 75% to 50%. The block\nsize limit (ie transactions + witness/2) is set to 1.5MB. This gives a\nmaximum block size of 3MB and a \"network-upgraded\" block size of roughly\n2.1MB. This still significantly discounts script data which is kept out of\nthe UTXO set, while keeping the maximum-sized block limited.\n\n2) In order to prevent significant blowups in the cost to validate\npessimistic blocks, we must place additional limits on the size of many\nnon-segwit transactions. scriptPubKeys are now limited to 100 bytes in size\nand may not contain OP_CODESEPARATOR, scriptSigs must be push-only (ie no\nnon-push opcodes), and transactions are only allowed to contain up to 20\nnon-segwit inputs. Together these limits limit total-bytes-hashed in block\nvalidation to under 200MB without any possibility of making existing outputs\nunspendable and without adding additional per-block limits which make\ntransaction-selection-for-mining difficult in the face of attacks or\nnon-standard transactions. Though 200MB of hashing (roughly 2 seconds of\nhash-time on my high-end\nworkstation) is pretty strongly centralizing, limiting transactions to fewer\nthan 20 inputs seems arbitrarily low.\n\nAlong similar lines, we may wish to switch MAX_BLOCK_SIGOPS from\n1-per-50-bytes across the entire block to a per-transaction limit which is\nslightly looser (though not too much looser - even with libsecp256k1\n1-per-50-bytes represents 2 seconds of single-threaded validation in just\nsigops on my high-end workstation).\n\n3) Move SegWit's generic commitments from an OP_RETURN output to a second\nbranch in the merkle tree. Depending on the timeline this may be something\nto skip - once there is tooling for dealing with the extra OP_RETURN output\nas a generic commitment, the small efficiency gain for applications checking\nthe witness of only one transaction or checking a non-segwit commitment may\nnot be worth it.\n\n4) Instead of requiring the first four bytes of the previous block hash\nfield be 0s, we allow them to contain any value. This allows Bitcoin mining\nhardware to reduce the required logic, making it easier to produce\ncompetitive hardware [1].\n\nI'll deliberately leave discussion of activation method out of this\nproposal. Both jl2012 and Luke-Jr recently begun some discussions about\nmethods for activation on this list, and I'd love to see those continue.\nIf folks think a hard fork should go ahead without SPV clients having a say,\nwe could table #4, or activate #4 a year or two after 1-3 activate.\n\n\n[1] Simpler here may not be entirely true. There is potential for\noptimization if you brute force the SHA256 midstate, but if nothing else,\nthis will prevent there being a strong incentive to use the version field as\nnonce space. This may need more investigation, as we may wish to just set\nthe minimum difficulty higher so that we can add more than 4 nonce-bytes.\n\n\n\n\nObviously we cannot reasonably move forward with a hard fork as long as the\ncontention in the community continues. Still, I'm confident continuing to\nwork towards SegWit as a 2MB-ish soft-fork in the short term with some plans\non what a hard fork should look like if we can form broad consensus can go a\nlong way to resolving much of the contention we've seen.\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Tao Effect",
                "date": "2016-02-08T22:24:01",
                "message_text_only": "Hard forks should always come in response to some major crisis that all participants can agree is an actual crisis, as per the excellent rational here:\n\nhttp://bitledger.info/why-a-hard-fork-should-be-fought-and-its-not-evil-to-discuss/\n\nAnd here:\n\nhttp://bitledger.info/hard-fork-risks-and-why-95-should-be-the-standard/\n\nAlso, if you\u2019re going to do a hard fork, you\u2019d better make the most of it as hard forks must be a *rare* world-is-ending-if-we-don\u2019t-do-it thing (otherwise Bitcoin cannot be considered decentralized in any sense of the word).\n\nSo for any sort of hard fork, be sure to address the real threats and challenges that are facing Bitcoin today:\n\n1. Mining centralization.\n2. Privacy.\n\nBest regards,\nGreg Slepak\n\n> On Feb 8, 2016, at 12:37 PM, jl2012--- via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Thanks for this proposal. Just some quick response:\n> \n> 1. The segwit hardfork (BIP HF) could be deployed with BIP141 (segwit\n> softfork). BIP141 doesn't need grace period. BIP HF will have around 1 year\n> of grace period.\n> \n> 2. Threshold is 95%. Using 4 versoin bits: a) BIP 141; b) BIP HF; c) BIP 141\n> if BIP HF has already got 95%; d) BIP HF if BIP141 has already got 95%.\n> Voting a and c (or b and d) at the same time is invalid. BIP 141 is\n> activated if a>95% or (a+c>95% and b+d>95%). BIP HF is activated if b>95% or\n> (a+c>95% and b+d>95%).\n> \n> 3. Fix time warp attack: this may break some SPV implementation\n> \n> 4. Limiting non-segwit inputs may make some existing signed tx invalid. My\n> proposal is: a) count the number of non-segwit sigop in a tx, including\n> those in unexecuted branch (sigop); b) measure the tx size without scripgSig\n> (size); c) a new rule is SUM(sigop*size) < some_value . This allows\n> calculation without actually running the script.\n> \n> \n> -----Original Message-----\n> From: bitcoin-dev-bounces at lists.linuxfoundation.org\n> [mailto:bitcoin-dev-bounces at lists.linuxfoundation.org] On Behalf Of Matt\n> Corallo via bitcoin-dev\n> Sent: Tuesday, 9 February, 2016 03:27\n> To: Bitcoin Dev <bitcoin-dev at lists.linuxfoundation.org>\n> Subject: [bitcoin-dev] On Hardforks in the Context of SegWit\n> \n> Hi all,\n> \n> I believe we, today, have a unique opportunity to begin to close the book on\n> the short-term scaling debate.\n> \n> First a little background. The scaling debate that has been gripping the\n> Bitcoin community for the past half year has taken an interesting turn in\n> 2016. Until recently, there have been two distinct camps - one proposing a\n> significant change to the consensus-enforced block size limit to allow for\n> more on-blockchain transactions and the other opposing such a change,\n> suggesting instead that scaling be obtained by adding more flexible systems\n> on top of the blockchain. At this point, however, the entire Bitcoin\n> community seems to have unified around a single vision - roughly 2MB of\n> transactions per block, whether via Segregated Witness or via a hard fork,\n> is something that can be both technically supported and which adds more\n> headroom before second-layer technologies must be in place. Additionally, it\n> seems that the vast majority of the community agrees that segregated witness\n> should be implemented in the near future and that hard forks will be a\n> necessity at some point, and I don't believe it should be controversial\n> that, as we have never done a hard fork before, gaining experience by\n> working towards a hard fork now is a good idea.\n> \n> With the apparent agreement in the community, it is incredibly disheartening\n> that there is still so much strife, creating a toxic environment in which\n> developers are not able to work, companies are worried about their future\n> ability to easily move Bitcoins, and investors are losing confidence. The\n> way I see it, this broad unification of visions across all parts of the\n> community places the burden of selecting the most technically-sound way to\n> achieve that vision squarely on the development community.\n> \n> Sadly, the strife is furthered by the huge risks involved in a hard fork in\n> the presence of strife, creating a toxic cycle which prevents a safe hard\n> fork. While there has been talk of doing an \"emergency hardfork\" as an\n> option, and while I do believe this is possible, it is not something that\n> will be easy, especially for something as controversial as rising fees.\n> Given that we have never done a hard fork before, being very careful and\n> deliberate in doing so is critical, and the technical community working\n> together to plan for all of the things that might go wrong is key to not\n> destroying significant value.\n> \n> As such, I'd like to ask everyone involved to take this opportunity to\n> \"reset\", forgive past aggressions, and return the technical debates to\n> technical forums (ie here, IRC, etc).\n> \n> As what a hard fork should look like in the context of segwit has never\n> (!) been discussed in any serious sense, I'd like to kick off such a\n> discussion with a (somewhat) specific proposal.\n> \n> First some design notes:\n> * I think a key design feature should be taking this opportunity to add\n> small increases in decentralization pressure, where possible.\n> * Due to the several non-linear validation time issues in transaction\n> validation which are fixed by SegWit's signature-hashing changes, I strongly\n> believe any hard fork proposal which changes the block size should rely on\n> SegWit's existence.\n> * As with any hard fork proposal, its easy to end up pulling in hundreds of\n> small fixes for any number of protocol annoyances. In order to avoid doing\n> this, we should try hard to stick with a few simple changes.\n> \n> Here is a proposed outline (to activate only after SegWit and with the\n> currently-proposed version of SegWit):\n> \n> 1) The segregated witness discount is changed from 75% to 50%. The block\n> size limit (ie transactions + witness/2) is set to 1.5MB. This gives a\n> maximum block size of 3MB and a \"network-upgraded\" block size of roughly\n> 2.1MB. This still significantly discounts script data which is kept out of\n> the UTXO set, while keeping the maximum-sized block limited.\n> \n> 2) In order to prevent significant blowups in the cost to validate\n> pessimistic blocks, we must place additional limits on the size of many\n> non-segwit transactions. scriptPubKeys are now limited to 100 bytes in size\n> and may not contain OP_CODESEPARATOR, scriptSigs must be push-only (ie no\n> non-push opcodes), and transactions are only allowed to contain up to 20\n> non-segwit inputs. Together these limits limit total-bytes-hashed in block\n> validation to under 200MB without any possibility of making existing outputs\n> unspendable and without adding additional per-block limits which make\n> transaction-selection-for-mining difficult in the face of attacks or\n> non-standard transactions. Though 200MB of hashing (roughly 2 seconds of\n> hash-time on my high-end\n> workstation) is pretty strongly centralizing, limiting transactions to fewer\n> than 20 inputs seems arbitrarily low.\n> \n> Along similar lines, we may wish to switch MAX_BLOCK_SIGOPS from\n> 1-per-50-bytes across the entire block to a per-transaction limit which is\n> slightly looser (though not too much looser - even with libsecp256k1\n> 1-per-50-bytes represents 2 seconds of single-threaded validation in just\n> sigops on my high-end workstation).\n> \n> 3) Move SegWit's generic commitments from an OP_RETURN output to a second\n> branch in the merkle tree. Depending on the timeline this may be something\n> to skip - once there is tooling for dealing with the extra OP_RETURN output\n> as a generic commitment, the small efficiency gain for applications checking\n> the witness of only one transaction or checking a non-segwit commitment may\n> not be worth it.\n> \n> 4) Instead of requiring the first four bytes of the previous block hash\n> field be 0s, we allow them to contain any value. This allows Bitcoin mining\n> hardware to reduce the required logic, making it easier to produce\n> competitive hardware [1].\n> \n> I'll deliberately leave discussion of activation method out of this\n> proposal. Both jl2012 and Luke-Jr recently begun some discussions about\n> methods for activation on this list, and I'd love to see those continue.\n> If folks think a hard fork should go ahead without SPV clients having a say,\n> we could table #4, or activate #4 a year or two after 1-3 activate.\n> \n> \n> [1] Simpler here may not be entirely true. There is potential for\n> optimization if you brute force the SHA256 midstate, but if nothing else,\n> this will prevent there being a strong incentive to use the version field as\n> nonce space. This may need more investigation, as we may wish to just set\n> the minimum difficulty higher so that we can add more than 4 nonce-bytes.\n> \n> \n> \n> \n> Obviously we cannot reasonably move forward with a hard fork as long as the\n> contention in the community continues. Still, I'm confident continuing to\n> work towards SegWit as a 2MB-ish soft-fork in the short term with some plans\n> on what a hard fork should look like if we can form broad consensus can go a\n> long way to resolving much of the contention we've seen.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 841 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160208/3e8cf754/attachment.sig>"
            },
            {
                "author": "Simon Liu",
                "date": "2016-02-08T22:36:47",
                "message_text_only": "> 1) The segregated witness discount is changed from 75% to 50%. The block\n> size limit (ie transactions + witness/2) is set to 1.5MB. This gives a\n> maximum block size of 3MB and a \"network-upgraded\" block size of roughly\n> 2.1MB. This still significantly discounts script data which is kept out\n> of the UTXO set, while keeping the maximum-sized block limited.\n\nWhat is the rationale for offering a discount?\n\nIs there an economic basis for setting the original discount at 75%\ninstead of some other number?\n\nIf it's okay to arbitrarily reduce the discount by 1/3, what are the\nactual boundary limits:  50% - 75% ?  40% - 80% ?\n\n--Simon"
            },
            {
                "author": "Peter Todd",
                "date": "2016-02-08T22:54:36",
                "message_text_only": "On Mon, Feb 08, 2016 at 02:36:47PM -0800, Simon Liu via bitcoin-dev wrote:\n> > 1) The segregated witness discount is changed from 75% to 50%. The block\n> > size limit (ie transactions + witness/2) is set to 1.5MB. This gives a\n> > maximum block size of 3MB and a \"network-upgraded\" block size of roughly\n> > 2.1MB. This still significantly discounts script data which is kept out\n> > of the UTXO set, while keeping the maximum-sized block limited.\n> \n> What is the rationale for offering a discount?\n\nUTXO set space is significantly more expensive for the network as all\nfull nodes must keep the entire UTXO set.\n\nAdditionally, transaction input/output data in general is argued by some\nto be less expensive than signatures, as you have more options with\nregard to skipping validation of signatures (e.g. how Bitcoin Core skips\nvalidation of signatures prior to checkpoints).\n\n> Is there an economic basis for setting the original discount at 75%\n> instead of some other number?\n> \n> If it's okay to arbitrarily reduce the discount by 1/3, what are the\n> actual boundary limits:  50% - 75% ?  40% - 80% ?\n\nSo, something to keep in mind in general in all these discussions is\nthat at best engineering always has \"magic numbers\" involved, the\nquestion is where?\n\nFor example, I've proposed that we use a 99% miner vote threshold for\nhard-forks (remember that the threshold can always be soft-forked down\nlater). The rational there is, among other things, you want to ensure\nthat the non-adopting miners' chain is useless for transacting due to\nextremely long block times, as well as we want it to receive\nconfirmations slowly to prevent fraud. (of course, there's also the\nnon-technical argument that we want to adopt hard-forks with extremely\nwide adoption) At 99% the 1% remaining chain will have a block interval\nof about 16 hours.\n\nNow, I've been asked \"why 99%? isn't that a magic number?\"\n\nI could have instead said my goal was to increase the block interval to\n24 hours, in which case I'd have used a 99.3% threshold. But again,\nisn't 24 hours a magic number? Why not 25hrs?\n\nThe answer is 24 hours *is* a magic number - but trying to eliminate\nthat with yet another meta level of engineering analysis becomes a game\nof diminishing returns.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n000000000000000001ae7ca66e52359d67c407a739fde42b83ecc746d3ab735d\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160208/ea039ad9/attachment-0001.sig>"
            },
            {
                "author": "Anthony Towns",
                "date": "2016-02-09T09:00:02",
                "message_text_only": "On Mon, Feb 08, 2016 at 07:26:48PM +0000, Matt Corallo via bitcoin-dev wrote:\n> As what a hard fork should look like in the context of segwit has never\n> (!) been discussed in any serious sense, I'd like to kick off such a\n> discussion with a (somewhat) specific proposal.\n\n> Here is a proposed outline (to activate only after SegWit and with the\n> currently-proposed version of SegWit):\n\nIs this intended to be activated soon (this year?) or a while away\n(2017, 2018?)?\n\n> 1) The segregated witness discount is changed from 75% to 50%. The block\n> size limit (ie transactions + witness/2) is set to 1.5MB. This gives a\n> maximum block size of 3MB and a \"network-upgraded\" block size of roughly\n> 2.1MB. This still significantly discounts script data which is kept out\n> of the UTXO set, while keeping the maximum-sized block limited.\n\nThis would mean the limits go from:\n\n   pre-segwit  segwit pkh  segwit 2/2 msig  worst case\n   1MB         -           -                1MB\n   1MB         1.7MB       2MB              4MB\n   1.5MB       2.1MB       2.2MB            3MB\n\nThat seems like a fairly small gain (20% for pubkeyhash, which would\nlast for about 3 months if you're growth rate means doubling every 9\nmonths), so this probably makes the most sense as a \"quick cleanup\"\nchange, that also safely demonstrates how easy/difficult doing a hard\nfork is in practice?\n\nOn the other hand, if segwit wallet deployment takes longer than\nhoped, the 50% increase for pre-segwit transactions might be a useful\nrelease-valve.\n\nDoing a \"2x\" hardfork with the same reduction to a 50% segwit discount\nwould (I think) look like:\n\n   pre-segwit  segwit pkh  segwit 2/2 msig  worst case\n   1MB         -           -                1MB\n   1MB         1.7MB       2MB              4MB\n   2MB         2.8MB       2.9MB            4MB\n\nwhich seems somewhat more appealing, without making the worst-case any\nworse; but I guess there's concern about the relay networking scaling\nabove around 2MB per block, at least prior to IBLT/weak-blocks/whatever?\n\n> 2) In order to prevent significant blowups in the cost to validate\n> [...] and transactions are only allowed to contain\n> up to 20 non-segwit inputs. [...]\n\nThis could potentially make old, signed, but time-locked transactions\ninvalid. Is that a good idea?\n\n> Along similar lines, we may wish to switch MAX_BLOCK_SIGOPS from\n> 1-per-50-bytes across the entire block to a per-transaction limit which\n> is slightly looser (though not too much looser - even with libsecp256k1\n> 1-per-50-bytes represents 2 seconds of single-threaded validation in\n> just sigops on my high-end workstation).\n\nI think turning MAX_BLOCK_SIGOPS and MAX_BLOCK_SIZE into a combined\nlimit would be a good addition, ie:\n\n  #define MAX_BLOCK_SIZE       1500000\n  #define MAX_BLOCK_DATA_SIZE  3000000\n  #define MAX_BLOCK_SIGOPS     50000\n\n  #define MAX_COST             3000000\n  #define SIGOP_COST           (MAX_COST / MAX_BLOCK_SIGOPS)\n  #define BLOCK_COST           (MAX_COST / MAX_BLOCK_SIZE)\n  #define DATA_COST            (MAX_COST / MAX_BLOCK_DATA_SIZE)\n\n  if (utxo_data * BLOCK_COST + bytes * DATA_COST + sigops * SIGOP_COST\n       > MAX_COST)\n  {\n      block_is_invalid();\n  }\n\nThough I think you'd need to bump up the worst-case limits somewhat to\nmake that work cleanly.\n\n> 4) Instead of requiring the first four bytes of the previous block hash\n> field be 0s, we allow them to contain any value. This allows Bitcoin\n> mining hardware to reduce the required logic, making it easier to\n> produce competitive hardware [1].\n> [1] Simpler here may not be entirely true. There is potential for\n> optimization if you brute force the SHA256 midstate, but if nothing\n> else, this will prevent there being a strong incentive to use the\n> version field as nonce space. This may need more investigation, as we\n> may wish to just set the minimum difficulty higher so that we can add\n> more than 4 nonce-bytes.\n\nCould you just use leading non-zero bytes of the prevhash as additional\nnonce?\n\nSo to work out the actual prev hash, set leading bytes to zero until\nyou hit a zero. Conversely, to add nonce info to a hash, if there are\nN leading zero bytes, fill up the first N-1 (or less) of them with\nnon-zero values.\n\nThat would give a little more than 255**(N-1) possible values\n((255**N-1)/254) to be exact). That would actually scale automatically\nwith difficulty, and seems easy enough to make use of in an ASIC?\n\nCheers,\naj"
            },
            {
                "author": "Matt Corallo",
                "date": "2016-02-09T21:54:01",
                "message_text_only": "Thanks for keeping on-topic, replying to the proposal, and being civil!\n\nReplies inline.\n\nOn 02/09/16 09:00, Anthony Towns via bitcoin-dev wrote:\n> On Mon, Feb 08, 2016 at 07:26:48PM +0000, Matt Corallo via bitcoin-dev wrote:\n>> As what a hard fork should look like in the context of segwit has never\n>> (!) been discussed in any serious sense, I'd like to kick off such a\n>> discussion with a (somewhat) specific proposal.\n> \n>> Here is a proposed outline (to activate only after SegWit and with the\n>> currently-proposed version of SegWit):\n> \n> Is this intended to be activated soon (this year?) or a while away\n> (2017, 2018?)?\n\nIt's intended to activate when we have clear and broad consensus around\na hard proposal across the community.\n\n>> 1) The segregated witness discount is changed from 75% to 50%. The block\n>> size limit (ie transactions + witness/2) is set to 1.5MB. This gives a\n>> maximum block size of 3MB and a \"network-upgraded\" block size of roughly\n>> 2.1MB. This still significantly discounts script data which is kept out\n>> of the UTXO set, while keeping the maximum-sized block limited.\n> \n> This would mean the limits go from:\n> \n>    pre-segwit  segwit pkh  segwit 2/2 msig  worst case\n>    1MB         -           -                1MB\n>    1MB         1.7MB       2MB              4MB\n>    1.5MB       2.1MB       2.2MB            3MB\n> \n> That seems like a fairly small gain (20% for pubkeyhash, which would\n> last for about 3 months if you're growth rate means doubling every 9\n> months), so this probably makes the most sense as a \"quick cleanup\"\n> change, that also safely demonstrates how easy/difficult doing a hard\n> fork is in practice?\n>\n> On the other hand, if segwit wallet deployment takes longer than\n> hoped, the 50% increase for pre-segwit transactions might be a useful\n> release-valve.\n> \n> Doing a \"2x\" hardfork with the same reduction to a 50% segwit discount\n> would (I think) look like:\n> \n>    pre-segwit  segwit pkh  segwit 2/2 msig  worst case\n>    1MB         -           -                1MB\n>    1MB         1.7MB       2MB              4MB\n>    2MB         2.8MB       2.9MB            4MB\n> \n> which seems somewhat more appealing, without making the worst-case any\n> worse; but I guess there's concern about the relay networking scaling\n> above around 2MB per block, at least prior to IBLT/weak-blocks/whatever?\n\n\nThe goal isnt really to get a \"gain\" here...its mostly to decrease the\nworst-case (4MB is pretty crazy) and keep the total size in-line with\nwhat the network could handle. Getting 1MB blocks through the network in\nunder a second is already incredibly difficult...2MB is pretty scary and\nwill take lots of work...3MB is over the bound of \"yea, we can pretty\nfor sure get that to work pretty well\".\n\n\n>> 2) In order to prevent significant blowups in the cost to validate\n>> [...] and transactions are only allowed to contain\n>> up to 20 non-segwit inputs. [...]\n> \n> This could potentially make old, signed, but time-locked transactions\n> invalid. Is that a good idea?\n\n\nHmmmmmm...you make a valid point. I was trying to avoid breaking old\ntransactions, but didnt think too much about time-locked ones.\nHmmmmmm...we could apply the limits to txn that dont have at least one\n\"newer than the fork input\", but I'm not sure I like that either.\n\n\n>> Along similar lines, we may wish to switch MAX_BLOCK_SIGOPS from\n>> 1-per-50-bytes across the entire block to a per-transaction limit which\n>> is slightly looser (though not too much looser - even with libsecp256k1\n>> 1-per-50-bytes represents 2 seconds of single-threaded validation in\n>> just sigops on my high-end workstation).\n> \n> I think turning MAX_BLOCK_SIGOPS and MAX_BLOCK_SIZE into a combined\n> limit would be a good addition, ie:\n> \n>   #define MAX_BLOCK_SIZE       1500000\n>   #define MAX_BLOCK_DATA_SIZE  3000000\n>   #define MAX_BLOCK_SIGOPS     50000\n> \n>   #define MAX_COST             3000000\n>   #define SIGOP_COST           (MAX_COST / MAX_BLOCK_SIGOPS)\n>   #define BLOCK_COST           (MAX_COST / MAX_BLOCK_SIZE)\n>   #define DATA_COST            (MAX_COST / MAX_BLOCK_DATA_SIZE)\n> \n>   if (utxo_data * BLOCK_COST + bytes * DATA_COST + sigops * SIGOP_COST\n>        > MAX_COST)\n>   {\n>       block_is_invalid();\n>   }\n> \n> Though I think you'd need to bump up the worst-case limits somewhat to\n> make that work cleanly.\n\n\nThere is a clear goal here of NOT using block-based limits and switching\nto transaction-based limits. By switching to transaction-based limits we\navoid nasty issues with mining code either getting complicated or\nenforcing too-strict limits on individual transactions.\n\n\n>> 4) Instead of requiring the first four bytes of the previous block hash\n>> field be 0s, we allow them to contain any value. This allows Bitcoin\n>> mining hardware to reduce the required logic, making it easier to\n>> produce competitive hardware [1].\n>> [1] Simpler here may not be entirely true. There is potential for\n>> optimization if you brute force the SHA256 midstate, but if nothing\n>> else, this will prevent there being a strong incentive to use the\n>> version field as nonce space. This may need more investigation, as we\n>> may wish to just set the minimum difficulty higher so that we can add\n>> more than 4 nonce-bytes.\n> \n> Could you just use leading non-zero bytes of the prevhash as additional\n> nonce?\n> \n> So to work out the actual prev hash, set leading bytes to zero until\n> you hit a zero. Conversely, to add nonce info to a hash, if there are\n> N leading zero bytes, fill up the first N-1 (or less) of them with\n> non-zero values.\n> \n> That would give a little more than 255**(N-1) possible values\n> ((255**N-1)/254) to be exact). That would actually scale automatically\n> with difficulty, and seems easy enough to make use of in an ASIC?"
            },
            {
                "author": "Matt Corallo",
                "date": "2016-02-09T22:00:44",
                "message_text_only": "Oops, forgot to reply to your last point.\n\nIndeed, we could push for more place by just always having one 0-byte,\nbut I'm not sure the added complexity helps anything? ASICs can never be\ndesigned which use more extra-nonce-space than what they can reasonably\nassume will always be available, so we might as well just set the\nmaximum number of bytes and let ASIC designers know exactly what they\nhave available. Currently blocks start with at least 8 0-bytes. We could\njust say minimum difficulty is now 6 0-bytes (2**16x harder) and reserve\nthose? Anyway, someone needs to take a closer look at the midstate\noptimization stuff to see what is reasonable required.\n\nMatt\n\n\n>>> 4) Instead of requiring the first four bytes of the previous block hash\n>>> field be 0s, we allow them to contain any value. This allows Bitcoin\n>>> mining hardware to reduce the required logic, making it easier to\n>>> produce competitive hardware [1].\n>>> [1] Simpler here may not be entirely true. There is potential for\n>>> optimization if you brute force the SHA256 midstate, but if nothing\n>>> else, this will prevent there being a strong incentive to use the\n>>> version field as nonce space. This may need more investigation, as we\n>>> may wish to just set the minimum difficulty higher so that we can add\n>>> more than 4 nonce-bytes.\n>>\n>> Could you just use leading non-zero bytes of the prevhash as additional\n>> nonce?\n>>\n>> So to work out the actual prev hash, set leading bytes to zero until\n>> you hit a zero. Conversely, to add nonce info to a hash, if there are\n>> N leading zero bytes, fill up the first N-1 (or less) of them with\n>> non-zero values.\n>>\n>> That would give a little more than 255**(N-1) possible values\n>> ((255**N-1)/254) to be exact). That would actually scale automatically\n>> with difficulty, and seems easy enough to make use of in an ASIC?"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-09T22:10:43",
                "message_text_only": "On Tuesday, February 09, 2016 10:00:44 PM Matt Corallo via bitcoin-dev wrote:\n> Indeed, we could push for more place by just always having one 0-byte,\n> but I'm not sure the added complexity helps anything? ASICs can never be\n> designed which use more extra-nonce-space than what they can reasonably\n> assume will always be available, so we might as well just set the\n> maximum number of bytes and let ASIC designers know exactly what they\n> have available. Currently blocks start with at least 8 0-bytes. We could\n> just say minimum difficulty is now 6 0-bytes (2**16x harder) and reserve\n> those?\n\nThe extranonce rolling doesn't necessarily need to happen in the ASIC itself. \nWith the current extranonce-in-gentx, an old RasPi 1 can only handle creating \nwork for up to 5 Gh/s with a 500k gentx.\n\nFurthermore, there is a direct correlation between ASIC speeds and difficulty, \nso increasing the extranonce space dynamically makes a lot of sense.\n\nI don't see any reason *not* to increase the minimum difficulty at the same \ntime, though.\n\nLuke"
            },
            {
                "author": "Matt Corallo",
                "date": "2016-02-09T22:39:34",
                "message_text_only": "On 02/09/16 22:10, Luke Dashjr wrote:\n> On Tuesday, February 09, 2016 10:00:44 PM Matt Corallo via bitcoin-dev wrote:\n>> Indeed, we could push for more place by just always having one 0-byte,\n>> but I'm not sure the added complexity helps anything? ASICs can never be\n>> designed which use more extra-nonce-space than what they can reasonably\n>> assume will always be available, so we might as well just set the\n>> maximum number of bytes and let ASIC designers know exactly what they\n>> have available. Currently blocks start with at least 8 0-bytes. We could\n>> just say minimum difficulty is now 6 0-bytes (2**16x harder) and reserve\n>> those?\n> \n> The extranonce rolling doesn't necessarily need to happen in the ASIC itself. \n> With the current extranonce-in-gentx, an old RasPi 1 can only handle creating \n> work for up to 5 Gh/s with a 500k gentx.\n\n\nDid you read the footnote on my original email? There is some potential\nfor optimization if you can brute-force the midstate, which today\nrequires using the nVersion space as nonce. In order to fix this we need\nto add nonce space in the first compression function, so this is an\nideal place. Even ignoring that reducing complexity of mining control\nstuff is really nice. If we could go back to just providing block\nheaders to miners instead of having to provide the entire\ntransaction-hash-list we could move a ton of complexity back into\nBitcoin Core from mining setups, which have historically been pretty\npoorly-reviewed codebases.\n\n\n> Furthermore, there is a direct correlation between ASIC speeds and difficulty, \n> so increasing the extranonce space dynamically makes a lot of sense.\n> \n> I don't see any reason *not* to increase the minimum difficulty at the same \n> time, though.\n\nMeh, my point was less that its a really bad idea and more that it adds\ncompexity that I dont see much need for."
            },
            {
                "author": "Anthony Towns",
                "date": "2016-02-10T05:16:56",
                "message_text_only": "On Tue, Feb 09, 2016 at 10:00:44PM +0000, Matt Corallo wrote:\n> Indeed, we could push for more place by just always having one 0-byte,\n> but I'm not sure the added complexity helps anything? ASICs can never be\n> designed which use more extra-nonce-space than what they can reasonably\n> assume will always be available,\n\nI was thinking ASICs could be passed a mask of which bytes they could\nuse for nonce; in which case the variable-ness can just be handled prior\nto passing the work to the ASIC.\n\nBut on second thoughts, the block already specifies the target difficulty,\nso maybe that could be used to indicate which bytes of the previous hash\nmust be zero? You have to be a bit careful to deal with the possibility\nthat you just did a maximum difficulty increase compared to the previous\nblock (in which case there may be fewer bits in the previous hash that\nare zero), but that's just a factor of 4, so:\n\n    #define RETARGET_THRESHOLD ((1ul<<24) / 4)\n    y = 32 - bits[0];\n    if (bits[1]*65536 + bits[2]*256 + bits[3] >= RETARGET_THRESHOLD)\n        y -= 1;\n    memset(prevhash, 0x00, y); // clear \"first\" y bytes of prevhash\n\nshould work correctly/safely, and give you 8 bytes of additional nonce\nto play with at current difficulty (or 3 bytes at minimum difficulty),\nand scale as difficulty increases. No need to worry about avoiding zeroes\nthat way either.\n\n\n\nAs far as midstate optimisations go, rearranging the block to be:\n\n version ; time ; bits ; merkleroot ; prevblock ; nonce\n\nwould mean that the last 12 bytes of prevblock and the 4 bytes of nonce\nwould be available for manipulation [0] if the first round of sha256\nwas pre-calculated prior to being sent to ASICs (and also that version\nand time wouldn't be available). Worth considering?\n\n\n\nI don't see how you'd make either of these changes compatible\nwith Luke-Jr's soft-hardfork approach [1] to ensuring non-upgraded\nclients/nodes can't be tricked into following a shorter chain, though.\nI think the approach I suggested in my mail avoid Gavin's proposed hard\nfork might work though [2].\n\n\n\nCombining these with making merge-mining easier [1] and Luke-Jr/Peter\nTodd's ideas [3] about splitting the proof of work between something\nvisible to miners, and something only visible to pool operators to avoid\nthe block withholding attack on pooled mining would probably make sense\nthough, to reduce the number of hard forks visible to lightweight clients?\n\nCheers,\naj\n\n[0] Giving a total of 128 bits, or 96 bits with difficulty such that\n    only the last 8 bytes of prevblock are available.\n\n[1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-February/012377.html\n\n[2] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-December/012046.html\n\n[3] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-February/012384.html\n    In particular, the paragraph beginning \"Alternatively, if the old\n    blockchain has 10% of less hashpower ...\""
            },
            {
                "author": "Tao Effect",
                "date": "2016-02-09T02:45:47",
                "message_text_only": "Look, if we\u2019re going to declare something an emergency, we cannot on the one hand say things like: \"I strongly believe bitcoin has no place in the world if the fee raise much higher than a few cents per typically-sized transaction\u201d, and on the other declare that there is an emergency worth redefining what *Bitcoin is* because the average txn fee is on the order of 7 cents [1] and has remained reasonable for some time [2].\n\nIf you\u2019d like to understand what a qualifying emergency looks like, read the links:\n\n> http://bitledger.info/why-a-hard-fork-should-be-fought-and-its-not-evil-to-discuss/\n> \n> And here:\n> \n> http://bitledger.info/hard-fork-risks-and-why-95-should-be-the-standard/\n\n\nIn terms of scaling, we are nowhere close to an emergency.\n\nScaling is priority #4, maybe, and it\u2019s being taken care of.\n\nMeanwhile, we should be directing our attention one the more pressing and serious concerns like mining centralization & privacy.\n\nMining centralization is a serious issue. It is *not cool* that 4 dudes (and 1 government) have the power to redefine what Bitcoin is *right now*.\n\nRelevant post with suggestions for fixing that:\n\nhttps://www.reddit.com/r/Bitcoin/comments/44kwf0/the_hardfork_that_bitcoin_really_needs_not/czrh3na\n\nAs far as I can tell, P2Pool & GBT are not the same thing, but I\u2019ve been told that P2Pool might use GBT in some way, even though it\u2019s listed on the wiki as not using it. [3]\n\nA hard fork would ideally enforce decentralized mining pools somehow so that transaction selection is done at the edges instead of the center.\n\nCheers,\nGreg\n\n[1] http://www.cointape.com/\n[2] https://blockchain.info/charts/transaction-fees\n[3] https://en.bitcoin.it/wiki/Comparison_of_mining_pools\n\n> On Feb 8, 2016, at 4:54 PM, Chris Priest <cp368202 at ohiou.edu> wrote:\n> \n>> Also, if you\u2019re going to do a hard fork, you\u2019d better make the most of it as hard forks must be a *rare* world-is-ending-if-we-don\u2019t-do-it thing\n> \n> In my opinion, the network publishing more than 1MB worth of\n> transactions while the limit is still 1MB *is* an emergency worthy of\n> a hard fork.\n> \n> If that's not an emergency, then what is?\n> \n> I strongly believe bitcoin has no place in the world if the fee raise\n> much higher than a few cents per typically-sized transaction.\n> \n> On 2/8/16, Tao Effect via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> Hard forks should always come in response to some major crisis that all\n>> participants can agree is an actual crisis, as per the excellent rational\n>> here:\n>> \n>> http://bitledger.info/why-a-hard-fork-should-be-fought-and-its-not-evil-to-discuss/\n>> \n>> And here:\n>> \n>> http://bitledger.info/hard-fork-risks-and-why-95-should-be-the-standard/\n>> \n>> Also, if you\u2019re going to do a hard fork, you\u2019d better make the most of it as\n>> hard forks must be a *rare* world-is-ending-if-we-don\u2019t-do-it thing\n>> (otherwise Bitcoin cannot be considered decentralized in any sense of the\n>> word).\n>> \n>> So for any sort of hard fork, be sure to address the real threats and\n>> challenges that are facing Bitcoin today:\n>> \n>> 1. Mining centralization.\n>> 2. Privacy.\n>> \n>> Best regards,\n>> Greg Slepak\n>> \n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 841 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160208/bb73279d/attachment.sig>"
            },
            {
                "author": "Nicolas Dorier",
                "date": "2016-02-09T12:32:06",
                "message_text_only": "> 2) In order to prevent significant blowups in the cost to validate\n> [...] and transactions are only allowed to contain\n> up to 20 non-segwit inputs. [...]\n\nThere is two kind of hard fork, the one who breaks things, and the one who\ndoes not.\nRestricting the non-segwit inputs would disrupt lots of services, and\npotentially invalidating\nhash time locked transactions, which is a very bad precedent.\nSo I'm strongly against this particular point.\n\n> scriptPubKeys are now limited to 100 bytes in\n> size and may not contain OP_CODESEPARATOR, scriptSigs must be push-only\n> (ie no non-push opcodes)\n\nSame problem for native multisig, however potentially less important than\nthe previous point.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160209/a04a4478/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "On Hardforks in the Context of SegWit",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Nicolas Dorier",
                "Anthony Towns",
                "Peter Todd",
                "Simon Liu",
                "Luke Dashjr",
                "Matt Corallo",
                "jl2012 at xbt.hk",
                "Tao Effect"
            ],
            "messages_count": 13,
            "total_messages_chars_count": 50358
        }
    },
    {
        "title": "[bitcoin-dev] BIP Final status",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2016-02-08T22:17:55",
                "message_text_only": "https://github.com/bitcoin/bips/pull/314 proposes updating the status of many \nAccepted BIPs to Final:\n\nBIP 11: M-of-N Standard Transactions\nBIP 14: Protocol Version and User Agent\nBIP 21: URI Scheme\nBIP 22: getblocktemplate - Fundamentals\nBIP 23: getblocktemplate - Pooled Mining\nBIP 31: Pong message\nBIP 32: Hierarchical Deterministic Wallets\nBIP 34: Block v2, Height in Coinbase\nBIP 35: mempool message\nBIP 37: Connection Bloom filtering\nBIP 65: OP_CHECKLOCKTIMEVERIFY\n\nThis PR has been open for a week, and I plan to merge it within the next week \nunless there are objections.\n\nAdditionally, https://github.com/bitcoin/bips/pull/315 proposes to upgrade \nfive additional from Draft to Final status, and preferably needs ACKs from the \nchampions of the BIPs:\n\nBIP 50: March 2013 Chain Fork Post-Mortem, by Gavin Andresen\nBIP 60: Fixed Length \"version\" Message (Relay-Transactions Field), by Amir\n        Taaki\nBIP 64: getutxo message, by Mike Hearn\nBIP 66: Strict DER signatures, by Pieter Wuille\nBIP 73: Use \"Accept\" header for response type negotiation with Payment Request\n        URLs, by Stephen Pair\n\nThanks,\n\nLuke"
            },
            {
                "author": "Peter Todd",
                "date": "2016-02-08T22:41:00",
                "message_text_only": "On Mon, Feb 08, 2016 at 10:17:55PM +0000, Luke Dashjr via bitcoin-dev wrote:\n> Additionally, https://github.com/bitcoin/bips/pull/315 proposes to upgrade \n> five additional from Draft to Final status, and preferably needs ACKs from the \n> champions of the BIPs:\n> \n> BIP 50: March 2013 Chain Fork Post-Mortem, by Gavin Andresen\n\nIt may be good to update BIP 50 with the new information that calling it\na \"hard fork\" misses subtleties about what happened during that fork. In\nparticular, 0.7 rejection of the chain was non-deterministic, based on\nhaving seen a re-org in a specific way.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n000000000000000001ae7ca66e52359d67c407a739fde42b83ecc746d3ab735d\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160208/e3c6f297/attachment.sig>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-08T22:57:34",
                "message_text_only": "On Monday, February 08, 2016 10:41:00 PM Peter Todd wrote:\n> On Mon, Feb 08, 2016 at 10:17:55PM +0000, Luke Dashjr via bitcoin-dev wrote:\n> > Additionally, https://github.com/bitcoin/bips/pull/315 proposes to\n> > upgrade five additional from Draft to Final status, and preferably needs\n> > ACKs from the champions of the BIPs:\n> > \n> > BIP 50: March 2013 Chain Fork Post-Mortem, by Gavin Andresen\n> \n> It may be good to update BIP 50 with the new information that calling it\n> a \"hard fork\" misses subtleties about what happened during that fork. In\n> particular, 0.7 rejection of the chain was non-deterministic, based on\n> having seen a re-org in a specific way.\n\nI agree BIP 50 could use some rephrasing, but the May 2013 change was \ndefinitely a hardfork, despite the problems with the pre-March protocol.\n\nLuke"
            }
        ],
        "thread_summary": {
            "title": "BIP Final status",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Luke Dashjr",
                "Peter Todd"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 2918
        }
    },
    {
        "title": "[bitcoin-dev] Question regarding Confidential Transactions",
        "thread_messages": [
            {
                "author": "Henning Kopp",
                "date": "2016-02-09T13:12:15",
                "message_text_only": "Hi all,\n\nI am trying to fully grasp confidential transactions.\n\nWhen a sender creates a confidential transaction and picks the blinding\nvalues correctly, anyone can check that the transaction is valid. It\nremains publically verifiable.\nBut how can the receiver of the transaction check which amount was\nsent to him?\nI think he needs to learn the blinding factor to reveal the commit\nsomehow off-chain. Am I correct with this assumption?\nIf yes, how does this work?\n\nAll the best\nHenning\n\n-- \nHenning Kopp\nInstitute of Distributed Systems\nUlm University, Germany\n\nOffice: O27 - 3402\nPhone: +49 731 50-24138\nWeb: http://www.uni-ulm.de/in/vs/~kopp"
            },
            {
                "author": "Jeremy Papp",
                "date": "2016-02-09T22:12:37",
                "message_text_only": "My understanding of the paper is that the blinding factor would be \nincluded in the extra data which is incorporated into the ring \nsignatures used in the range proof.\n\nAlthough, since I think the range proof is optional for single output \ntransactions (or at least, one output per transaction doesn't require a \nrange proof since there's only one possible value that it can be to make \nthe whole thing work, and that value must be in range, I'm not entirely \nsure how you'd transmit it then, though in any case, since using it will \npretty much require segwit, adding extraneous data isn't much of a \nproblem.  In both cases, I imagine the blinding factor would be \nprotected from outside examination via some form of shared secret \ngeneration... Although that would require the sender to know the \nrecipient's unhashed public key; I don't know of any shared secret \nschemes that will work on hashed keys.\n\nJeremy Papp\n\nOn 2/9/2016 7:12 AM, Henning Kopp via bitcoin-dev wrote:\n> Hi all,\n>\n> I am trying to fully grasp confidential transactions.\n>\n> When a sender creates a confidential transaction and picks the blinding\n> values correctly, anyone can check that the transaction is valid. It\n> remains publically verifiable.\n> But how can the receiver of the transaction check which amount was\n> sent to him?\n> I think he needs to learn the blinding factor to reveal the commit\n> somehow off-chain. Am I correct with this assumption?\n> If yes, how does this work?\n>\n> All the best\n> Henning\n>"
            },
            {
                "author": "Henning Kopp",
                "date": "2016-02-10T11:53:45",
                "message_text_only": "Hi Jeremy,\n\n> My understanding of the paper is that the blinding factor would be included\n> in the extra data which is incorporated into the ring signatures used in the\n> range proof.\n\nYep, that is a possibility. The blinding factor could be encrypted\nwith the public key of the receiver. Thus it is only visible for the\nreceiver who can then check that the correct amount has been sent.\n\n> Although, since I think the range proof is optional for single output\n> transactions (or at least, one output per transaction doesn't require a\n> range proof since there's only one possible value that it can be to make the\n> whole thing work, and that value must be in range, I'm not entirely sure how\n\nI understand and agree.\n\n> you'd transmit it then, though in any case, since using it will pretty much\n> require segwit, adding extraneous data isn't much of a problem.  In both\n> cases, I imagine the blinding factor would be protected from outside\n> examination via some form of shared secret generation... Although that would\n> require the sender to know the recipient's unhashed public key; I don't know\n> of any shared secret schemes that will work on hashed keys.\n\nHere you lost me.\nWhy do we need to create a shared secret? Is this shared secret used\nas the blinding factor?\nAlso I think the sender knows the unhashed public key of the receiver.\nThe only reason not to include it in the transaction script is that an\nexternal observer is unable to see the receiver directly in the\nblockchain.\n\nBest\nHenning\n\n\nOn Tue, Feb 09, 2016 at 04:12:37PM -0600, Jeremy Papp via bitcoin-dev wrote:\n> My understanding of the paper is that the blinding factor would be included\n> in the extra data which is incorporated into the ring signatures used in the\n> range proof.\n> \n> Although, since I think the range proof is optional for single output\n> transactions (or at least, one output per transaction doesn't require a\n> range proof since there's only one possible value that it can be to make the\n> whole thing work, and that value must be in range, I'm not entirely sure how\n> you'd transmit it then, though in any case, since using it will pretty much\n> require segwit, adding extraneous data isn't much of a problem.  In both\n> cases, I imagine the blinding factor would be protected from outside\n> examination via some form of shared secret generation... Although that would\n> require the sender to know the recipient's unhashed public key; I don't know\n> of any shared secret schemes that will work on hashed keys.\n> \n> Jeremy Papp\n> \n> On 2/9/2016 7:12 AM, Henning Kopp via bitcoin-dev wrote:\n> >Hi all,\n> >\n> >I am trying to fully grasp confidential transactions.\n> >\n> >When a sender creates a confidential transaction and picks the blinding\n> >values correctly, anyone can check that the transaction is valid. It\n> >remains publically verifiable.\n> >But how can the receiver of the transaction check which amount was\n> >sent to him?\n> >I think he needs to learn the blinding factor to reveal the commit\n> >somehow off-chain. Am I correct with this assumption?\n> >If yes, how does this work?\n> >\n> >All the best\n> >Henning\n> >\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n\n-- \nHenning Kopp\nInstitute of Distributed Systems\nUlm University, Germany\n\nOffice: O27 - 3402\nPhone: +49 731 50-24138\nWeb: http://www.uni-ulm.de/in/vs/~kopp"
            },
            {
                "author": "Jeremy Papp",
                "date": "2016-02-10T16:39:25",
                "message_text_only": "On 2/10/2016 5:53 AM, Henning Kopp wrote:\n> Hi Jeremy,\n>\n>> My understanding of the paper is that the blinding factor would be included\n>> in the extra data which is incorporated into the ring signatures used in the\n>> range proof.\n> Yep, that is a possibility. The blinding factor could be encrypted\n> with the public key of the receiver. Thus it is only visible for the\n> receiver who can then check that the correct amount has been sent.\nECC doesn't work like RSA; you can't encrypt directly with a public \nkey.  That's why you generate a shared secret between sender and \nreceiver.  See also, ECDH. (Basically, if (m, M = m*G) is your \nprivate/public key pair, and (n, N = n*G) is your recipient's private \npublic key pair, you can both generate shared secret S = m*N = n*M = \nm*n*G without revealing your private keys to each other, and without \nrevealing the secret to anyone else as long as they don't know either \nprivate key. You then use S as the basis for the key to some symmetric \nalgorithm.)\n>> you'd transmit it then, though in any case, since using it will pretty much\n>> require segwit, adding extraneous data isn't much of a problem.  In both\n>> cases, I imagine the blinding factor would be protected from outside\n>> examination via some form of shared secret generation... Although that would\n>> require the sender to know the recipient's unhashed public key; I don't know\n>> of any shared secret schemes that will work on hashed keys.\n> Here you lost me.\n> Why do we need to create a shared secret? Is this shared secret used\n> as the blinding factor?\n> Also I think the sender knows the unhashed public key of the receiver.\n> The only reason not to include it in the transaction script is that an\n> external observer is unable to see the receiver directly in the\n> blockchain.\nNormal Bitcoin transactions are made to the hash of a public key because \nonce the public key is known, it becomes easier to break it if we ever \ndevelop quantum computers. That's why it's recommended that you only \nspend from a particular address once (if possible) since its only in \nspending that you are required to reveal your public key.   Since you \ncan't do a shared secret with a public key hash, AFAIK, you'd have to \nknow the public key of your recipient to be able to do ECDH.\n\nJeremy Papp"
            },
            {
                "author": "Adam Gibson",
                "date": "2016-02-13T16:55:31",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nIn case it helps:\nThe elements alpha sidechain uses a different address format, which\nincludes an ECDH pubkey used for creating an ECDH shared secret.\nThat shared secret is used to seed a RFC6979 prng, which allows both\nsides to generate the blinding factors used in the rangeproof.\n\nSo the situation is: both sides can generate the blinding factors, but\nalso the fake signatures used in the rangeproof (the basic idea there\nis to have N signatures in a ring, but only one of them real; the rest\nare forged and can be (must be) entirely random numbers. I say 'basic'\nbecause the Borromean sig design is to link together several rings,\nnot just one). This allows the sender to embed the amount into one of\nthose fake signatures (usually the last one) using xor, with certain\nformatting details.\n\nIt would be possible to not bother to embed the amount in this way;\nthe receiver, knowing the stream of fake/real signatures (again -\nbecause he knows the seed for the prng), could simply observe which\nones are real and therefore know the digits of the amount. But if he\ndid it this way, it would not be possible to embed any other data into\nthe range proof (such as: auditing related information) using xor as\nabove.\n\nI did some detailed explanation/investigation of this in sections 3.3\nand 3.4 of\nhttps://github.com/AdamISZ/ConfidentialTransactionsDoc/blob/master/essayonCT.pdf\n; with apologies for any errors, it was just an investigation I did\nlast summer.\n\n\nOn 02/10/2016 06:39 PM, Jeremy Papp via bitcoin-dev wrote:\n> On 2/10/2016 5:53 AM, Henning Kopp wrote:\n>> Hi Jeremy,\n>> \n>>> My understanding of the paper is that the blinding factor would\n>>> be included in the extra data which is incorporated into the\n>>> ring signatures used in the range proof.\n>> Yep, that is a possibility. The blinding factor could be\n>> encrypted with the public key of the receiver. Thus it is only\n>> visible for the receiver who can then check that the correct\n>> amount has been sent.\n> ECC doesn't work like RSA; you can't encrypt directly with a\n> public key.  That's why you generate a shared secret between sender\n> and receiver.  See also, ECDH. (Basically, if (m, M = m*G) is your \n> private/public key pair, and (n, N = n*G) is your recipient's\n> private public key pair, you can both generate shared secret S =\n> m*N = n*M = m*n*G without revealing your private keys to each\n> other, and without revealing the secret to anyone else as long as\n> they don't know either private key. You then use S as the basis for\n> the key to some symmetric algorithm.)\n>>> you'd transmit it then, though in any case, since using it\n>>> will pretty much require segwit, adding extraneous data isn't\n>>> much of a problem.  In both cases, I imagine the blinding\n>>> factor would be protected from outside examination via some\n>>> form of shared secret generation... Although that would require\n>>> the sender to know the recipient's unhashed public key; I don't\n>>> know of any shared secret schemes that will work on hashed\n>>> keys.\n>> Here you lost me. Why do we need to create a shared secret? Is\n>> this shared secret used as the blinding factor? Also I think the\n>> sender knows the unhashed public key of the receiver. The only\n>> reason not to include it in the transaction script is that an \n>> external observer is unable to see the receiver directly in the \n>> blockchain.\n> Normal Bitcoin transactions are made to the hash of a public key\n> because once the public key is known, it becomes easier to break it\n> if we ever develop quantum computers. That's why it's recommended\n> that you only spend from a particular address once (if possible)\n> since its only in spending that you are required to reveal your\n> public key.   Since you can't do a shared secret with a public key\n> hash, AFAIK, you'd have to know the public key of your recipient to\n> be able to do ECDH.\n> \n> Jeremy Papp _______________________________________________ \n> bitcoin-dev mailing list bitcoin-dev at lists.linuxfoundation.org \n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1\n\niQEcBAEBAgAGBQJWv1/8AAoJELOuCfHpoxl6dV8H/AvlEUebgKBAZdSdIEDKm0m0\npSXNWH62v327YdJ2wFqPCB2zG9HKXP76XhCGx39PEEvBmAFAoD6URAWPk8o03kTo\naJZUeRB7wLqIALuUub/0JzAJwcxZtTIhYu3ygfyZZuvpomG8yXlERwfjB+BcCXnm\nD7TJ2qOyq3X3uaneb/OnUEvDxOrl9zAp9q7CUnFQB2xagCRnHyGNcrWaH43RmpHl\nEima6eonQUR4AAcIUu0CKSRjgM6q46bMbXTFt9I4XeqQxsMB5Gfe9Ggk15TNRoUm\nENVaJnPL4qlJqODSrO9R4xrurVCcp7HVeR9B5aztFQszVNxhMoZtFlyn5U3J0gY=\n=+I00\n-----END PGP SIGNATURE-----"
            }
        ],
        "thread_summary": {
            "title": "Question regarding Confidential Transactions",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Henning Kopp",
                "Jeremy Papp",
                "Adam Gibson"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 12489
        }
    },
    {
        "title": "[bitcoin-dev] A roadmap to a better header format and bigger block size",
        "thread_messages": [
            {
                "author": "jl2012 at xbt.hk",
                "date": "2016-02-09T14:16:15",
                "message_text_only": "I would like to present a 2-3 year roadmap to a better header format and\nbigger block size\n\nObjectives:\n\n1. Multistage rule changes to make sure everyone will have enough time to\nupgrade\n2. Make mining easier, without breaking existing mining hardware and the\nStratum protocol\n3. Make future hardfork less disruptive (with Luke-Jr's proposal)\n\nStage 1 is Segregated Witness (BIP141), which will not break any existing\nfull or light nodes. This may happen in Q2-Q3 2016\n\nStage 2 is fixes that will break existing full nodes, but not light nodes:\na. Increase the MAX_BLOCK_SIZE (the exact value is not suggested in this\nroadmap), potentially change the witness discount\nb. Anti-DoS rules for the O(n^2) validation of non-segwit scripts\nc. (optional) Move segwit's commitments to the header Merkle tree. This is\noptional at this stage as it will be fixed in Stage 3 anyway\nThis may happen in Q1-Q2 2017\n\nStage 3 is fixes that will break all existing full nodes and light nodes:\na. Full nodes upgraded to Stage 2 will not need to upgrade again, as the\nrules and activation logic should be included already\nb. Change the header format to Luke-Jr's proposal, and move all commitments\n(tx, witness, etc) to the new structure. All existing mining hardware with\nStratum protocol should work.\nc. Reclaiming unused bits in header for mining. All existing mining chips\nshould still work. Newly designed chips should be ready for the new rule.\nd. Fix the time warp attack\nThis may happen in 2018 to 2019\n\nPros:\na. Light nodes (usually less tech-savvy users) will have longer time to\nupgrade\nb. The stage 2 is opt-in for full nodes.\nc. The stage 3 is opt-in for light nodes.\n\nCons:\na. The stage 2 is not opt-in for light nodes. They will blindly follow the\nlongest chain which they might actually don't want to\nb. Non-upgraded full nodes will follow the old chain at Stage 2, which is\nlikely to have lower value.\nc. Non-upgraded light nodes will follow the old chain at Stage 3, which is\nlikely to have lower value. (However, this is not a concern as no one should\nbe mining on the old chain at that time)\n\n-------------------------------\nAn alternative roadmap would be:\n\nStage 2 is fixes that will break existing full nodes and light nodes.\nHowever, they will not follow the minority chain\na. Increase the MAX_BLOCK_SIZE, potentially change the witness discount\nb. Anti-DoS rules for the O(n^2) validation of non-segwit scripts\nc. Change the header format to Luke-Jr's proposal, and move all commitments\n(tx, witness, etc) to the new structure.\nThis may happen in mid 2017 or later\n\nStage 3 is fixes that will break all existing full nodes and light nodes. \na. Full nodes and light nodes upgraded to Stage 2 will not need to upgrade\nagain, as the rules and activation logic should be included already\nb. Reclaiming unused bits in header for mining. All existing mining chips\nshould still work.\nc. Fix the time warp attack\nThis may happen in 2018 to 2019\n\nPros:\na. The stage 2 and 3 are opt-in for everyone\nb. Even failing to upgrade, full nodes and light nodes won't follow the\nminority chain at stage 2\n\nCons:\na. Non-upgraded full/light nodes will follow the old chain at Stage 3, which\nis likely to have lower value. (However, this is not a concern as no one\nshould be mining on the old chain at that time)\nb. It takes longer to implement stage 2 to give enough time for light node\nusers to upgrade\n\n-------------------------------\n\nIn terms of safety, the second proposal is better. In terms of disruption,\nthe first proposal is less disruptive\n\nI would also like to emphasize that it is miners' responsibility, not the\ndevs', to confirm that the supermajority of the community accept changes in\nStage 2 and 3.\n\nReference:\nMatt Corallo's proposal:\nhttp://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-February/012403.\nhtml\nLuke-Jr's proposal:\nhttp://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-February/012377.\nhtml"
            },
            {
                "author": "Ricardo Filipe",
                "date": "2016-02-09T15:53:04",
                "message_text_only": "I believe i've seen Luke say this several times before, but there are\nseveral more things that the majority of the devs agree should be in\nbitcoin.\nI would suggest to compile that list for your stage 3, so that you can have\nan hardfork that fixes most of those things, and there should be some\nrepository with those changes deployed.\n\n2016-02-09 14:16 GMT+00:00 jl2012--- via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org>:\n\n> I would like to present a 2-3 year roadmap to a better header format and\n> bigger block size\n>\n> Objectives:\n>\n> 1. Multistage rule changes to make sure everyone will have enough time to\n> upgrade\n> 2. Make mining easier, without breaking existing mining hardware and the\n> Stratum protocol\n> 3. Make future hardfork less disruptive (with Luke-Jr's proposal)\n>\n> Stage 1 is Segregated Witness (BIP141), which will not break any existing\n> full or light nodes. This may happen in Q2-Q3 2016\n>\n> Stage 2 is fixes that will break existing full nodes, but not light nodes:\n> a. Increase the MAX_BLOCK_SIZE (the exact value is not suggested in this\n> roadmap), potentially change the witness discount\n> b. Anti-DoS rules for the O(n^2) validation of non-segwit scripts\n> c. (optional) Move segwit's commitments to the header Merkle tree. This is\n> optional at this stage as it will be fixed in Stage 3 anyway\n> This may happen in Q1-Q2 2017\n>\n> Stage 3 is fixes that will break all existing full nodes and light nodes:\n> a. Full nodes upgraded to Stage 2 will not need to upgrade again, as the\n> rules and activation logic should be included already\n> b. Change the header format to Luke-Jr's proposal, and move all commitments\n> (tx, witness, etc) to the new structure. All existing mining hardware with\n> Stratum protocol should work.\n> c. Reclaiming unused bits in header for mining. All existing mining chips\n> should still work. Newly designed chips should be ready for the new rule.\n> d. Fix the time warp attack\n> This may happen in 2018 to 2019\n>\n> Pros:\n> a. Light nodes (usually less tech-savvy users) will have longer time to\n> upgrade\n> b. The stage 2 is opt-in for full nodes.\n> c. The stage 3 is opt-in for light nodes.\n>\n> Cons:\n> a. The stage 2 is not opt-in for light nodes. They will blindly follow the\n> longest chain which they might actually don't want to\n> b. Non-upgraded full nodes will follow the old chain at Stage 2, which is\n> likely to have lower value.\n> c. Non-upgraded light nodes will follow the old chain at Stage 3, which is\n> likely to have lower value. (However, this is not a concern as no one\n> should\n> be mining on the old chain at that time)\n>\n> -------------------------------\n> An alternative roadmap would be:\n>\n> Stage 2 is fixes that will break existing full nodes and light nodes.\n> However, they will not follow the minority chain\n> a. Increase the MAX_BLOCK_SIZE, potentially change the witness discount\n> b. Anti-DoS rules for the O(n^2) validation of non-segwit scripts\n> c. Change the header format to Luke-Jr's proposal, and move all commitments\n> (tx, witness, etc) to the new structure.\n> This may happen in mid 2017 or later\n>\n> Stage 3 is fixes that will break all existing full nodes and light nodes.\n> a. Full nodes and light nodes upgraded to Stage 2 will not need to upgrade\n> again, as the rules and activation logic should be included already\n> b. Reclaiming unused bits in header for mining. All existing mining chips\n> should still work.\n> c. Fix the time warp attack\n> This may happen in 2018 to 2019\n>\n> Pros:\n> a. The stage 2 and 3 are opt-in for everyone\n> b. Even failing to upgrade, full nodes and light nodes won't follow the\n> minority chain at stage 2\n>\n> Cons:\n> a. Non-upgraded full/light nodes will follow the old chain at Stage 3,\n> which\n> is likely to have lower value. (However, this is not a concern as no one\n> should be mining on the old chain at that time)\n> b. It takes longer to implement stage 2 to give enough time for light node\n> users to upgrade\n>\n> -------------------------------\n>\n> In terms of safety, the second proposal is better. In terms of disruption,\n> the first proposal is less disruptive\n>\n> I would also like to emphasize that it is miners' responsibility, not the\n> devs', to confirm that the supermajority of the community accept changes in\n> Stage 2 and 3.\n>\n> Reference:\n> Matt Corallo's proposal:\n>\n> http://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-February/012403.\n> html\n> Luke-Jr's proposal:\n>\n> http://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-February/012377.\n> html\n>\n>\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160209/8baa5e97/attachment-0001.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2016-02-09T22:15:15",
                "message_text_only": "As for your stages idea, I generally like the idea (and mentioned it may\nbe a good idea in my proposal), but am worried about scheduling two\nhard-forks at once....Lets do our first hard-fork first with the things\nwe think we will need anytime in the visible future that we have\nreasonable designs for now, and talk about a second one after we've seen\nwhat did/didnt blow up with the first one.\n\nAnyway, this generally seems reasonable - it looks like most of this\nmatches up with what I said more specifically in my mail yesterday, with\nthe addition of timewarp fixes, which we should probably add, and Luke's\nheader changes, which I need to spend some more time thinking about.\n\nMatt\n\nOn 02/09/16 14:16, jl2012--- via bitcoin-dev wrote:\n> I would like to present a 2-3 year roadmap to a better header format and\n> bigger block size\n> \n> Objectives:\n> \n> 1. Multistage rule changes to make sure everyone will have enough time to\n> upgrade\n> 2. Make mining easier, without breaking existing mining hardware and the\n> Stratum protocol\n> 3. Make future hardfork less disruptive (with Luke-Jr's proposal)\n> \n> Stage 1 is Segregated Witness (BIP141), which will not break any existing\n> full or light nodes. This may happen in Q2-Q3 2016\n> \n> Stage 2 is fixes that will break existing full nodes, but not light nodes:\n> a. Increase the MAX_BLOCK_SIZE (the exact value is not suggested in this\n> roadmap), potentially change the witness discount\n> b. Anti-DoS rules for the O(n^2) validation of non-segwit scripts\n> c. (optional) Move segwit's commitments to the header Merkle tree. This is\n> optional at this stage as it will be fixed in Stage 3 anyway\n> This may happen in Q1-Q2 2017\n> \n> Stage 3 is fixes that will break all existing full nodes and light nodes:\n> a. Full nodes upgraded to Stage 2 will not need to upgrade again, as the\n> rules and activation logic should be included already\n> b. Change the header format to Luke-Jr's proposal, and move all commitments\n> (tx, witness, etc) to the new structure. All existing mining hardware with\n> Stratum protocol should work.\n> c. Reclaiming unused bits in header for mining. All existing mining chips\n> should still work. Newly designed chips should be ready for the new rule.\n> d. Fix the time warp attack\n> This may happen in 2018 to 2019\n> \n> Pros:\n> a. Light nodes (usually less tech-savvy users) will have longer time to\n> upgrade\n> b. The stage 2 is opt-in for full nodes.\n> c. The stage 3 is opt-in for light nodes.\n> \n> Cons:\n> a. The stage 2 is not opt-in for light nodes. They will blindly follow the\n> longest chain which they might actually don't want to\n> b. Non-upgraded full nodes will follow the old chain at Stage 2, which is\n> likely to have lower value.\n> c. Non-upgraded light nodes will follow the old chain at Stage 3, which is\n> likely to have lower value. (However, this is not a concern as no one should\n> be mining on the old chain at that time)\n> \n> -------------------------------\n> An alternative roadmap would be:\n> \n> Stage 2 is fixes that will break existing full nodes and light nodes.\n> However, they will not follow the minority chain\n> a. Increase the MAX_BLOCK_SIZE, potentially change the witness discount\n> b. Anti-DoS rules for the O(n^2) validation of non-segwit scripts\n> c. Change the header format to Luke-Jr's proposal, and move all commitments\n> (tx, witness, etc) to the new structure.\n> This may happen in mid 2017 or later\n> \n> Stage 3 is fixes that will break all existing full nodes and light nodes. \n> a. Full nodes and light nodes upgraded to Stage 2 will not need to upgrade\n> again, as the rules and activation logic should be included already\n> b. Reclaiming unused bits in header for mining. All existing mining chips\n> should still work.\n> c. Fix the time warp attack\n> This may happen in 2018 to 2019\n> \n> Pros:\n> a. The stage 2 and 3 are opt-in for everyone\n> b. Even failing to upgrade, full nodes and light nodes won't follow the\n> minority chain at stage 2\n> \n> Cons:\n> a. Non-upgraded full/light nodes will follow the old chain at Stage 3, which\n> is likely to have lower value. (However, this is not a concern as no one\n> should be mining on the old chain at that time)\n> b. It takes longer to implement stage 2 to give enough time for light node\n> users to upgrade\n> \n> -------------------------------\n> \n> In terms of safety, the second proposal is better. In terms of disruption,\n> the first proposal is less disruptive\n> \n> I would also like to emphasize that it is miners' responsibility, not the\n> devs', to confirm that the supermajority of the community accept changes in\n> Stage 2 and 3.\n> \n> Reference:\n> Matt Corallo's proposal:\n> http://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-February/012403.\n> html\n> Luke-Jr's proposal:\n> http://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-February/012377.\n> html\n> \n> \n> \n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "jl2012 at xbt.hk",
                "date": "2016-02-10T04:26:03",
                "message_text_only": "I am actually suggesting 1 hardfork, not 2. However, different rules are\nactivated at different time to enhance safety and reduce disruption. The\nadvantage is people are required to upgrade once, not twice. Any clients\ndesigned for stage 2 should also be ready for stage 3.\n\n\n-----Original Message-----\nFrom: Matt Corallo [mailto:lf-lists at mattcorallo.com] \nSent: Wednesday, 10 February, 2016 06:15\nTo: jl2012 at xbt.hk; bitcoin-dev at lists.linuxfoundation.org\nSubject: Re: [bitcoin-dev] A roadmap to a better header format and bigger\nblock size\n\nAs for your stages idea, I generally like the idea (and mentioned it may be\na good idea in my proposal), but am worried about scheduling two hard-forks\nat once....Lets do our first hard-fork first with the things we think we\nwill need anytime in the visible future that we have reasonable designs for\nnow, and talk about a second one after we've seen what did/didnt blow up\nwith the first one.\n\nAnyway, this generally seems reasonable - it looks like most of this matches\nup with what I said more specifically in my mail yesterday, with the\naddition of timewarp fixes, which we should probably add, and Luke's header\nchanges, which I need to spend some more time thinking about.\n\nMatt"
            }
        ],
        "thread_summary": {
            "title": "A roadmap to a better header format and bigger block size",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "jl2012 at xbt.hk",
                "Ricardo Filipe",
                "Matt Corallo"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 15130
        }
    },
    {
        "title": "[bitcoin-dev] Three Month bitcoin-dev Moderation Review",
        "thread_messages": [
            {
                "author": "David Vorick",
                "date": "2016-02-09T23:24:28",
                "message_text_only": "I do like that the volume of emails has been reduced substantially. I used\nto delete hordes of dev emails because I couldn't keep up. At least now I\nfeel like I'm able to skim most things that look interesting and I get to\nassume that if the subject seems relevant to me the content is worthwhile.\n\nMy life has improved because of the changes.\nOn Jan 23, 2016 8:08 PM, \"Dave Scotese via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> +1\n> The distinction we are making importantly requires that contributors\n> provide readers with another thing to say in favor of something - another\n> thing which is different than \"X people support this instead of only X-1\n> people.\"  Evidence trumps votes.\n>\n> On Sat, Jan 23, 2016 at 1:38 PM, Gavin via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>>\n>> > On Jan 23, 2016, at 3:59 PM, Peter Todd via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> >\n>> > I would extend this to say that the technical explanation also should\n>> > contribute uniquely to the conversation; a +1 with an explanation\n>> > the last +1 gave isn't useful.\n>>\n>> Yes, comments should contribute to the discussion, with either technical\n>> discussion or additional relevant data. I think a +1 like the following\n>> should be encouraged:\n>>\n>> \"+1: we had eleven customer support tickets in just the last week that\n>> would have been prevented if XYZ.\n>>\n>> Jane Doe, CTO CoinBitChainBasely.com\"\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n>\n>\n> --\n> I like to provide some work at no charge to prove my value. Do you need a\n> techie?\n> I own Litmocracy <http://www.litmocracy.com> and Meme Racing\n> <http://www.memeracing.net> (in alpha).\n> I'm the webmaster for The Voluntaryist <http://www.voluntaryist.com>\n> which now accepts Bitcoin.\n> I also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n> \"He ought to find it more profitable to play by the rules\" - Satoshi\n> Nakamoto\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160209/e9c58e70/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Three Month bitcoin-dev Moderation Review",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "David Vorick"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2497
        }
    },
    {
        "title": "[bitcoin-dev] Clearing up some misconceptions about full nodes",
        "thread_messages": [
            {
                "author": "Chris Belcher",
                "date": "2016-02-10T21:15:37",
                "message_text_only": "I've been asked to post this to this mailing list too. It's time to\nclear up some misconceptions floating around about full nodes.\n\n=== Myth: There are only about 5500 full nodes worldwide ===\n\nThis number comes from this and similar sites: https://bitnodes.21.co/\nand it measured by trying to probe every nodes on their open ports.\n\nProblem is, not all nodes actually have open ports that can be probed.\nEither because they are behind firewalls or because their users have\nconfigured them to not listen for connections.\n\nNobody knows how many full nodes there are, since many people don't know\nhow to forward ports behind a firewall, and bandwidth can be costly, its\nquite likely that the number of nodes with closed ports is at least\nanother several thousand.\n\nNodes with open ports are able to upload blocks to new full nodes. In\nall other ways they are the same as nodes with closed ports. But because\nopen-port-nodes can be measured and closed-port-nodes cannot, some\nmembers of the bitcoin community have been mistaken into believing that\nopen-port-nodes are that matters.\n\n=== Myth: This number of nodes matters and/or is too low. ===\n\nNodes with open ports are useful to the bitcoin network because they\nhelp bootstrap new nodes by uploading historical blocks, they are a\nmeasure of bandwidth capacity. Right now there is no shortage of\nbandwidth capacity, and if there was it could be easily added by renting\ncloud servers.\n\nThe problem is not bandwidth or connections, but trust, security and\nprivacy. Let me explain.\n\nFull nodes are able to check that all of bitcoin's rules are being\nfollowed. Rules like following the inflation schedule, no double\nspending, no spending of coins that don't belong to the holder of the\nprivate key and all the other rules required to make bitcoin work (e.g.\ndifficulty)\n\nFull nodes are what make bitcoin trustless. No longer do you have to\ntrust a financial institution like a bank or paypal, you can simply run\nsoftware on your own computer. To put simply, the only node that matters\nis the one you use.\n\n=== Myth: There is no incentive to run nodes, the network relies on\naltruism ===\n\nIt is very much in the individual bitcoin's users rational self interest\nto run a full node and use it as their wallet.\n\nUsing a full node as your wallet is the only way to know for sure that\nnone of bitcoin's rules have been broken. Rules like no coins were spent\nnot belonging to the owner, that no coins were spent twice, that no\ninflation happens outside of the schedule and that all the rules needed\nto make the system work are followed  (e.g. difficulty.) All other kinds\nof wallet involve trusting a third party server.\n\nAll these checks done by full nodes also increase the security. There\nare many attacks possible against lightweight wallets that do not affect\nfull node wallets.\n\nThis is not just mindless paranoia, there have been real world examples\nwhere full node users were unaffected by turmoil in the rest of the\nbitcoin ecosystem. The 4th July 2015 accidental chain fork effected many\nkinds of wallets. Here is the wiki page on this event\nhttps://en.bitcoin.it/wiki/July_2015_chain_forks#Wallet_Advice\n\nNotice how updated node software was completely unaffected by the fork.\nAll other wallets required either extra confirmations or checking that\nthe third-party institution was running the correct version.\n\nFull nodes wallets are also currently the most private way to use\nBitcoin, with nobody else learning which bitcoin addresses belong to\nyou. All other lightweight wallets leak information about which\naddresses are yours because they must query third-party servers. The\nElectrum servers will know which addresses belong to you and can link\nthem together. Despite bloom filtering, lightweight wallets based on\nBitcoinJ do not provide much privacy against nodes who connected\ndirectly to the wallet or wiretappers.\n\nFor many use cases, such privacy may not be required. But an important\nreason to run a full node and use it as a wallet is to get the full\nprivacy benefits.\n\n=== Myth: I can just set up a node on a cloud server instance and leave\nit ===\n\nTo get the benefits of running a full node, you must use it as your\nwallet, preferably on hardware you control.\n\nMost people who do this do not use a full node as their wallet.\nUnfortunately because Bitcoin has a similar name to Bittorrent, some\npeople believe that upload capacity is the most important thing for a\nhealthy network. As I've explained above: bandwidth and connections are\nnot a problem today, trust, security and privacy are.\n\n=== Myth: Running a full node is not recommended, most people should use\na lightweight client ===\n\nThis was common advice in 2012, but since then the full node software\nhas vastly improved in terms of user experience.\n\nIf you cannot spare the disk space to store the blockchain, you can\nenable pruning as in:\nhttps://bitcoin.org/en/release/v0.11.0#block-file-pruning. In Bitcoin\nCore 0.12, pruning being enabled will leave the wallet enabled.\nAltogether this should require less than 1.5GB of hard disk space.\n\nIf you cannot spare the bandwidth to upload blocks to other nodes, there\nare number of options to reduce or eliminate the bandwidth requirement\nfound in https://bitcoin.org/en/full-node#reduce-traffic . These include\nlimiting connections, bandwidth targetting and disabling listening.\nBitcoin Core 0.12 has the new option -blocksonly, where the node will\nnot download unconfirmed transaction and only download new blocks. This\nmore than halves the bandwidth usage at the expense of not seeing\nunconfirmed transactions.\n\nSynchronizing the blockchain for a new node has improved since 2012 too.\nFeatures like headers-first\n(https://bitcoin.org/en/release/v0.10.0#faster-synchronization) and\nlibsecp256k1 have greatly improved the initial synchronization time.\n\nIt can be further improved by setting -dbcache=6000 which keeps more of\nthe UTXO set in memory. It reduces the amount of time reading from disk\nand therefore speeds up synchronization. Tests showed that the entire\nblockchain can now be synchronized in less than _3 and a half hours_\n(See\nhttps://github.com/bitcoin/bitcoin/pull/6954#issuecomment-154993958)\nNote that you'll need Bitcoin Core 0.12 or later to get all these\nefficiency improvements.\n\n=== How to run a full node as your wallet ===\n\nI think every moderate user of bitcoin would benefit by running a full\nnode and using it as their wallet. There are several ways to do this.\n\n* Run a bitcoin-qt full node (https://bitcoin.org/en/download).\n\n* Use wallet software that is backed by a full node e.g. Armory\n(https://bitcoinarmory.com/) or JoinMarket\n(https://github.com/AdamISZ/JMBinary/#jmbinary)\n\n* Use a lightweight wallet that connects only to your full node (e.g.\nMultibit connecting only to your node running at home, Electrum\nconnecting only to your own Electrum server)\n\nSo what are you waiting for? The benefits are many, the downsides are\nnot that bad. The more people do this, the more robust and healthy the\nbitcoin ecosystem is."
            },
            {
                "author": "Patrick Shirkey",
                "date": "2016-02-11T07:03:18",
                "message_text_only": "On Thu, February 11, 2016 8:15 am, Chris Belcher via bitcoin-dev wrote:\n> I've been asked to post this to this mailing list too. It's time to\n> clear up some misconceptions floating around about full nodes.\n>\n> === Myth: There are only about 5500 full nodes worldwide ===\n>\n> This number comes from this and similar sites: https://bitnodes.21.co/\n> and it measured by trying to probe every nodes on their open ports.\n>\n> Problem is, not all nodes actually have open ports that can be probed.\n> Either because they are behind firewalls or because their users have\n> configured them to not listen for connections.\n>\n> Nobody knows how many full nodes there are, since many people don't know\n> how to forward ports behind a firewall, and bandwidth can be costly, its\n> quite likely that the number of nodes with closed ports is at least\n> another several thousand.\n>\n> Nodes with open ports are able to upload blocks to new full nodes. In\n> all other ways they are the same as nodes with closed ports. But because\n> open-port-nodes can be measured and closed-port-nodes cannot, some\n> members of the bitcoin community have been mistaken into believing that\n> open-port-nodes are that matters.\n>\n> === Myth: This number of nodes matters and/or is too low. ===\n>\n> Nodes with open ports are useful to the bitcoin network because they\n> help bootstrap new nodes by uploading historical blocks, they are a\n> measure of bandwidth capacity. Right now there is no shortage of\n> bandwidth capacity, and if there was it could be easily added by renting\n> cloud servers.\n>\n> The problem is not bandwidth or connections, but trust, security and\n> privacy. Let me explain.\n>\n> Full nodes are able to check that all of bitcoin's rules are being\n> followed. Rules like following the inflation schedule, no double\n> spending, no spending of coins that don't belong to the holder of the\n> private key and all the other rules required to make bitcoin work (e.g.\n> difficulty)\n>\n> Full nodes are what make bitcoin trustless. No longer do you have to\n> trust a financial institution like a bank or paypal, you can simply run\n> software on your own computer. To put simply, the only node that matters\n> is the one you use.\n>\n> === Myth: There is no incentive to run nodes, the network relies on\n> altruism ===\n>\n> It is very much in the individual bitcoin's users rational self interest\n> to run a full node and use it as their wallet.\n>\n> Using a full node as your wallet is the only way to know for sure that\n> none of bitcoin's rules have been broken. Rules like no coins were spent\n> not belonging to the owner, that no coins were spent twice, that no\n> inflation happens outside of the schedule and that all the rules needed\n> to make the system work are followed  (e.g. difficulty.) All other kinds\n> of wallet involve trusting a third party server.\n>\n> All these checks done by full nodes also increase the security. There\n> are many attacks possible against lightweight wallets that do not affect\n> full node wallets.\n>\n> This is not just mindless paranoia, there have been real world examples\n> where full node users were unaffected by turmoil in the rest of the\n> bitcoin ecosystem. The 4th July 2015 accidental chain fork effected many\n> kinds of wallets. Here is the wiki page on this event\n> https://en.bitcoin.it/wiki/July_2015_chain_forks#Wallet_Advice\n>\n> Notice how updated node software was completely unaffected by the fork.\n> All other wallets required either extra confirmations or checking that\n> the third-party institution was running the correct version.\n>\n> Full nodes wallets are also currently the most private way to use\n> Bitcoin, with nobody else learning which bitcoin addresses belong to\n> you. All other lightweight wallets leak information about which\n> addresses are yours because they must query third-party servers. The\n> Electrum servers will know which addresses belong to you and can link\n> them together. Despite bloom filtering, lightweight wallets based on\n> BitcoinJ do not provide much privacy against nodes who connected\n> directly to the wallet or wiretappers.\n>\n> For many use cases, such privacy may not be required. But an important\n> reason to run a full node and use it as a wallet is to get the full\n> privacy benefits.\n>\n> === Myth: I can just set up a node on a cloud server instance and leave\n> it ===\n>\n> To get the benefits of running a full node, you must use it as your\n> wallet, preferably on hardware you control.\n>\n> Most people who do this do not use a full node as their wallet.\n> Unfortunately because Bitcoin has a similar name to Bittorrent, some\n> people believe that upload capacity is the most important thing for a\n> healthy network. As I've explained above: bandwidth and connections are\n> not a problem today, trust, security and privacy are.\n>\n> === Myth: Running a full node is not recommended, most people should use\n> a lightweight client ===\n>\n> This was common advice in 2012, but since then the full node software\n> has vastly improved in terms of user experience.\n>\n> If you cannot spare the disk space to store the blockchain, you can\n> enable pruning as in:\n> https://bitcoin.org/en/release/v0.11.0#block-file-pruning. In Bitcoin\n> Core 0.12, pruning being enabled will leave the wallet enabled.\n> Altogether this should require less than 1.5GB of hard disk space.\n>\n> If you cannot spare the bandwidth to upload blocks to other nodes, there\n> are number of options to reduce or eliminate the bandwidth requirement\n> found in https://bitcoin.org/en/full-node#reduce-traffic . These include\n> limiting connections, bandwidth targetting and disabling listening.\n> Bitcoin Core 0.12 has the new option -blocksonly, where the node will\n> not download unconfirmed transaction and only download new blocks. This\n> more than halves the bandwidth usage at the expense of not seeing\n> unconfirmed transactions.\n>\n> Synchronizing the blockchain for a new node has improved since 2012 too.\n> Features like headers-first\n> (https://bitcoin.org/en/release/v0.10.0#faster-synchronization) and\n> libsecp256k1 have greatly improved the initial synchronization time.\n>\n> It can be further improved by setting -dbcache=6000 which keeps more of\n> the UTXO set in memory. It reduces the amount of time reading from disk\n> and therefore speeds up synchronization. Tests showed that the entire\n> blockchain can now be synchronized in less than _3 and a half hours_\n> (See\n> https://github.com/bitcoin/bitcoin/pull/6954#issuecomment-154993958)\n> Note that you'll need Bitcoin Core 0.12 or later to get all these\n> efficiency improvements.\n>\n> === How to run a full node as your wallet ===\n>\n> I think every moderate user of bitcoin would benefit by running a full\n> node and using it as their wallet. There are several ways to do this.\n>\n> * Run a bitcoin-qt full node (https://bitcoin.org/en/download).\n>\n> * Use wallet software that is backed by a full node e.g. Armory\n> (https://bitcoinarmory.com/) or JoinMarket\n> (https://github.com/AdamISZ/JMBinary/#jmbinary)\n>\n> * Use a lightweight wallet that connects only to your full node (e.g.\n> Multibit connecting only to your node running at home, Electrum\n> connecting only to your own Electrum server)\n>\n> So what are you waiting for? The benefits are many, the downsides are\n> not that bad. The more people do this, the more robust and healthy the\n> bitcoin ecosystem is.\n>\n>\n\nThis is very useful information but from my experience it is not viable to\nhave a full node running full time on a desktop system i.e sharing the\nsystem with a normal desktop workload.\n\nWith a very powerful \"Desktop\" machine bitcoin-qt dominates CPU/GPU\nresources. Surely the majority of nodes NOT running open ports are being\nrun on desktop systems.  It's likely that the vast majority of the\n\"normal/desktop\" user base are not going to setup dedicated machines to\nrun a full node full time.\n\nIt's likely that the vast majority of full nodes that are not running open\nports are used occasionally when the user wants to make a transaction or\n\"catch up\" with the blockchain.\n\nThat creates a divide between those who do have the resources to\ncontribute to the system on a full time basis (minority) and those who do\nnot (majority).\n\nDoes the power of p2p decentralization lie with the vast majority or the\n\"wealthy\" resource rich minority?\n\nHow will the move to 2MB hard fork affect the vast majority of nodes?\n\nFor example Debian unstable currently provides the following:\n\napt-cache  madison bitcoin-qt\nbitcoin-qt |   0.11.2-1 | http://ftp.lug.ro/debian/ unstable/main amd64\nPackages\n   bitcoin |   0.11.2-1 | http://ftp.lug.ro/debian/ unstable/main Sources\n\n\nThe rollout affect of the hard fork on the entire bitcoin ecosystem is a\ndifficult process to plan in advance. It's not viable to simply rely on\npress releases to encourage users to upgrade their nodes. The debacle with\nPulse Audio during the mid 2000's should be a lesson for those who seek\nthat route.\n\nCompare that to the requirements for spinning up \"bitcoin-2.0\" and\nenabling users to move their wallets to the new blockchain at their\nleisure.\n\nThe ecosystem doesn't suffer from instant degradation. Bitcoin \"brand\"\nloyalty will ensure that users who want to move forward with the economic\npotential of the 2MB blocksize will be able to keep their existing funds\nsafe while testing the waters with the new blocksize.\n\nAfter all Bitcoin is still the only game in town when it comes to scale\nand proven history of financial return.\n\nAs the new blockchain builds momentum the old one will eventually become\nobsolete. However it may also become the digital equivalency of Silver and\nthat is also a useful, profitable and viable alternative with a proven\nhistory of success.\n\n\n\n\n--\nPatrick Shirkey\nBoost Hardware Ltd"
            },
            {
                "author": "Danny Thorpe",
                "date": "2016-02-12T17:08:42",
                "message_text_only": "\"With a very powerful \"Desktop\" machine bitcoin-qt dominates CPU/GPU\nresources.\"\n\nThat doesn't match my experience.\n\nSystem responsiveness / user experience can suffer when running bitcoin-qt\non a spinning hard disk. Disk I/O load will cause the whole system to grind\nand severely disrupt the user experience.\n\nMove the Bitcoin data to an SSD, though, and it's an entirely different\nstory.\n\nThe initial blockchain synchronization / \"catch up\" is CPU and disk\nintensive, but after initial sync I find bitcoin-qt uses only a trivial\namount of CPU to keep up with verifying new blocks and new transactions.\n\nRunning bitcoin-qt occasionally is a much more painful user experience than\nrunning bitcoin-qt continuously.\n\nI'm running Bitcoin Core v0.12.rc2 on an old dual core Pentium E2160 at\n1.8GHz, 6GB RAM, 64 bit Windows 10, with the Bitcoin data on SSD. This\nsystem is about 6 years old and was an economy model even when new. Not\nwhat I would call a powerful system. I've only added RAM and the SSD.\n\nOn that machine I run two instances of Bitcoin-qt - one for mainnet, and\nanother for testnet, and an instance of bfgminer to manage a handful of USB\nBlock Eruptors for testnet mining. Both bitcoin-qt instances are typically\nat their max of 25 connections (each). Total CPU load floats around 11%,\nwith only occasional spikes to 40% for a few seconds.  The mainnet\nbitcoin-qt process uses about 700MB of RAM, testnet about 300MB.\n\nThis machine did fall into disk grinding paralysis during initial sync /\ncatchup with the v0.10 and v0.11 builds of bitcoin-qt, when the Bitcoin\ndata was on a spinning disk. Moving the Bitcoin data to an SSD drive had\nthe greatest impact on breaking the disk-bound whole-system paralysis.\nIncreasing the system RAM, upgrading to v0.12, and upgrading the OS to Win\n10 all contributed smaller improvements.\n\nIt is possible to run a full node on a small desktop machine concurrent\nwith user apps. Just get the Bitcoin data off of spinning media and onto\nSSD, make sure you have plenty of RAM, and leave bitcoin-qt running all the\ntime.\n\n-Danny\n\n\n\nOn Wed, Feb 10, 2016 at 11:03 PM, Patrick Shirkey via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> On Thu, February 11, 2016 8:15 am, Chris Belcher via bitcoin-dev wrote:\n> > I've been asked to post this to this mailing list too. It's time to\n> > clear up some misconceptions floating around about full nodes.\n> >\n> > === Myth: There are only about 5500 full nodes worldwide ===\n> >\n> > This number comes from this and similar sites: https://bitnodes.21.co/\n> > and it measured by trying to probe every nodes on their open ports.\n> >\n> > Problem is, not all nodes actually have open ports that can be probed.\n> > Either because they are behind firewalls or because their users have\n> > configured them to not listen for connections.\n> >\n> > Nobody knows how many full nodes there are, since many people don't know\n> > how to forward ports behind a firewall, and bandwidth can be costly, its\n> > quite likely that the number of nodes with closed ports is at least\n> > another several thousand.\n> >\n> > Nodes with open ports are able to upload blocks to new full nodes. In\n> > all other ways they are the same as nodes with closed ports. But because\n> > open-port-nodes can be measured and closed-port-nodes cannot, some\n> > members of the bitcoin community have been mistaken into believing that\n> > open-port-nodes are that matters.\n> >\n> > === Myth: This number of nodes matters and/or is too low. ===\n> >\n> > Nodes with open ports are useful to the bitcoin network because they\n> > help bootstrap new nodes by uploading historical blocks, they are a\n> > measure of bandwidth capacity. Right now there is no shortage of\n> > bandwidth capacity, and if there was it could be easily added by renting\n> > cloud servers.\n> >\n> > The problem is not bandwidth or connections, but trust, security and\n> > privacy. Let me explain.\n> >\n> > Full nodes are able to check that all of bitcoin's rules are being\n> > followed. Rules like following the inflation schedule, no double\n> > spending, no spending of coins that don't belong to the holder of the\n> > private key and all the other rules required to make bitcoin work (e.g.\n> > difficulty)\n> >\n> > Full nodes are what make bitcoin trustless. No longer do you have to\n> > trust a financial institution like a bank or paypal, you can simply run\n> > software on your own computer. To put simply, the only node that matters\n> > is the one you use.\n> >\n> > === Myth: There is no incentive to run nodes, the network relies on\n> > altruism ===\n> >\n> > It is very much in the individual bitcoin's users rational self interest\n> > to run a full node and use it as their wallet.\n> >\n> > Using a full node as your wallet is the only way to know for sure that\n> > none of bitcoin's rules have been broken. Rules like no coins were spent\n> > not belonging to the owner, that no coins were spent twice, that no\n> > inflation happens outside of the schedule and that all the rules needed\n> > to make the system work are followed  (e.g. difficulty.) All other kinds\n> > of wallet involve trusting a third party server.\n> >\n> > All these checks done by full nodes also increase the security. There\n> > are many attacks possible against lightweight wallets that do not affect\n> > full node wallets.\n> >\n> > This is not just mindless paranoia, there have been real world examples\n> > where full node users were unaffected by turmoil in the rest of the\n> > bitcoin ecosystem. The 4th July 2015 accidental chain fork effected many\n> > kinds of wallets. Here is the wiki page on this event\n> > https://en.bitcoin.it/wiki/July_2015_chain_forks#Wallet_Advice\n> >\n> > Notice how updated node software was completely unaffected by the fork.\n> > All other wallets required either extra confirmations or checking that\n> > the third-party institution was running the correct version.\n> >\n> > Full nodes wallets are also currently the most private way to use\n> > Bitcoin, with nobody else learning which bitcoin addresses belong to\n> > you. All other lightweight wallets leak information about which\n> > addresses are yours because they must query third-party servers. The\n> > Electrum servers will know which addresses belong to you and can link\n> > them together. Despite bloom filtering, lightweight wallets based on\n> > BitcoinJ do not provide much privacy against nodes who connected\n> > directly to the wallet or wiretappers.\n> >\n> > For many use cases, such privacy may not be required. But an important\n> > reason to run a full node and use it as a wallet is to get the full\n> > privacy benefits.\n> >\n> > === Myth: I can just set up a node on a cloud server instance and leave\n> > it ===\n> >\n> > To get the benefits of running a full node, you must use it as your\n> > wallet, preferably on hardware you control.\n> >\n> > Most people who do this do not use a full node as their wallet.\n> > Unfortunately because Bitcoin has a similar name to Bittorrent, some\n> > people believe that upload capacity is the most important thing for a\n> > healthy network. As I've explained above: bandwidth and connections are\n> > not a problem today, trust, security and privacy are.\n> >\n> > === Myth: Running a full node is not recommended, most people should use\n> > a lightweight client ===\n> >\n> > This was common advice in 2012, but since then the full node software\n> > has vastly improved in terms of user experience.\n> >\n> > If you cannot spare the disk space to store the blockchain, you can\n> > enable pruning as in:\n> > https://bitcoin.org/en/release/v0.11.0#block-file-pruning. In Bitcoin\n> > Core 0.12, pruning being enabled will leave the wallet enabled.\n> > Altogether this should require less than 1.5GB of hard disk space.\n> >\n> > If you cannot spare the bandwidth to upload blocks to other nodes, there\n> > are number of options to reduce or eliminate the bandwidth requirement\n> > found in https://bitcoin.org/en/full-node#reduce-traffic . These include\n> > limiting connections, bandwidth targetting and disabling listening.\n> > Bitcoin Core 0.12 has the new option -blocksonly, where the node will\n> > not download unconfirmed transaction and only download new blocks. This\n> > more than halves the bandwidth usage at the expense of not seeing\n> > unconfirmed transactions.\n> >\n> > Synchronizing the blockchain for a new node has improved since 2012 too.\n> > Features like headers-first\n> > (https://bitcoin.org/en/release/v0.10.0#faster-synchronization) and\n> > libsecp256k1 have greatly improved the initial synchronization time.\n> >\n> > It can be further improved by setting -dbcache=6000 which keeps more of\n> > the UTXO set in memory. It reduces the amount of time reading from disk\n> > and therefore speeds up synchronization. Tests showed that the entire\n> > blockchain can now be synchronized in less than _3 and a half hours_\n> > (See\n> > https://github.com/bitcoin/bitcoin/pull/6954#issuecomment-154993958)\n> > Note that you'll need Bitcoin Core 0.12 or later to get all these\n> > efficiency improvements.\n> >\n> > === How to run a full node as your wallet ===\n> >\n> > I think every moderate user of bitcoin would benefit by running a full\n> > node and using it as their wallet. There are several ways to do this.\n> >\n> > * Run a bitcoin-qt full node (https://bitcoin.org/en/download).\n> >\n> > * Use wallet software that is backed by a full node e.g. Armory\n> > (https://bitcoinarmory.com/) or JoinMarket\n> > (https://github.com/AdamISZ/JMBinary/#jmbinary)\n> >\n> > * Use a lightweight wallet that connects only to your full node (e.g.\n> > Multibit connecting only to your node running at home, Electrum\n> > connecting only to your own Electrum server)\n> >\n> > So what are you waiting for? The benefits are many, the downsides are\n> > not that bad. The more people do this, the more robust and healthy the\n> > bitcoin ecosystem is.\n> >\n> >\n>\n> This is very useful information but from my experience it is not viable to\n> have a full node running full time on a desktop system i.e sharing the\n> system with a normal desktop workload.\n>\n> With a very powerful \"Desktop\" machine bitcoin-qt dominates CPU/GPU\n> resources. Surely the majority of nodes NOT running open ports are being\n> run on desktop systems.  It's likely that the vast majority of the\n> \"normal/desktop\" user base are not going to setup dedicated machines to\n> run a full node full time.\n>\n> It's likely that the vast majority of full nodes that are not running open\n> ports are used occasionally when the user wants to make a transaction or\n> \"catch up\" with the blockchain.\n>\n> That creates a divide between those who do have the resources to\n> contribute to the system on a full time basis (minority) and those who do\n> not (majority).\n>\n> Does the power of p2p decentralization lie with the vast majority or the\n> \"wealthy\" resource rich minority?\n>\n> How will the move to 2MB hard fork affect the vast majority of nodes?\n>\n> For example Debian unstable currently provides the following:\n>\n> apt-cache  madison bitcoin-qt\n> bitcoin-qt |   0.11.2-1 | http://ftp.lug.ro/debian/ unstable/main amd64\n> Packages\n>    bitcoin |   0.11.2-1 | http://ftp.lug.ro/debian/ unstable/main Sources\n>\n>\n> The rollout affect of the hard fork on the entire bitcoin ecosystem is a\n> difficult process to plan in advance. It's not viable to simply rely on\n> press releases to encourage users to upgrade their nodes. The debacle with\n> Pulse Audio during the mid 2000's should be a lesson for those who seek\n> that route.\n>\n> Compare that to the requirements for spinning up \"bitcoin-2.0\" and\n> enabling users to move their wallets to the new blockchain at their\n> leisure.\n>\n> The ecosystem doesn't suffer from instant degradation. Bitcoin \"brand\"\n> loyalty will ensure that users who want to move forward with the economic\n> potential of the 2MB blocksize will be able to keep their existing funds\n> safe while testing the waters with the new blocksize.\n>\n> After all Bitcoin is still the only game in town when it comes to scale\n> and proven history of financial return.\n>\n> As the new blockchain builds momentum the old one will eventually become\n> obsolete. However it may also become the digital equivalency of Silver and\n> that is also a useful, profitable and viable alternative with a proven\n> history of success.\n>\n>\n>\n>\n> --\n> Patrick Shirkey\n> Boost Hardware Ltd\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160212/44d91731/attachment-0001.html>"
            },
            {
                "author": "Sean Greenslade",
                "date": "2016-02-13T06:20:06",
                "message_text_only": "On Thu, Feb 11, 2016 at 06:03:18PM +1100, Patrick Shirkey via bitcoin-dev wrote:\n> This is very useful information but from my experience it is not viable to\n> have a full node running full time on a desktop system i.e sharing the\n> system with a normal desktop workload.\n> \n> With a very powerful \"Desktop\" machine bitcoin-qt dominates CPU/GPU\n> resources. Surely the majority of nodes NOT running open ports are being\n> run on desktop systems.  It's likely that the vast majority of the\n> \"normal/desktop\" user base are not going to setup dedicated machines to\n> run a full node full time.\n\nI suspect you may be confusing full nodes with mining nodes. The two are\nnot directly synonymous. When running a full node in non-mining mode,\nthe CPU load is fairly light and the GPU is not touched at all. There is\na decent amount of RAM / disk used, but I've found that running a full\nnode on my low-power NAS box to be a nice way to use the extra idle CPU\ntime in a somewhat useful way (again, not mining). I've also run a full\nnode on a netbook without any trouble.\n\n> It's likely that the vast majority of full nodes that are not running open\n> ports are used occasionally when the user wants to make a transaction or\n> \"catch up\" with the blockchain.\n> \n> That creates a divide between those who do have the resources to\n> contribute to the system on a full time basis (minority) and those who do\n> not (majority).\n\nBitcoin is extremely tolerant of nodes entering and leaving the network\nat will. Even part time nodes help to improve the quality of the network\npurely by following the rules when passing on blocks / transactions\n(i.e. preventing the propogation of erroneous or invalid data and\nchecking the proof of work of all present chains)\n\n> Does the power of p2p decentralization lie with the vast majority or the\n> \"wealthy\" resource rich minority?\n> \n> How will the move to 2MB hard fork affect the vast majority of nodes?\n\nThey will need to upgrade, so yes it will affect every node.\n\n> The rollout affect of the hard fork on the entire bitcoin ecosystem is a\n> difficult process to plan in advance. It's not viable to simply rely on\n> press releases to encourage users to upgrade their nodes. The debacle with\n> Pulse Audio during the mid 2000's should be a lesson for those who seek\n> that route.\n\nThis has been thoroughly discussed in other threads. Hard forks are not\ndone on a whim.\n\n\n--Sean"
            }
        ],
        "thread_summary": {
            "title": "Clearing up some misconceptions about full nodes",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Chris Belcher",
                "Danny Thorpe",
                "Patrick Shirkey",
                "Sean Greenslade"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 31899
        }
    },
    {
        "title": "[bitcoin-dev] RFC for BIP: Best Practices for Heterogeneous Input Script Transactions",
        "thread_messages": [
            {
                "author": "Kristov Atlas",
                "date": "2016-02-10T21:36:05",
                "message_text_only": "BIP: TBD\nTitle: Best Practices for Heterogeneous Input Script Transactions\nAuthor: Kristov Atlas  <kristov at openbitcoinprivacyproject.org>\nStatus: Draft\nType: Informational\nCreated: 2016-02-10\n\n# Abstract\n\nThe privacy of Bitcoin users with respect to graph analysis is reduced when\na transaction is created that merges inputs composed from different\nscripts. However, creating such transactions is often unavoidable.\n\nThis document proposes a set of best practice guidelines which minimize the\nadverse privacy consequences of such unavoidable transaction situations\nwhile simultaneously maximising the effectiveness of privacy-improving\ntechniques such as CoinJoin.\n\n# Copyright\n\nThis BIP is in the public domain.\n\n# Definitions\n\nHeterogenous input script transaction (HIT): A transaction containing\nmultiple inputs where not all inputs have identical scripts (e.g. a\ntransaction spending from more than one Bitcoin address)\nUnavoidable heterogenous input script transaction: An HIT created as a\nresult of a user\u2019s desire to create a new output with a value larger than\nthe value of his wallet's largest unspent output\nIntentional heterogenous input script transaction: An HIT created as part\nof a protocol for improving user privacy against graph analysis, such as\nCoinJoin\n\n# Motivations\n\nThe recommendations in this document are designed to accomplish three goals:\n\n1. Maximise the effectiveness of privacy-enhancing transactions:\nPrivacy-sensitive users may find that techniques such as CoinJoin are\ncounterproductive if such transactions have a distinctive fingerprint which\nenables them to be censored or subjected to additional scrutiny.\n2. Minimise the adverse privacy consequences of unavoidable heterogenous\ninput transactions: If unavoidable HITs are indistinguishable from\nintentional HITs, a user creating an unavoidable HIT benefits from\nambiguity with respect to graph analysis.\n3. Limiting the effect on UTXO set growth: To date, non-standardized\nintentional HITs tend to increase the network's UTXO set with each\ntransaction; this standard attempts to minimize this effect by\nstandardizing unavoidable and intentional HITs to limit UTXO set growth.\nIn order to achieve these goals, this specification proposes a set of best\npractices for heterogenous input script transaction creation. These\npractices accommodate all applicable requirements of both intentional and\nunavoidable HITs and render the two types indistinguishable to the maximum\nextent possible.\nIn order to achieve this, two forms of HIT are proposed: Standard form and\nalternate form.\n\n# Standard form heterogenous input script transaction\n\n## Rules\n\nAn HIT is Standard form if it adheres to all of the following rules:\n\n1. The number of unique output scripts must be equal to the number of\nunique inputs scripts (irrespective of the number of inputs and outputs).\n2. All output scripts must be unique.\n3. At least one pair of outputs must be of equal value.\n4. The largest output in the transaction is a member of a set containing at\nleast two identically-sized outputs.\n\n## Rationale\n\nThe requirement for equal numbers of unique input/output scripts instead of\nequal number of inputs/outputs accommodates privacy-enhancing UTXO\nselection behavior. Wallets may contain spendable outputs with identical\nscripts due to intentional or accidental address reuse, or due to dusting\nattacks. In order to minimise the adverse privacy consequences of address\nreuse, any time a UTXO is included in a transaction as an input, all UTXOs\nwith the same spending script should also be included in the transaction.\n\nThe requirement that all output scripts are unique prevents address reuse.\nRestricting the number of outputs to the number of unique input scripts\nprevents this policy from growing the network\u2019s UTXO set. A standard form\nHIT transaction will always have a number of inputs greater than or equal\nto the number of outputs.\n\nThe requirement for at least one pair of outputs to be of equal value\nresults in optimal join transactions, and causes intentional HITs to\nresemble unavoidable HITs.\n\nOutside controlled laboratory conditions, join transactions will not\ninvolve identically-sized inputs due to a lack of accommodating volume.\nWithout the ability to cryptographically blind output values on the\nblockchain, every join transaction leaks information in the form of output\nsizes. Requiring a pair of identically sized outputs creates the desired\nambiguity for spend outputs, but in most cases makes change outputs\nlinkable to inputs.\n\n# Alternate form heterogenous input script transactions\n\nThe formation of a standard form HIT is not possible in the following cases:\n\nThe HIT is unavoidable, and the user\u2019s wallet contains an insufficient\nnumber or size of UTXOs to create a standard form HIT.\nThe user wishes to reduce the number of utxos in their wallet, and does not\nhave any sets of utxos with identical scripts.\nWhen one of the following cases exist, a compliant implementation may\ncreate an alternate form HIT by constructing a transaction as follows:\n\n## Procedure\n\n1. Find the smallest combination of inputs whose value is at least the\nvalue of the desired spend.\n  i. Add these inputs to the transaction.\n  ii. Add a spend output to the transaction.\n  iii. Add a change output to the transaction containing the difference\nbetween the current set of inputs and the desired spend.\n2. Repeat step 1 to create a second spend output and change output.\n3. Adjust the change outputs as necessary to pay the desired transaction\nfee.\n\nClients which create intentional HITs must have the capability to form\nalternate form HITs, and must do so for a non-zero fraction of the\ntransactions they create.\n\n# Non-compliant heterogenous input script transactions\n\nIf a user wishes to create an output that is larger than half the total\nsize of their spendable outputs, or if their inputs are not distributed in\na manner in which the alternate form procedure can be completed, then the\nuser can not create a transaction which is compliant with this procedure.\n\n----\n\nA working draft of this document is here:\nhttps://github.com/OpenBitcoinPrivacyProject/rfc/blob/master/bips/obpp-03.mediawiki\n\nA few points of anticipated discussion:\n\n1. It's possible for a CoinJoin transaction to decrease privacy by adhering\nto the Standard Form in this BIP, depending on the utxos available for\ncreating it. For example, a typical two-person CoinJoin might look like:\ninput_A, input_B => spend_A, change_A, spend_B, change_B\n\nIn order to comply with the standard form, one or more parties would have\nto add inputs to make this something like:\n\ninput_A_1, input_A_2, input_B_1, input_B_2 => spend_A, change_A, spend_B,\nchange_B.\n\nIf spend_A and spend_B are the same value, then input_A_1 and input_A_2 may\nbe linked based on the value of change_A and input_B_1 and input_B_2 may be\nlinked based on the value of change_B via sudoku analysis.\n\nIn that situation, wallets can opt to use the alternate form instead, or\nstick with the standard form but enjoy a non-utxo set increase and a\nsignificantly increased inter-transactional privacy set from other BIP\nadherents.\n\n2. In a naive simulation of a wallet randomly containing 1 to 10 utxos of\nrandom value 1 to 10 and a desired spend of random value between 1 and the\nsum of the utxos, the simulated wallet is able to create an alternate form\nHIT 40% of the time. If we assume that half of all desire spends are a\nvalue half or less of the total wallet balance, this improves to around\n60%. Unfortunately, I don't have any good data on what values are found in\naverage wallets and what desired spends look like on average.\n\n3. In the long-run it's better for all clients to participant in\nCoinJoin-like operations, but this should significantly increase the cost\nand decrease the signal of passive blockchain analysis attacks until that\nbecomes feasible.\n\nThanks in advance for your feedback.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160210/56f223bb/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "RFC for BIP: Best Practices for Heterogeneous Input Script Transactions",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Kristov Atlas"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 8086
        }
    },
    {
        "title": "[bitcoin-dev] BIP CPRKV: Check private key verify",
        "thread_messages": [
            {
                "author": "Tier Nolan",
                "date": "2016-02-11T20:05:15",
                "message_text_only": "There was some discussion on the bitcointalk forums about using CLTV for\ncross chain transfers.\n\nMany altcoins don't support CLTV, so transfers to those coins cannot be\nmade secure.\n\nI created a protocol.  It uses on cut and choose to allow commitments to\npublish private keys, but it is clunky and not entirely secure.\n\nI created a BIP draft for an opcode which would allow outputs to be locked\nunless a private key was published that matches a given public key.\n\nhttps://github.com/TierNolan/bips/blob/cpkv/bip-cprkv.mediawiki\n<https://www.avast.com/sig-email> This email has been sent from a\nvirus-free computer protected by Avast.\nwww.avast.com <https://www.avast.com/sig-email>\n<#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160211/161c3dd9/attachment.html>"
            },
            {
                "author": "Thomas Kerin",
                "date": "2016-02-11T22:20:33",
                "message_text_only": "I wonder if this is possible as a soft fork without using segwit?\nIncreasing the sigop count for a NOP would be a hard fork, but such a\nchange would be fine with a new segwit version. It might require specific\nsupport in the altcoin, which might be troublesome..\nOn 11 Feb 2016 20:05, \"Tier Nolan via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> There was some discussion on the bitcointalk forums about using CLTV for\n> cross chain transfers.\n>\n> Many altcoins don't support CLTV, so transfers to those coins cannot be\n> made secure.\n>\n> I created a protocol.  It uses on cut and choose to allow commitments to\n> publish private keys, but it is clunky and not entirely secure.\n>\n> I created a BIP draft for an opcode which would allow outputs to be locked\n> unless a private key was published that matches a given public key.\n>\n> https://github.com/TierNolan/bips/blob/cpkv/bip-cprkv.mediawiki\n> <https://www.avast.com/sig-email> This email has been sent from a\n> virus-free computer protected by Avast.\n> www.avast.com <https://www.avast.com/sig-email>\n> <#-1229186329_DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160211/1bf8b94b/attachment.html>"
            },
            {
                "author": "jl2012 at xbt.hk",
                "date": "2016-02-12T05:02:37",
                "message_text_only": "Seems it could be done without any new opcode:\n\n \n\nBob is trading b Bitcoins for a altcoins.\n\n \n\n1. Bob Pays D Bitcoins to\n\n \n\nIF\n\n<now+2days> CLTV DROP <Alice PK> CHECKSIG\n\nELSE\n\nHASH160 <hash secret B> EQUALVERIFY <Bob PK> CHECKSIG\n\nENDIF\n\n \n\n2. Alice pays a altcoins to\n\n \n\nIF\n\nHASH160 <hash secret B> EQUALVERIFY <Alice PK> CHECKSIG\n\nELSE\n\nHASH160 <hash secret A> EQUALVERIFY <Bob PK> CHECKSIG\n\nENDIF\n\n \n\n3. Bob pays b Bitcoins to\n\n \n\nIF\n\n<now+1days> CLTV DROP <Bob PK> CHECKSIG\n\nELSE\n\nHASH160 <hash secret A> EQUALVERIFY <Alice PK> CHECKSIG\n\nENDIF\n\n \n\n4. Alice claims output from step 3 and reveals secret A\n\n \n\n5. Bob claims output from step 2\n\n \n\n6. Bob claims output from step 1 and reveals secret B\n\n \n\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org [mailto:bitcoin-dev-bounces at lists.linuxfoundation.org] On Behalf Of Tier Nolan via bitcoin-dev\nSent: Friday, 12 February, 2016 04:05\nTo: Bitcoin Dev <bitcoin-dev at lists.linuxfoundation.org>\nSubject: [bitcoin-dev] BIP CPRKV: Check private key verify\n\n \n\nThere was some discussion on the bitcointalk forums about using CLTV for cross chain transfers.\n\nMany altcoins don't support CLTV, so transfers to those coins cannot be made secure.  \n\nI created a protocol.  It uses on cut and choose to allow commitments to publish private keys, but it is clunky and not entirely secure.\n\nI created a BIP draft for an opcode which would allow outputs to be locked unless a private key was published that matches a given public key.\n\n\nhttps://github.com/TierNolan/bips/blob/cpkv/bip-cprkv.mediawiki\n\n\n <https://www.avast.com/sig-email> \n\nThis email has been sent from a virus-free computer protected by Avast. \n <https://www.avast.com/sig-email> www.avast.com \n\n \n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160212/055b7677/attachment-0001.html>"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-02-12T10:05:08",
                "message_text_only": "On Fri, Feb 12, 2016 at 5:02 AM, <jl2012 at xbt.hk> wrote:\n\n> Seems it could be done without any new opcode:\n>\n\nThe assumption was that the altcoin would only accept standard output\nscripts.  Alice's payment in step 2 pays to a non-standard script.\n\nThis is an improvement over the cut and choose, but it will only work for\ncoins which allow non-standard scripts (type 2 in the BIP).\n\nI guess I was to focused on maintaining standard scripts on the altcoin.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160212/0b4e1726/attachment.html>"
            },
            {
                "author": "Mats Jerratsch",
                "date": "2016-02-29T10:58:06",
                "message_text_only": "This is actually very useful for LN too, see relevant discussion here\n\nhttp://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-November/011827.html\n\n2016-02-12 11:05 GMT+01:00 Tier Nolan via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org>:\n> On Fri, Feb 12, 2016 at 5:02 AM, <jl2012 at xbt.hk> wrote:\n>>\n>> Seems it could be done without any new opcode:\n>\n>\n> The assumption was that the altcoin would only accept standard output\n> scripts.  Alice's payment in step 2 pays to a non-standard script.\n>\n> This is an improvement over the cut and choose, but it will only work for\n> coins which allow non-standard scripts (type 2 in the BIP).\n>\n> I guess I was to focused on maintaining standard scripts on the altcoin.\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-02-29T11:52:39",
                "message_text_only": "On Mon, Feb 29, 2016 at 10:58 AM, Mats Jerratsch <matsjj at gmail.com> wrote:\n\n> This is actually very useful for LN too, see relevant discussion here\n>\n>\n> http://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-November/011827.html\n>\n\nIs there much demand for trying to code up a patch to the reference\nclient?  I did a basic one, but it would need tests etc. added.\n\nI think that segregated witness is going to be using up any potential\nsoft-fork slot for the time being anyway.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160229/f9ef54ca/attachment-0001.html>"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-02-11T23:04:37",
                "message_text_only": "On Thu, Feb 11, 2016 at 10:20 PM, Thomas Kerin <thomas.kerin at gmail.com>\nwrote:\n\n> I wonder if this is possible as a soft fork without using segwit?\nIncreasing the sigop count for a NOP would be a hard fork, but such a\nchange would be fine with a new segwit version. It might require specific\nsupport in the altcoin, which might be troublesome..\n\nIt is a soft fork since it makes things that were previous allowed\ndisallowed.  If it decreased the sigop count, then you could create a block\nthat had to many sigops due to the old rules.\n\nWith this rule, it increases the count.  If the sigop count is valid under\nthe new rules, it is also valid under the old rules.\n\nThere is no need for specific support on the altcoin.  It allows the\nBitcoin network act as trusted 3rd party so that you can do channels safely\non the altcoin, even though the altcoin still suffers from malleability and\ndoesn't have OP_CHECKLOCKTIMEVERIFY.\n\nWith regards to seg-witness, Ideally, the opcode would work in both old and\nnew scripts by re-purposing OP_NOP3.\n<https://www.avast.com/sig-email> This email has been sent from a\nvirus-free computer protected by Avast.\nwww.avast.com <https://www.avast.com/sig-email>\n<#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160211/05dd04fa/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP CPRKV: Check private key verify",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Thomas Kerin",
                "Tier Nolan",
                "Mats Jerratsch",
                "jl2012 at xbt.hk"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 7963
        }
    },
    {
        "title": "[bitcoin-dev] Soft fork fix for block withholding attacks",
        "thread_messages": [
            {
                "author": "gladoscc",
                "date": "2016-02-12T11:31:56",
                "message_text_only": "Here's a method of fixing block withholding attacks with a soft fork:\n\nWe require blocks to choose an arbitrary target, e.g. two bytes. We\nredefine the block PoW target to be \"less than the difficulty, with the\nlast two bytes being the target\".\n\nWe require blocks to include a blinded hash of the target plus some junk\n(which blinds it) in the coinbase. The miner cannot arbitrarily switch\ntargets.\n\nThe miner can now send the block header to hashers. Hashers do not know the\ntarget, and hence must submit all shares that matches the first PoW\ncriteria (below difficulty) and delegate secondary verification to the\nminer. With two bytes as the target, there are 65335 false positives for\nevery valid block.\n\nFinally, we require miners to communicate a proof of their target hash (ie,\nthe junk they generated) in a non-hashed area of the block. This can be a\nprotocol extension. The target is already included in the hash as the last\ntwo bytes.\n\nThis can be deployed as a soft fork with miner opt in, triggering across\nmany difficulty cycles. Initially, we soft fork to require the last bit of\nthe block hash to be zero. The next difficulty cycle, we require the last\ntwo bits to be zero. We do this 16 times to get 2 bytes, and then we\nactually activate targets.\n\nBy then, nominal difficulty would have been cut by 2^16 (65536), but the\nblock target makes mining each block 65536 times as hard. We do the\nprogression over 16 difficulty cycles to minimise increases in block\ntimings. We can be more specific and progress over even more difficulty\ncycles through more clever soft fork rules.\n\nFor example, Vitalik detailed \"timewalking\" attacks that allow effective\ngranular lowering of the nominal difficulty.\n\nCritique welcome.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160212/b16be954/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-02-12T15:34:53",
                "message_text_only": "On Fri, Feb 12, 2016 at 10:31:56PM +1100, gladoscc via bitcoin-dev wrote:\n> Here's a method of fixing block withholding attacks with a soft fork:\n\nSo, while you're technique I believe works, it's not a soft-fork, at\nleast under the definition most of the Bitcoin dev/research community\nhave been using.\n\nThe reason is if it's adopted by a majority of hashing power, less than\na majority of hashing power can create a chain that appears to be the\nmost-work chain, from the perspective of non-adopting nodes. Those nodes\nwould then be following a weaker chain.\n\nA better term for what you're proposing might be a \"pseudo-soft-fork\",\ngiven that you don't quite meet the requirements for a true soft-fork.\nHaving said that, it may be the case that overall your technique still\nreduces risk compared to a simpler hard-fork implementation of the idea;\nmore analysis is needed there.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n000000000000000006d243cee301d792809a7d4d00c13ac24b43d5e9548625e4\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160212/20a5a86c/attachment-0001.sig>"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-02-12T16:09:01",
                "message_text_only": "If clients were designed to warn their users when a soft fork happens, then\nit could be done reasonably safely.  The reference client does this (or is\nit just for high POW softforks?), but many SPV clients don't.\n\nIf there was a delay between version number changing and the rule\nactivation, at least nodes would get a warning recommending that they\nupdate.\n\n* At each difficulty interval, if 950 of the last 1000 blocks have the new\nversion number, reject the old version blocks from then on.\n\n* Start new target at 255, the least significant byte must be less than or\nequal to the target\n\n* Update target at each difficulty re-targetting\n\nT = ((T << 3) - T) >> 3\n\nThis increases the difficulty by around 12.5% per fortnight.   After 64\nweeks, the target would reach 0 and stay there meaning that the difficulty\nwould be 256 times higher than what is given in the header.\n\nAn attacker with 2% of the network power could create 5 blocks for every\nblock produced by the rest of the network.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160212/c954c6ff/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Soft fork fix for block withholding attacks",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Tier Nolan",
                "Peter Todd",
                "gladoscc"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 4359
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Core 0.12.0 release candidate 5 available",
        "thread_messages": [
            {
                "author": "Wladimir J. van der Laan",
                "date": "2016-02-15T11:10:39",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nBinaries for bitcoin Core version 0.12.0rc5 are available from:\n\n    https://bitcoin.org/bin/bitcoin-core-0.12.0/test/\n\nSource code can be found on github under the signed tag\n\n    https://github.com/bitcoin/bitcoin/tree/v0.12.0rc5\n\nThis is a release candidate for a new major version release, bringing new\nfeatures, bug fixes, as well as other improvements.\n\nPreliminary release notes for the release can be found here:\n\n    https://github.com/bitcoin/bitcoin/blob/0.12/doc/release-notes.md\n\nRelease candidates are test versions for releases. When no critical problems\nare found, this release candidate will be tagged as 0.12.0.\n\nDiff since rc3 (rc4 was DOA):\n\n- - #7472 `b2f2b85` rpc: Add WWW-Authenticate header to 401 response (Wladimir J. van der Laan)\n- - #7469 `9cb31e6` net.h fix spelling: misbeha{b,v}ing (Matt)\n- - #7482 `e16f5b4` Ensure headers count is correct (Suhas Daftuar)\n- - #7500 `889e5b3` Correctly report high-S violations (Pieter Wuille)\n- - #7491 `00ec73e` wallet: Ignore MarkConflict if block hash is not known (Wladimir J. van der Laan)\n- - #7502 `1329963` Update the wallet best block marker before pruning (Pieter Wuille)\n- - #7468 `947c4ff` [rpc-tests] Change solve() to use rehash (Brad Andrews)\n\nPlease report bugs using the issue tracker at github:\n\n    https://github.com/bitcoin/bitcoin/issues\n\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1\n\niQEcBAEBCgAGBQJWwbHqAAoJEHSBCwEjRsmmVJwH/3gvb5LAAL88R7ZbcKAzehdc\nBnAmCTWX+mJENWq9MX3OWmddetbZSBU0x9MzV6atQHMTmcxmMkCIzZrysoSq3uDg\n1IylViVPSr+36PPv2k1/chTun0yRWUGwLEz09JZscFILa0oJODvDISiOp0NEkDup\nbewkpkrpzxroAqlTFNuSUl9KDCQPXUGvqCDH7RwHC3D8L8apVIT6bE8FHW8je278\nQjf3Z5AehXVzOyrhg02tT0Ow3EueKtNDASmopX+aM70ErzUbxe8/mYP3GAsQwbMi\nWVdx7dvUdQQkNDIWGLH/V0AJlkbxDfBmAI0Ti2J9LxtbCOZdGAzId2aPpEOrfnU=\n=UUfq\n-----END PGP SIGNATURE-----"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Core 0.12.0 release candidate 5 available",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Wladimir J. van der Laan"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1849
        }
    },
    {
        "title": "[bitcoin-dev] [BIP Proposal] New \"feefilter\" p2p message",
        "thread_messages": [
            {
                "author": "Alex Morcos",
                "date": "2016-02-16T20:20:26",
                "message_text_only": "Hi,\n\nI'm proposing the addition of a new optional p2p message to help reduce\nunnecessary network traffic.  The draft BIP is available here and pasted\nbelow:\nhttps://gist.github.com/morcos/9aab223c443c9258c979\n\nThe goal of this message is to take advantage of the fact that when a node\nhas reached its mempool limit, there is a minimum fee below which no\ntransactions are accepted to the mempool.  Informing peers of this minimum\nwould save them inv'ing your node for those transaction id's and save your\nnode requesting them if they are not in your recentRejects filter.\n\nThis message is optional and may be ignored as a protocol rule.  There is\nalso an option to turn off sending the messages in the implementation.\n\nThanks to Suhas Daftuar, Greg Maxwell, and others for helping develop the\nidea.\n\n-Alex\n\nDraft BIP text:\n\n<pre>\n  BIP: <unassigned>\n  Title: feefilter message\n  Author: Alex Morcos <morcos at chaincode.com>\n  Status: Draft\n  Type: Standards Track\n  Created: 2016-02-13\n</pre>\n\n==Abstract==\n\nAdd a new message, \"feefilter\", which serves to instruct peers not to send\n\"inv\"'s to the node for transactions with fees below the specified fee rate.\n\n==Motivation==\n\nThe concept of a limited mempool was introduced in Bitcoin Core 0.12 to\nprovide protection against attacks or spam transactions of low fees that\nare not being mined. A reject filter was also introduced to help prevent\nrepeated requests for the same transaction that might have been recently\nrejected for insufficient fee. These methods help keep resource utilization\non a node from getting out of control.\n\nHowever, there are limitations to the effectiveness of these approaches.\nThe reject filter is reset after every block which means transactions that\nare inv'ed over a longer time period will be rerequested and there is no\nmethod to prevent requesting the transaction the first time.  Furthermore,\ninv data is sent at least once either to or from each peer for every\ntransaction accepted to the mempool and there is no mechanism by which to\nknow that an inv sent to a given peer would not result in a getdata request\nbecause it represents a transaction with too little fee.\n\nAfter receiving a feefilter message, a node can know before sending an inv\nthat a given transaction's fee rate is below the minimum currently required\nby a given peer, and therefore the node can skip relaying an inv for that\ntransaction to that peer.\n\n==Specification==\n\n# The feefilter message is defined as a message containing an int64_t where\npchCommand == \"feefilter\"\n# Upon receipt of a \"feefilter\" message, the node will be permitted, but\nnot required, to filter transaction invs for transactions that fall below\nthe feerate provided in the feefilter message interpreted as satoshis per\nkilobyte.\n# The fee filter is additive with a bloom filter for transactions so if an\nSPV client were to load a bloom filter and send a feefilter message,\ntransactions would only be relayed if they passed both filters.\n# Inv's generated from a mempool message are also subject to a fee filter\nif it exists.\n# Feature discovery is enabled by checking protocol version >= 70013\n\n==Considerations==\nThe propagation efficiency of transactions across the network should not be\nadversely affected by this change. In general, transactions which are not\naccepted to your mempool are not relayed and the funcionality implemented\nwith this message is meant only to filter those transactions.  There could\nbe a small number of edge cases where a node's mempool min fee is actually\nless than the filter value a peer is aware of and transactions with fee\nrates between these values will now be newly inhibited.\n\nFeefilter messages are not sent to whitelisted peers if the\n\"-whitelistforcerelay\" option is set. In that case, transactions are\nintended to be relayed even if they are not accepted to the mempool.\n\nThere are privacy concerns with deanonymizing a node by the fact that it is\nbroadcasting identifying information about its mempool min fee. To help\nameliorate this concern, the implementaion quantizes the filter value\nbroadcast with a small amount of randomness, in addition, the messages are\nbroadcast to different peers at individually randomly distributed times.\n\nIf a node is using prioritisetransaction to accept transactions whose\nactual fee rates might fall below the node's mempool min fee, it may want\nto consider setting \"-nofeefilter\" to make sure it is exposed to all\npossible txid's.\n\n==Backward compatibility==\n\nOlder clients remain fully compatible and interoperable after this change.\nThe sending of feefilter messages can be disabled by unsetting the\n\"-feefilter\" option.\n\n==Implementation==\n\nhttps://github.com/bitcoin/bitcoin/pull/7542\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160216/88e18afc/attachment-0001.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-17T00:46:16",
                "message_text_only": "On Tuesday, February 16, 2016 8:20:26 PM Alex Morcos via bitcoin-dev wrote:\n> # The feefilter message is defined as a message containing an int64_t where\n> pchCommand == \"feefilter\"\n\nWhat happened to extensibility? And why waste 64 bits for what is almost \ncertainly a small number?\n\n> # The fee filter is additive with a bloom filter for transactions so if an\n> SPV client were to load a bloom filter and send a feefilter message,\n> transactions would only be relayed if they passed both filters.\n\nThis seems to make feefilter entirely useless for wallets?\n\nLuke"
            },
            {
                "author": "Alex Morcos",
                "date": "2016-02-17T02:28:31",
                "message_text_only": "On Tue, Feb 16, 2016 at 6:46 PM, Luke Dashjr <luke at dashjr.org> wrote:\n\n> On Tuesday, February 16, 2016 8:20:26 PM Alex Morcos via bitcoin-dev wrote:\n> > # The feefilter message is defined as a message containing an int64_t\n> where\n> > pchCommand == \"feefilter\"\n>\n> What happened to extensibility? And why waste 64 bits for what is almost\n> certainly a small number?\n>\n\nI thought that extensibility was already sufficient with the command string\nsystem.  If we come up with a better version of the feefilter later we can\njust give it a different command name.  This seemed to encapsulate a fairly\ncomplete idea for now.  As for the 8 bytes, it didn't seem necessary to me\nto over optimize with a custom encoding for what amounts to well under 20%\nof ping traffic.  (pings are sent every 2 mins per peer, feefilters on\naverage every 10 mins, but when the quantized value to be sent would be the\nsame it is skipped)\n\n\n> > # The fee filter is additive with a bloom filter for transactions so if\n> an\n> > SPV client were to load a bloom filter and send a feefilter message,\n> > transactions would only be relayed if they passed both filters.\n>\n> This seems to make feefilter entirely useless for wallets?\n>\n>\nI don't follow this comment?  Transactions aren't synced with the wallet\nunless they are accepted into the mempool.  Sending feefilter messages\nshould not reduce the number of transactions that are accepted to the\nmempool.\n\n\n> Luke\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160216/08d950a6/attachment.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-17T02:36:09",
                "message_text_only": "On Wednesday, February 17, 2016 2:28:31 AM Alex Morcos wrote:\n> On Tue, Feb 16, 2016 at 6:46 PM, Luke Dashjr <luke at dashjr.org> wrote:\n> > On Tuesday, February 16, 2016 8:20:26 PM Alex Morcos via bitcoin-dev \nwrote:\n> > > # The feefilter message is defined as a message containing an int64_t\n> > \n> > where\n> > \n> > > pchCommand == \"feefilter\"\n> > \n> > What happened to extensibility? And why waste 64 bits for what is almost\n> > certainly a small number?\n> \n> I thought that extensibility was already sufficient with the command string\n> system.  If we come up with a better version of the feefilter later we can\n> just give it a different command name.\n\nWe shouldn't need a new protocol [extension] for every new policy. Obviously \nthis can't be perfectly flexible, but supporting different feerate definition \nversions is trivial and obvious.\n\n> > > # The fee filter is additive with a bloom filter for transactions so if\n> > an\n> > > SPV client were to load a bloom filter and send a feefilter message,\n> > > transactions would only be relayed if they passed both filters.\n> > \n> > This seems to make feefilter entirely useless for wallets?\n> \n> I don't follow this comment?  Transactions aren't synced with the wallet\n> unless they are accepted into the mempool.  Sending feefilter messages\n> should not reduce the number of transactions that are accepted to the\n> mempool.\n\nIn Core, they aren't (but Core never uses bloom filters anyway) - because \notherwise it would leak privacy. But light clients (particularly overlapping \nwith those that use bloom filters!) have no privacy in the first place, so \nthey have no reason to use this rule.\n\nLuke"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2016-02-17T02:43:02",
                "message_text_only": "On Wed, Feb 17, 2016 at 12:46 AM, Luke Dashjr via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> On Tuesday, February 16, 2016 8:20:26 PM Alex Morcos via bitcoin-dev wrote:\n>> # The feefilter message is defined as a message containing an int64_t where\n>> pchCommand == \"feefilter\"\n>\n> What happened to extensibility?\n\nI did think it might be interesting to do a priorityrate filter. but\nsince it seems no one is even working on adding an index for ancestor\npriorityrate... or working on a space limited priority mempool... if\nthat extension would be needed it could just be a new \"priorityfilt\"\ncommand.\n\n> And why waste 64 bits for what is almost\n> certainly a small number?\n\nTechnically fees per byte could be greater than 32 bits (e.g. a 9000\nBTC fee is enough). Values are normally 64 bits already.\n\n>> # The fee filter is additive with a bloom filter for transactions so if an\n>> SPV client were to load a bloom filter and send a feefilter message,\n>> transactions would only be relayed if they passed both filters.\n>\n> This seems to make feefilter entirely useless for wallets?\n\nI think your reasoning is that you want to learn of your own\ntransactions even if they don't meet the filter?\n\nI'm not sure this reasoning plays out though-- regardless of what your\nown feefilter is, if a tx has too low a rate for your peers to relay\nit, they won't and you won't learn of it.\n\nI might wave my hands at a use case for OR \"I will relay very high fee\ntxn ... or my own\"; but considering that performance/privacy disaster\nthat bloom filters are-- and that to relay third party txn at all you\nneed to be able to validate them (or will get yourself banned).  Also,\nif you really want the OR behavior you could make two connections...\nthe same cannot be said for and.\n\nMaybe one argument I could add is that if we added a priorityrate\nfilter, that one would be an OR"
            }
        ],
        "thread_summary": {
            "title": "New \"feefilter\" p2p message",
            "categories": [
                "bitcoin-dev",
                "BIP Proposal"
            ],
            "authors": [
                "Luke Dashjr",
                "Alex Morcos",
                "Gregory Maxwell"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 10608
        }
    },
    {
        "title": "[bitcoin-dev] Sig-Witness and legacy outputs",
        "thread_messages": [
            {
                "author": "Tier Nolan",
                "date": "2016-02-18T16:14:19",
                "message_text_only": "I wrote a bip last year about extended transaction information.  The idea\nwas to include the scriptPubKey that was being spent along with\ntransactions.\n\nhttps://github.com/TierNolan/bips/blob/extended_transactions/bip-etx.mediawiki\n\nThis makes it easier possible to verify the transactions locally.  An\nextended transaction would contain the current transaction and also the\nCTxOuts that are being spent.\n\nFor each entry in the UTXO set, a node could store\n\nUTXO_hash = hash(txid_parent | n | CTxOut)\n\nWitness transactions will do something similar.  I wonder if it would be\npossible to include the CTxOut for each input that isn't a segregated\nwitness output, as part of the witness data.  Even for witness data, it\nwould be good to commit to the value of the output as part of the witness.\n\nThere was a suggestion at one of the conferences to have the witness data\ninclude info about the block height/index of the output that each input is\nspending.\n\nThe effect of this change is that nodes would only have to store the\nUTXO_hashes for each UTXO value in the database.  This would make it much\nmore efficient.\n\nIt would also make it easier to create a simple consensus library.  You\ngive the library the transaction and the witness and it returns the\nUTXO_hashes that are spent, the UTXO_hashes that are created, the fee,\nsigops and anything that needs to be summed.\n\nValidating a block would mostly (famous last words) mean validating the\ntransactions in the block and then adding up the totals.\n\nThe advantage of including the info with the transactions is that it saves\neach node having to include a lookup table to find the data.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160218/231703a0/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Sig-Witness and legacy outputs",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Tier Nolan"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1818
        }
    },
    {
        "title": "[bitcoin-dev] New paper: On Bitcoin Security in the Presence of Broken Crypto Primitives",
        "thread_messages": [
            {
                "author": "Ethan Heilman",
                "date": "2016-02-22T18:06:56",
                "message_text_only": "\"*Abstract: *Digital currencies like Bitcoin rely on cryptographic\nprimitives to operate. However, past experience shows that cryptographic\nprimitives do not last forever: increased computational power and advanced\ncryptanalysis cause primitives to break frequently, and motivate the\ndevelopment of new ones. It is therefore crucial for maintaining trust in a\ncrypto currency to anticipate such breakage.\nWe present the first systematic analysis of the effect of broken primitives\non Bitcoin. We identify the core cryptographic building blocks and analyze\nthe various ways in which they can break, and the subsequent effect on the\nmain Bitcoin security guarantees. Our analysis reveals a wide range of\npossible effects depending on the primitive and type of breakage, ranging\nfrom minor privacy violations to a complete breakdown of the currency.\nOur results lead to several observations on, and suggestions for, the\nBitcoin migration plans in case of broken cryptographic primitives.\"\n\nhttps://eprint.iacr.org/2016/167\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160222/f19be77c/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "New paper: On Bitcoin Security in the Presence of Broken Crypto Primitives",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Ethan Heilman"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1202
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Core 0.12.0 released",
        "thread_messages": [
            {
                "author": "Wladimir J. van der Laan",
                "date": "2016-02-23T11:13:41",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nBitcoin Core version 0.12.0 is now available from:\n\n  <https://bitcoin.org/bin/bitcoin-core-0.12.0/>\n\nOr through bittorrent:\n\n   magnet:?xt=urn:btih:e6c0cd47cce75e53b04c1c575a39d2022612d1d6&dn=bitcoin-core-0.12.0&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.publicbt.com%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.ccc.de%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969&tr=udp%3A%2F%2Ftracker.leechers-paradise.org%3A6969&ws=https%3A%2F%2Fbitcoin.org%2Fbin%2F\n\nThis is a new major version release, bringing new features and other improvements.\n\nSee the full release announcement here:\n\n  <https://bitcoincore.org/en/2016/02/23/release-0.12.0/>\n\nPlease report bugs using the issue tracker at github:\n\n  <https://github.com/bitcoin/bitcoin/issues>\n\nUpgrading and downgrading\n=========================\n\nHow to Upgrade\n- --------------\n\nIf you are running an older version, shut it down. Wait until it has completely\nshut down (which might take a few minutes for older versions), then run the\ninstaller (on Windows) or just copy over /Applications/Bitcoin-Qt (on Mac) or\nbitcoind/bitcoin-qt (on Linux).\n\nDowngrade warning\n- -----------------\n\n### Downgrade to a version < 0.10.0\n\nBecause release 0.10.0 and later makes use of headers-first synchronization and\nparallel block download (see further), the block files and databases are not\nbackwards-compatible with pre-0.10 versions of Bitcoin Core or other software:\n\n* Blocks will be stored on disk out of order (in the order they are\nreceived, really), which makes it incompatible with some tools or\nother programs. Reindexing using earlier versions will also not work\nanymore as a result of this.\n\n* The block index database will now hold headers for which no block is\nstored on disk, which earlier versions won't support.\n\nIf you want to be able to downgrade smoothly, make a backup of your entire data\ndirectory. Without this your node will need start syncing (or importing from\nbootstrap.dat) anew afterwards. It is possible that the data from a completely\nsynchronised 0.10 node may be usable in older versions as-is, but this is not\nsupported and may break as soon as the older version attempts to reindex.\n\nThis does not affect wallet forward or backward compatibility.\n\n### Downgrade to a version < 0.12.0\n\nBecause release 0.12.0 and later will obfuscate the chainstate on every\nfresh sync or reindex, the chainstate is not backwards-compatible with\npre-0.12 versions of Bitcoin Core or other software.\n\nIf you want to downgrade after you have done a reindex with 0.12.0 or later,\nyou will need to reindex when you first start Bitcoin Core version 0.11 or\nearlier.\n\nNotable changes\n===============\n\nSignature validation using libsecp256k1\n- ---------------------------------------\n\nECDSA signatures inside Bitcoin transactions now use validation using\n[https://github.com/bitcoin/secp256k1](libsecp256k1) instead of OpenSSL.\n\nDepending on the platform, this means a significant speedup for raw signature\nvalidation speed. The advantage is largest on x86_64, where validation is over\nfive times faster. In practice, this translates to a raw reindexing and new\nblock validation times that are less than half of what it was before.\n\nLibsecp256k1 has undergone very extensive testing and validation.\n\nA side effect of this change is that libconsensus no longer depends on OpenSSL.\n\nReduce upload traffic\n- ---------------------\n\nA major part of the outbound traffic is caused by serving historic blocks to\nother nodes in initial block download state.\n\nIt is now possible to reduce the total upload traffic via the `-maxuploadtarget`\nparameter. This is *not* a hard limit but a threshold to minimize the outbound\ntraffic. When the limit is about to be reached, the uploaded data is cut by not\nserving historic blocks (blocks older than one week).\nMoreover, any SPV peer is disconnected when they request a filtered block.\n\nThis option can be specified in MiB per day and is turned off by default\n(`-maxuploadtarget=0`).\nThe recommended minimum is 144 * MAX_BLOCK_SIZE (currently 144MB) per day.\n\nWhitelisted peers will never be disconnected, although their traffic counts for\ncalculating the target.\n\nA more detailed documentation about keeping traffic low can be found in\n[/doc/reduce-traffic.md](/doc/reduce-traffic.md).\n\nDirect headers announcement (BIP 130)\n- -------------------------------------\n\nBetween compatible peers, [BIP 130]\n(https://github.com/bitcoin/bips/blob/master/bip-0130.mediawiki)\ndirect headers announcement is used. This means that blocks are advertized by\nannouncing their headers directly, instead of just announcing the hash. In a\nreorganization, all new headers are sent, instead of just the new tip. This\ncan often prevent an extra roundtrip before the actual block is downloaded.\n\nWith this change, pruning nodes are now able to relay new blocks to compatible\npeers.\n\nMemory pool limiting\n- --------------------\n\nPrevious versions of Bitcoin Core had their mempool limited by checking\na transaction's fees against the node's minimum relay fee. There was no\nupper bound on the size of the mempool and attackers could send a large\nnumber of transactions paying just slighly more than the default minimum\nrelay fee to crash nodes with relatively low RAM. A temporary workaround\nfor previous versions of Bitcoin Core was to raise the default minimum\nrelay fee.\n\nBitcoin Core 0.12 will have a strict maximum size on the mempool. The\ndefault value is 300 MB and can be configured with the `-maxmempool`\nparameter. Whenever a transaction would cause the mempool to exceed\nits maximum size, the transaction that (along with in-mempool descendants) has\nthe lowest total feerate (as a package) will be evicted and the node's effective\nminimum relay feerate will be increased to match this feerate plus the initial\nminimum relay feerate. The initial minimum relay feerate is set to\n1000 satoshis per kB.\n\nBitcoin Core 0.12 also introduces new default policy limits on the length and\nsize of unconfirmed transaction chains that are allowed in the mempool\n(generally limiting the length of unconfirmed chains to 25 transactions, with a\ntotal size of 101 KB).  These limits can be overriden using command line\narguments; see the extended help (`--help -help-debug`) for more information.\n\nOpt-in Replace-by-fee transactions\n- ----------------------------------\n\nIt is now possible to replace transactions in the transaction memory pool of\nBitcoin Core 0.12 nodes. Bitcoin Core will only allow replacement of\ntransactions which have any of their inputs' `nSequence` number set to less\nthan `0xffffffff - 1`.  Moreover, a replacement transaction may only be\naccepted when it pays sufficient fee, as described in [BIP 125]\n(https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki).\n\nTransaction replacement can be disabled with a new command line option,\n`-mempoolreplacement=0`.  Transactions signaling replacement under BIP125 will\nstill be allowed into the mempool in this configuration, but replacements will\nbe rejected.  This option is intended for miners who want to continue the\ntransaction selection behavior of previous releases.\n\nThe `-mempoolreplacement` option is *not recommended* for wallet users seeking\nto avoid receipt of unconfirmed opt-in transactions, because this option does\nnot prevent transactions which are replaceable under BIP 125 from being accepted\n(only subsequent replacements, which other nodes on the network that implement\nBIP 125 are likely to relay and mine).  Wallet users wishing to detect whether\na transaction is subject to replacement under BIP 125 should instead use the\nupdated RPC calls `gettransaction` and `listtransactions`, which now have an\nadditional field in the output indicating if a transaction is replaceable under\nBIP125 (\"bip125-replaceable\").\n\nNote that the wallet in Bitcoin Core 0.12 does not yet have support for\ncreating transactions that would be replaceable under BIP 125.\n\n\nRPC: Random-cookie RPC authentication\n- -------------------------------------\n\nWhen no `-rpcpassword` is specified, the daemon now uses a special 'cookie'\nfile for authentication. This file is generated with random content when the\ndaemon starts, and deleted when it exits. Its contents are used as\nauthentication token. Read access to this file controls who can access through\nRPC. By default it is stored in the data directory but its location can be\noverridden with the option `-rpccookiefile`.\n\nThis is similar to Tor's CookieAuthentication: see\nhttps://www.torproject.org/docs/tor-manual.html.en\n\nThis allows running bitcoind without having to do any manual configuration.\n\nRelay: Any sequence of pushdatas in OP_RETURN outputs now allowed\n- -----------------------------------------------------------------\n\nPreviously OP_RETURN outputs with a payload were only relayed and mined if they\nhad a single pushdata. This restriction has been lifted to allow any\ncombination of data pushes and numeric constant opcodes (OP_1 to OP_16) after\nthe OP_RETURN. The limit on OP_RETURN output size is now applied to the entire\nserialized scriptPubKey, 83 bytes by default. (the previous 80 byte default plus\nthree bytes overhead)\n\nRelay and Mining: Priority transactions\n- ---------------------------------------\n\nBitcoin Core has a heuristic 'priority' based on coin value and age. This\ncalculation is used for relaying of transactions which do not pay the\nminimum relay fee, and can be used as an alternative way of sorting\ntransactions for mined blocks. Bitcoin Core will relay transactions with\ninsufficient fees depending on the setting of `-limitfreerelay=<r>` (default:\n`r=15` kB per minute) and `-blockprioritysize=<s>`.\n\nIn Bitcoin Core 0.12, when mempool limit has been reached a higher minimum\nrelay fee takes effect to limit memory usage. Transactions which do not meet\nthis higher effective minimum relay fee will not be relayed or mined even if\nthey rank highly according to the priority heuristic.\n\nThe mining of transactions based on their priority is also now disabled by\ndefault. To re-enable it, simply set `-blockprioritysize=<n>` where is the size\nin bytes of your blocks to reserve for these transactions. The old default was\n50k, so to retain approximately the same policy, you would set\n`-blockprioritysize=50000`.\n\nAdditionally, as a result of computational simplifications, the priority value\nused for transactions received with unconfirmed inputs is lower than in prior\nversions due to avoiding recomputing the amounts as input transactions confirm.\n\nExternal miner policy set via the `prioritisetransaction` RPC to rank\ntransactions already in the mempool continues to work as it has previously.\nNote, however, that if mining priority transactions is left disabled, the\npriority delta will be ignored and only the fee metric will be effective.\n\nThis internal automatic prioritization handling is being considered for removal\nentirely in Bitcoin Core 0.13, and it is at this time undecided whether the\nmore accurate priority calculation for chained unconfirmed transactions will be\nrestored. Community direction on this topic is particularly requested to help\nset project priorities.\n\nAutomatically use Tor hidden services\n- -------------------------------------\n\nStarting with Tor version 0.2.7.1 it is possible, through Tor's control socket\nAPI, to create and destroy 'ephemeral' hidden services programmatically.\nBitcoin Core has been updated to make use of this.\n\nThis means that if Tor is running (and proper authorization is available),\nBitcoin Core automatically creates a hidden service to listen on, without\nmanual configuration. Bitcoin Core will also use Tor automatically to connect\nto other .onion nodes if the control socket can be successfully opened. This\nwill positively affect the number of available .onion nodes and their usage.\n\nThis new feature is enabled by default if Bitcoin Core is listening, and\na connection to Tor can be made. It can be configured with the `-listenonion`,\n`-torcontrol` and `-torpassword` settings. To show verbose debugging\ninformation, pass `-debug=tor`.\n\nNotifications through ZMQ\n- -------------------------\n\nBitcoind can now (optionally) asynchronously notify clients through a\nZMQ-based PUB socket of the arrival of new transactions and blocks.\nThis feature requires installation of the ZMQ C API library 4.x and\nconfiguring its use through the command line or configuration file.\nPlease see [docs/zmq.md](/doc/zmq.md) for details of operation.\n\nWallet: Transaction fees\n- ------------------------\n\nVarious improvements have been made to how the wallet calculates\ntransaction fees.\n\nUsers can decide to pay a predefined fee rate by setting `-paytxfee=<n>`\n(or `settxfee <n>` rpc during runtime). A value of `n=0` signals Bitcoin\nCore to use floating fees. By default, Bitcoin Core will use floating\nfees.\n\nBased on past transaction data, floating fees approximate the fees\nrequired to get into the `m`th block from now. This is configurable\nwith `-txconfirmtarget=<m>` (default: `2`).\n\nSometimes, it is not possible to give good estimates, or an estimate\nat all. Therefore, a fallback value can be set with `-fallbackfee=<f>`\n(default: `0.0002` BTC/kB).\n\nAt all times, Bitcoin Core will cap fees at `-maxtxfee=<x>` (default:\n0.10) BTC.\nFurthermore, Bitcoin Core will never create transactions smaller than\nthe current minimum relay fee.\nFinally, a user can set the minimum fee rate for all transactions with\n`-mintxfee=<i>`, which defaults to 1000 satoshis per kB.\n\nWallet: Negative confirmations and conflict detection\n- -----------------------------------------------------\n\nThe wallet will now report a negative number for confirmations that indicates\nhow deep in the block chain the conflict is found. For example, if a transaction\nA has 5 confirmations and spends the same input as a wallet transaction B, B\nwill be reported as having -5 confirmations. If another wallet transaction C\nspends an output from B, it will also be reported as having -5 confirmations.\nTo detect conflicts with historical transactions in the chain a one-time\n`-rescan` may be needed.\n\nUnlike earlier versions, unconfirmed but non-conflicting transactions will never\nget a negative confirmation count. They are not treated as spendable unless\nthey're coming from ourself (change) and accepted into our local mempool,\nhowever. The new \"trusted\" field in the `listtransactions` RPC output\nindicates whether outputs of an unconfirmed transaction are considered\nspendable.\n\nWallet: Merkle branches removed\n- -------------------------------\n\nPreviously, every wallet transaction stored a Merkle branch to prove its\npresence in blocks. This wasn't being used for more than an expensive\nsanity check. Since 0.12, these are no longer stored. When loading a\n0.12 wallet into an older version, it will automatically rescan to avoid\nfailed checks.\n\nWallet: Pruning\n- ---------------\n\nWith 0.12 it is possible to use wallet functionality in pruned mode.\nThis can reduce the disk usage from currently around 60 GB to\naround 2 GB.\n\nHowever, rescans as well as the RPCs `importwallet`, `importaddress`,\n`importprivkey` are disabled.\n\nTo enable block pruning set `prune=<N>` on the command line or in\n`bitcoin.conf`, where `N` is the number of MiB to allot for\nraw block & undo data.\n\nA value of 0 disables pruning. The minimal value above 0 is 550. Your\nwallet is as secure with high values as it is with low ones. Higher\nvalues merely ensure that your node will not shut down upon blockchain\nreorganizations of more than 2 days - which are unlikely to happen in\npractice. In future releases, a higher value may also help the network\nas a whole: stored blocks could be served to other nodes.\n\nFor further information about pruning, you may also consult the [release\nnotes of v0.11.0](https://github.com/bitcoin/bitcoin/blob/v0.11.0/doc/release-notes.md#block-file-pruning).\n\n`NODE_BLOOM` service bit\n- ------------------------\n\nSupport for the `NODE_BLOOM` service bit, as described in [BIP\n111](https://github.com/bitcoin/bips/blob/master/bip-0111.mediawiki), has been\nadded to the P2P protocol code.\n\nBIP 111 defines a service bit to allow peers to advertise that they support\nbloom filters (such as used by SPV clients) explicitly. It also bumps the protocol\nversion to allow peers to identify old nodes which allow bloom filtering of the\nconnection despite lacking the new service bit.\n\nIn this version, it is only enforced for peers that send protocol versions\n`>=70011`. For the next major version it is planned that this restriction will be\nremoved. It is recommended to update SPV clients to check for the `NODE_BLOOM`\nservice bit for nodes that report versions newer than 70011.\n\nOption parsing behavior\n- -----------------------\n\nCommand line options are now parsed strictly in the order in which they are\nspecified. It used to be the case that `-X -noX` ends up, unintuitively, with X\nset, as `-X` had precedence over `-noX`. This is no longer the case. Like for\nother software, the last specified value for an option will hold.\n\nRPC: Low-level API changes\n- --------------------------\n\n- - Monetary amounts can be provided as strings. This means that for example the\n  argument to sendtoaddress can be \"0.0001\" instead of 0.0001. This can be an\n  advantage if a JSON library insists on using a lossy floating point type for\n  numbers, which would be dangerous for monetary amounts.\n\n* The `asm` property of each scriptSig now contains the decoded signature hash\n  type for each signature that provides a valid defined hash type.\n\n* OP_NOP2 has been renamed to OP_CHECKLOCKTIMEVERIFY by [BIP 65](https://github.com/bitcoin/bips/blob/master/bip-0065.mediawiki)\n\nThe following items contain assembly representations of scriptSig signatures\nand are affected by this change:\n\n- - RPC `getrawtransaction`\n- - RPC `decoderawtransaction`\n- - RPC `decodescript`\n- - REST `/rest/tx/` (JSON format)\n- - REST `/rest/block/` (JSON format when including extended tx details)\n- - `bitcoin-tx -json`\n\nFor example, the `scriptSig.asm` property of a transaction input that\npreviously showed an assembly representation of:\n\n    304502207fa7a6d1e0ee81132a269ad84e68d695483745cde8b541e3bf630749894e342a022100c1f7ab20e13e22fb95281a870f3dcf38d782e53023ee313d741ad0cfbc0c509001 400000 OP_NOP2\n\nnow shows as:\n\n    304502207fa7a6d1e0ee81132a269ad84e68d695483745cde8b541e3bf630749894e342a022100c1f7ab20e13e22fb95281a870f3dcf38d782e53023ee313d741ad0cfbc0c5090[ALL] 400000 OP_CHECKLOCKTIMEVERIFY\n\nNote that the output of the RPC `decodescript` did not change because it is\nconfigured specifically to process scriptPubKey and not scriptSig scripts.\n\nRPC: SSL support dropped\n- ------------------------\n\nSSL support for RPC, previously enabled by the option `rpcssl` has been dropped\nfrom both the client and the server. This was done in preparation for removing\nthe dependency on OpenSSL for the daemon completely.\n\nTrying to use `rpcssl` will result in an error:\n\n    Error: SSL mode for RPC (-rpcssl) is no longer supported.\n\nIf you are one of the few people that relies on this feature, a flexible\nmigration path is to use `stunnel`. This is an utility that can tunnel\narbitrary TCP connections inside SSL. On e.g. Ubuntu it can be installed with:\n\n    sudo apt-get install stunnel4\n\nThen, to tunnel a SSL connection on 28332 to a RPC server bound on localhost on port 18332 do:\n\n    stunnel -d 28332 -r 127.0.0.1:18332 -p stunnel.pem -P ''\n\nIt can also be set up system-wide in inetd style.\n\nAnother way to re-attain SSL would be to setup a httpd reverse proxy. This solution\nwould allow the use of different authentication, loadbalancing, on-the-fly compression and\ncaching. A sample config for apache2 could look like:\n\n    Listen 443\n\n    NameVirtualHost *:443\n    <VirtualHost *:443>\n\n    SSLEngine On\n    SSLCertificateFile /etc/apache2/ssl/server.crt\n    SSLCertificateKeyFile /etc/apache2/ssl/server.key\n\n    <Location /bitcoinrpc>\n        ProxyPass http://127.0.0.1:8332/\n        ProxyPassReverse http://127.0.0.1:8332/\n        # optional enable digest auth\n        # AuthType Digest\n        # ...\n\n        # optional bypass bitcoind rpc basic auth\n        # RequestHeader set Authorization \"Basic <hash>\"\n        # get the <hash> from the shell with: base64 <<< bitcoinrpc:<password>\n    </Location>\n\n    # Or, balance the load:\n    # ProxyPass / balancer://balancer_cluster_name\n\n    </VirtualHost>\n\nMining Code Changes\n- -------------------\n\nThe mining code in 0.12 has been optimized to be significantly faster and use less\nmemory. As part of these changes, consensus critical calculations are cached on a\ntransaction's acceptance into the mempool and the mining code now relies on the\nconsistency of the mempool to assemble blocks. However all blocks are still tested\nfor validity after assembly.\n\nOther P2P Changes\n- -----------------\n\nThe list of banned peers is now stored on disk rather than in memory.\nRestarting bitcoind will no longer clear out the list of banned peers; instead\na new RPC call (`clearbanned`) can be used to manually clear the list.  The new\n`setban` RPC call can also be used to manually ban or unban a peer.\n\n0.12.0 Change log\n=================\n\nDetailed release notes follow. This overview includes changes that affect\nbehavior, not code moves, refactors and string updates. For convenience in locating\nthe code changes and accompanying discussion, both the pull request and\ngit merge commit are mentioned.\n\n### RPC and REST\n\n- - #6121 `466f0ea` Convert entire source tree from json_spirit to UniValue (Jonas Schnelli)\n- - #6234 `d38cd47` fix rpcmining/getblocktemplate univalue transition logic error (Jonas Schnelli)\n- - #6239 `643114f` Don't go through double in AmountFromValue and ValueFromAmount (Wladimir J. van der Laan)\n- - #6266 `ebab5d3` Fix univalue handling of \\u0000 characters. (Daniel Kraft)\n- - #6276 `f3d4dbb` Fix getbalance * 0 (Tom Harding)\n- - #6257 `5ebe7db` Add `paytxfee` and `errors` JSON fields where appropriate (Stephen)\n- - #6271 `754aae5` New RPC command disconnectnode (Alex van der Peet)\n- - #6158 `0abfa8a` Add setban/listbanned RPC commands (Jonas Schnelli)\n- - #6307 `7ecdcd9` rpcban fixes (Jonas Schnelli)\n- - #6290 `5753988` rpc: make `gettxoutsettinfo` run lock-free (Wladimir J. van der Laan)\n- - #6262 `247b914` Return all available information via RPC call \"validateaddress\" (dexX7)\n- - #6339 `c3f0490` UniValue: don't escape solidus, keep espacing of reverse solidus (Jonas Schnelli)\n- - #6353 `6bcb0a2` Show softfork status in getblockchaininfo (Wladimir J. van der Laan)\n- - #6247 `726e286` Add getblockheader RPC call (Peter Todd)\n- - #6362 `d6db115` Fix null id in RPC response during startup (Forrest Voight)\n- - #5486 `943b322` [REST] JSON support for /rest/headers (Jonas Schnelli)\n- - #6379 `c52e8b3` rpc: Accept scientific notation for monetary amounts in JSON (Wladimir J. van der Laan)\n- - #6388 `fd5dfda` rpc: Implement random-cookie based authentication (Wladimir J. van der Laan)\n- - #6457 `3c923e8` Include pruned state in chaininfo.json (Simon Males)\n- - #6456 `bfd807f` rpc: Avoid unnecessary parsing roundtrip in number formatting, fix locale issue (Wladimir J. van der Laan)\n- - #6380 `240b30e` rpc: Accept strings in AmountFromValue (Wladimir J. van der Laan)\n- - #6346 `6bb2805` Add OP_RETURN support in createrawtransaction RPC call, add tests. (paveljanik)\n- - #6013 `6feeec1` [REST] Add memory pool API (paveljanik)\n- - #6576 `da9beb2` Stop parsing JSON after first finished construct. (Daniel Kraft)\n- - #5677 `9aa9099` libevent-based http server (Wladimir J. van der Laan)\n- - #6633 `bbc2b39` Report minimum ping time in getpeerinfo (Matt Corallo)\n- - #6648 `cd381d7` Simplify logic of REST request suffix parsing. (Daniel Kraft)\n- - #6695 `5e21388` libevent http fixes (Wladimir J. van der Laan)\n- - #5264 `48efbdb` show scriptSig signature hash types in transaction decodes. fixes #3166 (mruddy)\n- - #6719 `1a9f19a` Make HTTP server shutdown more graceful (Wladimir J. van der Laan)\n- - #6859 `0fbfc51` http: Restrict maximum size of http + headers (Wladimir J. van der Laan)\n- - #5936 `bf7c195` [RPC] Add optional locktime to createrawtransaction (Tom Harding)\n- - #6877 `26f5b34` rpc: Add maxmempool and effective min fee to getmempoolinfo (Wladimir J. van der Laan)\n- - #6970 `92701b3` Fix crash in validateaddress with -disablewallet (Wladimir J. van der Laan)\n- - #5574 `755b4ba` Expose GUI labels in RPC as comments (Luke-Jr)\n- - #6990 `dbd2c13` http: speed up shutdown (Wladimir J. van der Laan)\n- - #7013 `36baa9f` Remove LOCK(cs_main) from decodescript (Peter Todd)\n- - #6999 `972bf9c` add (max)uploadtarget infos to getnettotals RPC help (Jonas Schnelli)\n- - #7011 `31de241` Add mediantime to getblockchaininfo (Peter Todd)\n- - #7065 `f91e29f` http: add Boost 1.49 compatibility (Wladimir J. van der Laan)\n- - #7087 `be281d8` [Net]Add -enforcenodebloom option (Patrick Strateman)\n- - #7044 `438ee59` RPC: Added additional config option for multiple RPC users. (Gregory Sanders)\n- - #7072 `c143c49` [RPC] Add transaction size to JSON output (Nikita Zhavoronkov)\n- - #7022 `9afbd96` Change default block priority size to 0 (Alex Morcos)\n- - #7141 `c0c08c7` rpc: Don't translate warning messages (Wladimir J. van der Laan)\n- - #7312 `fd4bd50` Add RPC call abandontransaction (Alex Morcos)\n- - #7222 `e25b158` RPC: indicate which transactions are replaceable (Suhas Daftuar)\n- - #7472 `b2f2b85` rpc: Add WWW-Authenticate header to 401 response (Wladimir J. van der Laan)\n- - #7469 `9cb31e6` net.h fix spelling: misbeha{b,v}ing (Matt)\n\n### Configuration and command-line options\n\n- - #6164 `8d05ec7` Allow user to use -debug=1 to enable all debugging (lpescher)\n- - #5288 `4452205` Added -whiteconnections=<n> option (Josh Lehan)\n- - #6284 `10ac38e` Fix argument parsing oddity with -noX (Wladimir J. van der Laan)\n- - #6489 `c9c017a` Give a better error message if system clock is bad (Casey Rodarmor)\n- - #6462 `c384800` implement uacomment config parameter which can add comments to user agent as per BIP-0014 (Pavol Rusnak)\n- - #6647 `a3babc8` Sanitize uacomment (MarcoFalke)\n- - #6742 `3b2d37c` Changed logging to make -logtimestamps to work also for -printtoconsole (arnuschky)\n- - #6846 `2cd020d` alias -h for -help (Daniel Cousens)\n- - #6622 `7939164` Introduce -maxuploadtarget (Jonas Schnelli)\n- - #6881 `2b62551` Debug: Add option for microsecond precision in debug.log (Suhas Daftuar)\n- - #6776 `e06c14f` Support -checkmempool=N, which runs checks once every N transactions (Pieter Wuille)\n- - #6896 `d482c0a` Make -checkmempool=1 not fail through int32 overflow (Pieter Wuille)\n- - #6993 `b632145` Add -blocksonly option (Patrick Strateman)\n- - #7323 `a344880` 0.12: Backport -bytespersigop option (Luke-Jr)\n- - #7386 `da83ecd` Add option `-permitrbf` to set transaction replacement policy (Wladimir J. van der Laan)\n- - #7290 `b16b5bc` Add missing options help (MarcoFalke)\n- - #7440 `c76bfff` Rename permitrbf to mempoolreplacement and provide minimal string-list forward compatibility (Luke-Jr)\n\n### Block and transaction handling\n\n- - #6203 `f00b623` Remove P2SH coinbase flag, no longer interesting (Luke-Jr)\n- - #6222 `9c93ee5` Explicitly set tx.nVersion for the genesis block and mining tests (Mark Friedenbach)\n- - #5985 `3a1d3e8` Fix removing of orphan transactions (Alex Morcos)\n- - #6221 `dd8fe82` Prune: Support noncontiguous block files (Adam Weiss)\n- - #6124 `41076aa` Mempool only CHECKLOCKTIMEVERIFY (BIP65) verification, unparameterized version (Peter Todd)\n- - #6329 `d0a10c1` acceptnonstdtxn option to skip (most) \"non-standard transaction\" checks, for testnet/regtest only (Luke-Jr)\n- - #6410 `7cdefb9` Implement accurate memory accounting for mempool (Pieter Wuille)\n- - #6444 `24ce77d` Exempt unspendable transaction outputs from dust checks (dexX7)\n- - #5913 `a0625b8` Add absurdly high fee message to validation state (Shaul Kfir)\n- - #6177 `2f746c6` Prevent block.nTime from decreasing (Mark Friedenbach)\n- - #6377 `e545371` Handle no chain tip available in InvalidChainFound() (Ross Nicoll)\n- - #6551 `39ddaeb` Handle leveldb::DestroyDB() errors on wipe failure (Adam Weiss)\n- - #6654 `b0ce450` Mempool package tracking (Suhas Daftuar)\n- - #6715 `82d2aef` Fix mempool packages (Suhas Daftuar)\n- - #6680 `4f44530` use CBlockIndex instead of uint256 for UpdatedBlockTip signal (Jonas Schnelli)\n- - #6650 `4fac576` Obfuscate chainstate (James O'Beirne)\n- - #6777 `9caaf6e` Unobfuscate chainstate data in CCoinsViewDB::GetStats (James O'Beirne)\n- - #6722 `3b20e23` Limit mempool by throwing away the cheapest txn and setting min relay fee to it (Matt Corallo)\n- - #6889 `38369dd` fix locking issue with new mempool limiting (Jonas Schnelli)\n- - #6464 `8f3b3cd` Always clean up manual transaction prioritization (Casey Rodarmor)\n- - #6865 `d0badb9` Fix chainstate serialized_size computation (Pieter Wuille)\n- - #6566 `ff057f4` BIP-113: Mempool-only median time-past as endpoint for lock-time calculations (Mark Friedenbach)\n- - #6934 `3038eb6` Restores mempool only BIP113 enforcement (Gregory Maxwell)\n- - #6965 `de7d459` Benchmark sanity checks and fork checks in ConnectBlock (Matt Corallo)\n- - #6918 `eb6172a` Make sigcache faster, more efficient, larger (Pieter Wuille)\n- - #6771 `38ed190` Policy: Lower default limits for tx chains (Alex Morcos)\n- - #6932 `73fa5e6` ModifyNewCoins saves database lookups (Alex Morcos)\n- - #5967 `05d5918` Alter assumptions in CCoinsViewCache::BatchWrite (Alex Morcos)\n- - #6871 `0e93586` nSequence-based Full-RBF opt-in (Peter Todd)\n- - #7008 `eb77416` Lower bound priority (Alex Morcos)\n- - #6915 `2ef5ffa` [Mempool] Improve removal of invalid transactions after reorgs (Suhas Daftuar)\n- - #6898 `4077ad2` Rewrite CreateNewBlock (Alex Morcos)\n- - #6872 `bdda4d5` Remove UTXO cache entries when the tx they were added for is removed/does not enter mempool (Matt Corallo)\n- - #7062 `12c469b` [Mempool] Fix mempool limiting and replace-by-fee for PrioritiseTransaction (Suhas Daftuar)\n- - #7276 `76de36f` Report non-mandatory script failures correctly (Pieter Wuille)\n- - #7217 `e08b7cb` Mark blocks with too many sigops as failed (Suhas Daftuar)\n- - #7387 `f4b2ce8` Get rid of inaccurate ScriptSigArgsExpected (Pieter Wuille)\n\n### P2P protocol and network code\n\n- - #6172 `88a7ead` Ignore getheaders requests when not synced (Suhas Daftuar)\n- - #5875 `9d60602` Be stricter in processing unrequested blocks (Suhas Daftuar)\n- - #6256 `8ccc07c` Use best header chain timestamps to detect partitioning (Gavin Andresen)\n- - #6283 `a903ad7` make CAddrMan::size() return the correct type of size_t (Diapolo)\n- - #6272 `40400d5` Improve proxy initialization (continues #4871) (Wladimir J. van der Laan, Diapolo)\n- - #6310 `66e5465` banlist.dat: store banlist on disk (Jonas Schnelli)\n- - #6412 `1a2de32` Test whether created sockets are select()able (Pieter Wuille)\n- - #6498 `219b916` Keep track of recently rejected transactions with a rolling bloom filter (cont'd) (Peter Todd)\n- - #6556 `70ec975` Fix masking of irrelevant bits in address groups. (Alex Morcos)\n- - #6530 `ea19c2b` Improve addrman Select() performance when buckets are nearly empty (Pieter Wuille)\n- - #6583 `af9305a` add support for miniupnpc api version 14 (Pavel Vasin)\n- - #6374 `69dc5b5` Connection slot exhaustion DoS mitigation (Patrick Strateman)\n- - #6636 `536207f` net: correctly initialize nMinPingUsecTime (Wladimir J. van der Laan)\n- - #6579 `0c27795` Add NODE_BLOOM service bit and bump protocol version (Matt Corallo)\n- - #6148 `999c8be` Relay blocks when pruning (Suhas Daftuar)\n- - #6588 `cf9bb11` In (strCommand == \"tx\"), return if AlreadyHave() (Tom Harding)\n- - #6974 `2f71b07` Always allow getheaders from whitelisted peers (Wladimir J. van der Laan)\n- - #6639 `bd629d7` net: Automatically create hidden service, listen on Tor (Wladimir J. van der Laan)\n- - #6984 `9ffc687` don't enforce maxuploadtarget's disconnect for whitelisted peers (Jonas Schnelli)\n- - #7046 `c322652` Net: Improve blocks only mode. (Patrick Strateman)\n- - #7090 `d6454f6` Connect to Tor hidden services by default (when listening on Tor) (Peter Todd)\n- - #7106 `c894fbb` Fix and improve relay from whitelisted peers (Pieter Wuille)\n- - #7129 `5d5ef3a` Direct headers announcement (rebase of #6494) (Pieter Wuille)\n- - #7079 `1b5118b` Prevent peer flooding inv request queue (redux) (redux) (Gregory Maxwell)\n- - #7166 `6ba25d2` Disconnect on mempool requests from peers when over the upload limit. (Gregory Maxwell)\n- - #7133 `f31955d` Replace setInventoryKnown with a rolling bloom filter (rebase of #7100) (Pieter Wuille)\n- - #7174 `82aff88` Don't do mempool lookups for \"mempool\" command without a filter (Matt Corallo)\n- - #7179 `44fef99` net: Fix sent reject messages for blocks and transactions (Wladimir J. van der Laan)\n- - #7181 `8fc174a` net: Add and document network messages in protocol.h (Wladimir J. van der Laan)\n- - #7125 `10b88be` Replace global trickle node with random delays (Pieter Wuille)\n- - #7415 `cb83beb` net: Hardcoded seeds update January 2016 (Wladimir J. van der Laan)\n- - #7438 `e2d9a58` Do not absolutely protect local peers; decide group ties based on time (Gregory Maxwell)\n- - #7439 `86755bc` Add whitelistforcerelay to control forced relaying. [#7099 redux] (Gregory Maxwell)\n- - #7482 `e16f5b4` Ensure headers count is correct (Suhas Daftuar)\n\n### Validation\n\n- - #5927 `8d9f0a6` Reduce checkpoints' effect on consensus. (Pieter Wuille)\n- - #6299 `24f2489` Bugfix: Don't check the genesis block header before accepting it (Jorge Tim\u00f3n)\n- - #6361 `d7ada03` Use real number of cores for default -par, ignore virtual cores (Wladimir J. van der Laan)\n- - #6519 `87f37e2` Make logging for validation optional (Wladimir J. van der Laan)\n- - #6351 `2a1090d` CHECKLOCKTIMEVERIFY (BIP65) IsSuperMajority() soft-fork (Peter Todd)\n- - #6931 `54e8bfe` Skip BIP 30 verification where not necessary (Alex Morcos)\n- - #6954 `e54ebbf` Switch to libsecp256k1-based ECDSA validation (Pieter Wuille)\n- - #6508 `61457c2` Switch to a constant-space Merkle root/branch algorithm. (Pieter Wuille)\n- - #6914 `327291a` Add pre-allocated vector type and use it for CScript (Pieter Wuille)\n- - #7500 `889e5b3` Correctly report high-S violations (Pieter Wuille)\n\n\n### Build system\n\n- - #6210 `0e4f2a0` build: disable optional use of gmp in internal secp256k1 build (Wladimir J. van der Laan)\n- - #6214 `87406aa` [OSX] revert renaming of Bitcoin-Qt.app and use CFBundleDisplayName (partial revert of #6116) (Jonas Schnelli)\n- - #6218 `9d67b10` build/gitian misc updates (Cory Fields)\n- - #6269 `d4565b6` gitian: Use the new bitcoin-detached-sigs git repo for OSX signatures (Cory Fields)\n- - #6418 `d4a910c` Add autogen.sh to source tarball. (randy-waterhouse)\n- - #6373 `1ae3196` depends: non-qt bumps for 0.12 (Cory Fields)\n- - #6434 `059b352` Preserve user-passed CXXFLAGS with --enable-debug (Gavin Andresen)\n- - #6501 `fee6554` Misc build fixes (Cory Fields)\n- - #6600 `ef4945f` Include bitcoin-tx binary on Debian/Ubuntu (Zak Wilcox)\n- - #6619 `4862708` depends: bump miniupnpc and ccache (Michael Ford)\n- - #6801 `ae69a75` [depends] Latest config.guess and config.sub (Michael Ford)\n- - #6938 `193f7b5` build: If both Qt4 and Qt5 are installed, use Qt5 (Wladimir J. van der Laan)\n- - #7092 `348b281` build: Set osx permissions in the dmg to make Gatekeeper happy (Cory Fields)\n- - #6980 `eccd671` [Depends] Bump Boost, miniupnpc, ccache & zeromq (Michael Ford)\n- - #7424 `aa26ee0` Add security/export checks to gitian and fix current failures (Cory Fields)\n\n### Wallet\n\n- - #6183 `87550ee` Fix off-by-one error w/ nLockTime in the wallet (Peter Todd)\n- - #6057 `ac5476e` re-enable wallet in autoprune (Jonas Schnelli)\n- - #6356 `9e6c33b` Delay initial pruning until after wallet init (Adam Weiss)\n- - #6088 `91389e5` fundrawtransaction (Matt Corallo)\n- - #6415 `ddd8d80` Implement watchonly support in fundrawtransaction (Matt Corallo)\n- - #6567 `0f0f323` Fix crash when mining with empty keypool. (Daniel Kraft)\n- - #6688 `4939eab` Fix locking in GetTransaction. (Alex Morcos)\n- - #6645 `4dbd43e` Enable wallet key imports without rescan in pruned mode. (Gregory Maxwell)\n- - #6550 `5b77244` Do not store Merkle branches in the wallet. (Pieter Wuille)\n- - #5924 `12a7712` Clean up change computation in CreateTransaction. (Daniel Kraft)\n- - #6906 `48b5b84` Reject invalid pubkeys when reading ckey items from the wallet. (Gregory Maxwell)\n- - #7010 `e0a5ef8` Fix fundrawtransaction handling of includeWatching (Peter Todd)\n- - #6851 `616d61b` Optimisation: Store transaction list order in memory rather than compute it every need (Luke-Jr)\n- - #6134 `e92377f` Improve usage of fee estimation code (Alex Morcos)\n- - #7103 `a775182` [wallet, rpc tests] Fix settxfee, paytxfee (MarcoFalke)\n- - #7105 `30c2d8c` Keep track of explicit wallet conflicts instead of using mempool (Pieter Wuille)\n- - #7096 `9490bd7` [Wallet] Improve minimum absolute fee GUI options (Jonas Schnelli)\n- - #6216 `83f06ca` Take the training wheels off anti-fee-sniping (Peter Todd)\n- - #4906 `96e8d12` Issue#1643: Coinselection prunes extraneous inputs from ApproximateBestSubset (Murch)\n- - #7200 `06c6a58` Checks for null data transaction before issuing error to debug.log (Andy Craze)\n- - #7296 `a36d79b` Add sane fallback for fee estimation (Alex Morcos)\n- - #7293 `ff9b610` Add regression test for vValue sort order (MarcoFalke)\n- - #7306 `4707797` Make sure conflicted wallet tx's update balances (Alex Morcos)\n- - #7381 `621bbd8` [walletdb] Fix syntax error in key parser (MarcoFalke)\n- - #7491 `00ec73e` wallet: Ignore MarkConflict if block hash is not known (Wladimir J. van der Laan)\n- - #7502 `1329963` Update the wallet best block marker before pruning (Pieter Wuille)\n\n### GUI\n\n- - #6217 `c57e12a` disconnect peers from peers tab via context menu (Diapolo)\n- - #6209 `ab0ec67` extend rpc console peers tab (Diapolo)\n- - #6484 `1369d69` use CHashWriter also in SignVerifyMessageDialog (Pavel Vasin)\n- - #6487 `9848d42` Introduce PlatformStyle (Wladimir J. van der Laan)\n- - #6505 `100c9d3` cleanup icons (MarcoFalke)\n- - #4587 `0c465f5` allow users to set -onion via GUI (Diapolo)\n- - #6529 `c0f66ce` show client user agent in debug window (Diapolo)\n- - #6594 `878ea69` Disallow duplicate windows. (Casey Rodarmor)\n- - #5665 `6f55cdd` add verifySize() function to PaymentServer (Diapolo)\n- - #6317 `ca5e2a1` minor optimisations in peertablemodel (Diapolo)\n- - #6315 `e59d2a8` allow banning and unbanning over UI->peers table (Jonas Schnelli)\n- - #6653 `e04b2fa` Pop debug window in foreground when opened twice (MarcoFalke)\n- - #6864 `c702521` Use monospace font (MarcoFalke)\n- - #6887 `3694b74` Update coin control and smartfee labels (MarcoFalke)\n- - #7000 `814697c` add shortcurts for debug-/console-window (Jonas Schnelli)\n- - #6951 `03403d8` Use maxTxFee instead of 10000000 (MarcoFalke)\n- - #7051 `a190777` ui: Add \"Copy raw transaction data\" to transaction list context menu (Wladimir J. van der Laan)\n- - #6979 `776848a` simple mempool info in debug window (Jonas Schnelli)\n- - #7006 `26af1ac` add startup option to reset Qt settings (Jonas Schnelli)\n- - #6780 `2a94cd6` Call init's parameter interaction before we create the UI options model (Jonas Schnelli)\n- - #7112 `96b8025` reduce cs_main locks during tip update, more fluently update UI (Jonas Schnelli)\n- - #7206 `f43c2f9` Add \"NODE_BLOOM\" to guiutil so that peers don't get UNKNOWN[4] (Matt Corallo)\n- - #7282 `5cadf3e` fix coincontrol update issue when deleting a send coins entry (Jonas Schnelli)\n- - #7319 `1320300` Intro: Display required space (Jonas Schnelli)\n- - #7318 `9265e89` quickfix for RPC timer interface problem (Jonas Schnelli)\n- - #7327 `b16b5bc` [Wallet] Transaction View: LastMonth calculation fixed (crowning-)\n- - #7364 `7726c48` [qt] Windows: Make rpcconsole monospace font larger (MarcoFalke)\n- - #7384 `294f432` [qt] Peertable: Increase SUBVERSION_COLUMN_WIDTH (MarcoFalke)\n\n### Tests and QA\n\n- - #6305 `9005c91` build: comparison tool swap (Cory Fields)\n- - #6318 `e307e13` build: comparison tool NPE fix (Cory Fields)\n- - #6337 `0564c5b` Testing infrastructure: mocktime fixes (Gavin Andresen)\n- - #6350 `60abba1` add unit tests for the decodescript rpc (mruddy)\n- - #5881 `3203a08` Fix and improve txn_doublespend.py test (Tom Harding)\n- - #6390 `6a73d66` tests: Fix bitcoin-tx signing test case (Wladimir J. van der Laan)\n- - #6368 `7fc25c2` CLTV: Add more tests to improve coverage (Esteban Ordano)\n- - #6414 `5121c68` Fix intermittent test failure, reduce test time (Tom Harding)\n- - #6417 `44fa82d` [QA] fix possible reorg issue in (fund)rawtransaction(s).py RPC test (Jonas Schnelli)\n- - #6398 `3d9362d` rpc: Remove chain-specific RequireRPCPassword (Wladimir J. van der Laan)\n- - #6428 `bb59e78` tests: Remove old sh-based test framework (Wladimir J. van der Laan)\n- - #5515 `d946e9a` RFC: Assert on probable deadlocks if the second lock isnt try_lock (Matt Corallo)\n- - #6287 `d2464df` Clang lock debug (Cory Fields)\n- - #6465 `410fd74` Don't share objects between TestInstances (Casey Rodarmor)\n- - #6534 `6c1c7fd` Fix test locking issues and un-revert the probable-deadlines assertions commit (Cory Fields)\n- - #6509 `bb4faee` Fix race condition on test node shutdown (Casey Rodarmor)\n- - #6523 `561f8af` Add p2p-fullblocktest.py (Casey Rodarmor)\n- - #6590 `981fd92` Fix stale socket rebinding and re-enable python tests for Windows (Cory Fields)\n- - #6730 `cb4d6d0` build: Remove dependency of bitcoin-cli on secp256k1 (Wladimir J. van der Laan)\n- - #6616 `5ab5dca` Regression Tests: Migrated rpc-tests.sh to all Python rpc-tests.py (Peter Tschipper)\n- - #6720 `d479311` Creates unittests for addrman, makes addrman more testable. (Ethan Heilman)\n- - #6853 `c834f56` Added fPowNoRetargeting field to Consensus::Params (Eric Lombrozo)\n- - #6827 `87e5539` [rpc-tests] Check return code (MarcoFalke)\n- - #6848 `f2c869a` Add DERSIG transaction test cases (Ross Nicoll)\n- - #6813 `5242bb3` Support gathering code coverage data for RPC tests with lcov (dexX7)\n- - #6888 `c8322ff` Clear strMiscWarning before running PartitionAlert (Eric Lombrozo)\n- - #6894 `2675276` [Tests] Fix BIP65 p2p test (Suhas Daftuar)\n- - #6863 `725539e` [Test Suite] Fix test for null tx input (Daniel Kraft)\n- - #6926 `a6d0d62` tests: Initialize networking on windows (Wladimir J. van der Laan)\n- - #6822 `9fa54a1` [tests] Be more strict checking dust (MarcoFalke)\n- - #6804 `5fcc14e` [tests] Add basic coverage reporting for RPC tests (James O'Beirne)\n- - #7045 `72dccfc` Bugfix: Use unique autostart filenames on Linux for testnet/regtest (Luke-Jr)\n- - #7095 `d8368a0` Replace scriptnum_test's normative ScriptNum implementation (Wladimir J. van der Laan)\n- - #7063 `6abf6eb` [Tests] Add prioritisetransaction RPC test (Suhas Daftuar)\n- - #7137 `16f4a6e` Tests: Explicitly set chain limits in replace-by-fee test (Suhas Daftuar)\n- - #7216 `9572e49` Removed offline testnet DNSSeed 'alexykot.me'. (tnull)\n- - #7209 `f3ad812` test: don't override BITCOIND and BITCOINCLI if they're set (Wladimir J. van der Laan)\n- - #7226 `301f16a` Tests: Add more tests to p2p-fullblocktest (Suhas Daftuar)\n- - #7153 `9ef7c54` [Tests] Add mempool_limit.py test (Jonas Schnelli)\n- - #7170 `453c567` tests: Disable Tor interaction (Wladimir J. van der Laan)\n- - #7229 `1ed938b` [qa] wallet: Check if maintenance changes the balance (MarcoFalke)\n- - #7308 `d513405` [Tests] Eliminate intermittent failures in sendheaders.py (Suhas Daftuar)\n- - #7468 `947c4ff` [rpc-tests] Change solve() to use rehash (Brad Andrews)\n\n### Miscellaneous\n\n- - #6213 `e54ff2f` [init] add -blockversion help and extend -upnp help (Diapolo)\n- - #5975 `1fea667` Consensus: Decouple ContextualCheckBlockHeader from checkpoints (Jorge Tim\u00f3n)\n- - #6061 `eba2f06` Separate Consensus::CheckTxInputs and GetSpendHeight in CheckInputs (Jorge Tim\u00f3n)\n- - #5994 `786ed11` detach wallet from miner (Jonas Schnelli)\n- - #6387 `11576a5` [bitcoin-cli] improve error output (Jonas Schnelli)\n- - #6401 `6db53b4` Add BITCOIND_SIGTERM_TIMEOUT to OpenRC init scripts (Florian Schmaus)\n- - #6430 `b01981e` doc: add documentation for shared library libbitcoinconsensus (Braydon Fuller)\n- - #6372 `dcc495e` Update Linearize tool to support Windows paths; fix variable scope; update README and example configuration (Paul Georgiou)\n- - #6453 `8fe5cce` Separate core memory usage computation in core_memusage.h (Pieter Wuille)\n- - #6149 `633fe10` Buffer log messages and explicitly open logs (Adam Weiss)\n- - #6488 `7cbed7f` Avoid leaking file descriptors in RegisterLoad (Casey Rodarmor)\n- - #6497 `a2bf40d` Make sure LogPrintf strings are line-terminated (Wladimir J. van der Laan)\n- - #6504 `b6fee6b` Rationalize currency unit to \"BTC\" (Ross Nicoll)\n- - #6507 `9bb4dd8` Removed contrib/bitrpc (Casey Rodarmor)\n- - #6527 `41d650f` Use unique name for AlertNotify tempfile (Casey Rodarmor)\n- - #6561 `e08a7d9` limitedmap fixes and tests (Casey Rodarmor)\n- - #6565 `a6f2aff` Make sure we re-acquire lock if a task throws (Casey Rodarmor)\n- - #6599 `f4d88c4` Make sure LogPrint strings are line-terminated (Ross Nicoll)\n- - #6630 `195942d` Replace boost::reverse_lock with our own (Casey Rodarmor)\n- - #6103 `13b8282` Add ZeroMQ notifications (Jo\u00e3o Barbosa)\n- - #6692 `d5d1d2e` devtools: don't push if signing fails in github-merge (Wladimir J. van der Laan)\n- - #6728 `2b0567b` timedata: Prevent warning overkill (Wladimir J. van der Laan)\n- - #6713 `f6ce59c` SanitizeString: Allow hypen char (MarcoFalke)\n- - #5987 `4899a04` Bugfix: Fix testnet-in-a-box use case (Luke-Jr)\n- - #6733 `b7d78fd` Simple benchmarking framework (Gavin Andresen)\n- - #6854 `a092970` devtools: Add security-check.py (Wladimir J. van der Laan)\n- - #6790 `fa1d252` devtools: add clang-format.py (MarcoFalke)\n- - #7114 `f3d0fdd` util: Don't set strMiscWarning on every exception (Wladimir J. van der Laan)\n- - #7078 `93e0514` uint256::GetCheapHash bigendian compatibility (arowser)\n- - #7094 `34e02e0` Assert now > 0 in GetTime GetTimeMillis GetTimeMicros (Patrick Strateman)\n\nCredits\n=======\n\nThanks to everyone who directly contributed to this release:\n\n- - accraze\n- - Adam Weiss\n- - Alex Morcos\n- - Alex van der Peet\n- - AlSzacrel\n- - Altoidnerd\n- - Andriy Voskoboinyk\n- - antonio-fr\n- - Arne Brutschy\n- - Ashley Holman\n- - Bob McElrath\n- - Braydon Fuller\n- - BtcDrak\n- - Casey Rodarmor\n- - centaur1\n- - Chris Kleeschulte\n- - Christian Decker\n- - Cory Fields\n- - daniel\n- - Daniel Cousens\n- - Daniel Kraft\n- - David Hill\n- - dexX7\n- - Diego Viola\n- - Elias Rohrer\n- - Eric Lombrozo\n- - Erik Mossberg\n- - Esteban Ordano\n- - EthanHeilman\n- - Florian Schmaus\n- - Forrest Voight\n- - Gavin Andresen\n- - Gregory Maxwell\n- - Gregory Sanders / instagibbs\n- - Ian T\n- - Irving Ruan\n- - Jacob Welsh\n- - James O'Beirne\n- - Jeff Garzik\n- - Johnathan Corgan\n- - Jonas Schnelli\n- - Jonathan Cross\n- - Jo\u00e3o Barbosa\n- - Jorge Tim\u00f3n\n- - Josh Lehan\n- - J Ross Nicoll\n- - kazcw\n- - Kevin Cooper\n- - lpescher\n- - Luke Dashjr\n- - Marco\n- - MarcoFalke\n- - Mark Friedenbach\n- - Matt\n- - Matt Bogosian\n- - Matt Corallo\n- - Matt Quinn\n- - Micha\n- - Michael\n- - Michael Ford / fanquake\n- - Midnight Magic\n- - Mitchell Cash\n- - mrbandrews\n- - mruddy\n- - Nick\n- - Patrick Strateman\n- - Paul Georgiou\n- - Paul Rabahy\n- - Pavel Jan\u00edk / paveljanik\n- - Pavel Vasin\n- - Pavol Rusnak\n- - Peter Josling\n- - Peter Todd\n- - Philip Kaufmann\n- - Pieter Wuille\n- - ptschip\n- - randy-waterhouse\n- - rion\n- - Ross Nicoll\n- - Ryan Havar\n- - Shaul Kfir\n- - Simon Males\n- - Stephen\n- - Suhas Daftuar\n- - tailsjoin\n- - Thomas Kerin\n- - Tom Harding\n- - tulip\n- - unsystemizer\n- - Veres Lajos\n- - Wladimir J. van der Laan\n- - xor-freenet\n- - Zak Wilcox\n- - zathras-crypto\n\nAs well as everyone that helped translating on [Transifex](https://www.transifex.com/projects/p/bitcoin/).\n\n\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1\n\niQEcBAEBCgAGBQJWzD2rAAoJEHSBCwEjRsmmg/wIAMdVQie2KQWASn+lDAxE/njW\nzOeWunnyiWLOEJYSHhPzb+1kDfubsHkEr8tvkfhBKI25NMg0yLBzB1QSfBmbXGZK\nXNWuaqkda9424iAcAuajtNHLYa9oolKI6ECYikYmsAFR2q0IlpV8c3BwGWJ7+/MV\nyD79f1PfmFakgApe53/dz1USm/y9afcZAiEsfhs5wc8Q8IJxOFv+7F05hRa2g4IJ\nZJk+Zotb9kQh39fGv4YGyo91NOr5ZzOhEYQAezJ+mCFflkjTwynz8ocjuqYg3nzq\nviKYTMi7zX56aDIw2OTX+gzWigIExObYxvre1oNCtXANTyzEMoLRYaSwjcrtTgE=\n=JwtP\n-----END PGP SIGNATURE-----"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Core 0.12.0 released",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Wladimir J. van der Laan"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 48268
        }
    },
    {
        "title": "[bitcoin-dev] Multi-Stage Merge-Mine Headers Hard-Fork BIP",
        "thread_messages": [
            {
                "author": "James Hilliard",
                "date": "2016-02-24T05:52:32",
                "message_text_only": "https://github.com/bitcoin/bips/pull/340\n\nBIP: ?\nTitle: 2016 Multi-Stage Merge-Mine Headers Hard-Fork\nAuthor: James Hilliard <james.hilliard1 at gmail.com>\nStatus: Draft\nType: Standards Track\nCreated: 2016-02-23\n\n==Abstract==\n\nUse a staged hard fork to implement a headers format change that is\nmerge mine incompatible along with a timewarp to kill the previous\nchain.\n\n==Specification==\n\nWe use a block version flag to activate this fork when 3900 out of the\nprevious 4032 blocks have this the version flag set. This flag locks\nin both of the below stages at the same time.\n\nMerge Mine Stage: The initial hard fork is implemented using a merge\nmine which requires that the original pre-fork chain be mined with a\ngeneration transaction that creates no new coins in addition to not\ncontaining any transactions. Additionally we have a consensus rule\nthat requires that ntime be manipulated on the original chain to\nartificially increase difficulty and hold back the original chain so\nthat all non-upgraded clients can never catch up with current time.\nThe artificial ntime is implemented as a consensus rule for blocks in\nthe new chain.\n\nHeaders Change Stage: This is the final stage of the hard fork where\nthe header format is made incompatible with merge mining, this is\nactivated ~50,000 blocks after the Merge Mine Stage and only at the\nstart of the 2016 block difficulty boundary.\n\n==Motivation==\n\nThere are serious issues with pooled mining such as block withhold\nattacks that can only be fixed by making major changes to the headers\nformat.\n\nThere are a number of other desirable header format changes that can\nonly be made in a non-merge mine compatible way.\n\nThere is a high risk of there being two viable chains if we don't have\na way to permanently disable the original chain.\n\n==Rationale==\n\nOur solution is to use a two stage hard fork with a single lock in period.\n\nThe first stage is designed to kill off the previous chain by holding\nback ntime to artificially increase network difficulty on the original\nchain to the point where it would be extremely difficult to mine the\n2016 blocks needed to trigger a difficulty adjustment. This also makes\nit obvious to unupgraded clients that they are not syncing properly\nand need to upgrade.\n\nBy locking in both stages at the same time we ensure that any clients\nmerge mining are also locked in for the headers change stage so that\nthe original chain is dead by the time the headers change takes place.\n\nWe timewarp over a year of merge mining to massively increase the\ndifficulty on the original chain to the point that it would be\nincredibly expensive to reduce the difficulty enough that the chain\nwould be able to get caught up to current time.\n\n==Backward Compatibility==\n\nThis hardfork will permanently disable all nodes, both full and light,\nwhich do not explicitly add support for it.\nHowever, their security will not be compromised due to the implementation.\nTo migrate, all nodes must choose to upgrade, and miners must express\nsupermajority support.\n\n==Reference Implementation==\n\nTODO"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-02-24T10:58:27",
                "message_text_only": "You need more detail for it to be a BIP.\n\nNew Header\n\nnew_header.prev = hash of previous header's bitcoin header\nnew_header.small_nonce = 4 byte nonce\nnew_header.big_nonce = 8 byte nonce\n\nnew_header.... (Can contain any new fields desired)\n\nFake Block\n\nblock.version = 4\nblock.prev = new_header.prev\nblock.merkle = calculate_merkle(coinbase)\nblock.timestamp = block.getPreviousBlock().median_time_past + 1\nblock.bits = calculate_bits()\nblock.nonce = new_header.small_nonce\nblock.tx_count = 1\n\nCoinbase\n\ncoinbase.version = 1\ncoinbase.tx_in_count = 0\ncoinbase.tx_out_count = 1\ncoinbase.tx_out[0].value = 0\ncoinbase.tx_out[0].pk_script = \"OP_RETURN\"\n\nThis is a \"nuclear option\" attack that knocks out the main chain.  The\nmedian time past will increase very slowly.  It only needs to increase by 1\nevery 6th blocks.  That gives an increase of 336 seconds for every\ndifficulty update.  This will cap the update rate, so give an increase of\n4X every doubling.\n\nThe new headers will end up not meeting the difficulty, so they will\npresumably just repeat the last header?\n\nIf the bitcoin chain stays at constant difficulty, then each quadrupling\nwill take more time.\n\nAfter 2 weeks: 4XDiff   (2 weeks per diff period)\nAfter 10 weeks: 16XDiff (8 weeks per diff period)\nAfter 42 weeks: 256XDiff (32 weeks per diff period)\n\n\nOn Wed, Feb 24, 2016 at 5:52 AM, James Hilliard via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> https://github.com/bitcoin/bips/pull/340\n>\n> BIP: ?\n> Title: 2016 Multi-Stage Merge-Mine Headers Hard-Fork\n> Author: James Hilliard <james.hilliard1 at gmail.com>\n> Status: Draft\n> Type: Standards Track\n> Created: 2016-02-23\n>\n> ==Abstract==\n>\n> Use a staged hard fork to implement a headers format change that is\n> merge mine incompatible along with a timewarp to kill the previous\n> chain.\n>\n> ==Specification==\n>\n> We use a block version flag to activate this fork when 3900 out of the\n> previous 4032 blocks have this the version flag set. This flag locks\n> in both of the below stages at the same time.\n>\n> Merge Mine Stage: The initial hard fork is implemented using a merge\n> mine which requires that the original pre-fork chain be mined with a\n> generation transaction that creates no new coins in addition to not\n> containing any transactions. Additionally we have a consensus rule\n> that requires that ntime be manipulated on the original chain to\n> artificially increase difficulty and hold back the original chain so\n> that all non-upgraded clients can never catch up with current time.\n> The artificial ntime is implemented as a consensus rule for blocks in\n> the new chain.\n>\n> Headers Change Stage: This is the final stage of the hard fork where\n> the header format is made incompatible with merge mining, this is\n> activated ~50,000 blocks after the Merge Mine Stage and only at the\n> start of the 2016 block difficulty boundary.\n>\n> ==Motivation==\n>\n> There are serious issues with pooled mining such as block withhold\n> attacks that can only be fixed by making major changes to the headers\n> format.\n>\n> There are a number of other desirable header format changes that can\n> only be made in a non-merge mine compatible way.\n>\n> There is a high risk of there being two viable chains if we don't have\n> a way to permanently disable the original chain.\n>\n> ==Rationale==\n>\n> Our solution is to use a two stage hard fork with a single lock in period.\n>\n> The first stage is designed to kill off the previous chain by holding\n> back ntime to artificially increase network difficulty on the original\n> chain to the point where it would be extremely difficult to mine the\n> 2016 blocks needed to trigger a difficulty adjustment. This also makes\n> it obvious to unupgraded clients that they are not syncing properly\n> and need to upgrade.\n>\n> By locking in both stages at the same time we ensure that any clients\n> merge mining are also locked in for the headers change stage so that\n> the original chain is dead by the time the headers change takes place.\n>\n> We timewarp over a year of merge mining to massively increase the\n> difficulty on the original chain to the point that it would be\n> incredibly expensive to reduce the difficulty enough that the chain\n> would be able to get caught up to current time.\n>\n> ==Backward Compatibility==\n>\n> This hardfork will permanently disable all nodes, both full and light,\n> which do not explicitly add support for it.\n> However, their security will not be compromised due to the implementation.\n> To migrate, all nodes must choose to upgrade, and miners must express\n> supermajority support.\n>\n> ==Reference Implementation==\n>\n> TODO\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160224/a97dd885/attachment.html>"
            },
            {
                "author": "James Hilliard",
                "date": "2016-02-24T11:37:10",
                "message_text_only": "I've updated the BIP with your suggestions, would it make sense to\njust move the activation condition to the 42 week boundary instead of\nrepeating the last header? Would that be at block 6048 from the start\nof the timewarp?\n\nhttps://github.com/jameshilliard/bips/blob/bip-msmmhhf/bip-msmmhhf.mediawiki\n\nOn Wed, Feb 24, 2016 at 4:58 AM, Tier Nolan via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> You need more detail for it to be a BIP.\n>\n> New Header\n>\n> new_header.prev = hash of previous header's bitcoin header\n> new_header.small_nonce = 4 byte nonce\n> new_header.big_nonce = 8 byte nonce\n>\n> new_header.... (Can contain any new fields desired)\n>\n> Fake Block\n>\n> block.version = 4\n> block.prev = new_header.prev\n> block.merkle = calculate_merkle(coinbase)\n> block.timestamp = block.getPreviousBlock().median_time_past + 1\n> block.bits = calculate_bits()\n> block.nonce = new_header.small_nonce\n> block.tx_count = 1\n>\n> Coinbase\n>\n> coinbase.version = 1\n> coinbase.tx_in_count = 0\n> coinbase.tx_out_count = 1\n> coinbase.tx_out[0].value = 0\n> coinbase.tx_out[0].pk_script = \"OP_RETURN\"\n>\n> This is a \"nuclear option\" attack that knocks out the main chain.  The\n> median time past will increase very slowly.  It only needs to increase by 1\n> every 6th blocks.  That gives an increase of 336 seconds for every\n> difficulty update.  This will cap the update rate, so give an increase of 4X\n> every doubling.\n>\n> The new headers will end up not meeting the difficulty, so they will\n> presumably just repeat the last header?\n>\n> If the bitcoin chain stays at constant difficulty, then each quadrupling\n> will take more time.\n>\n> After 2 weeks: 4XDiff   (2 weeks per diff period)\n> After 10 weeks: 16XDiff (8 weeks per diff period)\n> After 42 weeks: 256XDiff (32 weeks per diff period)\n>\n>\n> On Wed, Feb 24, 2016 at 5:52 AM, James Hilliard via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> https://github.com/bitcoin/bips/pull/340\n>>\n>> BIP: ?\n>> Title: 2016 Multi-Stage Merge-Mine Headers Hard-Fork\n>> Author: James Hilliard <james.hilliard1 at gmail.com>\n>> Status: Draft\n>> Type: Standards Track\n>> Created: 2016-02-23\n>>\n>> ==Abstract==\n>>\n>> Use a staged hard fork to implement a headers format change that is\n>> merge mine incompatible along with a timewarp to kill the previous\n>> chain.\n>>\n>> ==Specification==\n>>\n>> We use a block version flag to activate this fork when 3900 out of the\n>> previous 4032 blocks have this the version flag set. This flag locks\n>> in both of the below stages at the same time.\n>>\n>> Merge Mine Stage: The initial hard fork is implemented using a merge\n>> mine which requires that the original pre-fork chain be mined with a\n>> generation transaction that creates no new coins in addition to not\n>> containing any transactions. Additionally we have a consensus rule\n>> that requires that ntime be manipulated on the original chain to\n>> artificially increase difficulty and hold back the original chain so\n>> that all non-upgraded clients can never catch up with current time.\n>> The artificial ntime is implemented as a consensus rule for blocks in\n>> the new chain.\n>>\n>> Headers Change Stage: This is the final stage of the hard fork where\n>> the header format is made incompatible with merge mining, this is\n>> activated ~50,000 blocks after the Merge Mine Stage and only at the\n>> start of the 2016 block difficulty boundary.\n>>\n>> ==Motivation==\n>>\n>> There are serious issues with pooled mining such as block withhold\n>> attacks that can only be fixed by making major changes to the headers\n>> format.\n>>\n>> There are a number of other desirable header format changes that can\n>> only be made in a non-merge mine compatible way.\n>>\n>> There is a high risk of there being two viable chains if we don't have\n>> a way to permanently disable the original chain.\n>>\n>> ==Rationale==\n>>\n>> Our solution is to use a two stage hard fork with a single lock in period.\n>>\n>> The first stage is designed to kill off the previous chain by holding\n>> back ntime to artificially increase network difficulty on the original\n>> chain to the point where it would be extremely difficult to mine the\n>> 2016 blocks needed to trigger a difficulty adjustment. This also makes\n>> it obvious to unupgraded clients that they are not syncing properly\n>> and need to upgrade.\n>>\n>> By locking in both stages at the same time we ensure that any clients\n>> merge mining are also locked in for the headers change stage so that\n>> the original chain is dead by the time the headers change takes place.\n>>\n>> We timewarp over a year of merge mining to massively increase the\n>> difficulty on the original chain to the point that it would be\n>> incredibly expensive to reduce the difficulty enough that the chain\n>> would be able to get caught up to current time.\n>>\n>> ==Backward Compatibility==\n>>\n>> This hardfork will permanently disable all nodes, both full and light,\n>> which do not explicitly add support for it.\n>> However, their security will not be compromised due to the implementation.\n>> To migrate, all nodes must choose to upgrade, and miners must express\n>> supermajority support.\n>>\n>> ==Reference Implementation==\n>>\n>> TODO\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            }
        ],
        "thread_summary": {
            "title": "Multi-Stage Merge-Mine Headers Hard-Fork BIP",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Tier Nolan",
                "James Hilliard"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 13623
        }
    },
    {
        "title": "[bitcoin-dev] SIGHASH_NOINPUT in Segregated Witness",
        "thread_messages": [
            {
                "author": "Joseph Poon",
                "date": "2016-02-26T01:07:46",
                "message_text_only": "As Segregated Witness will be merged soon as a solution for transaction\nmalleability, especially with multi-party adversarial signatures, there\nmay be an additional use case/functionality which is helpful for\nLightning Network and possibly other Bitcoin use cases. This requires a\nnew SIGHASH flag inside Segregated Witness which does not sign the input\ntxid/index.\n\nSegwit is very helpful in resolving malleability in pretty much every\ncase which matters. It is especially helpful in having solid and safe\ndefaults for standard Bitcoin payments; it's very difficult to mess up\nif you are writing code in conjunction with the Bitcoin RPC API.\n\nHowever, it is very useful for LN if there is a certain level of\noutsourcibility for transactions without this 3rd party taking on\nonerous costs. In LN, there is a dispute resolution period established\nto prevent the counterparty from attesting an incorrect channel state\n(represented by broadcasting a timelocked transaction). In other words,\nif someone in a channel broadcasts an incorrect state, the output can be\nredeemed by a 3rd party (but this 3rd party is not a custodian, since\nthe output goes to the other party in the channel).\n\nIdeally, a 3rd-party can be handed a transaction which can encompass all\nprior states in a compact way. For currently-designed Segregated Witness\ntransactions, this requires storing all previous signatures, which can\nbecome very costly if individuals to thousands of channel state updates\nper day. This is very possible, as fees are near-zero, the value in\natomizing all payments to many transactions becomes viable (reducing\ntransaction/information costs). If individuals are doing tens of\nthousands of transactions per day, and one presumes something like\n70-bytes of data per Commitment state in the channel, it quickly becomes\ninfeasible to watch on behalf of many channels without material costs.\n\nThis is especially necessary because it is highly desirable to make\nkeeping track of these channels be very cheap, as it allows for more\nparticipants to be watching on one's behalf (reducing the chance of a\n3rd party fail to watch). Further, it may reduce the need to notify the\n3rd party for every single channel Commitment state, instead only\nproviding the most recent one should provide sufficient information for\nall prior states (since the signature will apply for any type of\ntransaction), making the only updated information the revocation\nsecret/preimage. Without this SIGHASH flag, every single state would\nneed to be contacted and updated with 3rd parties. With this SIGHASH\nflag, one could instead delegate outsourcing when one's client goes\noffline with a single message several hundred bytes in size,\nencompassing all prior states.\n\nOf course, while running a 24/7 full-node is encouraged, I suspect many\npeople will not want to do so at the current time, and it needs to be\nfunctional for those who elect to be connected intermittently. This\nrequires outsourcing or watching on one's behalf.\n\nThis would be achieved using a SIGHASH flag, termed SIGHASH_NOINPUT. It\ndoes not include as part of the signature, the outpoint being spent\n(txid and index), nor the amount. It however, would include the spent\noutpoint's script as part of the signature. Note that this is just a\nSIGHASH flag, and the outpoints are still being included as part of the\ntxins (if they are mutated, the new txids can be updated by the wallet\nwithout resigning). This allows for a signature to apply to anything\nwith that pubkey (therefore pubkeys with this flag should not be\nreused). For safety, this only applies in SegWit transactions, as segwit\nprovides a sufficient malleability solution, there is no incentive to\nimproperly use this sighash flag as a roundabout way to resolve\nmalleability.\n\nThis helps with 3rd-party outsourcing for watching the blockchain, as\none can provide a signature (and the most recent hash-chain of\nrevocation preimages), which encompasses penalty transactions for all\nprior states. Functionally, this allows for opt-in wildcard inputs, but\nwallets which do not require these transactions do not need to be\nconcerned with this flag; since they will never be signing with this\nflag, they do not need to be concerned with address re-use.\n\nI'm interested in input and in the level of receptiveness to this. If\nthere is interest, I'll write up a draft BIP in the next couple days.\n\n-- \nJoseph Poon"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2016-02-26T01:32:34",
                "message_text_only": "On Fri, Feb 26, 2016 at 1:07 AM, Joseph Poon via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> I'm interested in input and in the level of receptiveness to this. If\n> there is interest, I'll write up a draft BIP in the next couple days.\n\nThe design of segwit was carefully constructed to make it maximally\neasy and safe to soft-fork in future script enhancements after its\ndeployment with the specific goal of avoiding indefinite delays in its\ndeployment from inevitable scope creep from additional things that are\n\"easy\" to deploy as part of segwit.  I think to be successful we must\nbe absolutely ruthless about changes that go in there beyond the\nabsolute minimum needed for the safe deployment of segwit... so I\nthink this should probably be constructed as a new segwit script type,\nand not a base feature.\n\nThe exact construction you're thinking of there isn't clear to me...\none thing that comes to mind is that I think it is imperative that we\ndo not deploy a without-inputs SIGHASH flag without also deploying at\nleast a fee-committing sighash-all. The reason for this is that if\nhardware wallets are forced to continue transferring input\ntransactions to check fees or to use without-inputs, they may choose\nthe latter and leave the users needlessly exposed to replay attacks.\n\nWhen you do write a BIP for this its imperative that the vulnerability\nto replay is called out in bold blinking flaming text, along with the\nnecessary description of how to use it safely. The fact that without\ninput commitments transactions are replayable is highly surprising to\nmany developers... Personally, I'd even go so far as to name the flag\nSIGHASH_REPLAY_VULNERABLE. :)"
            },
            {
                "author": "Joseph Poon",
                "date": "2016-02-26T01:48:07",
                "message_text_only": "Hi Greg,\n\nOn Fri, Feb 26, 2016 at 01:32:34AM +0000, Gregory Maxwell wrote:\n> I think to be successful we must be absolutely ruthless about changes\n> that go in there beyond the absolute minimum needed for the safe\n> deployment of segwit... so I think this should probably be constructed\n> as a new segwit script type, and not a base feature.\n\nAbsolutely, I'd certainly be interested in this being the first\nproof/example for the script upgrade mechanisms if it's not ideal for\nthis to be implemented as part of Segregated Witness itself.\n\n> The reason for this is that if hardware wallets are forced to continue\n> transferring input transactions to check fees or to use\n> without-inputs, they may choose the latter and leave the users\n> needlessly exposed to replay attacks.\n\nYes, I think it's necessary to include the fees as part of the\nsignature, which will also allow for wallets to not require downloading\nthe input transactions. However, it's necessary to not include the input\namount itself, as they may differ. SegWit itself is very nice in that it\nprevents improperly designed wallets and services using the bitcoin RPC\nfrom making mistakes, you can resolve malleability without compromises\n-- I also think any proposed SIGHASH should ensure some measure of\nsafety from design error/shortcuts.\n\n> The fact that without input commitments transactions are replayable is\n> highly surprising to many developers... Personally, I'd even go so far\n> as to name the flag SIGHASH_REPLAY_VULNERABLE. :)\n\nThat's a good point, choosing a scary name is probably very helpful.\n\nThanks, I'll clarify with a specific BIP soon.\n\n-- \nJoseph Poon"
            },
            {
                "author": "Anthony Towns",
                "date": "2016-02-26T03:20:56",
                "message_text_only": "On Fri, Feb 26, 2016 at 01:32:34AM +0000, Gregory Maxwell via bitcoin-dev wrote:\n> On Fri, Feb 26, 2016 at 1:07 AM, Joseph Poon via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > I'm interested in input and in the level of receptiveness to this. If\n> > there is interest, I'll write up a draft BIP in the next couple days.\n> .. I think this should probably be constructed as a new segwit script type,\n> and not a base feature.\n\n+1 to both\n\n> The exact construction you're thinking of there isn't clear to me...\n\nI think the idea is that you have three transactions:\n\n anchor:\n   input: whatever\n   output:\n     - single output, spendable by 2-of-2 multisig\n     - [possibly others as well, whatever]\n\n commitment:\n   input: anchor\n   outputs:\n     1. payment to A\n     2. payment to B\n     3. HTLC to A on R1, timeout T1\n     4. HTLC to A on R2, timeout T2\n     5. HTLC to B on R3, timeout T3\n     ...\n\n penalty:\n   inputs:\n     all the outputs from the commitment tx\n   outputs:\n     1. 99% as payment to me\n     2.  1% as outsourcing fee\n\nAs long as the key I use for spending each of commitment transactions\noutputs is \"single use\" -- ie, I don't use it for other channels or\nanywhere else on the blockchain, then as long as the signature commits\nto the outputs it's safe afaics.\n\n(You still have to send a lot of data to the place you're outsourcing\nchain-monitoring to; all the R1,R2,R3 and T1,T2,T3 values are needed in\norder to reconstruct the redeem scripts)\n\n> one thing that comes to mind is that I think it is imperative that we\n> do not deploy a without-inputs SIGHASH flag without also deploying at\n> least a fee-committing sighash-all.\n\nIf the fee for commitment transactions changes regularly (eg, a new\ncommitment transaction is generated every few seconds/minutes, and the fee\nis chosen based on whatever estimatefee returns), I think this would cause\nproblems -- you couldn't use a single signature to cover every revoked\ncommitment, you'd need one for each different fee level that you'd used\nfor the lifetime of the channel. Actually, the size of the commitment\ntransaction will differ anyway depending on how many HTLCs are open,\nso even if estimatefee didn't change, the fee would still differ. So I\nthink commiting to a fee isn't workable for the lightning use case...\n\n> When you do write a BIP for this its imperative that the vulnerability\n> to replay is called out in bold blinking flaming text, along with the\n> necessary description of how to use it safely. The fact that without\n> input commitments transactions are replayable is highly surprising to\n> many developers... Personally, I'd even go so far as to name the flag\n> SIGHASH_REPLAY_VULNERABLE. :)\n\n+1, though I'm not sure it's so much \"vulnerable\" to replay as it is\n\"explicitly designed\" to be replayable...\n\nCheers,\naj"
            },
            {
                "author": "Bryan Bishop",
                "date": "2016-02-26T01:34:24",
                "message_text_only": "On Thu, Feb 25, 2016 at 7:07 PM, Joseph Poon wrote:\n> This would be achieved using a SIGHASH flag, termed SIGHASH_NOINPUT. It\n> does not include as part of the signature, the outpoint being spent\n> (txid and index), nor the amount. It however, would include the spent\n> outpoint's script as part of the signature. Note that this is just a\n\nWell if you are bothering to draft up a BIP about that SIGHASH flag,\nthen perhaps also consider some other SIGHASH flag types as well while\nyou are at it?\n\nVarious proposed sighash types:\nhttp://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-August/010759.html\n\n\"Build your own nHashType\" proposal draft:\nhttps://github.com/scmorse/bitcoin-misc/blob/master/sighash_proposal.md\n\njl2012's reply:\nhttp://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-August/010779.html\n\npetertodd's reply about OP_CODESEPARATOR linked back to this thread\nregarding \"Build your own nHashType\":\nhttp://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-April/007771.html\nhttp://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-April/007802.html\nhttp://gnusha.org/bitcoin-wizards/2014-12-09.log\n\n((That particular thread had other replies which can be viewed here:\nhttp://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-April/thread.html\n))\n\nAlso, there was a draft implementation of SIGHASH_NOINPUT:\nhttps://github.com/Roasbeef/bitcoin/commit/4b3c3f1baf7985208ceb6887261ee150ab6e3328\nhttps://github.com/Roasbeef/btcd/commit/67830e506fa135d5239177340918cea39909e6a4\n\nFWIW there was some concern about replay using SIGHAHS_NOINPUT or something:\nhttp://gnusha.org/bitcoin-wizards/2015-04-07.log\n\n- Bryan\nhttp://heybryan.org/\n1 512 203 0507"
            },
            {
                "author": "Joseph Poon",
                "date": "2016-02-26T02:02:26",
                "message_text_only": "Hi Bryan,\n\nOn Thu, Feb 25, 2016 at 07:34:24PM -0600, Bryan Bishop wrote:\n> Well if you are bothering to draft up a BIP about that SIGHASH flag,\n> then perhaps also consider some other SIGHASH flag types as well while\n> you are at it?\n\nI'll take a look at those proposals when drafting the BIP. I think for\nLN, there is a single clean way to achieve outsourcability, but may be\ncompatible with other arrangements. I'm somewhat averse to proposing too\nmuch flexibility before there's clear use-cases, though. However, if\nothers do have uses/examples for other sighash flags, I'd be very\ninterested while drafting this BIP!\n\n> FWIW there was some concern about replay using SIGHAHS_NOINPUT or something:\n> http://gnusha.org/bitcoin-wizards/2015-04-07.log\n\nYeah, I think the nice thing about SegWit is that you resolve\nmalleability without worrying about replay attacks in the event of key\nreuse. That's why I think it's only safe to do this new sighash type\ninside segwit itself -- if you only wanted protection against\nmalleability you'd use segwit, and not touch this new sighash type\n(you'd only use the new sighash flag if you actually need its features).\n\n-- \nJoseph Poon"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-02-26T02:35:23",
                "message_text_only": "On Friday, February 26, 2016 1:07:46 AM Joseph Poon via bitcoin-dev wrote:\n> This would be achieved using a SIGHASH flag, termed SIGHASH_NOINPUT. It\n> does not include as part of the signature, the outpoint being spent\n> (txid and index), nor the amount. It however, would include the spent\n> outpoint's script as part of the signature. Note that this is just a\n> SIGHASH flag, and the outpoints are still being included as part of the\n> txins (if they are mutated, the new txids can be updated by the wallet\n> without resigning). This allows for a signature to apply to anything\n> with that pubkey (therefore pubkeys with this flag should not be\n> reused). \n\nI'd like this regardless of Lightning, as it makes it possible to write fully \nmalleability-proof wallet software also.\n\n> For safety, this only applies in SegWit transactions, as segwit\n> provides a sufficient malleability solution, there is no incentive to\n> improperly use this sighash flag as a roundabout way to resolve\n> malleability.\n\nSegWit's malleability solution is not really sufficient in comparison, but I \ndon't think there's a need to make this available to pre-SegWit transactions \nanyway (and doing so would probably complicate it).\n\nLuke"
            },
            {
                "author": "Rusty Russell",
                "date": "2016-02-29T00:25:53",
                "message_text_only": "Joseph Poon via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> writes:\n> Ideally, a 3rd-party can be handed a transaction which can encompass all\n> prior states in a compact way. For currently-designed Segregated Witness\n> transactions, this requires storing all previous signatures, which can\n> become very costly if individuals to thousands of channel state updates\n> per day.\n\nAFAICT we need more than this.  Or are you using something other than\nthe deployable lightning commit tx style?\n\nIf each HTLC output is a p2sh[1], you need the timeout and rhash for\neach one to build the script to redeem it.  In practice, there's not\nmuch difference between sending a watcher a tx for every commit tx and\nsending it information for every new HTLC (roughly a factor of 2).\n\nSo we also need to put more in the scriptPubKey for this to work; either\nthe entire redeemscript, or possibly some kind of multiple-choice P2SH\nwhere any one of the hashes will redeem the payment.\n\nCheers,\nRusty.\n[1] eg. from https://github.com/ElementsProject/lightning/blob/master/doc/deployable-lightning.pdf\n        OP_HASH160 OP_DUP # Replace top element with two copies of its hash\n        <R-HASH> OP_EQUAL # Test if they supplied the HTLC R value\n        OP_SWAP <COMMIT-REVOCATION-HASH> OP_EQUAL OP_ADD\n                          # Or the commitment revocation hash\n        OP_IF # If any hash matched.\n                <KEY-B> # Pay to B.\n        OP_ELSE # Must be A, after HTLC has timed out.\n                <HTLC-TIMEOUT> OP_CHECKLOCKTIMEVERIFY Ensure (absolute) time has passed.\n                <DELAY> OP_CHECKSEQUENCEVERIFY # Delay gives B enough time to use revocation if it has it.\n                OP_2DROP # Drop the delay and htlc-timeout from the stack.\n                <KEY-A> # Pay to A.\n        OP_ENDIF\n        OP_CHECKSIG # Verify A or B's signature is correct.\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "SIGHASH_NOINPUT in Segregated Witness",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Bryan Bishop",
                "Anthony Towns",
                "Luke Dashjr",
                "Gregory Maxwell",
                "Joseph Poon"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 16492
        }
    },
    {
        "title": "[bitcoin-dev] INV overhead and batched INVs to reduce full node traffic",
        "thread_messages": [
            {
                "author": "Jonathan Toomim",
                "date": "2016-02-26T05:35:14",
                "message_text_only": "The INV scheme used by Bitcoin is not very efficient at all. Once you take into account Bitcoin, TCP (including ACKs), IP, and ethernet overheads, each INV takes 193 bytes, according to wireshark. That's 127 bytes for the INV message and 66 bytes for the ACK. All of this is for 32 bytes of payload, for an \"efficiency\" of 16.5% (i.e. 83.5% overhead). For a 400 byte transaction with 20 peers, this can result in 3860 bytes sent in INVs for only 400 bytes of actual data.\n\nAn improvement that I've been thinking about implementing (after Blocktorrent) is an option for batched INVs. Including the hashes for two txes per IP packet instead of one would increase the INV size to 229 bytes for 64 bytes of payload -- that is, you add 36 bytes to the packet for every 32 bytes of actual payload. This is a marginal efficiency of 88.8% for each hash after the first. This is *much* better.\n\nWaiting a short period of time to accumulate several hashes together and send them as a batched INV could easily reduce the traffic of running bitcoin nodes by a factor of 2, and possibly even more than that. However, if too many people used it, such a technique would slow down the propagation of transactions across the bitcoin network slightly, which might make some people unhappy. The ill effects could likely be mitigated by choosing a different batch size for each peer based on each peer's preferences. Each node could choose one or two peers to which they send INVs in batches of one or two, four more peers in which they send batches of two to four, and the rest in batches of four to eight, for example.\n\n(This is a continuation of a conversation started on https://bitcointalk.org/index.php?topic=1377345 <https://bitcointalk.org/index.php?topic=1377345.new#new>.)\n\nJonathan\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160225/9da5a57c/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 496 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160225/9da5a57c/attachment.sig>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2016-02-26T05:56:56",
                "message_text_only": "On Fri, Feb 26, 2016 at 5:35 AM, Jonathan Toomim via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> An improvement that I've been thinking about implementing (after\n> Blocktorrent) is an option for batched INVs. Including the hashes for two\n> txes per IP packet instead of one would increase the INV size to 229 bytes\n> for 64 bytes of payload -- that is, you add 36 bytes to the packet for every\n> 32 bytes of actual payload. This is a marginal efficiency of 88.8% for each\n> hash after the first. This is *much* better.\n>\n> Waiting a short period of time to accumulate several hashes together and\n> send them as a batched INV could easily reduce the traffic of running\n> bitcoin nodes by a factor of 2,\n\nCopying my response to you from BitcoinTalk\n(https://bitcointalk.org/index.php?topic=1377345.msg14013294#msg14013294):\n\nUh. Bitcoin has done this since the very early days. The batching was\ntemporarily somewhat hobbled between 0.10 and 0.12 (especially when\nyou had any abusive frequently pinging peers attached), but is now\nfully functional again and it now manages to batch many transactions\nper INV pretty effectively. Turn on net message debugging and you'll\nsee the many INVs that are much larger than the minimum. The average\nbatching size (ignoring the trickle cut-through) is about 5 seconds\nlong-- and usually gets about 10 transactions per INV. My measurements\nwere with these fixes in effect; I expect the blocksonly savings would\nhave been higher otherwise.\n\n2016-02-26 05:47:08 sending: inv (1261 bytes) peer=33900\n2016-02-26 05:47:08 sending: inv (109 bytes) peer=32460\n2016-02-26 05:47:08 sending: inv (37 bytes) peer=34501\n2016-02-26 05:47:08 sending: inv (217 bytes) peer=33897\n2016-02-26 05:47:08 sending: inv (145 bytes) peer=41863\n2016-02-26 05:47:08 sending: inv (37 bytes) peer=35725\n2016-02-26 05:47:08 sending: inv (73 bytes) peer=20567\n2016-02-26 05:47:08 sending: inv (289 bytes) peer=44703\n2016-02-26 05:47:08 sending: inv (73 bytes) peer=13408\n2016-02-26 05:47:09 sending: inv (649 bytes) peer=41279\n2016-02-26 05:47:09 sending: inv (145 bytes) peer=42612\n2016-02-26 05:47:09 sending: inv (325 bytes) peer=34525\n2016-02-26 05:47:09 sending: inv (181 bytes) peer=41174\n2016-02-26 05:47:09 sending: inv (469 bytes) peer=41460\n2016-02-26 05:47:10 sending: inv (973 bytes) peer=133\n2016-02-26 05:47:10 sending: inv (361 bytes) peer=20541\n\nTwiddling here doesn't change the asymptotic efficiency though; which\nis what my post is about.\n\n[I'm also somewhat surprised that you were unaware of this; one of the\npatches \"classic\" was talking about patching out was the one restoring\nthe batching... due to a transaction deanonymization service (or\ntroll) claiming it interfered with their operations.]"
            },
            {
                "author": "Jonathan Toomim",
                "date": "2016-02-26T07:50:41",
                "message_text_only": "> On Feb 25, 2016, at 9:56 PM, Gregory Maxwell <greg at xiph.org> wrote:\n> The batching was\n> temporarily somewhat hobbled between 0.10 and 0.12 (especially when\n> you had any abusive frequently pinging peers attached), but is now\n> fully functional again and it now manages to batch many transactions\n> per INV pretty effectively. T\n\nThanks for the response. I've been mostly using and working on 0.11-series versions, which very rarely send out INV batches. In my examination, about 85% of the packets had a single hash in it. Nice to know this is one of the other improvements in 0.12.\n\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 496 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160225/83670a67/attachment.sig>"
            },
            {
                "author": "Jonathan Toomim",
                "date": "2016-02-27T09:08:22",
                "message_text_only": "Well, here's another idea: we could shorten the tx hashes to about 4 to 6 bytes instead of 32.\n\nLet's say we have a 1 GB mempool with 2M transactions in it. A 4 byte shorthash would have a 0.046% chance of resulting in a collision with another transaction in our mempool, assuming a random distribution of hash values.\n\nOf course, an attacker might construct transactions specifically for collisions. To protect against that, we set up a different salt value for each connection, and for the INV message, we use a 4 to 6 byte salted hash instead of the full thing. In case a peer does have a collision with one salt value, there are still 7 other peers with different salt values. The probability that they all fail is about 2.2e-27 with a 4-byte hash for a single peer. If we have 500,000 full nodes and 1M transactions per 10 minutes, the chance is 1.1e-15 that even one peer misses even one transaction.\n\nThis strategy would come with about 12 bytes of additional memory overhead per peer per tx, or maybe a little more. In exchange for that 12 bytes per peer*tx, we would save up to 28 bytes per peer*tx of network bandwidth. In typical conditions (e.g. 100-ish MB mempool, 16 peers, 2 MB blocks, 500 B serialized tx size), that could result in 1.792 MB net traffic saved per block (7.7 GB/month) at the expense of 12 MB of RAM. Overall, this technique might have the ability to reduce INV traffic by 5-8x in the asymptotic case, or maybe 2-3x for a realistic case.\n\nI know short hashes like this have been proposed many times before for block propagation (e.g. by Gavin in his O(1) scaling gist, or in XTB). Has anyone else thought of using them like this in INV messages? Can anyone think of any major problems with the idea?\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 496 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160227/95ea770f/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "INV overhead and batched INVs to reduce full node traffic",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jonathan Toomim",
                "Gregory Maxwell"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 7922
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Vaults.",
        "thread_messages": [
            {
                "author": "Emin G\u00fcn Sirer",
                "date": "2016-02-26T16:05:20",
                "message_text_only": "At the 3rd Bitcoin Workshop being held in conjunction with the Financial\nCryptography Conference in Barbados, my group will be presenting a new idea\nfor improving Bitcoin wallet security and deterring thefts today.\n\nThe write-up is here:\n\nhttp://hackingdistributed.com/2016/02/26/how-to-implement-secure-bitcoin-vaults/\n\nThe paper with the nitty gritty details is here:\n    http://fc16.ifca.ai/bitcoin/papers/MES16.pdf\n\nThe core idea:\n\nOur paper describes a way to create vaults, special accounts whose keys can\nbe neutralized if they fall into the hands of attackers. Vaults are\nBitcoin\u2019s decentralized version of you calling your bank to report a stolen\ncredit card -- it renders the attacker\u2019s transactions null and void. And\nhere\u2019s the interesting part: in so doing, vaults demotivate key theft in\nthe first place. An attacker who knows that he will not be able to get away\nwith theft is less likely to attack in the first place, compared to current\nBitcoin attackers who are guaranteed that their hacking efforts will be\nhandsomely rewarded.\n\nOperationally, the idea is simple. You send your money to a vault address\nthat you yourself create. Every vault address has a vault key and a\nrecovery key. When spending money from the vault address with the\ncorresponding vault key, you must wait for a predefined amount of time\n(called the unvaulting period) that you established at the time you created\nthe vault -- say, 24 hours. When all goes well, your vault funds are\nunlocked after the unvaulting period and you can move them to a standard\naddress and subsequently spend them in the usual way. Now, in case Harry\nthe Hacker gets a hold of your vault key, you have 24 hours to revert any\ntransaction issued by Harry, using the recovery key. His theft,\nessentially, gets undone, and the funds are diverted unilaterally to their\nrightful owner. It\u2019s like an \u201cundo\u201d facility that the modern banking world\nrelies on, but for Bitcoin.\n\nThe technical trick relies on a single new opcode, CheckOutputVerify, that\nchecks the shape of a redeem transaction. Note that fungibility is not\naffected, as the restrictions are at the discretion of the coin owner alone\nand can only be placed by the coin owner ahead of time.\n\nWe suspect that this modest change could actually be a game-changer for\nbitcoin security: clients and keys are notoriously hard to secure, and a\nfacility that allows you to possibly recover, and if not, permanently keep\nthe hacker from acquiring your funds, could greatly deter Bitcoin thefts.\n\nAs always, comments and suggestions are welcome.\n- egs, Ittay Eyal and Malte Moeser.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160226/391038e4/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Vaults.",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Emin G\u00fcn Sirer"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2776
        }
    },
    {
        "title": "[bitcoin-dev] The first successful Zero-Knowledge Contingent Payment",
        "thread_messages": [
            {
                "author": "Gregory Maxwell",
                "date": "2016-02-26T21:42:26",
                "message_text_only": "I am happy to announce the first successful Zero-Knowledge Contingent\nPayment (ZKCP) on the Bitcoin network.\n\nZKCP is a transaction protocol that allows a buyer to purchase\ninformation from a seller using Bitcoin in a manner which is private,\nscalable, secure, and which doesn\u2019t require trusting anyone: the\nexpected information is transferred if and only if the payment is\nmade. The buyer and seller do not need to trust each other or depend\non arbitration by a third party.\n\nImagine a movie-style \u201cbriefcase swap\u201d (one party with a briefcase\nfull of cash, another containing secret documents), but without the\npotential scenario of one of the cases being filled with shredded\nnewspaper and the resulting exciting chase scene.\n\nAn example application would be the owners of a particular make of\ne-book reader cooperating to purchase the DRM master keys from a\nfailing manufacturer, so that they could load their own documents on\ntheir readers after the vendor\u2019s servers go offline. This type of sale\nis inherently irreversible, potentially crosses multiple\njurisdictions, and involves parties whose financial stability is\nuncertain\u2013meaning that both parties either take a great deal of risk\nor have to make difficult arrangement. Using a ZKCP avoids the\nsignificant transactional costs involved in a sale which can otherwise\neasily go wrong.\n\nIn today\u2019s transaction I purchased a solution to a 16x16 Sudoku puzzle\nfor 0.10 BTC from Sean Bowe, a member of the Zcash team, as part of a\ndemonstration performed live at Financial Cryptography 2016 in\nBarbados. I played my part in the transaction remotely from\nCalifornia.\n\nThe transfer involved two transactions:\n\n8e5df5f792ac4e98cca87f10aba7947337684a5a0a7333ab897fb9c9d616ba9e\n200554139d1e3fe6e499f6ffb0b6e01e706eb8c897293a7f6a26d25e39623fae\n\nAlmost all of the engineering work behind this ZKCP implementation was\ndone by Sean Bowe, with support from Pieter Wuille, myself, and Madars\nVirza.\n\n\nRead more, including technical details at\nhttps://bitcoincore.org/en/2016/02/26/zero-knowledge-contingent-payments-announcement/\n\n[I hope to have a ZKCP sudoku buying faucet up shortly. :) ]"
            },
            {
                "author": "Sergio Demian Lerner",
                "date": "2016-02-26T23:06:40",
                "message_text_only": "Congratulations!\n\nIt a property of the SKCP system that the person who performed the trusted\nsetup cannot extract any information from a proof?\n\nIn other words, is it proven hard to obtain information from a proof by the\nbuyer?\n\nOn Fri, Feb 26, 2016 at 6:42 PM, Gregory Maxwell via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I am happy to announce the first successful Zero-Knowledge Contingent\n> Payment (ZKCP) on the Bitcoin network.\n>\n> ZKCP is a transaction protocol that allows a buyer to purchase\n> information from a seller using Bitcoin in a manner which is private,\n> scalable, secure, and which doesn\u2019t require trusting anyone: the\n> expected information is transferred if and only if the payment is\n> made. The buyer and seller do not need to trust each other or depend\n> on arbitration by a third party.\n>\n> Imagine a movie-style \u201cbriefcase swap\u201d (one party with a briefcase\n> full of cash, another containing secret documents), but without the\n> potential scenario of one of the cases being filled with shredded\n> newspaper and the resulting exciting chase scene.\n>\n> An example application would be the owners of a particular make of\n> e-book reader cooperating to purchase the DRM master keys from a\n> failing manufacturer, so that they could load their own documents on\n> their readers after the vendor\u2019s servers go offline. This type of sale\n> is inherently irreversible, potentially crosses multiple\n> jurisdictions, and involves parties whose financial stability is\n> uncertain\u2013meaning that both parties either take a great deal of risk\n> or have to make difficult arrangement. Using a ZKCP avoids the\n> significant transactional costs involved in a sale which can otherwise\n> easily go wrong.\n>\n> In today\u2019s transaction I purchased a solution to a 16x16 Sudoku puzzle\n> for 0.10 BTC from Sean Bowe, a member of the Zcash team, as part of a\n> demonstration performed live at Financial Cryptography 2016 in\n> Barbados. I played my part in the transaction remotely from\n> California.\n>\n> The transfer involved two transactions:\n>\n> 8e5df5f792ac4e98cca87f10aba7947337684a5a0a7333ab897fb9c9d616ba9e\n> 200554139d1e3fe6e499f6ffb0b6e01e706eb8c897293a7f6a26d25e39623fae\n>\n> Almost all of the engineering work behind this ZKCP implementation was\n> done by Sean Bowe, with support from Pieter Wuille, myself, and Madars\n> Virza.\n>\n>\n> Read more, including technical details at\n>\n> https://bitcoincore.org/en/2016/02/26/zero-knowledge-contingent-payments-announcement/\n>\n> [I hope to have a ZKCP sudoku buying faucet up shortly. :) ]\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160226/09f83fe6/attachment.html>"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-02-26T23:33:51",
                "message_text_only": "That is very interesting.\n\nThere has been some recent discussion about atomic cross chain transfers\nbetween Bitcoin and legacy altcoins.  For this purpose a legacy altcoin is\none that has strict IsStandard() rules and none of the advanced script\nopcodes.\n\nIt has a requirement that Bob sends Alice a pair [hash_of_bob_private_key,\nbob_public_key].  Bob has to prove that the hash is actually the result of\nhashing the private key that matches bob_public_key.\n\nThis can be achieved with a cut-and-choose scheme.  It uses a fee so that\nan attacker loses money on average.  It is vulnerable to an attacker who\ndoesn't mind losing money as long as the target loses money too.\n\nBob would have to prove that he has an x such that\n\nxG = <bob_public_key>\nhash(x) = hash_of_bob_private_key\n\nIs the scheme fast enough such that an elliptic curve multiply would be\nfeasible?  You mention 20 seconds for 5 SHA256 operations, so I am guessing\nno?\n\n\n\nOn Fri, Feb 26, 2016 at 11:06 PM, Sergio Demian Lerner via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Congratulations!\n>\n> It a property of the SKCP system that the person who performed the trusted\n> setup cannot extract any information from a proof?\n>\n> In other words, is it proven hard to obtain information from a proof by\n> the buyer?\n>\n> On Fri, Feb 26, 2016 at 6:42 PM, Gregory Maxwell via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> I am happy to announce the first successful Zero-Knowledge Contingent\n>> Payment (ZKCP) on the Bitcoin network.\n>>\n>> ZKCP is a transaction protocol that allows a buyer to purchase\n>> information from a seller using Bitcoin in a manner which is private,\n>> scalable, secure, and which doesn\u2019t require trusting anyone: the\n>> expected information is transferred if and only if the payment is\n>> made. The buyer and seller do not need to trust each other or depend\n>> on arbitration by a third party.\n>>\n>> Imagine a movie-style \u201cbriefcase swap\u201d (one party with a briefcase\n>> full of cash, another containing secret documents), but without the\n>> potential scenario of one of the cases being filled with shredded\n>> newspaper and the resulting exciting chase scene.\n>>\n>> An example application would be the owners of a particular make of\n>> e-book reader cooperating to purchase the DRM master keys from a\n>> failing manufacturer, so that they could load their own documents on\n>> their readers after the vendor\u2019s servers go offline. This type of sale\n>> is inherently irreversible, potentially crosses multiple\n>> jurisdictions, and involves parties whose financial stability is\n>> uncertain\u2013meaning that both parties either take a great deal of risk\n>> or have to make difficult arrangement. Using a ZKCP avoids the\n>> significant transactional costs involved in a sale which can otherwise\n>> easily go wrong.\n>>\n>> In today\u2019s transaction I purchased a solution to a 16x16 Sudoku puzzle\n>> for 0.10 BTC from Sean Bowe, a member of the Zcash team, as part of a\n>> demonstration performed live at Financial Cryptography 2016 in\n>> Barbados. I played my part in the transaction remotely from\n>> California.\n>>\n>> The transfer involved two transactions:\n>>\n>> 8e5df5f792ac4e98cca87f10aba7947337684a5a0a7333ab897fb9c9d616ba9e\n>> 200554139d1e3fe6e499f6ffb0b6e01e706eb8c897293a7f6a26d25e39623fae\n>>\n>> Almost all of the engineering work behind this ZKCP implementation was\n>> done by Sean Bowe, with support from Pieter Wuille, myself, and Madars\n>> Virza.\n>>\n>>\n>> Read more, including technical details at\n>>\n>> https://bitcoincore.org/en/2016/02/26/zero-knowledge-contingent-payments-announcement/\n>>\n>> [I hope to have a ZKCP sudoku buying faucet up shortly. :) ]\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160226/cf480c4a/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2016-02-26T23:45:03",
                "message_text_only": "On Fri, Feb 26, 2016 at 11:33 PM, Tier Nolan via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> That is very interesting.\n>\n> There has been some recent discussion about atomic cross chain transfers\n> between Bitcoin and legacy altcoins.  For this purpose a legacy altcoin is\n> one that has strict IsStandard() rules and none of the advanced script\n> opcodes.\n\nOne might wonder why anyone would want to own coins that couldn't keep\nup technologically, but to each his own. (especially one defunct\nenough that it can't even update IsStandard rules...)\n\nI don't think it's infeasible to do the EC multiply in a snark, but an\nefficient implementation would be a lot of work. You'd probably want\nto build a circuit for the field operations using 128 bit operations.\nFortunately the overall operation is pretty easy to directly convert\ninto a circuit (e.g. no branching).\n\nWhy not use the single-show-signature scheme I came up with a while\nback on the Bitcoin side to force the bitcoin side to reveal a private\nkey?\n\nhttp://lists.linuxfoundation.org/pipermail/lightning-dev/2015-November/000344.html"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-02-26T23:56:58",
                "message_text_only": "On Fri, Feb 26, 2016 at 11:45 PM, Gregory Maxwell <greg at xiph.org> wrote:\n\n> Why not use the single-show-signature scheme I came up with a while\n> back on the Bitcoin side to force the bitcoin side to reveal a private\n> key?\n>\n>\n> http://lists.linuxfoundation.org/pipermail/lightning-dev/2015-November/000344.html\n>\n\nThanks for the info, I will give it a look.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160226/1116efe7/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "The first successful Zero-Knowledge Contingent Payment",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Sergio Demian Lerner",
                "Gregory Maxwell",
                "Tier Nolan"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 10982
        }
    },
    {
        "title": "[bitcoin-dev] Fwd: The first successful Zero-Knowledge Contingent Payment",
        "thread_messages": [
            {
                "author": "Gregory Maxwell",
                "date": "2016-02-26T23:23:09",
                "message_text_only": "On Fri, Feb 26, 2016 at 11:06 PM, Sergio Demian Lerner\n<sergio.d.lerner at gmail.com> wrote:\n> Congratulations!\n>\n> It a property of the SKCP system that the person who performed the trusted\n> setup cannot extract any information from a proof?\n>\n> In other words, is it proven hard to obtain information from a proof by the\n> buyer?\n\nYes, the secrecy is information theoretic (assuming no implementation\nbugs); beyond the truth of the outcome. This holds even if the\ninitialization is malicious.\n\nThe soundness of this scheme is computational-- we're trusting a deep\nstack of cryptographic assumptions that the proofs cannot be forged."
            }
        ],
        "thread_summary": {
            "title": "Fwd: The first successful Zero-Knowledge Contingent Payment",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Gregory Maxwell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 635
        }
    },
    {
        "title": "[bitcoin-dev] Fast bootstrapping with a pre-generated UTXO-set database",
        "thread_messages": [
            {
                "author": "Jonas Schnelli",
                "date": "2016-02-29T10:29:05",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\nHi\n\nI\u2019ve been thinking around a solution to reduce nodes bootstrap time\n(IBD) as well as a way to reduce the amount of bandwidth/network usage\nper node.\nNot sure if this idea was/is already discussed, haven\u2019t found anything\nin a quick research.\n\n\n==Title==\nFast bootstrapping with a pre-generated UTXO-set database.\n\n==Abstract==\nThis documents describes a way how bitcoin nodes can bootstrap faster\nby loading a pre-generated UTXO-set datafile with moderate reduction\nof the security model.\n\n==Specification==\nBitcoin-core or any other full node client will need to provide a\nfeature to \"freeze\" the UTXO-set at a specified height (will require a\nreindex). The frozen UTXO-set \u2013 at a specific height \u2013 will be\ndeterministic linearized in a currently not specified\ndata-serializing-format.\nAdditionally, a serialized form of the current chain-index (chain\ncontaining all block-headers) up to the specified height will be\nappended to the pre-generated UTXO-set-datafile.\nThe datafile will be hashed with a double SHA256.\n\nThe corresponding hash will be produced/reproduced and signed (ECDSA)\nby a group of developers, ideally the same group of developers who are\nalso signing deterministic builds (binary distribution).\n\nFull node client implementations that supports bootstrapping from a\npre-generated UTXO-set, need to include...\n1.) a set of pubkeys from trusted developers\n2.) the hash (or hashes) of the pre-generated UTXO-set-datafile(s)\n3.) n signatures of the hash(es) from 2) from a subset of developers\ndefined in 1)\n\nTo guarantee the integrity of developers pubkeys & signatures, methods\nlike the current gitian build, used in bitcoin-core, must be used.\n\nNew nodes could download a copy of the pre-generated UTXO-set, hash\nit, verify the hash against the allowed UTXO-sets, verify the ECDSA\nsignatures from various developers, and continue bootstrapping from\nthe specified height if the users accepts the amount of valid signatures\n.\n\nSharing of the pre-generated UTXO-set can be done over CDNs,\nbit-torrent or any other file hosting solution. It would also be\npossible to extend the bitcoin p2p layer with features to\ndistribute/share a such pre-generated UTXO-set, in chunks and with the\naccording hashes to detect invalidity before downloading the whole\ncontent (but would probably end up in something very similar to\nbit-torrent).\n\n\n- ----------------------\n</jonas>\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v2\n\niQIcBAEBCAAGBQJW1B1wAAoJECnUvLZBb1PsqzsP/iSdvyhUzy+BZVSZbKXNjk5P\n2vrtirI6NvKQd8hHbrcFeLfyswzYc2JWRnX8sATlauIS0pYdr97JriwUGlvxvNrY\niVTDdf8MIVu8zScLQtJbMatpMvsewtqQEidn/yxWIhiCg4G2T5DZmlBU6O4XIKR6\n5aPHElGOKZ15EWGHBG7z4owj3MiOaxhD9q5erBbfLPpcm08o6XAv5miqmGnnn3zh\ngocg4Gxs6iDygh3b2dCJFwWIVPxF6UVJhyjv2kLZUmEHT2Y2QvdGcLIIewcWHDze\nkgoZYmOEowujCbmeJ+LBwgOI0c1N6L/ciomPBne7ILmK4LyUEzyMLJKNYf/sZ8vI\nsVlmwZwZZLfILC7mzMAM0pfj99IOW680WHch9v31lWFlxW/bLvLqAO7n3acQuD6s\nxCZN2nAhmWC8FnMFxqB3EUz0lX8giV3qRJZjbQMS+ZrngYkAmVv2bAsoLndqf6MO\nl9W8B+ICg1KZLGIOF2pUrInpkB6gUALDFnypV4CeIVdeqtk5l4LnCHK6c4++Hl5n\nBv5HQ/wTgKKNFtHBEJpWyYWvAjfFtgUZUKblR+Bh+D7/Gte1ehiYd02KYD4ds9Y4\n3gfO8YbAz/I14Yuh2bIlvVKPWnLQBwL5BBioBfvmhV/r6rEpzWvB7H6Fmi1c759l\nVlL0GiUV8ar2LlFhEmWk\n=lZSy\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-02-29T11:49:57",
                "message_text_only": "One of the proposals was to build the UTXO set backwards.  You start from\nthe newest block and work backwards.\n\nThe database contains UTXOs (unspent transaction outputs) and \"UFTXI\"\n(unfunded transaction inputs).\n\nThe procedure would be\n\nFor each transaction (last to first ordering)\n    For each output\n        - check if it is in the UFTXI set\n        -- If so, validate the signatures\n        -- If not, add it to the UTXO set\n\n    For each input\n        - Add to the UFTXI set\n\nWhen you receive a transaction, it checks all the inputs\n-- If all inputs are in the UTXO set, it says confirmed\n-- Otherwise, gets marked as \"unknown inputs\"\n\nThere would also be a counter indicating how many blocks it has validated.\n\nA transaction with an unfunded input counts as validated back to the block\nit was included in.  Transactions count as confirmed to their ancestor that\nhas the newest validation time.\n\nAssume that the node had validated the last 10000 blocks and you had a\ntransaction with one input.  Assume the input transaction was included 5000\nblocks ago and its input was included 50,000 blocks ago.\n\nTX-A) input (TX-B:0) included in block 6 blocks ago\nTX-B) input (TX-C:0) included in block 5000 ago\nTX-C) input (TX-B:0) included in block 20000 ago\n\nTX-C would not be known to the node since it has only gone back 10000\nblocks.\n\nTX-A would have confirms 6 / 5000.  This means that its outputs have been\nconfirmed by 6 blocks (confirms work as currently) and that its inputs have\nbeen confirmed by 5000 blocks.\n\nThe reference client could mark transactions with 6+ output confirms and\n1000+ input confirms as confirmed.\n\nOnce it hits the genesis block, then all transactions would be\n6/<infinity>, so it could drop the second number.\n\n\nOn Mon, Feb 29, 2016 at 10:29 AM, Jonas Schnelli via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> -----BEGIN PGP SIGNED MESSAGE-----\n> Hash: SHA256\n>\n> Hi\n>\n> I\u2019ve been thinking around a solution to reduce nodes bootstrap time\n> (IBD) as well as a way to reduce the amount of bandwidth/network usage\n> per node.\n> Not sure if this idea was/is already discussed, haven\u2019t found anything\n> in a quick research.\n>\n>\n> ==Title==\n> Fast bootstrapping with a pre-generated UTXO-set database.\n>\n> ==Abstract==\n> This documents describes a way how bitcoin nodes can bootstrap faster\n> by loading a pre-generated UTXO-set datafile with moderate reduction\n> of the security model.\n>\n> ==Specification==\n> Bitcoin-core or any other full node client will need to provide a\n> feature to \"freeze\" the UTXO-set at a specified height (will require a\n> reindex). The frozen UTXO-set \u2013 at a specific height \u2013 will be\n> deterministic linearized in a currently not specified\n> data-serializing-format.\n> Additionally, a serialized form of the current chain-index (chain\n> containing all block-headers) up to the specified height will be\n> appended to the pre-generated UTXO-set-datafile.\n> The datafile will be hashed with a double SHA256.\n>\n> The corresponding hash will be produced/reproduced and signed (ECDSA)\n> by a group of developers, ideally the same group of developers who are\n> also signing deterministic builds (binary distribution).\n>\n> Full node client implementations that supports bootstrapping from a\n> pre-generated UTXO-set, need to include...\n> 1.) a set of pubkeys from trusted developers\n> 2.) the hash (or hashes) of the pre-generated UTXO-set-datafile(s)\n> 3.) n signatures of the hash(es) from 2) from a subset of developers\n> defined in 1)\n>\n> To guarantee the integrity of developers pubkeys & signatures, methods\n> like the current gitian build, used in bitcoin-core, must be used.\n>\n> New nodes could download a copy of the pre-generated UTXO-set, hash\n> it, verify the hash against the allowed UTXO-sets, verify the ECDSA\n> signatures from various developers, and continue bootstrapping from\n> the specified height if the users accepts the amount of valid signatures\n> .\n>\n> Sharing of the pre-generated UTXO-set can be done over CDNs,\n> bit-torrent or any other file hosting solution. It would also be\n> possible to extend the bitcoin p2p layer with features to\n> distribute/share a such pre-generated UTXO-set, in chunks and with the\n> according hashes to detect invalidity before downloading the whole\n> content (but would probably end up in something very similar to\n> bit-torrent).\n>\n>\n> - ----------------------\n> </jonas>\n> -----BEGIN PGP SIGNATURE-----\n> Version: GnuPG v2\n>\n> iQIcBAEBCAAGBQJW1B1wAAoJECnUvLZBb1PsqzsP/iSdvyhUzy+BZVSZbKXNjk5P\n> 2vrtirI6NvKQd8hHbrcFeLfyswzYc2JWRnX8sATlauIS0pYdr97JriwUGlvxvNrY\n> iVTDdf8MIVu8zScLQtJbMatpMvsewtqQEidn/yxWIhiCg4G2T5DZmlBU6O4XIKR6\n> 5aPHElGOKZ15EWGHBG7z4owj3MiOaxhD9q5erBbfLPpcm08o6XAv5miqmGnnn3zh\n> gocg4Gxs6iDygh3b2dCJFwWIVPxF6UVJhyjv2kLZUmEHT2Y2QvdGcLIIewcWHDze\n> kgoZYmOEowujCbmeJ+LBwgOI0c1N6L/ciomPBne7ILmK4LyUEzyMLJKNYf/sZ8vI\n> sVlmwZwZZLfILC7mzMAM0pfj99IOW680WHch9v31lWFlxW/bLvLqAO7n3acQuD6s\n> xCZN2nAhmWC8FnMFxqB3EUz0lX8giV3qRJZjbQMS+ZrngYkAmVv2bAsoLndqf6MO\n> l9W8B+ICg1KZLGIOF2pUrInpkB6gUALDFnypV4CeIVdeqtk5l4LnCHK6c4++Hl5n\n> Bv5HQ/wTgKKNFtHBEJpWyYWvAjfFtgUZUKblR+Bh+D7/Gte1ehiYd02KYD4ds9Y4\n> 3gfO8YbAz/I14Yuh2bIlvVKPWnLQBwL5BBioBfvmhV/r6rEpzWvB7H6Fmi1c759l\n> VlL0GiUV8ar2LlFhEmWk\n> =lZSy\n> -----END PGP SIGNATURE-----\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160229/b13250f5/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Fast bootstrapping with a pre-generated UTXO-set database",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Tier Nolan",
                "Jonas Schnelli"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 8871
        }
    }
]