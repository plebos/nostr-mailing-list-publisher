[
    {
        "title": "[bitcoin-dev] BIP draft: Memo server",
        "thread_messages": [
            {
                "author": "Chris Priest",
                "date": "2016-06-02T00:21:54",
                "message_text_only": "I'm currently working on a wallet called multiexplorer. You can check\nit at https://multiexplorer.com/wallet\n\nIt supports all the BIPs, including the ones that lets you export and\nimport based on a 12 word mnemonic. This lets you easily import\naddresses from one wallet to the next. For instance, you can\ncopy+paste your 12 word mnemonic from Coinbase CoPay into\nMultiexplorer wallet and all of your address and transaction history\nis imported (except CoPay doesn't support altcoins, so it will just be\nyour BTC balance that shows up). Its actually pretty cool, but not\neverything is transferred over.\n\nFor instance, some people like to add little notes such as \"paid sally\nfor lunch at Taco Bell\", or \"Paid rent\" to each transaction they make\nthrough their wallet's UI. When you export and import into another\nwallet these memos are lost, as there is no way for this data to be\nencoded into the mnemonic.\n\nFor my next project, I want to make a stand alone system for archiving\nand serving these memos. After it's been built and every wallet\nsupports the system, you should be able to move from one wallet by\njust copy+pasting the mnemonic into the next wallet without losing\nyour memos. This will make it easier for people to move off of old\nwallets that may not be safe anymore, to more modern wallets with\nbetter security features. Some people may want to switch wallets, but\nsince its much harder to backup memos, people may feel stuck using a\ncertain wallet. This is bad because it creates lock in.\n\nI wrote up some details of how the system will work:\n\nhttps://github.com/priestc/bips/blob/master/memo-server.mediawiki\n\nBasically the memos are encrypted and then sent to a server where the\nmemo is stored. An API exists that allows wallets to get the memos\nthrough an HTTPS interface. There isn't one single memo server, but\nmultiple memo servers all ran by different people. These memo servers\nshare data amongst each other through a sync process.\n\nThe specifics of how the memos will be encrypted have not been set in\nstone yet. The memos will be publicly propagated, so it is important\nthat they are encrypted strongly. I'm not a cryptography expert, so\nsomeone else has to decide on the scheme that is appropriate."
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-06-02T00:41:27",
                "message_text_only": "First of all, and most importantly, I like the idea/concept.\n\nThe first issue I see is that this scheme exposes private information in the \nform of which inputs/outputs are related to the user. But IMO this information \nshould also be private and kept encrypted, so memo servers don't have anything \nat all to leak. \n\nNote this necessarily means you can't reuse the keys for the blockchain UTXOs \nfor memos. But such key reuse is also a risk that should be avoided anyway. \nInstead, I suggest encrypting all the memos to an arbitrary key which is \nderived from the HD seed and shouldn't ever be used for UTXOs.\n\nIdeally, the memo server shouldn't be tied to a specific wallet schema. So the \nnext step is to not tell the memo server anything except your memo-specific \nidentifier (which can be a hash of a pubkey, or really anything at all - \nthere's no reason the memo server needs to know ANYTHING about the user's \nwallet). Using an arbitrary identifier of sufficient length allows for future \nwallet schemas to continue to use the same memo servers. (The specifics on how \nto derive the identifier can be specified in a separate BIP to ensure wallets \ncan be compatible with each other.)\n\nI don't think there is a real need for memo servers to sync data. It should be \nsufficient for users to decide on two or more memo servers they wish to \nentrust their memos with, or possibly trust only their own memo server(s).\n\nThere should probably also be a way for memos of different types. Some wallets \nmight only support simple memos, but others might associate more data for (eg) \nproof-of-existence schemas. What types are used *might* be desirable to \nencrypt as well, so this should probably be in the second \"how wallets use it\" \nBIP.\n\nIIRC, Electrum already has some kind of \"memo server\" interface in a plugin. \nHave you looked at how it works, and considered its features (and/or flaws) \nfor your proposal?\n\nFinally, using \"?data&data&data\" doesn't follow the standard \n\"?key=value&key=value\" scheme; simple to fix.\n\nLuke\n\nOn Thursday, June 02, 2016 12:21:54 AM Chris Priest via bitcoin-dev wrote:\n> I'm currently working on a wallet called multiexplorer. You can check\n> it at https://multiexplorer.com/wallet\n> \n> It supports all the BIPs, including the ones that lets you export and\n> import based on a 12 word mnemonic. This lets you easily import\n> addresses from one wallet to the next. For instance, you can\n> copy+paste your 12 word mnemonic from Coinbase CoPay into\n> Multiexplorer wallet and all of your address and transaction history\n> is imported (except CoPay doesn't support altcoins, so it will just be\n> your BTC balance that shows up). Its actually pretty cool, but not\n> everything is transferred over.\n> \n> For instance, some people like to add little notes such as \"paid sally\n> for lunch at Taco Bell\", or \"Paid rent\" to each transaction they make\n> through their wallet's UI. When you export and import into another\n> wallet these memos are lost, as there is no way for this data to be\n> encoded into the mnemonic.\n> \n> For my next project, I want to make a stand alone system for archiving\n> and serving these memos. After it's been built and every wallet\n> supports the system, you should be able to move from one wallet by\n> just copy+pasting the mnemonic into the next wallet without losing\n> your memos. This will make it easier for people to move off of old\n> wallets that may not be safe anymore, to more modern wallets with\n> better security features. Some people may want to switch wallets, but\n> since its much harder to backup memos, people may feel stuck using a\n> certain wallet. This is bad because it creates lock in.\n> \n> I wrote up some details of how the system will work:\n> \n> https://github.com/priestc/bips/blob/master/memo-server.mediawiki\n> \n> Basically the memos are encrypted and then sent to a server where the\n> memo is stored. An API exists that allows wallets to get the memos\n> through an HTTPS interface. There isn't one single memo server, but\n> multiple memo servers all ran by different people. These memo servers\n> share data amongst each other through a sync process.\n> \n> The specifics of how the memos will be encrypted have not been set in\n> stone yet. The memos will be publicly propagated, so it is important\n> that they are encrypted strongly. I'm not a cryptography expert, so\n> someone else has to decide on the scheme that is appropriate.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            }
        ],
        "thread_summary": {
            "title": "BIP draft: Memo server",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Chris Priest",
                "Luke Dashjr"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 6823
        }
    },
    {
        "title": "[bitcoin-dev] BIP141 segwit consensus rule update: extension of witness program definition",
        "thread_messages": [
            {
                "author": "Johnson Lau",
                "date": "2016-06-08T05:57:36",
                "message_text_only": "Please note that the segregated witness (BIP141) consensus rule is updated. Originally, a witness program is a scriptPubKey or redeemScript that consists of a 1-byte push opcode (OP_0 to OP_16) followed by a data push between 2 and 32 bytes. The definition is now extended to 2 to 40 bytes:\nhttps://github.com/bitcoin/bips/commit/d1b52cb198066d4e515e8a50fc3928c5397c3d9b https://github.com/bitcoin/bitcoin/pull/7910/commits/14d4d1d23a3cbaa8a3051d0da10ff7a536517ed0\n\n\nWhy?\n----------\nBIP141 defines only version 0 witness program: 20 bytes program for P2WPKH and 32 bytes program for P2WSH. Versions 1 to 16 are not defined, and are considered as anyone-can-spend scripts, reserved for future extension (e.g. the proposed BIP114). BIP141 also requires that only a witness program input may have witness data. Therefore, before this update, an 1-byte push opcode followed by a 33 bytes data push was not considered to be a witness program, and no witness data is allowed for that.\n\nThis may be over-restrictive for a future witness program softfork. When 32-byte program is used, this leaves only 16 versions for upgrade, and any \u201csub-version\u201d metadata must be recorded in the witness field. This may not be compatible with some novel hashing functions we are exploring.\n\nBy extending the maximum length by 8 bytes, it allows up to 16 * 2 ^ 64 versions for future upgrades, which is enough for any foreseeable use.\n\n\nWhy not make it even bigger, e.g. 75 bytes?\n----------\nA 40 bytes witness program allows a 32-byte hash with 8-byte metadata. For any scripts that are larger than 32 bytes, they should be recorded in the witness field, like P2WSH in BIP141, to reduce the transaction cost and impact on UTXO set. Since SHA256 is already used everywhere, it is very unlikely that we would require a larger witness program (e.g. SHA512) without also a major revamp of the bitcoin protocol.\n\nIn any case, since scripts with a 1-byte push followed by a push of >40 bytes remain anyone-can-spend, we always have the option to redefine them with a softfork.\n\n\nWhat are affected?\n----------\nAs defined in BIP141, a version 0 witness program is valid only with 20 bytes (P2WPKH) or 32 bytes (P2WSH). Before this update, an OP_0 followed by a data push of 33-40 bytes was not a witness program and considered as anyone-can-spend. Now, such a script will fail due to incorrect witness program length.\n\nBefore this update, no witness data was allowed for a script with a 1-byte push followed by a data push of 33-40 bytes. This is now allowed.\n\n\n\nActions to take:\n----------\nIf you are running a segnet node, or a testnet node with segwit code, please upgrade to the latest version at https://github.com/bitcoin/bitcoin/pull/7910\n\nIf you have an alternative implementation, please make sure your consensus code is updated accordingly, or your node may fork off the network.\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 671 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160608/cbf69a4f/attachment.sig>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-06-08T07:29:22",
                "message_text_only": "On Wednesday, June 08, 2016 5:57:36 AM Johnson Lau via bitcoin-dev wrote:\n> Why not make it even bigger, e.g. 75 bytes?\n\nI don't see a sufficient answer to this question. Pieter explained why >75 \nwould be annoying, but 75 seems like it should be fine.\n\n> In any case, since scripts with a 1-byte push followed by a push of >40\n> bytes remain anyone-can-spend, we always have the option to redefine them\n> with a softfork.\n\nIt's not that simple, since this is preventing use of the witness field for \nsuch scripts. With this limit in place, any such a softfork would suddenly \nrequire either two different witness commitments, or disabling the previous \nwitness transaction format.\n\nLuke"
            },
            {
                "author": "Johnson Lau",
                "date": "2016-06-08T08:23:51",
                "message_text_only": "> On 8 Jun 2016, at 15:29, Luke Dashjr <luke at dashjr.org> wrote:\n> \n> On Wednesday, June 08, 2016 5:57:36 AM Johnson Lau via bitcoin-dev wrote:\n>> Why not make it even bigger, e.g. 75 bytes?\n> \n> I don't see a sufficient answer to this question. Pieter explained why >75\n> would be annoying, but 75 seems like it should be fine.\n> \n>> In any case, since scripts with a 1-byte push followed by a push of >40\n>> bytes remain anyone-can-spend, we always have the option to redefine them\n>> with a softfork.\n> \n> It's not that simple, since this is preventing use of the witness field for\n> such scripts. With this limit in place, any such a softfork would suddenly\n> require either two different witness commitments, or disabling the previous\n> witness transaction format.\n> \n> Luke\n\nThis is exactly why I proposed to extend the definition. My initial proposal was extending it to 33 bytes to effectively allow 16*256 new script versions, assuming we will keep using 32 bytes program hash.\n\nIf someday 32 bytes hash is deemed to be unsafe, the txid would also be unsafe and a hard fork might be needed. Therefore, I don\u2019t see how a witness program larger than 40 bytes would be useful in any case (as it is more expensive and takes more UTXO space). I think Pieter doesn\u2019t want to make it unnecessarily lenient.\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 671 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160608/b00c1e10/attachment.sig>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-06-08T16:45:10",
                "message_text_only": "On Wednesday, June 08, 2016 8:23:51 AM Johnson Lau wrote:\n> If someday 32 bytes hash is deemed to be unsafe, the txid would also be\n> unsafe and a hard fork might be needed. Therefore, I don\u2019t see how a\n> witness program larger than 40 bytes would be useful in any case (as it is\n> more expensive and takes more UTXO space). I think Pieter doesn\u2019t want to\n> make it unnecessarily lenient.\n\nThere is no harm in being lenient, but it limits the ability to do softfork \nupgrades in the future. I appreciate Pieter's concern that we'd need to do \nmore development and testing to go to this extreme, which is why I am only \nasking the limit raised to 75 bytes.\n\nLuke"
            },
            {
                "author": "Pieter Wuille",
                "date": "2016-06-12T14:40:17",
                "message_text_only": "On Jun 8, 2016 18:46, \"Luke Dashjr via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> On Wednesday, June 08, 2016 8:23:51 AM Johnson Lau wrote:\n> > If someday 32 bytes hash is deemed to be unsafe, the txid would also be\n> > unsafe and a hard fork might be needed. Therefore, I don\u2019t see how a\n> > witness program larger than 40 bytes would be useful in any case (as it\nis\n> > more expensive and takes more UTXO space). I think Pieter doesn\u2019t want\nto\n> > make it unnecessarily lenient.\n>\n> There is no harm in being lenient, but it limits the ability to do\nsoftfork\n> upgrades in the future. I appreciate Pieter's concern that we'd need to do\n> more development and testing to go to this extreme, which is why I am only\n> asking the limit raised to 75 bytes.\n\nNo strong opinion, but I'd rather not change it anymore, as I don't see the\npoint. Any data you would want to encode there can be moved to the witness\nat 1/4 the cost and replaced by a 256-bit hash. If the data is 43 bytes or\nhigher, that is even cheaper. The only thing that cannot be in the hash is\nmetadata to indicate what hashing/rule scheme itself is used. I think 68\nbits (OP_n + 8 bytes) for that is plenty.\n\n-- \nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160612/ff54a257/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP141 segwit consensus rule update: extension of witness program definition",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Pieter Wuille",
                "Luke Dashjr",
                "Johnson Lau"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 7510
        }
    },
    {
        "title": "[bitcoin-dev] BIP 151 MITM",
        "thread_messages": [
            {
                "author": "Alfie John",
                "date": "2016-06-08T23:47:28",
                "message_text_only": "Hi folks,\n\nOverall I think BIP 151 is a good idea. However unless I'm mistaken, what's to\nprevent someone between peers to suppress the initial 'encinit' message during\nnegotiation, causing both to fallback to plaintext?\n\nPeers should negotiate a secure channel from the outset or backout entirely\nwith no option of falling back. This can be indicated loudly by the daemon\nlistening on an entirely new port.\n\nAlfie\n\n-- \nAlfie John\nhttps://www.alfie.wtf"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2016-06-09T01:24:09",
                "message_text_only": "On Wed, Jun 8, 2016 at 11:47 PM, Alfie John via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Hi folks,\n>\n> Overall I think BIP 151 is a good idea. However unless I'm mistaken, what's to\n> prevent someone between peers to suppress the initial 'encinit' message during\n> negotiation, causing both to fallback to plaintext?\n>\n> Peers should negotiate a secure channel from the outset or backout entirely\n> with no option of falling back. This can be indicated loudly by the daemon\n> listening on an entirely new port.\n\nReduction to plaintext isn't an interesting attack vector for an\nactive attacker: they can simply impersonate the remote side.\n\nThis is addressed via authentication, where available, which is done\nby a separate specification that builds on this one.\n\nWithout authentication this only provides protection against passive attackers."
            },
            {
                "author": "Alfie John",
                "date": "2016-06-09T01:42:59",
                "message_text_only": "On Thu, Jun 09, 2016 at 01:24:09AM +0000, Gregory Maxwell wrote:\n> Reduction to plaintext isn't an interesting attack vector for an active\n> attacker: they can simply impersonate the remote side.\n>\n> This is addressed via authentication, where available, which is done by a\n> separate specification that builds on this one.\n\nAre there any links to discussions on how authentication may be done?\n\nThanks,\n\nAlfie\n\n-- \nAlfie John\nhttps://www.alfie.wtf"
            },
            {
                "author": "Jonas Schnelli",
                "date": "2016-06-09T06:57:29",
                "message_text_only": "Hi\n\n> On Thu, Jun 09, 2016 at 01:24:09AM +0000, Gregory Maxwell wrote:\n>> Reduction to plaintext isn't an interesting attack vector for an active\n>> attacker: they can simply impersonate the remote side.\n>>\n>> This is addressed via authentication, where available, which is done by a\n>> separate specification that builds on this one.\n> \n> Are there any links to discussions on how authentication may be done?\n\nI'm currently working on the Auth-BIP which is not worth reviewing it\nright now (I will post it to the mailing list once it has been reached a\nstable level where it can be discusses).\n\nIf you can't wait, here is the current work:\nhttps://github.com/jonasschnelli/bips/blob/35d7e382cdd6955ff42726c3d06c44e33f61ae52/bip-undef-0.mediawiki\n\n\nMost recent MITM/auth discussion (there where plenty of discussions on\nIRC about this topic):\nhttps://botbot.me/freenode/bitcoin-core-dev/2016-04-04/?msg=63463826&page=3\n\n\n</jonas>\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 819 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160609/8f75bb8c/attachment.sig>"
            },
            {
                "author": "Alfie John",
                "date": "2016-06-09T07:00:51",
                "message_text_only": "On Thu, Jun 09, 2016 at 08:57:29AM +0200, Jonas Schnelli via bitcoin-dev wrote:\n> > Are there any links to discussions on how authentication may be done?\n> \n> I'm currently working on the Auth-BIP which is not worth reviewing it\n> right now (I will post it to the mailing list once it has been reached a\n> stable level where it can be discusses).\n> \n> If you can't wait, here is the current work:\n> https://github.com/jonasschnelli/bips/blob/35d7e382cdd6955ff42726c3d06c44e33f61ae52/bip-undef-0.mediawiki\n> \n> Most recent MITM/auth discussion (there where plenty of discussions on\n> IRC about this topic):\n> https://botbot.me/freenode/bitcoin-core-dev/2016-04-04/?msg=63463826&page=3\n\nAwesome, thanks for the link Jonas.\n\nAlfie\n\n-- \nAlfie John\nhttps://www.alfie.wtf"
            }
        ],
        "thread_summary": {
            "title": "BIP 151 MITM",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Gregory Maxwell",
                "Alfie John",
                "Jonas Schnelli"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 3745
        }
    },
    {
        "title": "[bitcoin-dev] RFC for BIP: Derivation scheme for P2WPKH-nested-in-P2SH based accounts",
        "thread_messages": [
            {
                "author": "Daniel Weigl",
                "date": "2016-06-14T15:41:15",
                "message_text_only": "Hi List,\n\nFollowing up to the discussion last month ( https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-May/012695.html ), ive prepared a proposal for a BIP here:\n\t\n\thttps://github.com/DanielWeigl/bips/blob/master/bip-p2sh-accounts.mediawiki\n\n\nAny comments on it? Does anyone working on a BIP44 compliant wallet implement something different?\nIf there are no objection, id also like to request a number for it.\n\nThx,\nDaniel"
            },
            {
                "author": "Jochen Hoenicke",
                "date": "2016-06-15T10:26:47",
                "message_text_only": "Hello Daniel,\n\nAm 14.06.2016 um 17:41 schrieb Daniel Weigl via bitcoin-dev:\n> Hi List,\n> \n> Following up to the discussion last month ( https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-May/012695.html ), ive prepared a proposal for a BIP here:\n> \t\n> \thttps://github.com/DanielWeigl/bips/blob/master/bip-p2sh-accounts.mediawiki\n> \n> \n> Any comments on it? Does anyone working on a BIP44 compliant wallet implement something different?\n> If there are no objection, id also like to request a number for it.\n\nthank you for going forward with this.  Should we keep the discussion on\nthe list, or should we make it on github?\n\nI think we should already consider not only P2WPKH over P2SH addresses\nbut also \"native\" P2WPKH addresses.  Instead of having one BIP for these\ntwo kinds of segwit addresses and forcing the user to have several\ndifferent accounts for each BIP, the idea would be that every fully\nBIP?? compatible wallet must support both of them.  Since P2WPKH is\nsimpler than P2WPKH over P2SH, this is IMHO reasonable to require.\n\nI would go with the suggestion from Aaron Voisine to use different chain\nid's to distinguish between different address types.   E.g., 0,1 for\nP2WPKH over P2SH and 2,3 for native P2WPKH.  I see no reason why a\nwallet would want to use P2WPKH over P2SH for change addresses instead\nof native P2WPKH, though.\n\n  Jochen"
            },
            {
                "author": "Daniel Weigl",
                "date": "2016-06-15T10:53:27",
                "message_text_only": "Hello Jochen,\n\n> I think we should already consider not only P2WPKH over P2SH addresses\n> but also \"native\" P2WPKH addresses.  Instead of having one BIP for these\n[...]\n> BIP?? compatible wallet must support both of them.  Since P2WPKH is\n> simpler than P2WPKH over P2SH, this is IMHO reasonable to require.\n[...]\n> E.g., 0,1 for\n> P2WPKH over P2SH and 2,3 for native P2WPKH.  I see no reason why a\n\nThats a good point and should be simple to maintain. Yes, ill extend on that part.\n\nThe problem is, we dont have a final decision how the address encoding for P2WPKH \npublic keys should look like. Or do we? Bip141 is \"Status: Deferred\"\n\nBut for now, I can at least include the public key derivation path.\n\n> I see no reason why a\n> wallet would want to use P2WPKH over P2SH for change addresses instead\n> of native P2WPKH, though.\n\nThat would be a big privacy leak, imo. As soon as both outputs are spent, its visible \nwhich one was the P2WPKH-in-P2SH and which one the pure P2WPKH and as a consequence\nyou leak which output was the change and which one the actual sent output\n\nSo, i'd suggest to even make it a requirement for \"normal\" send-to-single-address transactions\nto always use the same output type for the change output (if the wallet is able to recognize it)\n\nDaniel\n\nOn 2016-06-15 12:26, Jochen Hoenicke wrote:\n> Hello Daniel,\n> \n> Am 14.06.2016 um 17:41 schrieb Daniel Weigl via bitcoin-dev:\n>> Hi List,\n>>\n>> Following up to the discussion last month ( https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-May/012695.html ), ive prepared a proposal for a BIP here:\n>> \t\n>> \thttps://github.com/DanielWeigl/bips/blob/master/bip-p2sh-accounts.mediawiki\n>>\n>>\n>> Any comments on it? Does anyone working on a BIP44 compliant wallet implement something different?\n>> If there are no objection, id also like to request a number for it.\n> \n> thank you for going forward with this.  Should we keep the discussion on\n> the list, or should we make it on github?\n> \n> I think we should already consider not only P2WPKH over P2SH addresses\n> but also \"native\" P2WPKH addresses.  Instead of having one BIP for these\n> two kinds of segwit addresses and forcing the user to have several\n> different accounts for each BIP, the idea would be that every fully\n> BIP?? compatible wallet must support both of them.  Since P2WPKH is\n> simpler than P2WPKH over P2SH, this is IMHO reasonable to require.\n> \n> I would go with the suggestion from Aaron Voisine to use different chain\n> id's to distinguish between different address types.   E.g., 0,1 for\n> P2WPKH over P2SH and 2,3 for native P2WPKH.  I see no reason why a\n> wallet would want to use P2WPKH over P2SH for change addresses instead\n> of native P2WPKH, though.\n> \n>   Jochen\n>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2016-06-15T11:00:42",
                "message_text_only": "On Jun 15, 2016 12:53, \"Daniel Weigl via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> That would be a big privacy leak, imo. As soon as both outputs are spent,\nits visible\n> which one was the P2WPKH-in-P2SH and which one the pure P2WPKH and as a\nconsequence\n> you leak which output was the change and which one the actual sent output\n>\n> So, i'd suggest to even make it a requirement for \"normal\"\nsend-to-single-address transactions\n> to always use the same output type for the change output (if the wallet\nis able to recognize it)\n\nIndeed, and you can go even further. When there are multiple \"sending\"\noutputs, pick one at random, and mimic it for the change output. This means\nthat if you have a P2PKH and 3 P2SH sends, you'll have 25% chance for a\nP2PKH change output, and 75% chance for a P2SH output.\n\nYou can go even further of course, if you want privacy that remains after\nthose sends get spent. In that case, you also need to match the template of\nthe redeemscript/witnessscript. For example, if the send you are mimicking\nis a 2-of-3, the change output should also use 2-of-3.\n\n-- \nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160615/35a22171/attachment.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2016-06-15T17:08:13",
                "message_text_only": "On Wed, Jun 15, 2016 at 7:00 AM, Pieter Wuille via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\nIndeed, and you can go even further. When there are multiple \"sending\"\n> outputs, pick one at random, and mimic it for the change output. This means\n> that if you have a P2PKH and 3 P2SH sends, you'll have 25% chance for a\n> P2PKH change output, and 75% chance for a P2SH output.\n>\n\nThis isn't quite perfect because if there is only 1 P2PKH output and you\nknow the person is using the above algorithm then you know the P2PKH output\nisn't the change.\n\nI don't know what the perfect method is.  My guess is that it is to let p\nbe the probability that a P2PKH output is produced over the entire network\nand to pick P2PKH for your change output with probability p (and similarly\nfor other output types).\n\nOn Wed, Jun 15, 2016 at 7:00 AM, Pieter Wuille via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> On Jun 15, 2016 12:53, \"Daniel Weigl via bitcoin-dev\" <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >\n> > That would be a big privacy leak, imo. As soon as both outputs are\n> spent, its visible\n> > which one was the P2WPKH-in-P2SH and which one the pure P2WPKH and as a\n> consequence\n> > you leak which output was the change and which one the actual sent output\n> >\n> > So, i'd suggest to even make it a requirement for \"normal\"\n> send-to-single-address transactions\n> > to always use the same output type for the change output (if the wallet\n> is able to recognize it)\n>\n> Indeed, and you can go even further. When there are multiple \"sending\"\n> outputs, pick one at random, and mimic it for the change output. This means\n> that if you have a P2PKH and 3 P2SH sends, you'll have 25% chance for a\n> P2PKH change output, and 75% chance for a P2SH output.\n>\n> You can go even further of course, if you want privacy that remains after\n> those sends get spent. In that case, you also need to match the template of\n> the redeemscript/witnessscript. For example, if the send you are mimicking\n> is a 2-of-3, the change output should also use 2-of-3.\n>\n> --\n> Pieter\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160615/a1642a0d/attachment.html>"
            },
            {
                "author": "Aaron Voisine",
                "date": "2016-06-18T06:07:48",
                "message_text_only": "This works for segwit version 1 with the addition of also using a different\nchain id.\n\nI presume that segwit version 2 will be implementing schnorr signatures.\nWhat do we know about the likely implementation details? Is there any way\nto avoid using a third derivation path to support it?\n\n\nAaron Voisine\nco-founder and CEO\nbreadwallet <http://breadwallet.com>\n\nOn Tue, Jun 14, 2016 at 8:41 AM, Daniel Weigl via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi List,\n>\n> Following up to the discussion last month (\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-May/012695.html\n> ), ive prepared a proposal for a BIP here:\n>\n>\n> https://github.com/DanielWeigl/bips/blob/master/bip-p2sh-accounts.mediawiki\n>\n>\n> Any comments on it? Does anyone working on a BIP44 compliant wallet\n> implement something different?\n> If there are no objection, id also like to request a number for it.\n>\n> Thx,\n> Daniel\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160617/e8e17b28/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "RFC for BIP: Derivation scheme for P2WPKH-nested-in-P2SH based accounts",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Russell O'Connor",
                "Daniel Weigl",
                "Jochen Hoenicke",
                "Pieter Wuille",
                "Aaron Voisine"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 9619
        }
    },
    {
        "title": "[bitcoin-dev] Merkle trees and mountain ranges",
        "thread_messages": [
            {
                "author": "Bram Cohen",
                "date": "2016-06-15T00:14:23",
                "message_text_only": "This is in response to Peter Todd's proposal for Merkle Mountain Range\ncommitments in blocks:\n\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-May/012715.html\n\nI'm in strong agreement that there's a compelling need to put UTXO\ncommitments in blocks, and that the big barrier to getting it done is\nperformance, particularly latency. But I have strong disagreements (or\nperhaps the right word is skepticism) about the details.\n\nPeter proposes that there should be both UTXO and STXO commitments, and\nthey should be based on Merkle Mountain Ranges based on Patricia Tries. My\nfirst big disagreement is about the need for STXO commitments. I think\nthey're unnecessary and a performance problem. The STXO set is much larger\nthan the utxo set and requires much more memory and horespower to maintain.\nMost if not all of its functionality can in practice be done using the utxo\nset. Almost anything accepting proofs of inclusion and exclusion will have\na complete history of block headers, so to prove inclusion in the stxo set\nyou can use a utxo proof of inclusion in the past and a proof of exclusion\nfor the most recent block. In the case of a txo which has never been\nincluded at all, it's generally possible to show that an ancestor of the\ntxo in question was at one point included but that an incompatible\ndescendant of it (or the ancestor itself) is part of the current utxo set.\nGenerating these sorts of proofs efficiently can for some applications\nrequire a complete STXO set, but that can done with a non-merkle set,\ngetting the vastly better performance of an ordinary non-cryptographic\nhashtable.\n\nThe fundamental approach to handling the latency problem is to have the\nutxo commitments trail a bit. Computing utxo commitments takes a certain\namount of time, too much to hold up block propagation but still hopefully\nvastly less than the average amount of time between blocks. Trailing by a\nsingle block is probably a bad idea because you sometimes get blocks back\nto back, but you never get blocks back to back to back to back. Having the\nutxo set be trailing by a fixed amount - five blocks is probably excessive\n- would do a perfectly good job of keeping latency from every becoming an\nissue. Smaller commitments for the utxos added and removed in each block\nalone could be added without any significant performance penalty. That way\nall blocks would have sufficient commitments for a completely up to date\nproofs of inclusion and exclusion. This is not a controversial approach.\n\nNow I'm going to go out on a limb. My thesis is that usage of a mountain\nrange is unnecessary, and that a merkle tree in the raw can be made\nserviceable by sprinkling magic pixie dust on the performance problem.\n\nThere are two causes of performance problems for merkle trees: hashing\noperations and memory cache misses. For hashing functions, the difference\nbetween a mountain range and a straight merkle tree is roughly that in a\nmountain range there's one operation for each new update times the number\nof times that thing will get merged into larger hills. If there are fewer\nlevels of hills the number of operations is less but the expense of proof\nof inclusion will be larger. For raw merkle trees the number of operations\nper thing added is the log base 2 of the number of levels in the tree,\nminus the log base 2 of the number of things added at once since you can do\nlazy evaluation. For practical Bitcoin there are (very roughly) a million\nthings stored, or 20 levels, and there are (even more roughly) about a\nthousand things stored per block, so each thing forces about 20 - 10 = 10\noperations. If you follow the fairly reasonable guideline of mountain range\nhills go up by factors of four, you instead have 20/2 = 10 operations per\nthing added amortized. Depending on details this comparison can go either\nway but it's roughly a wash and the complexity of a mountain range is\nclearly not worth it at least from the point of view of CPU costs.\n\nBut CPU costs aren't the main performance problem in merkle trees. The\nbiggest issues is cache misses, specifically l1 and l2 cache misses. These\ntend to take a long time to do, resulting in the CPU spending most of its\ntime sitting around doing nothing. A naive tree implementation is pretty\nmuch the worst thing you can possibly build from a cache miss standpoint,\nand its performance will be completely unacceptable. Mountain ranges do a\nfabulous job of fixing this problem, because all their updates are merges\nso the metrics are more like cache misses per block instead of cache misses\nper transaction.\n\nThe magic pixie dust I mentioned earlier involves a bunch of subtle\nimplementation details to keep cache coherence down which should get the\nnumber of cache misses per transaction down under one, at which point it\nprobably isn't a bottleneck any more. There is an implementation in the\nworks here:\n\nhttps://github.com/bramcohen/MerkleSet\n\nThis implementation isn't finished yet! I'm almost there, and I'm\ndefinitely feeling time pressure now. I've spent quite a lot of time on\nthis, mostly because of a bunch of technical reworkings which proved\nnecessary. This is the last time I ever write a database for kicks. But\nthis implementation is good on all important dimensions, including:\n\nLazy root calculation\nFew l1 and l2 cache misses\nSmall proofs of inclusion/exclusion\nReasonably simple implementation\nReasonably efficient in memory\nReasonable defense against malicious insertion attacks\n\nThere is a bit of a false dichotomy with the mountain range approach.\nMountain ranges need underlying merkle trees, and mine are semantically\nnearly identically to Peter's. This is not a coincidence - I adopted\npatricia tries at his suggestion. There are a bunch of small changes which\nallow a more efficient implementation. I believe that my underlying merkle\ntree is unambiguously superior in every way, but the question of whether a\nmountain range is worth it is one which can only be answered empirically,\nand that requires a bunch of implementation work to be done, starting with\nme finishing my merkle tree implementation and then somebody porting it to\nC and optimizing it. The Python version has details which are ridiculous\nand only make sense once it gets ported, and even under the best of\nconditions Python performance is not strongly indicative of C performance.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160614/a1bc30c1/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-16T00:10:40",
                "message_text_only": "On Tue, Jun 14, 2016 at 05:14:23PM -0700, Bram Cohen via bitcoin-dev wrote:\n> This is in response to Peter Todd's proposal for Merkle Mountain Range\n> commitments in blocks:\n> \n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-May/012715.html\n> \n> I'm in strong agreement that there's a compelling need to put UTXO\n> commitments in blocks, and that the big barrier to getting it done is\n> performance, particularly latency. But I have strong disagreements (or\n> perhaps the right word is skepticism) about the details.\n> \n> Peter proposes that there should be both UTXO and STXO commitments, and\n\nNo, that's incorrect - I'm only proposing TXO commitments, not UTXO nor STXO\ncommitments.\n\n> they should be based on Merkle Mountain Ranges based on Patricia Tries. My\n> first big disagreement is about the need for STXO commitments. I think\n> they're unnecessary and a performance problem. The STXO set is much larger\n> than the utxo set and requires much more memory and horespower to maintain.\n\nAgain, I'm not proposing STXO commitments precisely because the set of _spent_\ntransactions grows without bound. TXO commitments with committed sums of\nremaining unspent TXO's and with pruning of old history are special in this\nregard, because once spent the data associated with spent transactions can be\ndiscarded completely, and at the same time, data associated with old history\ncan be pruned with responsibility for keeping it resting on the shoulders of\nthose owning those coins.\n\n> Most if not all of its functionality can in practice be done using the utxo\n> set. Almost anything accepting proofs of inclusion and exclusion will have\n> a complete history of block headers, so to prove inclusion in the stxo set\n> you can use a utxo proof of inclusion in the past and a proof of exclusion\n> for the most recent block. In the case of a txo which has never been\n> included at all, it's generally possible to show that an ancestor of the\n> txo in question was at one point included but that an incompatible\n> descendant of it (or the ancestor itself) is part of the current utxo set.\n> Generating these sorts of proofs efficiently can for some applications\n> require a complete STXO set, but that can done with a non-merkle set,\n> getting the vastly better performance of an ordinary non-cryptographic\n> hashtable.\n\nTXO commitments allows you to do all of this without requiring miners to have\nunbounded storage to create new blocks.\n\n> The fundamental approach to handling the latency problem is to have the\n> utxo commitments trail a bit. Computing utxo commitments takes a certain\n> amount of time, too much to hold up block propagation but still hopefully\n> vastly less than the average amount of time between blocks. Trailing by a\n> single block is probably a bad idea because you sometimes get blocks back\n> to back, but you never get blocks back to back to back to back. Having the\n> utxo set be trailing by a fixed amount - five blocks is probably excessive\n> - would do a perfectly good job of keeping latency from every becoming an\n> issue. Smaller commitments for the utxos added and removed in each block\n> alone could be added without any significant performance penalty. That way\n> all blocks would have sufficient commitments for a completely up to date\n> proofs of inclusion and exclusion. This is not a controversial approach.\n\nAgreed - regardless of approach adding latency to commitment calculations of\nall kinds is something I think we all agree can work in principle, although\nobviously it should be a last resort technique when optimization fails.\n\n> Now I'm going to go out on a limb. My thesis is that usage of a mountain\n> range is unnecessary, and that a merkle tree in the raw can be made\n> serviceable by sprinkling magic pixie dust on the performance problem.\n\nIt'd help if you specified exactly what type of merkle tree you're talking\nabout here; remember that the certificate transparency RFC appears to have\nreinvented merkle mountain ranges, and they call them \"merkle trees\".  Bitcoin\nmeanwhile uses a so-called \"merkle tree\" that's broken, and Zcash uses a\npartially filled fixed-sized perfect tree.\n\n> There are two causes of performance problems for merkle trees: hashing\n> operations and memory cache misses. For hashing functions, the difference\n> between a mountain range and a straight merkle tree is roughly that in a\n> mountain range there's one operation for each new update times the number\n> of times that thing will get merged into larger hills. If there are fewer\n> levels of hills the number of operations is less but the expense of proof\n> of inclusion will be larger. For raw merkle trees the number of operations\n> per thing added is the log base 2 of the number of levels in the tree,\n> minus the log base 2 of the number of things added at once since you can do\n> lazy evaluation. For practical Bitcoin there are (very roughly) a million\n> things stored, or 20 levels, and there are (even more roughly) about a\n> thousand things stored per block, so each thing forces about 20 - 10 = 10\n> operations. If you follow the fairly reasonable guideline of mountain range\n> hills go up by factors of four, you instead have 20/2 = 10 operations per\n> thing added amortized. Depending on details this comparison can go either\n> way but it's roughly a wash and the complexity of a mountain range is\n> clearly not worth it at least from the point of view of CPU costs.\n\nI'm having a hard time understanding this paragraph; could you explain what you\nthink is happening when things are \"merged into larger hills\"?\n\n> But CPU costs aren't the main performance problem in merkle trees. The\n> biggest issues is cache misses, specifically l1 and l2 cache misses. These\n> tend to take a long time to do, resulting in the CPU spending most of its\n> time sitting around doing nothing. A naive tree implementation is pretty\n> much the worst thing you can possibly build from a cache miss standpoint,\n> and its performance will be completely unacceptable. Mountain ranges do a\n> fabulous job of fixing this problem, because all their updates are merges\n> so the metrics are more like cache misses per block instead of cache misses\n> per transaction.\n>\n> The magic pixie dust I mentioned earlier involves a bunch of subtle\n> implementation details to keep cache coherence down which should get the\n> number of cache misses per transaction down under one, at which point it\n> probably isn't a bottleneck any more. There is an implementation in the\n> works here:\n\nAs UTXO/STXO/TXO sets are all enormously larger than L1/L2 cache, it's\nimpossible to get CPU cache misses below one for update operations. The closest\nthing to an exception is MMR's, which due to their insertion-ordering could\nhave good cache locality for appends, in the sense that the mountain tips\nrequired to recalculate the MMR tip digest will already be in cache from the\nprevious append. But that's not sufficient, as you also need to modify old\nTXO's further back in the tree to mark them as spent - that data is going to be\nfar larger than L1/L2 cache.\n\n> https://github.com/bramcohen/MerkleSet\n> \n> This implementation isn't finished yet! I'm almost there, and I'm\n> definitely feeling time pressure now. I've spent quite a lot of time on\n> this, mostly because of a bunch of technical reworkings which proved\n> necessary. This is the last time I ever write a database for kicks. But\n> this implementation is good on all important dimensions, including:\n> \n> Lazy root calculation\n> Few l1 and l2 cache misses\n> Small proofs of inclusion/exclusion\n\nHave you looked at the pruning system that my proofchains work implements?\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160615/9afd4c09/attachment.sig>"
            },
            {
                "author": "Bram Cohen",
                "date": "2016-06-16T01:16:26",
                "message_text_only": "On Wed, Jun 15, 2016 at 5:10 PM, Peter Todd <pete at petertodd.org> wrote:\n\n> On Tue, Jun 14, 2016 at 05:14:23PM -0700, Bram Cohen via bitcoin-dev wrote:\n> >\n> > Peter proposes that there should be both UTXO and STXO commitments, and\n>\n> No, that's incorrect - I'm only proposing TXO commitments, not UTXO nor\n> STXO\n> commitments.\n>\n\nWhat do you mean by TXO commitments? If you mean that it only records\ninsertions rather than deletions, then that can do many of the same proofs\nbut has no way of proving that something is currently in the UTXO set,\nwhich is functionality I'd like to provide.\n\nWhen I say 'merkle tree' what I mean is a patricia trie. What I assume is\nmeant by a merkle mountain range is a series of patricia tries of\ndecreasing size each of which is an addition to the previous one, and\nthey're periodically consolidated into larger tries so the old ones can go\naway. This data structure has the nice property that it's both in sorted\norder and has less than one cache miss per operation because the\nconsolidation operations can be batched and done linearly. There are a\nnumber of different things you could be describing if I misunderstood.\n\n\n> I'm not proposing STXO commitments precisely because the set of _spent_\n> transactions grows without bound.\n\n\nI'm worried that once there's real transaction fees everyone might stop\nconsolidating dust and the set of unspent transactions might grow without\nbound as well, but that's a topic for another day.\n\n\n> > Now I'm going to go out on a limb. My thesis is that usage of a mountain\n> > range is unnecessary, and that a merkle tree in the raw can be made\n> > serviceable by sprinkling magic pixie dust on the performance problem.\n>\n> It'd help if you specified exactly what type of merkle tree you're talking\n> about here; remember that the certificate transparency RFC appears to have\n> reinvented merkle mountain ranges, and they call them \"merkle trees\".\n> Bitcoin\n> meanwhile uses a so-called \"merkle tree\" that's broken, and Zcash uses a\n> partially filled fixed-sized perfect tree.\n>\n\nWhat I'm making is a patricia trie. Its byte level definition is very\nsimilar to the one in your MMR codebase.\n\nEach level of the tree has a single metadata byte and followed by two\nhashes. The hashes are truncated by one byte and the hash function is a\nnon-padding variant of sha256 (right now it's just using regular sha256,\nbut that's a nice optimization which allows everything to fit in a single\nblock).\n\nThe possible metadata values are: TERM0, TERM1, TERMBOTH, ONLY0, ONLY1,\nMIDDLE. They mean:\n\nTERM0, TERM1: There is a single thing in the tree on the specified side.\nThe thing hashed on that side is that thing verbatim. The other side has\nmore than one thing and the hash of it is the root of everything below.\n\nTERMBOTH: There are exactly two things below and they're included inline.\nNote that two things is a special case, if there are more you sometimes\nhave ONLY0 or ONLY1.\n\nONLY0, ONLY1: There are more than two things below and they're all on the\nsame side. This makes proofs of inclusion and exclusion simpler, and makes\nsome implementation details easier, for example there's always something at\nevery level with perfect memory positioning. It doesn't cause much extra\nmemory usage because of the TERMBOTH exception for exactly two things.\n\nMIDDLE: There two or more things on both sides.\n\nThere's also a SINGLETON special case for a tree which contains only one\nthing, and an EMPTY special value for tree which doesn't contain anything.\n\nThe main differences to your patricia trie are the non-padding sha256 and\nthat each level doesn't hash in a record of its depth and the usage of\nONLY0 and ONLY1.\n\n\n>\n> > There are two causes of performance problems for merkle trees: hashing\n> > operations and memory cache misses. For hashing functions, the difference\n> > between a mountain range and a straight merkle tree is roughly that in a\n> > mountain range there's one operation for each new update times the number\n> > of times that thing will get merged into larger hills. If there are fewer\n> > levels of hills the number of operations is less but the expense of proof\n> > of inclusion will be larger. For raw merkle trees the number of\n> operations\n> > per thing added is the log base 2 of the number of levels in the tree,\n> > minus the log base 2 of the number of things added at once since you can\n> do\n> > lazy evaluation. For practical Bitcoin there are (very roughly) a million\n> > things stored, or 20 levels, and there are (even more roughly) about a\n> > thousand things stored per block, so each thing forces about 20 - 10 = 10\n> > operations. If you follow the fairly reasonable guideline of mountain\n> range\n> > hills go up by factors of four, you instead have 20/2 = 10 operations per\n> > thing added amortized. Depending on details this comparison can go either\n> > way but it's roughly a wash and the complexity of a mountain range is\n> > clearly not worth it at least from the point of view of CPU costs.\n>\n> I'm having a hard time understanding this paragraph; could you explain\n> what you\n> think is happening when things are \"merged into larger hills\"?\n>\n\nI'm talking about the recalculation of mountain tips, assuming we're on the\nsame page about what 'MMR' means.\n\n\n> As UTXO/STXO/TXO sets are all enormously larger than L1/L2 cache, it's\n> impossible to get CPU cache misses below one for update operations. The\n> closest\n> thing to an exception is MMR's, which due to their insertion-ordering could\n> have good cache locality for appends, in the sense that the mountain tips\n> required to recalculate the MMR tip digest will already be in cache from\n> the\n> previous append. But that's not sufficient, as you also need to modify old\n> TXO's further back in the tree to mark them as spent - that data is going\n> to be\n> far larger than L1/L2 cache.\n>\n\nThis makes me think we're talking about subtly different things for MMRs.\nThe ones I described above have sub-1 cache miss per update due to the\namortized merging together of old mountains.\n\nTechnically even a patricia trie utxo commitment can have sub-1 cache\nmisses per update if some of the updates in a single block are close to\neach other in memory. I think I can get practical Bitcoin updates down to a\nlittle bit less than one l2 cache miss per update, but not a lot less.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160615/62646c88/attachment-0001.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-16T03:26:12",
                "message_text_only": "On Wed, Jun 15, 2016 at 06:16:26PM -0700, Bram Cohen wrote:\n> On Wed, Jun 15, 2016 at 5:10 PM, Peter Todd <pete at petertodd.org> wrote:\n> \n> > On Tue, Jun 14, 2016 at 05:14:23PM -0700, Bram Cohen via bitcoin-dev wrote:\n> > >\n> > > Peter proposes that there should be both UTXO and STXO commitments, and\n> >\n> > No, that's incorrect - I'm only proposing TXO commitments, not UTXO nor\n> > STXO\n> > commitments.\n> >\n> \n> What do you mean by TXO commitments? If you mean that it only records\n> insertions rather than deletions, then that can do many of the same proofs\n> but has no way of proving that something is currently in the UTXO set,\n> which is functionality I'd like to provide.\n\nI think you need to re-read my original post on TXO commitments, specifically\nwhere I say:\n\n    # TXO Commitments\n\n    A merkle tree committing to the state of __all transaction outputs, both spent\n    and unspent__, we can provide a method of compactly proving the current state of\n    an output.\n\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-May/012715.html\n\n> When I say 'merkle tree' what I mean is a patricia trie. What I assume is\n> meant by a merkle mountain range is a series of patricia tries of\n> decreasing size each of which is an addition to the previous one, and\n> they're periodically consolidated into larger tries so the old ones can go\n> away. This data structure has the nice property that it's both in sorted\n> order and has less than one cache miss per operation because the\n> consolidation operations can be batched and done linearly. There are a\n> number of different things you could be describing if I misunderstood.\n\nNope, MMR's are completely unlike what you just described.\n\n> > I'm not proposing STXO commitments precisely because the set of _spent_\n> > transactions grows without bound.\n> \n> \n> I'm worried that once there's real transaction fees everyone might stop\n> consolidating dust and the set of unspent transactions might grow without\n> bound as well, but that's a topic for another day.\n\nOk, but then if you're concerned about that risk, why introduce a data\nstructure - the STXO set - that's _guaranteed_ to grow without bound?\n\n> > > Now I'm going to go out on a limb. My thesis is that usage of a mountain\n> > > range is unnecessary, and that a merkle tree in the raw can be made\n> > > serviceable by sprinkling magic pixie dust on the performance problem.\n> >\n> > It'd help if you specified exactly what type of merkle tree you're talking\n> > about here; remember that the certificate transparency RFC appears to have\n> > reinvented merkle mountain ranges, and they call them \"merkle trees\".\n> > Bitcoin\n> > meanwhile uses a so-called \"merkle tree\" that's broken, and Zcash uses a\n> > partially filled fixed-sized perfect tree.\n> >\n> \n> What I'm making is a patricia trie. Its byte level definition is very\n> similar to the one in your MMR codebase.\n\nWhich codebase exactly? I have both a insertion-ordered list (MMR) and a\nkey:value mapping (referred to as a \"merbinner tree\" in the codebase) in the\nproofchains codebase. They're very different data structures.\n\n> Each level of the tree has a single metadata byte and followed by two\n> hashes. The hashes are truncated by one byte and the hash function is a\n> non-padding variant of sha256 (right now it's just using regular sha256,\n> but that's a nice optimization which allows everything to fit in a single\n> block).\n> \n> The possible metadata values are: TERM0, TERM1, TERMBOTH, ONLY0, ONLY1,\n> MIDDLE. They mean:\n> \n> TERM0, TERM1: There is a single thing in the tree on the specified side.\n> The thing hashed on that side is that thing verbatim. The other side has\n> more than one thing and the hash of it is the root of everything below.\n> \n> TERMBOTH: There are exactly two things below and they're included inline.\n> Note that two things is a special case, if there are more you sometimes\n> have ONLY0 or ONLY1.\n> \n> ONLY0, ONLY1: There are more than two things below and they're all on the\n> same side. This makes proofs of inclusion and exclusion simpler, and makes\n> some implementation details easier, for example there's always something at\n> every level with perfect memory positioning. It doesn't cause much extra\n> memory usage because of the TERMBOTH exception for exactly two things.\n> \n> MIDDLE: There two or more things on both sides.\n> \n> There's also a SINGLETON special case for a tree which contains only one\n> thing, and an EMPTY special value for tree which doesn't contain anything.\n> \n> The main differences to your patricia trie are the non-padding sha256 and\n> that each level doesn't hash in a record of its depth and the usage of\n> ONLY0 and ONLY1.\n\nI'm rather confused, as the above sounds nothing like what I've implemented,\nwhich only has leaf nodes, inner nodes, and the special empty node singleton,\nfor both the MMR and merbinner trees.\n\n> > I'm having a hard time understanding this paragraph; could you explain\n> > what you\n> > think is happening when things are \"merged into larger hills\"?\n> >\n> \n> I'm talking about the recalculation of mountain tips, assuming we're on the\n> same page about what 'MMR' means.\n\nYeah, we're definitely not...\n\nIn MMR's append operations never need to modify mountain contents.\n\n> > As UTXO/STXO/TXO sets are all enormously larger than L1/L2 cache, it's\n> > impossible to get CPU cache misses below one for update operations. The\n> > closest\n> > thing to an exception is MMR's, which due to their insertion-ordering could\n> > have good cache locality for appends, in the sense that the mountain tips\n> > required to recalculate the MMR tip digest will already be in cache from\n> > the\n> > previous append. But that's not sufficient, as you also need to modify old\n> > TXO's further back in the tree to mark them as spent - that data is going\n> > to be\n> > far larger than L1/L2 cache.\n> >\n> \n> This makes me think we're talking about subtly different things for MMRs.\n> The ones I described above have sub-1 cache miss per update due to the\n> amortized merging together of old mountains.\n\nAgain, see above.\n\n> Technically even a patricia trie utxo commitment can have sub-1 cache\n> misses per update if some of the updates in a single block are close to\n> each other in memory. I think I can get practical Bitcoin updates down to a\n> little bit less than one l2 cache miss per update, but not a lot less.\n\nI'm very confused as to why you think that's possible. When you say \"practical\nBitcoin updates\", what exactly is the data structure you're proposing to\nupdate? How is it indexed?\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160615/8500d863/attachment.sig>"
            },
            {
                "author": "Bram Cohen",
                "date": "2016-06-16T09:07:26",
                "message_text_only": "On Wed, Jun 15, 2016 at 8:26 PM, Peter Todd <pete at petertodd.org> wrote:\n\n> >\n> > What do you mean by TXO commitments? If you mean that it only records\n> > insertions rather than deletions, then that can do many of the same\n> proofs\n> > but has no way of proving that something is currently in the UTXO set,\n> > which is functionality I'd like to provide.\n>\n> I think you need to re-read my original post on TXO commitments,\n> specifically\n> where I say:\n>\n>     # TXO Commitments\n>\n>     A merkle tree committing to the state of __all transaction outputs,\n> both spent\n>     and unspent__, we can provide a method of compactly proving the\n> current state of\n>     an output.\n>\n>\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-May/012715.html\n\n\nOkay, clearly my assumptions about the parts of that post I didn't read\ncarefully were way off. I'll have to look through it carefully to be able\nto make coherent apples to apples comparisons.\n\n> I'm worried that once there's real transaction fees everyone might stop\n> > consolidating dust and the set of unspent transactions might grow without\n> > bound as well, but that's a topic for another day.\n>\n> Ok, but then if you're concerned about that risk, why introduce a data\n> structure - the STXO set - that's _guaranteed_ to grow without bound?\n>\n\nI'm not proposing STXO set commitments either. My point was that there\nshould be incentives for collecting dust. That has nothing to do with this\nthread though and should be discussed separately (also I don't feel like\ndiscussing it because I don't have a good proposal).\n\n\n> > What I'm making is a patricia trie. Its byte level definition is very\n> > similar to the one in your MMR codebase.\n>\n> Which codebase exactly? I have both a insertion-ordered list (MMR) and a\n> key:value mapping (referred to as a \"merbinner tree\" in the codebase) in\n> the\n> proofchains codebase. They're very different data structures.\n>\n\nI'm talking about your merbinner trees. I read through that part of your\ncodebase carefully and got the impression that the MMR tree section used it\nas a building block.\n\n\n> > The main differences to your patricia trie are the non-padding sha256 and\n> > that each level doesn't hash in a record of its depth and the usage of\n> > ONLY0 and ONLY1.\n>\n> I'm rather confused, as the above sounds nothing like what I've\n> implemented,\n> which only has leaf nodes, inner nodes, and the special empty node\n> singleton,\n> for both the MMR and merbinner trees.\n>\n\nIt's quite a bit like merbinner trees. I've basically taken the leaf nodes\nand smushed them into the inner nodes above them, thus saving a hashing\noperation and some memory. They're both binary radix trees.\n\n> Technically even a patricia trie utxo commitment can have sub-1 cache\n> > misses per update if some of the updates in a single block are close to\n> > each other in memory. I think I can get practical Bitcoin updates down\n> to a\n> > little bit less than one l2 cache miss per update, but not a lot less.\n>\n> I'm very confused as to why you think that's possible. When you say\n> \"practical\n> Bitcoin updates\", what exactly is the data structure you're proposing to\n> update? How is it indexed?\n\n\nMy calculations are: a Bitcoin block contains about 2000 updates. The l2\ncache is about 256 kilobytes, and if an update is about 32 bytes times two\nfor the parents, grandparents, etc. then an l2 cache can contain about 4000\nvalues. If the current utxo size is about 2000 * 4000 = 8,000,000 in size\nthen about half the pages which contain a transaction will contain a second\none. I think the utxo set is currently about an order of magnitude greater\nthan that, so the number of such collisions will be fairly mall, hence my\n'less than one but not a lot less' comment.\n\nAs for how it's indexed, at a crypto definition level it's just a binary\nradix tree. In terms of how it's indexed in memory, that involves some\noptimizations to avoid cache misses. Memory is allocated into blocks of\nabout the size of an 12 cache (or maybe an l1 cache, it will require some\ntesting and optimization). Blocks are either branch blocks, which keep\neverything in fixed positions, or leaf blocks, which contain fixed size\nentries for nodes plus indexes within the same leaf block of their\nchildren. Branch blocks can have many children which can be either branch\nblocks or leaf blocks, but typically are either all branch blocks or all\nleaf blocks. Branch blocks always have exactly one parent. Leaf blocks\nalways have all their inputs come from a single branch block, but there can\nbe multiple ones of those. When a branch block overflows it first tries to\nput stuff into the last leaf block it used, and if there's no more room it\nallocates a new one. It's fairly common for branches to have just a few\nleaf children, but they also could have a lot, depending on whether the\nbase 2 log of the number of things currently in the set modulo the number\nlevels in a branch is a small number.\n\nUsually when an update is done it consists of first checking the\nappropriate output of the root block (it's jumped to directly to avoid\nunnecessary memory lookups. If there's nothing there the algorithm will\nwalk back until it finds something.) That leads directly to (usually)\nanother branch whose output is jumped to directly again. At Bitcoin utxo\nset sizes that will usually lead to a leaf block, which is then walked down\nmanually to find the actual terminal node, which is then updated, and the\nparent, grandparent, etc. is then marked invalid until something which was\nalready marked invalid is hit, and it exits. Calculation of hash values is\ndone lazily.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160616/e266893c/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-17T04:34:35",
                "message_text_only": "On Thu, Jun 16, 2016 at 02:07:26AM -0700, Bram Cohen wrote:\n> On Wed, Jun 15, 2016 at 8:26 PM, Peter Todd <pete at petertodd.org> wrote:\n> Okay, clearly my assumptions about the parts of that post I didn't read\n> carefully were way off. I'll have to look through it carefully to be able\n> to make coherent apples to apples comparisons.\n\nThanks!\n\n> > I'm worried that once there's real transaction fees everyone might stop\n> > > consolidating dust and the set of unspent transactions might grow without\n> > > bound as well, but that's a topic for another day.\n> >\n> > Ok, but then if you're concerned about that risk, why introduce a data\n> > structure - the STXO set - that's _guaranteed_ to grow without bound?\n> >\n> \n> I'm not proposing STXO set commitments either. My point was that there\n> should be incentives for collecting dust. That has nothing to do with this\n> thread though and should be discussed separately (also I don't feel like\n> discussing it because I don't have a good proposal).\n\nAh, yeah, I misunderstood you there; as expected absolutely no-one is proposing\nSTXO set commitments. :)\n\n> > > The main differences to your patricia trie are the non-padding sha256 and\n> > > that each level doesn't hash in a record of its depth and the usage of\n> > > ONLY0 and ONLY1.\n> >\n> > I'm rather confused, as the above sounds nothing like what I've\n> > implemented,\n> > which only has leaf nodes, inner nodes, and the special empty node\n> > singleton,\n> > for both the MMR and merbinner trees.\n> >\n> \n> It's quite a bit like merbinner trees. I've basically taken the leaf nodes\n> and smushed them into the inner nodes above them, thus saving a hashing\n> operation and some memory. They're both binary radix trees.\n\nAh, I see what you mean now.\n\nSo above you said that in merbinner trees each node \"hash[es] in a record of\nits depth\" That's actually incorrect: each node commits to the prefix that all\nkeys below that level start with, not just the depth.\n\nThis means that in merbinner trees, cases where multiple keys share parts of\nthe same prefix are handled efficiently, without introducing extra levels\nunnecessarily; there's no need for the ONLY0/1 nodes as the children of an\ninner node will always be on different sides.\n\nWhen keys are randomly distributed, this isn't a big deal; OTOH against\nattackers who are choosing keys, e.g. by grinding hashes, merbinner trees\nalways have maximum depths in proportion to log2(n) of the actual number of\nitems in the tree. Grinding is particularly annoying to deal with due to the\nbirthday attack: creating a ground prefix 64 bits long only takes 32 bits worth\nof work.\n\n\nIn my deterministic expressions work one of the ideas I've been tossing around\nis rather than always using hash digests directly for when you need to commit\nto some data, we could instead extend the idea of a digest to that of a\n\"commitment\", where a commitment is simply some short, but variable-sized,\nstring that uniquely maps to a given set of data. Secondly, commitments do\n*not* always guarantee that the original data can't be recovered from the\ncommitment itself.\n\nBy allowing commitments to be variable sized - say 0 to ~64 bytes - we get a\nnumber of advantages:\n\n1) Data shorter than the length of a digest (32 bytes) can be included in the\ncommitment itself, improving efficiency.\n\n2) Data a little longer than a digest can have hashing delayed, to better fill\nup blocks.\n\nIn particular, case #2 handles your leaf node optimizations generically,\nwithout special cases and additional complexity. It'd also be a better way to\ndo the ONLY0/1 cases, as if the \"nothing on this side\" symbol is a single byte,\neach additional colliding level would simply extend the commitment without\nhashing. In short, you'd have nearly the same level of optimization even if at\nthe cryptography level your tree consists of only leaves, inner nodes, and nil.\n\nAnother advantage of variable sized commitments is that it can help make clear\nto users when it's possible to brute force the message behind the commitment.\nFor instance, digest from a hashed four byte integer can be trivially reversed\nby just trying all combinations. Equally, if that integer is concatenated with\na 32 byte digest that the attacker knows, the value of the integer can be brute\nforced.\n\n> > Technically even a patricia trie utxo commitment can have sub-1 cache\n> > > misses per update if some of the updates in a single block are close to\n> > > each other in memory. I think I can get practical Bitcoin updates down\n> > to a\n> > > little bit less than one l2 cache miss per update, but not a lot less.\n> >\n> > I'm very confused as to why you think that's possible. When you say\n> > \"practical\n> > Bitcoin updates\", what exactly is the data structure you're proposing to\n> > update? How is it indexed?\n> \n> \n> My calculations are: a Bitcoin block contains about 2000 updates. The l2\n> cache is about 256 kilobytes, and if an update is about 32 bytes times two\n> for the parents, grandparents, etc. then an l2 cache can contain about 4000\n> values. If the current utxo size is about 2000 * 4000 = 8,000,000 in size\n> then about half the pages which contain a transaction will contain a second\n> one. I think the utxo set is currently about an order of magnitude greater\n> than that, so the number of such collisions will be fairly mall, hence my\n> 'less than one but not a lot less' comment.\n\nYour estimate of updates requiring 32 bytes of data is *way* off.\n\nEach inner node updated on the path to a leaf node will itself require 32 bytes\nof data to be fetched - the digest of the sibling. As of block 416,628, there\nare 39,167,128 unspent txouts, giving us a tree about 25 levels deep.\n\nSo if I want to update a single leaf, I need to read:\n\n    25 nodes * 32 bytes/node = 800 bytes\n\nof data. Naively, that'd mean our 2,000 updates needs to read 1.6MB from RAM,\nwhich is 6.4x bigger than the L2 cache - it's just not going to fit.\n\nTaking into account the fact that this is a batched update improves things a\nlittle bit. For a node at level i with random access patterns and N accesses\ntotal our amortised cost is 1/(1 + N/2^i) Summing that over 2,000 leaf updates\nand 25 levels gives us ~29,000 total updates, 0.9MB, which is still a lot\nlarger than L2 cache.\n\nWhile this might fit in L3 cache - usually on the order of megabytes - this is\na rather optimistic scenario anyway: we're assuming no other cache pressure and\n100% hit rate.\n\nAnyway hashing is pretty slow. The very fast BLAKE2 is about 3 cycles/byte\n(SHA256 is about 15 cycles/byte) so hashing that same data would take around\n200 cycles, and probably quite a bit more in practice due to overheads from our\nshort message lengths; fetching a cache line from DRAM only takes about 1,000\ncycles. I'd guess that once other overheads are taken into account, even if you\ncould eliminate L2/L3 cache-misses it wouldn't be much of an improvement.\n\n> As for how it's indexed, at a crypto definition level it's just a binary\n> radix tree. In terms of how it's indexed in memory, that involves some\n> optimizations to avoid cache misses. Memory is allocated into blocks of\n> about the size of an 12 cache (or maybe an l1 cache, it will require some\n> testing and optimization). Blocks are either branch blocks, which keep\n> everything in fixed positions, or leaf blocks, which contain fixed size\n> entries for nodes plus indexes within the same leaf block of their\n> children. Branch blocks can have many children which can be either branch\n> blocks or leaf blocks, but typically are either all branch blocks or all\n> leaf blocks. Branch blocks always have exactly one parent. Leaf blocks\n> always have all their inputs come from a single branch block, but there can\n> be multiple ones of those. When a branch block overflows it first tries to\n> put stuff into the last leaf block it used, and if there's no more room it\n> allocates a new one. It's fairly common for branches to have just a few\n> leaf children, but they also could have a lot, depending on whether the\n> base 2 log of the number of things currently in the set modulo the number\n> levels in a branch is a small number.\n> \n> Usually when an update is done it consists of first checking the\n> appropriate output of the root block (it's jumped to directly to avoid\n> unnecessary memory lookups. If there's nothing there the algorithm will\n> walk back until it finds something.) That leads directly to (usually)\n> another branch whose output is jumped to directly again. At Bitcoin utxo\n> set sizes that will usually lead to a leaf block, which is then walked down\n> manually to find the actual terminal node, which is then updated, and the\n> parent, grandparent, etc. is then marked invalid until something which was\n> already marked invalid is hit, and it exits. Calculation of hash values is\n> done lazily.\n\nI think it's safe to say that given our working set is significantly larger\nthan the L2/L3 cache available, none of the above optimizations are likely to\nhelp much. Better to just keep the codebase simple and use standard techniques.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160617/3c2a9dc6/attachment.sig>"
            },
            {
                "author": "Bram Cohen",
                "date": "2016-06-18T02:43:47",
                "message_text_only": "On Thu, Jun 16, 2016 at 9:34 PM, Peter Todd <pete at petertodd.org> wrote:\n\n> So above you said that in merbinner trees each node \"hash[es] in a record\n> of\n> its depth\" That's actually incorrect: each node commits to the prefix that\n> all\n> keys below that level start with, not just the depth.\n\n\nI considered a similar trick at the implementation rather than the\ndefinition level: A node doesn't have to store the prefix which is implicit\nin its position. That would create a fair number of headaches though,\nbecause I'm using fixed size stuff in important ways, and it could at most\nsave about 10% of memory, so it goes into the 'maybe later' bucket.\n\n\n>\n> This means that in merbinner trees, cases where multiple keys share parts\n> of\n> the same prefix are handled efficiently, without introducing extra levels\n> unnecessarily; there's no need for the ONLY0/1 nodes as the children of an\n> inner node will always be on different sides.\n>\n> When keys are randomly distributed, this isn't a big deal; OTOH against\n> attackers who are choosing keys, e.g. by grinding hashes, merbinner trees\n> always have maximum depths in proportion to log2(n) of the actual number of\n> items in the tree. Grinding is particularly annoying to deal with due to\n> the\n> birthday attack: creating a ground prefix 64 bits long only takes 32 bits\n> worth\n> of work.\n>\n\nYes an attacker can force the tree to be deeper in places, but it's\nmitigated in several ways: (1) The way I'm using memory it won't cause a\nwhole new block to be allocated, it will just force log(attack strength) -\nlog(n) nodes to be used (2) logarithmic growth being what it is that isn't\nsuch a big amount (3) With the special casing of TERMBOTH an attacker needs\nthree things with the same prefix to pull off an attack rather than two,\nwhich is quite a bit harder to pull off.\n\nThat said, it wouldn't be all that hard to change how the hashing function\nworks to do a single hash for a whole series of ONLY in a row instead of a\nnew one at every level, which would make the attacker only able to force\nextra memory usage instead of extra CPU, but this is a slightly annoying\nthing to write to stop a fairly lame attack, so I'm at least not doing it\nfor my initial implementation. I could likely be convinced that it's worth\ndoing before an actual release though. There's another implementation trick\nto do the same thing for memory usage, which is much more in the 'do later'\ncategory because it doesn't involve changing the format and hence it can be\nput off.\n\n\n> In particular, case #2 handles your leaf node optimizations generically,\n> without special cases and additional complexity. It'd also be a better way\n> to\n> do the ONLY0/1 cases, as if the \"nothing on this side\" symbol is a single\n> byte,\n> each additional colliding level would simply extend the commitment without\n> hashing. In short, you'd have nearly the same level of optimization even\n> if at\n> the cryptography level your tree consists of only leaves, inner nodes, and\n> nil.\n>\n\nI'm taking pains to make all the hashing be of fixed-size things, so that a\nnon-padding variant of a secure hashing algorithm can be used. The chains\nof ONLY thing above would force a special exception to that, which can be\ndone but is annoying. Making things smaller than a single block (64 bytes)\nwon't speed up hashing time, and making things a single byte longer than\nthat doubles it.\n\n\n> Another advantage of variable sized commitments is that it can help make\n> clear\n> to users when it's possible to brute force the message behind the\n> commitment.\n> For instance, digest from a hashed four byte integer can be trivially\n> reversed\n> by just trying all combinations. Equally, if that integer is concatenated\n> with\n> a 32 byte digest that the attacker knows, the value of the integer can be\n> brute\n> forced.\n>\n\nI'm hashing all strings before inserting to get them to be a fixed size and\navoid a few different attacks. In Bitcoin most of the strings added are\nlonger than that so it's a form of compression. A custom hash function\ncould be used which 'hashes' very short strings by repeating them verbatim\ncould be used, but seems like not such a hot idea. I'm making extensive use\nof things being fixed size everywhere, which improves performance in a lot\nof ways.\n\n\n> > > Technically even a patricia trie utxo commitment can have sub-1 cache\n> > > > misses per update if some of the updates in a single block are close\n> to\n> > > > each other in memory. I think I can get practical Bitcoin updates\n> down\n> > > to a\n> > > > little bit less than one l2 cache miss per update, but not a lot\n> less.\n> > >\n> > > I'm very confused as to why you think that's possible. When you say\n> > > \"practical\n> > > Bitcoin updates\", what exactly is the data structure you're proposing\n> to\n> > > update? How is it indexed?\n>\n\nI'll re-answer this because I did a terrible job before. The entire data\nstructure consists of nodes which contain a metadata byte (TERM0, ONLY1,\netc.) followed by fixes size secure hashes, and (in some cases) pointers to\nwhere the children are. The secure hashes in parent nodes are found by\nhashing their children verbatim (or the stored string in the case of a\nTERM). This is very conventional. All of the cleverness is in where in\nmemory these nodes are stored so that tracing down the tree causes very few\ncache misses.\n\n(The alternate approach is to have each node store its own hash rather than\nthat be stored by the parent. That approach means that when you're\nrecalculating you have to look up siblings which doubles the number of\ncache misses. Not such a hot idea.)\n\nAt the root there's a branch block. It consists of all nodes up to some\nfixed depth - let's say 12 - with that depth set so that it roughly fits\nwithin a single memory page. Branch blocks are arranged with the nodes in\nfixed position defined by the prefix they correspond to, and the terminals\nhave outpointers to other blocks. Because they're all clustered together, a\nlookup or update will only require a single\n\nBelow the root block are other branch blocks. Each of them has a fixed 12\nbit prefix it is responsible for. When doing a lookup a second cache miss\nwill be hit for levels 13-24, because those are all clustered in the same\nbranch block.\n\nBelow the second level of root block (at Bitcoin utxo set scale - this\nvaries based on how much is stored) there are leaf blocks. A leaf block\nconsists of nodes with outpointers to its own children which must be within\nthe same leaf block. All entry points into a leaf block are from the same\nbranch block, and the leaf block has no out pointers to other blocks. When\na leaf block overflows the entry point into it which overflowed is moved\ninto the active leaf for that branch, and if that's full a new one is\nallocated. There's some subtlety to exactly how this is done, but I've\ngotten everything down to simple expedient tricks with straightforward\nimplementations. The thing which matters for now is that there's only a\nsingle cache miss for each leaf node, because they also fit in a page.\n\nSo at Bitcoin scale there will probably only be 3 cache misses for a\nlookup, and that's a worst case scenario. The first one is probably always\nwarm, bringing it down to 2, and if you do a bunch in sorted order they'll\nprobably hit the same second level branches repeatedly bringing it down to\n1, and might even average less than that if there are enough that the leaf\nblock has multiple things being accessed.\n\n(These same tricks can be applied to merbinner tree implementation as well,\nalthough that would be a bit less parsimonious with memory, by a small\nconstant factor.)\n\n\n> Anyway hashing is pretty slow. The very fast BLAKE2 is about 3 cycles/byte\n> (SHA256 is about 15 cycles/byte) so hashing that same data would take\n> around\n> 200 cycles, and probably quite a bit more in practice due to overheads\n> from our\n> short message lengths; fetching a cache line from DRAM only takes about\n> 1,000\n> cycles. I'd guess that once other overheads are taken into account, even\n> if you\n> could eliminate L2/L3 cache-misses it wouldn't be much of an improvement.\n>\n\nThose numbers actually back up my claims about performance. If you're doing\na single update and recalculating the root afterwards, then the amount of\nrehashing to be done is about 30 levels deep times 64 bytes per thing\nhashed times 15 cycles per byte then it's about 28,800 cycles of hashing.\nIf you have a naive radix tree implementation which hits a cache miss at\nevery level then that's 30,000 cycles, which is about half the performance\ntime, certainly worth optimizing. If instead of sha256 you use blake2\n(Which sounds like a very good idea!) then hashing for an update will be\nabout 5760 cycles and performance will be completely dominated by cache\nmisses. If a more cache coherent implementation is used, then the cost of\ncache misses will be 3000 cycles, which will be a non-factor with sha256\nand a significant but not dominating one with blake2.\n\nIt's reasonable to interpret those numbers as saying that blake2 and cache\ncoherent implementation are both clearly worth it (probably necessary for\nreal adoption) and that an amortized binary radix tree is tempting but not\nworth it.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160617/88e3169a/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-18T23:01:43",
                "message_text_only": "On Fri, Jun 17, 2016 at 07:43:47PM -0700, Bram Cohen wrote:\n> On Thu, Jun 16, 2016 at 9:34 PM, Peter Todd <pete at petertodd.org> wrote:\n> \n> > So above you said that in merbinner trees each node \"hash[es] in a record\n> > of\n> > its depth\" That's actually incorrect: each node commits to the prefix that\n> > all\n> > keys below that level start with, not just the depth.\n> \n> \n> I considered a similar trick at the implementation rather than the\n> definition level: A node doesn't have to store the prefix which is implicit\n> in its position. That would create a fair number of headaches though,\n> because I'm using fixed size stuff in important ways, and it could at most\n> save about 10% of memory, so it goes into the 'maybe later' bucket.\n\nWait, are you saying you think committing to the prefix is a \"trick\"? It's just\na very simple - and possibly not-optimal - way of committing to what data\nshould be accessible under a given node. An alternative would have been ensure\nthat in terms of _cryptographic_ tree position.\n\nBy \"position\", are you talking about position within RAM? That may or may not\nbe a viable optimization, but it's quite separate from the question of the\ncryptographic structure of the data.\n\n> > This means that in merbinner trees, cases where multiple keys share parts\n> > of\n> > the same prefix are handled efficiently, without introducing extra levels\n> > unnecessarily; there's no need for the ONLY0/1 nodes as the children of an\n> > inner node will always be on different sides.\n> >\n> > When keys are randomly distributed, this isn't a big deal; OTOH against\n> > attackers who are choosing keys, e.g. by grinding hashes, merbinner trees\n> > always have maximum depths in proportion to log2(n) of the actual number of\n> > items in the tree. Grinding is particularly annoying to deal with due to\n> > the\n> > birthday attack: creating a ground prefix 64 bits long only takes 32 bits\n> > worth\n> > of work.\n> >\n> \n> Yes an attacker can force the tree to be deeper in places, but it's\n> mitigated in several ways: (1) The way I'm using memory it won't cause a\n> whole new block to be allocated, it will just force log(attack strength) -\n> log(n) nodes to be used (2) logarithmic growth being what it is that isn't\n> such a big amount (3) With the special casing of TERMBOTH an attacker needs\n> three things with the same prefix to pull off an attack rather than two,\n> which is quite a bit harder to pull off.\n\n\n\n> That said, it wouldn't be all that hard to change how the hashing function\n> works to do a single hash for a whole series of ONLY in a row instead of a\n> new one at every level, which would make the attacker only able to force\n> extra memory usage instead of extra CPU, but this is a slightly annoying\n> thing to write to stop a fairly lame attack, so I'm at least not doing it\n> for my initial implementation. I could likely be convinced that it's worth\n> doing before an actual release though. There's another implementation trick\n> to do the same thing for memory usage, which is much more in the 'do later'\n> category because it doesn't involve changing the format and hence it can be\n> put off.\n> \n> \n> > In particular, case #2 handles your leaf node optimizations generically,\n> > without special cases and additional complexity. It'd also be a better way\n> > to\n> > do the ONLY0/1 cases, as if the \"nothing on this side\" symbol is a single\n> > byte,\n> > each additional colliding level would simply extend the commitment without\n> > hashing. In short, you'd have nearly the same level of optimization even\n> > if at\n> > the cryptography level your tree consists of only leaves, inner nodes, and\n> > nil.\n> >\n> \n> I'm taking pains to make all the hashing be of fixed-size things, so that a\n> non-padding variant of a secure hashing algorithm can be used. The chains\n> of ONLY thing above would force a special exception to that, which can be\n> done but is annoying. Making things smaller than a single block (64 bytes)\n> won't speed up hashing time, and making things a single byte longer than\n> that doubles it.\n\nHave you seen how BLAKE2 omits padding when the data to be hashed happens to be\nexactly one block in size? It's significantly faster than SHA256, and that's a\nstandard part of the algorithm already.\n\n> > > > Technically even a patricia trie utxo commitment can have sub-1 cache\n> > > > > misses per update if some of the updates in a single block are close\n> > to\n> > > > > each other in memory. I think I can get practical Bitcoin updates\n> > down\n> > > > to a\n> > > > > little bit less than one l2 cache miss per update, but not a lot\n> > less.\n> > > >\n> > > > I'm very confused as to why you think that's possible. When you say\n> > > > \"practical\n> > > > Bitcoin updates\", what exactly is the data structure you're proposing\n> > to\n> > > > update? How is it indexed?\n> >\n> \n> I'll re-answer this because I did a terrible job before. The entire data\n> structure consists of nodes which contain a metadata byte (TERM0, ONLY1,\n> etc.) followed by fixes size secure hashes, and (in some cases) pointers to\n> where the children are. The secure hashes in parent nodes are found by\n> hashing their children verbatim (or the stored string in the case of a\n> TERM). This is very conventional. All of the cleverness is in where in\n> memory these nodes are stored so that tracing down the tree causes very few\n> cache misses.\n> \n> (The alternate approach is to have each node store its own hash rather than\n> that be stored by the parent. That approach means that when you're\n> recalculating you have to look up siblings which doubles the number of\n> cache misses. Not such a hot idea.)\n\nHave you benchmarked the cost of a hash operation vs. the cost of a cache miss?\nWhat are the actual numbers?\n\n> At the root there's a branch block. It consists of all nodes up to some\n> fixed depth - let's say 12 - with that depth set so that it roughly fits\n> within a single memory page. Branch blocks are arranged with the nodes in\n> fixed position defined by the prefix they correspond to, and the terminals\n> have outpointers to other blocks. Because they're all clustered together, a\n> lookup or update will only require a single\n\nA single....?\n\n> Below the root block are other branch blocks. Each of them has a fixed 12\n> bit prefix it is responsible for. When doing a lookup a second cache miss\n> will be hit for levels 13-24, because those are all clustered in the same\n> branch block.\n\nSo, is this also how the data structure looks cryptographically, or is the way\nit's hashed separate from the above description?\n\n> Below the second level of root block (at Bitcoin utxo set scale - this\n> varies based on how much is stored) there are leaf blocks. A leaf block\n> consists of nodes with outpointers to its own children which must be within\n> the same leaf block. All entry points into a leaf block are from the same\n> branch block, and the leaf block has no out pointers to other blocks. When\n> a leaf block overflows the entry point into it which overflowed is moved\n> into the active leaf for that branch, and if that's full a new one is\n> allocated. There's some subtlety to exactly how this is done, but I've\n> gotten everything down to simple expedient tricks with straightforward\n> implementations. The thing which matters for now is that there's only a\n> single cache miss for each leaf node, because they also fit in a page.\n\nPage as in 4096 bytes? But L1/L2/L3 cache is arranged in terms of 64 byte cache\nlines - where do pages come in here?\n\nAt Bitcoin UTXO set scale, how large do you think these data structures are?\n\n> So at Bitcoin scale there will probably only be 3 cache misses for a\n> lookup, and that's a worst case scenario. The first one is probably always\n> warm, bringing it down to 2, and if you do a bunch in sorted order they'll\n> probably hit the same second level branches repeatedly bringing it down to\n> 1, and might even average less than that if there are enough that the leaf\n> block has multiple things being accessed.\n\n\"Sorted order\" - what exact type of sorting do you mean here?\n\n> > Anyway hashing is pretty slow. The very fast BLAKE2 is about 3 cycles/byte\n> > (SHA256 is about 15 cycles/byte) so hashing that same data would take\n> > around\n> > 200 cycles, and probably quite a bit more in practice due to overheads\n> > from our\n> > short message lengths; fetching a cache line from DRAM only takes about\n> > 1,000\n> > cycles. I'd guess that once other overheads are taken into account, even\n> > if you\n> > could eliminate L2/L3 cache-misses it wouldn't be much of an improvement.\n> >\n> \n> Those numbers actually back up my claims about performance. If you're doing\n> a single update and recalculating the root afterwards, then the amount of\n> rehashing to be done is about 30 levels deep times 64 bytes per thing\n> hashed times 15 cycles per byte then it's about 28,800 cycles of hashing.\n> If you have a naive radix tree implementation which hits a cache miss at\n> every level then that's 30,000 cycles, which is about half the performance\n> time, certainly worth optimizing. If instead of sha256 you use blake2\n> (Which sounds like a very good idea!) then hashing for an update will be\n> about 5760 cycles and performance will be completely dominated by cache\n> misses. If a more cache coherent implementation is used, then the cost of\n> cache misses will be 3000 cycles, which will be a non-factor with sha256\n> and a significant but not dominating one with blake2.\n\nBut that's assuming the dataset in question fits in cache; I don't see how it\ndoes. Since it doesn't, I'm argung the total % improvement by _any_ cache\noptimization on the subset that does fit in cache will be relatively small.\n\nAgain, how large a dataset do you think you're working with here?\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160618/e7c404fd/attachment.sig>"
            },
            {
                "author": "Bram Cohen",
                "date": "2016-06-18T03:22:04",
                "message_text_only": "On Wed, Jun 15, 2016 at 5:10 PM, Peter Todd <pete at petertodd.org> wrote:\n\n> On Tue, Jun 14, 2016 at 05:14:23PM -0700, Bram Cohen via bitcoin-dev wrote:\n>\n> > The fundamental approach to handling the latency problem is to have the\n> > utxo commitments trail a bit. Computing utxo commitments takes a certain\n> > amount of time, too much to hold up block propagation but still hopefully\n> > vastly less than the average amount of time between blocks. Trailing by a\n> > single block is probably a bad idea because you sometimes get blocks back\n> > to back, but you never get blocks back to back to back to back. Having\n> the\n> > utxo set be trailing by a fixed amount - five blocks is probably\n> excessive\n> > - would do a perfectly good job of keeping latency from every becoming an\n> > issue. Smaller commitments for the utxos added and removed in each block\n> > alone could be added without any significant performance penalty. That\n> way\n> > all blocks would have sufficient commitments for a completely up to date\n> > proofs of inclusion and exclusion. This is not a controversial approach.\n>\n> Agreed - regardless of approach adding latency to commitment calculations\n> of\n> all kinds is something I think we all agree can work in principle, although\n> obviously it should be a last resort technique when optimization fails.\n>\n\nAn important point: Adding latency to utxo commitments does not imply\nlatency to proofs of inclusion and exclusion! If roots of what's added and\ndeleted in each block are added as well, then a proof of inclusion can be\ndone by having a proof of inclusion of the trailing utxo set followed by a\nproof of exclusion from all the following deletion sets, or a proof of\ninclusion in one of the single block addition sets followed by proofs of\nexclusion from all the more recent deletion sets. Likewise a proof of\nexclusion can be a proof of exclusion from the utxo set followed by proofs\nof exclusion from all the more recent addition sets or a single proof of\ninclusion in a recent deletion set.\n\nThis does make proofs larger (except in the case of recent deletions and\nmaybe recent additions) and adds complexity, so it shouldn't be done unless\nnecessary. But validation before block propagation needs to be extremely\nfast, so for utxo roots this trick is probably both necessary and\nsufficient.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160617/1843b319/attachment-0001.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-18T22:09:29",
                "message_text_only": "On Fri, Jun 17, 2016 at 08:22:04PM -0700, Bram Cohen wrote:\n> On Wed, Jun 15, 2016 at 5:10 PM, Peter Todd <pete at petertodd.org> wrote:\n> > Agreed - regardless of approach adding latency to commitment calculations\n> > of\n> > all kinds is something I think we all agree can work in principle, although\n> > obviously it should be a last resort technique when optimization fails.\n> >\n> \n> An important point: Adding latency to utxo commitments does not imply\n> latency to proofs of inclusion and exclusion! If roots of what's added and\n> deleted in each block are added as well, then a proof of inclusion can be\n> done by having a proof of inclusion of the trailing utxo set followed by a\n> proof of exclusion from all the following deletion sets, or a proof of\n> inclusion in one of the single block addition sets followed by proofs of\n> exclusion from all the more recent deletion sets. Likewise a proof of\n> exclusion can be a proof of exclusion from the utxo set followed by proofs\n> of exclusion from all the more recent addition sets or a single proof of\n> inclusion in a recent deletion set.\n> \n> This does make proofs larger (except in the case of recent deletions and\n> maybe recent additions) and adds complexity, so it shouldn't be done unless\n> necessary.\n\nSo, to be clear you're assuming that blocks commit to key:value maps of the\nblock contents, specifically a pre-block \"UTXO deletion/things that this block\nspent\" set? First of all, it's interesting how the much smaller dataset of a\npre-block key:value map would make L2/L3 caching optimizations much more likely\nto be relevant. :)\n\n\nThat type of solution would be very similar to the solutions treechains would\nneed to prove coins haven't been doublespent. Basically, in treechains the\nsystem as a whole is a datastructure indexed by time and prefix. So, if you\nwant to prove a valid spend you need to convince me of three things:\n\n1. The coin existed as of time t1 at prefix p\n\n2. At t2, p, a valid spend was published.\n\n3. Between t1 and t2 at prefix p no other valid spend was published.\n\nPaths to any prefix p as of time t, will have about log2(len(p)) size (beyond\nthe top-level chain), similar to your above suggestion. Of course, unlike your\nabove suggestion, in treechains it's not clear if step #1 can be done without\nanother n*log(N)-ish sized proof in a truly trustless environment!\n\n> But validation before block propagation needs to be extremely\n> fast, so for utxo roots this trick is probably both necessary and\n> sufficient.\n\nI'm _not_ of the optinion that validation before propagation needs to be done\nat all - I think it's perfectly reasonable to propgate blocks that you have not\nvalidated at all (beyond checking PoW as an anti-DoS measure).  The time it\ntakes miners to start mining the next block - and collecting fees - is however\nvery important.\n\nIn practice, I think we're mostly in agreement here, but because I'm happy to\npropagate prior to validating I'd be ok with protocol designs that required\nminers to have relatively large amounts of RAM - say 32GB - dedicated to UTXO\nlookup because that wouldn't require relay nodes to also have those kinds of\nresources available to them once validationless propagation was implemented.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160618/0ca1a55b/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Merkle trees and mountain ranges",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Bram Cohen",
                "Peter Todd"
            ],
            "messages_count": 10,
            "total_messages_chars_count": 68622
        }
    },
    {
        "title": "[bitcoin-dev] Building Blocks of the State Machine Approach to Consensus",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2016-06-20T08:56:49",
                "message_text_only": "In light of Ethereum's recent problems with its imperative, account-based,\nprogramming model, I thought I'd do a quick writeup outlining the building\nblocks of the state-machine approach to so-called \"smart contract\" systems, an\nextension of Bitcoin's own design that I personally have been developing for a\nnumber of years now as my Proofchains/Dex research work.\n\n\n# Deterministic Code / Deterministic Expressions\n\nWe need to be able to run code on different computers and get identical\nresults; without this consensus is impossible and we might as well just use a\ncentral authoritative database. Traditional languages and surrounding\nframeworks make determinism difficult to achieve, as they tend to be filled\nwith undefined and underspecified behavior, ranging from signed integer\noverflow in C/C++ to non-deterministic behavior in databases. While some\nsuccessful systems like Bitcoin are based on such languages, their success is\nattributable to heroic efforts by their developers.\n\nDeterministic expression systems such as Bitcoin's scripting system and the\nauthor's Dex project improve on this by allowing expressions to be precisely\nspecified by hash digest, and executed against an environment with\ndeterministic results. In the case of Bitcoin's script, the expression is a\nForth-like stack-based program; in Dex the expression takes the form of a\nlambda calculus expression.\n\n\n## Proofs\n\nSo far the most common use for deterministic expressions is to specify\nconditions upon which funds can be spent, as seen in Bitcoin (particularly\nP2SH, and the upcoming Segwit). But we can generalize their use to precisely\ndefining consensus protocols in terms of state machines, with each state\ndefined in terms of a deterministic expression that must return true for the\nstate to have been reached. The data that causes a given expression to return\ntrue is then a \"proof\", and that proof can be passed from one party to another\nto prove desired states in the system have been reached.\n\nAn important implication of this model is that we need deterministic, and\nefficient, serialization of proof data.\n\n\n## Pruning\n\nOften the evaluation of an expression against a proof doesn't require all all\ndata in the proof. For example, to prove to a lite client that a given block\ncontains a transaction, we only need the merkle path from the transaction to\nthe block header. Systems like Proofchains and Dex generalize this process -\ncalled \"pruning\" - with built-in support to both keep track of what data is\naccessed by what operations, as well as support in their underlying\nserialization schemes for unneeded data to be elided and replaced by the hash\ndigest of the pruned data.\n\n\n# Transactions\n\nA common type of state machine is the transaction. A transaction history is a\ndirected acyclic graph of transactions, with one or more genesis transactions\nhaving no inputs (ancestors), and one or more outputs, and zero or more\nnon-genesis transactions with one or more inputs, and zero or more outputs. The\nedges of the graph connect inputs to outputs, with every input connected to\nexactly one output. Outputs with an associated input are known as spent\noutputs; outputs with out an associated input are unspent.\n\nOutputs have conditions attached to them (e.g. a pubkey for which a valid\nsignature must be produced), and may also be associated with other values such\nas \"# of coins\". We consider a transaction valid if we have a set of proofs,\none per input, that satisfy the conditions associated with each output.\nSecondly, validity may also require additional constraints to be true, such as\nrequiring the coins spent to be >= the coins created on the outputs. Input\nproofs also must uniquely commit to the transaction itself to be secure - if\nthey don't the proofs can be reused in a replay attack.\n\nA non-genesis transaction is valid if:\n\n1. Any protocol-specific rules such as coins spent >= coins output are\n   followed.\n\n2. For every input a valid proof exists.\n\n3. Every input transaction is itself valid.\n\nA practical implementation of the above for value-transfer systems like Bitcoin\ncould use two merkle-sum trees, one for the inputs, and one for the outputs,\nwith inputs simply committing to the previous transaction's txid and output #\n(outpoint), and outputs committing to a scriptPubKey and output amount.\nWitnesses can be provided separately, and would sign a signature committing to\nthe transaction or optionally, a subset of of inputs and/or outputs (with\nmerkle trees we can easily avoid the exponential signature validation problems\nbitcoin currently has).\n\nAs so long as all genesis transactions are unique, and our hash function is\nsecure, all transaction outputs can be uniquely identified (prior to BIP34 the\nBitcoin protocol actually failed at this!).\n\n\n## Proof Distribution\n\nHow does Alice convince Bob that she has done a transaction that puts the\nsystem into the state that Bob wanted? The obvious answer is she gives Bob data\nproving that the system is now in the desired state; in a transactional system\nthat proof is some or all of the transaction history. Systems like Bitcoin\nprovide a generic flood-fill messaging layer where all participants have the\nopportunity to get a copy of all proofs in the system, however we can also\nimplement more fine grained solutions based on peer-to-peer message passing -\none could imagine Alice proving to Bob that she transferred title to her house\nto him by giving him a series of proofs, not unlike the same way that property\ntitle transfer can be demonstrated by providing the buyer with a series of deed\ndocuments (though note the double-spend problem!).\n\n\n# Uniqueness and Single-Use Seals\n\nIn addition to knowing that a given transaction history is valid, we also want\nto know if it's unique. By that we mean that every spent output in the\ntransaction history is associated with exactly one input, and no other valid\nspends exist; we want to ensure no output has been double-spent.\n\nBitcoin (and pretty much every other cryptocurrency like it) achieves this goal\nby defining a method of achieving consensus over the set of all (valid)\ntransactions, and then defining that consensus as valid if and only if no\noutput is spent more than once.\n\nA more general approach is to introduce the idea of a cryptographic Single-Use\nSeal, analogous to the tamper-evidence single-use seals commonly used for\nprotecting goods during shipment and storage. Each individual seals is\nassociated with a globally unique identifier, and has two states, open and\nclosed. A secure seal can be closed exactly once, producing a proof that the\nseal was closed.\n\nAll practical single-use seals will be associated with some kind of condition,\nsuch as a pubkey, or deterministic expression, that needs to be satisfied for\nthe seal to be closed. Secondly, the contents of the proof will be able to\ncommit to new data, such as the transaction spending the output associated with\nthe seal.\n\nAdditionally some implementations of single-use seals may be able to also\ngenerate a proof that a seal was _not_ closed as of a certain\ntime/block-height/etc.\n\n\n## Implementations\n\n### Transactional Blockchains\n\nA transaction output on a system like Bitcoin can be used as a single-use seal.\nIn this implementation, the outpoint (txid:vout #) is the seal's identifier,\nthe authorization mechanism is the scriptPubKey of the output, and the proof\nis the transaction spending the output. The proof can commit to additional\ndata as needed in a variety of ways, such as an OP_RETURN output, or\nunspendable output.\n\nThis implementation approach is resistant to miner censorship if the seal's\nidentifier isn't made public, and the protocol (optionally) allows for the\nproof transaction to commit to the sealed contents with unspendable outputs;\nunspendable outputs can't be distinguished from transactions that move funds.\n\n\n### Unbounded Oracles\n\nA trusted oracle P can maintain a set of closed seals, and produce signed\nmessages attesting to the fact that a seal was closed. Specifically, the seal\nis identified by the tuple (P, q), with q being the per-seal authorization\nexpression that must be satisfied for the seal to be closed. The first time the\noracle is given a valid signature for the seal, it adds that signature and seal\nID to its closed seal set, and makes available a signed message attesting to\nthe fact that the seal has been closed. The proof is that message (and\npossibly the signature, or a second message signed by it).\n\nThe oracle can publish the set of all closed seals for transparency/auditing\npurposes. A good way to do this is to make a merkelized key:value set, with the\nseal identifiers as keys, and the value being the proofs, and in turn create a\nsigned certificate transparency log of that set over time. Merkle-paths from\nthis log can also serve as the closed seal proof, and for that matter, as\nproof of the fact that a seal has not been closed.\n\n\n### Bounded Oracles\n\nThe above has the problem of unbounded storage requirements as the closed seal\nset grows without bound. We can fix that problem by requiring users of the\noracle to allocate seals in advance, analogous to the UTXO set in Bitcoin.\n\nTo allocate a seal the user provides the oracle P with the authorization\nexpression q. The oracle then generates a nonce n and adds (q,n) to the set of\nunclosed seals, and tells the user that nonce. The seal is then uniquely\nidentified by (P, q, n)\n\nTo close a seal, the user provides the oracle with a valid signature over (P,\nq, n). If the open seal set contains that seal, the seal is removed from the\nset and the oracle provides the user with a signed message attesting to the\nvalid close.\n\nA practical implementation would be to have the oracle publish a transparency\nlog, with each entry in the log committing to the set of all open seals with a\nmerkle set, as well as any seals closed during that entry. Again, merkle paths\nfor this log can serve as proofs to the open or closed state of a seal.\n\nNote how with (U)TXO commitments, Bitcoin itself is a bounded oracle\nimplementation that can produce compact proofs.\n\n\n### Group Seals\n\nMultiple seals can be combined into one, by having the open seal commit to a\nset of sub-seals, and then closing the seal over a second set of closed seal\nproofs. Seals that didn't need to be closed can be closed over a special\nre-delegation message, re-delegating the seal to a new open seal.\n\nSince the closed sub-seal proof can additionally include a proof of\nauthorization, we have a protcol where the entity with authorization to close\nthe master seal has the ability to DoS attack sub-seals owners, but not the\nability to fraudulently close the seals over contents of their choosing. This\nmay be useful in cases where actions on the master seal is expensive - such as\nseals implemented on top of decentralized blockchains - by amortising the cost\nover all sub-seals.\n\n\n## Atomicity\n\nOften protocols will require multiple seals to be closed for a transaction to\nbe valid. If a single entity controls all seals, this is no problem: the\ntransaction simply isn't valid until the last seal is closed.\n\nHowever if multiple parties control the seals, a party could attack another\nparty by failing to go through with the transaction, after another party has\nclosed their seal, leaving the victim with an invalid transaction that they\ncan't reverse.\n\nWe have a few options to resolve this problem:\n\n### Use a single oracle\n\nThe oracle can additionally guarantee that a seal will be closed iff some other\nset of seals are also closed; seals implemented with Bitcoin can provide this\nguarantee. If the parties to a transaction aren't already all on the same\noracle, they can add an additional transaction reassigning their outputs to a\ncommon oracle.\n\nEqually, a temporary consensus between multiple mutually trusting oracles can\nbe created with a consensus protocol they share; this option doesn't need to\nchange the proof verification implementation.\n\n\n### Two-phase Timeouts\n\nIf a proof to the fact that a seal is open can be generated, even under\nadversarial conditions, we can make the seal protocol allow a close to be\nundone after a timeout if evidence can be provided that the other seal(s) were\nnot also closed (in the specified way).\n\nDepending on the implementation - especially in decentralized systems - the\nnext time the seal is closed, the proof it has been closed may in turn provide\nproof that a previous close was in fact invalid.\n\n\n# Proof-of-Publication and Proof-of-Non-Publication\n\nOften we need to be able to prove that a specified audience was able to receive\na specific message. For example, the author's PayPub protocol[^paypub],\nTodd/Taaki's timelock encryption protocol[^timelock], Zero-Knowledge Contingent\nPayments[^zkcp], and Lightning, among others work by requiring a secret key to\nbe published publicly in the Bitcoin blockchain as a condition of collecting a\npayment. At a much smaller scale - in terms of audience - in certain FinTech\napplications for regulated environments a transaction may be considered invalid\nunless it was provably published to a regulatory agency.  Another example is\nCertificate Transparency, where we consider a SSL certificate to be invalid\nunless it has been provably published to a transparency log maintained by a\nthird-party.\n\nSecondly, many proof-of-publication schemes also can prove that a message was\n_not_ published to a specific audience. With this type of proof single-use\nseals can be implemented, by having the proof consist of proof that a specified\nmessage was not published between the time the seal was created, and the time\nit was closed (a proof-of-publication of the message).\n\n## Implementations\n\n### Decentralized Blockchains\n\nHere the audience is all participants in the system. However miner censorship\ncan be a problem, and compact proofs of non-publication aren't yet available\n(requires (U)TXO commitments).\n\nThe authors treechains proposal is a particularly generic and scalable\nimplementation, with the ability to make trade offs between the size of\naudience (security) and publication cost.\n\n### Centralized Public Logs\n\nCertificate Transparency works this way, with trusted (but auditable) logs run\nby well known parties acting as the publication medium, who promise to allow\nanyone to obtain copies of the logs.\n\nThe logs themselves may be indexed in a variety of ways; CT simply indexes logs\nby time, however more efficient schemes are possible by having the operator\ncommit to a key:value mapping of \"topics\", to allow publication (and\nnon-publication) proofs to be created for specified topics or topic prefixes.\n\nAuditing the logs is done by verifying that queries to the state of the log\nreturn the same state at the same time for different requesters.\n\n### Receipt Oracles\n\nFinally publication can be proven by a receipt proof by the oracle, attesting\nto the fact that the oracle has successfully received the message. This is\nparticularly appropriate in cases where the required audience is the oracle\nitself, as in the FinTech regulator case.\n\n\n# Validity Oracles\n\nAs transaction histories grow longer, they may become impractical to move from\none party to another. Validity oracles can solve this problem by attesting to\nthe validity of transactions, allowing history prior to the attested\ntransactions to be discarded.\n\nA particularly generic validity oracle can be created using deterministic\nexpressions systems. The user gives the oracle an expression, and the oracle\nreturns a signed message attesting to the validity of the expression.\nOptionally, the expression may be incomplete, with parts of the expression\nreplaced by previously generated attestations. For example, an expression that\nreturns true if a transaction is valid could in turn depend on the previous\ntransaction also being valid - a recursive call of itself - and that recursive\ncall can be proven with a prior attestation.\n\n## Implementations\n\n### Proof-of-Work Decentralized Consensus\n\nMiners in decentralized consensus systems act as a type of validity oracle, in\nthat the economic incentives in the system are (supposed to be) designed to\nencourage only the mining of valid blocks; a user who trusts the majority of\nhashing power can trust that any transaction with a valid merkle path to a\nblock header in the most-work chain is valid. Existing decentralized consensus\nsystems like Bitcoin and Ethereum conflate the roles of validity oracle and\nsingle-use seal/anti-replay oracle, however in principle that need not be true.\n\n\n### Trusted Oracles\n\nAs the name suggests. Remote-attestation-capable trusted hardware is a\nparticularly powerful implementation - a conspiracy theory is that the reason\nwhy essentially zero secure true remote attestation implementations exist is\nbecause they'd immediately make untraceable digital currency systems easy to\nimplement (Finney's RPOW[^rpow] is a rare counter-example).\n\nNote how a single-use seal oracle that supports a generic deterministic\nexpressions scheme for seal authorization can be easily extended to provide a\nvalidity oracle service as well. The auditing mechanisms for a single-use seal\noracle can also be applied to validity oracles.\n\n\n# Fraud Proofs\n\nProtocols specified with deterministic expressions can easily generate \"fraud\nproofs\", showing that claimed states/proof in the system are actually invalid.\nAdditionally many protocols can be specified with expressions of k*log2(n)\ndepth, allowing these fraud proofs to be compact.\n\nA simple example is proving fraud in merkle-sum tree, where the validity\nexpression would be something like:\n\n    (defun valid? (node)\n        (or (== node.type leaf)\n            (and (== node.sum (+ node.left.sum node.right.sum))\n                 (and (valid? node.left)\n                      (valid? node.right)))))\n\nTo prove the above expression evaluates to true, we'll need the entire contents\nof the tree. However, to prove that it evaluates to false, we only need a\nsubset of the tree as proving an and expression evaluates to false only\nrequires one side, and requires log2(n) data. Secondly, with pruning, the\ndeterministic expressions evaluator can automatically keep track of exactly\nwhat data was needed to prove that result, and prune all other data when\nserializing the proof.\n\n\n## Validity Challenges\n\nHowever how do you guarantee it will be possible to prove fraud in the first\nplace? If pruning is allowed, you may simply not have access to the data\nproving fraud - an especially severe problem in transactional systems where a\nsingle fraudulent transaction can counterfeit arbitrary amounts of value out of\nthin air.\n\nA possible approach is the validity challenge: a subset of proof data, with\npart of the data marked as \"potentially fraudulent\". The challenge can be\nsatisfied by providing the marked data and showing that the proof in question\nis in fact valid; if the challenge is unmet participants in the system can\nchoose to take action, such as refusing to accept additional transactions.\n\nOf course, this raises a whole host of so-far unsolved issues, such as DoS\nattacks and lost data.\n\n\n# Probabilistic Validation\n\nProtocols that can tolerate some fraud can make use of probabilistic\nverification techniques to prove that the percentage of undetected fraud within\nthe system is less than a certain amount, with a specified probability.\n\nA common way to do this is the Fiat-Shamir transform, which repeatedly samples\na data structure deterministically, using the data's own hash digest as a seed\nfor a PRNG. Let's apply this technique to our merkle-sum tree example. We'll\nfirst need a recursive function to check a sample, weighted by value:\n\n    (defun prefix-valid? (node nonce)\n        (or (== node.type leaf)\n            (and (and (== node.sum (+ node.left.sum node.right.sum))\n                      (> 0 node.sum)) ; mod by 0 is invalid, just like division by zero\n                                      ; also could guarantee this with a type system\n                 (and (if (< node.left.sum (mod nonce node.sum))\n                          (prefix-valid? node.right (hash nonce))\n                          (prefix-valid? node.left (hash nonce)))))))\n\nNow we can combine multiple invocations of the above, in this case 256\ninvocations:\n\n    (defun prob-valid? (node)\n        (and (and (and .... (prefix-valid? node (digest (cons (digest node) 0)))\n             (and (and ....\n                            (prefix-valid? node (digest (cons (digest node) 255)))\n\nAs an exercise for a reader: generalize the above with a macro, or a suitable\ntypes/generics system.\n\nIf we assume our attacker can grind up to 128 bits, that leaves us with 128\nrandom samples that they can't control. If the (value weighted) probability of\na given node is fraudulent q, then the chance of the attacker getting away with\nfraud is (1-q)^128 - for q=5% that works out to 0.1%\n\n(Note that the above analysis isn't particularly well done - do a better\nanalysis before implementing this in production!)\n\n\n## Random Beacons and Transaction History Linearization\n\nThe Fiat-Shamir transform requires a significant number of samples to defeat\ngrinding attacks; if we have a random beacon available we can significantly\nreduce the size of our probabilistic proofs. PoW blockchains can themselves act\nas random beacons, as it is provably expensive for miners to manipulate the\nhash digests of blocks they produce - to do so requires discarding otherwise\nvalid blocks.\n\nAn example where this capability is essential is the author's transaction\nhistory linearization technique. In value transfer systems such as Bitcoin, the\nhistory of any given coin grows quasi-exponentially as coins are mixed across\nthe entire economy. We can linearize the growth of history proofs by redefining\ncoin validity to be probabilistic.\n\nSuppose we have a transaction with n inputs. Of those inputs, the total value\nof real inputs is p, and the total claimed value of fake inputs is q. The\ntransaction commits to all inputs in a merkle sum tree, and we define the\ntransaction as valid if a randomly chosen input - weighted by value - can\nitself be proven valid. Finally, we assume that creating a genuine input is a\nirrevocable action which irrevocable commits to the set of all inputs, real and\nfake.\n\nIf all inputs are real, 100% of the time the transaction will be valid; if all\ninputs are fake, 100% of the time the transaction will be invalid. In the case\nwhere some inputs are real and some are fake the probability that the fraud\nwill be detected is:\n\n    q / (q + p)\n\nThe expected value of the fake inputs is then the sum of the potential upside -\nthe fraud goes detected - and the potential downside - the fraud is detected\nand the real inputs are destroyed:\n\n    E = q(1 - q/(q + p)) - p(q/(q + p)\n      = q(p/(q + p)) - p(q/(q + p)\n      = (q - q)(p/(q + p))\n      = 0\n\nThus so long as the random beacon is truly unpredictable, there's no economic\nadvantage to creating fake inputs, and it is sufficient for validity to only\nrequire one input to be proven, giving us O(n) scaling for transaction history\nproofs.\n\n\n### Inflationary O(1) History Proofs\n\nWe can further improve our transaction history proof scalability by taking\nadvantage of inflation. We do this by occasionally allowing a transaction proof\nto be considered valid without validating _any_ of the inputs; every time a\ntransaction is allowed without proving any inputs the size of the transaction\nhistory proof is reset. Of course, this can be a source of inflation, but\nprovided the probability of this happening can be limited we can limit the\nmaximum rate of inflation to the chosen value.\n\nFor example, in Bitcoin as of writing every block inflates the currency supply\nby 25BTC, and contains a maximum of 1MB of transaction data, 0.025BTC/KB. If we\ncheck the prior input proof with probability p, then the expected value of a\ntransaction claiming to spend x BTC is:\n\n    E = x(1-p)\n\nWe can rewrite that in terms of the block reward per-byte R, and the transaction size l:\n\n    lR = x(1-p)\n\nAnd solving for p:\n\n    p = 1 - lR/x\n\nFor example, for a 1KB transaction proof claiming to spending 10BTC we can omit\nchecking the input 0.25% of the time without allowing more monetary inflation\nthan the block reward already does. Secondly, this means that after n\ntransactions, the probability that proof shortening will _not_ happen is p^n,\nwhich reaches 1% after 1840 transactions.\n\nIn a system like Bitcoin where miners are expected to validate, a transaction\nproof could consist of just a single merkle path showing that a single-use seal\nwas closed in some kind of TXO commitment - probably under 10KB of data. That\ngives us a history proof less than 18.4MB in size, 99% of the time, and less\nthan 9.2MB in size 90% of the time.\n\nAn interesting outcome of thing kind of design is that we can institutionalize\ninflation fraud: the entire block reward can be replaced by miners rolling the\ndice, attempting to create valid \"fake\" transactions. However, such a pure\nimplementation would put a floor on the lowest transaction fee possible, so\nbetter to allow both transaction fee and subsidy collection at the same time.\n\n\n# References\n\n[^paypub] https://github.com/unsystem/paypub\n[^timelock] https://github.com/petertodd/timelock\n[^zkcp] https://bitcoincore.org/en/2016/02/26/zero-knowledge-contingent-payments-announcement/\n[^rpow] https://cryptome.org/rpow.htm\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160620/73f11845/attachment.sig>"
            },
            {
                "author": "Police Terror",
                "date": "2016-06-20T13:26:22",
                "message_text_only": "Bitcoin could embed a lisp interpreter such as Scheme, reverse engineer\nthe current protocol into lisp (inside C++), run this alternative engine\nalongside the current one as an option for some years (only for fine\ntuning) then eventually fade this lisp written validation code instead\nof the current one.\n\nScheme is small and minimal, and embeds easily in C++. This could be a\nbetter option than the libconsensus library - validation in a functional\nscripting language.\n\nThat doesn't mean people can't program the validation code in other\nlanguages (maybe they'd want to optimize), but this code would be the\nstandard.\n\nIt's really good how you are thinking deeply how Bitcoin can be used,\nand the implications of everything. Also there's a lot of magical utopic\nthinking in Ethereum, which is transhumanist nonsense that is life\ndenying. Bitcoin really speaks to me because it is real and a great tool\nfollowing the UNIX principle.\n\nI wouldn't be so quick to deride good engineering over systematic\nprovable systems for all domains. Bitcoin being written in C++ is not a\ndefect. It's actually a strong language for what it does. Especially\nwhen used correctly (which is not often and takes years to master).\n\nWith the seals idea- am I understand this correctly?: Every transaction\nhas a number (essentially the index starting from 0 upwards) depending\non where it is in the blockchain.\n\nThen there is an array (probably an on disk array mapping transaction\nindexes to hashes). Each hash entry in the array must be unique (the\nhashes) otherwise the transaction will be denied. This is a great idea\nto solve transaction hash collisions and simple to implement.\n\nProbabilistic validation is a good idea, although the real difficulty\nnow seems to be writing and indexing all the blockchain data for\nlookups. And validation is disabled for most of the blocks. Pruning is\nonly a stop gap measure (which loses data) that doesn't solve the issue\nof continually growing resource consumption. Hardware and implementation\ncan only mitigate this so much. If only there was a way to simplify the\nunderlying protocol to make it more resource efficient...\n\nPeter Todd via bitcoin-dev:\n> In light of Ethereum's recent problems with its imperative, account-based,\n> programming model, I thought I'd do a quick writeup outlining the building\n> blocks of the state-machine approach to so-called \"smart contract\" systems, an\n> extension of Bitcoin's own design that I personally have been developing for a\n> number of years now as my Proofchains/Dex research work.\n> \n> \n> # Deterministic Code / Deterministic Expressions\n> \n> We need to be able to run code on different computers and get identical\n> results; without this consensus is impossible and we might as well just use a\n> central authoritative database. Traditional languages and surrounding\n> frameworks make determinism difficult to achieve, as they tend to be filled\n> with undefined and underspecified behavior, ranging from signed integer\n> overflow in C/C++ to non-deterministic behavior in databases. While some\n> successful systems like Bitcoin are based on such languages, their success is\n> attributable to heroic efforts by their developers.\n> \n> Deterministic expression systems such as Bitcoin's scripting system and the\n> author's Dex project improve on this by allowing expressions to be precisely\n> specified by hash digest, and executed against an environment with\n> deterministic results. In the case of Bitcoin's script, the expression is a\n> Forth-like stack-based program; in Dex the expression takes the form of a\n> lambda calculus expression.\n> \n> \n> ## Proofs\n> \n> So far the most common use for deterministic expressions is to specify\n> conditions upon which funds can be spent, as seen in Bitcoin (particularly\n> P2SH, and the upcoming Segwit). But we can generalize their use to precisely\n> defining consensus protocols in terms of state machines, with each state\n> defined in terms of a deterministic expression that must return true for the\n> state to have been reached. The data that causes a given expression to return\n> true is then a \"proof\", and that proof can be passed from one party to another\n> to prove desired states in the system have been reached.\n> \n> An important implication of this model is that we need deterministic, and\n> efficient, serialization of proof data.\n> \n> \n> ## Pruning\n> \n> Often the evaluation of an expression against a proof doesn't require all all\n> data in the proof. For example, to prove to a lite client that a given block\n> contains a transaction, we only need the merkle path from the transaction to\n> the block header. Systems like Proofchains and Dex generalize this process -\n> called \"pruning\" - with built-in support to both keep track of what data is\n> accessed by what operations, as well as support in their underlying\n> serialization schemes for unneeded data to be elided and replaced by the hash\n> digest of the pruned data.\n> \n> \n> # Transactions\n> \n> A common type of state machine is the transaction. A transaction history is a\n> directed acyclic graph of transactions, with one or more genesis transactions\n> having no inputs (ancestors), and one or more outputs, and zero or more\n> non-genesis transactions with one or more inputs, and zero or more outputs. The\n> edges of the graph connect inputs to outputs, with every input connected to\n> exactly one output. Outputs with an associated input are known as spent\n> outputs; outputs with out an associated input are unspent.\n> \n> Outputs have conditions attached to them (e.g. a pubkey for which a valid\n> signature must be produced), and may also be associated with other values such\n> as \"# of coins\". We consider a transaction valid if we have a set of proofs,\n> one per input, that satisfy the conditions associated with each output.\n> Secondly, validity may also require additional constraints to be true, such as\n> requiring the coins spent to be >= the coins created on the outputs. Input\n> proofs also must uniquely commit to the transaction itself to be secure - if\n> they don't the proofs can be reused in a replay attack.\n> \n> A non-genesis transaction is valid if:\n> \n> 1. Any protocol-specific rules such as coins spent >= coins output are\n>    followed.\n> \n> 2. For every input a valid proof exists.\n> \n> 3. Every input transaction is itself valid.\n> \n> A practical implementation of the above for value-transfer systems like Bitcoin\n> could use two merkle-sum trees, one for the inputs, and one for the outputs,\n> with inputs simply committing to the previous transaction's txid and output #\n> (outpoint), and outputs committing to a scriptPubKey and output amount.\n> Witnesses can be provided separately, and would sign a signature committing to\n> the transaction or optionally, a subset of of inputs and/or outputs (with\n> merkle trees we can easily avoid the exponential signature validation problems\n> bitcoin currently has).\n> \n> As so long as all genesis transactions are unique, and our hash function is\n> secure, all transaction outputs can be uniquely identified (prior to BIP34 the\n> Bitcoin protocol actually failed at this!).\n> \n> \n> ## Proof Distribution\n> \n> How does Alice convince Bob that she has done a transaction that puts the\n> system into the state that Bob wanted? The obvious answer is she gives Bob data\n> proving that the system is now in the desired state; in a transactional system\n> that proof is some or all of the transaction history. Systems like Bitcoin\n> provide a generic flood-fill messaging layer where all participants have the\n> opportunity to get a copy of all proofs in the system, however we can also\n> implement more fine grained solutions based on peer-to-peer message passing -\n> one could imagine Alice proving to Bob that she transferred title to her house\n> to him by giving him a series of proofs, not unlike the same way that property\n> title transfer can be demonstrated by providing the buyer with a series of deed\n> documents (though note the double-spend problem!).\n> \n> \n> # Uniqueness and Single-Use Seals\n> \n> In addition to knowing that a given transaction history is valid, we also want\n> to know if it's unique. By that we mean that every spent output in the\n> transaction history is associated with exactly one input, and no other valid\n> spends exist; we want to ensure no output has been double-spent.\n> \n> Bitcoin (and pretty much every other cryptocurrency like it) achieves this goal\n> by defining a method of achieving consensus over the set of all (valid)\n> transactions, and then defining that consensus as valid if and only if no\n> output is spent more than once.\n> \n> A more general approach is to introduce the idea of a cryptographic Single-Use\n> Seal, analogous to the tamper-evidence single-use seals commonly used for\n> protecting goods during shipment and storage. Each individual seals is\n> associated with a globally unique identifier, and has two states, open and\n> closed. A secure seal can be closed exactly once, producing a proof that the\n> seal was closed.\n> \n> All practical single-use seals will be associated with some kind of condition,\n> such as a pubkey, or deterministic expression, that needs to be satisfied for\n> the seal to be closed. Secondly, the contents of the proof will be able to\n> commit to new data, such as the transaction spending the output associated with\n> the seal.\n> \n> Additionally some implementations of single-use seals may be able to also\n> generate a proof that a seal was _not_ closed as of a certain\n> time/block-height/etc.\n> \n> \n> ## Implementations\n> \n> ### Transactional Blockchains\n> \n> A transaction output on a system like Bitcoin can be used as a single-use seal.\n> In this implementation, the outpoint (txid:vout #) is the seal's identifier,\n> the authorization mechanism is the scriptPubKey of the output, and the proof\n> is the transaction spending the output. The proof can commit to additional\n> data as needed in a variety of ways, such as an OP_RETURN output, or\n> unspendable output.\n> \n> This implementation approach is resistant to miner censorship if the seal's\n> identifier isn't made public, and the protocol (optionally) allows for the\n> proof transaction to commit to the sealed contents with unspendable outputs;\n> unspendable outputs can't be distinguished from transactions that move funds.\n> \n> \n> ### Unbounded Oracles\n> \n> A trusted oracle P can maintain a set of closed seals, and produce signed\n> messages attesting to the fact that a seal was closed. Specifically, the seal\n> is identified by the tuple (P, q), with q being the per-seal authorization\n> expression that must be satisfied for the seal to be closed. The first time the\n> oracle is given a valid signature for the seal, it adds that signature and seal\n> ID to its closed seal set, and makes available a signed message attesting to\n> the fact that the seal has been closed. The proof is that message (and\n> possibly the signature, or a second message signed by it).\n> \n> The oracle can publish the set of all closed seals for transparency/auditing\n> purposes. A good way to do this is to make a merkelized key:value set, with the\n> seal identifiers as keys, and the value being the proofs, and in turn create a\n> signed certificate transparency log of that set over time. Merkle-paths from\n> this log can also serve as the closed seal proof, and for that matter, as\n> proof of the fact that a seal has not been closed.\n> \n> \n> ### Bounded Oracles\n> \n> The above has the problem of unbounded storage requirements as the closed seal\n> set grows without bound. We can fix that problem by requiring users of the\n> oracle to allocate seals in advance, analogous to the UTXO set in Bitcoin.\n> \n> To allocate a seal the user provides the oracle P with the authorization\n> expression q. The oracle then generates a nonce n and adds (q,n) to the set of\n> unclosed seals, and tells the user that nonce. The seal is then uniquely\n> identified by (P, q, n)\n> \n> To close a seal, the user provides the oracle with a valid signature over (P,\n> q, n). If the open seal set contains that seal, the seal is removed from the\n> set and the oracle provides the user with a signed message attesting to the\n> valid close.\n> \n> A practical implementation would be to have the oracle publish a transparency\n> log, with each entry in the log committing to the set of all open seals with a\n> merkle set, as well as any seals closed during that entry. Again, merkle paths\n> for this log can serve as proofs to the open or closed state of a seal.\n> \n> Note how with (U)TXO commitments, Bitcoin itself is a bounded oracle\n> implementation that can produce compact proofs.\n> \n> \n> ### Group Seals\n> \n> Multiple seals can be combined into one, by having the open seal commit to a\n> set of sub-seals, and then closing the seal over a second set of closed seal\n> proofs. Seals that didn't need to be closed can be closed over a special\n> re-delegation message, re-delegating the seal to a new open seal.\n> \n> Since the closed sub-seal proof can additionally include a proof of\n> authorization, we have a protcol where the entity with authorization to close\n> the master seal has the ability to DoS attack sub-seals owners, but not the\n> ability to fraudulently close the seals over contents of their choosing. This\n> may be useful in cases where actions on the master seal is expensive - such as\n> seals implemented on top of decentralized blockchains - by amortising the cost\n> over all sub-seals.\n> \n> \n> ## Atomicity\n> \n> Often protocols will require multiple seals to be closed for a transaction to\n> be valid. If a single entity controls all seals, this is no problem: the\n> transaction simply isn't valid until the last seal is closed.\n> \n> However if multiple parties control the seals, a party could attack another\n> party by failing to go through with the transaction, after another party has\n> closed their seal, leaving the victim with an invalid transaction that they\n> can't reverse.\n> \n> We have a few options to resolve this problem:\n> \n> ### Use a single oracle\n> \n> The oracle can additionally guarantee that a seal will be closed iff some other\n> set of seals are also closed; seals implemented with Bitcoin can provide this\n> guarantee. If the parties to a transaction aren't already all on the same\n> oracle, they can add an additional transaction reassigning their outputs to a\n> common oracle.\n> \n> Equally, a temporary consensus between multiple mutually trusting oracles can\n> be created with a consensus protocol they share; this option doesn't need to\n> change the proof verification implementation.\n> \n> \n> ### Two-phase Timeouts\n> \n> If a proof to the fact that a seal is open can be generated, even under\n> adversarial conditions, we can make the seal protocol allow a close to be\n> undone after a timeout if evidence can be provided that the other seal(s) were\n> not also closed (in the specified way).\n> \n> Depending on the implementation - especially in decentralized systems - the\n> next time the seal is closed, the proof it has been closed may in turn provide\n> proof that a previous close was in fact invalid.\n> \n> \n> # Proof-of-Publication and Proof-of-Non-Publication\n> \n> Often we need to be able to prove that a specified audience was able to receive\n> a specific message. For example, the author's PayPub protocol[^paypub],\n> Todd/Taaki's timelock encryption protocol[^timelock], Zero-Knowledge Contingent\n> Payments[^zkcp], and Lightning, among others work by requiring a secret key to\n> be published publicly in the Bitcoin blockchain as a condition of collecting a\n> payment. At a much smaller scale - in terms of audience - in certain FinTech\n> applications for regulated environments a transaction may be considered invalid\n> unless it was provably published to a regulatory agency.  Another example is\n> Certificate Transparency, where we consider a SSL certificate to be invalid\n> unless it has been provably published to a transparency log maintained by a\n> third-party.\n> \n> Secondly, many proof-of-publication schemes also can prove that a message was\n> _not_ published to a specific audience. With this type of proof single-use\n> seals can be implemented, by having the proof consist of proof that a specified\n> message was not published between the time the seal was created, and the time\n> it was closed (a proof-of-publication of the message).\n> \n> ## Implementations\n> \n> ### Decentralized Blockchains\n> \n> Here the audience is all participants in the system. However miner censorship\n> can be a problem, and compact proofs of non-publication aren't yet available\n> (requires (U)TXO commitments).\n> \n> The authors treechains proposal is a particularly generic and scalable\n> implementation, with the ability to make trade offs between the size of\n> audience (security) and publication cost.\n> \n> ### Centralized Public Logs\n> \n> Certificate Transparency works this way, with trusted (but auditable) logs run\n> by well known parties acting as the publication medium, who promise to allow\n> anyone to obtain copies of the logs.\n> \n> The logs themselves may be indexed in a variety of ways; CT simply indexes logs\n> by time, however more efficient schemes are possible by having the operator\n> commit to a key:value mapping of \"topics\", to allow publication (and\n> non-publication) proofs to be created for specified topics or topic prefixes.\n> \n> Auditing the logs is done by verifying that queries to the state of the log\n> return the same state at the same time for different requesters.\n> \n> ### Receipt Oracles\n> \n> Finally publication can be proven by a receipt proof by the oracle, attesting\n> to the fact that the oracle has successfully received the message. This is\n> particularly appropriate in cases where the required audience is the oracle\n> itself, as in the FinTech regulator case.\n> \n> \n> # Validity Oracles\n> \n> As transaction histories grow longer, they may become impractical to move from\n> one party to another. Validity oracles can solve this problem by attesting to\n> the validity of transactions, allowing history prior to the attested\n> transactions to be discarded.\n> \n> A particularly generic validity oracle can be created using deterministic\n> expressions systems. The user gives the oracle an expression, and the oracle\n> returns a signed message attesting to the validity of the expression.\n> Optionally, the expression may be incomplete, with parts of the expression\n> replaced by previously generated attestations. For example, an expression that\n> returns true if a transaction is valid could in turn depend on the previous\n> transaction also being valid - a recursive call of itself - and that recursive\n> call can be proven with a prior attestation.\n> \n> ## Implementations\n> \n> ### Proof-of-Work Decentralized Consensus\n> \n> Miners in decentralized consensus systems act as a type of validity oracle, in\n> that the economic incentives in the system are (supposed to be) designed to\n> encourage only the mining of valid blocks; a user who trusts the majority of\n> hashing power can trust that any transaction with a valid merkle path to a\n> block header in the most-work chain is valid. Existing decentralized consensus\n> systems like Bitcoin and Ethereum conflate the roles of validity oracle and\n> single-use seal/anti-replay oracle, however in principle that need not be true.\n> \n> \n> ### Trusted Oracles\n> \n> As the name suggests. Remote-attestation-capable trusted hardware is a\n> particularly powerful implementation - a conspiracy theory is that the reason\n> why essentially zero secure true remote attestation implementations exist is\n> because they'd immediately make untraceable digital currency systems easy to\n> implement (Finney's RPOW[^rpow] is a rare counter-example).\n> \n> Note how a single-use seal oracle that supports a generic deterministic\n> expressions scheme for seal authorization can be easily extended to provide a\n> validity oracle service as well. The auditing mechanisms for a single-use seal\n> oracle can also be applied to validity oracles.\n> \n> \n> # Fraud Proofs\n> \n> Protocols specified with deterministic expressions can easily generate \"fraud\n> proofs\", showing that claimed states/proof in the system are actually invalid.\n> Additionally many protocols can be specified with expressions of k*log2(n)\n> depth, allowing these fraud proofs to be compact.\n> \n> A simple example is proving fraud in merkle-sum tree, where the validity\n> expression would be something like:\n> \n>     (defun valid? (node)\n>         (or (== node.type leaf)\n>             (and (== node.sum (+ node.left.sum node.right.sum))\n>                  (and (valid? node.left)\n>                       (valid? node.right)))))\n> \n> To prove the above expression evaluates to true, we'll need the entire contents\n> of the tree. However, to prove that it evaluates to false, we only need a\n> subset of the tree as proving an and expression evaluates to false only\n> requires one side, and requires log2(n) data. Secondly, with pruning, the\n> deterministic expressions evaluator can automatically keep track of exactly\n> what data was needed to prove that result, and prune all other data when\n> serializing the proof.\n> \n> \n> ## Validity Challenges\n> \n> However how do you guarantee it will be possible to prove fraud in the first\n> place? If pruning is allowed, you may simply not have access to the data\n> proving fraud - an especially severe problem in transactional systems where a\n> single fraudulent transaction can counterfeit arbitrary amounts of value out of\n> thin air.\n> \n> A possible approach is the validity challenge: a subset of proof data, with\n> part of the data marked as \"potentially fraudulent\". The challenge can be\n> satisfied by providing the marked data and showing that the proof in question\n> is in fact valid; if the challenge is unmet participants in the system can\n> choose to take action, such as refusing to accept additional transactions.\n> \n> Of course, this raises a whole host of so-far unsolved issues, such as DoS\n> attacks and lost data.\n> \n> \n> # Probabilistic Validation\n> \n> Protocols that can tolerate some fraud can make use of probabilistic\n> verification techniques to prove that the percentage of undetected fraud within\n> the system is less than a certain amount, with a specified probability.\n> \n> A common way to do this is the Fiat-Shamir transform, which repeatedly samples\n> a data structure deterministically, using the data's own hash digest as a seed\n> for a PRNG. Let's apply this technique to our merkle-sum tree example. We'll\n> first need a recursive function to check a sample, weighted by value:\n> \n>     (defun prefix-valid? (node nonce)\n>         (or (== node.type leaf)\n>             (and (and (== node.sum (+ node.left.sum node.right.sum))\n>                       (> 0 node.sum)) ; mod by 0 is invalid, just like division by zero\n>                                       ; also could guarantee this with a type system\n>                  (and (if (< node.left.sum (mod nonce node.sum))\n>                           (prefix-valid? node.right (hash nonce))\n>                           (prefix-valid? node.left (hash nonce)))))))\n> \n> Now we can combine multiple invocations of the above, in this case 256\n> invocations:\n> \n>     (defun prob-valid? (node)\n>         (and (and (and .... (prefix-valid? node (digest (cons (digest node) 0)))\n>              (and (and ....\n>                             (prefix-valid? node (digest (cons (digest node) 255)))\n> \n> As an exercise for a reader: generalize the above with a macro, or a suitable\n> types/generics system.\n> \n> If we assume our attacker can grind up to 128 bits, that leaves us with 128\n> random samples that they can't control. If the (value weighted) probability of\n> a given node is fraudulent q, then the chance of the attacker getting away with\n> fraud is (1-q)^128 - for q=5% that works out to 0.1%\n> \n> (Note that the above analysis isn't particularly well done - do a better\n> analysis before implementing this in production!)\n> \n> \n> ## Random Beacons and Transaction History Linearization\n> \n> The Fiat-Shamir transform requires a significant number of samples to defeat\n> grinding attacks; if we have a random beacon available we can significantly\n> reduce the size of our probabilistic proofs. PoW blockchains can themselves act\n> as random beacons, as it is provably expensive for miners to manipulate the\n> hash digests of blocks they produce - to do so requires discarding otherwise\n> valid blocks.\n> \n> An example where this capability is essential is the author's transaction\n> history linearization technique. In value transfer systems such as Bitcoin, the\n> history of any given coin grows quasi-exponentially as coins are mixed across\n> the entire economy. We can linearize the growth of history proofs by redefining\n> coin validity to be probabilistic.\n> \n> Suppose we have a transaction with n inputs. Of those inputs, the total value\n> of real inputs is p, and the total claimed value of fake inputs is q. The\n> transaction commits to all inputs in a merkle sum tree, and we define the\n> transaction as valid if a randomly chosen input - weighted by value - can\n> itself be proven valid. Finally, we assume that creating a genuine input is a\n> irrevocable action which irrevocable commits to the set of all inputs, real and\n> fake.\n> \n> If all inputs are real, 100% of the time the transaction will be valid; if all\n> inputs are fake, 100% of the time the transaction will be invalid. In the case\n> where some inputs are real and some are fake the probability that the fraud\n> will be detected is:\n> \n>     q / (q + p)\n> \n> The expected value of the fake inputs is then the sum of the potential upside -\n> the fraud goes detected - and the potential downside - the fraud is detected\n> and the real inputs are destroyed:\n> \n>     E = q(1 - q/(q + p)) - p(q/(q + p)\n>       = q(p/(q + p)) - p(q/(q + p)\n>       = (q - q)(p/(q + p))\n>       = 0\n> \n> Thus so long as the random beacon is truly unpredictable, there's no economic\n> advantage to creating fake inputs, and it is sufficient for validity to only\n> require one input to be proven, giving us O(n) scaling for transaction history\n> proofs.\n> \n> \n> ### Inflationary O(1) History Proofs\n> \n> We can further improve our transaction history proof scalability by taking\n> advantage of inflation. We do this by occasionally allowing a transaction proof\n> to be considered valid without validating _any_ of the inputs; every time a\n> transaction is allowed without proving any inputs the size of the transaction\n> history proof is reset. Of course, this can be a source of inflation, but\n> provided the probability of this happening can be limited we can limit the\n> maximum rate of inflation to the chosen value.\n> \n> For example, in Bitcoin as of writing every block inflates the currency supply\n> by 25BTC, and contains a maximum of 1MB of transaction data, 0.025BTC/KB. If we\n> check the prior input proof with probability p, then the expected value of a\n> transaction claiming to spend x BTC is:\n> \n>     E = x(1-p)\n> \n> We can rewrite that in terms of the block reward per-byte R, and the transaction size l:\n> \n>     lR = x(1-p)\n> \n> And solving for p:\n> \n>     p = 1 - lR/x\n> \n> For example, for a 1KB transaction proof claiming to spending 10BTC we can omit\n> checking the input 0.25% of the time without allowing more monetary inflation\n> than the block reward already does. Secondly, this means that after n\n> transactions, the probability that proof shortening will _not_ happen is p^n,\n> which reaches 1% after 1840 transactions.\n> \n> In a system like Bitcoin where miners are expected to validate, a transaction\n> proof could consist of just a single merkle path showing that a single-use seal\n> was closed in some kind of TXO commitment - probably under 10KB of data. That\n> gives us a history proof less than 18.4MB in size, 99% of the time, and less\n> than 9.2MB in size 90% of the time.\n> \n> An interesting outcome of thing kind of design is that we can institutionalize\n> inflation fraud: the entire block reward can be replaced by miners rolling the\n> dice, attempting to create valid \"fake\" transactions. However, such a pure\n> implementation would put a floor on the lowest transaction fee possible, so\n> better to allow both transaction fee and subsidy collection at the same time.\n> \n> \n> # References\n> \n> [^paypub] https://github.com/unsystem/paypub\n> [^timelock] https://github.com/petertodd/timelock\n> [^zkcp] https://bitcoincore.org/en/2016/02/26/zero-knowledge-contingent-payments-announcement/\n> [^rpow] https://cryptome.org/rpow.htm\n> \n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "zaki at manian.org",
                "date": "2016-06-20T16:21:39",
                "message_text_only": "Hi Peter,\n\nI didn't entirely understand the process of transaction linearization.\n\nWhat I see is a potential process where when the miner assembles the block,\nhe strips all but one sigscript per tx. The selection of which  sigscript\nis retained is determined by the random oracle.  Is this is primary benefit\nyou are suggesting?\n\nIt appears to me that blocks still need to contain a list of full TX Input\nand Tx Outputs with your approach. Some of the description seems to\nindicate that there are opportunities to elide further data but it's\nunclear to me how.\n\nOn Mon, Jun 20, 2016 at 7:14 AM Police Terror via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Bitcoin could embed a lisp interpreter such as Scheme, reverse engineer\n> the current protocol into lisp (inside C++), run this alternative engine\n> alongside the current one as an option for some years (only for fine\n> tuning) then eventually fade this lisp written validation code instead\n> of the current one.\n>\n> Scheme is small and minimal, and embeds easily in C++. This could be a\n> better option than the libconsensus library - validation in a functional\n> scripting language.\n>\n> That doesn't mean people can't program the validation code in other\n> languages (maybe they'd want to optimize), but this code would be the\n> standard.\n>\n> It's really good how you are thinking deeply how Bitcoin can be used,\n> and the implications of everything. Also there's a lot of magical utopic\n> thinking in Ethereum, which is transhumanist nonsense that is life\n> denying. Bitcoin really speaks to me because it is real and a great tool\n> following the UNIX principle.\n>\n> I wouldn't be so quick to deride good engineering over systematic\n> provable systems for all domains. Bitcoin being written in C++ is not a\n> defect. It's actually a strong language for what it does. Especially\n> when used correctly (which is not often and takes years to master).\n>\n> With the seals idea- am I understand this correctly?: Every transaction\n> has a number (essentially the index starting from 0 upwards) depending\n> on where it is in the blockchain.\n>\n> Then there is an array (probably an on disk array mapping transaction\n> indexes to hashes). Each hash entry in the array must be unique (the\n> hashes) otherwise the transaction will be denied. This is a great idea\n> to solve transaction hash collisions and simple to implement.\n>\n> Probabilistic validation is a good idea, although the real difficulty\n> now seems to be writing and indexing all the blockchain data for\n> lookups. And validation is disabled for most of the blocks. Pruning is\n> only a stop gap measure (which loses data) that doesn't solve the issue\n> of continually growing resource consumption. Hardware and implementation\n> can only mitigate this so much. If only there was a way to simplify the\n> underlying protocol to make it more resource efficient...\n>\n> Peter Todd via bitcoin-dev:\n> > In light of Ethereum's recent problems with its imperative,\n> account-based,\n> > programming model, I thought I'd do a quick writeup outlining the\n> building\n> > blocks of the state-machine approach to so-called \"smart contract\"\n> systems, an\n> > extension of Bitcoin's own design that I personally have been developing\n> for a\n> > number of years now as my Proofchains/Dex research work.\n> >\n> >\n> > # Deterministic Code / Deterministic Expressions\n> >\n> > We need to be able to run code on different computers and get identical\n> > results; without this consensus is impossible and we might as well just\n> use a\n> > central authoritative database. Traditional languages and surrounding\n> > frameworks make determinism difficult to achieve, as they tend to be\n> filled\n> > with undefined and underspecified behavior, ranging from signed integer\n> > overflow in C/C++ to non-deterministic behavior in databases. While some\n> > successful systems like Bitcoin are based on such languages, their\n> success is\n> > attributable to heroic efforts by their developers.\n> >\n> > Deterministic expression systems such as Bitcoin's scripting system and\n> the\n> > author's Dex project improve on this by allowing expressions to be\n> precisely\n> > specified by hash digest, and executed against an environment with\n> > deterministic results. In the case of Bitcoin's script, the expression\n> is a\n> > Forth-like stack-based program; in Dex the expression takes the form of a\n> > lambda calculus expression.\n> >\n> >\n> > ## Proofs\n> >\n> > So far the most common use for deterministic expressions is to specify\n> > conditions upon which funds can be spent, as seen in Bitcoin\n> (particularly\n> > P2SH, and the upcoming Segwit). But we can generalize their use to\n> precisely\n> > defining consensus protocols in terms of state machines, with each state\n> > defined in terms of a deterministic expression that must return true for\n> the\n> > state to have been reached. The data that causes a given expression to\n> return\n> > true is then a \"proof\", and that proof can be passed from one party to\n> another\n> > to prove desired states in the system have been reached.\n> >\n> > An important implication of this model is that we need deterministic, and\n> > efficient, serialization of proof data.\n> >\n> >\n> > ## Pruning\n> >\n> > Often the evaluation of an expression against a proof doesn't require\n> all all\n> > data in the proof. For example, to prove to a lite client that a given\n> block\n> > contains a transaction, we only need the merkle path from the\n> transaction to\n> > the block header. Systems like Proofchains and Dex generalize this\n> process -\n> > called \"pruning\" - with built-in support to both keep track of what data\n> is\n> > accessed by what operations, as well as support in their underlying\n> > serialization schemes for unneeded data to be elided and replaced by the\n> hash\n> > digest of the pruned data.\n> >\n> >\n> > # Transactions\n> >\n> > A common type of state machine is the transaction. A transaction history\n> is a\n> > directed acyclic graph of transactions, with one or more genesis\n> transactions\n> > having no inputs (ancestors), and one or more outputs, and zero or more\n> > non-genesis transactions with one or more inputs, and zero or more\n> outputs. The\n> > edges of the graph connect inputs to outputs, with every input connected\n> to\n> > exactly one output. Outputs with an associated input are known as spent\n> > outputs; outputs with out an associated input are unspent.\n> >\n> > Outputs have conditions attached to them (e.g. a pubkey for which a valid\n> > signature must be produced), and may also be associated with other\n> values such\n> > as \"# of coins\". We consider a transaction valid if we have a set of\n> proofs,\n> > one per input, that satisfy the conditions associated with each output.\n> > Secondly, validity may also require additional constraints to be true,\n> such as\n> > requiring the coins spent to be >= the coins created on the outputs.\n> Input\n> > proofs also must uniquely commit to the transaction itself to be secure\n> - if\n> > they don't the proofs can be reused in a replay attack.\n> >\n> > A non-genesis transaction is valid if:\n> >\n> > 1. Any protocol-specific rules such as coins spent >= coins output are\n> >    followed.\n> >\n> > 2. For every input a valid proof exists.\n> >\n> > 3. Every input transaction is itself valid.\n> >\n> > A practical implementation of the above for value-transfer systems like\n> Bitcoin\n> > could use two merkle-sum trees, one for the inputs, and one for the\n> outputs,\n> > with inputs simply committing to the previous transaction's txid and\n> output #\n> > (outpoint), and outputs committing to a scriptPubKey and output amount.\n> > Witnesses can be provided separately, and would sign a signature\n> committing to\n> > the transaction or optionally, a subset of of inputs and/or outputs (with\n> > merkle trees we can easily avoid the exponential signature validation\n> problems\n> > bitcoin currently has).\n> >\n> > As so long as all genesis transactions are unique, and our hash function\n> is\n> > secure, all transaction outputs can be uniquely identified (prior to\n> BIP34 the\n> > Bitcoin protocol actually failed at this!).\n> >\n> >\n> > ## Proof Distribution\n> >\n> > How does Alice convince Bob that she has done a transaction that puts the\n> > system into the state that Bob wanted? The obvious answer is she gives\n> Bob data\n> > proving that the system is now in the desired state; in a transactional\n> system\n> > that proof is some or all of the transaction history. Systems like\n> Bitcoin\n> > provide a generic flood-fill messaging layer where all participants have\n> the\n> > opportunity to get a copy of all proofs in the system, however we can\n> also\n> > implement more fine grained solutions based on peer-to-peer message\n> passing -\n> > one could imagine Alice proving to Bob that she transferred title to her\n> house\n> > to him by giving him a series of proofs, not unlike the same way that\n> property\n> > title transfer can be demonstrated by providing the buyer with a series\n> of deed\n> > documents (though note the double-spend problem!).\n> >\n> >\n> > # Uniqueness and Single-Use Seals\n> >\n> > In addition to knowing that a given transaction history is valid, we\n> also want\n> > to know if it's unique. By that we mean that every spent output in the\n> > transaction history is associated with exactly one input, and no other\n> valid\n> > spends exist; we want to ensure no output has been double-spent.\n> >\n> > Bitcoin (and pretty much every other cryptocurrency like it) achieves\n> this goal\n> > by defining a method of achieving consensus over the set of all (valid)\n> > transactions, and then defining that consensus as valid if and only if no\n> > output is spent more than once.\n> >\n> > A more general approach is to introduce the idea of a cryptographic\n> Single-Use\n> > Seal, analogous to the tamper-evidence single-use seals commonly used for\n> > protecting goods during shipment and storage. Each individual seals is\n> > associated with a globally unique identifier, and has two states, open\n> and\n> > closed. A secure seal can be closed exactly once, producing a proof that\n> the\n> > seal was closed.\n> >\n> > All practical single-use seals will be associated with some kind of\n> condition,\n> > such as a pubkey, or deterministic expression, that needs to be\n> satisfied for\n> > the seal to be closed. Secondly, the contents of the proof will be able\n> to\n> > commit to new data, such as the transaction spending the output\n> associated with\n> > the seal.\n> >\n> > Additionally some implementations of single-use seals may be able to also\n> > generate a proof that a seal was _not_ closed as of a certain\n> > time/block-height/etc.\n> >\n> >\n> > ## Implementations\n> >\n> > ### Transactional Blockchains\n> >\n> > A transaction output on a system like Bitcoin can be used as a\n> single-use seal.\n> > In this implementation, the outpoint (txid:vout #) is the seal's\n> identifier,\n> > the authorization mechanism is the scriptPubKey of the output, and the\n> proof\n> > is the transaction spending the output. The proof can commit to\n> additional\n> > data as needed in a variety of ways, such as an OP_RETURN output, or\n> > unspendable output.\n> >\n> > This implementation approach is resistant to miner censorship if the\n> seal's\n> > identifier isn't made public, and the protocol (optionally) allows for\n> the\n> > proof transaction to commit to the sealed contents with unspendable\n> outputs;\n> > unspendable outputs can't be distinguished from transactions that move\n> funds.\n> >\n> >\n> > ### Unbounded Oracles\n> >\n> > A trusted oracle P can maintain a set of closed seals, and produce signed\n> > messages attesting to the fact that a seal was closed. Specifically, the\n> seal\n> > is identified by the tuple (P, q), with q being the per-seal\n> authorization\n> > expression that must be satisfied for the seal to be closed. The first\n> time the\n> > oracle is given a valid signature for the seal, it adds that signature\n> and seal\n> > ID to its closed seal set, and makes available a signed message\n> attesting to\n> > the fact that the seal has been closed. The proof is that message (and\n> > possibly the signature, or a second message signed by it).\n> >\n> > The oracle can publish the set of all closed seals for\n> transparency/auditing\n> > purposes. A good way to do this is to make a merkelized key:value set,\n> with the\n> > seal identifiers as keys, and the value being the proofs, and in turn\n> create a\n> > signed certificate transparency log of that set over time. Merkle-paths\n> from\n> > this log can also serve as the closed seal proof, and for that matter, as\n> > proof of the fact that a seal has not been closed.\n> >\n> >\n> > ### Bounded Oracles\n> >\n> > The above has the problem of unbounded storage requirements as the\n> closed seal\n> > set grows without bound. We can fix that problem by requiring users of\n> the\n> > oracle to allocate seals in advance, analogous to the UTXO set in\n> Bitcoin.\n> >\n> > To allocate a seal the user provides the oracle P with the authorization\n> > expression q. The oracle then generates a nonce n and adds (q,n) to the\n> set of\n> > unclosed seals, and tells the user that nonce. The seal is then uniquely\n> > identified by (P, q, n)\n> >\n> > To close a seal, the user provides the oracle with a valid signature\n> over (P,\n> > q, n). If the open seal set contains that seal, the seal is removed from\n> the\n> > set and the oracle provides the user with a signed message attesting to\n> the\n> > valid close.\n> >\n> > A practical implementation would be to have the oracle publish a\n> transparency\n> > log, with each entry in the log committing to the set of all open seals\n> with a\n> > merkle set, as well as any seals closed during that entry. Again, merkle\n> paths\n> > for this log can serve as proofs to the open or closed state of a seal.\n> >\n> > Note how with (U)TXO commitments, Bitcoin itself is a bounded oracle\n> > implementation that can produce compact proofs.\n> >\n> >\n> > ### Group Seals\n> >\n> > Multiple seals can be combined into one, by having the open seal commit\n> to a\n> > set of sub-seals, and then closing the seal over a second set of closed\n> seal\n> > proofs. Seals that didn't need to be closed can be closed over a special\n> > re-delegation message, re-delegating the seal to a new open seal.\n> >\n> > Since the closed sub-seal proof can additionally include a proof of\n> > authorization, we have a protcol where the entity with authorization to\n> close\n> > the master seal has the ability to DoS attack sub-seals owners, but not\n> the\n> > ability to fraudulently close the seals over contents of their choosing.\n> This\n> > may be useful in cases where actions on the master seal is expensive -\n> such as\n> > seals implemented on top of decentralized blockchains - by amortising\n> the cost\n> > over all sub-seals.\n> >\n> >\n> > ## Atomicity\n> >\n> > Often protocols will require multiple seals to be closed for a\n> transaction to\n> > be valid. If a single entity controls all seals, this is no problem: the\n> > transaction simply isn't valid until the last seal is closed.\n> >\n> > However if multiple parties control the seals, a party could attack\n> another\n> > party by failing to go through with the transaction, after another party\n> has\n> > closed their seal, leaving the victim with an invalid transaction that\n> they\n> > can't reverse.\n> >\n> > We have a few options to resolve this problem:\n> >\n> > ### Use a single oracle\n> >\n> > The oracle can additionally guarantee that a seal will be closed iff\n> some other\n> > set of seals are also closed; seals implemented with Bitcoin can provide\n> this\n> > guarantee. If the parties to a transaction aren't already all on the same\n> > oracle, they can add an additional transaction reassigning their outputs\n> to a\n> > common oracle.\n> >\n> > Equally, a temporary consensus between multiple mutually trusting\n> oracles can\n> > be created with a consensus protocol they share; this option doesn't\n> need to\n> > change the proof verification implementation.\n> >\n> >\n> > ### Two-phase Timeouts\n> >\n> > If a proof to the fact that a seal is open can be generated, even under\n> > adversarial conditions, we can make the seal protocol allow a close to be\n> > undone after a timeout if evidence can be provided that the other\n> seal(s) were\n> > not also closed (in the specified way).\n> >\n> > Depending on the implementation - especially in decentralized systems -\n> the\n> > next time the seal is closed, the proof it has been closed may in turn\n> provide\n> > proof that a previous close was in fact invalid.\n> >\n> >\n> > # Proof-of-Publication and Proof-of-Non-Publication\n> >\n> > Often we need to be able to prove that a specified audience was able to\n> receive\n> > a specific message. For example, the author's PayPub protocol[^paypub],\n> > Todd/Taaki's timelock encryption protocol[^timelock], Zero-Knowledge\n> Contingent\n> > Payments[^zkcp], and Lightning, among others work by requiring a secret\n> key to\n> > be published publicly in the Bitcoin blockchain as a condition of\n> collecting a\n> > payment. At a much smaller scale - in terms of audience - in certain\n> FinTech\n> > applications for regulated environments a transaction may be considered\n> invalid\n> > unless it was provably published to a regulatory agency.  Another\n> example is\n> > Certificate Transparency, where we consider a SSL certificate to be\n> invalid\n> > unless it has been provably published to a transparency log maintained\n> by a\n> > third-party.\n> >\n> > Secondly, many proof-of-publication schemes also can prove that a\n> message was\n> > _not_ published to a specific audience. With this type of proof\n> single-use\n> > seals can be implemented, by having the proof consist of proof that a\n> specified\n> > message was not published between the time the seal was created, and the\n> time\n> > it was closed (a proof-of-publication of the message).\n> >\n> > ## Implementations\n> >\n> > ### Decentralized Blockchains\n> >\n> > Here the audience is all participants in the system. However miner\n> censorship\n> > can be a problem, and compact proofs of non-publication aren't yet\n> available\n> > (requires (U)TXO commitments).\n> >\n> > The authors treechains proposal is a particularly generic and scalable\n> > implementation, with the ability to make trade offs between the size of\n> > audience (security) and publication cost.\n> >\n> > ### Centralized Public Logs\n> >\n> > Certificate Transparency works this way, with trusted (but auditable)\n> logs run\n> > by well known parties acting as the publication medium, who promise to\n> allow\n> > anyone to obtain copies of the logs.\n> >\n> > The logs themselves may be indexed in a variety of ways; CT simply\n> indexes logs\n> > by time, however more efficient schemes are possible by having the\n> operator\n> > commit to a key:value mapping of \"topics\", to allow publication (and\n> > non-publication) proofs to be created for specified topics or topic\n> prefixes.\n> >\n> > Auditing the logs is done by verifying that queries to the state of the\n> log\n> > return the same state at the same time for different requesters.\n> >\n> > ### Receipt Oracles\n> >\n> > Finally publication can be proven by a receipt proof by the oracle,\n> attesting\n> > to the fact that the oracle has successfully received the message. This\n> is\n> > particularly appropriate in cases where the required audience is the\n> oracle\n> > itself, as in the FinTech regulator case.\n> >\n> >\n> > # Validity Oracles\n> >\n> > As transaction histories grow longer, they may become impractical to\n> move from\n> > one party to another. Validity oracles can solve this problem by\n> attesting to\n> > the validity of transactions, allowing history prior to the attested\n> > transactions to be discarded.\n> >\n> > A particularly generic validity oracle can be created using deterministic\n> > expressions systems. The user gives the oracle an expression, and the\n> oracle\n> > returns a signed message attesting to the validity of the expression.\n> > Optionally, the expression may be incomplete, with parts of the\n> expression\n> > replaced by previously generated attestations. For example, an\n> expression that\n> > returns true if a transaction is valid could in turn depend on the\n> previous\n> > transaction also being valid - a recursive call of itself - and that\n> recursive\n> > call can be proven with a prior attestation.\n> >\n> > ## Implementations\n> >\n> > ### Proof-of-Work Decentralized Consensus\n> >\n> > Miners in decentralized consensus systems act as a type of validity\n> oracle, in\n> > that the economic incentives in the system are (supposed to be) designed\n> to\n> > encourage only the mining of valid blocks; a user who trusts the\n> majority of\n> > hashing power can trust that any transaction with a valid merkle path to\n> a\n> > block header in the most-work chain is valid. Existing decentralized\n> consensus\n> > systems like Bitcoin and Ethereum conflate the roles of validity oracle\n> and\n> > single-use seal/anti-replay oracle, however in principle that need not\n> be true.\n> >\n> >\n> > ### Trusted Oracles\n> >\n> > As the name suggests. Remote-attestation-capable trusted hardware is a\n> > particularly powerful implementation - a conspiracy theory is that the\n> reason\n> > why essentially zero secure true remote attestation implementations\n> exist is\n> > because they'd immediately make untraceable digital currency systems\n> easy to\n> > implement (Finney's RPOW[^rpow] is a rare counter-example).\n> >\n> > Note how a single-use seal oracle that supports a generic deterministic\n> > expressions scheme for seal authorization can be easily extended to\n> provide a\n> > validity oracle service as well. The auditing mechanisms for a\n> single-use seal\n> > oracle can also be applied to validity oracles.\n> >\n> >\n> > # Fraud Proofs\n> >\n> > Protocols specified with deterministic expressions can easily generate\n> \"fraud\n> > proofs\", showing that claimed states/proof in the system are actually\n> invalid.\n> > Additionally many protocols can be specified with expressions of\n> k*log2(n)\n> > depth, allowing these fraud proofs to be compact.\n> >\n> > A simple example is proving fraud in merkle-sum tree, where the validity\n> > expression would be something like:\n> >\n> >     (defun valid? (node)\n> >         (or (== node.type leaf)\n> >             (and (== node.sum (+ node.left.sum node.right.sum))\n> >                  (and (valid? node.left)\n> >                       (valid? node.right)))))\n> >\n> > To prove the above expression evaluates to true, we'll need the entire\n> contents\n> > of the tree. However, to prove that it evaluates to false, we only need a\n> > subset of the tree as proving an and expression evaluates to false only\n> > requires one side, and requires log2(n) data. Secondly, with pruning, the\n> > deterministic expressions evaluator can automatically keep track of\n> exactly\n> > what data was needed to prove that result, and prune all other data when\n> > serializing the proof.\n> >\n> >\n> > ## Validity Challenges\n> >\n> > However how do you guarantee it will be possible to prove fraud in the\n> first\n> > place? If pruning is allowed, you may simply not have access to the data\n> > proving fraud - an especially severe problem in transactional systems\n> where a\n> > single fraudulent transaction can counterfeit arbitrary amounts of value\n> out of\n> > thin air.\n> >\n> > A possible approach is the validity challenge: a subset of proof data,\n> with\n> > part of the data marked as \"potentially fraudulent\". The challenge can be\n> > satisfied by providing the marked data and showing that the proof in\n> question\n> > is in fact valid; if the challenge is unmet participants in the system\n> can\n> > choose to take action, such as refusing to accept additional\n> transactions.\n> >\n> > Of course, this raises a whole host of so-far unsolved issues, such as\n> DoS\n> > attacks and lost data.\n> >\n> >\n> > # Probabilistic Validation\n> >\n> > Protocols that can tolerate some fraud can make use of probabilistic\n> > verification techniques to prove that the percentage of undetected fraud\n> within\n> > the system is less than a certain amount, with a specified probability.\n> >\n> > A common way to do this is the Fiat-Shamir transform, which repeatedly\n> samples\n> > a data structure deterministically, using the data's own hash digest as\n> a seed\n> > for a PRNG. Let's apply this technique to our merkle-sum tree example.\n> We'll\n> > first need a recursive function to check a sample, weighted by value:\n> >\n> >     (defun prefix-valid? (node nonce)\n> >         (or (== node.type leaf)\n> >             (and (and (== node.sum (+ node.left.sum node.right.sum))\n> >                       (> 0 node.sum)) ; mod by 0 is invalid, just like\n> division by zero\n> >                                       ; also could guarantee this with a\n> type system\n> >                  (and (if (< node.left.sum (mod nonce node.sum))\n> >                           (prefix-valid? node.right (hash nonce))\n> >                           (prefix-valid? node.left (hash nonce)))))))\n> >\n> > Now we can combine multiple invocations of the above, in this case 256\n> > invocations:\n> >\n> >     (defun prob-valid? (node)\n> >         (and (and (and .... (prefix-valid? node (digest (cons (digest\n> node) 0)))\n> >              (and (and ....\n> >                             (prefix-valid? node (digest (cons (digest\n> node) 255)))\n> >\n> > As an exercise for a reader: generalize the above with a macro, or a\n> suitable\n> > types/generics system.\n> >\n> > If we assume our attacker can grind up to 128 bits, that leaves us with\n> 128\n> > random samples that they can't control. If the (value weighted)\n> probability of\n> > a given node is fraudulent q, then the chance of the attacker getting\n> away with\n> > fraud is (1-q)^128 - for q=5% that works out to 0.1%\n> >\n> > (Note that the above analysis isn't particularly well done - do a better\n> > analysis before implementing this in production!)\n> >\n> >\n> > ## Random Beacons and Transaction History Linearization\n> >\n> > The Fiat-Shamir transform requires a significant number of samples to\n> defeat\n> > grinding attacks; if we have a random beacon available we can\n> significantly\n> > reduce the size of our probabilistic proofs. PoW blockchains can\n> themselves act\n> > as random beacons, as it is provably expensive for miners to manipulate\n> the\n> > hash digests of blocks they produce - to do so requires discarding\n> otherwise\n> > valid blocks.\n> >\n> > An example where this capability is essential is the author's transaction\n> > history linearization technique. In value transfer systems such as\n> Bitcoin, the\n> > history of any given coin grows quasi-exponentially as coins are mixed\n> across\n> > the entire economy. We can linearize the growth of history proofs by\n> redefining\n> > coin validity to be probabilistic.\n> >\n> > Suppose we have a transaction with n inputs. Of those inputs, the total\n> value\n> > of real inputs is p, and the total claimed value of fake inputs is q. The\n> > transaction commits to all inputs in a merkle sum tree, and we define the\n> > transaction as valid if a randomly chosen input - weighted by value - can\n> > itself be proven valid. Finally, we assume that creating a genuine input\n> is a\n> > irrevocable action which irrevocable commits to the set of all inputs,\n> real and\n> > fake.\n> >\n> > If all inputs are real, 100% of the time the transaction will be valid;\n> if all\n> > inputs are fake, 100% of the time the transaction will be invalid. In\n> the case\n> > where some inputs are real and some are fake the probability that the\n> fraud\n> > will be detected is:\n> >\n> >     q / (q + p)\n> >\n> > The expected value of the fake inputs is then the sum of the potential\n> upside -\n> > the fraud goes detected - and the potential downside - the fraud is\n> detected\n> > and the real inputs are destroyed:\n> >\n> >     E = q(1 - q/(q + p)) - p(q/(q + p)\n> >       = q(p/(q + p)) - p(q/(q + p)\n> >       = (q - q)(p/(q + p))\n> >       = 0\n> >\n> > Thus so long as the random beacon is truly unpredictable, there's no\n> economic\n> > advantage to creating fake inputs, and it is sufficient for validity to\n> only\n> > require one input to be proven, giving us O(n) scaling for transaction\n> history\n> > proofs.\n> >\n> >\n> > ### Inflationary O(1) History Proofs\n> >\n> > We can further improve our transaction history proof scalability by\n> taking\n> > advantage of inflation. We do this by occasionally allowing a\n> transaction proof\n> > to be considered valid without validating _any_ of the inputs; every\n> time a\n> > transaction is allowed without proving any inputs the size of the\n> transaction\n> > history proof is reset. Of course, this can be a source of inflation, but\n> > provided the probability of this happening can be limited we can limit\n> the\n> > maximum rate of inflation to the chosen value.\n> >\n> > For example, in Bitcoin as of writing every block inflates the currency\n> supply\n> > by 25BTC, and contains a maximum of 1MB of transaction data,\n> 0.025BTC/KB. If we\n> > check the prior input proof with probability p, then the expected value\n> of a\n> > transaction claiming to spend x BTC is:\n> >\n> >     E = x(1-p)\n> >\n> > We can rewrite that in terms of the block reward per-byte R, and the\n> transaction size l:\n> >\n> >     lR = x(1-p)\n> >\n> > And solving for p:\n> >\n> >     p = 1 - lR/x\n> >\n> > For example, for a 1KB transaction proof claiming to spending 10BTC we\n> can omit\n> > checking the input 0.25% of the time without allowing more monetary\n> inflation\n> > than the block reward already does. Secondly, this means that after n\n> > transactions, the probability that proof shortening will _not_ happen is\n> p^n,\n> > which reaches 1% after 1840 transactions.\n> >\n> > In a system like Bitcoin where miners are expected to validate, a\n> transaction\n> > proof could consist of just a single merkle path showing that a\n> single-use seal\n> > was closed in some kind of TXO commitment - probably under 10KB of data.\n> That\n> > gives us a history proof less than 18.4MB in size, 99% of the time, and\n> less\n> > than 9.2MB in size 90% of the time.\n> >\n> > An interesting outcome of thing kind of design is that we can\n> institutionalize\n> > inflation fraud: the entire block reward can be replaced by miners\n> rolling the\n> > dice, attempting to create valid \"fake\" transactions. However, such a\n> pure\n> > implementation would put a floor on the lowest transaction fee possible,\n> so\n> > better to allow both transaction fee and subsidy collection at the same\n> time.\n> >\n> >\n> > # References\n> >\n> > [^paypub] https://github.com/unsystem/paypub\n> > [^timelock] https://github.com/petertodd/timelock\n> > [^zkcp]\n> https://bitcoincore.org/en/2016/02/26/zero-knowledge-contingent-payments-announcement/\n> > [^rpow] https://cryptome.org/rpow.htm\n> >\n> >\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160620/f6abdd58/attachment-0001.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-21T22:42:25",
                "message_text_only": "On Mon, Jun 20, 2016 at 04:21:39PM +0000, zaki--- via bitcoin-dev wrote:\n> Hi Peter,\n> \n> I didn't entirely understand the process of transaction linearization.\n> \n> What I see is a potential process where when the miner assembles the block,\n> he strips all but one sigscript per tx. The selection of which  sigscript\n> is retained is determined by the random oracle.  Is this is primary benefit\n> you are suggesting?\n> \n> It appears to me that blocks still need to contain a list of full TX Input\n> and Tx Outputs with your approach. Some of the description seems to\n> indicate that there are opportunities to elide further data but it's\n> unclear to me how.\n\nI think you've misunderstood what I'm proposing. The state machine approach I\ndescribed doesn't necessarily require blocks or even miners to exist at all.\nRather, it assumes that a single-use seal primitive is available, and a random\nbeacon primitive for tx linearization, and then builds a system on top of those\nprimitives. Transaction data - the proofs that certain states have been reached\nin the system - does not need to be broadcast publicly; if Alice wants to\nconvince Bob that she has given him money, the only person who needs that\ntransaction (and transactions prior to it in the tx history) is Bob.\n\nSo as to your question about miners assembling blocks, and what blocks contain:\nthere doesn't need to be blocks at all! Transaction history linearization is\nsomething your wallet would do for you.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/6a758129/attachment.sig>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-23T11:21:16",
                "message_text_only": "On Mon, Jun 20, 2016 at 01:26:22PM +0000, Police Terror via bitcoin-dev wrote:\n> Bitcoin could embed a lisp interpreter such as Scheme, reverse engineer\n> the current protocol into lisp (inside C++), run this alternative engine\n> alongside the current one as an option for some years (only for fine\n> tuning) then eventually fade this lisp written validation code instead\n> of the current one.\n\nYou know, I'm kinda regretting not making it sufficiently clear that Dex isn't\nLisp... It may look like it with all the braces, but expressions in it are\nevaluated without any global state (they can be evaluated in parallel) and I've\ngot a lot of work ahead of me in type safety.\n\n> Scheme is small and minimal, and embeds easily in C++. This could be a\n> better option than the libconsensus library - validation in a functional\n> scripting language.\n\nI'd be surprised if you could find a scheme interpreter that's sufficiently\nwell defined to be suitable for that; starting with an existing one and\nwhipping it into shape would very likely be more work than starting from\nscratch.\n \n> That doesn't mean people can't program the validation code in other\n> languages (maybe they'd want to optimize), but this code would be the\n> standard.\n\nYeah, in general I'd expect most of these systems to be layered to a degree;\nafter all even in something like MAST you need tooling to manage the fact that\nthe opcodes that end up public, on-chain, are only a subset of the script.\n\n> I wouldn't be so quick to deride good engineering over systematic\n> provable systems for all domains. Bitcoin being written in C++ is not a\n> defect. It's actually a strong language for what it does. Especially\n> when used correctly (which is not often and takes years to master).\n\nIt's probably the best of a lot of bad alternatives... We use C++ not because\nit's good, but because there's no other option.\n\nIn particular, we have enormous cost and risk in moving to other things due to\nconsensus, so making use of other languages is very difficult; my work with\ndex/proofchains does not have that constraint.\n\n> With the seals idea- am I understand this correctly?: Every transaction\n> has a number (essentially the index starting from 0 upwards) depending\n> on where it is in the blockchain.\n> \n> Then there is an array (probably an on disk array mapping transaction\n> indexes to hashes). Each hash entry in the array must be unique (the\n> hashes) otherwise the transaction will be denied. This is a great idea\n> to solve transaction hash collisions and simple to implement.\n\nNo, I think you've very much misunderstood things. The abstract notion of a\nsingle-use seal doesn't even need global consensus on anything to implement; it\ndoes not require transactions to have \"indexes\"\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/afb2886e/attachment.sig>"
            },
            {
                "author": "Alex Mizrahi",
                "date": "2016-06-20T22:28:48",
                "message_text_only": "> All practical single-use seals will be associated with some kind of\n> condition,\n> such as a pubkey, or deterministic expression, that needs to be satisfied\n> for\n> the seal to be closed.\n\n\nI think it would be useful to classify systems w.r.t. what data is\navailable to condition.\nI imagine it might be useful if status of other seals is available.\n\n\n> Secondly, the contents of the proof will be able to\n> commit to new data, such as the transaction spending the output associated\n> with\n> the seal.\n>\n\nSo basically a \"condition\" returns that \"new data\", right?\nIf it commits to a data in a recognizable way, then it's practically a\nfunction which yields a tuple (valid, new_data).\nIf an oracle doesn't care about data then you can convert it to a predicate\nusing a simple projection.\nBut from point of view of a client, it is a function which returns a tuple.\n\nIt might help if you describe a type of the condition function.\n\nSome related work on UTXO-based smart contracts:\n\n1. Typecoin described in the paper\n\"Peer-to-peer Affine Commitment using Bitcoin\" Karl Crary and Michael J.\nSullivan Carnegie Mellon University PLDI \u201915, Portland June 17, 2015\n\nI don't see the paper in open access and I've lost my copy, but there are\nslides: https://www.msully.net/stuff/typecoin-slides.pdf\n\nThe paper is written by programming language researchers, and thus use\nfairly complex constructs.\nThe idea is to use the language of linear logic, but it's actually\nimplemented using type-oriented programming.\nSo, basically, they associate logical propositions with transaction\noutputs. Transactions proof that output-propositions logically follow from\ninput-propositions.\nThe paper first describes as a colored coin kind of a system, where color\nvalues are propositions/types.\nBut in the implementation part it became more like a metacoin, as it uses a\ncomplete transaction history.\nA setup with a trusted server is also mentioned.\n\nThe interesting thing about Typecoin is that a contract language is based\non logic, which makes it powerful and -- I guess -- analyzable. However,\nthe paper doesn't mention any performance details, and I guess it's not\ngood.\nAnother problem is that it looks very unusual to people who aren't used to\ntype-oriented programming.\n\n2. Generic coins\nSeeing how much Typecoin people had to struggle to describe a Bitcoin-style\nsystem I decided to describe a generalized Bitcoin-style system, so it can\nbe easily referenced in research. Sadly all I got so far is a draft of an\nintroduction/definition sections:\nhttps://github.com/chromaway/ngcccbase/wiki/gc\n\nIn the first section I described a transaction graph model which is\nsupposed to be general enough to describe any kind of a transaction graph\nsystem with explicit dependencies and no \"spooky action at distance\". As it\nturns out, any such system can be defined in terms of few predicate\nfunctions, however, using these functions directly might be very\ninefficient.\n\nThe next section introduces a coin-based model. A coin-based system can be\ndescribed using a single function called coin kernel which is applied to a\ntransaction and a list of input coinstates.\nIt is then described how to go from a coin-based model to a\ntransaction-graph model.\nThe reverse should also be possible if we add additional restrictions on a\ntransaction-graph model, it's probably enough to define that coin can be\nspent only once. (Partial coin spends were described in Freimarkets.)\n\nThere is a fairly shitty prototype in Haskell:\nhttps://github.com/baldmaster/ColorCoin\n\n3. flexichains\nThis is a prototype done by me more recently, the interesting thing about\nit is that it unifies account-based and UTXO-based models in a single model.\n\nWe first introduce a notion of record. A record can be of an arbitrary\ntype, the only restriction is that it must have a key which must be unique\nwithin a system.\nThen transaction model can be introduced using two function:\n  txDependencies returns a list of keys of records transaction depends on\n  applyTx takes a transaction and a list of records it depends on and\nreturns either a list of records or an error.\n\nA list of records includes\n * new records which are created by a transaction\n * updated records will have the same key but different content\n\nA simple account-based system can be implement using tuples (pubkey,\nbalance, last_update) as records.\nIn an UTXO-based system records are transaction output, and they should\ninclude a spent flag. (Obviously, records with spent flag can be pruned.)\nA system with custom smart contracts can be implemented by adding some sort\nof a function or bytecode to records.\n\nA Haskell prototype is here:\nhttps://bitbucket.org/chromawallet/flexichains/src/21059080bed6?at=develop\n(It's kinda broken and incomplete, though.)\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/a4d13078/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-23T11:11:52",
                "message_text_only": "On Tue, Jun 21, 2016 at 01:28:48AM +0300, Alex Mizrahi wrote:\n> > All practical single-use seals will be associated with some kind of\n> > condition,\n> > such as a pubkey, or deterministic expression, that needs to be satisfied\n> > for\n> > the seal to be closed.\n> \n> \n> I think it would be useful to classify systems w.r.t. what data is\n> available to condition.\n> I imagine it might be useful if status of other seals is available.\n\nUseful yes, but actually implementing that often results in systems that are\ntoo tightly coupled to scale well.\n\n> > Secondly, the contents of the proof will be able to\n> > commit to new data, such as the transaction spending the output associated\n> > with\n> > the seal.\n> >\n> \n> So basically a \"condition\" returns that \"new data\", right?\n> If it commits to a data in a recognizable way, then it's practically a\n> function which yields a tuple (valid, new_data).\n> If an oracle doesn't care about data then you can convert it to a predicate\n> using a simple projection.\n> But from point of view of a client, it is a function which returns a tuple.\n\nWhat do you mean by \"new data\"?\n\nThe point I'm making is simply that to be useful, when you close a seal you\nhave to be able to close it over some data, in particular, another seal. That's\nthe key thing that makes the idea a useful construct for smart contacts, value\ntransfer/currency systems, etc.\n\n> It might help if you describe a type of the condition function.\n\nI did describe some seal authorization condition functions in my more recent\npost; the key thing is you'd have some kind of \"checksig\" operator that checks\na cryptographic signature.\n\n> Some related work on UTXO-based smart contracts:\n\n<snip>\n\nThanks for the links! Not at all surprising to me that there's a whole bunch of\nprojects working along those same lines; it's the obvious way to build this\nkind of stuff once you realise that the imperative, stateful, model isn't\nviable.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/17812b8c/attachment-0001.sig>"
            },
            {
                "author": "Alex Mizrahi",
                "date": "2016-06-23T12:58:29",
                "message_text_only": ">\n> The point I'm making is simply that to be useful, when you close a seal you\n> have to be able to close it over some data, in particular, another seal.\n> That's\n> the key thing that makes the idea a useful construct for smart contacts,\n> value\n> transfer/currency systems, etc.\n>\n\nOK, your second post (\"Closed Seal Sets and Truth Lists for Better Privacy\nand Censorship Resistance\") seems to clarify that this data is one of\narguments to the condition function.\nFrankly this stuff is rather hard to follow. (Or maybe I'm dumb.)\n\nNow I don't get scability properties. Let's consider a simplest scenario\nwhere Alice creates some token, sends it to Bob, who sends it to Claire. So\nnow Claire needs to get both a proof that Alice sent it to Bob and that Bob\nsent it to Claire, right? So Claire needs to verify 2 proofs, and for a\nchain of N transfers one would need to verify N proofs, right?\n\nAnd how it works in general:\n\n1. Alice creates a token. To do that she constructs an unique expression\nwhich checks her signature and signs a message \"This token has such and\nsuch meaning and its ownership originally associated with seal <hash of the\nexpression>\" with her PGP key.\n2. To transfer this token to Bob, she asks Bob for his auth expression and\nsends a seal oracle a message (Alice_expression (Bob_expression .\nsignature)) where signatures is constructed in such a way that it evaluates\nas true. Oracle stores this in a map: Alice_expression -> (Bob_expression .\nsignatures)\n3. Bob sends token to Claire in a same way: (Bob_expression\n(Claire_expression . signature))\n4. Now Claire asks if Alice_expression->(Bob_expression . _) and\nBob_expression->(Claire_expression . _) are in oracle's map. She might\ntrust the oracle to verify signatures, but oracle doesn't understand token\nsemantics. Thus she needs to check if these entries were added.\nIf I understand correctly, Alice_expression->(Bob_expression . _) record\ncan be communicated in just 3 * size_of_hash_digest bytes.\n\nSo this seems to have rather bad scalability even with trusted oracles, am\nI missing something?\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/2ebbc3c3/attachment-0001.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-24T22:23:16",
                "message_text_only": "On Thu, Jun 23, 2016 at 03:58:29PM +0300, Alex Mizrahi wrote:\n> >\n> > The point I'm making is simply that to be useful, when you close a seal you\n> > have to be able to close it over some data, in particular, another seal.\n> > That's\n> > the key thing that makes the idea a useful construct for smart contacts,\n> > value\n> > transfer/currency systems, etc.\n> >\n> \n> OK, your second post (\"Closed Seal Sets and Truth Lists for Better Privacy\n> and Censorship Resistance\") seems to clarify that this data is one of\n> arguments to the condition function.\n> Frankly this stuff is rather hard to follow. (Or maybe I'm dumb.)\n> \n> Now I don't get scability properties. Let's consider a simplest scenario\n> where Alice creates some token, sends it to Bob, who sends it to Claire. So\n> now Claire needs to get both a proof that Alice sent it to Bob and that Bob\n> sent it to Claire, right? So Claire needs to verify 2 proofs, and for a\n> chain of N transfers one would need to verify N proofs, right?\n\nNot necessarily. In my writeup I outlined two ways that those chains can be\nshortened: trusted validity oracles and the probabalistic, inflationary,\nhistory proof concept.\n\nEqually, even if history grows over time, that's no worse than Bitcoin.\n\n> And how it works in general:\n> \n> 1. Alice creates a token. To do that she constructs an unique expression\n> which checks her signature and signs a message \"This token has such and\n> such meaning and its ownership originally associated with seal <hash of the\n> expression>\" with her PGP key.\n\nAlice isn't _creating_ a tokne, she's _defining_ a token.\n\n> 2. To transfer this token to Bob, she asks Bob for his auth expression and\n> sends a seal oracle a message (Alice_expression (Bob_expression .\n> signature)) where signatures is constructed in such a way that it evaluates\n> as true. Oracle stores this in a map: Alice_expression -> (Bob_expression .\n> signatures)\n\nNope.\n\nIn Alice's token definition, the genesis state of the token is defined to be\nassociated with a specific single-use seal. To transfer the token to Bob, she\nasks Bob for the seal he wishes to use, and then closes the genesis seal over a\nnew state committing to Bob's seal.\n\nNow Alice could construct the seal for Bob, in which case she'd just need to\nknow the auth expression Bob wants to use, but that's not the most fundamental\nway of implementing this.\n\nRegardless, the seal oracle doesn't need to know that any of the above is\nhappening; all it needs to do is spit out seal closed witnesses when the\nauthorization expressions are satisfied appropriately; the oracle does not and\nshould not know what the seals have been closed over. Whether or not the oracle\nstores anything when seals are closed is an implementation decision - see my\noriginal writeup on the unbounded vs. bounded oracle case. And of course, seals\nimplemented with decentralized blockchains are a different matter entirely.\n\n> 3. Bob sends token to Claire in a same way: (Bob_expression\n> (Claire_expression . signature))\n> 4. Now Claire asks if Alice_expression->(Bob_expression . _) and\n> Bob_expression->(Claire_expression . _) are in oracle's map. She might\n> trust the oracle to verify signatures, but oracle doesn't understand token\n> semantics. Thus she needs to check if these entries were added.\n> If I understand correctly, Alice_expression->(Bob_expression . _) record\n> can be communicated in just 3 * size_of_hash_digest bytes.\n> \n> So this seems to have rather bad scalability even with trusted oracles, am\n> I missing something?\n\nYes, as I mentioned above, there exists multiple techniques that can shorten\nhistory proofs in a variety of ways, depending on what kinds of tradeoffs your\napplication needs.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160624/f1a28cc1/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Building Blocks of the State Machine Approach to Consensus",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "zaki at manian.org",
                "Police Terror",
                "Alex Mizrahi",
                "Peter Todd"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 104202
        }
    },
    {
        "title": "[bitcoin-dev] Even more proposed BIP extensions to BIP 0070",
        "thread_messages": [
            {
                "author": "Erik Aronesty",
                "date": "2016-06-20T17:33:32",
                "message_text_only": "BIP 0070 has been a a moderate success, however, IMO:\n\n- protocol buffers are inappropriate since ease of use and extensibility is\ndesired over the minor gains of efficiency in this protocol.  Not too late\nto support JSON messages as the standard going forward\n\n- problematic reliance on merchant-supplied https (X509) as the sole form\nof mechant identification.   alternate schemes (dnssec/netki), pgp and\npossibly keybase seem like good ideas.   personally, i like keybase, since\nthere is no reliance on the existing domain-name system (you can sell with\na github id, for example)\n\n- missing an optional client supplied identification\n\n- lack of basic subscription support\n\n*Proposed for subscriptions:*\n\n- BIP0047 payment codes are recommended instead of wallet addresses when\nestablishing subscriptions.  Or, merchants can specify replacement\naddresses in ACK/NACK responses.   UI confirms are *required *when there\nare no replacement addresses or payment codes used.\n\n- Wallets must confirm and store subscriptions, and are responsible for\ninitiating them at the specified interval.\n\n- Intervals can *only *be from a preset list: weekly, biweekly, or 1,\n2,3,4,6 or 12 months.   Intervals missed by more than 3 days cause\nsuspension until the user re-verifies.\n\n- Wallets *may *optionally ask the user whether they want to be notified\nand confirm every interval - or not.   Wallets that do not ask *must *notify\nbefore initiating each payment.   Interval confirmations should begin at *least\n*1 day in advance of the next payment.\n\n\n*Proposed in general:*\n- JSON should be used instead of protocol buffers going forward.  Easier to\nuse, explain extend.\n\n- \"Extendible\" URI-like scheme to support multi-mode identity mechanisms on\nboth payment and subscription requests.   Support for keybase://, netki://\nand others as alternates to https://.\n\n- Support for client as well as merchant multi-mode verification\n\n- Ideally, the identity verification URI scheme is somewhat\northogonal/independent of the payment request itself\n\nQuestion:\n\nShould this be a new BIP?  I know netki's BIP75 is out there - but I think\nit's too specific and too reliant on the domain name system.\n\nMaybe an identity-protocol-agnostic BIP + solid implementation of a couple\nmajor protocols without any mention of payment URI's ... just a way of\nsending and receiving identity verified messages in general?\n\nI would be happy to implement plugins for identity protocols, if anyone\nthinks this is a good idea.\n\nDoes anyone think https:// or keybase, or PGP or netki all by themselves,\nis enough - or is it always better to have an extensible protocol?\n\n- Erik Aronesty\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160620/947bebda/attachment.html>"
            },
            {
                "author": "Andreas Schildbach",
                "date": "2016-06-21T09:43:15",
                "message_text_only": "Protobuf vs. JSON was a deliberate decision. Afaik Protobuf was chosen\nbecause of its strong types, less vulnerability to malleability and very\ngood platform support. Having coded both, I can say Protobuf is not more\ndifficult than JSON. (Actually the entire Bitcoin P2P protocol should be\nbased on Protobuf, but that's another story.)\n\nYes, all extensions to BIP70 should go into new BIPs. Note the plural\nhere: if you have orthogonal ideas I strongly suggest one BIP per idea\nso they can be discussed and implemented (or rejected) separately.\n\n\nOn 06/20/2016 07:33 PM, Erik Aronesty via bitcoin-dev wrote:\n> BIP 0070 has been a a moderate success, however, IMO:\n> \n> - protocol buffers are inappropriate since ease of use and extensibility\n> is desired over the minor gains of efficiency in this protocol.  Not too\n> late to support JSON messages as the standard going forward\n> \n> - problematic reliance on merchant-supplied https (X509) as the sole\n> form of mechant identification.   alternate schemes (dnssec/netki), pgp\n> and possibly keybase seem like good ideas.   personally, i like keybase,\n> since there is no reliance on the existing domain-name system (you can\n> sell with a github id, for example)\n> \n> - missing an optional client supplied identification\n> \n> - lack of basic subscription support\n> \n> /Proposed for subscriptions:/\n> \n> - BIP0047 payment codes are recommended instead of wallet addresses when\n> establishing subscriptions.  Or, merchants can specify replacement\n> addresses in ACK/NACK responses.   UI confirms are /required /when there\n> are no replacement addresses or payment codes used.\n> \n> - Wallets must confirm and store subscriptions, and are responsible for\n> initiating them at the specified interval.  \n> \n> - Intervals can /only /be from a preset list: weekly, biweekly, or 1,\n> 2,3,4,6 or 12 months.   Intervals missed by more than 3 days cause\n> suspension until the user re-verifies.\n> \n> - Wallets /may /optionally ask the user whether they want to be notified\n> and confirm every interval - or not.   Wallets that do not ask /must\n> /notify before initiating each payment.   Interval confirmations should\n> begin at /least /1 day in advance of the next payment.\n> \n> /Proposed in general:\n> /\n> - JSON should be used instead of protocol buffers going forward.  Easier\n> to use, explain extend.\n> \n> - \"Extendible\" URI-like scheme to support multi-mode identity mechanisms\n> on both payment and subscription requests.   Support for keybase://,\n> netki:// and others as alternates to https://. \n> \n> - Support for client as well as merchant multi-mode verification\n> \n> - Ideally, the identity verification URI scheme is somewhat\n> orthogonal/independent of the payment request itself\n> \n> Question:\n> \n> Should this be a new BIP?  I know netki's BIP75 is out there - but I\n> think it's too specific and too reliant on the domain name system.\n> \n> Maybe an identity-protocol-agnostic BIP + solid implementation of a\n> couple major protocols without any mention of payment URI's ... just a\n> way of sending and receiving identity verified messages in general?\n> \n> I would be happy to implement plugins for identity protocols, if anyone\n> thinks this is a good idea.\n> \n> Does anyone think https:// or keybase, or PGP or netki all by\n> themselves, is enough - or is it always better to have an extensible\n> protocol?\n> \n> - Erik Aronesty\n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2016-06-21T17:09:41",
                "message_text_only": "On Tue, Jun 21, 2016 at 5:43 AM, Andreas Schildbach via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Protobuf vs. JSON was a deliberate decision. Afaik Protobuf was chosen\n> because of its strong types, less vulnerability to malleability and very\n> good platform support. Having coded both, I can say Protobuf is not more\n> difficult than JSON. (Actually the entire Bitcoin P2P protocol should be\n> based on Protobuf, but that's another story.)\n>\n\nI like protobuf, personally, for C++ stuff.  I just imagined it would be\nharder on mobile, or in some languages, to implement.   I'll focus on the\nscheduling issue.  Really, that's the only thing I want hashed out.\n\n\n>\n> Yes, all extensions to BIP70 should go into new BIPs. Note the plural\n> here: if you have orthogonal ideas I strongly suggest one BIP per idea\n> so they can be discussed and implemented (or rejected) separately.\n>\n>\nI think the intervals should *not* be flexible, even at the protocol level,\nto prevent attacks designed to confuse users  - plus for shorter intervals,\nyou need payment channels anyway.  Also, I think the spec should be rigid\nwith respect to response times, retry periods, etc.... to encourage\nconsistency among wallet vendors.   Not sure how anyone else feels about\nthat.  I suspect the netki guys should have opinions, since they are\nworking on similar UI-stuff.\n\nShould UI standards go somewhere else - not in a BIP?  I do think there\nneed to be UI standards.  Something with RFC-style should/must/will/wont\nlanguage, like \"Wallet software *must* show unconfirmed transactions as\ndistinct from confirmed\", and \"Wallet software *should *show some visual\nindication of other levels of confirmation\" ....  stuff like that.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/3d77b01a/attachment.html>"
            },
            {
                "author": "Andy Schroder",
                "date": "2016-06-21T19:50:59",
                "message_text_only": "Bluetooth exchange of payment requests already has a noticeable lag with \nprotocol buffers, so that would be another reason to argue against JSON, \nbecause JSON is less efficient size wise, correct? I will say that \nalthough protocol buffers have good platform support, I don't know that \nthe documentation for each platform is very good. This is the main \ndrawback I see with them. One additional advantage of protocol buffers \nis that the .proto file is a specification, whereas with JSON, you'd \njust have an example file, right?\n\nIsn't keybase a centralized infrastructure? Are you against a blockchain \nbased identification? There are a few out there. There is some confusion \nbecause onename's efforts are breaking away from namecoin though.\n\nI like the idea of PGP signatures of payment requests. This allows for \nmanual verification (in my mind, the highest quality) of key \nauthenticity (or, with PGP you also have the option to opt into some \ncentralized service for key verification). This can be useful when \ndealing with semi-manually issued invoices for goods and services. The \nlocal bitcoin wallet could just interact with the local PGP keyring. \nAlthough, one can already just send the payment request in a PGP signed \ne-mail, so I'm not sure if PGP signing is really needed if you're using \nPGP email. The main benefit may just be consolidating/itemizing into \nyour bitcoin wallet's transaction history whether the payment \ndestination/request was securely received or not. It may also be useful \nfor someone to be able to extract a signed payment request from a signed \nPGP e-mail and send it to someone else to make a payment for you (maybe \nyou don't want your accounting person to need your entire e-mail \ncorrespondence with a supplier to be able to just verify the payment \nrequest and make a payment for your company).\n\nI'm concerned about extending the URI scheme too much. Isn't this going \nto reach the practical size limit of NFC and QR codes pretty quickly?\n\n\n\n\nAndy Schroder\n\nOn 06/21/2016 05:43 AM, Andreas Schildbach via bitcoin-dev wrote:\n> Protobuf vs. JSON was a deliberate decision. Afaik Protobuf was chosen\n> because of its strong types, less vulnerability to malleability and very\n> good platform support. Having coded both, I can say Protobuf is not more\n> difficult than JSON. (Actually the entire Bitcoin P2P protocol should be\n> based on Protobuf, but that's another story.)\n>\n> Yes, all extensions to BIP70 should go into new BIPs. Note the plural\n> here: if you have orthogonal ideas I strongly suggest one BIP per idea\n> so they can be discussed and implemented (or rejected) separately.\n>\n>\n> On 06/20/2016 07:33 PM, Erik Aronesty via bitcoin-dev wrote:\n>> BIP 0070 has been a a moderate success, however, IMO:\n>>\n>> - protocol buffers are inappropriate since ease of use and extensibility\n>> is desired over the minor gains of efficiency in this protocol.  Not too\n>> late to support JSON messages as the standard going forward\n>>\n>> - problematic reliance on merchant-supplied https (X509) as the sole\n>> form of mechant identification.   alternate schemes (dnssec/netki), pgp\n>> and possibly keybase seem like good ideas.   personally, i like keybase,\n>> since there is no reliance on the existing domain-name system (you can\n>> sell with a github id, for example)\n>>\n>> - missing an optional client supplied identification\n>>\n>> - lack of basic subscription support\n>>\n>> /Proposed for subscriptions:/\n>>\n>> - BIP0047 payment codes are recommended instead of wallet addresses when\n>> establishing subscriptions.  Or, merchants can specify replacement\n>> addresses in ACK/NACK responses.   UI confirms are /required /when there\n>> are no replacement addresses or payment codes used.\n>>\n>> - Wallets must confirm and store subscriptions, and are responsible for\n>> initiating them at the specified interval.\n>>\n>> - Intervals can /only /be from a preset list: weekly, biweekly, or 1,\n>> 2,3,4,6 or 12 months.   Intervals missed by more than 3 days cause\n>> suspension until the user re-verifies.\n>>\n>> - Wallets /may /optionally ask the user whether they want to be notified\n>> and confirm every interval - or not.   Wallets that do not ask /must\n>> /notify before initiating each payment.   Interval confirmations should\n>> begin at /least /1 day in advance of the next payment.\n>>\n>> /Proposed in general:\n>> /\n>> - JSON should be used instead of protocol buffers going forward.  Easier\n>> to use, explain extend.\n>>\n>> - \"Extendible\" URI-like scheme to support multi-mode identity mechanisms\n>> on both payment and subscription requests.   Support for keybase://,\n>> netki:// and others as alternates to https://.\n>>\n>> - Support for client as well as merchant multi-mode verification\n>>\n>> - Ideally, the identity verification URI scheme is somewhat\n>> orthogonal/independent of the payment request itself\n>>\n>> Question:\n>>\n>> Should this be a new BIP?  I know netki's BIP75 is out there - but I\n>> think it's too specific and too reliant on the domain name system.\n>>\n>> Maybe an identity-protocol-agnostic BIP + solid implementation of a\n>> couple major protocols without any mention of payment URI's ... just a\n>> way of sending and receiving identity verified messages in general?\n>>\n>> I would be happy to implement plugins for identity protocols, if anyone\n>> thinks this is a good idea.\n>>\n>> Does anyone think https:// or keybase, or PGP or netki all by\n>> themselves, is enough - or is it always better to have an extensible\n>> protocol?\n>>\n>> - Erik Aronesty\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/6970aa58/attachment.sig>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-06-21T20:44:37",
                "message_text_only": "On Monday, June 20, 2016 5:33:32 PM Erik Aronesty via bitcoin-dev wrote:\n> BIP 0070 has been a a moderate success, however, IMO:\n> \n> - protocol buffers are inappropriate since ease of use and extensibility is\n> desired over the minor gains of efficiency in this protocol.  Not too late\n> to support JSON messages as the standard going forward\n\nIMO JSON is too prone to gratuitous inefficiency (both at network and CPU \nlevel), parser bugs, etc. Even the best C implementation (jansson) has serious \nissues with Number handling.\n\nA few years ago, I looked into binary alternatives to JSON and concluded they \nall had problems, while it seems more than reasonable to do even dynamic \nparsing of protobuf messages. So to conclude, I prefer to stick to protobuf \nunless a clearly superior protocol turns up.\n\n> - problematic reliance on merchant-supplied https (X509) as the sole form\n> of mechant identification.   alternate schemes (dnssec/netki), pgp and\n> possibly keybase seem like good ideas.   personally, i like keybase, since\n> there is no reliance on the existing domain-name system (you can sell with\n> a github id, for example)\n\nX509 is entrenched, so it should remain supported. PGP might make sense for \npeople already using it (it provides no real security for un-WoT-networked \nusers), but unforunately, few people use it. Correct me if I'm wrong, but IIRC \nKeybase uses blockchain spam, so definitely not something to be encouraged if \nso. Namecoin seems like a more than reasonable decentralised solution, but \nwill probably take some real work to implement (not that this is avoidable for \na general-usage decentralised solution).\n\n> - missing an optional client supplied identification\n\nWhat do you mean by this? There's the memo field at least.\n\n> - lack of basic subscription support\n> \n> *Proposed for subscriptions:*\n> \n> - BIP0047 payment codes are recommended instead of wallet addresses when\n> establishing subscriptions.  Or, merchants can specify replacement\n> addresses in ACK/NACK responses.   UI confirms are *required *when there\n> are no replacement addresses or payment codes used.\n\nI'd discourage anything using BIP 47 due to its serious design flaws.\nNo reason a regular BIP 32 pub seed can't be used instead.\n\nWhat do you mean by \"replacement addresses\" and \"UI confirms\" here?\n\n> - Wallets must confirm and store subscriptions, and are responsible for\n> initiating them at the specified interval.\n> \n> - Intervals can *only *be from a preset list: weekly, biweekly, or 1,\n> 2,3,4,6 or 12 months.   Intervals missed by more than 3 days cause\n> suspension until the user re-verifies.\n\nDisagree with hard-coding intervals, or mandating specific policies from the \nservice providers.\n\n> - Wallets *may *optionally ask the user whether they want to be notified\n> and confirm every interval - or not.   Wallets that do not ask *must\n> *notify before initiating each payment.   Interval confirmations should\n> begin at *least *1 day in advance of the next payment.\n\nThis is wallet policy, but maybe makes sense as a \"best practices\" BIP.\n\n> *Proposed in general:*\n> - JSON should be used instead of protocol buffers going forward.  Easier to\n> use, explain extend.\n> \n> - \"Extendible\" URI-like scheme to support multi-mode identity mechanisms on\n> both payment and subscription requests.   Support for keybase://, netki://\n> and others as alternates to https://.\n> \n> - Support for client as well as merchant multi-mode verification\n> \n> - Ideally, the identity verification URI scheme is somewhat\n> orthogonal/independent of the payment request itself\n> \n> Question:\n> \n> Should this be a new BIP?  I know netki's BIP75 is out there - but I think\n> it's too specific and too reliant on the domain name system.\n>\n> Maybe an identity-protocol-agnostic BIP + solid implementation of a couple\n> major protocols without any mention of payment URI's ... just a way of\n> sending and receiving identity verified messages in general?\n> \n> I would be happy to implement plugins for identity protocols, if anyone\n> thinks this is a good idea.\n> \n> Does anyone think https:// or keybase, or PGP or netki all by themselves,\n> is enough - or is it always better to have an extensible protocol?\n> \n> - Erik Aronesty"
            },
            {
                "author": "Erik Aronesty",
                "date": "2016-06-21T21:42:39",
                "message_text_only": "> keybase spam\n\ngood point about keybase spam, but i think it's limited to once hash per\nhour (?), not really too bad... the tx's are just root signatures, so you\ncan verify a whole keybase tree (up to the last hour) with very minimal\nbitcoin blockchain impact.\n\n> What do you mean by \"replacement addresses\" and \"UI confirms\" here?\n\n\"Replacement addresses\" would take the place of BIP 32/47 support, if\nsomeone thought maybe that was too difficult to deal with.   So each time i\npaid Alice, Alice could generate a new payment address for the next monthly\npayment.   If you support BIP 32 pub seed, then there's no need for this.\nI don't know any wallets that support a BIP 32 pub seed (and then what,\nsome random number generator?) as a destination address yet.\n\n> Disagree with hard-coding intervals, or mandating specific policies from\nthe\nservice providers.\n\nI think mandating is a harsh word here, but i I'm a strong believer in\nproviding strict guidelines that if people break, others can call them\non.   Giving someone a 12.3 +/- 5 day interval for payments using this\nprotocol would suck.   You should use payment channels for that stuff.\nThe idea is a lightweight protocol for getting monthly subscriptions\nworking.\n\n\n\n\nOn Tue, Jun 21, 2016 at 4:44 PM, Luke Dashjr <luke at dashjr.org> wrote:\n\n> On Monday, June 20, 2016 5:33:32 PM Erik Aronesty via bitcoin-dev wrote:\n> > BIP 0070 has been a a moderate success, however, IMO:\n> >\n> > - protocol buffers are inappropriate since ease of use and extensibility\n> is\n> > desired over the minor gains of efficiency in this protocol.  Not too\n> late\n> > to support JSON messages as the standard going forward\n>\n> IMO JSON is too prone to gratuitous inefficiency (both at network and CPU\n> level), parser bugs, etc. Even the best C implementation (jansson) has\n> serious\n> issues with Number handling.\n>\n> A few years ago, I looked into binary alternatives to JSON and concluded\n> they\n> all had problems, while it seems more than reasonable to do even dynamic\n> parsing of protobuf messages. So to conclude, I prefer to stick to protobuf\n> unless a clearly superior protocol turns up.\n>\n> > - problematic reliance on merchant-supplied https (X509) as the sole form\n> > of mechant identification.   alternate schemes (dnssec/netki), pgp and\n> > possibly keybase seem like good ideas.   personally, i like keybase,\n> since\n> > there is no reliance on the existing domain-name system (you can sell\n> with\n> > a github id, for example)\n>\n> X509 is entrenched, so it should remain supported. PGP might make sense for\n> people already using it (it provides no real security for un-WoT-networked\n> users), but unforunately, few people use it. Correct me if I'm wrong, but\n> IIRC\n> Keybase uses blockchain spam, so definitely not something to be encouraged\n> if\n> so. Namecoin seems like a more than reasonable decentralised solution, but\n> will probably take some real work to implement (not that this is avoidable\n> for\n> a general-usage decentralised solution).\n>\n> > - missing an optional client supplied identification\n>\n> What do you mean by this? There's the memo field at least.\n>\n> > - lack of basic subscription support\n> >\n> > *Proposed for subscriptions:*\n> >\n> > - BIP0047 payment codes are recommended instead of wallet addresses when\n> > establishing subscriptions.  Or, merchants can specify replacement\n> > addresses in ACK/NACK responses.   UI confirms are *required *when there\n> > are no replacement addresses or payment codes used.\n>\n> I'd discourage anything using BIP 47 due to its serious design flaws.\n> No reason a regular BIP 32 pub seed can't be used instead.\n>\n> What do you mean by \"replacement addresses\" and \"UI confirms\" here?\n>\n> > - Wallets must confirm and store subscriptions, and are responsible for\n> > initiating them at the specified interval.\n> >\n> > - Intervals can *only *be from a preset list: weekly, biweekly, or 1,\n> > 2,3,4,6 or 12 months.   Intervals missed by more than 3 days cause\n> > suspension until the user re-verifies.\n>\n> Disagree with hard-coding intervals, or mandating specific policies from\n> the\n> service providers.\n>\n> > - Wallets *may *optionally ask the user whether they want to be notified\n> > and confirm every interval - or not.   Wallets that do not ask *must\n> > *notify before initiating each payment.   Interval confirmations should\n> > begin at *least *1 day in advance of the next payment.\n>\n> This is wallet policy, but maybe makes sense as a \"best practices\" BIP.\n>\n> > *Proposed in general:*\n> > - JSON should be used instead of protocol buffers going forward.  Easier\n> to\n> > use, explain extend.\n> >\n> > - \"Extendible\" URI-like scheme to support multi-mode identity mechanisms\n> on\n> > both payment and subscription requests.   Support for keybase://,\n> netki://\n> > and others as alternates to https://.\n> >\n> > - Support for client as well as merchant multi-mode verification\n> >\n> > - Ideally, the identity verification URI scheme is somewhat\n> > orthogonal/independent of the payment request itself\n> >\n> > Question:\n> >\n> > Should this be a new BIP?  I know netki's BIP75 is out there - but I\n> think\n> > it's too specific and too reliant on the domain name system.\n> >\n> > Maybe an identity-protocol-agnostic BIP + solid implementation of a\n> couple\n> > major protocols without any mention of payment URI's ... just a way of\n> > sending and receiving identity verified messages in general?\n> >\n> > I would be happy to implement plugins for identity protocols, if anyone\n> > thinks this is a good idea.\n> >\n> > Does anyone think https:// or keybase, or PGP or netki all by\n> themselves,\n> > is enough - or is it always better to have an extensible protocol?\n> >\n> > - Erik Aronesty\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/9920f0c4/attachment.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-06-22T00:36:53",
                "message_text_only": "On Tuesday, June 21, 2016 9:42:39 PM Erik Aronesty wrote:\n> > What do you mean by \"replacement addresses\" and \"UI confirms\" here?\n> \n> \"Replacement addresses\" would take the place of BIP 32/47 support, if\n> someone thought maybe that was too difficult to deal with.   So each time i\n> paid Alice, Alice could generate a new payment address for the next monthly\n> payment.   If you support BIP 32 pub seed, then there's no need for this.\n\nI suppose it makes sense that since every payment requires communication with \nthe recipient, that the recipient could give you a new scriptPubKey each time. \nNo need to save [potentially compromised] payment info in advance?\n\n> I don't know any wallets that support a BIP 32 pub seed (and then what,\n> some random number generator?) as a destination address yet.\n\nThe point, as I see it, of payment protocol(s) is to deprecate addresses.\nie, this new protocol *could be* the BIP 32 pub seed destination address. ;)\n\n> > Disagree with hard-coding intervals, or mandating specific policies from\n> > the service providers.\n> \n> I think mandating is a harsh word here, but i I'm a strong believer in\n> providing strict guidelines that if people break, others can call them\n> on.   Giving someone a 12.3 +/- 5 day interval for payments using this\n> protocol would suck.   You should use payment channels for that stuff.\n> The idea is a lightweight protocol for getting monthly subscriptions\n> working.\n\nMaybe just a field specifying how far in advance payments should be sent, \nthen?\n\nLuke"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-21T22:10:08",
                "message_text_only": "On Tue, Jun 21, 2016 at 08:44:37PM +0000, Luke Dashjr via bitcoin-dev wrote:\n> On Monday, June 20, 2016 5:33:32 PM Erik Aronesty via bitcoin-dev wrote:\n> > BIP 0070 has been a a moderate success, however, IMO:\n> > \n> > - protocol buffers are inappropriate since ease of use and extensibility is\n> > desired over the minor gains of efficiency in this protocol.  Not too late\n> > to support JSON messages as the standard going forward\n> \n> IMO JSON is too prone to gratuitous inefficiency (both at network and CPU \n> level), parser bugs, etc. Even the best C implementation (jansson) has serious \n> issues with Number handling.\n> \n> A few years ago, I looked into binary alternatives to JSON and concluded they \n> all had problems, while it seems more than reasonable to do even dynamic \n> parsing of protobuf messages. So to conclude, I prefer to stick to protobuf \n> unless a clearly superior protocol turns up.\n\nI'll second that statement.\n\nEase of use isn't a very good criteria for security-critical software handling\nmoney, and the JSON standard has a very large amount of degrees of freedom in\nhow people have implemented it historically. Even protobuf I'd personally avoid\nusing on that basis, as protobuf encoding isn't deterministic: you can encode\nthe same data in multiple ways.\n\nUnfortunately there isn't a viable alternative, so we're probably stuck with\nprotobuf right now for standards that want to see wide adoption in the near\nfuture; I've got a few projects that need an alternative, which I'm working on,\nbut that's a ways off.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/ab86e67e/attachment.sig>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-21T22:19:40",
                "message_text_only": "On Tue, Jun 21, 2016 at 08:44:37PM +0000, Luke Dashjr via bitcoin-dev wrote:\n> X509 is entrenched, so it should remain supported. PGP might make sense for \n> people already using it (it provides no real security for un-WoT-networked \n> users), but unforunately, few people use it. Correct me if I'm wrong, but IIRC \n> Keybase uses blockchain spam, so definitely not something to be encouraged if \n\nHow else would you have keybase accomplish what they're accomplishing, with the\nsame security model?\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/ec2235c8/attachment-0001.sig>"
            },
            {
                "author": "James MacWhyte",
                "date": "2016-06-21T20:56:40",
                "message_text_only": "Thanks for starting this discussion, Erik.\n\n\n> Should this be a new BIP?  I know netki's BIP75 is out there - but I think\n> it's too specific and too reliant on the domain name system.\n>\n\nThis is not quite accurate. BIP75 is designed to be independent of any name\nresolution system. You could use it with a static URL that you share, for\nexample, or even use it to implement a mesh-network payment system over\nbluetooth. Netki's wallet names do use DNS, but that isn't related to this\ndiscussion.\n\nWhat BIP75 *does* do is provide a way for a client to get a new payment\naddress for every payment. I personally think it is better than BIP47 for\nthe uses you mentioned (subscriptions, etc).\n\nI'm glad you brought up identity methods other than x509. At breadwallet we\nare thinking about how to establish the most universal system, and letting\nusers identify themselves with any of a selection of identity systems is\nideal. I think the pki_data slot should be constantly expanded to allow new\nidentity types, but they should be explained/standardized in the BIPs that\nadd them and use universal names. \"netki://\" wouldn't be appropriate, for\nexample, if their method is open sourced and possibly used by others--it\nshould instead be given a product name like \"dnswallet://\" or something\nmore clever.\n\nJames\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/316a6995/attachment.html>"
            },
            {
                "author": "Matt David",
                "date": "2016-06-21T21:17:12",
                "message_text_only": "Hey all,\n\nInterestingly enough, the original BIP75 idea started by trying to move the Payment Protocol to use JSON, but because of all of the reasons mentioned by Andreas, we ended up with protobuf. There is quite a bit of language support on both desktop and mobile platforms so that's become mostly a non-issue.\n\nRegarding the lack of optional client-supplied identification, BIP75 was designed to solve this issue. It allows both parties in a transaction to share identity information in an out-of-band fashion in order to keep specific identity information off-chain.\n\nWith regards to extensibility of PKI usage, both BIP70 and BIP75 provide plenty of flexibility. Both the InvoiceRequest and PaymentRequest contain the pki_type and pki_data fields to allow for the use of non X.509 certificates. Currently, the only pki_types specified in both BIPs are none or x509_sha256, but there isn't any specific limit on what can be used as long as you can define a PKI type to be used, include a public key and a signature that proves control of the keypair. Perhaps a new BIP allowing for additional PKI types can be submitted, similar to how RFCs extend usage of ciphers for TLS (ie., RFC 5932).\n\nRegarding subscriptions, and as proposed in the address book example use case in BIP75, a wallet can be setup to automatically create BIP75 transactions in order to retrieve a wallet address to pay for a subscription on whatever frequency you would like to use. The service provider can approve the first BIP75 transaction and then store the public key for that client for future use. For subsequent subscription payments, the service provider may automatically return wallet addresses for each BIP75 transaction, understanding that the subsequent BIP75 transactions are linked to the public key that was used for the first transaction and therefore the subscription has been paid for. Additionally, the BIP75 InvoiceRequest message contains a memo field that can be used to include any additional subscription information required by the subscription provider (and can be different for both first and subsequent BIP75 transactions).\n\nThis is a very interesting idea and I'd love to see how the community can work together to make Bitcoin more user and mainstream friendly while increasing security for all parties involved. All movement toward this is really the goal at Netki.\n\nBest,\n\nMatt David\nSr. Software Engineer\nNetki, Inc.\n\nmatt at netki.com\n\n\n\n> On Jun 21, 2016, at 1:56 PM, James MacWhyte via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Thanks for starting this discussion, Erik.\n> \n> \n> Should this be a new BIP?  I know netki's BIP75 is out there - but I think it's too specific and too reliant on the domain name system.\n> \n> This is not quite accurate. BIP75 is designed to be independent of any name resolution system. You could use it with a static URL that you share, for example, or even use it to implement a mesh-network payment system over bluetooth. Netki's wallet names do use DNS, but that isn't related to this discussion.\n> \n> What BIP75 *does* do is provide a way for a client to get a new payment address for every payment. I personally think it is better than BIP47 for the uses you mentioned (subscriptions, etc).\n> \n> I'm glad you brought up identity methods other than x509. At breadwallet we are thinking about how to establish the most universal system, and letting users identify themselves with any of a selection of identity systems is ideal. I think the pki_data slot should be constantly expanded to allow new identity types, but they should be explained/standardized in the BIPs that add them and use universal names. \"netki://\" wouldn't be appropriate, for example, if their method is open sourced and possibly used by others--it should instead be given a product name like \"dnswallet://\" or something more clever.\n> \n> James\n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/ab05606d/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: PastedGraphic-2.tiff\nType: image/tiff\nSize: 10972 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/ab05606d/attachment-0001.tiff>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 801 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/ab05606d/attachment-0001.sig>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-21T22:13:47",
                "message_text_only": "On Mon, Jun 20, 2016 at 05:33:32PM +0000, Erik Aronesty via bitcoin-dev wrote:\n> BIP 0070 has been a a moderate success, however, IMO:\n> \n> - protocol buffers are inappropriate since ease of use and extensibility is\n> desired over the minor gains of efficiency in this protocol.  Not too late\n> to support JSON messages as the standard going forward\n> \n> - problematic reliance on merchant-supplied https (X509) as the sole form\n> of mechant identification.   alternate schemes (dnssec/netki), pgp and\n> possibly keybase seem like good ideas.   personally, i like keybase, since\n> there is no reliance on the existing domain-name system (you can sell with\n> a github id, for example)\n> \n> - missing an optional client supplied identification\n\nNote that \"client supplied identification\" is being pushed for AML/KYC\ncompliance, e.g. Netki's AML/KYC compliance product:\n\nhttp://www.coindesk.com/blockchain-identity-company-netki-launch-ssl-certificate-blockchain/\n\nThis is an extremely undesirable feature to be baking into standards given it's\nnegative impact on fungibility and privacy; we should not be adopting standards\nwith AML/KYC support, for much the same reasons that the W3C should not be\nstandardizing DRM.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/5e89e377/attachment.sig>"
            },
            {
                "author": "James MacWhyte",
                "date": "2016-06-21T22:50:36",
                "message_text_only": "> Note that \"client supplied identification\" is being pushed for AML/KYC\n> compliance, e.g. Netki's AML/KYC compliance product:\n>\n>\n> http://www.coindesk.com/blockchain-identity-company-netki-launch-ssl-certificate-blockchain/\n>\n> This is an extremely undesirable feature to be baking into standards given\n> it's\n> negative impact on fungibility and privacy; we should not be adopting\n> standards\n> with AML/KYC support, for much the same reasons that the W3C should not be\n> standardizing DRM.\n>\n>\nKYC isn't the only use case. There are other situations in which you would\nwant to confirm who is sending you money. Making it *required* would of\ncourse be a horrible idea, but allowing people to identify themselves, in\nmany cases with an online-only identity that isn't tied to their real world\nidentity, will be very useful to newly-developing use cases.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/6984221f/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-21T23:02:33",
                "message_text_only": "On Tue, Jun 21, 2016 at 10:50:36PM +0000, James MacWhyte wrote:\n> > Note that \"client supplied identification\" is being pushed for AML/KYC\n> > compliance, e.g. Netki's AML/KYC compliance product:\n> >\n> >\n> > http://www.coindesk.com/blockchain-identity-company-netki-launch-ssl-certificate-blockchain/\n> >\n> > This is an extremely undesirable feature to be baking into standards given\n> > it's\n> > negative impact on fungibility and privacy; we should not be adopting\n> > standards\n> > with AML/KYC support, for much the same reasons that the W3C should not be\n> > standardizing DRM.\n> >\n> >\n> KYC isn't the only use case. There are other situations in which you would\n> want to confirm who is sending you money. Making it *required* would of\n> course be a horrible idea, but allowing people to identify themselves, in\n> many cases with an online-only identity that isn't tied to their real world\n> identity, will be very useful to newly-developing use cases.\n\nIt's easy to confirm who is sending you money: give out different addresses to\ndifferent people, and keep those addresses private.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/0cbe3456/attachment.sig>"
            },
            {
                "author": "Justin Newton",
                "date": "2016-06-22T00:14:31",
                "message_text_only": "On Tue, Jun 21, 2016 at 3:13 PM, Peter Todd via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Mon, Jun 20, 2016 at 05:33:32PM +0000, Erik Aronesty via bitcoin-dev\n> wrote:\n>\n> > - missing an optional client supplied identification\n>\n> Note that \"client supplied identification\" is being pushed for AML/KYC\n> compliance, e.g. Netki's AML/KYC compliance product:\n>\n>\n> http://www.coindesk.com/blockchain-identity-company-netki-launch-ssl-certificate-blockchain/\n>\n> This is an extremely undesirable feature to be baking into standards given\n> it's\n> negative impact on fungibility and privacy; we should not be adopting\n> standards\n> with AML/KYC support, for much the same reasons that the W3C should not be\n> standardizing DRM.\n>\n\nHi Peter,\n   Certainly AML/KYC compliance is one of the use cases that BIP 75 and our\ncertificates can support.  As a quick summary,\n\nThere are individuals and entities that would like to buy, sell, and use\nbitcoin, and other public blockchains, but that have compliance\nrequirements that they need to meet before they can do so.  Similarly,\ncompanies and entrepreneurs in the space suffer under the potential threat\nof fines, or in extreme cases, jail time, also for not meeting AML or\nsanctions list compliance.  We wanted to build tools that allowed\nentrepreneurs to breathe easy, while at the same time allow more people and\ncompanies to enter the ecosystem.  We also believe that the solution we are\nusing has the characteristics that you want in such a solution, for example:\n\n1> Only the counterparties (and possibly their service providers in the\ncase of hosted services) in a transaction can see the identity data,\nprotecting user privacy.\n\n2> The counterparties themselves (and possibly their service providers in\nthe case of hosted services) decide whether identity information is\nrequired for any given transaction.\n\n3> No trace is left on the blockchain or anywhere else (other than with the\ncounterparties) that identity information was even exchanged, protecting\nfungibility\n\n4> The solution is based on open source and open standards, allowing open\npermissionless innovation, versus parties building closed networks based on\nclosed standards.  The very fact that this solution went through the BIP\nprocess and was adapted based on feedback is an example of how this is\nbetter for users than the inevitable closed solution that would arise if\nthe open source, community vetted version didn\u2019t already exist.\n\nI don\u2019t know if you are opposed to organizations that have AML requirements\nfrom using the bitcoin blockchain, but if you aren\u2019t, why wouldn\u2019t you\nprefer an open source, open standards based solution to exclusionary,\nproprietary ones?\n\nBIP 70 and BIP 75 are standards for voluntary information exchange between\ncounterparties in a transaction.  This is exactly the kind of thing we want\nstandards for, in my experience.\n\n\n-- \n\nJustin W. Newton\nFounder/CEO\nNetki, Inc.\n\njustin at netki.com\n+1.818.261.4248\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/e821a4e8/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: PastedGraphic-1.tiff\nType: image/tiff\nSize: 10972 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/e821a4e8/attachment-0001.tiff>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-23T10:56:32",
                "message_text_only": "On Tue, Jun 21, 2016 at 05:14:31PM -0700, Justin Newton wrote:\n> On Tue, Jun 21, 2016 at 3:13 PM, Peter Todd via bitcoin-dev <\n> Hi Peter,\n>    Certainly AML/KYC compliance is one of the use cases that BIP 75 and our\n> certificates can support.  As a quick summary,\n> \n> There are individuals and entities that would like to buy, sell, and use\n> bitcoin, and other public blockchains, but that have compliance\n> requirements that they need to meet before they can do so.  Similarly,\n> companies and entrepreneurs in the space suffer under the potential threat\n> of fines, or in extreme cases, jail time, also for not meeting AML or\n> sanctions list compliance.  We wanted to build tools that allowed\n> entrepreneurs to breathe easy, while at the same time allow more people and\n> companies to enter the ecosystem.  We also believe that the solution we are\n> using has the characteristics that you want in such a solution, for example:\n> \n> 1> Only the counterparties (and possibly their service providers in the\n> case of hosted services) in a transaction can see the identity data,\n> protecting user privacy.\n> \n> 2> The counterparties themselves (and possibly their service providers in\n> the case of hosted services) decide whether identity information is\n> required for any given transaction.\n> \n> 3> No trace is left on the blockchain or anywhere else (other than with the\n> counterparties) that identity information was even exchanged, protecting\n> fungibility\n> \n> 4> The solution is based on open source and open standards, allowing open\n> permissionless innovation, versus parties building closed networks based on\n> closed standards.  The very fact that this solution went through the BIP\n> process and was adapted based on feedback is an example of how this is\n> better for users than the inevitable closed solution that would arise if\n> the open source, community vetted version didn\u2019t already exist.\n> \n> I don\u2019t know if you are opposed to organizations that have AML requirements\n> from using the bitcoin blockchain, but if you aren\u2019t, why wouldn\u2019t you\n> prefer an open source, open standards based solution to exclusionary,\n> proprietary ones?\n\nIn some (most?) countries, it is illegal to offer telecoms services without\nwiretap facilities. Does that mean Tor builds into its software \"open source\"\n\"open standards\" wiretapping functionality? No. And interestingly, people\ntrying to add support for that stuff is actually a thing that keeps happening\nin the Tor community...\n\nIn any case, I'd strongly argue that we remove BIP75 from the bips repository,\nand boycott wallets that implement it. It's bad strategy for Bitcoin developers\nto willingly participate in AML/KYC, just the same way as it's bad for Tor to\nadd wiretapping functionality, and W3C to support DRM tech. The minor tactical\nwins you'll get our of this aren't worth it.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/594d6918/attachment.sig>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2016-06-23T11:30:45",
                "message_text_only": "On Jun 23, 2016 12:56, \"Peter Todd via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> In any case, I'd strongly argue that we remove BIP75 from the bips\nrepository,\n> and boycott wallets that implement it. It's bad strategy for Bitcoin\ndevelopers\n> to willingly participate in AML/KYC, just the same way as it's bad for\nTor to\n> add wiretapping functionality, and W3C to support DRM tech. The minor\ntactical\n> wins you'll get our of this aren't worth it.\n\nI hope you're not seriously suggesting to censor a BIP because you feel it\nis a bad idea.\n\n-- \nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/b6c34061/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-23T11:39:04",
                "message_text_only": "On Thu, Jun 23, 2016 at 01:30:45PM +0200, Pieter Wuille wrote:\n> On Jun 23, 2016 12:56, \"Peter Todd via bitcoin-dev\" <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> > In any case, I'd strongly argue that we remove BIP75 from the bips\n> repository,\n> > and boycott wallets that implement it. It's bad strategy for Bitcoin\n> developers\n> > to willingly participate in AML/KYC, just the same way as it's bad for\n> Tor to\n> > add wiretapping functionality, and W3C to support DRM tech. The minor\n> tactical\n> > wins you'll get our of this aren't worth it.\n> \n> I hope you're not seriously suggesting to censor a BIP because you feel it\n> is a bad idea.\n\nFor the record, I think the idea of the bips repo being a pure publication\nplatform isn't a good one and doesn't match reality; like it or not by\naccepting bips we're putting a stamp of some kind of approval on them.\n\nFor example, I suspect I wouldn't be able to get a BIP for a decentralized\nassassination market protocol standard into the repository, regardless of\nwhether or not it was used - it's simply too distastful and controversial for\nus to want to merge that. Would you call that rejection censorship?\n\nI have zero issues with us exercising editorial control over what's in the bips\nrepo; us doing so doesn't in any way prevent other's from publishing elsewhere.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/6fce728d/attachment.sig>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2016-06-23T12:01:10",
                "message_text_only": "On Thu, Jun 23, 2016 at 1:39 PM, Peter Todd <pete at petertodd.org> wrote:\n> On Thu, Jun 23, 2016 at 01:30:45PM +0200, Pieter Wuille wrote:\n>> On Jun 23, 2016 12:56, \"Peter Todd via bitcoin-dev\" <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> > In any case, I'd strongly argue that we remove BIP75 from the bips\n>> repository,\n>> > and boycott wallets that implement it. It's bad strategy for Bitcoin\n>> developers\n>> > to willingly participate in AML/KYC, just the same way as it's bad for\n>> Tor to\n>> > add wiretapping functionality, and W3C to support DRM tech. The minor\n>> tactical\n>> > wins you'll get our of this aren't worth it.\n>>\n>> I hope you're not seriously suggesting to censor a BIP because you feel it\n>> is a bad idea.\n>\n> For the record, I think the idea of the bips repo being a pure publication\n> platform isn't a good one and doesn't match reality; like it or not by\n> accepting bips we're putting a stamp of some kind of approval on them.\n\nWe? I don't feel like I have any authority to say what goes into that\nrepository, and neither do you. We just give technical opinion on\nproposals. The fact that it's under the bitcoin organization on github\nis a historical artifact.\n\n> I have zero issues with us exercising editorial control over what's in the bips\n> repo; us doing so doesn't in any way prevent other's from publishing elsewhere.\n\nEditorial control is inevitable to some extent, but I think that's\nmore a matter of process than of opinion. Things like \"Was there\ncommunity discussion?\", \"Is it relevant?\", \"Is there a reference\nimplementation?\". I don't think that you objecting for moral reasons\nto an otherwise technically sound idea is a reason for removal of a\nBIP. You are of course free to propose alternatives, or recommend\nagainst its usage.\n\n-- \nPieter"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-23T12:10:00",
                "message_text_only": "On Thu, Jun 23, 2016 at 02:01:10PM +0200, Pieter Wuille wrote:\n> On Thu, Jun 23, 2016 at 1:39 PM, Peter Todd <pete at petertodd.org> wrote:\n> > On Thu, Jun 23, 2016 at 01:30:45PM +0200, Pieter Wuille wrote:\n> > For the record, I think the idea of the bips repo being a pure publication\n> > platform isn't a good one and doesn't match reality; like it or not by\n> > accepting bips we're putting a stamp of some kind of approval on them.\n> \n> We? I don't feel like I have any authority to say what goes into that\n> repository, and neither do you. We just give technical opinion on\n> proposals. The fact that it's under the bitcoin organization on github\n> is a historical artifact.\n\nThat's simply not how the rest of the community perceives bips, and until we\nmove them elsewhere that's not going to change.\n\nNo matter how much we scream that we don't have authority, the fact of the\nmatter is the bips are located under the github.com/bitcoin namespace, and we\ndo have editorial control over them.\n\n> > I have zero issues with us exercising editorial control over what's in the bips\n> > repo; us doing so doesn't in any way prevent other's from publishing elsewhere.\n> \n> Editorial control is inevitable to some extent, but I think that's\n> more a matter of process than of opinion. Things like \"Was there\n> community discussion?\", \"Is it relevant?\", \"Is there a reference\n> implementation?\". I don't think that you objecting for moral reasons\n> to an otherwise technically sound idea is a reason for removal of a\n> BIP. You are of course free to propose alternatives, or recommend\n> against its usage.\n\nRight, so you accept that we'll exert some degree of editorial control; the\nquestion now is what editorial policies should we exert?\n\nMy argument is that rejecting BIP75 is something we should do on\nethical/strategic grounds. You may disagree with that, but please don't troll\nand call that \"advocating censorship\"\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/406e462b/attachment.sig>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2016-06-23T12:16:48",
                "message_text_only": "On Jun 23, 2016 14:10, \"Peter Todd\" <pete at petertodd.org> wrote:\n\n> Right, so you accept that we'll exert some degree of editorial control;\nthe\n> question now is what editorial policies should we exert?\n\nNo, I do not. I am saying that some degree of editorial control will\ninevitably exist, simply because there is some human making the choice of\nassigning a BIP number and merging. My opinion is that we should try to\nrestrict that editorial control to only be subject to objective process,\nand not be dependent on personal opinions.\n\n> My argument is that rejecting BIP75 is something we should do on\n> ethical/strategic grounds. You may disagree with that, but please don't\ntroll\n> and call that \"advocating censorship\"\n\nI think that you are free to express dislike of BIP75. Suggesting to remove\nit for that reason is utterly ridiculous to me, whatever you want to call\nit.\n\n-- \nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/ba7a229f/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-23T12:43:04",
                "message_text_only": "On Thu, Jun 23, 2016 at 02:16:48PM +0200, Pieter Wuille wrote:\n> On Jun 23, 2016 14:10, \"Peter Todd\" <pete at petertodd.org> wrote:\n> \n> > Right, so you accept that we'll exert some degree of editorial control;\n> the\n> > question now is what editorial policies should we exert?\n> \n> No, I do not. I am saying that some degree of editorial control will\n> inevitably exist, simply because there is some human making the choice of\n> assigning a BIP number and merging. My opinion is that we should try to\n> restrict that editorial control to only be subject to objective process,\n> and not be dependent on personal opinions.\n>\n> > My argument is that rejecting BIP75 is something we should do on\n> > ethical/strategic grounds. You may disagree with that, but please don't\n> troll\n> > and call that \"advocating censorship\"\n> \n> I think that you are free to express dislike of BIP75. Suggesting to remove\n> it for that reason is utterly ridiculous to me, whatever you want to call\n> it.\n\nIn the future we're likely to see a lot of BIPs around AML/KYC support, e.g.\nadding personal identity information to transactions, blacklist standards, etc.\nShould we accept those BIPs into the bips repo?\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/363edf91/attachment.sig>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2016-06-23T13:03:36",
                "message_text_only": "AML/KYC is a *side-effect *of a some very important features of BIP0075.\n\nFeatures that have nothing to do with public names for wallet seeds,\nand moniker *consistency *should be scrapped.\n\nBIP 75 formalises what someone could do today with a bunch of PGP emails\nback and forth.\n\nI create a public key, and I exchange it via QR code with you.   From then\non, You can initiate invoice requests with me, knowing my moniker is the\nsame as it was the last time.   I publish this key to a server (via DNSSEC)\nso anyone can obtain it.   Sounds exactly like PGP.\n\nIdentity in BIP 75 is merely \"moniker consistency\".  Nothing says that\nidentity has to be \"real\"... only publicly verifiably consistent and\naccessible.  This consistency and the ability to have public names for both\nmerchants and users are the important features of BIP 075.\n\nOther features linking monikers to real-world identity should be surgically\nremoved from the standard.\n\n- Users need to be able to send Bitcoin to an address without MITM attacks\nduring the address exchange.\n\n- Merchants need to be able to supply memorable names linked to internet\nservices, like web servers and email addresses.\n\n- Merchants and users both need to be able to initiate transaction\noff-chain, with a workflow that allows things like rejection, subscription,\netc.\n\n\n\nOn Thu, Jun 23, 2016 at 6:56 AM, Peter Todd <pete at petertodd.org> wrote:\n\n> On Tue, Jun 21, 2016 at 05:14:31PM -0700, Justin Newton wrote:\n> > On Tue, Jun 21, 2016 at 3:13 PM, Peter Todd via bitcoin-dev <\n> > Hi Peter,\n> >    Certainly AML/KYC compliance is one of the use cases that BIP 75 and\n> our\n> > certificates can support.  As a quick summary,\n> >\n> > There are individuals and entities that would like to buy, sell, and use\n> > bitcoin, and other public blockchains, but that have compliance\n> > requirements that they need to meet before they can do so.  Similarly,\n> > companies and entrepreneurs in the space suffer under the potential\n> threat\n> > of fines, or in extreme cases, jail time, also for not meeting AML or\n> > sanctions list compliance.  We wanted to build tools that allowed\n> > entrepreneurs to breathe easy, while at the same time allow more people\n> and\n> > companies to enter the ecosystem.  We also believe that the solution we\n> are\n> > using has the characteristics that you want in such a solution, for\n> example:\n> >\n> > 1> Only the counterparties (and possibly their service providers in the\n> > case of hosted services) in a transaction can see the identity data,\n> > protecting user privacy.\n> >\n> > 2> The counterparties themselves (and possibly their service providers in\n> > the case of hosted services) decide whether identity information is\n> > required for any given transaction.\n> >\n> > 3> No trace is left on the blockchain or anywhere else (other than with\n> the\n> > counterparties) that identity information was even exchanged, protecting\n> > fungibility\n> >\n> > 4> The solution is based on open source and open standards, allowing open\n> > permissionless innovation, versus parties building closed networks based\n> on\n> > closed standards.  The very fact that this solution went through the BIP\n> > process and was adapted based on feedback is an example of how this is\n> > better for users than the inevitable closed solution that would arise if\n> > the open source, community vetted version didn\u2019t already exist.\n> >\n> > I don\u2019t know if you are opposed to organizations that have AML\n> requirements\n> > from using the bitcoin blockchain, but if you aren\u2019t, why wouldn\u2019t you\n> > prefer an open source, open standards based solution to exclusionary,\n> > proprietary ones?\n>\n> In some (most?) countries, it is illegal to offer telecoms services without\n> wiretap facilities. Does that mean Tor builds into its software \"open\n> source\"\n> \"open standards\" wiretapping functionality? No. And interestingly, people\n> trying to add support for that stuff is actually a thing that keeps\n> happening\n> in the Tor community...\n>\n> In any case, I'd strongly argue that we remove BIP75 from the bips\n> repository,\n> and boycott wallets that implement it. It's bad strategy for Bitcoin\n> developers\n> to willingly participate in AML/KYC, just the same way as it's bad for Tor\n> to\n> add wiretapping functionality, and W3C to support DRM tech. The minor\n> tactical\n> wins you'll get our of this aren't worth it.\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/07cec89c/attachment.html>"
            },
            {
                "author": "Aaron Voisine",
                "date": "2016-06-23T16:58:58",
                "message_text_only": "On Thu, Jun 23, 2016 at 3:56 AM, Peter Todd via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> In any case, I'd strongly argue that we remove BIP75 from the bips\n> repository,\n> and boycott wallets that implement it. It's bad strategy for Bitcoin\n> developers\n> to willingly participate in AML/KYC, just the same way as it's bad for Tor\n> to\n> add wiretapping functionality, and W3C to support DRM tech. The minor\n> tactical\n> wins you'll get our of this aren't worth it.\n>\n>\nPeter, BIP75 gives the parties transacting complete control over who they\nchoose to share their identity information with. This was the entire point\nof the proposal. You authorize who you choose to give your payment address\nto, and the sender can verify who they are sending payment to. All\ncommunication and payment info are encrypted against third party snooping,\nwhile still allowing asynchronous communication to accommodate ephemeral\nmobile connections.\n\nThe fact that some people will choose to use this identity information for\nAML/KYC purposes doesn't detract at all from the fact that it gives bitcoin\nusers the tools they need to keep their payment information private, and\nonly communicate it with the parties they choose.\n\nAaron Voisine\nco-founder and CEO\nbreadwallet <http://breadwallet.com/>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/a4f599d1/attachment.html>"
            },
            {
                "author": "s7r",
                "date": "2016-06-23T20:46:46",
                "message_text_only": "On 6/23/2016 1:56 PM, Peter Todd via bitcoin-dev wrote:\n>>\n>> I don\u2019t know if you are opposed to organizations that have AML requirements\n>> from using the bitcoin blockchain, but if you aren\u2019t, why wouldn\u2019t you\n>> prefer an open source, open standards based solution to exclusionary,\n>> proprietary ones?\n> \n> In some (most?) countries, it is illegal to offer telecoms services without\n> wiretap facilities. Does that mean Tor builds into its software \"open source\"\n> \"open standards\" wiretapping functionality? No. And interestingly, people\n> trying to add support for that stuff is actually a thing that keeps happening\n> in the Tor community...\n> \n> In any case, I'd strongly argue that we remove BIP75 from the bips repository,\n> and boycott wallets that implement it. It's bad strategy for Bitcoin developers\n> to willingly participate in AML/KYC, just the same way as it's bad for Tor to\n> add wiretapping functionality, and W3C to support DRM tech. The minor tactical\n> wins you'll get our of this aren't worth it.\n> \nExactly!\nTotally agree with Peter Todd. There's absolutely no gain for Bitcoin to\nwillingly participate in AML/KYC. Plus this might come with strings\nattached: for example when running a Tor relay in some countries if you\ninterfere with the traffic (censor, limit, filter, etc.) you become\nresponsible for it, while when you only relay anonymous traffic without\ninterfering or having the possibility to do so (installing certain\ntools, using a modified Tor which allows you to do so, etc.) you cannot\nbe held responsible for the traffic.\n\nAny kind of built-in AML/KYC tools in Bitcoin is bad, and might draw\nexpectations from _all_ users from authorities. Companies or individuals\nwho want and/or need AML/KYC can find ways and do it at their side\nisolated from the entire network, and the solutions shouldn't come from\nupstream. AML/KYC/<insert other regulation here> differ from country to\ncountry and will be hard to implement in a global consensus network even\nif it would be worth it.\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 488 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/3541af5b/attachment.sig>"
            },
            {
                "author": "Justin Newton",
                "date": "2016-06-23T21:07:06",
                "message_text_only": "On Thu, Jun 23, 2016 at 1:46 PM, s7r via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n>\n>\n> Any kind of built-in AML/KYC tools in Bitcoin is bad, and might draw\n> expectations from _all_ users from authorities. Companies or individuals\n> who want and/or need AML/KYC can find ways and do it at their side\n> isolated from the entire network, and the solutions shouldn't come from\n> upstream. AML/KYC/<insert other regulation here> differ from country to\n> country and will be hard to implement in a global consensus network even\n> if it would be worth it.\n>\n>\nThis was precisely our thinking as well.\n\nThis is actually exactly why BIP 75 was designed the way that it was.  Any\n(voluntary) identity exchange is done at the application level, on an\nencrypted https (or other) connection between the sender and receiver.\nIdentity data is not passed through or stored on the blockchain, and there\nis actually no mark left on the blockchain that identity was even exchanged\non that transaction.\n\nThe only people who know identity info was exchanged, or what the identity\nwas is the counterparties in the transaction, and depending on\nimplementation, their service provider.  (At a high level, many software\nbased wallet providers wouldn\u2019t have any visibility into identity info,\nwhere many hosted services would, for example)\n\nWe did this to protect user privacy as well as fungibility.\n\nWe are allowing the people who want or need to exchange identtity info\n(either self signed or 3rd party validated) the option to exchange it, in a\nstandards based way, directly between peers, without touching the\nblockchain or network itself.\n\nIs this more clear?\n\n-- \n\nJustin W. Newton\nFounder/CEO\nNetki, Inc.\n\njustin at netki.com\n+1.818.261.4248\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/30ac6899/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: PastedGraphic-1.tiff\nType: image/tiff\nSize: 10972 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/30ac6899/attachment-0001.tiff>"
            },
            {
                "author": "Police Terror",
                "date": "2016-06-23T21:31:29",
                "message_text_only": "In England under RIPA 2000 legislation, it's irrelevant whether you have\nthe data or not. If the authorities compel you to hand over that\ninformation, and it is within your means to obtain it then you are\nobliged to do so under threat of criminal offense.\n\nSo any mechanism whereby data could be collected from Bitcoin users,\nwhether it's stored ephemerally or not, if the police have reasonable\nsuspicion to think it exists then they can compel all parties to work to\nget them the data they require.\n\nIf the mechanism flat out does not exist, that is miles better than\ncould exist. Deniability is not a defense when served with a police\nnotice for disclosing data.\n\nYou have to think not only about the end result, but also about how\nthese mechanisms can be used for intimidating users or leveraging\ntechnologies.\n\nJustin Newton via bitcoin-dev:\n> On Thu, Jun 23, 2016 at 1:46 PM, s7r via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n>>\n>>\n>>\n>> Any kind of built-in AML/KYC tools in Bitcoin is bad, and might draw\n>> expectations from _all_ users from authorities. Companies or individuals\n>> who want and/or need AML/KYC can find ways and do it at their side\n>> isolated from the entire network, and the solutions shouldn't come from\n>> upstream. AML/KYC/<insert other regulation here> differ from country to\n>> country and will be hard to implement in a global consensus network even\n>> if it would be worth it.\n>>\n>>\n> This was precisely our thinking as well.\n> \n> This is actually exactly why BIP 75 was designed the way that it was.  Any\n> (voluntary) identity exchange is done at the application level, on an\n> encrypted https (or other) connection between the sender and receiver.\n> Identity data is not passed through or stored on the blockchain, and there\n> is actually no mark left on the blockchain that identity was even exchanged\n> on that transaction.\n> \n> The only people who know identity info was exchanged, or what the identity\n> was is the counterparties in the transaction, and depending on\n> implementation, their service provider.  (At a high level, many software\n> based wallet providers wouldn\u2019t have any visibility into identity info,\n> where many hosted services would, for example)\n> \n> We did this to protect user privacy as well as fungibility.\n> \n> We are allowing the people who want or need to exchange identtity info\n> (either self signed or 3rd party validated) the option to exchange it, in a\n> standards based way, directly between peers, without touching the\n> blockchain or network itself.\n> \n> Is this more clear?\n> \n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Justin Newton",
                "date": "2016-06-23T22:44:34",
                "message_text_only": "Hi there,\n   For users who don\u2019t wish a service provider to be able to see their\ninformation, even ephemerally, and they would like to exchange information\nvia BIP75, they can use a software wallet, such as a breadwallet or others,\nand that data will only exist on their phone, and the phone of their\ncounterparty (assuming the counterparty also chose to exchange info, and\nwas running on a software wallet).\n\nIn this way, we allow users to exchange data as they choose, without having\nthe risk that a service provider be asked for that data.\n\nIf a user chooses to use a hosted platform, and also to store their\nidentity data there, I do agree it could be subject to a subpoena, the same\nas when they host their email, and other services.\n\nFinally, they could choose not to use BIP75 at all, and no one would know\nwhether they did or didn\u2019t (other than their counterparts) as we don\u2019t\nleave any residue on the blockchain, or anywhere else in the public eye.\n\nWe believe that this solution, due in part to its narrow data aperture, is\nthe best solution available to the problem we are solving.  We are eager to\nengage in any discussions about how to improve the proposed solution, with\nan eye to fungibility, privacy, and usability.\n\nThat said, there is a real need for people to know who they are transacting\nwith for usability reasons, for fraud reduction, and also of regulatory\nreasons for some players.  To NOT solve it with a carefully crafted\nstandard means that it is more likely to be solved with back room, quick\nand dirty solutions that are not available for community review and\nfeedback.\n\nThanks!\n\nJustin\n\n\n\n\n\n\nOn Thu, Jun 23, 2016 at 2:31 PM, Police Terror via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> In England under RIPA 2000 legislation, it's irrelevant whether you have\n> the data or not. If the authorities compel you to hand over that\n> information, and it is within your means to obtain it then you are\n> obliged to do so under threat of criminal offense.\n>\n> So any mechanism whereby data could be collected from Bitcoin users,\n> whether it's stored ephemerally or not, if the police have reasonable\n> suspicion to think it exists then they can compel all parties to work to\n> get them the data they require.\n>\n> If the mechanism flat out does not exist, that is miles better than\n> could exist. Deniability is not a defense when served with a police\n> notice for disclosing data.\n>\n> You have to think not only about the end result, but also about how\n> these mechanisms can be used for intimidating users or leveraging\n> technologies.\n>\n> Justin Newton via bitcoin-dev:\n> > On Thu, Jun 23, 2016 at 1:46 PM, s7r via bitcoin-dev <\n> > bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >\n> >>\n> >>\n> >>\n> >> Any kind of built-in AML/KYC tools in Bitcoin is bad, and might draw\n> >> expectations from _all_ users from authorities. Companies or individuals\n> >> who want and/or need AML/KYC can find ways and do it at their side\n> >> isolated from the entire network, and the solutions shouldn't come from\n> >> upstream. AML/KYC/<insert other regulation here> differ from country to\n> >> country and will be hard to implement in a global consensus network even\n> >> if it would be worth it.\n> >>\n> >>\n> > This was precisely our thinking as well.\n> >\n> > This is actually exactly why BIP 75 was designed the way that it was.\n> Any\n> > (voluntary) identity exchange is done at the application level, on an\n> > encrypted https (or other) connection between the sender and receiver.\n> > Identity data is not passed through or stored on the blockchain, and\n> there\n> > is actually no mark left on the blockchain that identity was even\n> exchanged\n> > on that transaction.\n> >\n> > The only people who know identity info was exchanged, or what the\n> identity\n> > was is the counterparties in the transaction, and depending on\n> > implementation, their service provider.  (At a high level, many software\n> > based wallet providers wouldn\u2019t have any visibility into identity info,\n> > where many hosted services would, for example)\n> >\n> > We did this to protect user privacy as well as fungibility.\n> >\n> > We are allowing the people who want or need to exchange identtity info\n> > (either self signed or 3rd party validated) the option to exchange it,\n> in a\n> > standards based way, directly between peers, without touching the\n> > blockchain or network itself.\n> >\n> > Is this more clear?\n> >\n> >\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n\n-- \n\nJustin W. Newton\nFounder/CEO\nNetki, Inc.\n\njustin at netki.com\n+1.818.261.4248\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/cc872bf8/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: PastedGraphic-1.tiff\nType: image/tiff\nSize: 10972 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/cc872bf8/attachment-0001.tiff>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2016-06-24T02:26:52",
                "message_text_only": "Sometimes I think there's concerted resistance to making Bitcoin usable for\nthe average person.   Clearly the primary purpose of BIP0075 is to enshrine\na DNSSEC protocol for giving wallet addresses memorable names.\n\n\nOn Thu, Jun 23, 2016 at 6:44 PM, Justin Newton via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi there,\n>    For users who don\u2019t wish a service provider to be able to see their\n> information, even ephemerally, and they would like to exchange information\n> via BIP75, they can use a software wallet, such as a breadwallet or others,\n> and that data will only exist on their phone, and the phone of their\n> counterparty (assuming the counterparty also chose to exchange info, and\n> was running on a software wallet).\n>\n> In this way, we allow users to exchange data as they choose, without\n> having the risk that a service provider be asked for that data.\n>\n> If a user chooses to use a hosted platform, and also to store their\n> identity data there, I do agree it could be subject to a subpoena, the same\n> as when they host their email, and other services.\n>\n> Finally, they could choose not to use BIP75 at all, and no one would know\n> whether they did or didn\u2019t (other than their counterparts) as we don\u2019t\n> leave any residue on the blockchain, or anywhere else in the public eye.\n>\n> We believe that this solution, due in part to its narrow data aperture, is\n> the best solution available to the problem we are solving.  We are eager to\n> engage in any discussions about how to improve the proposed solution, with\n> an eye to fungibility, privacy, and usability.\n>\n> That said, there is a real need for people to know who they are\n> transacting with for usability reasons, for fraud reduction, and also of\n> regulatory reasons for some players.  To NOT solve it with a carefully\n> crafted standard means that it is more likely to be solved with back room,\n> quick and dirty solutions that are not available for community review and\n> feedback.\n>\n> Thanks!\n>\n> Justin\n>\n>\n>\n>\n>\n>\n> On Thu, Jun 23, 2016 at 2:31 PM, Police Terror via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> In England under RIPA 2000 legislation, it's irrelevant whether you have\n>> the data or not. If the authorities compel you to hand over that\n>> information, and it is within your means to obtain it then you are\n>> obliged to do so under threat of criminal offense.\n>>\n>> So any mechanism whereby data could be collected from Bitcoin users,\n>> whether it's stored ephemerally or not, if the police have reasonable\n>> suspicion to think it exists then they can compel all parties to work to\n>> get them the data they require.\n>>\n>> If the mechanism flat out does not exist, that is miles better than\n>> could exist. Deniability is not a defense when served with a police\n>> notice for disclosing data.\n>>\n>> You have to think not only about the end result, but also about how\n>> these mechanisms can be used for intimidating users or leveraging\n>> technologies.\n>>\n>> Justin Newton via bitcoin-dev:\n>> > On Thu, Jun 23, 2016 at 1:46 PM, s7r via bitcoin-dev <\n>> > bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> >\n>> >>\n>> >>\n>> >>\n>> >> Any kind of built-in AML/KYC tools in Bitcoin is bad, and might draw\n>> >> expectations from _all_ users from authorities. Companies or\n>> individuals\n>> >> who want and/or need AML/KYC can find ways and do it at their side\n>> >> isolated from the entire network, and the solutions shouldn't come from\n>> >> upstream. AML/KYC/<insert other regulation here> differ from country to\n>> >> country and will be hard to implement in a global consensus network\n>> even\n>> >> if it would be worth it.\n>> >>\n>> >>\n>> > This was precisely our thinking as well.\n>> >\n>> > This is actually exactly why BIP 75 was designed the way that it was.\n>> Any\n>> > (voluntary) identity exchange is done at the application level, on an\n>> > encrypted https (or other) connection between the sender and receiver.\n>> > Identity data is not passed through or stored on the blockchain, and\n>> there\n>> > is actually no mark left on the blockchain that identity was even\n>> exchanged\n>> > on that transaction.\n>> >\n>> > The only people who know identity info was exchanged, or what the\n>> identity\n>> > was is the counterparties in the transaction, and depending on\n>> > implementation, their service provider.  (At a high level, many software\n>> > based wallet providers wouldn\u2019t have any visibility into identity info,\n>> > where many hosted services would, for example)\n>> >\n>> > We did this to protect user privacy as well as fungibility.\n>> >\n>> > We are allowing the people who want or need to exchange identtity info\n>> > (either self signed or 3rd party validated) the option to exchange it,\n>> in a\n>> > standards based way, directly between peers, without touching the\n>> > blockchain or network itself.\n>> >\n>> > Is this more clear?\n>> >\n>> >\n>> >\n>> > _______________________________________________\n>> > bitcoin-dev mailing list\n>> > bitcoin-dev at lists.linuxfoundation.org\n>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> >\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n>\n>\n> --\n>\n> Justin W. Newton\n> Founder/CEO\n> Netki, Inc.\n>\n> justin at netki.com\n> +1.818.261.4248\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/f11d74c6/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: PastedGraphic-1.tiff\nType: image/tiff\nSize: 10972 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160623/f11d74c6/attachment-0001.tiff>"
            },
            {
                "author": "James MacWhyte",
                "date": "2016-06-24T05:27:36",
                "message_text_only": "> Clearly the primary purpose of BIP0075 is to enshrine a DNSSEC protocol\n> for giving wallet addresses memorable names.\n>\n>\nI can't tell if you're being sarcastic or not, but if you aren't, I don't\nthink this is an accurate description at all. BIP75 is, at its most\nsimplest, nothing more than an encrypted/encapsulated version of BIP70. All\nwe did was make it safe for people to exchange BIP70 messages through an\nintermediary.\n\nThe only identity information included in BIP75 is the pki_data field,\nwhich wasn't even introduced in BIP75--it was already in BIP70. I'm\nguessing Peter would also have us remove BIP70 altogether?\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160624/4fda853a/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: PastedGraphic-1.tiff\nType: image/tiff\nSize: 10972 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160624/4fda853a/attachment.tiff>"
            },
            {
                "author": "Thomas Voegtlin",
                "date": "2016-06-22T07:57:37",
                "message_text_only": "IMO the moderate success of BIP70 is caused by its complexity. Since the\namount of data in a BIP70 payment request does not fit in a bitcoin:\nURI, an https server is required to serve the requests.\n\nOnly large merchants are able to maintain such an infrastructure; (even\nCoinbase recently failed at it, they forgot to update their\ncertificate). For end users that is completely unpractical.\n\nThe main benefit of BIP70 is that the payment request is signed by the\nrequestor; this gives the sender a proof that they are sending to the\nright person, and that the person actually requested the payment.\n\nThe same benefit can be achieved without the complexity of BIP70, by\nextending the Bitcoin URI scheme. The requestor is authenticated using\nDNSSEC, and the payment request is signed using an EC private key. A\ndomain name and an EC signature are short enough to fit in a Bitcoin URI\nand to be shared by QR code or SMS text.\n\n bitcoin:address?amount=xx&message=yyy&name=john.example.com&sig=zzz\n\nThe URI scheme is extended with two fields:\n name: DNS name containing a public key or bitcoin address\n sig: signature\n\nThat extension is sufficient to provide authenticated requests, without\nrequiring a https server. The signed data can be serialized from the\nURI, and DNSSEC verification succeeds without requesting extra data from\nthe requestor. The only assumption is that the verifier is able to make\nDNS requests.\n\nI am willing to write a BIP if other wallet developers are interested.\n\n\n\n\nLe 20/06/2016 19:33, Erik Aronesty via bitcoin-dev a \u00e9crit :\n> BIP 0070 has been a a moderate success, however, IMO:\n> \n> - protocol buffers are inappropriate since ease of use and extensibility is\n> desired over the minor gains of efficiency in this protocol.  Not too late\n> to support JSON messages as the standard going forward\n> \n> - problematic reliance on merchant-supplied https (X509) as the sole form\n> of mechant identification.   alternate schemes (dnssec/netki), pgp and\n> possibly keybase seem like good ideas.   personally, i like keybase, since\n> there is no reliance on the existing domain-name system (you can sell with\n> a github id, for example)\n> \n> - missing an optional client supplied identification\n> \n> - lack of basic subscription support\n> \n> *Proposed for subscriptions:*\n> \n> - BIP0047 payment codes are recommended instead of wallet addresses when\n> establishing subscriptions.  Or, merchants can specify replacement\n> addresses in ACK/NACK responses.   UI confirms are *required *when there\n> are no replacement addresses or payment codes used.\n> \n> - Wallets must confirm and store subscriptions, and are responsible for\n> initiating them at the specified interval.\n> \n> - Intervals can *only *be from a preset list: weekly, biweekly, or 1,\n> 2,3,4,6 or 12 months.   Intervals missed by more than 3 days cause\n> suspension until the user re-verifies.\n> \n> - Wallets *may *optionally ask the user whether they want to be notified\n> and confirm every interval - or not.   Wallets that do not ask *must *notify\n> before initiating each payment.   Interval confirmations should begin at *least\n> *1 day in advance of the next payment.\n> \n> \n> *Proposed in general:*\n> - JSON should be used instead of protocol buffers going forward.  Easier to\n> use, explain extend.\n> \n> - \"Extendible\" URI-like scheme to support multi-mode identity mechanisms on\n> both payment and subscription requests.   Support for keybase://, netki://\n> and others as alternates to https://.\n> \n> - Support for client as well as merchant multi-mode verification\n> \n> - Ideally, the identity verification URI scheme is somewhat\n> orthogonal/independent of the payment request itself\n> \n> Question:\n> \n> Should this be a new BIP?  I know netki's BIP75 is out there - but I think\n> it's too specific and too reliant on the domain name system.\n> \n> Maybe an identity-protocol-agnostic BIP + solid implementation of a couple\n> major protocols without any mention of payment URI's ... just a way of\n> sending and receiving identity verified messages in general?\n> \n> I would be happy to implement plugins for identity protocols, if anyone\n> thinks this is a good idea.\n> \n> Does anyone think https:// or keybase, or PGP or netki all by themselves,\n> is enough - or is it always better to have an extensible protocol?\n> \n> - Erik Aronesty\n> \n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2016-06-22T14:25:03",
                "message_text_only": "> Only large merchants are able to maintain such an infrastructure; (even\n> Coinbase recently failed at it, they forgot to update their\n> certificate). For end users that is completely unpractical.\n>\n\nPayment protocol is for when you buy stuff from purse.io, not really needed\nfor face-to face transfers, end users, IMO.\n\n\n> The same benefit can be achieved without the complexity of BIP70, by\n> extending the Bitcoin URI scheme. The requestor is authenticated using\n> DNSSEC, and the payment request is signed using an EC private key. A\n> domain name and an EC signature are short enough to fit in a Bitcoin URI\n> and to be shared by QR code or SMS text.\n>\n>  bitcoin:address?amount=xx&message=yyy&name=john.example.com&sig=zzz\n>\n\nI agree.  A TXT record at that name could contain the pubkey.\n\n\n> That extension is sufficient to provide authenticated requests, without\n> requiring a https server. The signed data can be serialized from the\n> URI, and DNSSEC verification succeeds without requesting extra data from\n> the requestor. The only assumption is that the verifier is able to make\n> DNS requests.\n>\n\nThe problem is that there's no way for a merchant to *refuse *a payment\nwithout a direct communication with the merchant's server.    Verify first\n/ clear later is the rule.   Check stock, ensure you can deliver, and clear\nthe payment on the way out the door.\n\nAlso, as a merchant processing monthly subscriptions, you don't want the\nfirst time you hear about a user's payment to be *after *it hits the\nblockchain.  You could add a refund address to deal with it after the\nfact... stuff a refund address int OP_RETURN somehow?\n\nbitcoin:address?amount=xx&currency=ccc&message=yyy&name=john.example.com\n&offset=3d&interval=1m&sig=zzz\n\n... But what if the merchant simply goes out of business.  No OP_RETURN\nwill help you here.   You'll be posting transactions into a dead wallet.\nYou could have some way of posting a \"ping\" transaction, and then\nmonitoring for a valid response.   But this is \"spamming the blockchain for\ncommunications\".\n\nNo, I think BIP075 is fine.   You just need to extend the *PaymentAck *with\na single field, instead of just having a memo.\n\nnext_payment_days : integer\n\nThe wallet, when it sees this field, re-initiates an invoice request after\nthe selected number of days, after presenting the user with the content of\nthe memo field which will presumably explain the subscription.   Wallet\nvendors can let users \"auto approve\" vendors as needed.\n\nThis is, I think, the absolute minimum needed to update BIP0070/0075 for\nsubscriptions.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160622/69c8ccf9/attachment.html>"
            },
            {
                "author": "Andy Schroder",
                "date": "2016-06-22T15:12:04",
                "message_text_only": ">\n>     Only large merchants are able to maintain such an infrastructure;\n>     (even\n>     Coinbase recently failed at it, they forgot to update their\n>     certificate). For end users that is completely unpractical.\n>\n>\n> Payment protocol is for when you buy stuff from purse.io \n> <http://purse.io>, not really needed for face-to face transfers, end \n> users, IMO.\n\n\n\nI disagree with your statements. There are many face to face use cases \nwhere the payment protocol is essential. Pretty much anything where the \npayee's hardware device that the payer interacts with is automated in \npublic and/or operated or accessible by untrusted employees. In any of \nthose cases the software on the payee's hardware device can be modified. \nProviding a signed payment request gives the payer additional confidence \nthat they are paying the correct person.\n\nSee some examples here: http://andyschroder.com/BitcoinFluidDispenser/2.3/\n\n\nThere was a secure bluetooth protocol that Andreas Schildbach and Eric \nVoskuil and I were working on, but we never pulled it all the way \ntogether. This would also need a two way exchange for a face to face \npayment. This could be used without using some sort of key/certificate \nverification service if being done between two humans who are the direct \nsenders and receivers of the payment and are using hardware that they \npersonally own (not necessarily the case of untrusted employees or \npublic vulnerable machines).\n\n\n\n\n>     The same benefit can be achieved without the complexity of BIP70, by\n>     extending the Bitcoin URI scheme. The requestor is authenticated using\n>     DNSSEC, and the payment request is signed using an EC private key. A\n>     domain name and an EC signature are short enough to fit in a\n>     Bitcoin URI\n>     and to be shared by QR code or SMS text.\n>\n>      bitcoin:address?amount=xx&message=yyy&name=john.example.com\n>     <http://john.example.com>&sig=zzz\n>\n>\n> I agree.  A TXT record at that name could contain the pubkey.\n\n\nDid you not see my previous message about the size of the bitcoin: URI \ngetting too big for NFC and QR codes? Do you not care about giving the \npayer the option of using multiple destination payment addresses? This \nis important for many reasons.\n\n\n>     That extension is sufficient to provide authenticated requests,\n>     without\n>     requiring a https server. The signed data can be serialized from the\n>     URI, and DNSSEC verification succeeds without requesting extra\n>     data from\n>     the requestor. The only assumption is that the verifier is able to\n>     make\n>     DNS requests.\n>\n>\n> The problem is that there's no way for a merchant to /refuse /a \n> payment without a direct communication with the merchant's server.    \n> Verify first / clear later is the rule.   Check stock, ensure you can \n> deliver, and clear the payment on the way out the door.\n\nSo, are you saying first the payer should send an unsigned transaction \nfor review, and then once the payee has agreed it's good, they can send \nan ACK message back and then wait for the signed version? I don't think \nthis is a bad option to have. Many wallets simultaneously broadcast a \nsigned transaction to their peers and and also back to the payee via \nhttps or bluetooth. So, you'd have to add another step to do the \nunsigned transaction review in order to avoid a transaction being \naccidentally broadcast that both parties don't like.\n\n\n>\n> Also, as a merchant processing monthly subscriptions, you don't want \n> the first time you hear about a user's payment to be /after /it hits \n> the blockchain.  You could add a refund address to deal with it after \n> the fact... stuff a refund address int OP_RETURN somehow?\n>\n> bitcoin:address?amount=xx&currency=ccc&message=yyy&name=john.example.com \n> <http://john.example.com>&offset=3d&interval=1m&sig=zzz\n\nAgain, my comments above about issues with using bitcoin: URI for \neverything. Also, why do you want to bloat the blockchain with \nunnecessary refund transaction data?\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160622/9ae17eed/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160622/9ae17eed/attachment.sig>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2016-06-22T15:30:55",
                "message_text_only": "> Again, my comments above about issues with using bitcoin: URI for\neverything. Also, why do you want to bloat the blockchain with unnecessary\nrefund transaction data?\n\nI don't, sorry -  I was just kind of thinking out loud and explaining what\nhappens when you stuff that into a URL.\n\nMy conclusion at the bottom of that post was to keep BIP 75 the same, don't\nchange a bit, and stick any subscription information (future payment\nschedule) in the PaymentACK.   Then the wallet then re-initiates an invoice\n(unattended or attended.. up to the user), after the subscription interval\nis passed.  Subscriptions are pretty important for Bitcoin to be used as a\nreal payment system.\n\n\n\u200b\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160622/890f2b72/attachment-0001.html>"
            },
            {
                "author": "Andy Schroder",
                "date": "2016-06-22T16:20:38",
                "message_text_only": "I understand the need for people to make repeated payments to \nindividuals in real life that they know, without the payee every even \ntaking the effort to make a formal payment request (say you're just \npaying a family member of friend back for picking something up for you \nat the store, and you've already payed them many times before).\n\nFor a subscription, wouldn't it be better to promote payment channels or \njust send another payment request? I've been brainstorming recently \nabout a model where service providers could deliver invoices, receipts, \nand payment requests in a standardized and secure way. In addition to \nhaving a send, receive, and transaction history tab in your bitcoin \nwallet, you'd also have an open payment channels tab (which would \ninclude all applications on your computer that have an open real time \npayment channel, such as a wifi access point, web browser, voip \nprovider, etc.), as well as a \"bills to pay\" tab. Since everything would \nbe automated and consolidated locally, you wouldn't have to deal with \nlogging into a million different websites to get the bills and then pay \nthem. If it were this easy, why would you ever want to do a recurring \npayment from a single payment request? I understand why you may think \nyou want to given current work flows, but I'm wondering if it may be \nbetter to just skip over to a completely better way of doing things.\n\n\nAndy Schroder\n\nOn 06/22/2016 11:30 AM, Erik Aronesty wrote:\n> My conclusion at the bottom of that post was to keep BIP 75 the same, \n> don't change a bit, and stick any subscription information (future \n> payment schedule) in the PaymentACK.   Then the wallet then \n> re-initiates an invoice (unattended or attended.. up to the user), \n> after the subscription interval is passed. Subscriptions are pretty \n> important for Bitcoin to be used as a real payment system. \n\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160622/a494da7d/attachment.sig>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2016-06-22T17:07:21",
                "message_text_only": "- Payment channels seem clearly inappropriate for things like monthly\nsubscriptions, the use of nlocktime, etc.\n\n- Merchants cannot send requests to users for future payments, because\nusers don't run servers that they can connect to.  That's why BIP0070 works\nthe way it does.\n\n- Need to have an interval for subscriptions, at a minimum, and stored in\nthe wallet so next months payment can go out on time\n\n- Support for varying currency conversion needs to be baked in to\nwallets.   Fortunately, by adding advisory subscription info to the\npaymentrequest, this is left up to the wallet to\nsecure/validate/repeat/convert/etc. as needed for each subscription.\n\n- The UI you describe is nice - but not unique to the solution.\n\n\n\n\nOn Wed, Jun 22, 2016 at 12:20 PM, Andy Schroder <info at andyschroder.com>\nwrote:\n\n> I understand the need for people to make repeated payments to individuals\n> in real life that they know, without the payee every even taking the effort\n> to make a formal payment request (say you're just paying a family member of\n> friend back for picking something up for you at the store, and you've\n> already payed them many times before).\n>\n> For a subscription, wouldn't it be better to promote payment channels or\n> just send another payment request? I've been brainstorming recently about a\n> model where service providers could deliver invoices, receipts, and payment\n> requests in a standardized and secure way. In addition to having a send,\n> receive, and transaction history tab in your bitcoin wallet, you'd also\n> have an open payment channels tab (which would include all applications on\n> your computer that have an open real time payment channel, such as a wifi\n> access point, web browser, voip provider, etc.), as well as a \"bills to\n> pay\" tab. Since everything would be automated and consolidated locally, you\n> wouldn't have to deal with logging into a million different websites to get\n> the bills and then pay them. If it were this easy, why would you ever want\n> to do a recurring payment from a single payment request? I understand why\n> you may think you want to given current work flows, but I'm wondering if it\n> may be better to just skip over to a completely better way of doing things.\n>\n>\n> Andy Schroder\n>\n>\n> On 06/22/2016 11:30 AM, Erik Aronesty wrote:\n>\n>> My conclusion at the bottom of that post was to keep BIP 75 the same,\n>> don't change a bit, and stick any subscription information (future payment\n>> schedule) in the PaymentACK.   Then the wallet then re-initiates an invoice\n>> (unattended or attended.. up to the user), after the subscription interval\n>> is passed. Subscriptions are pretty important for Bitcoin to be used as a\n>> real payment system.\n>>\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160622/d383acf0/attachment.html>"
            },
            {
                "author": "James MacWhyte",
                "date": "2016-06-22T20:11:36",
                "message_text_only": "Thomas,\n\nI like your idea about expanding Bitcoin URI's to include signatures. For\nBIP75 store and forward servers we are already thinking the DNS record\nwould have the user's public key as well as the URL of their store and\nforward endpoint, so as soon as that becomes a standard you could use it\njust for the public key part. Expanding the Bitcoin URI should be done as\nwell, for people who want to go the simpler route and not rely on servers.\n\nErik, Andy, everyone else,\n\nI don't understand why subscriptions would need to be built into the\nprotocol. With BIP75 the merchant could automatically issue a\nPaymentRequest message every X amount of time, and the customer's wallet\nwould either display the request like normal or be set to pre-authorize\nrequests from the merchant. If the merchant goes out of business, the\nrequests would stop coming. This sounds like a UI issue and not a\nprotocol-level requirement.\n\nIf you think I'm wrong, please explain why :)\n\nOn Wed, Jun 22, 2016 at 12:35 PM Erik Aronesty via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> - Payment channels seem clearly inappropriate for things like monthly\n> subscriptions, the use of nlocktime, etc.\n>\n> - Merchants cannot send requests to users for future payments, because\n> users don't run servers that they can connect to.  That's why BIP0070 works\n> the way it does.\n>\n> - Need to have an interval for subscriptions, at a minimum, and stored in\n> the wallet so next months payment can go out on time\n>\n> - Support for varying currency conversion needs to be baked in to\n> wallets.   Fortunately, by adding advisory subscription info to the\n> paymentrequest, this is left up to the wallet to\n> secure/validate/repeat/convert/etc. as needed for each subscription.\n>\n> - The UI you describe is nice - but not unique to the solution.\n>\n>\n>\n>\n> On Wed, Jun 22, 2016 at 12:20 PM, Andy Schroder <info at andyschroder.com>\n> wrote:\n>\n>> I understand the need for people to make repeated payments to individuals\n>> in real life that they know, without the payee every even taking the effort\n>> to make a formal payment request (say you're just paying a family member of\n>> friend back for picking something up for you at the store, and you've\n>> already payed them many times before).\n>>\n>> For a subscription, wouldn't it be better to promote payment channels or\n>> just send another payment request? I've been brainstorming recently about a\n>> model where service providers could deliver invoices, receipts, and payment\n>> requests in a standardized and secure way. In addition to having a send,\n>> receive, and transaction history tab in your bitcoin wallet, you'd also\n>> have an open payment channels tab (which would include all applications on\n>> your computer that have an open real time payment channel, such as a wifi\n>> access point, web browser, voip provider, etc.), as well as a \"bills to\n>> pay\" tab. Since everything would be automated and consolidated locally, you\n>> wouldn't have to deal with logging into a million different websites to get\n>> the bills and then pay them. If it were this easy, why would you ever want\n>> to do a recurring payment from a single payment request? I understand why\n>> you may think you want to given current work flows, but I'm wondering if it\n>> may be better to just skip over to a completely better way of doing things.\n>>\n>>\n>> Andy Schroder\n>>\n>>\n>> On 06/22/2016 11:30 AM, Erik Aronesty wrote:\n>>\n>>> My conclusion at the bottom of that post was to keep BIP 75 the same,\n>>> don't change a bit, and stick any subscription information (future payment\n>>> schedule) in the PaymentACK.   Then the wallet then re-initiates an invoice\n>>> (unattended or attended.. up to the user), after the subscription interval\n>>> is passed. Subscriptions are pretty important for Bitcoin to be used as a\n>>> real payment system.\n>>>\n>>\n>>\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160622/ebc7af2e/attachment-0001.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2016-06-22T20:37:06",
                "message_text_only": "> I don't understand why subscriptions would need to be built into the\nprotocol.\n\nSimple: Because the PaymentRequest is somewhat counter-intuitively a\n/response/ to a customer initiated action.   It's not something the\nmerchant can initiate (of course, logically this makes sense... how can a\nmerchant know how to connect to some random android app).\n\nCustomers initiate all InvoiceRequests  BIP0075 clarifies this.   BIP0070\nmerely says that the customer \"somehow indicates they are ready to pay\".\nBIP0075 formalizes a standard way to do this.\n\nIn no way do merchants initiate anything (of course).   Subscription\ninformation must reside in the customers wallet, in response to a\nmerchant's advice to set up subscription.   Tacking parameters on to a\nPaymentRequest or PaymentAck is the only good way to do this within BIP\n70/75.\n\nThe only thing to hash out is exactly what fields to tack on and what they\nmean.  ( subscription amount / currency / interval / interval_type ...\ncan't think of anything else )\n\nWallets are responsible for initiating the subscriptions on behalf of the\nuser.  Recommendations on how to do this should go into the spec.\n\nOf course any wallet can, with BIP0075 add support for subscriptions\nwithout any spec - just let the user set them up manually.   But it would\nbe nice if a user didn't have to enter the main parameters for\nsubscriptions... too easy to get times amounts, etc wrong.\n\n\nOn Wed, Jun 22, 2016 at 4:11 PM, James MacWhyte <macwhyte at gmail.com> wrote:\n\n> Thomas,\n>\n> I like your idea about expanding Bitcoin URI's to include signatures. For\n> BIP75 store and forward servers we are already thinking the DNS record\n> would have the user's public key as well as the URL of their store and\n> forward endpoint, so as soon as that becomes a standard you could use it\n> just for the public key part. Expanding the Bitcoin URI should be done as\n> well, for people who want to go the simpler route and not rely on servers.\n>\n> Erik, Andy, everyone else,\n>\n> I don't understand why subscriptions would need to be built into the\n> protocol. With BIP75 the merchant could automatically issue a\n> PaymentRequest message every X amount of time, and the customer's wallet\n> would either display the request like normal or be set to pre-authorize\n> requests from the merchant. If the merchant goes out of business, the\n> requests would stop coming. This sounds like a UI issue and not a\n> protocol-level requirement.\n>\n> If you think I'm wrong, please explain why :)\n>\n> On Wed, Jun 22, 2016 at 12:35 PM Erik Aronesty via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> - Payment channels seem clearly inappropriate for things like monthly\n>> subscriptions, the use of nlocktime, etc.\n>>\n>> - Merchants cannot send requests to users for future payments, because\n>> users don't run servers that they can connect to.  That's why BIP0070 works\n>> the way it does.\n>>\n>> - Need to have an interval for subscriptions, at a minimum, and stored in\n>> the wallet so next months payment can go out on time\n>>\n>> - Support for varying currency conversion needs to be baked in to\n>> wallets.   Fortunately, by adding advisory subscription info to the\n>> paymentrequest, this is left up to the wallet to\n>> secure/validate/repeat/convert/etc. as needed for each subscription.\n>>\n>> - The UI you describe is nice - but not unique to the solution.\n>>\n>>\n>>\n>>\n>> On Wed, Jun 22, 2016 at 12:20 PM, Andy Schroder <info at andyschroder.com>\n>> wrote:\n>>\n>>> I understand the need for people to make repeated payments to\n>>> individuals in real life that they know, without the payee every even\n>>> taking the effort to make a formal payment request (say you're just paying\n>>> a family member of friend back for picking something up for you at the\n>>> store, and you've already payed them many times before).\n>>>\n>>> For a subscription, wouldn't it be better to promote payment channels or\n>>> just send another payment request? I've been brainstorming recently about a\n>>> model where service providers could deliver invoices, receipts, and payment\n>>> requests in a standardized and secure way. In addition to having a send,\n>>> receive, and transaction history tab in your bitcoin wallet, you'd also\n>>> have an open payment channels tab (which would include all applications on\n>>> your computer that have an open real time payment channel, such as a wifi\n>>> access point, web browser, voip provider, etc.), as well as a \"bills to\n>>> pay\" tab. Since everything would be automated and consolidated locally, you\n>>> wouldn't have to deal with logging into a million different websites to get\n>>> the bills and then pay them. If it were this easy, why would you ever want\n>>> to do a recurring payment from a single payment request? I understand why\n>>> you may think you want to given current work flows, but I'm wondering if it\n>>> may be better to just skip over to a completely better way of doing things.\n>>>\n>>>\n>>> Andy Schroder\n>>>\n>>>\n>>> On 06/22/2016 11:30 AM, Erik Aronesty wrote:\n>>>\n>>>> My conclusion at the bottom of that post was to keep BIP 75 the same,\n>>>> don't change a bit, and stick any subscription information (future payment\n>>>> schedule) in the PaymentACK.   Then the wallet then re-initiates an invoice\n>>>> (unattended or attended.. up to the user), after the subscription interval\n>>>> is passed. Subscriptions are pretty important for Bitcoin to be used as a\n>>>> real payment system.\n>>>>\n>>>\n>>>\n>>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160622/00d7edc0/attachment.html>"
            },
            {
                "author": "Andreas Schildbach",
                "date": "2016-06-23T11:50:16",
                "message_text_only": "On 06/22/2016 04:25 PM, Erik Aronesty via bitcoin-dev wrote:\n> \n>     Only large merchants are able to maintain such an infrastructure; (even\n>     Coinbase recently failed at it, they forgot to update their\n>     certificate). For end users that is completely unpractical.\n> \n> \n> Payment protocol is for when you buy stuff from purse.io\n> <http://purse.io>, not really needed for face-to face transfers, end\n> users, IMO.\n\nWhat Andy said, plus there is an (unencrypted) version of BIP70 via\nBluetooth already in place. And its used in several thousand\nface-to-face trades per day."
            }
        ],
        "thread_summary": {
            "title": "Even more proposed BIP extensions to BIP 0070",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Thomas Voegtlin",
                "Andreas Schildbach",
                "s7r",
                "Police Terror",
                "Peter Todd",
                "Matt David",
                "Justin Newton",
                "Luke Dashjr",
                "Erik Aronesty",
                "James MacWhyte",
                "Pieter Wuille",
                "Andy Schroder",
                "Aaron Voisine"
            ],
            "messages_count": 39,
            "total_messages_chars_count": 108943
        }
    },
    {
        "title": "[bitcoin-dev] Geographic Partitioning",
        "thread_messages": [
            {
                "author": "Akiva Lichtner",
                "date": "2016-06-21T15:31:01",
                "message_text_only": "I am a long-time developer and I have some experience in process groups. I\nam going to try to keep this short. If you are interested in pursuing this\nidea please reply to me privately so we don't put a burden on the list.\n\nAs per Satoshi's paper, the blockchain implements a distributed timestamp\nservice. It defeats double-spending by establishing a \"total order\" on\ntransactions. The \"domain\" on which the ordering takes place is the entire\ncoin, the money supply. It's obvious to me that total ordering does not\nscale well as a use case, it's not a matter of implementation details or\ndesign. It's the requirement which is a problem. Therefore when I see\nmention of the many clever schemes proposed to make Bitcoin scalable I\nalready know that by using that proposal we are going to give up something.\nAnd in some cases I see lengthy and complex proposals, and just what the\nuser is giving up is not easy to see.\n\nI think that the user has to give up something in order for electronic cash\nto really scale, and that something has to be non-locality. At the moment\nBitcoin doesn't know whether I am buying a laptop from 3,000 miles away or\n300. This is a wonderful property, but this property makes it impossible to\npartition the users geographically. I think that a simple and effective way\nto do this is to partition the address using a hash. A convention could be\nadopted whereby there is a well-known partition number for each geographic\nlocation. Most users would use third-party clients and the client could\ngenerate Bitcoin addresses until it hits one in the user's geographical\narea.\n\nThe partitioning scheme could be hierarchical. For example there could be\npartitions at the city, state, and country level. A good way to see how\nthis works in real life is shopping at Walmart, which is something like\n4,000 stores. Walmart could have users pay local addresses, and then move\nthe money \"up\" to a regional or country level.\n\nThe problem is what to do when an address in partition A wants to pay an\naddress in partition B. This should be done by processing the transaction\nin partition A first, and once the block is made a hash of that block\nshould be included in some block in partition B. After A has made the block\nthe coin has left A, it cannot be spent. Once B has made its block the coin\nhas \"arrived\" in B and can be spent. It can be seen that some transactions\nspan a longer distance than others, in that they require two or more\nblocks. These transactions take longer to execute, and I think that that is\nentirely okay.\n\nTransaction verification benefits because a small merchant can accept\npayments from local addresses only. Larger merchants can verify\ntransactions across two or more partitions.\n\nSome will be concerned about 51% attacks on partitions. I would point\nout that nodes could process transactions at random, so that the majority\nof the computing power is well-balanced across all partitions.\n\nRegards,\nAkiva\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/a5aebe68/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Geographic Partitioning",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Akiva Lichtner"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3124
        }
    },
    {
        "title": "[bitcoin-dev] Merkel Forrest Partitioning",
        "thread_messages": [
            {
                "author": "Scott Morgan",
                "date": "2016-06-21T22:12:32",
                "message_text_only": "Hi Akiva,\n\n   I have also given a little thought to partitioning, in a totally\ndifferent way a Merkel Tree Forrest. Generally the idea here would have be\nto create new Merkel Trees every so often as currency supply was added. It\nwould partition the mining process and therefore improve the distribution\nof the verification.\n\nIt would work as follows, and NO I haven't really thought this through it's\njust an idea!\n\n\nImagine it was 2009 and there was a small number of 250 BTC in 'Batch 1',\nonce the number of BTC needed to go above 250 BTC two new Batches would be\ncreated each one with it's own Merkel Tree until 750 BTC and so on.\nEventually there would be a large number of trees, allowing small scale\npool miners to dominate a single or small number of the trees and their\nblock chains.\n\nThis would also create a potential partial payment problem, where you send\n3 BTC but only receive 2 BTC since 1 BTC ends up on a bad block and needs\nto be resent.\n\n\nSince most of the BTC currency supply is already available it's a bit late\nfor BitCoin, but could be used for new crypto currencies.\n\n\nAny thoughts on this idea?\n\n\nCheers,\n\nScott\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160621/b9c50054/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Merkel Forrest Partitioning",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Scott Morgan"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1319
        }
    },
    {
        "title": "[bitcoin-dev] Closed Seal Sets and Truth Lists for Better Privacy and Censorship Resistance",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2016-06-22T11:10:09",
                "message_text_only": "At the recent coredev.tech meetup in Zurich I spent much of my time discussing\nanti-censorship improvements with Adam Back, building on his idea of blind\nsymmetric commitments[^bsc], and my own ideas of client-side verification. Our\ngoal here is to combat censorship by ensuring that miners do not have the\ninformation needed to selectively censor (blacklist) transactions, forcing them\nto adopt a whitelist approach of allowed transactions if they choose to censor.\n\nBack's work achieves that by changing the protocol such that users commit to\ntheir transaction in advance, in such a way that the commitment doesn't contain\nthe information necessary to censor the transaction, although after commitment\nall transactional information becomes available. Here we propose a similar\nscheme with using \"smart contract\" state machine tooling, with the potential\nfor an even better Zerocash-like guarantee that only a subset of data ever\nbecomes public, without requiring \"moon math\" of uncertain security.\n\n\n# The Closed Seal Maps\n\nTo implement Single-Use Seals we propose that miners attest to the contents of\na series of key:value maps of true expressions, with the keys being the\nexpressions, and the values being commitments, which along with (discardable)\nwitnesses make up the argument to the expression. Once an expression is added\nto the closed seal map, the value associated with it can't be changed.\n\nPeriodically - perhaps once a year - the most recent map is archived, and the\nmap is started fresh again. Once archived a closed seal map is never changed.\nMiners are expected to keep the contents of the current map, as well as the\nmost recent closed seal map - the contents of older maps are proven on demand\nusing techniques similar to TXO commitments.\n\nA single-use seal[^sma] implemented with the closed seal maps is then\nidentified by the expression and a block height. The seal is open if the\nexpression does not exist in any closed seal maps between the creation block\nheight and the most recent block height. A witness to the fact that the seal\nhas been closed is then a proof that the seal was recorded as closed in one of\nthe closed seal maps, and (if needed) proof that the seal was still open in any\nprior maps between its creation and closing.\n\nSimilar to the logic in Bitcoin's segregated witnesses proposal, separating the\ncommitment and witness arguments to the seal expression ensures that the\nwitness attesting to the fact that a given seal was closed does not depend on\nthe exact signature used to actually close it.\n\nHere's a very simple example of such a seal expression, in the author's\nDex[^dex] expression language, for an application that can avoid reusing\npubkeys:\n\n     (checksig <pubkey> <sig> (hash <committed-value>))\n\nThis desugars to the following after all named arguments were replaced by\nexplicit destructuring of the expression argument, denoted by the arg symbol:\n\n    (and <nonce>\n         (checksig <pubkey> (cdr arg) (digest (car arg))))\n\nThe arguments to the expression are the closed seal map's commitment and\nwitness, which are our committed value and signature respectively:\n\n    (<committed-value> . <sig>)\n\n\n## The Truth List\n\nWe implement an expression validity oracle by having miners attest to the\nvalidity of a perpetually growing list of true predicate expressions, whose\nevaluation can in turn depend on depend on previously attested expressions in\nthe truth list. SPV clients who trust miners can use the truth list to skip\nvalidation of old history.\n\nSimilar to TXO commitments, we expect miners to have a copy of recent entries\nin the truth list, perhaps the previous year. Older history can be proven on an\nas-needed basis. Unlike TXO commitments, since this is a pure list of valid\nexpressions, once an item is added to the list it is never modified.\n\nAs the truth list can include expressions that reference previously\nevaluated expressions, expressions of arbitrary depth can be evaluated. For\nexample, suppose we have an extremely long linked list of numbers, represented\nas the following sexpr:\n\n    (i_n i_n-1 i_n-2 ... i_1 i_0)\n\nWe want to check that every number in the list is even:\n\n    (defun all-even? (l)\n        (match l\n            (nil true)\n            ((n . rest) (if (mod n 2)\n                            false\n                            (all-even? rest)))))\n\nIn any real system this will fail for a sufficiently long list, either due to\nstack overflow, or (if tail recursion is supported) due to exceeding the\nanti-DoS limits on cycles executed in one expression; expressing the above may\neven be impossible in expression systems that don't allow unbounded recursion.\n\nA more subtle issue is that in a merkelized expression language, an expression\nthat calls itself is impossible to directly represent: doing so creates a cycle\nin the call graph, which isn't possible without breaking the hash function. So\ninstead we'll define the special symbol self, which triggers a lookup in the\ntruth map instead of actually evaluating directly. Now our expression is:\n\n    (defun all-even? (l)\n        (match l\n            (nil true)\n            ((n . rest) (if (mod n 2)\n                            false\n                            (self rest)))))\n\nWe evaluate it in parts, starting with the end of the list. The truth list only\nattests to valid expressions - not arguments - so we curry the argument to form\nthe following expression:\n\n    (all-even? nil)\n\nThe second thing that is appended to the truth list is:\n\n    (all-even? (0 . #<digest of \"nil\">))\n\nNote how we haven't actually provided the cdr of the cons cell - it's been\npruned and replaced by the digest of nil. With an additional bit of metadata -\nthe index of that expression within the trust list, and possibly a merkle path\nto the tip if the expression has been archived - we can show that the\nexpression has been previously evaluated and is true.\n\nSubsequent expressions follow the same pattern:\n\n    (all-even? (1 . #<digest of \"(0)\">))\n\nUntil finally we reach the last item:\n\n    (all-even? (n_i . #<digest of \"(n_i-1 n_i-2 ... 1 0)\">))\n\nNow we can show anyone who trusts that the truth list is valid - like a SPV\nclient - that evaluating all-even? on that list returns true by extracting a\nmerkle path from that item to the tip of the list's MMR commitment.\n\n\n# Transactions\n\nWhen we spend an output our goal is to direct the funds spent to a set of\noutputs by irrovocably committing single-use seals to that distribution of\noutputs. Equally, to validate an output we must show that sufficient funds have\nbeen directed assigned to it. However, our anti-censorship goals make this\ndifficult, as we'll often want to reveal some information about where funds\nbeing spend are going immediately - say to pay fees - while delaying when other\ninformation is revealed as long as possible.\n\nTo achieve this we generalize the idea of a transaction slightly. Rather than\nsimply having a set of inputs spent and outputs created, we have a set of\n_input splits_ spent, and outputs created. An input split is then a merkle-sum\nmap of nonces:values that the particular input has been split into; the\ntransaction commits to a specific nonce within that split, and is only valid if\nthe seal for that input is closed over a split actually committing to the\ntransaction.\n\nSecondly, in a transaction with multiple outputs, we don't want it to be\nimmediately possible to link outputs together as seals associated with them are\nclosed, even if the transaction ID is known publicly. So we associate each\noutput with a unique nonce.\n\nThus we can uniquely identify a specific transaction output - an outpoint - by\nthe following data (remember that the tx would usually be pruned, leaving just\nthe digest):\n\n    (struct outpoint\n        (tx     :transaction)\n        (nonce  :digest))\n\nAn transaction output is defined as:\n\n    (struct txout\n        (value     :int)    ; value of output\n        (nonce     :digest)\n        (authexpr  :func))  ; authorization expression\n\nAn input:\n\n    (struct txin\n        (prevout :outpoint) ; authorization expression\n        (split   :digest)   ; split nonce\n        (value   :int))     ; claimed value of output spent\n\nAnd a transaction:\n\n    (struct transaction\n        ; fixme: need to define functions to extract sums and keys\n        (inputs   :(merkle-sum-map  (:digest :txin))\n        (outputs  :(merkle-sum-map  (:digest :txout))\n        ; and probably more metadata here)\n\n\n## Spending Outputs\n\nOur single-use seal associated with a specific output is the expression:\n\n    (<auth expr> <outpoint> . arg)\n\nWhen the seal is closed it commits to the merkle-sum split map, which is\nindexed by split nonces, one per (tx, value) pair committed to.  This means\nthat in the general case of an spend authorization expression that just checks\na signature, the actual outpoint can be pruned and what actually gets published\nin the closed seal set is just:\n\n    (<auth expr> #<digest of <outpoint>> . arg)\n\nAlong with the commitment:\n\n    #<digest of split map>\n\nWith the relevant data hidden behind opaque digests, protected from\nbrute-forcing by nonces, external observers have no information about what\ntransaction output was spent, or anything about the transaction spending that\noutput. The nonce in the seal commitment prevents that multiple spends for the\nsame transaction from being linked together.  Yet at the same time, we're still\nable to write a special-purpose spend auth expressions that do inspect the\ncontents of the transaction if needed.\n\n\n## Validating Transactions\n\nWhen validating a transaction, we want to validate the least amount of data\npossible, allowing the maximum amount of data to be omitted for a given\nrecipient. Thus when we validate a transaction we _don't_ validate the outputs;\nwe only validate that the inputs spent by the transaction are valid, and the\nsum of (split) inputs spent is correct. We only need to validate outputs when\nthey're spent - until then an invalid output is of no relevance. We also don't\nneed to validate any outputs other than the ones we're trying to spend - the\nmerkle sum tree guarantees that regardless of what's going on with other\noutputs, the funds we're spending are uniquely allocated to us.\n\nThis means our function to check that a transaction is valid won't check the\noutputs of the transaction itself, but will check outputs of previous\ntransactions:\n\n    (defun valid-tx? (tx)\n        (map-reduce tx.inputs\n            (lambda (txin)\n                (and <input is valid>\n                     <witness is valid>\n                     <split is valid>\n                     (valid-output? txin.prevout)))))\n\n\n# Censorship Resistant Usage\n\nTo make use of the separation between seal closure and validation we need to\npass transaction information from peer to peer. Let's look at what happens when\nAlice pays Bob:\n\n1. Alice picks one or more inputs to spend.\n\n2. For each input she constructs a split, paying part of the funds to a\nper-input fee transaction with no outputs, and committing part of the funds to\nthe transaction paying Bob. If she has change left over she'll construct a\nthird transaction with just that change as an input.\n\n3. She signs each input, creating valid signatures for the corresponding\noutput's seal's authorization expression.\n\n4. She broadcasts the subset of data corresponding to just the fee paying\ntransactions and related signatures individually, with a time delay between\neach one. All other data is pruned, leaving just opaque digests.\n\n5. Once all inputs are confirmed, she gives Bob the data corresponding to his\ntransaction, including the relevant parts of the merkle trees, and relevant\nclosed seal witnesses.\n\nAt this point, a whole bunch of seals have been closed, but there's absolutely\nnothing on chain that links them together. Now let's suppose Bob pays Charlie,\nusing the funds Alice gave him, and a different input to pay mining fees:\n\n1. Bob constructs a fee paying transaction, splitting some funds from a\npreviously revealed output, and depending on the seal for the output Alice gave\nhim, but without spending any of that output's funds.\n\n2. Bob broadcasts the above publicly. Miners have to add both seals to the\nclosed seal set to collect the fees.\n\n3. Once confirmed, Bob gives Charlie the corresponding transaction information\nfor his output, as well as the still-private information it depends on to prove\nthat the output Alice created for Bob is itself valid.\n\nAgain, nearly none of the information related to the transaction is public, yet\nthe funds have moved twice.\n\n\n## Pruning Old History\n\nOver time the proofs that a coin is valid will grow as each additional\ntransaction adds more data. We shorten these proofs by publishing some of the\ndata in the form of additions to the truth list of valid expressions,\nspecifically the is-valid-tx? expressions that determine whether or not a\ntransaction (and prior transactions) are valid. This allows SPV clients who\ntrust miners to stop validating once they reach that old history.\n\nSecondly, with transaction history linearization[^sma] we can avoid ever\nrevealing most of the transaction data, greatly improving privacy. Only one\ninput per transaction needs to be proven, so all data related to other inputs\ncan be discarded permanently; in practice this will lead to either one or two\npublic inputs, including the input made public to pay mining fees.\n\n\n# \"Smart Contracts\"\n\nPrivacy aside, the combination of single-use seal and true expressions list\nenables all known \"smart contract\" applications, such as the ones Ethereum\ncurrently targets. After all, the accounts-based Ethereum architecture can\nalways be simulated with a series of single-use seal's that explicitly keeps\ntrack of of an account balance based on actions taken.\n\n\n# Open Questions\n\n1. How does the above architecture interact with scaling proposals, like\nsharding? Fraud proofs?\n\n2. How does the statistical inflation protection of transaction history\nlinearization work in a real economy, e.g. if people use it gamble with their\nfunds?\n\n3. PoW isn't a perfect random beacon; how do we take that into account when\ndesigning linearization?\n\n4. How do wallets pass proof data between each other, e.g. offline?\n\n5. How do wallets backup proof data? (similar problem that Lightning has)\n\n\n# References\n\n[^bsc]: \"blind symmetric commitment for stronger byzantine voting resilience\",\n        Adam Back, May 15th 2013, bitcoin-dev mailing list,\n        https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2013-May/002600.html\n\n[^sma]: \"Building Blocks of the State Machine Approach to Consensus\",\n        Peter Todd, Jun 20th 2016,\n        https://petertodd.org/2016/state-machine-consensus-building-blocks\n        https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-June/012773.html\n\n[^dex]: \"Dex: Deterministic Predicate Expressions for Smarter Signatures\",\n        Peter Todd, May 25th 2016,\n        https://github.com/WebOfTrustInfo/ID2020DesignWorkshop/blob/master/topics-and-advance-readings/DexPredicatesForSmarterSigs.md\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160622/bab63bb0/attachment-0001.sig>"
            }
        ],
        "thread_summary": {
            "title": "Closed Seal Sets and Truth Lists for Better Privacy and Censorship Resistance",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Peter Todd"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 15371
        }
    },
    {
        "title": "[bitcoin-dev] parallel token idea & question",
        "thread_messages": [
            {
                "author": "Erik Aronesty",
                "date": "2016-06-26T12:12:11",
                "message_text_only": "token miners who will work to the a new token signal readiness to secure\nthat token by posting a public key to the bitcoin blockchain along with a\ncollateral and possibly a block mined from a side chain, or some other\nsignal proving sufficient participation (allows for non-blockchain tokens).\n\ncoin moved to the new token set is sent to a multisig wallet consisting of\nminers who have signaled readiness, with nlocktime set to some time in the\nfuture\n\ncoin sits in that wallet - the new token doesn't even have to be a chain,\nit could be a DAG, or some other mechanism - following whatever rules it\npleases\n\nany time, miner of the new system can move coin back to the main chain...\ntrivially and following whatever rules are need.  also, any time a miner\nfails to follow the rules of the new system, they lose their collateral\n\nany sufficient consortium of miners/participants in the side chain can, of\ncourse, steal that coin...but that is true for all sidechains - and to some\nextent bitcoin - anyway\n\ndoes this seem too simplistic or weak in some way?\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160626/bf2a17d5/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "parallel token idea & question",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Erik Aronesty"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1238
        }
    },
    {
        "title": "[bitcoin-dev] BIP 151 use of HMAC_SHA512",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2016-06-28T02:31:34",
                "message_text_only": "To quote:\n\n> HMAC_SHA512(key=ecdh_secret|cipher-type,msg=\"encryption key\").\n> \n>  K_1 must be the left 32bytes of the HMAC_SHA512 hash.\n>  K_2 must be the right 32bytes of the HMAC_SHA512 hash.\n\nThis seems a weak reason to introduce SHA512 to the mix.  Can we just\nmake:\n\nK_1 = HMAC_SHA256(key=ecdh_secret|cipher-type,msg=\"header encryption key\")\nK_2 = HMAC_SHA256(key=ecdh_secret|cipher-type,msg=\"body encryption key\")\n\nThanks,\nRusty."
            },
            {
                "author": "Jonas Schnelli",
                "date": "2016-06-28T07:19:04",
                "message_text_only": "> To quote:\n> \n>> HMAC_SHA512(key=ecdh_secret|cipher-type,msg=\"encryption key\").\n>>\n>>  K_1 must be the left 32bytes of the HMAC_SHA512 hash.\n>>  K_2 must be the right 32bytes of the HMAC_SHA512 hash.\n> \n> This seems a weak reason to introduce SHA512 to the mix.  Can we just\n> make:\n> \n> K_1 = HMAC_SHA256(key=ecdh_secret|cipher-type,msg=\"header encryption key\")\n> K_2 = HMAC_SHA256(key=ecdh_secret|cipher-type,msg=\"body encryption key\")\n\nSHA512_HMAC is used by BIP32 [1] and I guess most clients will somehow\nmake use of bip32 features. I though a single SHA512_HMAC operation is\ncheaper and simpler then two SHA256_HMAC.\n\nAFAIK, sha256_hmac is also not used by the current p2p & consensus layer.\nBitcoin-Core uses it for HTTP RPC auth and Tor control.\n\nI don't see big pros/cons for SHA512_HMAC over SHA256_HMAC.\n\n</jonas>\n\n[1]\nhttps://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki#child-key-derivation-ckd-functions\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 819 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160628/bbe12795/attachment.sig>"
            },
            {
                "author": "Arthur Chen",
                "date": "2016-06-28T08:31:51",
                "message_text_only": "Based on previous crypto analysis result, the actual security of SHA512 is\nnot significantly higher than SHA256.\nmaybe we should consider SHA3?\n\n\nOn Tue, Jun 28, 2016 at 3:19 PM, Jonas Schnelli via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> > To quote:\n> >\n> >> HMAC_SHA512(key=ecdh_secret|cipher-type,msg=\"encryption key\").\n> >>\n> >>  K_1 must be the left 32bytes of the HMAC_SHA512 hash.\n> >>  K_2 must be the right 32bytes of the HMAC_SHA512 hash.\n> >\n> > This seems a weak reason to introduce SHA512 to the mix.  Can we just\n> > make:\n> >\n> > K_1 = HMAC_SHA256(key=ecdh_secret|cipher-type,msg=\"header encryption\n> key\")\n> > K_2 = HMAC_SHA256(key=ecdh_secret|cipher-type,msg=\"body encryption key\")\n>\n> SHA512_HMAC is used by BIP32 [1] and I guess most clients will somehow\n> make use of bip32 features. I though a single SHA512_HMAC operation is\n> cheaper and simpler then two SHA256_HMAC.\n>\n> AFAIK, sha256_hmac is also not used by the current p2p & consensus layer.\n> Bitcoin-Core uses it for HTTP RPC auth and Tor control.\n>\n> I don't see big pros/cons for SHA512_HMAC over SHA256_HMAC.\n>\n> </jonas>\n>\n> [1]\n>\n> https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki#child-key-derivation-ckd-functions\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n\n\n-- \nXuesong (Arthur) Chen\nSenior Principle Engineer\nBlockChain Technologist\nBTCC\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160628/01c60739/attachment.html>"
            },
            {
                "author": "Jonas Schnelli",
                "date": "2016-06-29T18:34:06",
                "message_text_only": "> Based on previous crypto analysis result, the actual security of SHA512\n> is not significantly higher than SHA256.\n> maybe we should consider SHA3?\n\nAs far as I know the security of the symmetric cipher key mainly depends\non the PRNG and the ECDH scheme.\n\nThe HMAC_SHA512 will be used to \"drive\" keys from the ECDH shared secret.\nHMAC_SHA256 would be sufficient but I have specified SHA512 to allow to\ndirectly derive 512bits which allows to have two 256bit keys with one\nHMAC operation (same pattern is used in BIP for the key/chaincode\nderivation).\n\nKeccak would be an alternative but we probably don't want to introduce\nanother new hash type just for the encryption.\n\n</jonas>\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 819 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160629/3c5c25c5/attachment.sig>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-29T20:13:17",
                "message_text_only": "On Wed, Jun 29, 2016 at 08:34:06PM +0200, Jonas Schnelli via bitcoin-dev wrote:\n> > Based on previous crypto analysis result, the actual security of SHA512\n> > is not significantly higher than SHA256.\n> > maybe we should consider SHA3?\n> \n> As far as I know the security of the symmetric cipher key mainly depends\n> on the PRNG and the ECDH scheme.\n> \n> The HMAC_SHA512 will be used to \"drive\" keys from the ECDH shared secret.\n> HMAC_SHA256 would be sufficient but I have specified SHA512 to allow to\n> directly derive 512bits which allows to have two 256bit keys with one\n> HMAC operation (same pattern is used in BIP for the key/chaincode\n> derivation).\n\nWhat's the rational for doing that \"directly\" rather than with two SHA256\noperations? (specifcially SHA256(0 . thing), SHA256(1 + thing) for the two\nparts we need to derive)\n\nReducing the # of basic cryptographic primitives you need to implement a\nstandard needs is a good thing.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160629/12948cd4/attachment.sig>"
            },
            {
                "author": "Jonas Schnelli",
                "date": "2016-06-29T20:31:50",
                "message_text_only": "> On Wed, Jun 29, 2016 at 08:34:06PM +0200, Jonas Schnelli via bitcoin-dev wrote:\n>>> Based on previous crypto analysis result, the actual security of SHA512\n>>> is not significantly higher than SHA256.\n>>> maybe we should consider SHA3?\n>>\n>> As far as I know the security of the symmetric cipher key mainly depends\n>> on the PRNG and the ECDH scheme.\n>>\n>> The HMAC_SHA512 will be used to \"drive\" keys from the ECDH shared secret.\n>> HMAC_SHA256 would be sufficient but I have specified SHA512 to allow to\n>> directly derive 512bits which allows to have two 256bit keys with one\n>> HMAC operation (same pattern is used in BIP for the key/chaincode\n>> derivation).\n> \n> What's the rational for doing that \"directly\" rather than with two SHA256\n> operations? (specifcially SHA256(0 . thing), SHA256(1 + thing) for the two\n> parts we need to derive)\n\nSHA256 and SHA512 are both from the SHA-2 family.\n\nI have specified SHA512 to (slightly) increase the brute-force security\nof the ecdh shared secret when knowing K_1 and K_2.\n\nAnd I assumed (haven't measured the required cpu cycles) that a single\nSHA512_HMAC is less expensive then two SHA256_HMAC.\n\n</jonas>\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 819 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160629/8661e056/attachment.sig>"
            },
            {
                "author": "Rusty Russell",
                "date": "2016-06-29T01:00:29",
                "message_text_only": "Jonas Schnelli <dev at jonasschnelli.ch> writes:\n>> To quote:\n>> \n>>> HMAC_SHA512(key=ecdh_secret|cipher-type,msg=\"encryption key\").\n>>>\n>>>  K_1 must be the left 32bytes of the HMAC_SHA512 hash.\n>>>  K_2 must be the right 32bytes of the HMAC_SHA512 hash.\n>> \n>> This seems a weak reason to introduce SHA512 to the mix.  Can we just\n>> make:\n>> \n>> K_1 = HMAC_SHA256(key=ecdh_secret|cipher-type,msg=\"header encryption key\")\n>> K_2 = HMAC_SHA256(key=ecdh_secret|cipher-type,msg=\"body encryption key\")\n>\n> SHA512_HMAC is used by BIP32 [1] and I guess most clients will somehow\n> make use of bip32 features. I though a single SHA512_HMAC operation is\n> cheaper and simpler then two SHA256_HMAC.\n\nGood point; I would argue that mistake has already been made.  But I was\nlooking at appropriating your work for lightning inter-node comms, and\nadding another hash algo seemed unnecessarily painful.\n\n> AFAIK, sha256_hmac is also not used by the current p2p & consensus layer.\n> Bitcoin-Core uses it for HTTP RPC auth and Tor control.\n\nIt's also not clear to me why the HMAC, vs just\nSHA256(key|cipher-type|mesg).  But that's probably just my crypto\nignorance...\n\nThanks!\nRusty."
            },
            {
                "author": "Arthur Chen",
                "date": "2016-06-29T01:38:44",
                "message_text_only": "HMAC has proven security property.\nIt is still secure even when underlying crypto hashing function has\ncollision resistant weakness.\nFor example, MD5 is considered completely insecure now, but HMAC-MD5 is\nstill considered secure.\nWhen in doubt, we should always use HMAC for MAC(Message Authentication\nCode) rather than custom construction\n\nOn Wed, Jun 29, 2016 at 9:00 AM, Rusty Russell via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Jonas Schnelli <dev at jonasschnelli.ch> writes:\n> >> To quote:\n> >>\n> >>> HMAC_SHA512(key=ecdh_secret|cipher-type,msg=\"encryption key\").\n> >>>\n> >>>  K_1 must be the left 32bytes of the HMAC_SHA512 hash.\n> >>>  K_2 must be the right 32bytes of the HMAC_SHA512 hash.\n> >>\n> >> This seems a weak reason to introduce SHA512 to the mix.  Can we just\n> >> make:\n> >>\n> >> K_1 = HMAC_SHA256(key=ecdh_secret|cipher-type,msg=\"header encryption\n> key\")\n> >> K_2 = HMAC_SHA256(key=ecdh_secret|cipher-type,msg=\"body encryption key\")\n> >\n> > SHA512_HMAC is used by BIP32 [1] and I guess most clients will somehow\n> > make use of bip32 features. I though a single SHA512_HMAC operation is\n> > cheaper and simpler then two SHA256_HMAC.\n>\n> Good point; I would argue that mistake has already been made.  But I was\n> looking at appropriating your work for lightning inter-node comms, and\n> adding another hash algo seemed unnecessarily painful.\n>\n> > AFAIK, sha256_hmac is also not used by the current p2p & consensus layer.\n> > Bitcoin-Core uses it for HTTP RPC auth and Tor control.\n>\n> It's also not clear to me why the HMAC, vs just\n> SHA256(key|cipher-type|mesg).  But that's probably just my crypto\n> ignorance...\n>\n> Thanks!\n> Rusty.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n\n-- \nXuesong (Arthur) Chen\nSenior Principle Engineer\nBlockChain Technologist\nBTCC\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160629/3e68c72a/attachment-0001.html>"
            },
            {
                "author": "Ethan Heilman",
                "date": "2016-06-29T01:56:55",
                "message_text_only": ">It's also not clear to me why the HMAC, vs just SHA256(key|cipher-type|mesg).  But that's probably just my crypto ignorance...\n\nSHA256(key|cipher-type|mesg) is an extremely insecure MAC because of\nthe length extension property of SHA256.\n\nIf I have a tag y = SHA256(key|cipher-type|mesg), I can without\nknowing key or msg compute a value y' such that\ny' = SHA256(key|cipher-type|mesg|any values I want).\n\nThus, an attacker can trivially forge a tag protected by\nSHA256(key|cipher-type|mesg).\n\nFor more details see:\nhttps://web.archive.org/web/20141029080820/http://vudang.com/2012/03/md5-length-extension-attack/\n\nOn Tue, Jun 28, 2016 at 9:00 PM, Rusty Russell via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Jonas Schnelli <dev at jonasschnelli.ch> writes:\n>>> To quote:\n>>>\n>>>> HMAC_SHA512(key=ecdh_secret|cipher-type,msg=\"encryption key\").\n>>>>\n>>>>  K_1 must be the left 32bytes of the HMAC_SHA512 hash.\n>>>>  K_2 must be the right 32bytes of the HMAC_SHA512 hash.\n>>>\n>>> This seems a weak reason to introduce SHA512 to the mix.  Can we just\n>>> make:\n>>>\n>>> K_1 = HMAC_SHA256(key=ecdh_secret|cipher-type,msg=\"header encryption key\")\n>>> K_2 = HMAC_SHA256(key=ecdh_secret|cipher-type,msg=\"body encryption key\")\n>>\n>> SHA512_HMAC is used by BIP32 [1] and I guess most clients will somehow\n>> make use of bip32 features. I though a single SHA512_HMAC operation is\n>> cheaper and simpler then two SHA256_HMAC.\n>\n> Good point; I would argue that mistake has already been made.  But I was\n> looking at appropriating your work for lightning inter-node comms, and\n> adding another hash algo seemed unnecessarily painful.\n>\n>> AFAIK, sha256_hmac is also not used by the current p2p & consensus layer.\n>> Bitcoin-Core uses it for HTTP RPC auth and Tor control.\n>\n> It's also not clear to me why the HMAC, vs just\n> SHA256(key|cipher-type|mesg).  But that's probably just my crypto\n> ignorance...\n>\n> Thanks!\n> Rusty.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Pieter Wuille",
                "date": "2016-06-29T06:58:21",
                "message_text_only": "On Jun 29, 2016 07:05, \"Ethan Heilman via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> >It's also not clear to me why the HMAC, vs just\nSHA256(key|cipher-type|mesg).  But that's probably just my crypto\nignorance...\n>\n> SHA256(key|cipher-type|mesg) is an extremely insecure MAC because of\n> the length extension property of SHA256.\n\nThis property does technically not apply here, as the output of the hash is\nkept secret, and the possible messages are constants (which are presumably\nchosen in such a way that one is never an extension of another).\n\nHowever, this is a good example of why you can't generically use a hash\nfunction in places where you want a MAC (aka \"a hash with a shared\nsecret\"). Furthermore, if you already have a hash function anyway, HMAC is\nvery easy construct on top of it.\n\n-- \nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160629/72f9c103/attachment.html>"
            },
            {
                "author": "Ethan Heilman",
                "date": "2016-06-29T14:38:43",
                "message_text_only": "Just to clarify in BIP-0151 when it says:\n\n>It is important to include the cipher-type into the symmetric cipher key to avoid weak-cipher-attacks.\n\nthe cipher-type here refers to the ECDH negotiation parameters?\n\nOn Wed, Jun 29, 2016 at 2:58 AM, Pieter Wuille <pieter.wuille at gmail.com> wrote:\n> On Jun 29, 2016 07:05, \"Ethan Heilman via bitcoin-dev\"\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> >It's also not clear to me why the HMAC, vs just\n>> > SHA256(key|cipher-type|mesg).  But that's probably just my crypto\n>> > ignorance...\n>>\n>> SHA256(key|cipher-type|mesg) is an extremely insecure MAC because of\n>> the length extension property of SHA256.\n>\n> This property does technically not apply here, as the output of the hash is\n> kept secret, and the possible messages are constants (which are presumably\n> chosen in such a way that one is never an extension of another).\n>\n> However, this is a good example of why you can't generically use a hash\n> function in places where you want a MAC (aka \"a hash with a shared secret\").\n> Furthermore, if you already have a hash function anyway, HMAC is very easy\n> construct on top of it.\n>\n> --\n> Pieter"
            },
            {
                "author": "Jonas Schnelli",
                "date": "2016-06-29T18:46:01",
                "message_text_only": "Hi Ethan\n\n\n>> It is important to include the cipher-type into the symmetric cipher key to avoid weak-cipher-attacks.\n> \n> the cipher-type here refers to the ECDH negotiation parameters?\n\nNo. Not to the ECDH negotiation.\nBIP151 specifies a flexible symmetric key cipher type negotiation,\nalthough, BIP151 only specifies chacha20-poly1305 at openssh.com.\n\nLets assume someone adds another symmetric cipher type after BIP151 has\nbeen deployed which has less strong security properties then\nchacha20-poly1305.\n\nIf we don't include the ciphersuite-type in the key derivation HMAC, an\nattacker/MITM could in theory force both nodes to use the weaker\nsymmetric cipher type.\n\n</jonas>\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 819 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160629/47d92fd6/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "BIP 151 use of HMAC_SHA512",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Arthur Chen",
                "Peter Todd",
                "Ethan Heilman",
                "Pieter Wuille",
                "Jonas Schnelli"
            ],
            "messages_count": 12,
            "total_messages_chars_count": 15598
        }
    },
    {
        "title": "[bitcoin-dev] BIP 151",
        "thread_messages": [
            {
                "author": "Eric Voskuil",
                "date": "2016-06-28T07:17:31",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\nI haven't seen much discussion here on the rationale behind BIP 151. Apologies if I missed it. I'm trying to understand why libbitcoin (or any node) would want to support it.\n\nI understand the use, when coupled with a yet-to-be-devised identity system, with Bloom filter features. Yet these features are client-server in nature. Libbitcoin (for example) supports client-server features on an independent port (and implements a variant of CurveCP for encryption and identity). My concern arises with application of identity to the P2P protocol (excluding Bloom filter features).\n\nIt seems to me that the desire to secure against the weaknesses of BF is being casually generalized to the P2P network. That generalization may actually weaken the security of the P2P protocol. One might consider the proper resolution is to move the BF features to a client-server protocol.\n\nThe BIP does not make a case for other scenarios, or contemplate the significant problems associated with key distribution in any identity system. Given that the BIP relies on identity, these considerations should be fully vetted before heading down another blind alley.\n\ne\n-----BEGIN PGP SIGNATURE-----\nVersion: oPenGP 6.0 on iOS\n\niQEVAwUBV3IkYjzYwH8LXOFOAQg+iggAkFShi/ibZXiVv3A3z1a1SMd+4ar0kiZk\nmCkBBZaatoW8tXVZmuv5xzLnj3ali9Y4jp/3h2nUJ1B4ov2kcB0kZIKE/a1DTFwb\n4X3uSzgu0lEAqSZormOvt7Op46NPn6KJ+/wTtP4lUFU72lSd7qrVKMlCVc88VE7/\npMloKSc69nAeFIkyWbOUi/zDzefu/5tarfif85jumooYjPmAwJnkgiPCqpqBbuga\n5lBdS1r47KK+SaDFl6Cbn4i/c6tBPLTnu+TR7TEKOW5vwVA7eUqb6SOK7pETWJGK\n0Ii4ZWYt7MOPSEda381CMjWEwtsCNp0eI4GPZAAz+jNLo4G1+PAbaw==\n=Balw\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "Jonas Schnelli",
                "date": "2016-06-28T08:26:12",
                "message_text_only": "Hi Eric\n\n> I haven't seen much discussion here on the rationale behind BIP 151. Apologies if I missed it. I'm trying to understand why libbitcoin (or any node) would want to support it.\n> \n> I understand the use, when coupled with a yet-to-be-devised identity system, with Bloom filter features. Yet these features are client-server in nature. Libbitcoin (for example) supports client-server features on an independent port (and implements a variant of CurveCP for encryption and identity). My concern arises with application of identity to the P2P protocol (excluding Bloom filter features).\n> \n> It seems to me that the desire to secure against the weaknesses of BF is being casually generalized to the P2P network. That generalization may actually weaken the security of the P2P protocol. One might consider the proper resolution is to move the BF features to a client-server protocol.\n> \n> The BIP does not make a case for other scenarios, or contemplate the significant problems associated with key distribution in any identity system. Given that the BIP relies on identity, these considerations should be fully vetted before heading down another blind alley.\n\n\nIn my opinion, the question should be \"why would you _not_ encrypt\".\n\n\n1) Transaction censorship\nISPs, WIFI provider or any other MITM, can holdback/censor unconfirmed\ntransactions. Regardless if you are a miner or a validation/wallet node.\n\n2) Peer censorship\nMITM can remove or add entries from a \"addr\" message.\n\n3) Fingerprinting\nISPs or any other MITM can intercept/inject fingerprinting relevant\nmessages like \"mempool\" to analyze the bitcoin network.\n\n4) SPV\nFor obvious reasons regarding BF (see BIP or above).\n\n5) Goundwork for a \"client-server\" model over the P2P channel\nFee estimation, bloom-filters, or any other message type that requires\nauthentication.\n\nI would not reduce BIP151 to only solve the BF privacy/censorship problem.\n\nIf we agree that censorship-resistance is one of the main properties of\nBitcoin, then we should definitively use a form of end-to-end encryption\nbetween nodes. Built into the network layer.\n\nThere are plenty of other options to solve this problem. stunnel,\nBernsteins CurveCP, VPN, etc. which are available since years.\nBut the reality has shown that most bitcoin traffic is still unencrypted.\nExample: IIRC non of the available SPV wallets can \"speak\" on of the\npossible encryption techniques. Encrypting traffic below the application\nlayer is extremely hard to set up for non-experienced users.\n\nOn top of that, encryption allows us to drop the SHA256 checksum per p2p\nmessage which should result in a better performance on the network layer\nonce BIP151 is deployed.\n\nI agree that BIP151 _must_ be deployed together with an authentication\nscheme (I'm working on that) to protect again MITM during encryption\ninitialization.\n\n---\n</jonas>\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 819 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160628/4b67008b/attachment.sig>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-28T16:45:58",
                "message_text_only": "Hi Jonas, I'll follow up in your second reply as well. Responses inline:\n\n> On Jun 28, 2016, at 10:26 AM, Jonas Schnelli via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Hi Eric\n> \n>> I haven't seen much discussion here on the rationale behind BIP 151. Apologies if I missed it. I'm trying to understand why libbitcoin (or any node) would want to support it.\n>> \n>> I understand the use, when coupled with a yet-to-be-devised identity system, with Bloom filter features. Yet these features are client-server in nature. Libbitcoin (for example) supports client-server features on an independent port (and implements a variant of CurveCP for encryption and identity). My concern arises with application of identity to the P2P protocol (excluding Bloom filter features).\n>> \n>> It seems to me that the desire to secure against the weaknesses of BF is being casually generalized to the P2P network. That generalization may actually weaken the security of the P2P protocol. One might consider the proper resolution is to move the BF features to a client-server protocol.\n>> \n>> The BIP does not make a case for other scenarios, or contemplate the significant problems associated with key distribution in any identity system. Given that the BIP relies on identity, these considerations should be fully vetted before heading down another blind alley.\n\n> In my opinion, the question should be \"why would you _not_ encrypt\".\n\n1) creation of a false sense of security\n2) as a tradeoff against anonymity\n3) benefit does not justify cost\n\n> 1) Transaction censorship\n> ISPs, WIFI provider or any other MITM, can holdback/censor unconfirmed\n> transactions. Regardless if you are a miner or a validation/wallet node.\n> \n> 2) Peer censorship\n> MITM can remove or add entries from a \"addr\" message.\n> \n> 3) Fingerprinting\n> ISPs or any other MITM can intercept/inject fingerprinting relevant\n> messages like \"mempool\" to analyze the bitcoin network.\n\nEncryption alone cannot protect against a MITM attack in an anonymous and permissionless network. This is accepted in the BIP (and your follow-up reply).\n\n> 4) SPV\n> For obvious reasons regarding BF (see BIP or above).\n> \n> 5) Goundwork for a \"client-server\" model over the P2P channel\n> Fee estimation, bloom-filters, or any other message type that requires\n> authentication.\n\nI do not challenge the usefulness and appropriateness of encryption with authentication in a client-server blockchain protocol.\n\n> I would not reduce BIP151 to only solve the BF privacy/censorship problem.\n> \n> If we agree that censorship-resistance is one of the main properties of Bitcoin,\n\nWe do.\n\n> then we should definitively use a form of end-to-end encryption between nodes. Built into the network layer.\n\nThis is the assumption that I'm questioning.\n\n> There are plenty of other options to solve this problem. stunnel,\n> Bernsteins CurveCP, VPN, etc. which are available since years.\n> But the reality has shown that most bitcoin traffic is still unencrypted.\n\nThe question arises from concern over the security of the network in the case where encryption (and therefore authentication) is pervasive.\n\nAs you point out, anyone can set up a private network of nodes today. These nodes must also connect to the permissionless network to maintain the chain. These nodes constitute a trust zone within Bitcoin. This zone of exclusion operates as a single logical node from the perspective of the Bitcoin security model (one entity controls the validation rules for all nodes).\n\nWidespread application of this model is potentially problematic. It is a non-trivial problem to design a distributed system that requires authentication but without identity and without central control. In fact this may be more challenging than Bitcoin itself. Trust on first use (TOFU) does not solve this problem.\n\nIn my opinion this question has not received sufficient consideration to warrant proceeding with a network encryption scheme (which concerns me as well, but as I consider it premature I won't comment).\n\n> Example: IIRC non of the available SPV wallets can \"speak\" on of the\n> possible encryption techniques. Encrypting traffic below the application\n> layer is extremely hard to set up for non-experienced users.\n\nBloom filters can (and IMO should) be isolated from the P2P protocol. Also, if the proposal creates an insecurity its ease of deployment is moot.\n\n> On top of that, encryption allows us to drop the SHA256 checksum per p2p\n> message which should result in a better performance on the network layer\n> once BIP151 is deployed.\n\nI would not consider this a performance enhancing proposal. Simply dropping the checksum seems like a better option. But again, it is moot if it creates an insecurity.\n\n> I agree that BIP151 _must_ be deployed together with an authentication\n> scheme (I'm working on that) to protect again MITM during encryption\n> initialization.\n\nAt a minimum I would propose that you modify BIP151 to declare a dependency on a future BIP, making BIP151 incomplete without it. I think we can agree that it would be unadvisable to deploy (and therefore to implement) encryption alone.\n\nI'll respond to the question of authentication in your follow-up post.\n\ne\n\n> ---\n> </jonas>\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-28T18:22:02",
                "message_text_only": "On Tue, Jun 28, 2016 at 06:45:58PM +0200, Eric Voskuil via bitcoin-dev wrote:\n> > 1) Transaction censorship\n> > ISPs, WIFI provider or any other MITM, can holdback/censor unconfirmed\n> > transactions. Regardless if you are a miner or a validation/wallet node.\n> > \n> > 2) Peer censorship\n> > MITM can remove or add entries from a \"addr\" message.\n> > \n> > 3) Fingerprinting\n> > ISPs or any other MITM can intercept/inject fingerprinting relevant\n> > messages like \"mempool\" to analyze the bitcoin network.\n> \n> Encryption alone cannot protect against a MITM attack in an anonymous and permissionless network. This is accepted in the BIP (and your follow-up reply).\n\nBeing able to easily detect MITM attacks is a _huge_ step forward that\nshouldn't be underestimated; even if 99% of users aren't in a position to\ndetect the MITM you only need a small subset of users that do the necessary\nchecks to alert the wider community, who can then respond with stronger\nsecurity measures. Those measures are likely to be more costly - authenticated\nsystems are significantly harder than not - so better to save your efforts\nuntil the need for them is more obvious.\n\nAlso the fact that an attack has a reasonable probability of detection is a big\ndisincentive for many types of attackers - note how one of the things revealed\nin the Snowden leaks was the fact that the NSA generally tries quite hard to\navoid tipping off targets to the fact that they're being surveilled, with a\nmyriad of carefully scripted policies to control when and how exploits are used\nagainst targets.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160628/5edcd321/attachment.sig>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-28T18:35:26",
                "message_text_only": "Hi Peter,\n\nWhat in this BIP makes a MITM attack easier (or easy) to detect, or increases the probability of one being detected?\n\ne\n\n> On Jun 28, 2016, at 8:22 PM, Peter Todd <pete at petertodd.org> wrote:\n> \n> On Tue, Jun 28, 2016 at 06:45:58PM +0200, Eric Voskuil via bitcoin-dev wrote:\n>>> 1) Transaction censorship\n>>> ISPs, WIFI provider or any other MITM, can holdback/censor unconfirmed\n>>> transactions. Regardless if you are a miner or a validation/wallet node.\n>>> \n>>> 2) Peer censorship\n>>> MITM can remove or add entries from a \"addr\" message.\n>>> \n>>> 3) Fingerprinting\n>>> ISPs or any other MITM can intercept/inject fingerprinting relevant\n>>> messages like \"mempool\" to analyze the bitcoin network.\n>> \n>> Encryption alone cannot protect against a MITM attack in an anonymous and permissionless network. This is accepted in the BIP (and your follow-up reply).\n> \n> Being able to easily detect MITM attacks is a _huge_ step forward that\n> shouldn't be underestimated; even if 99% of users aren't in a position to\n> detect the MITM you only need a small subset of users that do the necessary\n> checks to alert the wider community, who can then respond with stronger\n> security measures. Those measures are likely to be more costly - authenticated\n> systems are significantly harder than not - so better to save your efforts\n> until the need for them is more obvious.\n> \n> Also the fact that an attack has a reasonable probability of detection is a big\n> disincentive for many types of attackers - note how one of the things revealed\n> in the Snowden leaks was the fact that the NSA generally tries quite hard to\n> avoid tipping off targets to the fact that they're being surveilled, with a\n> myriad of carefully scripted policies to control when and how exploits are used\n> against targets.\n> \n> -- \n> https://petertodd.org 'peter'[:-1]@petertodd.org"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-28T20:14:47",
                "message_text_only": "On Tue, Jun 28, 2016 at 08:35:26PM +0200, Eric Voskuil wrote:\n> Hi Peter,\n> \n> What in this BIP makes a MITM attack easier (or easy) to detect, or increases the probability of one being detected?\n\nBIP151 gives users the tools to detect a MITM attack.\n\nIt's kinda like PGP in that way: lots of PGP users don't properly check keys,\nso an attacker won't have a hard time MITM attacking those users. But some\nusers do check keys, a labor intensive manual process, but not a process that\nrequires any real cryptographic sophistication, let alone writing any code.\nIt's very difficult for widescale attackers to distinguish the users who do\ncheck keys from the ones that don't, so if you MITM attack _any_ user you run\nthe risk of running into one of the few that does check, and those users can\nalert everyone else.\n\nThe key thing, is we need to get everyones communications encrypted first: if\nwe don't the MITM attacker can intercept 99% of the communications with 0% risk\nof detection, because the non-sophisticated users are trivially distinguishable\nfrom the sophisticated users: just find the users with unencrypted\ncommunications!\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160628/a26f4f33/attachment-0001.sig>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-28T20:29:54",
                "message_text_only": "> On Jun 28, 2016, at 10:14 PM, Peter Todd <pete at petertodd.org> wrote:\n> \n>> On Tue, Jun 28, 2016 at 08:35:26PM +0200, Eric Voskuil wrote:\n>> Hi Peter,\n>> \n>> What in this BIP makes a MITM attack easier (or easy) to detect, or increases the probability of one being detected?\n> \n> BIP151 gives users the tools to detect a MITM attack.\n> \n> It's kinda like PGP in that way: lots of PGP users don't properly check keys,\n\nPGP requires a secure side channel for transmission of public keys. How does one \"check\" a key of an anonymous peer? I know you well enough to know you wouldn't trust a PGP key received over an insecure channel.\n\nAll you can prove is that you are talking to a peer and that communications in the session remain with that peer. The peer can be the attacker. As Jonas has acknowledged, authentication is required to actually guard against MITM attacks.\n\n> so an attacker won't have a hard time MITM attacking those users. But some\n> users do check keys, a labor intensive manual process, but not a process that\n> requires any real cryptographic sophistication, let alone writing any code.\n> It's very difficult for widescale attackers to distinguish the users who do\n> check keys from the ones that don't, so if you MITM attack _any_ user you run\n> the risk of running into one of the few that does check, and those users can\n> alert everyone else.\n> \n> The key thing, is we need to get everyones communications encrypted first: if\n> we don't the MITM attacker can intercept 99% of the communications with 0% risk\n> of detection, because the non-sophisticated users are trivially distinguishable from the sophisticated users: just find the users with unencrypted\n> communications!\n> \n> -- \n> https://petertodd.org 'peter'[:-1]@petertodd.org"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-28T20:36:05",
                "message_text_only": "On Tue, Jun 28, 2016 at 10:29:54PM +0200, Eric Voskuil wrote:\n> \n> \n> > On Jun 28, 2016, at 10:14 PM, Peter Todd <pete at petertodd.org> wrote:\n> > \n> >> On Tue, Jun 28, 2016 at 08:35:26PM +0200, Eric Voskuil wrote:\n> >> Hi Peter,\n> >> \n> >> What in this BIP makes a MITM attack easier (or easy) to detect, or increases the probability of one being detected?\n> > \n> > BIP151 gives users the tools to detect a MITM attack.\n> > \n> > It's kinda like PGP in that way: lots of PGP users don't properly check keys,\n> \n> PGP requires a secure side channel for transmission of public keys. How does one \"check\" a key of an anonymous peer? I know you well enough to know you wouldn't trust a PGP key received over an insecure channel.\n> \n> All you can prove is that you are talking to a peer and that communications in the session remain with that peer. The peer can be the attacker. As Jonas has acknowledged, authentication is required to actually guard against MITM attacks.\n\nEasy: anonymous peers aren't always actually anonymous.\n\nA MITM attacker can't easily distinguish communications between two nodes that\nrandomly picked their peers, and nodes that are connected because their\noperators manually used -addnode to peer; in the latter case the operators can\ncheck whether or not they're being attacked with an out-of-band key check.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160628/cbd12c6b/attachment.sig>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-28T21:22:23",
                "message_text_only": "> On Jun 28, 2016, at 10:36 PM, Peter Todd <pete at petertodd.org> wrote:\n> \n>> On Tue, Jun 28, 2016 at 10:29:54PM +0200, Eric Voskuil wrote:\n>> \n>> \n>>>> On Jun 28, 2016, at 10:14 PM, Peter Todd <pete at petertodd.org> wrote:\n>>>> \n>>>> On Tue, Jun 28, 2016 at 08:35:26PM +0200, Eric Voskuil wrote:\n>>>> Hi Peter,\n>>>> \n>>>> What in this BIP makes a MITM attack easier (or easy) to detect, or increases the probability of one being detected?\n>>> \n>>> BIP151 gives users the tools to detect a MITM attack.\n>>> \n>>> It's kinda like PGP in that way: lots of PGP users don't properly check keys,\n>> \n>> PGP requires a secure side channel for transmission of public keys. How does one \"check\" a key of an anonymous peer? I know you well enough to know you wouldn't trust a PGP key received over an insecure channel.\n>> \n>> All you can prove is that you are talking to a peer and that communications in the session remain with that peer. The peer can be the attacker. As Jonas has acknowledged, authentication is required to actually guard against MITM attacks.\n> \n> Easy: anonymous peers aren't always actually anonymous.\n> \n> A MITM attacker can't easily distinguish communications between two nodes that\n> randomly picked their peers, and nodes that are connected because their operators manually used -addnode to peer; in the latter case the operators can\n> check whether or not they're being attacked with an out-of-band key check.\n\nAn \"out of band key check\" is not part of BIP151. It requires a secure channel and is authentication. So BIP151 doesn't provide the tools to detect an attack, that requires authentication. A general requirement for authentication is the issue I have raised.\n\ne"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2016-06-28T21:36:00",
                "message_text_only": "On Tue, Jun 28, 2016 at 9:22 PM, Eric Voskuil via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> An \"out of band key check\" is not part of BIP151.\n\nIt has a session ID for this purpose.\n\n> It requires a secure channel and is authentication. So BIP151 doesn't provide the tools to detect an attack, that requires authentication. A general requirement for authentication is the issue I have raised.\n\nOne might wonder how you ever use a Bitcoin address, or even why we\nmight guess these emails from \"you\" aren't actually coming from the\nNSA."
            },
            {
                "author": "Cameron Garnham",
                "date": "2016-06-28T21:40:23",
                "message_text_only": "Unauthenticated link level encryption is wonderful! MITM attacks are overrated; as they require an active attacker.\n\nStopping passive attacks is the low hanging fruit. This should be taken first.\n\nAutomated and secure peer authentication in a mesh network is a huge topic. One of the unsolved problems in computer science.\n\nA simple 'who is that' by asking for the fingerprint of your peers from your other peers is a very simple way to get 'some' authentication.  Semi-trusted index nodes also is a low hanging fruit for authentication.\n\nHowever, let's first get unauthenticated encryption. Force the attackers to use active attacks. (That are thousands times more costly to couduct).\n\nSent from my iPhone\n\n> On 29 Jun 2016, at 00:36, Gregory Maxwell via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> On Tue, Jun 28, 2016 at 9:22 PM, Eric Voskuil via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> An \"out of band key check\" is not part of BIP151.\n> \n> It has a session ID for this purpose.\n> \n>> It requires a secure channel and is authentication. So BIP151 doesn't provide the tools to detect an attack, that requires authentication. A general requirement for authentication is the issue I have raised.\n> \n> One might wonder how you ever use a Bitcoin address, or even why we\n> might guess these emails from \"you\" aren't actually coming from the\n> NSA.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160629/436fe397/attachment-0001.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-28T22:07:45",
                "message_text_only": "Hi Cameron, good to hear from you!\n\n> On Jun 28, 2016, at 11:40 PM, Cameron Garnham <da2ce7 at gmail.com> wrote:\n> \n> Unauthenticated link level encryption is wonderful! MITM attacks are overrated; as they require an active attacker.\n\nThis is not really the case with Bitcoin. A MITM attack does not require that the attacker find a way to inject traffic into the communication between nodes. Peers will connect to the attacker directly, or accept connections directly from it. Such attacks can be easier than even passive attacks.\n\n> Stopping passive attacks is the low hanging fruit. This should be taken first.\n> \n> Automated and secure peer authentication in a mesh network is a huge topic. One of the unsolved problems in computer science.\n> \n> A simple 'who is that' by asking for the fingerprint of your peers from your other peers is a very simple way to get 'some' authentication.  Semi-trusted index nodes also is a low hanging fruit for authentication.\n\nIt is the implication of widespread authentication that is at issue. Clearly there are ways to implement it using a secure side channels.\n\n> However, let's first get unauthenticated encryption. Force the attackers to use active attacks. (That are thousands times more costly to couduct).\n> \n> Sent from my iPhone\n> \n>> On 29 Jun 2016, at 00:36, Gregory Maxwell via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> \n>> On Tue, Jun 28, 2016 at 9:22 PM, Eric Voskuil via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> An \"out of band key check\" is not part of BIP151.\n>> \n>> It has a session ID for this purpose.\n>> \n>>> It requires a secure channel and is authentication. So BIP151 doesn't provide the tools to detect an attack, that requires authentication. A general requirement for authentication is the issue I have raised.\n>> \n>> One might wonder how you ever use a Bitcoin address, or even why we\n>> might guess these emails from \"you\" aren't actually coming from the\n>> NSA.\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160629/5fb01d58/attachment.html>"
            },
            {
                "author": "Cameron Garnham",
                "date": "2016-06-28T22:33:35",
                "message_text_only": "There are two different topics mixed up here.\n\n1. Link-level security (secure connection to the node we intended to connect to).\n\n2. Node-level security (aka; don't connect to a 'evil node').\n\nThe fist requires link-level encryption and authentication.\n\nThe second requires identity authentication.\n\nYou described the 'evil node' attack; that indeed needs an identity system to stop. However BIP151 doesn't intend to protect against connecting to evil Bitcoin Nodes.\n\nIt is important not to mixup link-level authentication and node-level authentication.\n\nWhen your client picks random nodes to connect to, you are not considered whom in particular runs them. (Rather that you have a good random sample of the network).\n\nIf you manually add a friends node; at this point you wish to have node-level authentication.  However, this may (and probably should) happen out-of-band.\n\n\nSent from my iPhone\n\n> On 29 Jun 2016, at 01:07, Eric Voskuil <eric at voskuil.org> wrote:\n> \n> Hi Cameron, good to hear from you!\n> \n>> On Jun 28, 2016, at 11:40 PM, Cameron Garnham <da2ce7 at gmail.com> wrote:\n>> \n>> Unauthenticated link level encryption is wonderful! MITM attacks are overrated; as they require an active attacker.\n> \n> This is not really the case with Bitcoin. A MITM attack does not require that the attacker find a way to inject traffic into the communication between nodes. Peers will connect to the attacker directly, or accept connections directly from it. Such attacks can be easier than even passive attacks.\n> \n>> Stopping passive attacks is the low hanging fruit. This should be taken first.\n>> \n>> Automated and secure peer authentication in a mesh network is a huge topic. One of the unsolved problems in computer science.\n>> \n>> A simple 'who is that' by asking for the fingerprint of your peers from your other peers is a very simple way to get 'some' authentication.  Semi-trusted index nodes also is a low hanging fruit for authentication.\n> \n> It is the implication of widespread authentication that is at issue. Clearly there are ways to implement it using a secure side channels.\n> \n>> However, let's first get unauthenticated encryption. Force the attackers to use active attacks. (That are thousands times more costly to couduct).\n>> \n>> Sent from my iPhone\n>> \n>>> On 29 Jun 2016, at 00:36, Gregory Maxwell via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> \n>>> On Tue, Jun 28, 2016 at 9:22 PM, Eric Voskuil via bitcoin-dev\n>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>> An \"out of band key check\" is not part of BIP151.\n>>> \n>>> It has a session ID for this purpose.\n>>> \n>>>> It requires a secure channel and is authentication. So BIP151 doesn't provide the tools to detect an attack, that requires authentication. A general requirement for authentication is the issue I have raised.\n>>> \n>>> One might wonder how you ever use a Bitcoin address, or even why we\n>>> might guess these emails from \"you\" aren't actually coming from the\n>>> NSA.\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160629/49c7f475/attachment-0001.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-28T23:29:10",
                "message_text_only": "Your description of the two scenarios reduces to one. They both require authentication, and if you intend to connect to potentially evil nodes you aren't securing anything with link level security except the knowledge that your potentially evil node connection remains so.\n\ne\n\n> On Jun 29, 2016, at 12:33 AM, Cameron Garnham <da2ce7 at gmail.com> wrote:\n> \n> \n> There are two different topics mixed up here.\n> \n> 1. Link-level security (secure connection to the node we intended to connect to).\n> \n> 2. Node-level security (aka; don't connect to a 'evil node').\n> \n> The fist requires link-level encryption and authentication.\n> \n> The second requires identity authentication.\n> \n> You described the 'evil node' attack; that indeed needs an identity system to stop. However BIP151 doesn't intend to protect against connecting to evil Bitcoin Nodes.\n> \n> It is important not to mixup link-level authentication and node-level authentication.\n> \n> When your client picks random nodes to connect to, you are not considered whom in particular runs them. (Rather that you have a good random sample of the network).\n> \n> If you manually add a friends node; at this point you wish to have node-level authentication.  However, this may (and probably should) happen out-of-band.\n> \n> \n> Sent from my iPhone\n> \n>> On 29 Jun 2016, at 01:07, Eric Voskuil <eric at voskuil.org> wrote:\n>> \n>> Hi Cameron, good to hear from you!\n>> \n>>> On Jun 28, 2016, at 11:40 PM, Cameron Garnham <da2ce7 at gmail.com> wrote:\n>>> \n>>> Unauthenticated link level encryption is wonderful! MITM attacks are overrated; as they require an active attacker.\n>> \n>> This is not really the case with Bitcoin. A MITM attack does not require that the attacker find a way to inject traffic into the communication between nodes. Peers will connect to the attacker directly, or accept connections directly from it. Such attacks can be easier than even passive attacks.\n>> \n>>> Stopping passive attacks is the low hanging fruit. This should be taken first.\n>>> \n>>> Automated and secure peer authentication in a mesh network is a huge topic. One of the unsolved problems in computer science.\n>>> \n>>> A simple 'who is that' by asking for the fingerprint of your peers from your other peers is a very simple way to get 'some' authentication.  Semi-trusted index nodes also is a low hanging fruit for authentication.\n>> \n>> It is the implication of widespread authentication that is at issue. Clearly there are ways to implement it using a secure side channels.\n>> \n>>> However, let's first get unauthenticated encryption. Force the attackers to use active attacks. (That are thousands times more costly to couduct).\n>>> \n>>> Sent from my iPhone\n>>> \n>>>> On 29 Jun 2016, at 00:36, Gregory Maxwell via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>> \n>>>> On Tue, Jun 28, 2016 at 9:22 PM, Eric Voskuil via bitcoin-dev\n>>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>> An \"out of band key check\" is not part of BIP151.\n>>>> \n>>>> It has a session ID for this purpose.\n>>>> \n>>>>> It requires a secure channel and is authentication. So BIP151 doesn't provide the tools to detect an attack, that requires authentication. A general requirement for authentication is the issue I have raised.\n>>>> \n>>>> One might wonder how you ever use a Bitcoin address, or even why we\n>>>> might guess these emails from \"you\" aren't actually coming from the\n>>>> NSA.\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160629/5343f305/attachment.html>"
            },
            {
                "author": "Nick ODell",
                "date": "2016-06-29T00:06:41",
                "message_text_only": ">They both require authentication,\n\nYeah, but not the same *sort* of authentication. As a trivial example,\nyou could have ten servers that sign long-term keys for nodes. All\nthat they need to check is that the node requesting a signature owns\nthe corresponding IP address. On the other hand, 'evil nodes' is a\nsubjective quality that is hard to assess automatically.\n\n>and if you intend to connect to potentially evil nodes you aren't securing anything\n\nBitcoin is designed with the assumption that some of the nodes you\nconnect to might be evil. Sure, if 100% of the nodes you're connected\nto are evil, you're screwed. However, we shouldn't avoid protecting\npeople from someone on the same coffee-shop network, just because the\nsame mitigation won't work against a nation-state.\n\nOn Tue, Jun 28, 2016 at 5:29 PM, Eric Voskuil via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Your description of the two scenarios reduces to one. They both require\n> authentication, and if you intend to connect to potentially evil nodes you\n> aren't securing anything with link level security except the knowledge that\n> your potentially evil node connection remains so.\n>\n> e\n>\n> On Jun 29, 2016, at 12:33 AM, Cameron Garnham <da2ce7 at gmail.com> wrote:\n>\n>\n> There are two different topics mixed up here.\n>\n> 1. Link-level security (secure connection to the node we intended to connect\n> to).\n>\n> 2. Node-level security (aka; don't connect to a 'evil node').\n>\n> The fist requires link-level encryption and authentication.\n>\n> The second requires identity authentication.\n>\n> You described the 'evil node' attack; that indeed needs an identity system\n> to stop. However BIP151 doesn't intend to protect against connecting to evil\n> Bitcoin Nodes.\n>\n> It is important not to mixup link-level authentication and node-level\n> authentication.\n>\n> When your client picks random nodes to connect to, you are not considered\n> whom in particular runs them. (Rather that you have a good random sample of\n> the network).\n>\n> If you manually add a friends node; at this point you wish to have\n> node-level authentication.  However, this may (and probably should) happen\n> out-of-band.\n>\n>\n> Sent from my iPhone\n>\n> On 29 Jun 2016, at 01:07, Eric Voskuil <eric at voskuil.org> wrote:\n>\n> Hi Cameron, good to hear from you!\n>\n> On Jun 28, 2016, at 11:40 PM, Cameron Garnham <da2ce7 at gmail.com> wrote:\n>\n> Unauthenticated link level encryption is wonderful! MITM attacks are\n> overrated; as they require an active attacker.\n>\n>\n> This is not really the case with Bitcoin. A MITM attack does not require\n> that the attacker find a way to inject traffic into the communication\n> between nodes. Peers will connect to the attacker directly, or accept\n> connections directly from it. Such attacks can be easier than even passive\n> attacks.\n>\n> Stopping passive attacks is the low hanging fruit. This should be taken\n> first.\n>\n> Automated and secure peer authentication in a mesh network is a huge topic.\n> One of the unsolved problems in computer science.\n>\n> A simple 'who is that' by asking for the fingerprint of your peers from your\n> other peers is a very simple way to get 'some' authentication.  Semi-trusted\n> index nodes also is a low hanging fruit for authentication.\n>\n>\n> It is the implication of widespread authentication that is at issue. Clearly\n> there are ways to implement it using a secure side channels.\n>\n> However, let's first get unauthenticated encryption. Force the attackers to\n> use active attacks. (That are thousands times more costly to couduct).\n>\n> Sent from my iPhone\n>\n> On 29 Jun 2016, at 00:36, Gregory Maxwell via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> On Tue, Jun 28, 2016 at 9:22 PM, Eric Voskuil via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> An \"out of band key check\" is not part of BIP151.\n>\n>\n> It has a session ID for this purpose.\n>\n> It requires a secure channel and is authentication. So BIP151 doesn't\n> provide the tools to detect an attack, that requires authentication. A\n> general requirement for authentication is the issue I have raised.\n>\n>\n> One might wonder how you ever use a Bitcoin address, or even why we\n> might guess these emails from \"you\" aren't actually coming from the\n> NSA.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-28T21:59:54",
                "message_text_only": "> On Jun 28, 2016, at 11:36 PM, Gregory Maxwell <greg at xiph.org> wrote:\n> \n> On Tue, Jun 28, 2016 at 9:22 PM, Eric Voskuil via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> An \"out of band key check\" is not part of BIP151.\n> \n> It has a session ID for this purpose.\n\nPassing the session ID out of band is authentication. As this is explicitly not part of BIP151 it cannot be that BIP151 provides the tools to detect a attack (the point at issue).\n\n>> It requires a secure channel and is authentication. So BIP151 doesn't provide the tools to detect an attack, that requires authentication. A general requirement for authentication is the issue I have raised.\n> \n> One might wonder how you ever use a Bitcoin address, or even why we might guess these emails from \"you\" aren't actually coming from the NSA.\n\nThe sarcasm is counterproductive Greg. By the same token I could ask how you ever use Bitcoin given that the P2P protocol is not encrypted or authenticated.\n\nIt doesn't matter who I am, maybe I am the NSA. I don't argue from a position of authority. Signing my emails while traveling on holiday with only my phone gets a little tedious.\n\nThe blockchain and mempool are a cache of public data. Transmission of a payment address to a payer is not a comparable scenario.\n\nThe possibility that authentication may become required to participate in this trustless network is a legitimate concern, and one that has not been addressed.\n\ne"
            },
            {
                "author": "Jonas Schnelli",
                "date": "2016-06-28T20:06:58",
                "message_text_only": ">> In my opinion, the question should be \"why would you _not_ encrypt\".\n> \n> 1) creation of a false sense of security\n\nFalse sense of security is mostly a communication issue.\nBIP151 does focus on encryption (not trust).\n\nAre users aware of the fact that ISP/WiFi-Providers can track their\nbitcoin spending (if they use SPV+BF) and link it with other internet\ntraffic or sell the data to anyone who is interested to do correlation?\n\nAre node operators aware of the possibilities that ISPs/Data-Centers,\netc. can hold back peers, etc.?\n\nIf there is a false sense of security/anonymity, then we are already\ndeep into this territory.\nBIP151 was designed as a puzzle-pice towards better security and better\ncensorship resistance. You shouldn't project all sorts of \"false sense\nof security\" into BIP151. Is a stepping stone towards greater security.\n\n> 2) as a tradeoff against anonymity\n\nCan you point out the tradeoffs?\nBIP151 does not introduce fingerprinting possibilities.\n\n> 3) benefit does not justify cost\n\nCan you elaborate the costs?\n[Extremely simplified]: we need 300 lines of code from openssh\n(ChaCha20-Poly1305 at openssl) and some ECDH magic (already in\nBitcoin-Cores codebase) together with two or three (maybe payed)\ncryptoanalysis once the implementation is done.\n\n\n>> There are plenty of other options to solve this problem. stunnel,\n>> Bernsteins CurveCP, VPN, etc. which are available since years.\n>> But the reality has shown that most bitcoin traffic is still unencrypted.\n> \n> The question arises from concern over the security of the network in the case where encryption (and therefore authentication) is pervasive.\n> \n> As you point out, anyone can set up a private network of nodes today. These nodes must also connect to the permissionless network to maintain the chain. These nodes constitute a trust zone within Bitcoin. This zone of exclusion operates as a single logical node from the perspective of the Bitcoin security model (one entity controls the validation rules for all nodes).\n> \n> Widespread application of this model is potentially problematic. It is a non-trivial problem to design a distributed system that requires authentication but without identity and without central control. In fact this may be more challenging than Bitcoin itself. Trust on first use (TOFU) does not solve this problem.\n\nYes. There is no plan to adopt a TUFO scheme. Bip151 does not use TUFO\nit does not cover \"trust\" (It just encrypt all traffic).\n\nImaging Bip151 together with a simple form of preshared EC key\nauthentication (nonce signing or similar). You could drastically\nincrease the security/censor-resistance-properties between nodes where\nowners have preshared identity keys (with nodes I also mean SPV/wallet\nnodes).\n\nAnd I guess there are plenty of awesome identity management system ideas\ntied or not tied to the Bitcoin blockchain out there.\nThis is also a reason to not cover trust/authentication/identity in BIP151.\nIt is  possible to have multiple authentication schemes.\n\n> In my opinion this question has not received sufficient consideration to warrant proceeding with a network encryption scheme (which concerns me as well, but as I consider it premature I won't comment).\n\nYes. I think nobody have started implementing BIP151. It's a draft BIP\nand I think it's still okay and great that we have this discussion.\n\nBIP151 hopefully has started some brainwork in how encryption and\nauthentication could work in Bitcoin and I'm happy to deprecate BIP151\nif we have found a better solution or if we come to a point where we\nagree that BIP151 does make the network security worse.\n\n>> Example: IIRC non of the available SPV wallets can \"speak\" on of the\n>> possible encryption techniques. Encrypting traffic below the application\n>> layer is extremely hard to set up for non-experienced users.\n> \n> Bloom filters can (and IMO should) be isolated from the P2P protocol. Also, if the proposal creates an insecurity its ease of deployment is moot.\n\nIf we assume increasing amount of novice users starting with Bitcoin\nevery day, how should these users run wallets without increasing\ncentralization by using webwallets or client/central-server wallets?\n(which is OT, but an interesting question)\n\n>> On top of that, encryption allows us to drop the SHA256 checksum per p2p\n>> message which should result in a better performance on the network layer\n>> once BIP151 is deployed.\n> \n> I would not consider this a performance enhancing proposal. Simply dropping the checksum seems like a better option. But again, it is moot if it creates an insecurity.\n> \n>> I agree that BIP151 _must_ be deployed together with an authentication\n>> scheme (I'm working on that) to protect again MITM during encryption\n>> initialization.\n> \n> At a minimum I would propose that you modify BIP151 to declare a dependency on a future BIP, making BIP151 incomplete without it. I think we can agree that it would be unadvisable to deploy (and therefore to implement) encryption alone.\n\nI think BIP151 does what it says: encryption and laying groundwork for\nauthentication.\nYou wouldn't probably say BIP32 is incomplete because it does not cover\na scheme how to recover funds (or BIP141 [SW consensus] is incomplete\nbecause it does not cover p2p [BIP144]).\n\nThe missing MITM protection (solvable over auth) is prominent mentioned\nin the BIP [1].\n\n\n(from your other mail):\n>> I don't see reasons why BIP151 could weaken the security of the P2P network. Can you point out some specific concerns?\n> \n> TOFU cannot prevent MITM attacks (the goal of the encryption). Authentication requires a secure (trusted) side channel by which to distribute public keys. This presents what I consider a significant problem. If widespread, control over this distribution network would constitute control over who can use Bitcoin.\n> The effort to prevent censorship could actually enable it. I don't think it would get that far. Someone would point this out in the process of vetting the authentication BIP, and the result would be the scrapping of BIP151.\n\nI agree that the secure trusted 2nd channel key-sharing problem can be\nsignificant for large networks and/or connecting to unknown identities.\n\nBut as said, there could be multiple ways of sharing identity keys.\nIf you want to connect your node to serval other trusted nodes, you can\nsimply physically preshare keys or do it over GPG / Signal App, etc..\n\nAnd if I have followed the news correctly, there are some clever guys\nworking on various internet of trust 2.0 proposals...\n\n>>\n>> BIP151 does not rely on identities. BIP151 does not use persisted keys\n>> (only ephemeral keys).\n> \n> BIP 151 is incomplete without authentication.\n\nI would agree if you would say, _trusted encryption_ is incomplete with\nauthentication. But IMO BIP151 is complete and should be deployed\ntogether with one or multiple authentication schemes.\n\n\n[1] https://github.com/bitcoin/bips/blob/master/bip-0151.mediawiki#risks\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 819 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160628/3748c989/attachment.sig>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-28T23:31:19",
                "message_text_only": "On Jun 28, 2016, at 10:06 PM, Jonas Schnelli <dev at jonasschnelli.ch> wrote:\n\n>>> In my opinion, the question should be \"why would you _not_ encrypt\".\n>> \n>> 1) creation of a false sense of security\n> \n> False sense of security is mostly a communication issue.\n> BIP151 does focus on encryption (not trust).\n> \n> Are users aware of the fact that ISP/WiFi-Providers can track their\n> bitcoin spending (if they use SPV+BF) and link it with other internet\n> traffic or sell the data to anyone who is interested to do correlation?\n\nThe relevant question would be to ask whether encryption would prevent an ISP from doing so (which it would not). This is a good example of false sense of security.\n\n> Are node operators aware of the possibilities that ISPs/Data-Centers,\n> etc. can hold back peers, etc.?\n> \n> If there is a false sense of security/anonymity, then we are already\n> deep into this territory.\n> BIP151 was designed as a puzzle-pice towards better security and better\n> censorship resistance. You shouldn't project all sorts of \"false sense\n> of security\" into BIP151. Is a stepping stone towards greater security.\n\nFWIW I was just answering your question comprehensively. Relationship to BIP151 is incidental (though apparently applicable).\n\nKeep in mind my specific concern is not with the design of BIP151, it is with the implication of its dependency on an unspecified authentication proposal.\n\n>> 2) as a tradeoff against anonymity\n> \n> Can you point out the tradeoffs?\n> BIP151 does not introduce fingerprinting possibilities.\n\nThe security tradeoff would arise from widespread deployment of authentication - which is necessary to make encryption useful against envisioned MITM attacks. See my previous discussion of trust zones below.\n\n>> 3) benefit does not justify cost\n> \n> Can you elaborate the costs?\n> [Extremely simplified]: we need 300 lines of code from openssh\n> (ChaCha20-Poly1305 at openssl) and some ECDH magic (already in\n> Bitcoin-Cores codebase) together with two or three (maybe payed)\n> cryptoanalysis once the implementation is done.\n\nSimply put, any code that is unnecessary does not justify its cost.\n\n>>> There are plenty of other options to solve this problem. stunnel,\n>>> Bernsteins CurveCP, VPN, etc. which are available since years.\n>>> But the reality has shown that most bitcoin traffic is still unencrypted.\n>> \n>> The question arises from concern over the security of the network in the case where encryption (and therefore authentication) is pervasive.\n>> \n>> As you point out, anyone can set up a private network of nodes today. These nodes must also connect to the permissionless network to maintain the chain. These nodes constitute a trust zone within Bitcoin. This zone of exclusion operates as a single logical node from the perspective of the Bitcoin security model (one entity controls the validation rules for all nodes).\n>> \n>> Widespread application of this model is potentially problematic. It is a non-trivial problem to design a distributed system that requires authentication but without identity and without central control. In fact this may be more challenging than Bitcoin itself. Trust on first use (TOFU) does not solve this problem.\n> \n> Yes. There is no plan to adopt a TUFO scheme. Bip151 does not use TUFO\n> it does not cover \"trust\" (It just encrypt all traffic).\n\nTOFU (trust on first use) was a reference to what was discussed on IRC as a potential solution to the (deferred) authentication problem. I didn't mean to imply that it was part of BIP151.\n\n> Imaging Bip151 together with a simple form of preshared EC key\n> authentication (nonce signing or similar). You could drastically\n> increase the security/censor-resistance-properties between nodes where\n> owners have preshared identity keys (with nodes I also mean SPV/wallet\n> nodes).\n\nThis is a restatement of what I have accepted as a premise - that authentication, and as such, key distribution, will be a necessary part of making any encryption scheme effective. \"Preshared\" implies a secure side channel for key distribution.\n\n> And I guess there are plenty of awesome identity management system ideas\n> tied or not tied to the Bitcoin blockchain out there.\n> This is also a reason to not cover trust/authentication/identity in BIP151.\n> It is  possible to have multiple authentication schemes.\n\nWhether or not there are multiple schemes is not relevant to the point I have raised. The issue is that authentication is necessary.\n\n>> In my opinion this question has not received sufficient consideration to warrant proceeding with a network encryption scheme (which concerns me as well, but as I consider it premature I won't comment).\n> \n> Yes. I think nobody have started implementing BIP151. It's a draft BIP\n> and I think it's still okay and great that we have this discussion.\n> \n> BIP151 hopefully has started some brainwork in how encryption and\n> authentication could work in Bitcoin and I'm happy to deprecate BIP151 if we have found a better solution or if we come to a point where we agree that BIP151 does make the network security worse.\n\nWe should contemplate what the distributed permissionless network of anonymous peers looks like once every node authenticates every one of its peers using one or more key distribution side channels.\n\n>>> Example: IIRC non of the available SPV wallets can \"speak\" on of the\n>>> possible encryption techniques. Encrypting traffic below the application\n>>> layer is extremely hard to set up for non-experienced users.\n>> \n>> Bloom filters can (and IMO should) be isolated from the P2P protocol. Also, if the proposal creates an insecurity its ease of deployment is moot.\n> \n> If we assume increasing amount of novice users starting with Bitcoin every day, how should these users run wallets without increasing centralization by using webwallets or client/central-server wallets?\n> (which is OT, but an interesting question)\n\nI fully appreciate the significant security risk arising from the proliferation of web wallets. This can only be resolved by people validating using code under their own control.\n\nEncryption/authentication are orthogonal to this question, assuming people have wallets directly attached to full nodes. Remoting a wallet from a full node does not require use of the P2P protocol, and can use encryption/authentication without the concerns I've raised. It properly places the trust boundary around a wallet and its trusted node(s), as opposed to spanning (independent) nodes.\n\n>>> On top of that, encryption allows us to drop the SHA256 checksum per p2p\n>>> message which should result in a better performance on the network layer\n>>> once BIP151 is deployed.\n>> \n>> I would not consider this a performance enhancing proposal. Simply dropping the checksum seems like a better option. But again, it is moot if it creates an insecurity.\n>> \n>>> I agree that BIP151 _must_ be deployed together with an authentication\n>>> scheme (I'm working on that) to protect again MITM during encryption\n>>> initialization.\n>> \n>> At a minimum I would propose that you modify BIP151 to declare a dependency on a future BIP, making BIP151 incomplete without it. I think we can agree that it would be unadvisable to deploy (and therefore to implement) encryption alone.\n> \n> I think BIP151 does what it says: encryption and laying groundwork for authentication.\n> You wouldn't probably say BIP32 is incomplete because it does not cover\n> a scheme how to recover funds (or BIP141 [SW consensus] is incomplete\n> because it does not cover p2p [BIP144]).\n\nThis is an unfair statement. You have acknowledged that BIP151 requires authentication to accomplish its sole objective.\n\n> The missing MITM protection (solvable over auth) is prominent mentioned in the BIP [1].\n\nAs I pointed out.\n\n> (from your other mail):\n>>> I don't see reasons why BIP151 could weaken the security of the P2P network. Can you point out some specific concerns?\n>> \n>> TOFU cannot prevent MITM attacks (the goal of the encryption). Authentication requires a secure (trusted) side channel by which to distribute public keys. This presents what I consider a significant problem. If widespread, control over this distribution network would constitute control over who can use Bitcoin.\n>> The effort to prevent censorship could actually enable it. I don't think it would get that far. Someone would point this out in the process of vetting the authentication BIP, and the result would be the scrapping of BIP151.\n> \n> I agree that the secure trusted 2nd channel key-sharing problem can be significant for large networks and/or connecting to unknown identities.\n> \n> But as said, there could be multiple ways of sharing identity keys.\n> If you want to connect your node to serval other trusted nodes, you can simply physically preshare keys or do it over GPG / Signal App, etc..\n\nAgain, it's the fact that authentication is required that produces the issue, not that there are multiple ways to implement it.\n\n> And if I have followed the news correctly, there are some clever guys\n> working on various internet of trust 2.0 proposals...\n\nI don't see how this is relevant.\n\n>>> BIP151 does not rely on identities. BIP151 does not use persisted keys\n>>> (only ephemeral keys).\n>> \n>> BIP 151 is incomplete without authentication.\n> \n> I would agree if you would say, _trusted encryption_ is incomplete with\n> authentication. But IMO BIP151 is complete and should be deployed together with one or multiple authentication schemes.\n\nIt seems that we are talking past each other. You haven't yet addressed the issue that I have raised.\n\nIt is the requirement for authentication of any node that any other node may wish to connect to that is the issue. We end up with something that looks like WoT or PKI. And if not fully controlled by PKI (so using WoT) we will have hybrid nodes that accept untrusted connections and propagate information between trusted and untrusted nodes.\n\n> [1] https://github.com/bitcoin/bips/blob/master/bip-0151.mediawiki#risks\n>"
            },
            {
                "author": "Alfie John",
                "date": "2016-06-29T11:17:28",
                "message_text_only": "On Tue, Jun 28, 2016 at 06:45:58PM +0200, Eric Voskuil via bitcoin-dev wrote:\n> > then we should definitively use a form of end-to-end encryption between\n> > nodes. Built into the network layer.\n> \n> Widespread application of this model is potentially problematic. It is a\n> non-trivial problem to design a distributed system that requires authentication\n> but without identity and without central control. In fact this may be more\n> challenging than Bitcoin itself. Trust on first use (TOFU) does not solve this\n> problem.\n\nMaybe the following paper can feed into this discussion:\n\n  \"Decentralized Anonymous Credentials\" by Christina Garman, Matthew Green, Ian Miers\n\thttps://eprint.iacr.org/2013/622.pdf\n\nAlfie\n\n-- \nAlfie John\nhttps://www.alfie.wtf"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-30T11:56:42",
                "message_text_only": "Hi Alfie,\n\nYes, this is exactly what I meant. The complexity of the proposed construction is comparable to that of Bitcoin itself. This is not itself prohibitive, but it is clearly worthy of consideration.\n\nA question we should ask is whether decentralized anonymous credentials is applicable to the authentication problem posed by BIP151. I propose that it is not.\n\nThe core problem posed by BIP151 is a MITM attack. The implied solution (BIP151 + authentication) requires that a peer trusts that another is not an attacker. \n\nAuthentication of an anonymous peer cannot achieve this objective, since the peer may be anyone and an attack on privacy can be undetectable. The identity of a peer must be known to the relying peer, either directly or transitively.\n\nDAC is applicable in cases where identity is never required.  The prime example in the paper is that of first-come-first-served name registration. No identity is required in that scenario, just proof that a party in question is the original registrant. All participants are presumed to be \"good\".\n\nI believe that a distributed anonymous system is fundamentally at odds with isolation of \"good\" vs. \"bad\" participants who comply with protocol rules (DoS considerations aside), and that any attempt to resolve this conflict will result in the system no longer allowing anonymous participation.\n\nI may be mistaken, but I haven't found a way out of this realization.\n\ne\n\n> On Jun 29, 2016, at 1:17 PM, Alfie John <alfie at alfie.wtf> wrote:\n> \n> On Tue, Jun 28, 2016 at 06:45:58PM +0200, Eric Voskuil via bitcoin-dev wrote:\n>>> then we should definitively use a form of end-to-end encryption between\n>>> nodes. Built into the network layer.\n>> \n>> Widespread application of this model is potentially problematic. It is a\n>> non-trivial problem to design a distributed system that requires authentication\n>> but without identity and without central control. In fact this may be more\n>> challenging than Bitcoin itself. Trust on first use (TOFU) does not solve this\n>> problem.\n> \n> Maybe the following paper can feed into this discussion:\n> \n> \"Decentralized Anonymous Credentials\" by Christina Garman, Matthew Green, Ian Miers\n>   https://eprint.iacr.org/2013/622.pdf\n> \n> Alfie\n> \n> -- \n> Alfie John\n> https://www.alfie.wtf"
            },
            {
                "author": "Jonas Schnelli",
                "date": "2016-06-30T12:20:59",
                "message_text_only": "> Yes, this is exactly what I meant. The complexity of the proposed construction is comparable to that of Bitcoin itself. This is not itself prohibitive, but it is clearly worthy of consideration.\n> \n> A question we should ask is whether decentralized anonymous credentials is applicable to the authentication problem posed by BIP151. I propose that it is not.\n> \n> The core problem posed by BIP151 is a MITM attack. The implied solution (BIP151 + authentication) requires that a peer trusts that another is not an attacker. \n\nBIP151 would increase the risks for MITM attackers.\nWhat are the benefits for Mallory of he can't be sure Alice and Bob may\nknow that he is intercepting the channel?\n\nMITM is possible today, it would still be possible (though under higher\ncosts) with BIP151.\n\nWith BIP151 we would have the basic tool-set to effectively reduce the\nrisks of being MITMled.\n\nIMO we should focus on the risks and benefits of BIP151 and not drag\nthis discussion into the realm of authentication. This can and should be\ndone once we have proposals for authentication (and I'm sure this will\nbe a heated debate).\n\nThe only valid risk I have on my list from you, Eric, is the false sense\nof security.\n\nMy countermeasure for that would be...\n- deploy BIP151 together with the simplest form of authentication\n(know_hosts / authorized_keys file, no TOFU only editable \"by hand\")\n- make it more clear (in the BIP151 MOTIVATION text) that it won't solve\nthe privacy/MITM problem without additional authentication.\n\nOr could you elaborate again \u2013 without stepping into the realm of\nauthentication/MITM (which is not part of the BIP or possible already\ntoday) \u2013 why BIP151 would make things worse?\n\n</jonas>\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 819 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160630/ddefb09d/attachment.sig>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-30T12:27:30",
                "message_text_only": "> On Jun 30, 2016, at 2:20 PM, Jonas Schnelli <dev at jonasschnelli.ch> wrote:\n> \n> \n>> Yes, this is exactly what I meant. The complexity of the proposed construction is comparable to that of Bitcoin itself. This is not itself prohibitive, but it is clearly worthy of consideration.\n>> \n>> A question we should ask is whether decentralized anonymous credentials is applicable to the authentication problem posed by BIP151. I propose that it is not.\n>> \n>> The core problem posed by BIP151 is a MITM attack. The implied solution (BIP151 + authentication) requires that a peer trusts that another is not an attacker.\n> \n> BIP151 would increase the risks for MITM attackers.\n> What are the benefits for Mallory of he can't be sure Alice and Bob may\n> know that he is intercepting the channel?\n\nIt is not clear to me why you believe an attack on privacy by an anonymous peer is detectable.\n\n> MITM is possible today, it would still be possible (though under higher\n> costs) with BIP151.\n> \n> With BIP151 we would have the basic tool-set to effectively reduce the\n> risks of being MITMled.\n> \n> IMO we should focus on the risks and benefits of BIP151 and not drag\n> this discussion into the realm of authentication. This can and should be\n> done once we have proposals for authentication (and I'm sure this will\n> be a heated debate).\n> \n> The only valid risk I have on my list from you, Eric, is the false sense\n> of security.\n> \n> My countermeasure for that would be...\n> - deploy BIP151 together with the simplest form of authentication\n> (know_hosts / authorized_keys file, no TOFU only editable \"by hand\")\n> - make it more clear (in the BIP151 MOTIVATION text) that it won't solve\n> the privacy/MITM problem without additional authentication.\n> \n> Or could you elaborate again \u2013 without stepping into the realm of\n> authentication/MITM (which is not part of the BIP or possible already\n> today) \u2013 why BIP151 would make things worse?\n> \n> </jonas>\n>"
            },
            {
                "author": "Jonas Schnelli",
                "date": "2016-06-30T12:43:07",
                "message_text_only": ">>> The core problem posed by BIP151 is a MITM attack. The implied solution (BIP151 + authentication) requires that a peer trusts that another is not an attacker.\n>>\n>> BIP151 would increase the risks for MITM attackers.\n>> What are the benefits for Mallory of he can't be sure Alice and Bob may\n>> know that he is intercepting the channel?\n> \n> It is not clear to me why you believe an attack on privacy by an anonymous peer is detectable.\n\nIf Mallory has substituted the ephemeral keys in both directions, at the\npoint where Alice and Bob will do an authentication, they can be sure\nMallory is listening.\n\nSimple dummy example:\n1.) Encryption setup with ECDH with ephemeral keys after BIP151\n2.) Mallory is MITMling the connection. He is substituting both\ndirection with its own keys\n3.) Connection is successfully MITMled\n4.) Alice tells Bob \"prove me that you are Bob, please sign the\nsession-ID with your identity key\"\n5.) Bob signs the sessionID (ECDH secret) with his identity key which\nwill be unusable for Mallory who has a substituted sessionID in both\ndirections.\n6.) Alice has successfully detected the Mallory\n\nDisclaimer: 4) and 5) are _not_ authentication proposals :-)\n\n</jonas>\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 819 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160630/0920253c/attachment.sig>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-30T15:22:08",
                "message_text_only": "> On Jun 30, 2016, at 2:43 PM, Jonas Schnelli <dev at jonasschnelli.ch> wrote:\n> \n>>>> The core problem posed by BIP151 is a MITM attack. The implied solution (BIP151 + authentication) requires that a peer trusts that another is not an attacker.\n>>> \n>>> BIP151 would increase the risks for MITM attackers.\n>>> What are the benefits for Mallory of he can't be sure Alice and Bob may\n>>> know that he is intercepting the channel?\n>> \n>> It is not clear to me why you believe an attack on privacy by an anonymous peer is detectable.\n> \n> If Mallory has substituted the ephemeral keys in both directions, at the\n> point where Alice and Bob will do an authentication, they can be sure\n> Mallory is listening.\n\nI understand the mechanics of a tunnel between trusting parties that have a secure side channel. But this assumes that no other peer can connect to these two nodes. How then do they maintain the chain?\n\nThe \"middle\" in this sense does not have to be the wire directly between these two peers. It can be between either of them and any anonymous connection they (must) allow.\n\nOf course this creates pressure to expand their tunnel. Hence the problem of expanding node identity in an effort to preserve privacy. The protection will remain weak until the entire network is \"secure\". At that point it would necessarily be a private network.\n\nAs Pieter rightly observes, there are and always will be tunnels between trusting nodes. Often these are groups of nodes that are in collaboration, so logically they are one node from a system security standpoint. But if people become generally reliant on good node registration, it will become the registrar who controls access to the network. So my concern rests I this proposal becoming widely adopted.\n\n> Simple dummy example:\n> 1.) Encryption setup with ECDH with ephemeral keys after BIP151\n> 2.) Mallory is MITMling the connection. He is substituting both direction with its own keys\n> 3.) Connection is successfully MITMled\n> 4.) Alice tells Bob \"prove me that you are Bob, please sign the session-ID with your identity key\"\n> 5.) Bob signs the sessionID (ECDH secret) with his identity key which\n> will be unusable for Mallory who has a substituted sessionID in both directions.\n> 6.) Alice has successfully detected the Mallory\n> \n> Disclaimer: 4) and 5) are _not_ authentication proposals :-)\n> \n> </jonas>\n>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-30T16:52:27",
                "message_text_only": "On Thu, Jun 30, 2016 at 05:22:08PM +0200, Eric Voskuil via bitcoin-dev wrote:\n> \n> > On Jun 30, 2016, at 2:43 PM, Jonas Schnelli <dev at jonasschnelli.ch> wrote:\n> > \n> >>>> The core problem posed by BIP151 is a MITM attack. The implied solution (BIP151 + authentication) requires that a peer trusts that another is not an attacker.\n> >>> \n> >>> BIP151 would increase the risks for MITM attackers.\n> >>> What are the benefits for Mallory of he can't be sure Alice and Bob may\n> >>> know that he is intercepting the channel?\n> >> \n> >> It is not clear to me why you believe an attack on privacy by an anonymous peer is detectable.\n> > \n> > If Mallory has substituted the ephemeral keys in both directions, at the\n> > point where Alice and Bob will do an authentication, they can be sure\n> > Mallory is listening.\n> \n> I understand the mechanics of a tunnel between trusting parties that have a secure side channel. But this assumes that no other peer can connect to these two nodes. How then do they maintain the chain?\n> \n> The \"middle\" in this sense does not have to be the wire directly between these two peers. It can be between either of them and any anonymous connection they (must) allow.\n> \n> Of course this creates pressure to expand their tunnel. Hence the problem of expanding node identity in an effort to preserve privacy. The protection will remain weak until the entire network is \"secure\". At that point it would necessarily be a private network.\n> \n> As Pieter rightly observes, there are and always will be tunnels between trusting nodes. Often these are groups of nodes that are in collaboration, so logically they are one node from a system security standpoint. But if people become generally reliant on good node registration, it will become the registrar who controls access to the network. So my concern rests I this proposal becoming widely adopted.\n\nTo be clear, are you against Bitcoin Core's tor support?\n\nBecause node-to-node connections over tor are encrypted, and make use of onion\naddresses, which are self-authenticated in the exact same way as BIP151\nproposes. And we're shipping that in production as of 0.12.0, and by default\nTor onion support is enabled and will be automatically setup if you have a\nrecent version of Tor installed.\n\nDoes that \"create pressure to expand node identity\"?\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160630/8a16ac69/attachment.sig>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-30T18:25:45",
                "message_text_only": "> On Jun 30, 2016, at 6:52 PM, Peter Todd <pete at petertodd.org> wrote:\n> \n>> On Thu, Jun 30, 2016 at 05:22:08PM +0200, Eric Voskuil via bitcoin-dev wrote:\n>> \n>>> On Jun 30, 2016, at 2:43 PM, Jonas Schnelli <dev at jonasschnelli.ch> wrote:\n>>> \n>>>>>> The core problem posed by BIP151 is a MITM attack. The implied solution (BIP151 + authentication) requires that a peer trusts that another is not an attacker.\n>>>>> \n>>>>> BIP151 would increase the risks for MITM attackers.\n>>>>> What are the benefits for Mallory of he can't be sure Alice and Bob may\n>>>>> know that he is intercepting the channel?\n>>>> \n>>>> It is not clear to me why you believe an attack on privacy by an anonymous peer is detectable.\n>>> \n>>> If Mallory has substituted the ephemeral keys in both directions, at the\n>>> point where Alice and Bob will do an authentication, they can be sure\n>>> Mallory is listening.\n>> \n>> I understand the mechanics of a tunnel between trusting parties that have a secure side channel. But this assumes that no other peer can connect to these two nodes. How then do they maintain the chain?\n>> \n>> The \"middle\" in this sense does not have to be the wire directly between these two peers. It can be between either of them and any anonymous connection they (must) allow.\n>> \n>> Of course this creates pressure to expand their tunnel. Hence the problem of expanding node identity in an effort to preserve privacy. The protection will remain weak until the entire network is \"secure\". At that point it would necessarily be a private network.\n>> \n>> As Pieter rightly observes, there are and always will be tunnels between trusting nodes. Often these are groups of nodes that are in collaboration, so logically they are one node from a system security standpoint. But if people become generally reliant on good node registration, it will become the registrar who controls access to the network. So my concern rests I this proposal becoming widely adopted.\n> \n> To be clear, are you against Bitcoin Core's tor support?\n> \n> Because node-to-node connections over tor are encrypted, and make use of onion\n> addresses, which are self-authenticated in the exact same way as BIP151 proposes.\n\nBIP151 is self-admittedly insufficient to protect against a MITM attack. It proposes node identity to close this hole (future BIP required). The yet-to-be-specified requirement for node identity is the basis of my primary concern. This is not self-authentication.\n\n> And we're shipping that in production as of 0.12.0, and by default Tor onion support is enabled and will be automatically setup if you have a recent version of Tor installed.\n> \n> Does that \"create pressure to expand node identity\"?\n\nThe orthogonal question of whether Tor is safe for use with the Bitcoin P2P protocol is a matter of existing research.\n\ne"
            },
            {
                "author": "Peter Todd",
                "date": "2016-06-30T19:06:13",
                "message_text_only": "On Thu, Jun 30, 2016 at 08:25:45PM +0200, Eric Voskuil wrote:\n> > To be clear, are you against Bitcoin Core's tor support?\n> > \n> > Because node-to-node connections over tor are encrypted, and make use of onion\n> > addresses, which are self-authenticated in the exact same way as BIP151 proposes.\n> \n> BIP151 is self-admittedly insufficient to protect against a MITM attack. It proposes node identity to close this hole (future BIP required). The yet-to-be-specified requirement for node identity is the basis of my primary concern. This is not self-authentication.\n> \n> > And we're shipping that in production as of 0.12.0, and by default Tor onion support is enabled and will be automatically setup if you have a recent version of Tor installed.\n> > \n> > Does that \"create pressure to expand node identity\"?\n> \n> The orthogonal question of whether Tor is safe for use with the Bitcoin P2P protocol is a matter of existing research.\n\nI don't think you answered my question.\n\nAgain, we _already have_ the equivalent of BIP151 functionality in Bitcoin\nCore, shipping in production, but implemented with a Tor dependency.\n\nBIP151 removes that dependency on Tor, enabling encrypted connections\nregardless of whether or not you have Tor installed.\n\nSo any arguments against BIP151 being implemented, are equally arguments\nagainst our existing Tor onion support. Are you against that support? Because\nif you aren't, you can't have any objections to BIP151 being implemented\neither.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160630/6e23ac54/attachment.sig>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-30T20:26:48",
                "message_text_only": "> On Jun 30, 2016, at 9:06 PM, Peter Todd <pete at petertodd.org> wrote:\n> \n> On Thu, Jun 30, 2016 at 08:25:45PM +0200, Eric Voskuil wrote:\n>>> To be clear, are you against Bitcoin Core's tor support?\n>>> \n>>> Because node-to-node connections over tor are encrypted, and make use of onion\n>>> addresses, which are self-authenticated in the exact same way as BIP151 proposes.\n>> \n>> BIP151 is self-admittedly insufficient to protect against a MITM attack. It proposes node identity to close this hole (future BIP required). The yet-to-be-specified requirement for node identity is the basis of my primary concern. This is not self-authentication.\n>> \n>>> And we're shipping that in production as of 0.12.0, and by default Tor onion support is enabled and will be automatically setup if you have a recent version of Tor installed.\n>>> \n>>> Does that \"create pressure to expand node identity\"?\n>> \n>> The orthogonal question of whether Tor is safe for use with the Bitcoin P2P protocol is a matter of existing research.\n> \n> I don't think you answered my question.\n> \n> Again, we _already have_ the equivalent of BIP151 functionality in Bitcoin\n> Core, shipping in production, but implemented with a Tor dependency.\n> \n> BIP151 removes that dependency on Tor, enabling encrypted connections\n> regardless of whether or not you have Tor installed.\n> \n> So any arguments against BIP151 being implemented, are equally arguments\n> against our existing Tor onion support. Are you against that support? Because\n> if you aren't, you can't have any objections to BIP151 being implemented\n\nNeither Tor nor Bitcoin Core are part of this BIP (or its proposed dependency on node identity).\n\nBut again, given that node identity is not part of the Bitcoin Core Tor integration, my objection to the presumption of node identity by BIP151 is unrelated to Bitcoin Core's Tor integration.\n\ne"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2016-06-28T19:55:37",
                "message_text_only": "> I understand the use, when coupled with a yet-to-be-devised identity system, with Bloom filter features. Yet these features\n\nThis is a bit of a strawman, you've selected a single narrow usecase\nwhich isn't proposed by the BIP and then argue it is worthless. I\nagree that example doesn't have much value (and I believe that\neventually the BIP37 bloom filters should be removed from the\nprotocol).\n\nWithout something like BIP151 network participants cannot have privacy\nfor the transactions they originate within the protocol against\nnetwork observers. Even if, through some extraordinary effort, their\nown first hop is encrypted, unencrypted later hops would rapidly\nexpose significant information about transaction origins in the\nnetwork.\n\nWithout something like BIP151 authenticated links are not possible, so\nmanually curated links (addnode/connect) cannot be counted on to\nprovide protection against partitioning sybils.\n\nAlong the way BIP151 appears that it will actually make the protocol faster.\n\n> Given that the BIP relies on identity\n\nThis is untrue. The proposal is an ephemerally keyed opportunistic\nencryption system. The privacy against a network observer does not\ndepend on authentication, much less \"identity\".  And when used with\nauthentication at all it makes interception strongly detectable after\nthe fact.\n\n> The BIP does not [...] contemplate the significant problems associated with key distribution in any identity system\n\nBecause it does not propose any \"identity system\" or authorization\n(also, I object to your apparent characterization of authentication as\nas an 'identity system'-- do you also call Bitcoin addresses an\nidentity system?).\n\nThat said, manually maintaining adds nodes to your own and somewhat\ntrusted nodes is a recommend best practice for miners and other high\nvalue systems which is rendered much less effective due to a lack of\nauthentication, there is no significant key distribution problem in\nthat case, and I expect the future auth BIP (Jonas had one before, but\nit was put aside for now to first focus on the link layer encryption)\nto address that case quite well."
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-28T23:33:53",
                "message_text_only": "On Jun 28, 2016, at 9:55 PM, Gregory Maxwell via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>> I understand the use, when coupled with a yet-to-be-devised identity system, with Bloom filter features. Yet these features\n> \n> This is a bit of a strawman, you've selected a single narrow usecase which isn't proposed by the BIP and then argue it is worthless. I agree that example doesn't have much value (and I believe that\n> eventually the BIP37 bloom filters should be removed from the protocol).\n\nI don't follow this comment. The BIP aims quite clearly at \"SPV\" wallets as its justifying scenario.\n\n> Without something like BIP151 network participants cannot have privacy for the transactions they originate within the protocol against network observers.\n\nAnd they won't get it with BIP151 either. Being a peer is easier than observing the network. If one can observe the encrypted traffic one can certainly use a timing attack to determine what the node has sent.\n\n> Even if, through some extraordinary effort, their own first hop is encrypted, unencrypted later hops would rapidly\n> expose significant information about transaction origins in the network.\n\nAs will remain the case until all connections are encrypted and authenticated, and all participants are known to be good guys. Starting to sound like PKI?\n\n> Without something like BIP151 authenticated links are not possible, so\n> manually curated links (addnode/connect) cannot be counted on to provide protection against partitioning sybils.\n\nIf we trust the manual links we don't need/want the other links. In fact retaining the other links enables the attack you described above. Of course there is no need to worry about Sybil attacks when all of your peers are authenticated. But again, let us not ignore the problems of requiring all peers on the network be authenticated.\n\n> Along the way BIP151 appears that it will actually make the protocol faster.\n> \n>> Given that the BIP relies on identity\n> \n> This is untrue. The proposal is an ephemerally keyed opportunistic\n> encryption system. The privacy against a network observer does not depend on authentication, much less \"identity\".  And when used with authentication at all it makes interception strongly detectable after the fact.\n\nMaybe I was insufficiently explicit. By \"relies on identity\" I meant that the BIP is not effective without it. I did not mean to imply that the BIP itself implements an identity scheme. I thought this was clear from the context.\n\n>> The BIP does not [...] contemplate the significant problems associated with key distribution in any identity system\n> \n> Because it does not propose any \"identity system\" or authorization (also, I object to your apparent characterization of authentication as as an 'identity system'-- do you also call Bitcoin addresses an identity system?).\n\nPlease read more carefully what I wrote. I did not characterize authentication as an identity system. I proposed that key distribution has significant problems, and used identity systems as an example of systems with such problems. I could just have easily written \"authentication systems\", (and probably should have).\n\n> That said, manually maintaining adds nodes to your own and somewhat trusted nodes is a recommend best practice for miners and other high value systems which is rendered much less effective due to a lack of\n> authentication, there is no significant key distribution problem in that case\n\nThis is the only legitimate scenario that I am aware of. Doing this by IP address (as we do) is weak if there is no VPN.\n\nYet this scenario is very different than general authentication. This scenario is a set of nodes that is essentially a single logical node from the perspective of the Bitcoin security model. One entity controls the validation rules, or is collaborating with another entity to do so.\n\nMy concern is that a general authentication requirement expands this single logical node and gives control over if to the entity that controls key distribution - the hard problem that hasn't been addressed.\n\nIf there is no such entity restricting access to the network (which hopefully we can assume) then there is no reason to expect any effective improvement, since nodes will necessarily have to connect with anonymous peers. Anyone with a node and the ability to monitor traffic should remain very effective.\n\n> and I expect the future auth BIP (Jonas had one before, but it was put aside for now to first focus on the link layer encryption)\n> to address that case quite well.\n\nDefining an auth implementation is not a hard problem, nor is it the concern I have raised.\n\ne"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2016-06-29T01:01:50",
                "message_text_only": "On Tue, Jun 28, 2016 at 11:33 PM, Eric Voskuil <eric at voskuil.org> wrote:\n> I don't follow this comment. The BIP aims quite clearly at \"SPV\" wallets as its justifying scenario.\n\nIt cites SPV as an example, doesn't mention bloom filters.. and sure--\nsounds like the bip text should make the\n\n>> Without something like BIP151 network participants cannot have privacy for the transactions they originate within the protocol against network observers.\n>\n> And they won't get it with BIP151 either. Being a peer is easier than observing the network.\n\nNot passively, undetectable, and against thousands of users at once at low cost.\n\n> If one can observe the encrypted traffic one can certainly use a timing attack to determine what the node has sent.\n\nNot against Bitcoin Core, transactions are batched and relayed in\nsorted order.  (obviously there are limits at what this provides;\nironically, the lack of link encryption has been used to argue against\nprivacy preserving relay behavior)\n\n>> Even if, through some extraordinary effort, their own first hop is encrypted, unencrypted later hops would rapidly\n>> expose significant information about transaction origins in the network.\n>\n> As will remain the case until all connections are encrypted and authenticated, and all participants are known to be good guys. Starting to sound like PKI?\n\nHuh? The first and subsequent hops obscures the origin and timing.\n\n>> Without something like BIP151 authenticated links are not possible, so\n>> manually curated links (addnode/connect) cannot be counted on to provide protection against partitioning sybils.\n>\n> If we trust the manual links we don't need/want the other links. In fact retaining the other links enables the attack you described above. Of course there is no need to worry about Sybil attacks when all of your peers are authenticated. But again, let us not ignore the problems of requiring all peers on the network be authenticated.\n\nDon't need and want them for what?  For _partitioning_ resistance,\nyou are not partitioned if you have one honest connection to the\nfunctional network. Additional peers purely reduce your partition\nvulnerability-- so long as an active network attacker isn't\nitercepting all your connections out.\n\nFor privacy, you have improve transaction privacy so long as your\ntransaction isn't initially relayed to a malicious peer-- but\nmalicious peers can lie further out because transit nodes obscure the\norder of message creation.  Bitcoin Core currently relays transactions\nfirst and more frequently to outbound and whitelisted peers.\n\n> Maybe I was insufficiently explicit. By \"relies on identity\" I meant that the BIP is not effective without it. I did not mean to imply that the BIP itself implements an identity scheme. I thought this was clear from the context.\n\nI understood that, but my point was that Bitcoin cannot be used at\nall_unless users have secure communication channels to share\naddresses.\n\n> then there is no reason to expect any effective improvement, since nodes will necessarily have to connect with anonymous peers.\n\nThey're not required to _only_ connect with anonymous peers. And\npartition resistance requires that you have any one good link.\n\n> Anyone with a node and the ability to monitor traffic should remain very effective.\n\nNot via passive observation.\n\n> Defining an auth implementation is not a hard problem, nor is it the concern I have raised.\n\nGlad you agree.\n\nWe seem to be looping now. Feel free to not implement this proposal,\nno one suggests making it mandatory."
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-30T09:57:02",
                "message_text_only": "On Jun 29, 2016, at 3:01 AM, Gregory Maxwell <greg at xiph.org> wrote:\n> \n>> On Tue, Jun 28, 2016 at 11:33 PM, Eric Voskuil <eric at voskuil.org> wrote:\n>> I don't follow this comment. The BIP aims quite clearly at \"SPV\" wallets as its justifying scenario.\n> \n> It cites SPV as an example, doesn't mention bloom filters.. and sure-- sounds like the bip text should make the\n\n\"MOTIVATION:\nThe Bitcoin network does not encrypt communication between peers today. This opens up security issues (eg: traffic manipulation by others) and allows for mass surveillance / analysis of bitcoin users. Mostly this is negligible because of the nature of Bitcoins trust model, however for SPV nodes this can have significant privacy impacts [1] and could reduce the censorship-resistance of a peer.\"\n\nThis is not an example, this is the exception that is described as \"significant\" in comparison to the other issues, which are described as \"negligible\".\n\nThe Bloom filters messages are of course the unique aspects of the protocol as it pertains to \"SPV\".\n\nThe RISKS section declares that the BIP cannot prevent MITM attacks and that \"identity authentication\" will  be defined in a forthcoming BIP.\n\nThe obvious implication (accepted by the author) is that authentication is required to prevent a MITM attack, and furthermore establishment of identity will be required to ensure that the authenticated party is not a bad actor.\n\n>>> Without something like BIP151 network participants cannot have privacy for the transactions they originate within the protocol against network observers.\n>> \n>> And they won't get it with BIP151 either. Being a peer is easier than observing the network.\n> \n> Not passively, undetectable, and against thousands of users at once at low cost.\n\nThis is a straw man, as the BIP does not state that its objective is to moderately raise the cost of passive attack against large numbers of users.\n\nIt is also a red herring, as passivity is not itself a benefit. It implies that the attack is easier and therefore less costly. But a trivial active attack may be a larger security problem than a complex passive attack. Attacks against privacy under this BIP (and with authentication) can be carried out by passively monitoring traffic and operating one or more nodes. Operating a node may be considered \"active\" because the node communicates, but technically it is not. In either case the activeness itself hardly raises the difficulty, especially for a global (thousands of users) passive attacker.\n\nDepending on the attacker, cost may not be an issue at all, so raising it can have zero effect. Certainly we are not talking about prohibitive (cryptographically hard) cost. Raising the cost *any* amount is not likely a reasonable cost-benefit tradeoff.\n\nPrivacy attacks would remain entirely undetectable under this proposal, and under any additional proposal that required authentication in the absence of identity. Only with all users of the network identified as \"good\" would such proposals be effective. Until that point any bad actors can become an integral part of the network. I will investigate the question of identity in a follow-up to an independent post.\n\n>> If one can observe the encrypted traffic one can certainly use a timing attack to determine what the node has sent.\n> \n> Not against Bitcoin Core, transactions are batched and relayed in\n> sorted order.  (obviously there are limits at what this provides;\n> ironically, the lack of link encryption has been used to argue against\n> privacy preserving relay behavior)\n\nIt cannot be both impossible (\"not against Bitcoin Core\") and limited in effectiveness (\"obviously there are limits\").\n\nWe should be clear at this point that the transaction-posting security provided against a privacy attack, based on the assumption of \"good\" (identified) peers in the first few hops, derives entirely from the ability of the good peers to break the timing attack, which is itself \"limited\".\n\nThis is a compound pair of weak assumptions, that to be made stronger will require widespread use of identity (not just authentication).\n\nThe proliferation of node identity is my primary concern - this relates to privacy and the security of the network. Secondarily I am concerned about users operating under a false assumption about the strength of privacy. Thirdly I am concerned about the risk of vulnerability introduced by the integration into the P2P network layer of an totally new network security scheme. Fourthly I'm concerned about the cost of the above based on the belief that the benefit may not be material and that it may lead to increased centralization.\n\n>>> Even if, through some extraordinary effort, their own first hop is encrypted, unencrypted later hops would rapidly\n>>> expose significant information about transaction origins in the network.\n>> \n>> As will remain the case until all connections are encrypted and authenticated, and all participants are known to be good guys. Starting to sound like PKI?\n> \n> Huh? The first and subsequent hops obscures the origin and timing.\n\nDescribed as \"limited\" in effectiveness, and clearly useful only if these hops are not attacker nodes.\n\nSo back to my comment on how we maintain a pool of \"good\" nodes for people to connect to, and raising the question of how effective is this strategy (which is itself unspecified and so cannot be assumed to even exist in the context of the BIP).\n\n>>> Without something like BIP151 authenticated links are not possible, so\n>>> manually curated links (addnode/connect) cannot be counted on to provide protection against partitioning sybils.\n>> \n>> If we trust the manual links we don't need/want the other links. In fact retaining the other links enables the attack you described above. Of course there is no need to worry about Sybil attacks when all of your peers are authenticated. But again, let us not ignore the problems of requiring all peers on the network be authenticated.\n> \n> Don't need and want them for what?  For _partitioning_ resistance,\n> you are not partitioned if you have one honest connection to the\n> functional network. Additional peers purely reduce your partition vulnerability-- so long as an active network attacker isn't\n> intercepting all your connections out.\n\nDon't want them as peers for the purpose of tx relay. As I said this, \"enables the attack you described above.\"\n\n> For privacy, you have improve transaction privacy so long as your\n> transaction isn't initially relayed to a malicious peer-- but\n> malicious peers can lie further out because transit nodes obscure the\n> order of message creation.  Bitcoin Core currently relays transactions\n> first and more frequently to outbound and whitelisted peers.\n\nThis whitelisting is simply a stand-in for a more formal identity system. One doesn't whitelist anonymous peers, one whitelists peers controlled by trusted parties. Preferring trusted peers is another aspect of trying to break the timing attack. So I would lump this under the same analysis as above (batching).\n\n>> Maybe I was insufficiently explicit. By \"relies on identity\" I meant that the BIP is not effective without it. I did not mean to imply that the BIP itself implements an identity scheme. I thought this was clear from the context.\n> \n> I understood that, but my point was that Bitcoin cannot be used at all_unless users have secure communication channels to share addresses.\n\nThis is true but not relevant. The parties with whom we transact are not in the same space as the nodes with which we connect. The fact that I am face-to-face with a counterparty does not help me find a \"good\" node, nor does my ability to PGP email a payment address or to send a stealth address in the clear.\n\nBut the fact that you raise this point is itself instructive. The solution that was devised to resolve the problem of verifying that a counterparty is who one thinks it is ended up being based on the use of certificate authorities - despite the fact the the BIP did not require this. Some people consider this extremely dangerous for Bitcoin, enough so that Peter Todd recently proposed scrapping the BIP.\n\nIt's not clear to me how the Bitcoin community intends to establish what nodes are good nodes. But one thing is certain, any anonymous node may be an undetectable attacker.\n\n>> then there is no reason to expect any effective improvement, since nodes will necessarily have to connect with anonymous peers.\n> \n> They're not required to _only_ connect with anonymous peers. And partition resistance requires that you have any one good link.\n\nAs a minimum requirement, it implies that only need only to connect to one or more \"good\" peers. Anonymous peers are gravy for partition resistance, yet they are potential attackers for tx tainting. In other words the logical topology is to only connect to good peers. That is a problem.\n\n>> Anyone with a node and the ability to monitor traffic should remain very effective.\n> \n> Not via passive observation.\n\nSee above commentary on the irrelevance of this distinction.\n\n>> Defining an auth implementation is not a hard problem, nor is it the concern I have raised.\n> \n> Glad you agree.\n\nI don't get your point here. It seems like you are just trying to antagonize.\n\n> We seem to be looping now. Feel free to not implement this proposal,\n\nAt this point I think it's fair for me to say that nobody needs your permission.\n\n> no one suggests making it mandatory.\n\nHave you ever debated an optional feature proposal?\n\ne"
            },
            {
                "author": "Pieter Wuille",
                "date": "2016-06-30T13:03:18",
                "message_text_only": "On Thu, Jun 30, 2016 at 11:57 AM, Eric Voskuil via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> The proliferation of node identity is my primary concern - this relates to privacy and the security of the network.\n\nI think this is a reasonable concern.\n\nHowever, node identity is already being used widely, and in a very\ninadvisable way:\n* Since forever there have been lists of 'good nodes' to pass in\naddnode= configuration options.\n* Various people run multiple nodes in different geographic locations,\npeering with each other.\n* Various pieces of infrastructure exist that relies on connecting to\nwell-behaving nodes (miner relay networks, large players peering\ndirectly with each other, ...)\n* Several lightweight clients support configuring a trusted host to connect to.\n\nPerhaps you deplore that fact, but I believe it is inevitable that\ndifferent pieces of the network will make different choices here. You\ncan'tg prevent people from create connections along preexisting trust\nlines. That does not mean that the network as a whole relies on first\nestablishing trust everywhere.\n\nAnd I do think there are advantages.\n\nBIP 151 on its own gives you opportunistic encryption. You're very\nright to point out that this does not give you protection from active\nattackers, and that active attacking is relatively easy through sybil\nattacks. I still prefer my attacker to actually do that over just\nlistening in on my connection. And yes, we should also work on\nimproving the privacy nodes and wallets have orthogonal to encryption,\nbut nothing will make everything perfectly private.\n\nBIP 151 plus a simple optional pre-shared-secret authentication\nextension can improve upon pure IP-based authentication, as well as\nsimplify things like SSL tunnels, and onion addresses purely used as\nidentity. This will still require explicit configuration, but not more\nthan now.\n\nBIP 151 plus a non-leaking public key authentication scheme (where\npeers can query \"are you the peer with pubkey X?\" but don't learn\nanything if the answer is no) with keys specific to the IP addresses\ncan give a TOFU-like security. Nodes already remember IP addresses\nthey've succesfully interacted with in the past, and ban IP addresses\nthat misbehave. Being able to tell whether a node you connect to is\nthe same as one you've connected to before is a natural extension of\nthis, and does not require establishing any real-world identity beyond\nwhat we're already implicitly relying on.\n\nPerhaps these use cases and their security assumptions should be\nspelled out more clearly in the BIP. If there is a misunderstanding,\nit should be clearly stated that BIP 151 is only a building block for\nfurther improvements\n\n> Secondarily I am concerned about users operating under a false assumption about the strength of privacy.\n\nThis is a widespread problem, but it exists far outside the scope of\nthis proposal. The privacy properties of Bitcoin are often\nmisrepresented and even used as advertizements. The solution is\neducation, not avoiding improvements because they may be\nmisunderstood.\n\n> The complexity of the proposed construction is comparable to that of Bitcoin itself.\n\nI really think this is an exaggeration. It's a diffie-hellman\nhandshake and a stream cipher (both very common constructions), that\napply to individual connections. There are no consensus risks nor a\nrequirement for coordinated change through the network. The\ncryptographic code can be directly reused from a well-known project\n(OpenSSH), and is very small in size.\n\n-- \nPieter"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-30T15:10:52",
                "message_text_only": "Pieter, these are in my opinion very reasonable positions. I've made some observations inline.\n\n> On Jun 30, 2016, at 3:03 PM, Pieter Wuille <pieter.wuille at gmail.com> wrote:\n> \n> On Thu, Jun 30, 2016 at 11:57 AM, Eric Voskuil via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> The proliferation of node identity is my primary concern - this relates to privacy and the security of the network.\n> \n> I think this is a reasonable concern.\n> \n> However, node identity is already being used widely, and in a very\n> inadvisable way:\n> * Since forever there have been lists of 'good nodes' to pass in\n> addnode= configuration options.\n> * Various people run multiple nodes in different geographic locations,\n> peering with each other.\n> * Various pieces of infrastructure exist that relies on connecting to\n> well-behaving nodes (miner relay networks, large players peering\n> directly with each other, ...)\n\nYes, libbitcoin also provides these options on an IP basis.\n\n> * Several lightweight clients support configuring a trusted host to connect to.\n\nI explicitly exclude client-server behavior as I believe the proper resolution is to isolate clients from the P2P protocol. Libbitcoin does this already.\n\n> Perhaps you deplore that fact, but I believe it is inevitable that different pieces of the network will make different choices here. You can't prevent people from create connections along preexisting trust lines. That does not mean that the network as a whole relies on first establishing trust everywhere.\n\nOf course, the network operates just fine without universal trust. My concern is not that it is required, but that it may grow significantly and will have a tendency to gravitate towards more effective registration mechanisms for what is a \"good\" peer. Even an informal but pervasive web of trust may make it difficult for untrusted parties to connect.\n\n> And I do think there are advantages.\n> \n> BIP 151 on its own gives you opportunistic encryption. You're very right to point out that this does not give you protection from active attackers, and that active attacking is relatively easy through sybil attacks. I still prefer my attacker to actually do that over just listening in on my connection.\n\nWe agree, and the ease of this attack must be acknowledged. And given that the protection is weak it is not unreasonable to consider the potential downside of creeping node identity.\n\n> And yes, we should also work on improving the privacy nodes and wallets have orthogonal to encryption, but nothing will make everything perfectly private.\n\nI agree, and I doubt this proposal will have much impact on an advanced persistent threat, or even lesser threats. People should understand that there is both a risk and a limited benefit to this proposal.\n\n> BIP 151 plus a simple optional pre-shared-secret authentication extension can improve upon pure IP-based authentication, as well as simplify things like SSL tunnels, and onion addresses purely used as identity. This will still require explicit configuration, but not more than now.\n\nI agree - I consider tunneling the legitimate use case for this proposal. Yet when nodes become closely coupled they are not fully independent. I have a concern with these practices being promoted for general use while at the same time being strongly implemented.\n\n> BIP 151 plus a non-leaking public key authentication scheme (where peers can query \"are you the peer with pubkey X?\" but don't learn anything if the answer is no) with keys specific to the IP addresses can give a TOFU-like security. Nodes already remember IP addresses they've succesfully interacted with in the past, and ban IP addresses that misbehave. Being able to tell whether a node you connect to is the same as one you've connected to before is a natural extension of this,\n\nWith this I disagree. There is no way to know that a node is one you have connected to previously unless that node wants you to know (apart from relying on the IP address). This is of no value in detecting misbehaving nodes that do not want to be detected. Ones that don't care (eg broken nodes) can be sufficiently managed by IP address.\n\n> and does not require establishing any real-world identity beyond what we're already implicitly relying on.\n> \n> Perhaps these use cases and their security assumptions should be spelled out more clearly in the BIP.\n\nAbsolutely.\n\n> If there is a misunderstanding, it should be clearly stated that BIP 151 is only a building block for further improvements\n> \n>> Secondarily I am concerned about users operating under a false assumption about the strength of privacy.\n> \n> This is a widespread problem, but it exists far outside the scope of this proposal. The privacy properties of Bitcoin are often\n> misrepresented and even used as advertizements. The solution is education, not avoiding improvements because they may be misunderstood.\n\nYes, let's not make it worse. This is a secondary concern. I remain primarily concerned about growth of node identity in a vain attempt to make transaction submission private in the P2P protocol (and to patch the other client-server features, specifically Bloom filters). As you imply, we cannot stop people from turning Bitcoin into a private network - but let's not facilitate it either.\n\n>> The complexity of the proposed construction is comparable to that of Bitcoin itself.\n> \n> I really think this is an exaggeration. It's a diffie-hellman handshake and a stream cipher (both very common constructions), that apply to individual connections. There are no consensus risks nor a\n> requirement for coordinated change through the network. The\n> cryptographic code can be directly reused from a well-known project\n> (OpenSSH), and is very small in size.\n\nI believe you have misinterpreted my comments on distributed anonymous credentials (and the like) as commentary on the construction of BIP151 (and a subsequent auth proposal). As such your observation that it is exaggerated would make sense, but it is not what I intended. Encryption and auth are straightforward. Preventing bad nodes from participating in an anonymous distributed system is not.\n\ne"
            },
            {
                "author": "Erik Aronesty",
                "date": "2016-06-30T13:36:57",
                "message_text_only": "I agree.\n\nEncrypting links in a network without identity doesn't really seem to help\nenough for the costs to be justified.\n\nI would like to see a PGP-like \"web of trust\" proposal for both the\nsecurity of the bitcoin network itself /and/ (eventually) of things like\ntransmission of bitcoin addresses.\n\nSomething where nodes of any kind (full, spv, mobile wallets) can\n/optionally/ accumulate trust over time and are capable of verifying the\nidentity of other nodes in that web.\n\n*Then* you can slap an encryption layer on top of it.   Once you have\nidentity & P2P verified pub keys for nodes, encryption becomes easy.\n\n\nOn Thu, Jun 30, 2016 at 5:57 AM, Eric Voskuil via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Jun 29, 2016, at 3:01 AM, Gregory Maxwell <greg at xiph.org> wrote:\n> >\n> >> On Tue, Jun 28, 2016 at 11:33 PM, Eric Voskuil <eric at voskuil.org>\n> wrote:\n> >> I don't follow this comment. The BIP aims quite clearly at \"SPV\"\n> wallets as its justifying scenario.\n> >\n> > It cites SPV as an example, doesn't mention bloom filters.. and sure--\n> sounds like the bip text should make the\n>\n> \"MOTIVATION:\n> The Bitcoin network does not encrypt communication between peers today.\n> This opens up security issues (eg: traffic manipulation by others) and\n> allows for mass surveillance / analysis of bitcoin users. Mostly this is\n> negligible because of the nature of Bitcoins trust model, however for SPV\n> nodes this can have significant privacy impacts [1] and could reduce the\n> censorship-resistance of a peer.\"\n>\n> This is not an example, this is the exception that is described as\n> \"significant\" in comparison to the other issues, which are described as\n> \"negligible\".\n>\n> The Bloom filters messages are of course the unique aspects of the\n> protocol as it pertains to \"SPV\".\n>\n> The RISKS section declares that the BIP cannot prevent MITM attacks and\n> that \"identity authentication\" will  be defined in a forthcoming BIP.\n>\n> The obvious implication (accepted by the author) is that authentication is\n> required to prevent a MITM attack, and furthermore establishment of\n> identity will be required to ensure that the authenticated party is not a\n> bad actor.\n>\n> >>> Without something like BIP151 network participants cannot have privacy\n> for the transactions they originate within the protocol against network\n> observers.\n> >>\n> >> And they won't get it with BIP151 either. Being a peer is easier than\n> observing the network.\n> >\n> > Not passively, undetectable, and against thousands of users at once at\n> low cost.\n>\n> This is a straw man, as the BIP does not state that its objective is to\n> moderately raise the cost of passive attack against large numbers of users.\n>\n> It is also a red herring, as passivity is not itself a benefit. It implies\n> that the attack is easier and therefore less costly. But a trivial active\n> attack may be a larger security problem than a complex passive attack.\n> Attacks against privacy under this BIP (and with authentication) can be\n> carried out by passively monitoring traffic and operating one or more\n> nodes. Operating a node may be considered \"active\" because the node\n> communicates, but technically it is not. In either case the activeness\n> itself hardly raises the difficulty, especially for a global (thousands of\n> users) passive attacker.\n>\n> Depending on the attacker, cost may not be an issue at all, so raising it\n> can have zero effect. Certainly we are not talking about prohibitive\n> (cryptographically hard) cost. Raising the cost *any* amount is not likely\n> a reasonable cost-benefit tradeoff.\n>\n> Privacy attacks would remain entirely undetectable under this proposal,\n> and under any additional proposal that required authentication in the\n> absence of identity. Only with all users of the network identified as\n> \"good\" would such proposals be effective. Until that point any bad actors\n> can become an integral part of the network. I will investigate the question\n> of identity in a follow-up to an independent post.\n>\n> >> If one can observe the encrypted traffic one can certainly use a timing\n> attack to determine what the node has sent.\n> >\n> > Not against Bitcoin Core, transactions are batched and relayed in\n> > sorted order.  (obviously there are limits at what this provides;\n> > ironically, the lack of link encryption has been used to argue against\n> > privacy preserving relay behavior)\n>\n> It cannot be both impossible (\"not against Bitcoin Core\") and limited in\n> effectiveness (\"obviously there are limits\").\n>\n> We should be clear at this point that the transaction-posting security\n> provided against a privacy attack, based on the assumption of \"good\"\n> (identified) peers in the first few hops, derives entirely from the ability\n> of the good peers to break the timing attack, which is itself \"limited\".\n>\n> This is a compound pair of weak assumptions, that to be made stronger will\n> require widespread use of identity (not just authentication).\n>\n> The proliferation of node identity is my primary concern - this relates to\n> privacy and the security of the network. Secondarily I am concerned about\n> users operating under a false assumption about the strength of privacy.\n> Thirdly I am concerned about the risk of vulnerability introduced by the\n> integration into the P2P network layer of an totally new network security\n> scheme. Fourthly I'm concerned about the cost of the above based on the\n> belief that the benefit may not be material and that it may lead to\n> increased centralization.\n>\n> >>> Even if, through some extraordinary effort, their own first hop is\n> encrypted, unencrypted later hops would rapidly\n> >>> expose significant information about transaction origins in the\n> network.\n> >>\n> >> As will remain the case until all connections are encrypted and\n> authenticated, and all participants are known to be good guys. Starting to\n> sound like PKI?\n> >\n> > Huh? The first and subsequent hops obscures the origin and timing.\n>\n> Described as \"limited\" in effectiveness, and clearly useful only if these\n> hops are not attacker nodes.\n>\n> So back to my comment on how we maintain a pool of \"good\" nodes for people\n> to connect to, and raising the question of how effective is this strategy\n> (which is itself unspecified and so cannot be assumed to even exist in the\n> context of the BIP).\n>\n> >>> Without something like BIP151 authenticated links are not possible, so\n> >>> manually curated links (addnode/connect) cannot be counted on to\n> provide protection against partitioning sybils.\n> >>\n> >> If we trust the manual links we don't need/want the other links. In\n> fact retaining the other links enables the attack you described above. Of\n> course there is no need to worry about Sybil attacks when all of your peers\n> are authenticated. But again, let us not ignore the problems of requiring\n> all peers on the network be authenticated.\n> >\n> > Don't need and want them for what?  For _partitioning_ resistance,\n> > you are not partitioned if you have one honest connection to the\n> > functional network. Additional peers purely reduce your partition\n> vulnerability-- so long as an active network attacker isn't\n> > intercepting all your connections out.\n>\n> Don't want them as peers for the purpose of tx relay. As I said this,\n> \"enables the attack you described above.\"\n>\n> > For privacy, you have improve transaction privacy so long as your\n> > transaction isn't initially relayed to a malicious peer-- but\n> > malicious peers can lie further out because transit nodes obscure the\n> > order of message creation.  Bitcoin Core currently relays transactions\n> > first and more frequently to outbound and whitelisted peers.\n>\n> This whitelisting is simply a stand-in for a more formal identity system.\n> One doesn't whitelist anonymous peers, one whitelists peers controlled by\n> trusted parties. Preferring trusted peers is another aspect of trying to\n> break the timing attack. So I would lump this under the same analysis as\n> above (batching).\n>\n> >> Maybe I was insufficiently explicit. By \"relies on identity\" I meant\n> that the BIP is not effective without it. I did not mean to imply that the\n> BIP itself implements an identity scheme. I thought this was clear from the\n> context.\n> >\n> > I understood that, but my point was that Bitcoin cannot be used at\n> all_unless users have secure communication channels to share addresses.\n>\n> This is true but not relevant. The parties with whom we transact are not\n> in the same space as the nodes with which we connect. The fact that I am\n> face-to-face with a counterparty does not help me find a \"good\" node, nor\n> does my ability to PGP email a payment address or to send a stealth address\n> in the clear.\n>\n> But the fact that you raise this point is itself instructive. The solution\n> that was devised to resolve the problem of verifying that a counterparty is\n> who one thinks it is ended up being based on the use of certificate\n> authorities - despite the fact the the BIP did not require this. Some\n> people consider this extremely dangerous for Bitcoin, enough so that Peter\n> Todd recently proposed scrapping the BIP.\n>\n> It's not clear to me how the Bitcoin community intends to establish what\n> nodes are good nodes. But one thing is certain, any anonymous node may be\n> an undetectable attacker.\n>\n> >> then there is no reason to expect any effective improvement, since\n> nodes will necessarily have to connect with anonymous peers.\n> >\n> > They're not required to _only_ connect with anonymous peers. And\n> partition resistance requires that you have any one good link.\n>\n> As a minimum requirement, it implies that only need only to connect to one\n> or more \"good\" peers. Anonymous peers are gravy for partition resistance,\n> yet they are potential attackers for tx tainting. In other words the\n> logical topology is to only connect to good peers. That is a problem.\n>\n> >> Anyone with a node and the ability to monitor traffic should remain\n> very effective.\n> >\n> > Not via passive observation.\n>\n> See above commentary on the irrelevance of this distinction.\n>\n> >> Defining an auth implementation is not a hard problem, nor is it the\n> concern I have raised.\n> >\n> > Glad you agree.\n>\n> I don't get your point here. It seems like you are just trying to\n> antagonize.\n>\n> > We seem to be looping now. Feel free to not implement this proposal,\n>\n> At this point I think it's fair for me to say that nobody needs your\n> permission.\n>\n> > no one suggests making it mandatory.\n>\n> Have you ever debated an optional feature proposal?\n>\n> e\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160630/c7b1a867/attachment-0001.html>"
            },
            {
                "author": "Alfie John",
                "date": "2016-06-30T14:47:34",
                "message_text_only": "On Thu, Jun 30, 2016 at 09:36:57AM -0400, Erik Aronesty via bitcoin-dev wrote:\n> Encrypting links in a network without identity doesn't really seem to help\n> enough for the costs to be justified.\n\nPassive is still better than none.\n\n> I would like to see a PGP-like \"web of trust\" proposal for both the\n> security of the bitcoin network itself /and/ (eventually) of things like\n> transmission of bitcoin addresses.\n\nThere already exists an unutilised WoT of \"good\" actors within the network -\nminers via the coinbase transaction. Bootstrapping their own \"trusted\" pool of\nIP addresses would be possible via the 100 bytes coinbase script.\n\n> *Then* you can slap an encryption layer on top of it.   Once you have\n> identity & P2P verified pub keys for nodes, encryption becomes easy.\n\nA miner's WoT will give you this.\n\nAlfie\n\n-- \nAlfie John\nhttps://www.alfie.wtf"
            },
            {
                "author": "Jonas Schnelli",
                "date": "2016-06-28T12:13:27",
                "message_text_only": "Hi Eric\n\nSorry for not directly addressing your points.\nI try to be more precise in this follow up email:\n\n> I understand the use, when coupled with a yet-to-be-devised identity system, with Bloom filter features. Yet these features are client-server in nature. Libbitcoin (for example) supports client-server features on an independent port (and implements a variant of CurveCP for encryption and identity). My concern arises with application of identity to the P2P protocol (excluding Bloom filter features).\n\nI think the bloom filter SPV usecase is not \"pure client-server\". SPV\nclients could request from/broadcast to multiple \"trusted nodes\".\nTrusted nodes could be nodes where the operators have shared\nidentities/keys in advance over a different channel.\n\nFurther private p2p extensions (lets say a p2p form of the estimatefee\ncommand) are something which needs to be discussed first and not\nsomething that is encouraged or outlined in BIP151.\n\n> It seems to me that the desire to secure against the weaknesses of BF is being casually generalized to the P2P network. That generalization may actually weaken the security of the P2P protocol. One might consider the proper resolution is to move the BF features to a client-server protocol.\n\nI don't see reasons why BIP151 could weaken the security of the P2P\nnetwork. Can you point out some specific concerns?\n\n\n> The BIP does not make a case for other scenarios, or contemplate the significant problems associated with key distribution in any identity system. Given that the BIP relies on identity, these considerations should be fully vetted before heading down another blind alley.\n\nBIP151 does not rely on identities. BIP151 does not use persisted keys\n(only ephemeral keys). The authentication/identity system needs to be\ndescribed in a another BIP.\nBut correct, BIP151 without a form of authentication/identity management\nis vulnerable to all sorts of MITM attacks and that's why I think BIP151\nmust be deployed together with an p2p authentication scheme.\n\nScope creeping and the risks of overspecifying is the main reason to\nfocus on the \"pure encryption part\" in BIP151.\n\nThanks\n---\n</jonas>\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 819 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160628/404f4808/attachment.sig>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-28T17:39:41",
                "message_text_only": "continued from previous post...\n\n> On Jun 28, 2016, at 2:13 PM, Jonas Schnelli via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Hi Eric\n> \n> Sorry for not directly addressing your points.\n\nNo problem. Thanks for the detailed replies.\n\n> I try to be more precise in this follow up email:\n> \n>> I understand the use, when coupled with a yet-to-be-devised identity system, with Bloom filter features. Yet these features are client-server in nature. Libbitcoin (for example) supports client-server features on an independent port (and implements a variant of CurveCP for encryption and identity). My concern arises with application of identity to the P2P protocol (excluding Bloom filter features).\n> \n> I think the bloom filter SPV usecase is not \"pure client-server\". SPV\n> clients could request from/broadcast to multiple \"trusted nodes\".\n\nI have referred to the Bloom filters messages. These are clearly asymmetric in nature. Despite being possible it is not a valid use case for a full node to make BF requests to another node.\n\nOne client to multiple servers is still client-server for the sake of this discussion. The nature of the P2P protocol is synchronization of content between all nodes/peers. If the protocol is asymmetric the semantics, and therefore use cases, are different.\n\nFWIW posting a transaction to the network can be done using the P2P protocol, connecting for a short period of time. But this is also a client-server scenario and is a hack when done (full disclosure, bx provides both P2P and client-server commands for tx posting). Broadcasting is naturally the behavior of a full node.\n\n> Trusted nodes could be nodes where the operators have shared identities/keys in advance over a different channel.\n\nYes, this is necessarily the case in order to prevent a MITM attack. This is the basis of my concern.\n\n> Further private p2p extensions (lets say a p2p form of the estimatefee\n> command) are something which needs to be discussed first and not\n> something that is encouraged or outlined in BIP151.\n\nSure, but then let us not make assumptions about it in the context of this discussion. Libbitcoin provides fee estimation by monitoring broadcast penetration using a client-server protocol with an optional subscription mechanism.\n\n>> It seems to me that the desire to secure against the weaknesses of BF is being casually generalized to the P2P network. That generalization may actually weaken the security of the P2P protocol. One might consider the proper resolution is to move the BF features to a client-server protocol.\n> \n> I don't see reasons why BIP151 could weaken the security of the P2P network. Can you point out some specific concerns?\n\nTOFU cannot prevent MITM attacks (the goal of the encryption). Authentication requires a secure (trusted) side channel by which to distribute public keys. This presents what I consider a significant problem. If widespread, control over this distribution network would constitute control over who can use Bitcoin.\n\nThe effort to prevent censorship could actually enable it. I don't think it would get that far. Someone would point this out in the process of vetting the authentication BIP, and the result would be the scrapping of BIP151.\n\n>> The BIP does not make a case for other scenarios, or contemplate the significant problems associated with key distribution in any identity system. Given that the BIP relies on identity, these considerations should be fully vetted before heading down another blind alley.\n> \n> BIP151 does not rely on identities. BIP151 does not use persisted keys\n> (only ephemeral keys).\n\nBIP 151 is incomplete without authentication.\n\n> The authentication/identity system needs to be described in a another BIP.\n> But correct, BIP151 without a form of authentication/identity management\n> is vulnerable to all sorts of MITM attacks and that's why I think BIP151\n> must be deployed together with an p2p authentication scheme.\n\nAgree, but my problem is that I do not believe we can assume this is a solvable problem.\n\n> Scope creeping and the risks of overspecifying is the main reason to\n> focus on the \"pure encryption part\" in BIP151.\n\nUnderstood, yet this is the basis of my blind alley comment.\n\ne\n\n> Thanks\n> ---\n> </jonas>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-06-28T23:34:33",
                "message_text_only": ">> On Jun 29, 2016, at 12:22 AM, Gregory Maxwell <gmaxwell at gmail.com> wrote:\n>> \n>> On Tue, Jun 28, 2016 at 9:59 PM, Eric Voskuil <eric at voskuil.org> wrote:\n>> Passing the session ID out of band is authentication. As this is explicitly not part of BIP151 it cannot be that BIP151 provides the tools to detect a attack (the point at issue).\n> \n> It provides the ID, the rest is meat.\n\nThe rest is \"authentication\".\n\n> Users can compare session IDs\n> via whatever communications channels they already use after the fact\n> and discover if they were or are being MITMed.\n> \n>>>> It requires a secure channel and is authentication. So BIP151 doesn't provide the tools to detect an attack, that requires authentication. A general requirement for authentication is the issue I have raised.\n>>> \n>>> One might wonder how you ever use a Bitcoin address, or even why we might guess these emails from \"you\" aren't actually coming from the NSA.\n>> \n>> The sarcasm is counterproductive Greg. By the same token I could ask how you ever use Bitcoin given that the P2P protocol is not encrypted or authenticated.\n> \n> I think I was unclear. A bitcoin address needs to be sent over a secure channel, which we do not provide. Yet sending funds to addresses instead of anyone_can_spend is pretty useful.\n> \n> Similarly, I can guess that messages claiming to you are probably from you when many people can independently check, even if they don't usually. The fact tampered messages might be detected is a big disincentive from trying.\n\nYou were perfectly clear. Did I give some indication that I did not understand what you meant?\n\n>> The blockchain and mempool are a cache of public data. Transmission of a payment address to a payer is not a comparable scenario.\n> \n> The precise timing and ordering of transactions being relayed is _not_\n> public data.\n\nPosting txs to the network is a client-server scenario. The set of txs arriving at an arbitrary node, including the order of arrival, is by definition public information. The only possible way it could be considered private is if the entire network was private.\n\nSo where does the private timing become public? First hop, second, third?\n\nEncryption and authentication cannot prevent timing attacks against a person posting txs to the network unless the entire network is \"secured\". That is not possible without centralized access control.\n\nEncrypting the P2P network doesn't resolve this problem, nor does authentication, nor does Tor. I would prefer we advance an actual solution to this significant problem than advance a false sense of security while creating both complexity and the likely evolution of node identity.\n\ne"
            }
        ],
        "thread_summary": {
            "title": "BIP 151",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Eric Voskuil",
                "Nick ODell",
                "Peter Todd",
                "Gregory Maxwell",
                "Erik Aronesty",
                "Pieter Wuille",
                "Cameron Garnham",
                "Alfie John",
                "Jonas Schnelli"
            ],
            "messages_count": 39,
            "total_messages_chars_count": 126355
        }
    },
    {
        "title": "[bitcoin-dev] Code Review: The Consensus Critical Parts of Segwit by Peter Todd",
        "thread_messages": [
            {
                "author": "Johnson Lau",
                "date": "2016-06-28T16:22:45",
                "message_text_only": "Thanks for Peter Todd\u2019s detailed report:\nhttps://petertodd.org/2016/segwit-consensus-critical-code-review\n\nI have the following response.\n\n>Since the reserve value is only a single, 32-byte value, we\u2019re setting ourselves up for the same problem again7.\n\nPlease note that unlimited space has been reserved after the witness commitment:\n\n  block.vtx[0].vout[o].scriptPubKey.size() >= 38\n\n Which means anything after 38 bytes has no consensus meaning. Any new consensus critical commitments/metadata could be put there. Anyway, there is no efficient way to add a new commitment with softfork.\n\n\n> the fact that we do this has a rather odd result: a transaction spending a witness output with an unknown version is valid even if the transaction doesn\u2019t have any witnesses!\n\nI don\u2019t see any reason to have such check. We simply leave unknown witness program as any-one-can-spend without looking at the witness, as described in BIP141.\n\n\n> Bizzarely segwit has an additonal pay-to-witness-pubkey-hashP2WPKH that lets you use a 160-bit (20 byte) commitment\u2026\u2026\n\nSince ~90% of current transactions are P2PKH, we expect many people will keep using this type of transaction in the future. P2WPKH gives the same level of security as P2PKH, and smaller scriptPubKey.\n\n>give users the option instead to choose to accept the less secure 160-bit commitment if their use-case doesn\u2019t need the full 256-bit security level\n\nThis is actually discussed on the mailing list. P2WSH with multi-sig is subject to birthday attack, and therefore 256-bit is used to provide 128-bit security. P2WPKH is used as single sig and therefore 160-bit is enough.\n\n\n>Secondly, if you are going to give a 160-bit commitment option, you don\u2019t need the extra level of indirection in the P2SH case: just make the segwit redeemScript be: <version> <serialized witness script>\n\nSomething wrong here? In P2WPKH, the witness is <sig> <pubkey>\n\n\n>The only downside is the serialized witness script is constrained to 520 bytes max\n\n520 is the original limit. BIP141 tries to mimic the existing behaviour as much as possible. Anyway, normally nothing in the current scripts should use a push with more than 75 bytes\n\n\n>we haven\u2019t explicitly ensured that signatures for the new signature hash can\u2019t be reused for the old signature hash\n\nHow could that be? That\u2019d be a hash collision.\n\n\n\n\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 671 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160629/cefe2cd2/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Code Review: The Consensus Critical Parts of Segwit by Peter Todd",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Johnson Lau"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2638
        }
    }
]