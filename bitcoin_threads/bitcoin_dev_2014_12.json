[
    {
        "title": "[Bitcoin-development] Deanonymisation of clients in Bitcoin P2P network paper",
        "thread_messages": [
            {
                "author": "Isidor Zeuner",
                "date": "2014-12-01T10:42:58",
                "message_text_only": "Hi Gregory,\n\nresponse below quote:\n> > Since this attack vector has been discussed, I started making some\n> > measurements on how effective it is to connect to Bitcoin using Tor,\n> > and I found that the number of connections dropping to near-zero is\n> > a situation which occurs rather frequently, which suggests that there\n> > is still room to improve on the DoS handling.\n>\n> I'm confused by this, I run quite a few nodes exclusively on tor and\n> chart their connectivity and have seen no such connection dropping\n> behaviour.\n>\n> Can you tell me more about how you measured this?\n>\n\nWhen you say \"running exclusively on Tor\", what do you mean exactly?\nDo you also connect or allow connections through hidden services?\n\nI made outbound connections through Tor exit points the only way to\nconnect to Bitcoin, and increased the number of allowed outbound\nconnection in order to get more meaningful values.\n\nLately, I could see unusual behaviour at:\n\n* 2014-11-28 13:14 UTC\n* 2014-11-25 07:32 UTC\n* 2014-11-24 13:06 UTC\n\nAnything I should look into?\n\n> [As an aside I agree that there are lots of things to improve here,\n> but the fact that users can in theory be forced off of tor via DOS\n> attacks is not immediately concerning to me because its a conscious\n> choice users would make to abandon their privacy (and the behaviour of\n> the system here is known and intentional). There are other mechanisms\n> available for people to relay their transactions than connecting\n> directly to the bitcoin network; so their choice isn't just abandon\n> privacy or don't use bitcoin at all.]\n>\n\nI think this issue is more important than it seems.\n\nFirstly, when running Tor-only, there are still attack vectors which\nmake use of the DoS protection deficiencies.\n\nSecondly, if we tell people not to connect directly if they want\nprivacy, how do we ensure that these indirect methods will not come\nwith implications for their privacy?\n\nBest regards,\n\nIsidor"
            },
            {
                "author": "Isidor Zeuner",
                "date": "2014-12-08T16:15:14",
                "message_text_only": "> >\n> > [As an aside I agree that there are lots of things to improve here,\n> > but the fact that users can in theory be forced off of tor via DOS\n> > attacks is not immediately concerning to me because its a conscious\n> > choice users would make to abandon their privacy\n>\n>\n> Bitcoin already has a large population of users who have little or no\n> technical skill, it wouldn't surprise me at all if it was found to be the\n> clear majority by now. Assuming success and growth in future, very few\n> users will make any decisions at all about their privacy, they will just\n> accept the defaults. In such a world no consumer wallet is going to\n> directly expose Tor to end users - if used at all it'll just be used behind\n> the scenes. So automated fallback or control over exits would be a concern\n> for such wallets.\n>\n\nIn order to get more synergy between Bitcoin users of varying skill\nlevels, my suggestion would be a cleaner separation between technical\nmechanisms and policies (possibly suitable for users without technical\nskills).\n\nCore development would mean providing suitable mechanisms by which it\nis possible to run Bitcoin on different constraints. This may include\nways to handle attacks specific to the Tor/Bitcoin combination.\n\nPeople who like to research what is possible with the protocol can\nthen experiment on how these mechanisms can be used in order to\nmitigate these attacks.\n\nFinally, distributors of consumer wallets can use this research in\norder to distribute their wallet with policies which may be less prone\nto Tor-specific attacks. Or leave this out altogether if their\naudience has different expectations for connecting to Bitcoin.\n\nThe tricky part is probably to figure out what is the greatest common\ndenominator of what keeps Bitcoin stable and running while still\nleaving room for customized policies. But I think that separating\nconcerns like this is better than letting a debate about how to\nmitigate certain Tor-related attacks evolve towards a debate about Tor\nor not Tor.\n\n> My gut feeling about this stuff has changed over time. I don't think it'd\n> be a great idea to tie Bitcoin to Tor too deeply, convenient though its\n> infrastructure is. Most apps don't need a whole lot of onion routing - a\n> small amount built in to the p2p layer would be sufficient. Tor is huge,\n> complicated and could be a liability in future.\n>\n\nI think it would be very interesting to explore alternatives for\nTor. But at this point, completely abandoning Tor would mean that\nusers either have to agree to have their transactions correlated to\ntheir IP address, or to trust their transactions to a third party\nwhere they are not subject to the security guarantees Bitcoin's\nlogic can provide anymore. In my opinion, it's a rather huge\nsacrifice.\n\nWhat I find interesting, however, is that a lot of suggestions I see\nwith respect to attacks related to Tor/Bitcoin (including my own)\ninvolve some kind of extra effort required for Tor users on Bitcoin in\norder to protect themselves against these attacks. So, it may be\ninteresting to explore if it is viable to think of Tor's privacy\nguarantees as coming for free. Going from there, if it cannot be\nguaranteed to work completely for free, the question would be to what\nextent the required extra effort should be a shared effort of the\nnetwork, and to what extent users requiring the improved privacy\nshould use their own resources in order to make it possible.\n\nBest regards,\n\nIsidor"
            },
            {
                "author": "Mike Hearn",
                "date": "2014-12-08T16:59:06",
                "message_text_only": ">\n> Finally, distributors of consumer wallets can use this research in\n> order to distribute their wallet with policies which may be less prone\n> to Tor-specific attacks. Or leave this out altogether if their\n> audience has different expectations for connecting to Bitcoin.\n>\n\nSure. I guess there will be wallets for all kinds of people in future,\nsharing a common core that they can customise (this is certainly the vision\nand general direction for bitcoinj, and it's working out OK).\n\nTo clarify, my comments above were for mainstream granny-focused wallets.\nWallets designed for crypto geeks can and should expose all the knobs to\nlet people run wild.\n\nOne possible direction to go is to use Tor for writing to the network and\nuse general link encryption and better Bloom filtering for reading it. Thus\nnew transactions would pop out of Tor exits, but there isn't much they can\ndo that's malicious there except mutate them or block them entirely. If you\ninsert the same transaction into the P2P network via say 10 randomly chosen\nexits, the worst a malicious mutator can do is race the real transaction\nand that's no different to a malicious P2P node. Even in a world where an\nattacker has DoS-banned a lot of nodes and now controls your TX submission\npath entirely, it's hard to see how it helps them.\n\nThe nice thing about the above approach is that it solves the latency\nproblems. Startup speed is really an issue for reading from the network:\njust syncing the block chain is already enough of a speed hit without\nadding consensus sync as well. But if you're syncing the block chain via\nthe clearnet you can connect to Tor in parallel so that by the time the\nuser has scanned a QR code, verified the details on the screen and then\npressed the Pay button, you have a warm connection and can upload the TX\nthrough that. It reduces the level of startup time optimisation needed,\nalthough Tor consensus download is still too slow even to race a QR code\nscan at the moment. I think tuning the consensus caching process and\nswitching to a fresh one on the fly might be the way to go.\n\nWhen BIP70 is in use, you wouldn't write the tx to the network yourself but\nyou could download the PaymentRequest and upload the Payment message via an\nSSLd Tor connection to the merchant. Then malicious exits can only DoS you\nbut not do anything else so there's no need for multiple exit paths\nsimultaneously.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141208/02888598/attachment.html>"
            },
            {
                "author": "Isidor Zeuner",
                "date": "2014-12-11T11:51:18",
                "message_text_only": "[...]\n> And, on the flip side if the host is persistently behind tor, even\n> with some watermarkable behaviour, their privacy is protected.  So\n> making sure that hosts can continually use tor (or similar systems)\n> should be the higher priority.  (And, of course, not reimplementing\n> tor  leverages the millions of dollars of investment and dozens of\n> subject matter experts working on that system).\n>\n\nReimplementing Tor would not only mean to lose all the investment that\nran into Tor, but also to lose a large user base. We can see this with\nTorCoin. Still, the fact that Bitcoin is a use case for Tor which\nmeasurably shows some limits where it is not fully clear if Tor or\nBitcoin is to be blamed does not only mean that both projects may\nhave to evolve in order to properly solve the issue, but also that the\nmeans of interfacing between both projects may have to be\nextended. Ideally, in a way which does not require to run a separate\nTor and/or Bitcoin network in order to work, but which will be generic\nenough to satisfy both sides' need to still work in a standalone\nmanner.\n\nBut I do see huge merit in exploring better ways of synergy between\nthe projects. For example, Tor's hardcoded circuit length may be\nconsidered as a hack which was only necessary due to the lack of a\nsuitable resource compensation mechanism. Which is something that is\navailable with Bitcoin.\n\nBest regards,\n\nIsidor"
            },
            {
                "author": "Isidor Zeuner",
                "date": "2014-12-15T13:25:14",
                "message_text_only": "[...]\n> > I'm confused by this, I run quite a few nodes exclusively on tor and\n> > chart their connectivity and have seen no such connection dropping\n> > behaviour.\n>\n> In my experience the problem has always been getting bootstrapped.\n> Most nodes hardly give any hidden service nodes in their getaddr.\n> (this has been improved in master by including a set of hidden service\n> seed nodes)\n> But this assumes -onlynet=tor. Tor with exit nodes should be less\n> problematic, unless someone managed to DoSban all the exit nodes as\n> described in the paper (but I've never seen such an attack myself).\n>\n\nWhen refering to \"getting bootstrapped\", do you only mean collecting\nnode addresses, or also syncing blocks?\n\nIf you're saying the drops in connection counts are likely to be\nnot caused by a DoSban attack on the exit nodes, what could be other\nreasons to look into?\n\n> > Can you tell me more about how you measured this?\n> >\n> > [As an aside I agree that there are lots of things to improve here,\n> > but the fact that users can in theory be forced off of tor via DOS\n> > attacks is not immediately concerning to me because its a conscious\n> > choice users would make to abandon their privacy (and the behaviour of\n> > the system here is known and intentional). There are other mechanisms\n> > available for people to relay their transactions than connecting\n> > directly to the bitcoin network; so their choice isn't just abandon\n> > privacy or don't use bitcoin at all.]\n>\n> Right, there's something to be said for splitting your own transaction\n> submission from normal P2P networking and transaction relay.\n> (esp for non-SPV wallets which don't inherently leak any information\n> about their addresses)\n>\n> There was a pull request about this for Bitcoin Core one, maybe I\n> closed it unfairly https://github.com/bitcoin/bitcoin/issues/4564 .\n>\n\nGreat! I find it very interesting to research options for splitting\ncommunication between Tor and non-Tor as long as the introduced\ninformation leakage between both connection methods can be proved to\nbe nonexistent or negligible.\n\nIn the case of Bitcoin, this makes me wonder about an attack that\ncould look approximately like this:\n\n* Node A connects to Bitcoin using Tor (for submitting transactions)\n  and IPv4 (for all other communication).\n\n* Node B strives for direct IPv4 connections with node A\n\n* Node B uses the direct IPv4 connections in order to supply Node A\n  with additional peer addresses not supplied to any other nodes\n\n* Node B observes these additional peer addresses\n\nFor transactions submitted to the additional peer addresses supplied\nby node B, how to prevent that the probability of these originating\nfrom node A is higher than for originating from other nodes?\n\nFor handling block propagation using non-Tor connections, it's\nprobably harder to create information leaks, as the logic for handling\ndisagreement about blocks is pretty well-researched, meaning that\nit's less important where the blocks come from.\n\nBest regards,\n\nIsidor"
            }
        ],
        "thread_summary": {
            "title": "Deanonymisation of clients in Bitcoin P2P network paper",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Mike Hearn",
                "Isidor Zeuner"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 12392
        }
    },
    {
        "title": "[Bitcoin-development] [bitcoin-list] Running a full node",
        "thread_messages": [
            {
                "author": "Martinx - \u30b8\u30a7\u30fc\u30e0\u30ba",
                "date": "2014-12-04T14:32:19",
                "message_text_only": "Bitcoind|qt needs Dual-Stack support.   ;-)\n\nCheers!\nThiago\n\nOn 9 November 2014 at 15:52, grarpamp <grarpamp at gmail.com> wrote:\n> You may also wish to consider linking your node into\n> the Tor, I2P, and maybe even CJDNS networks. Details\n> on their respective mailing lists.\n>\n> ------------------------------------------------------------------------------\n> _______________________________________________\n> bitcoin-list mailing list\n> bitcoin-list at lists.sourceforge.net\n> https://lists.sourceforge.net/lists/listinfo/bitcoin-list"
            }
        ],
        "thread_summary": {
            "title": "Running a full node",
            "categories": [
                "Bitcoin-development",
                "bitcoin-list"
            ],
            "authors": [
                "Martinx - \u30b8\u30a7\u30fc\u30e0\u30ba"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 537
        }
    },
    {
        "title": "[Bitcoin-development] Serialised P2SH HD chains",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2014-12-04T15:42:42",
                "message_text_only": "Is anyone working on a serialisation format to convey P2SH HD chains? For \nexample, to give someone who wants to make recurring payments a single token \nthat can be used to generate many P2SH addresses paying to a multisig script.\n\nI'm thinking of something along the lines of a simple series of tokens, each \nindicating either a HD chain or literal script content. For all HD chains in \nthe data, a child key would be generated based on the payment number, and all \ntokens concatenated to form the P2SH serialised script. Eg, for a simple 2-\nof-2, you would do something like this:\n    literal(OP_2) HDChain HDChain literal(OP_2 OP_CHECKMULTISIG)\nDoes this sufficiently cover all reasonable use cases?\n\nLuke"
            },
            {
                "author": "Gavin Andresen",
                "date": "2014-12-04T16:46:28",
                "message_text_only": "On Thu, Dec 4, 2014 at 10:42 AM, Luke Dashjr <luke at dashjr.org> wrote:\n\n> Is anyone working on a serialisation format to convey P2SH HD chains? For example,\n> to give someone who wants to make recurring payments a single token that\n> can be used to generate many P2SH addresses paying to a multisig script.\n\n\nSeems like the wrong approach to me, because in practice you really need\na reasonable expiration date or some way of determining that whatever you\nare paying\nis still around (I still get random transactions to the Bitcoin Faucet's\nold addresses).\n\nSee the discussion from January about extending the payment protocol for\nrecurring transactions:\n\nhttps://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg03823.html\n\n\"Give them a single token\" == \"give them a recurring PaymentRequest\" in my\nmind. Or maybe \"Give them a URL where they can fetch PaymentRequests\nwhenever they need to make a payment\" or maybe \"Give them an array of\nPaymentRequests for the next X days/months/years of payments.\"\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141204/2bb31fe5/attachment.html>"
            },
            {
                "author": "William Swanson",
                "date": "2014-12-04T17:25:05",
                "message_text_only": "Yes. A few of us over here in San Diego actually started working on a\nformat like this a few months ago, but it's been on the back burner\nfor a while.\n\nOur motivation was to come up with a shared HD wallet format. Say I\nwould like create a 2-of-3 multisig wallet using my phone, PC, and\nhardware key fob. All three devices would presumably be running\ndifferent wallet software, so we need some sort of standardized HD\nmultisig chain-description format that all three wallets can\nunderstand. That way, regardless of their other differences, the\nwallets can at least agree on how to generate new addresses.\n\nOf course, once you share this chain-description file with a third\nparty, they too can generate addresses out of the wallet. This can be\nused for auditing (like for charities), for receive-only wallets (like\na merchant kiosk), and for recurring payments. The recurring payment\ncase is a little problematic, since you need to trust the payee with\nyour privacy. I imagine this would only be useful for payouts you\nmanage yourself, like a mining pool, and not something you share with\nthe general public.\n\nOur format is very similar to yours. We have a script template, just\nlike you do, but we describe the HD chains in a separate section\nrather than in-line with the script. The script template only comes\ninto being once the chains have been gathered together into one place,\nso the chain descriptions need to stand alone.\n\nUnfortunately, we still have a lot of details to work through before\nwe have a concrete proposal that's ready for this mailing list.\nPerhaps we can work together to come up with something.\n\n-William\n\nOn Thu, Dec 4, 2014 at 7:42 AM, Luke Dashjr <luke at dashjr.org> wrote:\n> Is anyone working on a serialisation format to convey P2SH HD chains? For\n> example, to give someone who wants to make recurring payments a single token\n> that can be used to generate many P2SH addresses paying to a multisig script.\n>\n> I'm thinking of something along the lines of a simple series of tokens, each\n> indicating either a HD chain or literal script content. For all HD chains in\n> the data, a child key would be generated based on the payment number, and all\n> tokens concatenated to form the P2SH serialised script. Eg, for a simple 2-\n> of-2, you would do something like this:\n>     literal(OP_2) HDChain HDChain literal(OP_2 OP_CHECKMULTISIG)\n> Does this sufficiently cover all reasonable use cases?\n>\n> Luke"
            },
            {
                "author": "Mike Hearn",
                "date": "2014-12-04T18:04:21",
                "message_text_only": "I wrote a little Javascript program\n<https://github.com/bitcoinj/bitcoinj/blob/master/examples/src/main/javascript/payprotocol.js>\nto print some minimal protobufs to base64.\n\nResult for a multisig output:\n\nIk0SSRJHUiECpm1rIsOcaCf/CqL/YeqNXgcnQzb/+hfaawdi9u46xhEhAgoJfDU3M5mr++dfBG2gO5DiBiBVkVmLzjSLf26HEINeUq4YAA\n\nResult for a regular pay to address output:\n\nIh8SGxIZdqkU4nFAzWDBp6LEi4uXgddL65H11nGIrBgA\n\nThat is without any expiry time, which you'd want in practice. For an\nHD-iterating payment request you'd also need a few flags and fields, but a\nwell designed protocol should only add a handful of bytes. The above\nstrings are, I think, short enough to set as a username in a mining program\nso the general UX of Eligius can be maintained.\n\nHow to generate them? That's not too hard. Building specialised one-off SPV\nwallets is quite easy these days with bitcoinj, there's a template app and\na video tutorial on how to customise it available here:\n\nhttps://bitcoinj.github.io/simple-gui-wallet\n\nYou can just copy/paste the code into a new directory and start modifying\nit. The final result is like Lighthouse - you run a program and get an EXE\ninstaller or MSI for Windows, a DMG for MacOS and a .deb for Linux (though\na tarball would work just as well).\n\nSo producing a little GUI that lets you build a base64 encoded payment\nprotocol request that supports HD iteration for one or more keys, along\nwith a little BIP70 extension that says \"although this output is a multisig\noutput, please actually create a p2sh output\", would make a nice starter\nproject for someone. It could also then act as a watching wallet and plot a\ngraph of mining payouts over time, for example.\n\nIf anyone wants to take this on let me know. I can help out with the final\ncode signing steps to make Gatekeeper/Internet Explorer happy so don't\nworry about distribution.\n\nOn Thu, Dec 4, 2014 at 6:25 PM, William Swanson <swansontec at gmail.com>\nwrote:\n\n> Yes. A few of us over here in San Diego actually started working on a\n> format like this a few months ago, but it's been on the back burner\n> for a while.\n>\n> Our motivation was to come up with a shared HD wallet format. Say I\n> would like create a 2-of-3 multisig wallet using my phone, PC, and\n> hardware key fob. All three devices would presumably be running\n> different wallet software, so we need some sort of standardized HD\n> multisig chain-description format that all three wallets can\n> understand. That way, regardless of their other differences, the\n> wallets can at least agree on how to generate new addresses.\n>\n> Of course, once you share this chain-description file with a third\n> party, they too can generate addresses out of the wallet. This can be\n> used for auditing (like for charities), for receive-only wallets (like\n> a merchant kiosk), and for recurring payments. The recurring payment\n> case is a little problematic, since you need to trust the payee with\n> your privacy. I imagine this would only be useful for payouts you\n> manage yourself, like a mining pool, and not something you share with\n> the general public.\n>\n> Our format is very similar to yours. We have a script template, just\n> like you do, but we describe the HD chains in a separate section\n> rather than in-line with the script. The script template only comes\n> into being once the chains have been gathered together into one place,\n> so the chain descriptions need to stand alone.\n>\n> Unfortunately, we still have a lot of details to work through before\n> we have a concrete proposal that's ready for this mailing list.\n> Perhaps we can work together to come up with something.\n>\n> -William\n>\n> On Thu, Dec 4, 2014 at 7:42 AM, Luke Dashjr <luke at dashjr.org> wrote:\n> > Is anyone working on a serialisation format to convey P2SH HD chains? For\n> > example, to give someone who wants to make recurring payments a single\n> token\n> > that can be used to generate many P2SH addresses paying to a multisig\n> script.\n> >\n> > I'm thinking of something along the lines of a simple series of tokens,\n> each\n> > indicating either a HD chain or literal script content. For all HD\n> chains in\n> > the data, a child key would be generated based on the payment number,\n> and all\n> > tokens concatenated to form the P2SH serialised script. Eg, for a simple\n> 2-\n> > of-2, you would do something like this:\n> >     literal(OP_2) HDChain HDChain literal(OP_2 OP_CHECKMULTISIG)\n> > Does this sufficiently cover all reasonable use cases?\n> >\n> > Luke\n>\n>\n> ------------------------------------------------------------------------------\n> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n> from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n> with Interactivity, Sharing, Native Excel Exports, App Integration & more\n> Get technology previously reserved for billion-dollar corporations, FREE\n>\n> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n> _______________________________________________\n> Bitcoin-development mailing list\n> Bitcoin-development at lists.sourceforge.net\n> https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141204/0b9d3095/attachment.html>"
            },
            {
                "author": "Jeffrey Paul",
                "date": "2014-12-04T20:02:17",
                "message_text_only": "> On 20141204, at 07:42, Luke Dashjr <luke at dashjr.org> wrote:\n> \n> Is anyone working on a serialisation format to convey P2SH HD chains? For \n> example, to give someone who wants to make recurring payments a single token \n> that can be used to generate many P2SH addresses paying to a multisig script.\n> \n> I'm thinking of something along the lines of a simple series of tokens, each \n> indicating either a HD chain or literal script content. For all HD chains in \n> the data, a child key would be generated based on the payment number, and all \n> tokens concatenated to form the P2SH serialised script. Eg, for a simple 2-\n> of-2, you would do something like this:\n>    literal(OP_2) HDChain HDChain literal(OP_2 OP_CHECKMULTISIG)\n> Does this sufficiently cover all reasonable use cases?\n\n\nWhat is the use case for something like this?  It\u2019s my impression that a single token that can be used to obtain many P2SH addresses paying to a multisig script looks something like\n\n   bitcoin:?r=https://payee.com/customer12345/recurring/paymentrequest/new\n\nAs it\u2019s impossible to actually transmit a tx without network access, why would it be necessary to, at payment time, not contact the payee and use the existing bip70 authenticated payment request protocol to find out exactly what multisig address they\u2019d like paid at that moment?\n\nThe model that you describe where a payer can, without communication with the payee, generate additional multisig p2sh addresses based on a set of xpubs presumes that the payee would never want to e.g. cycle their own keys or change their cooperating multisig participants\u2019 keys.  Is this wise?\n\nLately I\u2019ve been thinking of bitcoin addresses (even multisig) as sort of MX records - something that the paying user shouldn\u2019t depend on being static, because they are derived from keys that may change (or be lost or compromised) over time.  The canonical \u201cpay me at this address forever QR code\u201d should be a bitcoin: URI that points to a payment request generating URL, should it not?\n\nBest,\n-jp\n\n--\nJeffrey Paul                                                      EEQJ\njp at eeqj.com                                           https://eeqj.com\n+1-800-403-1126 (America)                  +1-312-361-0355 (Worldwide)\n5539 AD00 DE4C 42F3 AFE1                      1575 0524 43F4 DF2A 55C2"
            },
            {
                "author": "Peter Todd",
                "date": "2014-12-04T20:43:32",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\n\n\nOn 4 December 2014 20:02:17 GMT+00:00, Jeffrey Paul <jp at eeqj.com> wrote:\n>\n>> On 20141204, at 07:42, Luke Dashjr <luke at dashjr.org> wrote:\n>>\n>> Is anyone working on a serialisation format to convey P2SH HD chains?\n>For\n>> example, to give someone who wants to make recurring payments a\n>single token\n>> that can be used to generate many P2SH addresses paying to a multisig\n>script.\n>>\n>> I'm thinking of something along the lines of a simple series of\n>tokens, each\n>> indicating either a HD chain or literal script content. For all HD\n>chains in\n>> the data, a child key would be generated based on the payment number,\n>and all\n>> tokens concatenated to form the P2SH serialised script. Eg, for a\n>simple 2-\n>> of-2, you would do something like this:\n>>    literal(OP_2) HDChain HDChain literal(OP_2 OP_CHECKMULTISIG)\n>> Does this sufficiently cover all reasonable use cases?\n>\n>\n>What is the use case for something like this?  It\u2019s my impression that\n>a single token that can be used to obtain many P2SH addresses paying to\n>a multisig script looks something like\n>\n>bitcoin:?r=https://payee.com/customer12345/recurring/paymentrequest/new\n>\n>As it\u2019s impossible to actually transmit a tx without network access,\n>why would it be necessary to, at payment time, not contact the payee\n>and use the existing bip70 authenticated payment request protocol to\n>find out exactly what multisig address they\u2019d like paid at that moment?\n\nIt's quite common to run into situations where the payee is *not* online. Similarly requiring them to be online is a security risk and defeats many ways of authenticating payment addresses. This stuff isn't evident in trivial consumer<->merchant use-cases, but is very common in anything else. For instance, consider the case of moving funds from a hot wallet or cold, and vice-versa.\n\nLuke-Jr: sounds like some of the ideas I've been playing around with for generalised stealth addresses, using a declarative template scheme to avoid specifying scriptPubKey formats too explicitly. (though obcs k-anon set issues)\n-----BEGIN PGP SIGNATURE-----\nVersion: APG v1.1.1\n\niQFQBAEBCAA6BQJUgMd0MxxQZXRlciBUb2RkIChsb3cgc2VjdXJpdHkga2V5KSA8\ncGV0ZUBwZXRlcnRvZGQub3JnPgAKCRAZnIM7qOfwhRJjB/0fvNisFR4cktOhDJYl\nnq2gb39aiV7Wufh7NcTI0mqsC1yhIgFW5fgl7TmiK76Tn4gH0rhfJe3u7GhVsmSy\nSx1qEJJN6yNsiu6elmLe8xISVTwHu+kLqKFTyZNrd4BObHVumyLAhea2lFSzZmBu\nGQF/AnVzf06vAT8CnZZm3hMgt1kFv32KglIIWLdztvvgi7yK6fi2GlZUW1J+jCUk\n6AyQbnpPkHPHIJe7UMM0oeC2w6cN5nH0ccIutwkYDHwo/APa0TkX1hu3bJh5/Cor\nzh+BLdOYgAP28wUZ1fkQoAj/0l79+3wyBC7+6lblV90y7C68G6zqMav7lDZdsBK9\n4DU0\n=Atvv\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "Luke Dashjr",
                "date": "2014-12-04T21:10:14",
                "message_text_only": "On Thursday, December 04, 2014 8:02:17 PM Jeffrey Paul wrote:\n> What is the use case for something like this?  It\u2019s my impression that a\n> single token that can be used to obtain many P2SH addresses paying to a\n> multisig script looks something like\n> \n>    bitcoin:?r=https://payee.com/customer12345/recurring/paymentrequest/new\n\nThis requires the payee operate a server. My use case is for payment to \nindividuals, who may or may not have a computer powered at the time of the \ntransactions being sent. Furthermore, the users I am targeting (miners, to be \nspecific), wish to remain entirely anonymous, and not hold accounts of any \nsort.\n\n> The model that you describe where a payer can, without communication with\n> the payee, generate additional multisig p2sh addresses based on a set of\n> xpubs presumes that the payee would never want to e.g. cycle their own\n> keys or change their cooperating multisig participants\u2019 keys.  Is this\n> wise?\n\nThis depends on the framework. As of present day, miners are limited to only \nuse a single address ever, and cannot change it even to avoid address reuse. \nOne goal is to solve that, without breaking multisig.\n\nLuke"
            },
            {
                "author": "Michael Perklin",
                "date": "2014-12-04T20:40:12",
                "message_text_only": "Luke,\n\nEric Lombrozo is doing work similar to that. You may wish to connect.\n\nHe's building a BIP to standardize a multisig application of BIP32.\nLike there are xprv and xpubs for single keychains, he is developing a similar construct that would embed all information necessary for a \"multisig xpub\" (total keychains in system, minimum # of keys required, and which derivation paths on each keychain are to be combined to make the resultant multisig wallet)\n\nThe result would be taking an xpub style string and piping it through a BIP32-like algorithm to pop off P2SH addresses in a deterministic order, just like BIP32 pops off standard addresses in deterministic order.\n\nI will ping Eric to connect with you in case the both of you are working on something similar and you can help each other.\n\n\nMichael Perklin\nBitcoinsultants Inc.\n\nOn Thu, Dec 4, 2014 at 7:42 AM, Luke Dashjr <luke at dashjr.org <mailto:luke at dashjr.org>> wrote:\n> Is anyone working on a serialisation format to convey P2SH HD chains? For\n> example, to give someone who wants to make recurring payments a single token\n> that can be used to generate many P2SH addresses paying to a multisig script.\n> \n> I'm thinking of something along the lines of a simple series of tokens, each\n> indicating either a HD chain or literal script content. For all HD chains in\n> the data, a child key would be generated based on the payment number, and all\n> tokens concatenated to form the P2SH serialised script. Eg, for a simple 2-\n> of-2, you would do something like this:\n>    literal(OP_2) HDChain HDChain literal(OP_2 OP_CHECKMULTISIG)\n> Does this sufficiently cover all reasonable use cases?\n> \n> Luke\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141204/144f7678/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 842 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141204/144f7678/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Serialised P2SH HD chains",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "William Swanson",
                "Mike Hearn",
                "Jeffrey Paul",
                "Peter Todd",
                "Luke Dashjr",
                "Michael Perklin",
                "Gavin Andresen"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 17937
        }
    },
    {
        "title": "[Bitcoin-development] ACK NACK utACK \"Concept ACK\"",
        "thread_messages": [
            {
                "author": "Sergio Lerner",
                "date": "2014-12-09T21:14:59",
                "message_text_only": "Is that the full terminology or are there more acronyms?\nIs this documented somewhere?\n\nBest regards,\n Sergio."
            },
            {
                "author": "Matt Corallo",
                "date": "2014-12-09T21:30:34",
                "message_text_only": "Also utACK (\"untested ack\") and \"tested ack\" when people are being explicit.\n\nOn 12/09/14 21:14, Sergio Lerner wrote:\n> Is that the full terminology or are there more acronyms?\n> Is this documented somewhere?\n> \n> Best regards,\n>  Sergio.\n> \n> \n> \n> ------------------------------------------------------------------------------\n> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n> from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n> with Interactivity, Sharing, Native Excel Exports, App Integration & more\n> Get technology previously reserved for billion-dollar corporations, FREE\n> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n> _______________________________________________\n> Bitcoin-development mailing list\n> Bitcoin-development at lists.sourceforge.net\n> https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n>"
            },
            {
                "author": "Wladimir",
                "date": "2014-12-10T06:47:53",
                "message_text_only": "Abbreviations:\n\nConcept ACK -> agree with the idea and overall direction, but haven't\nreviewed the code changes nor tested it\nutACK -> reviewed the code changes, but did not put it through any testing\nTested ACK -> reviewed the code changes and verified the functionality/bug fix\n\nI tend to only use bare \"ACK\" if there is nothing to test in the first\nplace, for example for documentation changes.\n\nWladimir\n\n\nOn Tue, Dec 9, 2014 at 9:30 PM, Matt Corallo <bitcoin-list at bluematt.me> wrote:\n> Also utACK (\"untested ack\") and \"tested ack\" when people are being explicit.\n>\n> On 12/09/14 21:14, Sergio Lerner wrote:\n>> Is that the full terminology or are there more acronyms?\n>> Is this documented somewhere?\n>>\n>> Best regards,\n>>  Sergio.\n>>\n>>\n>>\n>> ------------------------------------------------------------------------------\n>> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n>> from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n>> with Interactivity, Sharing, Native Excel Exports, App Integration & more\n>> Get technology previously reserved for billion-dollar corporations, FREE\n>> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n>> _______________________________________________\n>> Bitcoin-development mailing list\n>> Bitcoin-development at lists.sourceforge.net\n>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n>>\n>\n> ------------------------------------------------------------------------------\n> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n> from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n> with Interactivity, Sharing, Native Excel Exports, App Integration & more\n> Get technology previously reserved for billion-dollar corporations, FREE\n> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n> _______________________________________________\n> Bitcoin-development mailing list\n> Bitcoin-development at lists.sourceforge.net\n> https://lists.sourceforge.net/lists/listinfo/bitcoin-development"
            },
            {
                "author": "Wladimir",
                "date": "2014-12-10T08:21:00",
                "message_text_only": "On Wed, Dec 10, 2014 at 6:47 AM, Wladimir <laanwj at gmail.com> wrote:\n> Abbreviations:\n>\n> Concept ACK -> agree with the idea and overall direction, but haven't\n> reviewed the code changes nor tested it\n> utACK -> reviewed the code changes, but did not put it through any testing\n> Tested ACK -> reviewed the code changes and verified the functionality/bug fix\n\nAnd there is also NACK, that's an aspecific 'I wouldn't like this\nmerged'. I always explain why in the text.\n\nA document on this would be welcome, as it may look like Martian to\noutsiders. That's been brought up many times before, but no one ever\ncreated it.\n\nWladimir"
            },
            {
                "author": "Austin Walne",
                "date": "2014-12-10T15:45:49",
                "message_text_only": "I've had these same questions myself. I'm happy to write up some documentation this afternoon. I can draft something based on this thread. What other key terminology should be included?\n\n> On Dec 10, 2014, at 00:21, Wladimir <laanwj at gmail.com> wrote:\n> \n>> On Wed, Dec 10, 2014 at 6:47 AM, Wladimir <laanwj at gmail.com> wrote:\n>> Abbreviations:\n>> \n>> Concept ACK -> agree with the idea and overall direction, but haven't\n>> reviewed the code changes nor tested it\n>> utACK -> reviewed the code changes, but did not put it through any testing\n>> Tested ACK -> reviewed the code changes and verified the functionality/bug fix\n> \n> And there is also NACK, that's an aspecific 'I wouldn't like this\n> merged'. I always explain why in the text.\n> \n> A document on this would be welcome, as it may look like Martian to\n> outsiders. That's been brought up many times before, but no one ever\n> created it.\n> \n> Wladimir\n> \n> ------------------------------------------------------------------------------\n> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n> from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n> with Interactivity, Sharing, Native Excel Exports, App Integration & more\n> Get technology previously reserved for billion-dollar corporations, FREE\n> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n> _______________________________________________\n> Bitcoin-development mailing list\n> Bitcoin-development at lists.sourceforge.net\n> https://lists.sourceforge.net/lists/listinfo/bitcoin-development"
            },
            {
                "author": "Wladimir",
                "date": "2014-12-17T08:44:45",
                "message_text_only": "On Wed, Dec 10, 2014 at 3:45 PM, Austin Walne <austin.walne at gmail.com> wrote:\n> I've had these same questions myself. I'm happy to write up some documentation this afternoon. I can draft something based on this thread. What other key terminology should be included?\n\nFanquake already started on that (but didn't even mention it here!)\nhttps://github.com/bitcoin/bitcoin/pull/5468\n\nWladimir"
            },
            {
                "author": "Jeff Garzik",
                "date": "2014-12-10T15:52:59",
                "message_text_only": "On Wed, Dec 10, 2014 at 1:47 AM, Wladimir <laanwj at gmail.com> wrote:\n\n> Concept ACK -> agree with the idea and overall direction, but haven't\n> reviewed the code changes nor tested it\n>\n\nConcept ACK -> like the idea; the code may need rewriting (or haven't\nreviewed).\n\n-- \nJeff Garzik\nBitcoin core developer and open source evangelist\nBitPay, Inc.      https://bitpay.com/\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141210/18685b0f/attachment.html>"
            },
            {
                "author": "Btc Drak",
                "date": "2014-12-16T23:40:34",
                "message_text_only": "Would someone also clarify the use of \"nit\" for nitpicking and how it plays\nin the role of consensus?\nIt seems like it's used for minor complaints/preferences.\n\nDrak\n\nOn Wed, Dec 10, 2014 at 3:52 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:\n>\n> On Wed, Dec 10, 2014 at 1:47 AM, Wladimir <laanwj at gmail.com> wrote:\n>\n>> Concept ACK -> agree with the idea and overall direction, but haven't\n>> reviewed the code changes nor tested it\n>>\n>\n> Concept ACK -> like the idea; the code may need rewriting (or haven't\n> reviewed).\n>\n> --\n> Jeff Garzik\n> Bitcoin core developer and open source evangelist\n> BitPay, Inc.      https://bitpay.com/\n>\n>\n> ------------------------------------------------------------------------------\n> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n> from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n> with Interactivity, Sharing, Native Excel Exports, App Integration & more\n> Get technology previously reserved for billion-dollar corporations, FREE\n>\n> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n> _______________________________________________\n> Bitcoin-development mailing list\n> Bitcoin-development at lists.sourceforge.net\n> https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/55cd726a/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "ACK NACK utACK \"Concept ACK\"",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Jeff Garzik",
                "Wladimir",
                "Sergio Lerner",
                "Btc Drak",
                "Matt Corallo",
                "Austin Walne"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 7717
        }
    },
    {
        "title": "[Bitcoin-development] Merged mining a side chain with proof of burn on parent chain",
        "thread_messages": [
            {
                "author": "Tamas Blummer",
                "date": "2014-12-10T07:35:01",
                "message_text_only": "We spend scarce resources external to the digital realm to create Bitcoin. Real world sacrifice is needed to avoid \u201cnothing at stake\u201d  and sybil attacks. With Bitcoin we now have a scarce resource within the digital realm, so it appeals my intuition to re-use it for sacrifice instead of linking again an external, real world resource. \n\nIn following I outline a new mining algorithm for side chains, that burn Bitcoins to secure them.\n\nThe side chain block validity rules would require that a transaction on the Bitcoin block chain provably destroys Bitcoins with an OP_RET output, that contains the hash of the block header of the side chain. To also introduce a lottery, the burn transaction\u2019s hash is required to satisfy some function of the block hash it was included in on the Bitcoin block chain. For example modulo m of the burn transaction hash must match modulo m of the block hash, that is not known in advance.\n\nThose who want to mine the side chain will assemble  side chain block candidates that comply the rules of the side chain, then a Bitcoin transaction burning to the hash of the block candidate and submit it to the Bitcoin network. Should he burn transaction be included into the Bitcoin block chain and the Bitcoin block\u2019s hash satisfy the lottery criteria, then the block candidate can be submitted to extend the side chain.\n\nA side chain block header sequence would be accepted as side chain trunk if a sequence of Bitcoin SPV proofs for burn transactions prove, that linked blocks have the highest cumulative burn, if compared to alternative sequences. \n\nThe Bitcoin miner will include burn transactions because they offer Bitcoin fees. Bitcoin miner can not selectively block side chains since the hashes associated with the burn do not disclose which side chain or other project they are for. Here you have a \u201cmerged mining\u201d that does not need Bitcoin miner support or even consent.\n\nMining difficulty of the side chain could be adjusted by stepping up the required burn and/or hardening the criteria that links a burn proof transaction with the bitcoin block hash it is included in.\n\nThe difficulty to mine with burn would be dynamic and would also imply a floating exchange rate between Bitcoin and the side coin.\n\nTamas Blummer\nBits of Proof\n\n00000000000000001172380e63346e3e915b52fcbae838ba958948ac9aa85edd\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 496 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141210/190bfea3/attachment.sig>"
            },
            {
                "author": "patrick",
                "date": "2014-12-10T08:30:10",
                "message_text_only": "The goal is to have an opportunity cost to breaking the rules.\n\nProof of Burn is a real cost for following the rules.\n\nOn 12/10/2014 01:35 AM, Tamas Blummer wrote:\n> We spend scarce resources external to the digital realm to create Bitcoin. Real world sacrifice is needed to avoid \u201cnothing at stake\u201d  and sybil attacks. With Bitcoin we now have a scarce resource within the digital realm, so it appeals my intuition to re-use it for sacrifice instead of linking again an external, real world resource. \n>\n> In following I outline a new mining algorithm for side chains, that burn Bitcoins to secure them.\n>\n> The side chain block validity rules would require that a transaction on the Bitcoin block chain provably destroys Bitcoins with an OP_RET output, that contains the hash of the block header of the side chain. To also introduce a lottery, the burn transaction\u2019s hash is required to satisfy some function of the block hash it was included in on the Bitcoin block chain. For example modulo m of the burn transaction hash must match modulo m of the block hash, that is not known in advance.\n>\n> Those who want to mine the side chain will assemble  side chain block candidates that comply the rules of the side chain, then a Bitcoin transaction burning to the hash of the block candidate and submit it to the Bitcoin network. Should he burn transaction be included into the Bitcoin block chain and the Bitcoin block\u2019s hash satisfy the lottery criteria, then the block candidate can be submitted to extend the side chain.\n>\n> A side chain block header sequence would be accepted as side chain trunk if a sequence of Bitcoin SPV proofs for burn transactions prove, that linked blocks have the highest cumulative burn, if compared to alternative sequences. \n>\n> The Bitcoin miner will include burn transactions because they offer Bitcoin fees. Bitcoin miner can not selectively block side chains since the hashes associated with the burn do not disclose which side chain or other project they are for. Here you have a \u201cmerged mining\u201d that does not need Bitcoin miner support or even consent.\n>\n> Mining difficulty of the side chain could be adjusted by stepping up the required burn and/or hardening the criteria that links a burn proof transaction with the bitcoin block hash it is included in.\n>\n> The difficulty to mine with burn would be dynamic and would also imply a floating exchange rate between Bitcoin and the side coin.\n>\n> Tamas Blummer\n> Bits of Proof\n>\n> 00000000000000001172380e63346e3e915b52fcbae838ba958948ac9aa85edd\n>\n>\n> ------------------------------------------------------------------------------\n> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n> from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n> with Interactivity, Sharing, Native Excel Exports, App Integration & more\n> Get technology previously reserved for billion-dollar corporations, FREE\n> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n>\n>\n> _______________________________________________\n> Bitcoin-development mailing list\n> Bitcoin-development at lists.sourceforge.net\n> https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141210/ed5fdc7d/attachment.html>"
            },
            {
                "author": "Isidor Zeuner",
                "date": "2014-12-15T14:55:06",
                "message_text_only": "> The goal is to have an opportunity cost to breaking the rules.\n>\n> Proof of Burn is a real cost for following the rules.\n>\n\nFor every participant who could try to decide about the adequateness\nof the cost, no direct effect comes from the difference between Proof\nof Burn, and approaches which keep the Bitcoins inside the set of\noutputs that can still participate. So, any notion which\ndifferentiates with respect to this must make some assumption about\nwhat defines the interest of the Bitcoin nodes as a community.\n\nBest regards,\n\nIsidor"
            },
            {
                "author": "Tamas Blummer",
                "date": "2014-12-16T08:28:02",
                "message_text_only": "The output has to be burned  otherwise there is no cost of expressing\nany number of alternate opinions the same time. \n\nTamas Blummer\nBits of Proof\n\nOn Dec 15, 2014, at 3:55 PM, Isidor Zeuner <cryptocurrencies at quidecco.de> wrote:\n> For every participant who could try to decide about the adequateness\n> of the cost, no direct effect comes from the difference between Proof\n> of Burn, and approaches which keep the Bitcoins inside the set of\n> outputs that can still participate. So, any notion which\n> differentiates with respect to this must make some assumption about\n> what defines the interest of the Bitcoin nodes as a community.\n> \n> Best regards,\n> \n> Isidor\n> \n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/1d71ad5e/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 496 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/1d71ad5e/attachment.sig>"
            },
            {
                "author": "Alex Mizrahi",
                "date": "2014-12-16T09:55:50",
                "message_text_only": ">  The goal is to have an opportunity cost to breaking the rules.\n>\n\nYou could as well have said \"The goal is to implement it in a specific way\nI want it to be implemented.\"\nThis makes zero sense.\nYou aren't even trying to compare properties of different possible\nimplementations, you just outright reject the alternatives.\n\nSo the thing is, relying on opportunity cost is rather problematic.\n\n1. can't work when system isn't heavily used (you'll have to rely on the\nhonesty of miners instead)\n2. chicken-and-egg: system is not secure until it is heavily used, and it\nisn't heavily used until it is secure\n3. finally, if the expected profit from attack is higher than the\nopportunity cost of it, it just makes no sense\n\nLet's put 1 and 2 aside. For the start, you need to prove that attack\ncannot yield profits which are higher than honest mining.\n\nThe problem with it is that the total amount of money is much higher than\nthe amount of money which is being transacted in a short time frame. And it\nis much higher than what fees might yield within a reasonable time frame.\n\nSo if there is a way to attack the whole (with a profit proportional to the\nwhole), you won't be able to rely on opportunity cost to prevent the attack.\n\nUsually at this point people say \"we assume that miners aren't going to\ncollude, otherwise even Bitcoin is not secure\".\nWell, this is BS. The fact that a pool can acquire more than 50% of total\nhashpower was successfully demonstrated by ghash.io.\nBut the thing is, Bitcoin doesn't offer one a good way to attack the whole,\nas there are powerful factors which will work against the attacker.\nBut this is not the case with sidechains (or any merged-mined chains, for\nthat matter).\nAnd once you have a clear incentive, collusion is much more likely.\n\n\n> Proof of Burn is a real cost for following the rules.\n>\n\n So what? As long as cost is less than revenue, it is OK.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/ec335df8/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2014-12-16T12:36:42",
                "message_text_only": "On Tue, Dec 16, 2014 at 11:55:50AM +0200, Alex Mizrahi wrote:\n> Usually at this point people say \"we assume that miners aren't going to\n> collude, otherwise even Bitcoin is not secure\".\n> Well, this is BS. The fact that a pool can acquire more than 50% of total\n> hashpower was successfully demonstrated by ghash.io.\n> But the thing is, Bitcoin doesn't offer one a good way to attack the whole,\n> as there are powerful factors which will work against the attacker.\n> But this is not the case with sidechains (or any merged-mined chains, for\n> that matter).\n> And once you have a clear incentive, collusion is much more likely.\n\n+1\n\nIt's notable that blockstream hasn't published much if anything concrete\non what exactly you'd use merge-mined sidechains for; they're even worse\nthan Ethereum in that regard.\n\n> > Proof of Burn is a real cost for following the rules.\n> >\n> \n>  So what? As long as cost is less than revenue, it is OK.\n\nIt's even better than that: if an attack does happen, the participants\nin the consensus system have an incentive to defend against it to\nmaintain the value of their tokens. Proof-of-burn allows that defense to\nbe in response to a threat, and essentially unlimited in size.\n\nSo now any attacker knows that if they launch an attack in theory the\nresponse could be as strong as the value of the system itself.\n\nThis can be improved upon with systems that allow the tokens to be\nburned, \"internal\" proof-of-burn. This suffers from \"nothing-at-stake\"\nvulnerabilities to an extent, OTOH within the context of the system it\nis a true sacrifice of value; probably not a big deal in a zookeyv-style\nblock-DAG where multiple lines of history can be combined. Here the\nincentives of the defenders are even more strongly tipped towards\nburning their value to preserve the system, not unlike\nreplace-by-fee-scorched-earth thinking.\n\n-- \n'peter'[:-1]@petertodd.org\n00000000000000000e0c078667795abe21bfdebb913eba60cc7a625c732f0a89\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/369a1f00/attachment.sig>"
            },
            {
                "author": "Isidor Zeuner",
                "date": "2014-12-11T12:09:16",
                "message_text_only": "[...]\n> The Bitcoin miner will include burn transactions because they offer\n> Bitcoin fees. Bitcoin miner can not selectively block side chains\n> since the hashes associated with the burn do not disclose which side\n> chain or other project they are for. Here you have a \u201cmerged\n> mining\u201d that does not need Bitcoin miner support or even consent.\n>\n\nMiners might decide to block all burn transactions, and other nodes\nmight decide to stop relaying them. This may be considered as\npreferable by all participants who do not want to add more potential\nfor deflation.\n\nBest regards,\n\nIsidor"
            },
            {
                "author": "Tamas Blummer",
                "date": "2014-12-11T14:56:24",
                "message_text_only": "Isodor: Rational Miner will include burn transaction for fee, no doubt. Censoring transactions is against Bitcoin\u2019s core values, unlikely to get wide support for any form of that.\n\nPatrick: Mining is at cost even if following the rules. No change to that.\n\nTamas Blummer\nBits of Proof\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141211/8b7cc2e1/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 496 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141211/8b7cc2e1/attachment.sig>"
            },
            {
                "author": "Tamas Blummer",
                "date": "2014-12-15T10:21:01",
                "message_text_only": "Burn mining side chains might be one of the foundation ideas for that ecosystem, enabling permission-less merge mining for\nanyone with interest in a side chain.\n\nI am puzzled by the lack of feedback on the idea.\n\nTamas Blummer\nBits of Proof\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/ecb6c9ca/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 496 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/ecb6c9ca/attachment.sig>"
            },
            {
                "author": "Peter Todd",
                "date": "2014-12-15T12:39:42",
                "message_text_only": "On Mon, Dec 15, 2014 at 11:21:01AM +0100, Tamas Blummer wrote:\n> Burn mining side chains might be one of the foundation ideas for that ecosystem, enabling permission-less merge mining for\n> anyone with interest in a side chain.\n> \n> I am puzzled by the lack of feedback on the idea.\n\nIt's not a new idea actually - I outlined a system I eventually called\n\"zookeyv\"\u00b9 based on the notion of sacrificing Bitcoins to achieve\nconsensus a year and a half ago on #bitcoin-wizards. The discussion\nstarted here and continued for a few days:\n\nhttps://download.wpsoftware.net/bitcoin/wizards/2013/05/13-05-29.log\n\nI later wrote up the idea in the context of adding Zerocoin to Bitcoin:\n\nhttp://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg02472.html\n\nFor key-value mapping I eventually decided that the system didn't\nnecessarily need to be a strict linear blockchain - a directed acyclic\ngraph of commitments had advantages as there needed to be less\nsyncronization between transactions. This also means that the graph\ndoesn't necessarily need to be revealed directly in the blockchain,\nexposing it to miner censorship. OTOH revealing it makes it easy to\ndetermine if an attacker larger than you exists. These days I'd suggest\nusing timelock crypto to defeat miner censorship, while ensuring that in\nprinciple consensus over all possible parts of the chain can eventually\nbe reached.\u00b2\n\nProof-of-sacrifice for consensus has a few weird properties. For\ninstance you can defeat attackers after the fact by simply sacrificing\nmore than the attacker. Not unlike having a infinite amount of mining\nequipment available with the only constraint being funds to pay for the\nelectricity. (which *is* semi-true with altcoins!)\n\nAs for your specific example, you can improve it's censorship resistance\nby having the transactions commit to a nonce in advance in some way\nindistinguishable from normal transactions, and then making the\nselection criteria be some function of H(nonce | blockhash) - for\ninstance highest wins. So long as the chain selection is based on\ncumulative difficulty based on a fixed target - as is the case in\nBitcoin proper - you should get a proper incentive to publish blocks, as\nwell as the \"total work information rachet\" effect Bitcoin has against\nattackers.\n\n\n1) In honor of Zooko's triangle.\n\n2) This doesn't necessarily take as much work as you might expect: you\n   can work backwards from the most recent block(s) if the scheme\n   requires block B_i to include the decryption key for block B_{i-1}.\n\n-- \n'peter'[:-1]@petertodd.org\n000000000000000018d439a78581d2a9ecd762a2b37dd5b403a82beb58dcbc7c\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/493ead87/attachment.sig>"
            },
            {
                "author": "Tamas Blummer",
                "date": "2014-12-15T13:06:32",
                "message_text_only": "Peter,\n\nThanks for the research, I am glad that the idea, that proof-of-burn can \u201ctransfer\" proof-of-work \nwas discussed earlier, as those discussions give some attack vectors that I can reevaluate in \na new context, that is side chains. \n\nI think that the lottery component I suggested, makes it much more resilient to \u201coutspend\u201d attack, since\nthe attacker not only needs to outspend but win the lottery for a reorg. This raises the cost of the attack\nby magnitudes above the regular miner burn cost.\n\nIn addition, I suggest the burn transaction to include the Bitcoin block height, thereby disabling re-use of a burn,\nfor a later reorg.\n\nTamas Blummer\nBits of Proof\n\nOn Dec 15, 2014, at 1:39 PM, Peter Todd <pete at petertodd.org> wrote:\n\n> On Mon, Dec 15, 2014 at 11:21:01AM +0100, Tamas Blummer wrote:\n>> Burn mining side chains might be one of the foundation ideas for that ecosystem, enabling permission-less merge mining for\n>> anyone with interest in a side chain.\n>> \n>> I am puzzled by the lack of feedback on the idea.\n> \n> It's not a new idea actually - I outlined a system I eventually called\n> \"zookeyv\"\u00b9 based on the notion of sacrificing Bitcoins to achieve\n> consensus a year and a half ago on #bitcoin-wizards. The discussion\n> started here and continued for a few days:\n> \n> https://download.wpsoftware.net/bitcoin/wizards/2013/05/13-05-29.log\n> \n> I later wrote up the idea in the context of adding Zerocoin to Bitcoin:\n> \n> http://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg02472.html\n> \n> For key-value mapping I eventually decided that the system didn't\n> necessarily need to be a strict linear blockchain - a directed acyclic\n> graph of commitments had advantages as there needed to be less\n> syncronization between transactions. This also means that the graph\n> doesn't necessarily need to be revealed directly in the blockchain,\n> exposing it to miner censorship. OTOH revealing it makes it easy to\n> determine if an attacker larger than you exists. These days I'd suggest\n> using timelock crypto to defeat miner censorship, while ensuring that in\n> principle consensus over all possible parts of the chain can eventually\n> be reached.\u00b2\n> \n> Proof-of-sacrifice for consensus has a few weird properties. For\n> instance you can defeat attackers after the fact by simply sacrificing\n> more than the attacker. Not unlike having a infinite amount of mining\n> equipment available with the only constraint being funds to pay for the\n> electricity. (which *is* semi-true with altcoins!)\n> \n> As for your specific example, you can improve it's censorship resistance\n> by having the transactions commit to a nonce in advance in some way\n> indistinguishable from normal transactions, and then making the\n> selection criteria be some function of H(nonce | blockhash) - for\n> instance highest wins. So long as the chain selection is based on\n> cumulative difficulty based on a fixed target - as is the case in\n> Bitcoin proper - you should get a proper incentive to publish blocks, as\n> well as the \"total work information rachet\" effect Bitcoin has against\n> attackers.\n> \n> \n> 1) In honor of Zooko's triangle.\n> \n> 2) This doesn't necessarily take as much work as you might expect: you\n>   can work backwards from the most recent block(s) if the scheme\n>   requires block B_i to include the decryption key for block B_{i-1}.\n> \n> -- \n> 'peter'[:-1]@petertodd.org\n> 000000000000000018d439a78581d2a9ecd762a2b37dd5b403a82beb58dcbc7c\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/5921cb09/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 496 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/5921cb09/attachment.sig>"
            },
            {
                "author": "Tamas Blummer",
                "date": "2014-12-16T12:30:04",
                "message_text_only": "Let me be more concrete in implementation details: \n\n1) burn transaction sends at least n satoshis to an OP_RETURN h, \n2) h mod m matches the bitcoin block hash mod m, for the block the burn transaction was mined into.\n3) The side chain block header hashes to h and also contains the bitcoin block hight.\n4) a side chain block releases x new side coins\n\nSince the burn hash does not reveal in advance which side chain it will be used for, the Bitcoin miner can not selectively block burn mining. They will include loosing bets for the Bitcoin fee. Bitcoin miner have no advantage over independent burn miner of the side chain.\n\nAnyone who issues a burn transaction that complies the rules 1-3 has 1/m the chance to win the next block on the side chain. This implies a fair exchange rate of n*m satoshis = x side coins (at the margin).\n\nShould two burn transactions fulfill the mod m lottery criteria, then we have a competing fork on the side chain. Just as for Bitcoin, the next block(s) will pick the winner. \n\nTo contain fork rate, the parameter m would have to be adjusted dynamically, similar to Bitcoins difficulty. It needs to increase if fork rate increases and decrease if no valid block is burned with Bitcoin blocks. Unfortunately SPV can only prove the existence of a transaction, but not the non-existence of an alternative. Therefore the fork rate within a block cycle can not be evaluated with SPV proofs. \n\nRational burn miner who frequently faces and loses head-to-head runs with a competing forks would increase his bet for the next burn cycle, as increasing the individual bet amount has the advantage that if he wins his victory is more stable. Remember the side chain trunk is selected as the one with highest cumulative burn.\n\nConsequently cumulative burn within an adjustment period (measured in Bitcoin blocks) is expected to rise in face of high fork rate. If the sample period burn exceeds a target, then it would trigger a rise to the lottery criteria m, reducing the fork rate and vs.\n\nTamas Blummer\nBits of Proof\n\nOn Dec 10, 2014, at 8:35 AM, Tamas Blummer <tamas at bitsofproof.com> wrote:\n\n> \n> We spend scarce resources external to the digital realm to create Bitcoin. Real world sacrifice is needed to avoid \u201cnothing at stake\u201d  and sybil attacks. With Bitcoin we now have a scarce resource within the digital realm, so it appeals my intuition to re-use it for sacrifice instead of linking again an external, real world resource. \n> \n> In following I outline a new mining algorithm for side chains, that burn Bitcoins to secure them.\n> \n> The side chain block validity rules would require that a transaction on the Bitcoin block chain provably destroys Bitcoins with an OP_RET output, that contains the hash of the block header of the side chain. To also introduce a lottery, the burn transaction\u2019s hash is required to satisfy some function of the block hash it was included in on the Bitcoin block chain. For example modulo m of the burn transaction hash must match modulo m of the block hash, that is not known in advance.\n> \n> Those who want to mine the side chain will assemble  side chain block candidates that comply the rules of the side chain, then a Bitcoin transaction burning to the hash of the block candidate and submit it to the Bitcoin network. Should he burn transaction be included into the Bitcoin block chain and the Bitcoin block\u2019s hash satisfy the lottery criteria, then the block candidate can be submitted to extend the side chain.\n> \n> A side chain block header sequence would be accepted as side chain trunk if a sequence of Bitcoin SPV proofs for burn transactions prove, that linked blocks have the highest cumulative burn, if compared to alternative sequences. \n> \n> The Bitcoin miner will include burn transactions because they offer Bitcoin fees. Bitcoin miner can not selectively block side chains since the hashes associated with the burn do not disclose which side chain or other project they are for. Here you have a \u201cmerged mining\u201d that does not need Bitcoin miner support or even consent.\n> \n> Mining difficulty of the side chain could be adjusted by stepping up the required burn and/or hardening the criteria that links a burn proof transaction with the bitcoin block hash it is included in.\n> \n> The difficulty to mine with burn would be dynamic and would also imply a floating exchange rate between Bitcoin and the side coin.\n> \n> Tamas Blummer\n> Bits of Proof\n> \n> 00000000000000001172380e63346e3e915b52fcbae838ba958948ac9aa85edd\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/4179037c/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 496 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/4179037c/attachment.sig>"
            },
            {
                "author": "Tamas Blummer",
                "date": "2014-12-18T16:23:53",
                "message_text_only": "Moving further with the Idea:\n\nAlternative to re-adjusting the lottery criteria, the side chain block candidate could be required to prove a work to be eligible for the burn lottery. \n\nA mix of required burn, work and luck could be tailored to achieve the desired \"51% resilience\u201d of the side chain. \n\nThe side chain could use work for regular blocks and a much higher \u201cdifficulty\u201d parent chain burn lottery for less frequent \u201ccheckpoints\". \n\nEg. the side chain difficulty of 1/n of Bitcoin is attainable for a small side chain miner community to advance its chain at Bitcoin\u2019s speed. Simultaneously the block candidates\nwould be submitted to a Bitcoin burn lottery with 1/n odds, so the security of the side chain roughly equals that of Bitcoin at every successful burn mined checkpoint.\n\nTamas Blummer\nBits of Proof\n\nOn Dec 16, 2014, at 1:30 PM, Tamas Blummer <tamas at bitsofproof.com> wrote:\n\n> Let me be more concrete in implementation details: \n> \n> 1) burn transaction sends at least n satoshis to an OP_RETURN h, \n> 2) h mod m matches the bitcoin block hash mod m, for the block the burn transaction was mined into.\n> 3) The side chain block header hashes to h and also contains the bitcoin block hight.\n> 4) a side chain block releases x new side coins\n> \n> Since the burn hash does not reveal in advance which side chain it will be used for, the Bitcoin miner can not selectively block burn mining. They will include loosing bets for the Bitcoin fee. Bitcoin miner have no advantage over independent burn miner of the side chain.\n> \n> Anyone who issues a burn transaction that complies the rules 1-3 has 1/m the chance to win the next block on the side chain. This implies a fair exchange rate of n*m satoshis = x side coins (at the margin).\n> \n> Should two burn transactions fulfill the mod m lottery criteria, then we have a competing fork on the side chain. Just as for Bitcoin, the next block(s) will pick the winner. \n> \n> To contain fork rate, the parameter m would have to be adjusted dynamically, similar to Bitcoins difficulty. It needs to increase if fork rate increases and decrease if no valid block is burned with Bitcoin blocks. Unfortunately SPV can only prove the existence of a transaction, but not the non-existence of an alternative. Therefore the fork rate within a block cycle can not be evaluated with SPV proofs. \n> \n> Rational burn miner who frequently faces and loses head-to-head runs with a competing forks would increase his bet for the next burn cycle, as increasing the individual bet amount has the advantage that if he wins his victory is more stable. Remember the side chain trunk is selected as the one with highest cumulative burn.\n> \n> Consequently cumulative burn within an adjustment period (measured in Bitcoin blocks) is expected to rise in face of high fork rate. If the sample period burn exceeds a target, then it would trigger a rise to the lottery criteria m, reducing the fork rate and vs.\n> \n> Tamas Blummer\n> Bits of Proof\n> \n> On Dec 10, 2014, at 8:35 AM, Tamas Blummer <tamas at bitsofproof.com> wrote:\n> \n>> \n>> We spend scarce resources external to the digital realm to create Bitcoin. Real world sacrifice is needed to avoid \u201cnothing at stake\u201d  and sybil attacks. With Bitcoin we now have a scarce resource within the digital realm, so it appeals my intuition to re-use it for sacrifice instead of linking again an external, real world resource. \n>> \n>> In following I outline a new mining algorithm for side chains, that burn Bitcoins to secure them.\n>> \n>> The side chain block validity rules would require that a transaction on the Bitcoin block chain provably destroys Bitcoins with an OP_RET output, that contains the hash of the block header of the side chain. To also introduce a lottery, the burn transaction\u2019s hash is required to satisfy some function of the block hash it was included in on the Bitcoin block chain. For example modulo m of the burn transaction hash must match modulo m of the block hash, that is not known in advance.\n>> \n>> Those who want to mine the side chain will assemble  side chain block candidates that comply the rules of the side chain, then a Bitcoin transaction burning to the hash of the block candidate and submit it to the Bitcoin network. Should he burn transaction be included into the Bitcoin block chain and the Bitcoin block\u2019s hash satisfy the lottery criteria, then the block candidate can be submitted to extend the side chain.\n>> \n>> A side chain block header sequence would be accepted as side chain trunk if a sequence of Bitcoin SPV proofs for burn transactions prove, that linked blocks have the highest cumulative burn, if compared to alternative sequences. \n>> \n>> The Bitcoin miner will include burn transactions because they offer Bitcoin fees. Bitcoin miner can not selectively block side chains since the hashes associated with the burn do not disclose which side chain or other project they are for. Here you have a \u201cmerged mining\u201d that does not need Bitcoin miner support or even consent.\n>> \n>> Mining difficulty of the side chain could be adjusted by stepping up the required burn and/or hardening the criteria that links a burn proof transaction with the bitcoin block hash it is included in.\n>> \n>> The difficulty to mine with burn would be dynamic and would also imply a floating exchange rate between Bitcoin and the side coin.\n>> \n>> Tamas Blummer\n>> Bits of Proof\n>> \n>> 00000000000000001172380e63346e3e915b52fcbae838ba958948ac9aa85edd\n> \n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141218/ba26d4c3/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 496 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141218/ba26d4c3/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Merged mining a side chain with proof of burn on parent chain",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Tamas Blummer",
                "Isidor Zeuner",
                "patrick",
                "Peter Todd",
                "Alex Mizrahi"
            ],
            "messages_count": 13,
            "total_messages_chars_count": 31890
        }
    },
    {
        "title": "[Bitcoin-development] BitCoin TPB, P2P Currency/Torrent",
        "thread_messages": [
            {
                "author": "Tiago Docilio Caldeira",
                "date": "2014-12-10T17:07:38",
                "message_text_only": "Dear All,\n\nI've been trying to better understand the bitcoin in the last few months,\nboth in the mathematical as the programming point of view. I went through\npart of the documentation, and I got curious to find ways to use their data\npackage to store some useful msg.\n\nAs most of you know, one of the freedom parts of the internet was\n(temporary) knock out yesterday, the PirateBay, a \"service\" that was built\nin open source and the freedom to share, so I start trying to design an\nidea to allow us to create the future of p2p transference, using bitcoin as\na currency and data provider.\n\nIf you insert similar message that a torrent has inside of a bitcoin\nportion (for example, in a satochi), you could not only \"tip\" the person\nwho would share the content (eventually, even the producer of it), but\nalso, make a public (but anonymous) request of a certain content.\n\nBy doing this micro transference, you would receive an entry to a content\ntorrent information.\n\nWhat is your opinion about this? Would someone (with more pratice inside\nbitcoin algorithms) be interested in developing some front end with me?\n\nHope that you like the idea, and share the vision of a open content world,\nwith fair return for the people who shares the data.\n\nBest Regards,\n\nTiago Caldeira\nbitcoin: 1BTdPcpLfpLVouDh32532SqCXibAjXoRqp\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141210/321b6dde/attachment.html>"
            },
            {
                "author": "Parazyd",
                "date": "2014-12-10T17:18:31",
                "message_text_only": "What came to my mind today, is, implementing a blockchain as a tracker. \nNothing to do with Bitcoin as such, but with the blockchain \nplatform/technology.\nI thought about making the blockchain contain all the magnet links and \ndeveloping it independently. But that's another story and I think it has \nno place in this mailing list.\nAlso, you do realize that the majority of The Pirate Bay's content is \nillegal and shouldn't be discussed here.\n\nYou talk about open source, and yet you insist on people doing spam \ntransactions in order to access certain content? That's a no-no.\n\nOn 12/10/2014 06:07 PM, Tiago Docilio Caldeira wrote:\n> Dear All,\n>\n> I've been trying to better understand the bitcoin in the last few \n> months, both in the mathematical as the programming point of view. I \n> went through part of the documentation, and I got curious to find ways \n> to use their data package to store some useful msg.\n>\n> As most of you know, one of the freedom parts of the internet was \n> (temporary) knock out yesterday, the PirateBay, a \"service\" that was \n> built in open source and the freedom to share, so I start trying to \n> design an idea to allow us to create the future of p2p transference, \n> using bitcoin as a currency and data provider.\n>\n> If you insert similar message that a torrent has inside of a bitcoin \n> portion (for example, in a satochi), you could not only \"tip\" the \n> person who would share the content (eventually, even the producer of \n> it), but also, make a public (but anonymous) request of a certain content.\n>\n> By doing this micro transference, you would receive an entry to a \n> content torrent information.\n>\n> What is your opinion about this? Would someone (with more pratice \n> inside bitcoin algorithms) be interested in developing some front end \n> with me?\n>\n> Hope that you like the idea, and share the vision of a open content \n> world, with fair return for the people who shares the data.\n>\n> Best Regards,\n>\n> Tiago Caldeira\n> bitcoin: 1BTdPcpLfpLVouDh32532SqCXibAjXoRqp\n>\n>\n>\n> ------------------------------------------------------------------------------\n> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n> from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n> with Interactivity, Sharing, Native Excel Exports, App Integration & more\n> Get technology previously reserved for billion-dollar corporations, FREE\n> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n>\n>\n> _______________________________________________\n> Bitcoin-development mailing list\n> Bitcoin-development at lists.sourceforge.net\n> https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141210/78c19b09/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BitCoin TPB, P2P Currency/Torrent",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Tiago Docilio Caldeira",
                "Parazyd"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 4362
        }
    },
    {
        "title": "[Bitcoin-development] Setting the record straight on Proof-of-Publication",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2014-12-12T09:05:51",
                "message_text_only": "Introduction\n============\n\nWhile not a new concept proof-of-publication is receiving a significant\namount of attention right now both as an idea, with regard to the\nembedded consensus systems that make use of it, and in regard to the\nsidechains model proposed by Blockstream that rejects it. Here we give a\nclear definition of proof-of-publication and its weaker predecessor\ntimestamping, describe some usecases for it, and finally dispel some of\nthe common myths about it.\n\n\nWhat is timestamping?\n=====================\n\nA cryptographic timestamp proves that message m existed prior to some\ntime t.\n\nThis is the cryptographic equivalent of mailing yourself a patentable\nidea in a sealed envelope to establish the date at which the idea\nexisted on paper.\n\nTraditionally this has been done with one or more trusted third parties\nwho attest to the fact that they saw m prior to the time t. More\nrecently blockchains have been used for this purpose, particularly the\nBitcoin blockchain, as block headers include a block time which is\nverified by the consensus algorithm.\n\n\nWhat is proof-of-publication?\n=============================\n\nProof-of-publication is what solves the double-spend problem.\n\nCryptographic proof-of-publication actually refers to a few closely\nrelated proofs, and practical uses of it will generally make use of more\nthan one proof.\n\n\nProof-of-receipt\n----------------\n\nProve that every member p in of audience P has received message m. A\nreal world analogy is a legal notice being published in a major\nnewspaper - we can assume any subscriber received the message and had a\nchance to read it.\n\n\nProof-of-non-publication\n------------------------\n\nProve that message m has *not* been published. Extending the above real\nworld analogy the court can easily determine that a legal notice was not\npublished when it should have been by examining newspaper archives. (or\nequally, *because* the notice had not been published, some action a\nlitigant had taken was permissable)\n\n\nProof-of-membership\n-------------------\n\nA proof-of-non-publication isn't very useful if you can't prove that\nsome member q is in the audience P. In particular, if you are to\nevaluate a proof-of-membership, q is yourself, and you want assurance\nyou are in that audience. In the case of our newspaper analogy because\nwe know what today's date is, and we trust the newspaper never to\npublish two different editions with the same date we can be certain we\nhave searched all possible issues where the legal notice may have been\npublished.\n\n\nReal-world proof-of-publication: The Torrens Title System\n---------------------------------------------------------\n\nLand titles are a real-world example, dating back centuries, with\nremarkable simularities to the Bitcoin blockchain. Prior to the torrens\nsystem land was transferred between owners through a chain of valid\ntitle deeds going back to some \"genesis\" event establishing rightful\nownership independently of prior history. As with the blockchain the\ntitle deed system has two main problems: establishing that each title\ndeed in the chain is valid in isolation, and establishing that no other\nvalid title deeds exist. While the analogy isn't exact - establishing\nthe validity of title deeds isn't as crisp a process as simple checking\na cryptographic signature - these two basic problems are closely related\nto the actions of checking a transaction's signatures in isolation, and\nensuring it hasn't been double-spent.\n\nTo solve these problems the Torrens title system was developed, first in\nAustralia and later Canada, to establish a singular central registry of\ndeeds, or property transfers. Simplifying a bit we can say inclusion -\npublication - in the official registery is a necessary pre-condition to\na given property transfer being valid. Multiple competing transfers are\nmade obvious, and the true valid transfer can be determined by whichever\ntransfer happened first.\n\nSimilarly in places where the Torrens title system has not been adopted,\nalmost always a small number of title insurance providers have taken on\nthe same role. The title insurance provider maintains a database of all\nknown title deeds, and in practice if a given title deed isn't published\nin the database it's not considered valid.\n\n\nCommon myths\n============\n\nProof-of-publication is the same as timestamping\n------------------------------------------------\n\nNo. Timestamping is a significantly weaker primitive than\nproof-of-publication. This myth seems to persist because unfortunately\nmany members of the Bitcoin development and theory community - and even\nmembers of the Blockstream project - have frequently used the term\n\"timestamping\" for applications that need proof-of-publication.\n\n\nPublication means publishing meaningful data to the whole world\n---------------------------------------------------------------\n\nNo. The data to be published can often be an otherwise meaningless\nnonce, indistinguishable from any other random value. (e.g. an ECC\npubkey)\n\nFor example colored coins can be implemented by committing the hash of\nthe map of colored inputs to outputs inside a transaction. These maps\ncan be passed from payee to payor to prove that a given output is\ncolored with a set of recursive proofs, as is done in the author's\nSmartcolors library. The commitment itself can be a simple hash, or even\na pay-to-contract style derived pubkey.\n\nA second example is Zerocash, which depends on global consensus of a set\nof revealed serial numbers. As this set can include \"false-positives\" -\nfalse revealed serial numbers that do not actually correspond to a real\nZerocash transaction - the blockchain itself can be that set. The\nZerocash transactions themselves - and associated proofs - can then be\npassed around via a p2p network separate from the blockchain itself.\nEach Zerocash Pour proof then simply needs to specify what set of\npriorly evaluated proofs makes up its particular commitment merkle tree\nand the proofs are then evaluated against that proof-specific tree. (in\npractice likely some kind of DAG-like structure) (note that there is a\nsybil attack risk here: a sybil attack reduces your k-anonymity set by\nthe number of transactions you were prevented from seeing; a weaker\nproof-of-publication mechanism may be appropriate to prevent that sybil\nattack).\n\nThe published data may also not be meaningful because it is encrypted.\nOnly a small community may need to come to consensus about it; everyone\nelse can ignore it. For instance proof-of-publication for decentralized\nasset exchange is an application where you need publication to be\ntimely, however the audience may still be small. That audience can share\nan encryption key.\n\n\nProof-of-publication is always easy to censor\n---------------------------------------------\n\nNo, with some precautions. This myth is closely related to the above\nidea that the data must be globally meaningful to be useful. The colored\ncoin and Zerocash examples above are cases where censoring the\npublication is obviously impossible as it can be made prior to giving\nanyone at all sufficient info to determine if the publicaiton has been\nmade; the data itself is just nonces.\n\nIn the case of encrypted data the encryption key can also often be\nrevealed well after the publication has been made. For instance in a\nCertificate Transparency scheme the certificate authority (CA) may use\nproof-of-publication to prove that a certificate was in a set of\ncertificates. If that set of certificates is hashed into a merkelized\nbinary prefix tree indexed by domain name the correct certificate for a\ngiven domain name - or lack thereof - is easily proven. Changes to that\nset can be published on the blockchain by publishing successive prefix\ntree commitments.\n\nIf these commitments are encrypted, each commitment C_i can also commit\nto the encryption key to be used for C_{i+1}. That key need not be\nrevealed until the commitment is published; validitity is assured as\nevery client knows that only one C_{i+1} is possible, so any malfeasance\nis guaranteed to be revealed when C_{i+2} is published.\n\nSecondly the published data can be timelock encrypted with timelocks\nthat take more than the average block interval to decrypt. This puts\nwould-be censoring miners into a position of either delaying all\ntransactions, or accepting that they will end up mining publication\nproofs. The only way to circumvent this is highly restrictive\nwhitelisting.\n\n\nProof-of-publication is easier to censor than (merge)-mined sidechains\n----------------------------------------------------------------------\n\nFalse under all circumstances. Even if the publications use no\nanti-censorship techniques to succesfully censor a proof-of-publication\nsystem at least 51% of the total hashing power must decide to censor it,\nand they must do so by attacking the other 49% of hashing power -\nspecifically rejecting their blocks. This is true no matter how \"niche\"\nthe proof-of-publication system is - whether it is used by two people or\ntwo million people it has the same security.\n\nOn the other hand a (merge)-mined sidechain with x% of the total hashing\npower supporting it can be attacked at by anyone with >x% hashing power.\nIn the case of a merge-mined sidechain this cost will often be near zero\n- only by providing miners with a significant and ongoing reward can the\nmarginal cost be made high. In the case of sidechains with niche\naudiences this is particularly true - sidechain advocates have often\nadvocated that sidechains be initially protected by centralized\ncheckpoints until they become popular enough to begin to be secure.\n\nSecondly sidechains can't make use of anti-censorship techniques the way\nproof-of-publication systems can: they inherently must be public for\nminers to be able to mine them in a decentralized fashion. Of course,\nusers of them may use anti-censorship techniques, but that leads to a\nsimple security-vs-cost tradeoff between using the Bitcoin blockchain\nand a sidechain. (note the simularity to the author's treechains\nproposal!)\n\n\nProof-of-publication can be made expensive\n------------------------------------------\n\nTrue, in some cases! By tightly constraining the Bitcoin scripting\nsystem the available bytes for stenographic embedment can be reduced.\nFor instance P2SH^2 requires an brute force exponentially increasing\namount of hashes-per-byte-per-pushdata. However this is still\nineffective against publishing hashes, and to fully implement it -\nscriptSigs included - would require highly invasive changes to the\nentire scripting system that would greatly limit its value.\n\n\nProof-of-publication can be outsourced to untrusted third-parties\n-----------------------------------------------------------------\n\nTimestamping yes, but proof-of-publication no.\n\nWe're talking about systems that attempt to publish multiple pieces of\ndata from multiple parties with a single hash in the Bitcoin blockchain,\nsuch as Factom.  Essentially this works by having a \"child\" blockchain,\nand the hash of that child blockchain is published in the master Bitcoin\nblockchain. To prove publicaiton you prove that your message is in that\nchild chain, and the child chain is itself published in the Bitcoin\nblockchain.  Proving membership is possible for yourself by determining\nif you have the contents corresponding to the most recent child-chain\nhash.\n\nThe problem is proving non-publication. The set of all *potential*\nchild-chain hashes must be possible to obtain by scanning the Bitcoin\nblockchain. As a hash is meaningless by itself, these hashes must be\nsigned. That introduces a trusted third-party who can also sign an\ninvalid hash that does not correspond to a block and publish it in the\nblockchain. This in turn makes it impossible for anyone using the child\nblockchain to prove non-publication - they can't prove they did not\npublish a message because the content of *all* child blockchains is now\nunknown.\n\nIn short, Factom and systems like it rely on trusted third parties who\ncan put you in a position where you can't prove you did not commit\nfraud.\n\n\nProof-of-publication \"bloats\" the blockchain\n--------------------------------------------\n\nDepends on your perspective.\n\nSystems that do not make use of the UTXO are no different technically\nthan any other transaction: they pay fees to publish messages to the\nBitcoin blockchain with no amortized increase in the UTXO set. Some\nsystems do grow the UTXO set - a potential scaling problem as currently\nthat all full nodes must have the entire UTXO set - although there are a\nnumber of existing mechanisms and proposals to mitigate this issue such\nas the (crippled) OP_RETURN scriptPubKey format, the dust rule, the\nauthors TXO commitments, UTXO expiry etc.\n\nFrom an economic point of view proof-of-publication systems compete with\nother uses of the blockchain as they pay fees; supply of blockchain\nspace is fixed so the increased demand must result in a higher\nper-transaction price in fees. On the other hand this is true of *all*\nuses of the blockchain, which collectively share the limited transaction\ncapacity. For instance Satoshidice and similar sites have been widely\ncondemned for doing conventional transactions on Bitcoin when they could\nhave potentially used off-chain transactions.\n\nIt's unknown what the effect on the Bitcoin price will actually be. Some\nproof-of-publication uses have nothing to do with money at all - e.g.\ncertificate transparency. Others are only indirectly related, such as\nsecuring financial audit logs such as merkle-sum-trees of total Bitcoins\nheld by exchanges. Others in effect add new features to Bitcoin, such as\nhow colored coins allows the trade of assets on the blockchain, or how\nZerocash makes Bitcoin transactions anonymous. The sum total of all\nthese effects on the Bitcoin price is difficult to predict.\n\nThe authors belief is that even if proof-of-publication is a\nnet-negative to Bitcoin as it is significantly more secure than the\nalternatives and can't be effectively censored people will use it\nregardless of effects to discourage them through social pressure. Thus\nBitcoin must make technical improvements to scalability that negate\nthese potentially harmful effects.\n\n\nProof-of-publication systems are inefficient\n--------------------------------------------\n\nIf you're talking about inefficient from the perspective of a full-node\nthat does full validation, they are no different than (merge)-mined\nsidechain and altcoin alternatives. If you're talking about efficiency\nfrom the perspective of a SPV client, then yes, proof-of-publication\nsystems will often require more resources than mining-based\nalternatives.\n\nHowever it must be remembered that the cost of mining is the\nintroduction of a trusted third party - miners. Of course, mined\nproof-of-publication has miners already, but trusting those miners to\ndetermine the meaning of that data places significantly more trust in\nthem than mearly trusting them to create consensus on the order in which\ndata is published.\n\nMany usecases involve trusted third-parties anyway - the role of\nproof-of-publication is to hold those third-parties to account and keep\nthem honest. For these use-cases - certificate transparency, audit logs,\nfinancial assets - mined alternatives simply add new trusted third\nparties and points of failure rather than remove them.\n\nOf course, global consensus is inefficient - Bitcoin itself is\ninefficient. But this is a fundemental problem to Bitcoin's architecture\nthat applies to all uses of it, a problem that should be solved in\ngeneral.\n\n\nProof-of-publication needs \"scamcoins\" like Mastercoin and Counterparty\n-----------------------------------------------------------------------\n\nFirst of all, whether or not a limited-supply token is a \"scam\" is not a\ntechnical question. However some types of embedded consensus systems, a\nspecific use-case for proof-of-publication, do require limited-supply\ntokens within the system for technical reasons, for instance to support\nbid orders functionality in decentralized marketplaces.\n\nSecondly using a limited-supply token in a proof-of-publicaton system is\nwhat lets you have secure client side validation rather than the\nalternative of 2-way-pegging that requires users to trust miners not to\nsteal the pegged funds. Tokens also do not need to be, economically\nspeaking, assets that can appreciate in value relative to Bitcoin;\none-way-pegs where Bitcoins can always be turned into the token in\nconjunction with decentralized exchange to buy and sell tokens for\nBitcoins ensure the token value will always closely approximate the\nBitcoin value as long as the protocol itself is considered valuable.\n\nFinally only a subset of proof-of-publication use-cases involve tokens\nat all - many like colored coins transact directly to and from Bitcoin,\nwhile other use-cases don't even involve finance at all.\n\n-- \n'peter'[:-1]@petertodd.org\n00000000000000000681f4e5c84bc0bf7e6c5db8673eef225da652fbb785a0de\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141212/444476e8/attachment.sig>"
            },
            {
                "author": "Gareth Williams",
                "date": "2014-12-12T12:25:53",
                "message_text_only": "On 12/12/14 20:05, Peter Todd wrote:\n> Secondly using a limited-supply token in a proof-of-publicaton system is\n> what lets you have secure client side validation rather than the\n> alternative of 2-way-pegging that requires users to trust miners not to\n> steal the pegged funds. \n\n\"Secure\" and \"client side validation\" don't really belong in the same\nsentence, do they?\n\nIf I am to accept a transaction with any assurance of security at all,\nthe important question to ask is not: \"does my client consider this\nvalid?\" but: \"does the rest of the world consider this valid?\"\n\nValidated data in the blockchain is far more useful for this purpose\nthan unvalidated data with a mere proof of publication in the\nblockchain, precisely because it records what /everybody else/ considers\nvalid history (and very likely will continue to consider valid history\nin future.)\n\nPegged sidechains have their challenges, but at least they provide\ndistributed consensus on transaction history.\n\nProof-of-publication systems like Counterparty and Mastercoin require me\nto trust, with zero evidence, that everybody else's client has the exact\nsame interpretation of transaction history as mine, and will continue to\nhave for the indefinite future. How is that not a horribly broken\nsecurity model? I'd use a sidechain - with reasonable parameters that\ndisincentivise peg theft as much as practical - over that any day.\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 473 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141212/e4a2e4e2/attachment.sig>"
            },
            {
                "author": "Alex Mizrahi",
                "date": "2014-12-12T17:04:08",
                "message_text_only": ">\n> \"Secure\" and \"client side validation\" don't really belong in the same\n> sentence, do they?\n>\n\nWell, client-side validation is mathematically secure, while SPV is\neconomically secure.\nI.e. it is secure if you make several assumptions about economics of the\nwhole thing.\n\nIn my opinion the former is transfinitely more secure than the later.\nBut it's more of a philosophical question, sure.\n\nThe good thing about PoW-based consensus is that it is robust against\nversion inconsistencies and various accidents of this nature up to a\ncertain degree. But you hardly can depend on that:\nYou know, The Great Fork of 2013 was resolved through human intervention,\nBitcoin nodes were not smart enough to detect that something is going awry\non their own.\n\nNaive proof-of-publication is very fragile in that respect, but you can\neasily bring back robustness.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141212/76a5cbeb/attachment.html>"
            },
            {
                "author": "odinn",
                "date": "2014-12-12T13:41:34",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nPeter... It kind of sounds to me that (as fine of a position paper as\nthis is) on _certain_ points, you're falling prey to the \"but it's\ninefficient, but it's a scamcoin, but luke-jr told me so\" argument...\n\nI think the Mastercoin devs are doing fine work and I consider the\nzerocash devs to have developed (in v2, mint and pour) to have\ndeveloped something that will really turn the world on its ear, but\nwhat do I know? Nothing.  Nothing at all.\n\ngmorning\n\nPeter Todd:\n> Introduction ============\n> \n> While not a new concept proof-of-publication is receiving a\n> significant amount of attention right now both as an idea, with\n> regard to the embedded consensus systems that make use of it, and\n> in regard to the sidechains model proposed by Blockstream that\n> rejects it. Here we give a clear definition of proof-of-publication\n> and its weaker predecessor timestamping, describe some usecases for\n> it, and finally dispel some of the common myths about it.\n> \n> \n> What is timestamping? =====================\n> \n> A cryptographic timestamp proves that message m existed prior to\n> some time t.\n> \n> This is the cryptographic equivalent of mailing yourself a\n> patentable idea in a sealed envelope to establish the date at which\n> the idea existed on paper.\n> \n> Traditionally this has been done with one or more trusted third\n> parties who attest to the fact that they saw m prior to the time t.\n> More recently blockchains have been used for this purpose,\n> particularly the Bitcoin blockchain, as block headers include a\n> block time which is verified by the consensus algorithm.\n> \n> \n> What is proof-of-publication? =============================\n> \n> Proof-of-publication is what solves the double-spend problem.\n> \n> Cryptographic proof-of-publication actually refers to a few\n> closely related proofs, and practical uses of it will generally\n> make use of more than one proof.\n> \n> \n> Proof-of-receipt ----------------\n> \n> Prove that every member p in of audience P has received message m.\n> A real world analogy is a legal notice being published in a major \n> newspaper - we can assume any subscriber received the message and\n> had a chance to read it.\n> \n> \n> Proof-of-non-publication ------------------------\n> \n> Prove that message m has *not* been published. Extending the above\n> real world analogy the court can easily determine that a legal\n> notice was not published when it should have been by examining\n> newspaper archives. (or equally, *because* the notice had not been\n> published, some action a litigant had taken was permissable)\n> \n> \n> Proof-of-membership -------------------\n> \n> A proof-of-non-publication isn't very useful if you can't prove\n> that some member q is in the audience P. In particular, if you are\n> to evaluate a proof-of-membership, q is yourself, and you want\n> assurance you are in that audience. In the case of our newspaper\n> analogy because we know what today's date is, and we trust the\n> newspaper never to publish two different editions with the same\n> date we can be certain we have searched all possible issues where\n> the legal notice may have been published.\n> \n> \n> Real-world proof-of-publication: The Torrens Title System \n> ---------------------------------------------------------\n> \n> Land titles are a real-world example, dating back centuries, with \n> remarkable simularities to the Bitcoin blockchain. Prior to the\n> torrens system land was transferred between owners through a chain\n> of valid title deeds going back to some \"genesis\" event\n> establishing rightful ownership independently of prior history. As\n> with the blockchain the title deed system has two main problems:\n> establishing that each title deed in the chain is valid in\n> isolation, and establishing that no other valid title deeds exist.\n> While the analogy isn't exact - establishing the validity of title\n> deeds isn't as crisp a process as simple checking a cryptographic\n> signature - these two basic problems are closely related to the\n> actions of checking a transaction's signatures in isolation, and \n> ensuring it hasn't been double-spent.\n> \n> To solve these problems the Torrens title system was developed,\n> first in Australia and later Canada, to establish a singular\n> central registry of deeds, or property transfers. Simplifying a bit\n> we can say inclusion - publication - in the official registery is a\n> necessary pre-condition to a given property transfer being valid.\n> Multiple competing transfers are made obvious, and the true valid\n> transfer can be determined by whichever transfer happened first.\n> \n> Similarly in places where the Torrens title system has not been\n> adopted, almost always a small number of title insurance providers\n> have taken on the same role. The title insurance provider maintains\n> a database of all known title deeds, and in practice if a given\n> title deed isn't published in the database it's not considered\n> valid.\n> \n> \n> Common myths ============\n> \n> Proof-of-publication is the same as timestamping \n> ------------------------------------------------\n> \n> No. Timestamping is a significantly weaker primitive than \n> proof-of-publication. This myth seems to persist because\n> unfortunately many members of the Bitcoin development and theory\n> community - and even members of the Blockstream project - have\n> frequently used the term \"timestamping\" for applications that need\n> proof-of-publication.\n> \n> \n> Publication means publishing meaningful data to the whole world \n> ---------------------------------------------------------------\n> \n> No. The data to be published can often be an otherwise meaningless \n> nonce, indistinguishable from any other random value. (e.g. an ECC \n> pubkey)\n> \n> For example colored coins can be implemented by committing the hash\n> of the map of colored inputs to outputs inside a transaction. These\n> maps can be passed from payee to payor to prove that a given output\n> is colored with a set of recursive proofs, as is done in the\n> author's Smartcolors library. The commitment itself can be a simple\n> hash, or even a pay-to-contract style derived pubkey.\n> \n> A second example is Zerocash, which depends on global consensus of\n> a set of revealed serial numbers. As this set can include\n> \"false-positives\" - false revealed serial numbers that do not\n> actually correspond to a real Zerocash transaction - the blockchain\n> itself can be that set. The Zerocash transactions themselves - and\n> associated proofs - can then be passed around via a p2p network\n> separate from the blockchain itself. Each Zerocash Pour proof then\n> simply needs to specify what set of priorly evaluated proofs makes\n> up its particular commitment merkle tree and the proofs are then\n> evaluated against that proof-specific tree. (in practice likely\n> some kind of DAG-like structure) (note that there is a sybil attack\n> risk here: a sybil attack reduces your k-anonymity set by the\n> number of transactions you were prevented from seeing; a weaker \n> proof-of-publication mechanism may be appropriate to prevent that\n> sybil attack).\n> \n> The published data may also not be meaningful because it is\n> encrypted. Only a small community may need to come to consensus\n> about it; everyone else can ignore it. For instance\n> proof-of-publication for decentralized asset exchange is an\n> application where you need publication to be timely, however the\n> audience may still be small. That audience can share an encryption\n> key.\n> \n> \n> Proof-of-publication is always easy to censor \n> ---------------------------------------------\n> \n> No, with some precautions. This myth is closely related to the\n> above idea that the data must be globally meaningful to be useful.\n> The colored coin and Zerocash examples above are cases where\n> censoring the publication is obviously impossible as it can be made\n> prior to giving anyone at all sufficient info to determine if the\n> publicaiton has been made; the data itself is just nonces.\n> \n> In the case of encrypted data the encryption key can also often be \n> revealed well after the publication has been made. For instance in\n> a Certificate Transparency scheme the certificate authority (CA)\n> may use proof-of-publication to prove that a certificate was in a\n> set of certificates. If that set of certificates is hashed into a\n> merkelized binary prefix tree indexed by domain name the correct\n> certificate for a given domain name - or lack thereof - is easily\n> proven. Changes to that set can be published on the blockchain by\n> publishing successive prefix tree commitments.\n> \n> If these commitments are encrypted, each commitment C_i can also\n> commit to the encryption key to be used for C_{i+1}. That key need\n> not be revealed until the commitment is published; validitity is\n> assured as every client knows that only one C_{i+1} is possible, so\n> any malfeasance is guaranteed to be revealed when C_{i+2} is\n> published.\n> \n> Secondly the published data can be timelock encrypted with\n> timelocks that take more than the average block interval to\n> decrypt. This puts would-be censoring miners into a position of\n> either delaying all transactions, or accepting that they will end\n> up mining publication proofs. The only way to circumvent this is\n> highly restrictive whitelisting.\n> \n> \n> Proof-of-publication is easier to censor than (merge)-mined\n> sidechains \n> ----------------------------------------------------------------------\n>\n>  False under all circumstances. Even if the publications use no \n> anti-censorship techniques to succesfully censor a\n> proof-of-publication system at least 51% of the total hashing power\n> must decide to censor it, and they must do so by attacking the\n> other 49% of hashing power - specifically rejecting their blocks.\n> This is true no matter how \"niche\" the proof-of-publication system\n> is - whether it is used by two people or two million people it has\n> the same security.\n> \n> On the other hand a (merge)-mined sidechain with x% of the total\n> hashing power supporting it can be attacked at by anyone with >x%\n> hashing power. In the case of a merge-mined sidechain this cost\n> will often be near zero - only by providing miners with a\n> significant and ongoing reward can the marginal cost be made high.\n> In the case of sidechains with niche audiences this is particularly\n> true - sidechain advocates have often advocated that sidechains be\n> initially protected by centralized checkpoints until they become\n> popular enough to begin to be secure.\n> \n> Secondly sidechains can't make use of anti-censorship techniques\n> the way proof-of-publication systems can: they inherently must be\n> public for miners to be able to mine them in a decentralized\n> fashion. Of course, users of them may use anti-censorship\n> techniques, but that leads to a simple security-vs-cost tradeoff\n> between using the Bitcoin blockchain and a sidechain. (note the\n> simularity to the author's treechains proposal!)\n> \n> \n> Proof-of-publication can be made expensive \n> ------------------------------------------\n> \n> True, in some cases! By tightly constraining the Bitcoin scripting \n> system the available bytes for stenographic embedment can be\n> reduced. For instance P2SH^2 requires an brute force exponentially\n> increasing amount of hashes-per-byte-per-pushdata. However this is\n> still ineffective against publishing hashes, and to fully implement\n> it - scriptSigs included - would require highly invasive changes to\n> the entire scripting system that would greatly limit its value.\n> \n> \n> Proof-of-publication can be outsourced to untrusted third-parties \n> -----------------------------------------------------------------\n> \n> Timestamping yes, but proof-of-publication no.\n> \n> We're talking about systems that attempt to publish multiple pieces\n> of data from multiple parties with a single hash in the Bitcoin\n> blockchain, such as Factom.  Essentially this works by having a\n> \"child\" blockchain, and the hash of that child blockchain is\n> published in the master Bitcoin blockchain. To prove publicaiton\n> you prove that your message is in that child chain, and the child\n> chain is itself published in the Bitcoin blockchain.  Proving\n> membership is possible for yourself by determining if you have the\n> contents corresponding to the most recent child-chain hash.\n> \n> The problem is proving non-publication. The set of all *potential* \n> child-chain hashes must be possible to obtain by scanning the\n> Bitcoin blockchain. As a hash is meaningless by itself, these\n> hashes must be signed. That introduces a trusted third-party who\n> can also sign an invalid hash that does not correspond to a block\n> and publish it in the blockchain. This in turn makes it impossible\n> for anyone using the child blockchain to prove non-publication -\n> they can't prove they did not publish a message because the content\n> of *all* child blockchains is now unknown.\n> \n> In short, Factom and systems like it rely on trusted third parties\n> who can put you in a position where you can't prove you did not\n> commit fraud.\n> \n> \n> Proof-of-publication \"bloats\" the blockchain \n> --------------------------------------------\n> \n> Depends on your perspective.\n> \n> Systems that do not make use of the UTXO are no different\n> technically than any other transaction: they pay fees to publish\n> messages to the Bitcoin blockchain with no amortized increase in\n> the UTXO set. Some systems do grow the UTXO set - a potential\n> scaling problem as currently that all full nodes must have the\n> entire UTXO set - although there are a number of existing\n> mechanisms and proposals to mitigate this issue such as the\n> (crippled) OP_RETURN scriptPubKey format, the dust rule, the \n> authors TXO commitments, UTXO expiry etc.\n> \n> From an economic point of view proof-of-publication systems compete\n> with other uses of the blockchain as they pay fees; supply of\n> blockchain space is fixed so the increased demand must result in a\n> higher per-transaction price in fees. On the other hand this is\n> true of *all* uses of the blockchain, which collectively share the\n> limited transaction capacity. For instance Satoshidice and similar\n> sites have been widely condemned for doing conventional\n> transactions on Bitcoin when they could have potentially used\n> off-chain transactions.\n> \n> It's unknown what the effect on the Bitcoin price will actually be.\n> Some proof-of-publication uses have nothing to do with money at all\n> - e.g. certificate transparency. Others are only indirectly\n> related, such as securing financial audit logs such as\n> merkle-sum-trees of total Bitcoins held by exchanges. Others in\n> effect add new features to Bitcoin, such as how colored coins\n> allows the trade of assets on the blockchain, or how Zerocash makes\n> Bitcoin transactions anonymous. The sum total of all these effects\n> on the Bitcoin price is difficult to predict.\n> \n> The authors belief is that even if proof-of-publication is a \n> net-negative to Bitcoin as it is significantly more secure than\n> the alternatives and can't be effectively censored people will use\n> it regardless of effects to discourage them through social\n> pressure. Thus Bitcoin must make technical improvements to\n> scalability that negate these potentially harmful effects.\n> \n> \n> Proof-of-publication systems are inefficient \n> --------------------------------------------\n> \n> If you're talking about inefficient from the perspective of a\n> full-node that does full validation, they are no different than\n> (merge)-mined sidechain and altcoin alternatives. If you're talking\n> about efficiency from the perspective of a SPV client, then yes,\n> proof-of-publication systems will often require more resources than\n> mining-based alternatives.\n> \n> However it must be remembered that the cost of mining is the \n> introduction of a trusted third party - miners. Of course, mined \n> proof-of-publication has miners already, but trusting those miners\n> to determine the meaning of that data places significantly more\n> trust in them than mearly trusting them to create consensus on the\n> order in which data is published.\n> \n> Many usecases involve trusted third-parties anyway - the role of \n> proof-of-publication is to hold those third-parties to account and\n> keep them honest. For these use-cases - certificate transparency,\n> audit logs, financial assets - mined alternatives simply add new\n> trusted third parties and points of failure rather than remove\n> them.\n> \n> Of course, global consensus is inefficient - Bitcoin itself is \n> inefficient. But this is a fundemental problem to Bitcoin's\n> architecture that applies to all uses of it, a problem that should\n> be solved in general.\n> \n> \n> Proof-of-publication needs \"scamcoins\" like Mastercoin and\n> Counterparty \n> -----------------------------------------------------------------------\n>\n>  First of all, whether or not a limited-supply token is a \"scam\" is\n> not a technical question. However some types of embedded consensus\n> systems, a specific use-case for proof-of-publication, do require\n> limited-supply tokens within the system for technical reasons, for\n> instance to support bid orders functionality in decentralized\n> marketplaces.\n> \n> Secondly using a limited-supply token in a proof-of-publicaton\n> system is what lets you have secure client side validation rather\n> than the alternative of 2-way-pegging that requires users to trust\n> miners not to steal the pegged funds. Tokens also do not need to\n> be, economically speaking, assets that can appreciate in value\n> relative to Bitcoin; one-way-pegs where Bitcoins can always be\n> turned into the token in conjunction with decentralized exchange to\n> buy and sell tokens for Bitcoins ensure the token value will always\n> closely approximate the Bitcoin value as long as the protocol\n> itself is considered valuable.\n> \n> Finally only a subset of proof-of-publication use-cases involve\n> tokens at all - many like colored coins transact directly to and\n> from Bitcoin, while other use-cases don't even involve finance at\n> all.\n> \n> \n> \n> ------------------------------------------------------------------------------\n>\n> \nDownload BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n> from Actuate! Instantly Supercharge Your Business Reports and\n> Dashboards with Interactivity, Sharing, Native Excel Exports, App\n> Integration & more Get technology previously reserved for\n> billion-dollar corporations, FREE \n> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n>\n> \n> \n> \n> _______________________________________________ Bitcoin-development\n> mailing list Bitcoin-development at lists.sourceforge.net \n> https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n> \n\n- -- \nhttp://abis.io ~\n\"a protocol concept to enable decentralization\nand expansion of a giving economy, and a new social good\"\nhttps://keybase.io/odinn\n-----BEGIN PGP SIGNATURE-----\n\niQEcBAEBCgAGBQJUivCNAAoJEGxwq/inSG8ChVUH/26zj2pj7AF+oa2RDkPZN980\nqFTY7x2s9w97bEuCiFfFpYjIP26mY4+snuoTWBa8yCp7gLVVsk9JKkN0dmXIboXf\nocoJY9s/wT7QLqJMRRwWb/8XPKwjXB10PNawCRoUk++8E0Y+W6mxiH5Gs1UnYKwI\n2DHHh/hTh35mR5burwdLGEMLaVtK4BFLJTZwW+4xlWESsoWeQnxEuty799HldOaN\n+wms8dvtZlzJElLUPjBGBZT6DRTaPsvqSvQ0CnHI84LYwuUObMcV89mkBcfTHlMt\nMczwaO7CCc/jmoOoQKDyIVuW1eJeXggln+LOS34qwH8rCgjdOZeT3y4PgUTZ+AM=\n=Sm96\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "Justus Ranvier",
                "date": "2014-12-12T14:17:47",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\nOn 12/12/2014 01:41 PM, odinn wrote:\n> I think the Mastercoin devs are doing fine work\n\nI wonder if all the Mastercoin devs would agree with that statement.\n\n- -- \nSupport online privacy by using email encryption whenever possible.\nLearn how here: http://www.youtube.com/watch?v=bakOKJFtB-k\n-----BEGIN PGP SIGNATURE-----\n\niQEcBAEBCAAGBQJUivkLAAoJEMP3uyY4RQ21r5cIANvabja0i5j79a6KSkKOgEyR\nLhBz4mugzTc8Zej2NBeyEtv0pzO4fs5wvQo4N/1BW7aHXuFJsgJpGlV8thkuFhek\nUhoPC23i7u3jCPQ30PintqvCBCimse+PJa60KE2QL2DZn7WgRGKrEuo41AROxeit\nvfVMcFULc6bB9hxIEBpcU4RuwKJHVgzSHMkO75/uHHtPLJ9TbCfqcxT146cZvSjc\nTc62ukuX1xBj5PhQM8GaUGzkQcfcZ+7d3DD1X22Gk1U6w+zat52dapy/qYgn9oA5\nubk/p/7Kywd8D44rPsr/pbdlDZxG0w77yRJIMboXhFMV7rY3sMRHHQmAUz+I8FY=\n=R4pR\n-----END PGP SIGNATURE-----\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: 0x38450DB5.asc\nType: application/pgp-keys\nSize: 14542 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141212/3302f4a2/attachment.bin>"
            },
            {
                "author": "Peter Todd",
                "date": "2014-12-15T04:59:58",
                "message_text_only": "On Fri, Dec 12, 2014 at 01:41:34PM +0000, odinn wrote:\n> Peter... It kind of sounds to me that (as fine of a position paper as\n> this is) on _certain_ points, you're falling prey to the \"but it's\n> inefficient, but it's a scamcoin, but luke-jr told me so\" argument...\n\nI prefer to make robust arguments; if I can start with accepting that\n95% of what my opponents say is true, yet still end up being correct,\nall the better!\n\n> I think the Mastercoin devs are doing fine work and I consider the\n> zerocash devs to have developed (in v2, mint and pour) to have\n> developed something that will really turn the world on its ear, but\n> what do I know? Nothing.  Nothing at all.\n\nMy personal opinion is that what Mastercoin has started will turn the\nworld on its ear, but I'd be surprised if the succesful implementations\nof the underlying ideas come from that team. But there's nothing\nsurprising about that - when was the last time you used Netscape\nNavigator, let alone NCSA Mosaic?\n\n-- \n'peter'[:-1]@petertodd.org\n00000000000000000681f4e5c84bc0bf7e6c5db8673eef225da652fbb785a0de\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141214/4d956b31/attachment.sig>"
            },
            {
                "author": "odinn",
                "date": "2014-12-17T01:16:30",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nbleep bloop\n\nPeter Todd:\n> On Fri, Dec 12, 2014 at 01:41:34PM +0000, odinn wrote:\n>> Peter... It kind of sounds to me that (as fine of a position\n>> paper as this is) on _certain_ points, you're falling prey to the\n>> \"but it's inefficient, but it's a scamcoin, but luke-jr told me\n>> so\" argument...\n> \n> I prefer to make robust arguments; if I can start with accepting\n> that 95% of what my opponents say is true, yet still end up being\n> correct, all the better!\n> \n>> I think the Mastercoin devs are doing fine work and I consider\n>> the zerocash devs to have developed (in v2, mint and pour) to\n>> have developed something that will really turn the world on its\n>> ear, but what do I know? Nothing.  Nothing at all.\n> \n> My personal opinion is that what Mastercoin has started will turn\n> the world on its ear, but I'd be surprised if the succesful\n> implementations of the underlying ideas come from that team. But\n> there's nothing surprising about that - when was the last time you\n> used Netscape Navigator, let alone NCSA Mosaic?\n> \n\n- -- \nhttp://abis.io ~\n\"a protocol concept to enable decentralization\nand expansion of a giving economy, and a new social good\"\nhttps://keybase.io/odinn\n-----BEGIN PGP SIGNATURE-----\n\niQEcBAEBCgAGBQJUkNluAAoJEGxwq/inSG8CKy0IAJmCUmDbaCx33/km0J2mP7ha\nkxX3fxiPpicD8hXa4FXBsrYqj7ZFu0OmFOU/ei0AXMOuu94rQdIp6hon3f5GO73J\nWVT2Toqd2GTCXhmddyqtOzZ5mYOyZhlJUYlNjbwTmlk+U2hQbZC1aJ4AKdmjQn5v\n9DFkZfqBSsNhcoLCKoVqY3l4qzw0XqeL6fOYkz2H9AssWdcUV9JB5C0wm8rI70AX\nqcxABgrKDwhThWgHyHGZXHLCvRRpMUFFVbzO67BPZA2R+gXYtOAVDozl7jdx7PLl\nx3nyzZK3pX1bqcT2T5fD8wQtu4yJ3RCBVWzHfrA5MF6q4Yh6DEh7DnO8ccOnPlk=\n=1os7\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "Alex Mizrahi",
                "date": "2014-12-12T17:50:48",
                "message_text_only": "> I think what Gareth was getting at was that with client-side validation\n> there can be no concept of a soft-fork. And how certain are you that the\n> consensus rules will never change?\n>\n\nYes, it is true that you can't do a soft-fork, but you can do a hard-fork.\nUsing scheduled updates: client simply stops working at a certain block,\nand user is required to download an update.\n\nIn Bitcoin we can operate with some assurance that hard-forks will almost\n> never happen, exactly because extensions are more likely to occur via\n> soft-fork mechanisms. In such a case, old non-updated clients will still\n> generate a correct view of the ledger state. But this is not so with client\n> side validation!\n>\n\nYou assume that an ability to operate with zero maintenance is very\nimportant, but is this a case?\n\nThere was a plenty of critical bugs in bitcoind, and in many cases people\nwere strongly encouraged to upgrade to a new version.\nSo, you urge people to keep their clients up-to-date, but at the same time\nclaim that keeping very old versions is critically important.\nHow does this make sense? Is this an exercise at double-think?\n\nAn alternative to this is to make updates mandatory. You will no longer\nneed to maintain compatibility with version 0.1 (which is impossible) and\nyou can also evolve consensus rules over time.\n\nIt looks like people make a cargo cult out of Bitcoin's emergent\nproperties.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141212/7dd1f4ef/attachment.html>"
            },
            {
                "author": "Gareth Williams",
                "date": "2014-12-13T13:32:22",
                "message_text_only": "On 13/12/14 04:04, Alex Mizrahi wrote:\n> Well, client-side validation is mathematically secure, while SPV is\n> economically secure.\n> I.e. it is secure if you make several assumptions about economics of the\n> whole thing.\n\nComparisons with the SPV security of sidechains are fallacious. The\nalternative to a proof-of-publication system reliant on client-side\nvalidation is a blockchain. The question of whether the token used on\nsaid blockchain should be two-way-pegged to BTC is completely orthogonal.\n\n(ie. yes, sidechains are \"economically secure\", in that you're reduced\nto balancing economic incentives to avoid peg theft. But sidechains also\ngive us something unique in return - the ability to innovate without\nneeding to start new artificial scarcity races. Nothing else can do that.)\n\n<snip>\n\n> You know, The Great Fork of 2013 was resolved through human\n> intervention, Bitcoin nodes were not smart enough to detect that\n> something is going awry on their own.\n\nI hate to think what the outcome would've been on a proof-of-publication\nsystem. You don't even have a fork. You just have a whole bunch of nodes\nwho sort-of-mostly agree on a shared history, except where they don't.\nMaybe they just disagree on the validity of a single transaction.\nThey'll slowly diverge over time (as bad transactions are used as input\nto other transactions.) You have no reliable way to detect this lapse in\nconsensus, nor any mechanism to incentivse convergence. Indeed, you have\nno consensus mechanism in the first place.\n\nBitcoin is where it is today because of Satoshi's elegant solution to\nexactly such problems. Which some people now appear to be in a hurry to\ndiscard :)\n\nAlex Mizrahi wrote:\n> Using scheduled updates: client simply stops working at a certain block,\n> and user is required to download an update.\n\n<snip>\n\n> An alternative to this is to make updates mandatory. You will no longer\n> need to maintain compatibility with version 0.1 (which is impossible)\n> and you can also evolve consensus rules over time.\n\nPeter Todd might disagree with the wisdom of that :) He wrote an\nexcellent email to this list not long ago warning of the dangers of\ncentralisation. IIRC one point he made was that scheduled, regular\nhardforks were a real threat - if a single entity (eg. the Bitcoin\nFoundation) were to become politically established as the coordinator of\nsuch forks, they would have de-facto control over the protocol.\n\nEven in that dark scenario, I would feel a measure of confidence that\npast transactions I had received could not be tampered with. The fact\nthat those transactions happened, and that there was (and is) consensus\nthey were valid, is publicly documented in the blockchain. I trust any\nreasonable person would not accept a client that ignored validated data\nin the blockchain as \"Bitcoin\" any more.\n\nYour proof-of-publication system with mandatory updates is another\nmatter entirely. No public record of transactions I have received with\nthat system exists, anywhere. If tomorrow's mandatory update has the\neffect of zeroing my account balance (by happening to now interpret one\nor more transactions I received, or their inputs, as invalid) then I\nhave no recourse. I won't find sympathy with the majority of users, who\nare unaffected and just accept the update.\n\nIn short, what you describe doesn't sound very decentralised :) Do you\nwant transactions you receive validated by distributed consensus and\nburried under PoW, or validated by some guy's mandatory-updating python\nscript?\n\n(Also worth noting: all such systems are effectively \"mandatory\nupdating\" due to the risk of subtle consensus bugs of the type I\ndescribed above. Your only assurance that your view of the world is the\nsame as everyone elses' is that you're running the exact same software.\nI played with Counterparty a while ago and quickly learned - the hard\nway - to do a 'git pull' before any important operation.)\n\n\n\n\n\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 473 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141214/312b03d8/attachment.sig>"
            },
            {
                "author": "Peter Todd",
                "date": "2014-12-15T04:52:36",
                "message_text_only": "On Sun, Dec 14, 2014 at 12:32:22AM +1100, Gareth Williams wrote:\n> On 13/12/14 04:04, Alex Mizrahi wrote:\n> > Well, client-side validation is mathematically secure, while SPV is\n> > economically secure.\n> > I.e. it is secure if you make several assumptions about economics of the\n> > whole thing.\n> \n> Comparisons with the SPV security of sidechains are fallacious. The\n> alternative to a proof-of-publication system reliant on client-side\n> validation is a blockchain. The question of whether the token used on\n> said blockchain should be two-way-pegged to BTC is completely orthogonal.\n> \n> (ie. yes, sidechains are \"economically secure\", in that you're reduced\n> to balancing economic incentives to avoid peg theft. But sidechains also\n> give us something unique in return - the ability to innovate without\n> needing to start new artificial scarcity races. Nothing else can do that.)\n\nI covered this in my original post: 1-way-pegs allow the creation of new\nvaluable tokens without those tokens being useful for speculation.\n\nTo recap, a 1-way-peg allows the conversion of Bitcoins to another token\nby provably destroying the Bitcoins, thus capping the maximum possible\nvalue of that token and ensuring the token can-not become an investment.\nFor owners of these tokens they can convert them back to Bitcoin by\nselling them at a discount to buyers who would otherwise be able to\npurchase them via provable destruction. A pragmatic implementation may\nwish to make obtaining the token via destruction option unattractive\ncompared to obtaining them through trade by incorporating a time delay\ninto the destruction process to encourage liquidity. (interestingly a\nnatural outcome of an announce-commit sacrifice-to-fees scheme)\n\nOf course even without 1-way-pegs there's a much more important issue\nwith your objection: worrying about creating new artificial scarcity\nraces while innovating is fundementally a *moralistic* and *regulatory*\nconcern that has no little if any bearing on whether or not the systems\ncreated are useful and secure. It's also an objection that raises\nserious questions about conflicts of interest between giving accurate\nand honest technical advice and promoting ways of using Bitcoin that\nwill drive the price up.\n\n> > You know, The Great Fork of 2013 was resolved through human\n> > intervention, Bitcoin nodes were not smart enough to detect that\n> > something is going awry on their own.\n> \n> I hate to think what the outcome would've been on a proof-of-publication\n> system. You don't even have a fork. You just have a whole bunch of nodes\n> who sort-of-mostly agree on a shared history, except where they don't.\n> Maybe they just disagree on the validity of a single transaction.\n> They'll slowly diverge over time (as bad transactions are used as input\n> to other transactions.) You have no reliable way to detect this lapse in\n> consensus, nor any mechanism to incentivse convergence. Indeed, you have\n> no consensus mechanism in the first place.\n\nA number of mechanisms for detecting divergence are possible in embedded\nconsensus systems, some of them even natural outcomes. For instance\ntransactions can contain a hash of the previous consensus state, thereby\ncreating an indicator of consensus measured in terms of economic stake.\nExtending that idea many anti-censorship proposals are to use such state\nhashes as encryption keys - if you are out of consensus you won't even\nsee the transaction. (and you can't be double-spent either if\nimplemented correctly; see my other reply to this thread today)\n\n> Bitcoin is where it is today because of Satoshi's elegant solution to\n> exactly such problems. Which some people now appear to be in a hurry to\n> discard :)\n\nFWIW usually Satoshi's solution is described as a hack, sometimes as an\nelegant hack.\n\n> Peter Todd might disagree with the wisdom of that :) He wrote an\n> excellent email to this list not long ago warning of the dangers of\n> centralisation. IIRC one point he made was that scheduled, regular\n> hardforks were a real threat - if a single entity (eg. the Bitcoin\n> Foundation) were to become politically established as the coordinator of\n> such forks, they would have de-facto control over the protocol.\n\nIndeed I did, which is why I worked out a better way to do upgrades\nalmost a year ago:\n\nhttp://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg06578.html\n\n\n> (Also worth noting: all such systems are effectively \"mandatory\n> updating\" due to the risk of subtle consensus bugs of the type I\n> described above. Your only assurance that your view of the world is the\n> same as everyone elses' is that you're running the exact same software.\n> I played with Counterparty a while ago and quickly learned - the hard\n> way - to do a 'git pull' before any important operation.)\n\nThe quality of Counterparty's software engineering has no bearing on\nwhether or not the underlying idea is a good one; you wouldn't say ring\nsignatures are an inherently bad idea just because the CryptoNote\nimplementation of them is atrocious.\n\n-- \n'peter'[:-1]@petertodd.org\n00000000000000000681f4e5c84bc0bf7e6c5db8673eef225da652fbb785a0de\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141214/599477c2/attachment.sig>"
            },
            {
                "author": "Gareth Williams",
                "date": "2014-12-17T11:55:28",
                "message_text_only": "On Mon, Dec 15, 2014 at 3:52 PM, Peter Todd <pete at petertodd.org> wrote:\n>> Comparisons with the SPV security of sidechains are fallacious. The\n>> alternative to a proof-of-publication system reliant on client-side\n>> validation is a blockchain. The question of whether the token used on\n>> said blockchain should be two-way-pegged to BTC is completely orthogonal.\n>>\n>> (ie. yes, sidechains are \"economically secure\", in that you're reduced\n>> to balancing economic incentives to avoid peg theft. But sidechains also\n>> give us something unique in return - the ability to innovate without\n>> needing to start new artificial scarcity races. Nothing else can do that.)\n>\n> I covered this in my original post: 1-way-pegs allow the creation of new\n> valuable tokens without those tokens being useful for speculation.\n\nI stand corrected. A permanent 1-way-peg is sufficient to preserve\nscarcity; \"nothing else can do that\" WRT 2-way-pegs was overreaching.\n\nI still don't see what \"2-way-peg vs. 1-way-peg\" has to do with\n\"embedded consensus vs. blockchain consensus\" though, and feel it\ndisingenious to conflate them.\n\nBlockchain consensus (eg. sidechains) can utilise either mechanism,\n1-way-peg or 2-way-peg. Arguments in favour of 1-way-peg are\ninteresting, but they're ultimatley just arguments in favour of one\ntype of sidechain over another.\n\nArguments in favour of embedded consensus - and I feel I'm being\ngenerous with the term \"consensus\" here - should surely stand on their\nown merit against blockchain consensus, if they're to be convincing.\n\n> Of course even without 1-way-pegs there's a much more important issue\n> with your objection: worrying about creating new artificial scarcity\n> races while innovating is fundementally a *moralistic* and *regulatory*\n> concern that has no little if any bearing on whether or not the systems\n> created are useful and secure. It's also an objection that raises\n> serious questions about conflicts of interest between giving accurate\n> and honest technical advice and promoting ways of using Bitcoin that\n> will drive the price up.\n\nIMO the question of whether scarcity can be preserved while enabling\ninnovation bears heavily on the liklihood of longterm viability of\nsaid innovations - and perhaps of Bitcoin itself.\n\nFWIW I'll happily declare that I hold a modest amount of BTC and have\nan interest in the price appreciating. I'm sure you'll admit you're\nhardly an impartial party in this discussion yourself Peter :) But it\nreally shouldn't matter. I'm not here today to make it, but I think\nthe argument for preservation of scarcity stands quite well on its own\nmerits - as rightly it should, regardless of anybody's interests.\n\n> A number of mechanisms for detecting divergence are possible in embedded\n> consensus systems, some of them even natural outcomes. For instance\n> transactions can contain a hash of the previous consensus state, thereby\n> creating an indicator of consensus measured in terms of economic stake.\n> Extending that idea many anti-censorship proposals are to use such state\n> hashes as encryption keys - if you are out of consensus you won't even\n> see the transaction. (and you can't be double-spent either if\n> implemented correctly; see my other reply to this thread today)\n\n<snip>\n\n> Indeed I did, which is why I worked out a better way to do upgrades\n> almost a year ago:\n>\n> http://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg06578.html\n\n<snip>\n\n> The quality of Counterparty's software engineering has no bearing on\n> whether or not the underlying idea is a good one; you wouldn't say ring\n> signatures are an inherently bad idea just because the CryptoNote\n> implementation of them is atrocious.\n\nVery interesting. I admit I hadn't come across these ideas before; I\nreally must search the archive before posting :) They certainly offer\na measure of robustness over the naive approach. I'm not sure they\naddress my primary concerns however, WRT how consensus is demonstrated\nand incentivised.\n\nI know what my own node considers valid transaction history; how can I\nbe confident that everyone else takes the same view? For contrast,\nwith blockchain consensus, I can be confident that there is consensus\non the longest chain observed. If I receive a new transaction, simply\nwaiting for it to be buried under N blocks of PoW provides a high\nlevel of confidence that everyone else considers it valid.\n\nThe obvious \"embedded consensus\" answer of \"wait until N other\ntransactions have occurred that include a hash of system state that\nincludes your transaction\" doesn't provide me with any confidence; it\ncould be simulated with a Sybil attack.\n\n<snip>\n\n> I prefer to make robust arguments; if I can start with accepting that\n> 95% of what my opponents say is true, yet still end up being correct,\n> all the better!\n\nIndeed :) To avoid wasting time it's only ever worth arguing against\nthe strongest opposing position you're aware of (whether your opponent\nis aware of it or not.)\n\nhttps://en.wikipedia.org/wiki/Principle_of_charity"
            },
            {
                "author": "Peter Todd",
                "date": "2014-12-21T06:12:20",
                "message_text_only": "On Wed, Dec 17, 2014 at 10:55:28PM +1100, Gareth Williams wrote:\n> > I covered this in my original post: 1-way-pegs allow the creation of new\n> > valuable tokens without those tokens being useful for speculation.\n> \n> I stand corrected. A permanent 1-way-peg is sufficient to preserve\n> scarcity; \"nothing else can do that\" WRT 2-way-pegs was overreaching.\n\nYup.\n\n> I still don't see what \"2-way-peg vs. 1-way-peg\" has to do with\n> \"embedded consensus vs. blockchain consensus\" though, and feel it\n> disingenious to conflate them.\n\n1-way-pegs don't require the Bitcoin protocol to change; 2-way-pegs do.\n\n> Blockchain consensus (eg. sidechains) can utilise either mechanism,\n> 1-way-peg or 2-way-peg. Arguments in favour of 1-way-peg are\n> interesting, but they're ultimatley just arguments in favour of one\n> type of sidechain over another.\n\nNo, they're in favor of systems that are client-side validatable vs.\nsystems that either allow anyone with sufficient hashing power to steal\ncoins *or* require \"moon-math\" that isn't yet available to production\nsystems.\n\n> IMO the question of whether scarcity can be preserved while enabling\n> innovation bears heavily on the liklihood of longterm viability of\n> said innovations - and perhaps of Bitcoin itself.\n> \n> FWIW I'll happily declare that I hold a modest amount of BTC and have\n> an interest in the price appreciating. I'm sure you'll admit you're\n> hardly an impartial party in this discussion yourself Peter :) But it\n> really shouldn't matter. I'm not here today to make it, but I think\n> the argument for preservation of scarcity stands quite well on its own\n> merits - as rightly it should, regardless of anybody's interests.\n\nBut again, all these discussions about scarcity are fundementally\n*moral* arguments that have no bearing on what's actually the most\nappropriate solution for an *individual* problem.\n\nIn a decentralized system filled with anonymous actors telling people\n\"stop doing that! it's bad!\" on reddit has pretty severe limitations in\ntrying to convince people to act against their own best interests.\n\n> > The quality of Counterparty's software engineering has no bearing on\n> > whether or not the underlying idea is a good one; you wouldn't say ring\n> > signatures are an inherently bad idea just because the CryptoNote\n> > implementation of them is atrocious.\n> \n> Very interesting. I admit I hadn't come across these ideas before; I\n> really must search the archive before posting :) They certainly offer\n> a measure of robustness over the naive approach. I'm not sure they\n> address my primary concerns however, WRT how consensus is demonstrated\n> and incentivised.\n\nI think you think consensus in Bitcoin is more \"magical\" than it really\nis; Bitcoin is just code running on computers; consensus isn't really\nincentivised at the protocol level beyond \"screw it up and you'll lose\nmoney\"\n\nEmbedded consensus systems are no different: screw up consensus and\nyou'll lose money in a variety of ways.\n\n> The obvious \"embedded consensus\" answer of \"wait until N other\n> transactions have occurred that include a hash of system state that\n> includes your transaction\" doesn't provide me with any confidence; it\n> could be simulated with a Sybil attack.\n\nNo it can't - the transactions are in the blockchain so the sybil attack\nhas to attack the host system as well.\n\nIn any case, keep in mind all of this is in the context of tradeoffs:\nfor a different and sometimes more fragile consensus mechanism embedded\nconsensus gets immunity to attack by miners. You're trading off one type\nof fragility for another - I'd much rather take the \"one-time\" fragility\ninherent in having to write really solid software than the ongoing\nfragility of always being vulnerable to miners.\n\nNotably this is the exact same tradeoff taken elsewhere by the majority\nof the crypto world.\n\n-- \n'peter'[:-1]@petertodd.org\n000000000000000017d70ee98f4cee509d95c4f31d5b998bae6deb09df1088fc\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/c9345024/attachment.sig>"
            },
            {
                "author": "Peter Todd",
                "date": "2014-12-15T04:17:14",
                "message_text_only": "On Fri, Dec 12, 2014 at 07:50:48PM +0200, Alex Mizrahi wrote:\n> > I think what Gareth was getting at was that with client-side validation\n> > there can be no concept of a soft-fork. And how certain are you that the\n> > consensus rules will never change?\n> >\n> \n> Yes, it is true that you can't do a soft-fork, but you can do a hard-fork.\n> Using scheduled updates: client simply stops working at a certain block,\n> and user is required to download an update.\n\nYou're quite mistaken actually. One of the first things to come out of\nmy research as Mastercoin's Chief Scientist - indeed after a week on the\njob - was how to safely upgrade embedded consensus systems in a\ndecentralized fashion:\n\nhttp://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg03890.html\n\nTo recap, where valuable scarce tokens are concerned we want to ensure\nthat an attacker can't use a fork caused by an upgrade to double-spend\ntokens. We solve this problem by ensuring that when a token visible to\nversion V_i is spent in a V_{i+1} client, the token appears spent to\nversion V_i clients as well. This is easy to accomplish by a \"split\ntransaction\" scheme that separates all operations into separate\n\"increment\" and \"decrement\" operations.\n\nThe simplest example of this principle in action is colored coins, which\nare certainly an example of an embedded consensus system. Colored coin\nimplementations naturally ensure that all versions of the system see a\ntoken getting spent the same way - the corresponding txout is spent! So\nlong as changes to the coloring rules are handled such that only one set\nof rules - one version - can apply to a given txout spend we get\nanti-doublespend protection.\n\nThe second aspect of the problem is the social/political implications of\nupgrades - because embedded consensus systems don't outsource trust they\nvery clearly require the co-operation of the economic majority in an\nupgrade. For instance if the community has two competing proposals for\nhow to upgrade version V1 of Counterparty, V2a and V2b, choosing to move\nyour tokens to either version becomes a vote with serious economic\nconsequences. In fact, it's quite possible that a community would choose\nto simply fork into two different systems each offering a different set\nof features. Equally in the event of such a fork someone can create a\nthird version, V3, that recombines the two incompatible forks. Again,\nanyone who agrees with version V3 can choose to move their tokens to it,\nhealing the fork.\n\nArguably this process of handling forks by direct economic voting is\nsignificantly *more* decentralized than Bitcoin's soft-fork mechanism as\nadoption of a new version is something all participants in the system\nplay a part in equally. (as measured by economic stake) Of course, it\nwill lead to sometimes ugly political battles, but that's simply part of\nthe cost of having democratic systems.\n\n\n> It looks like people make a cargo cult out of Bitcoin's emergent\n> properties.\n\n+1\n\n-- \n'peter'[:-1]@petertodd.org\n00000000000000000681f4e5c84bc0bf7e6c5db8673eef225da652fbb785a0de\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141214/616bc743/attachment.sig>"
            },
            {
                "author": "paul snow",
                "date": "2014-12-16T20:28:29",
                "message_text_only": "Peter provides an excellent summary of Proof of Publication, which starts\nwith defining it as being composed of a solution to the double spend\nproblem.  He requires Proof-of-receipt (proof every member of p in audience\nP has received a message m), Proof-of-non-publication (proof a message m\nhas not been published to an audience P), and Proof-of-membership (proof\nsome q is a member of P).\n\nHe goes on to state (curiously) that Factom cannot provide Proof of\nPublication.\n\nProof of Audience\n=============\n\nLet's first satisfy the easier proofs. A Factom user can know they are in\nthe Factom audience if they have access to the Bitcoin Blockchain,\nknowledge of Factom's first anchor (Merkle root stored in the blockchain)\nand the Factom network for distributing Factom's structures.  They can\npretty much know that they are in the Audience.\n\nProof of Receipt\n============\n\nProof of receipt is also pretty easy for the Factom user.  User submit\nentries, and Factom publishes a Merkle Root to the Bitcoin Blockchain.  The\nMerkle proof to the entry proves receipt.  To get the Merkle proof requires\naccess to Factom structures, which all in the audience have access to by\ndefinition.  But the proof itself only requires the blockchain.\n\nAt this point the user can have a Merkle proof of their entry rooted in the\nblockchain.\n\nProof of non-publication\n==================\n\nLast, can the Factom user have a  Proof-of-non-publication.  Well,\nabsolutely.  The Factom state limits the public keys that can be used to\nwrite the anchors in the blockchain.  Entries that are not written with\nthose public keys are discounted out of hand.  Just like publishing in Mad\nMagazine does not qualify if publishing a notice in the New York Times is\nthe standard.\n\nThe complaint Peter has that the user cannot see all the \"child chains\"\n(what we call Factom Chains) is invalid.  The user can absolutely see all\nthe Directory Blocks (which documents all Factom Chains) if they have\naccess to Factom. But the user doesn't need to prove publication in all\nchains.  Some of those chains are like Car Magazines, Math Textbooks,\nToaster manuals, etc. Without restricting the domain of publication there\nis no proof of the negative. The negative must be proved in the standard of\npublication, i.e. the user's chain.  And the user can in fact know their\nchain, and can enumerate their chain, without regard to most of the other\ndata in Factom.\n\nPeter seems to be operating under the assumption that the audience for a\nFactom user must necessarily be limited to information found in the\nblockchain.  Yet the user certainly should have access to Factom if they\nare a Factom user.  Factom then is no different from the New York Times,\nand the trust in Factom is less. As Peter says himself, he has to trust the\nNew York Times doesn't publish multiple versions of the same issue. The\nuser of the New York Times would have no way to know if there were other\nversions of an issue outside of looking at all New York Times issues ever\npublished.\n\nFactom on the other hand documents their \"issues\" on the blockchain.  Any\nfork in publication is obvious as it would require different Bitcoin\naddresses to be used, and the blocks would have to have validating\nsignatures of majorities of all the Factom servers. As long as a fork in\nFactom can be clearly identified, and no fork exists, proof of the negative\nis assured.  And upon a fork, one must assume the users will specify which\nfork should be used.\n\nProof of publication does not require a system that cannot fork, since no\nsuch non-trivial system exists.  What is required is that forks can be\ndetected, and that a path can be chosen to move forward.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/d02c40c2/attachment.html>"
            },
            {
                "author": "paul snow",
                "date": "2014-12-17T22:20:33",
                "message_text_only": "[[Since I sent this while the List Server was down, it didn't actually go\nto everyone.  Forgive me if you ended up with two copies.]]\n\nPeter provides an excellent summary of Proof of Publication, which starts\nwith defining it as being composed of a solution to the double spend\nproblem.  He requires Proof-of-receipt (proof every member of p in audience\nP has received a message m), Proof-of-non-publication (proof a message m\nhas not been published to an audience P), and Proof-of-membership (proof\nsome q is a member of P).\n\nHe goes on to state (curiously) that Factom cannot provide Proof of\nPublication.\n\nProof of Membership\n================\n\nLet's first satisfy the easier proofs. A Factom user can know they are a\nmember of the Factom audience if they have access to the Bitcoin\nBlockchain, knowledge of Factom's first anchor (Merkle root stored in the\nblockchain) and the Factom network for distributing Factom's structures.\nThey can pretty much know that they are in the Audience.\n\nProof of Receipt\n============\n\nProof of receipt is also pretty easy for the Factom user.  User submit\nentries, and Factom publishes a Merkle Root to the Bitcoin Blockchain.  The\nMerkle proof to the entry proves receipt.  To get the Merkle proof requires\naccess to Factom structures, which all in the audience have access to by\ndefinition.  But the proof itself only requires the blockchain.\n\nAt this point the user can have a Merkle proof of their entry rooted in the\nblockchain.\n\nProof of non-publication\n==================\n\nLast, can the Factom user have a  Proof-of-non-publication?  Well,\nabsolutely.  The Factom state limits the public keys that can be used to\nwrite the anchors in the blockchain.  Transactions in Bitcoin that are not\nsigned with those public keys are discounted out of hand.  Just like\npublishing in Mad Magazine does not qualify if publishing a notice in the\nNew York Times is the standard.\n\nThe complaint Peter has that the user cannot see all the \"child chains\"\n(what we call Factom Chains) is invalid.  The user can absolutely see all\nthe Directory Blocks (which documents all Factom Chains) if they have\naccess to Factom. But the user doesn't need to prove publication in all\nchains.  Some of those chains are like Car Magazines, Math Textbooks,\nToaster manuals, etc. Without restricting the domain of publication there\nis no proof of the negative. The negative must be proved in the standard of\npublication, i.e. the user's chain.  And the user can in fact know their\nchain, and can enumerate their chain, without regard to most of the other\ndata in Factom.\n\nPeter seems to be operating under the assumption that the audience for a\nFactom user must necessarily be limited to information found in the\nblockchain.  Yet the user certainly should have access to Factom if they\nare a Factom user.  Factom then is no different from the New York Times,\nand the trust in Factom is less. As Peter says himself, he has to trust the\nNew York Times doesn't publish multiple versions of the same issue. The\nuser of the New York Times would have no way to know if there were other\nversions of an issue outside of looking at all New York Times issues ever\npublished.\n\nFactom on the other hand documents their \"issues\" on the blockchain.  Any\nfork in publication is obvious as it would require different Bitcoin\naddresses to be used, and the blocks would have to have validating\nsignatures of majorities of all the Factom servers. As long as a fork in\nFactom can be clearly identified, and no fork exists, proof of the negative\nis assured.  And upon a fork, one must assume the users will specify which\nfork should be used.\n\nProof of publication does not require a system that cannot fork, since no\nsuch non-trivial system exists.  What is required is that forks can be\ndetected, and that a path can be chosen to move forward.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141217/ec077915/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Setting the record straight on Proof-of-Publication",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "odinn",
                "Peter Todd",
                "Gareth Williams",
                "paul snow",
                "Alex Mizrahi",
                "Justus Ranvier"
            ],
            "messages_count": 15,
            "total_messages_chars_count": 75021
        }
    },
    {
        "title": "[Bitcoin-development] The relationship between Proof-of-Publication and Anti-Replay Oracles",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2014-12-20T14:48:01",
                "message_text_only": "Gregory Maxwell recently pointed out to me in private conservation that\nthere potentially existed a fundemental disagreement between him and I\non our philosophical approaches to blockchains, in that he prioritised\nthe notion of the blockchain as an anti-replay oracle, and I prioritised\nit as a publication layer. Here I'll talk about the differences and\nsimularities between those two approaches.\n\n\nWhat's Anti-Replay?\n===================\n\nWe have some action - perhaps spending a txout - and we only want it to\nbe possible for that action to happen once; we don't want it to be\npossible for that action to be replayed again. This is inherently not\npossible with cryptography alone as cryptography is just math and any\nmathematical calculation can be repeated with different parameters.\n\n\nWhat's an Anti-Replay Oracle?\n=============================\n\nWe need the following primitives operating on message m, pubkey p, and a\nvalid signature sig1 for m, p:\n\n    AntiReplaySign(m, p, sig1) -> sig2\n    VerifyAntiReplaySig(m, p, sig2) -> True or False\n\nAdditionally once AntiReplaySign() has been used once for a given pubkey\nit is impossible to re-run the primitive on a different message m'. This\nis of course impossible to implement with math alone, but we can\nimplement it with a trusted third party. For instance Carol can perform\nthe AntiReplaySign operation and make the promise that she will only\never perform it once for any given (m,p) tuple.\n\nMaxwell points out in CoinWitness\u00b9 that the anti-replay oracle is\nsufficient to implement a digital currency. So long as the trusted\noracle, or majority of a federation of trusted oracles, is honest coins\ncannot be double-spent and can be securely passed from owner-to-owner\nwith an ever-growing transcript\u2071 proving each valid spend.\n\ni) The transcript is needed in this model only because the oracles do\n   nothing more than promise to never sign a message twice; it can be\n   removed if the oracles additionally validate transactions in some\n   way.\n\n\nThe Blockchain as an Anti-Replay Oracle\n=======================================\n\nIn Bitcoin miners act as a trusted anti-replay oracle. If they follow\nthe Bitcoin protocol faithfully for any given txout one and only one\nvalid scriptSig will ever be accepted into the blockchain. Thus the\nspend of a txout is a valid anti-replay-protected signature, and the\nvalidity of that signature can be verified by SPV clients with a merkle\npath to the block headers.\n\n\nUsing proof-of-publication to prove non-replay\n==============================================\n\nGiven a secure proof-of-publication\u00b2 system we can prove non-replay. We\ndefine a valid signature as both being published on that system, as well\nas there existing no other valid signature. (proof-of-non-publication)\nAn attempt to fraudulently create a second signature will either fail\nthe first test - not being published at all - or will fail the second\ntest - not being able to prove no other valid signature exists.\n\nThus we see that proof-of-publication can be used to securely audit the\nhonesty of an anti-replay oracle, resulting in secure anti-replay\nprotection without the requirement of trust.\n\nHowever the converse is not possible: anti-replay cannot be used to\nimplement proof-of-publication. Knowing that no conflicting message\nexists says nothing about who be in posession of that message, or\nindeed, any message at all. Thus anti-replay is not sufficient to\nimplement other uses of proof-of-publication such as decentralized\nexchange\u00b3.\n\n\nAnti-replay in place of proof-of-publication to secure audit logs\n=================================================================\n\nThe author's proof-of-concept Uniquebits\u2074 allows Alice to prove to Bob\nthat some set of records R_i that she has given to Bob is the same set\nof records she has given to everyone else - that is no R_i' exists.\nSecondly Alice can update the records producing R_{i+1}, and Bob can\ndetermine if such an update exists.\n\nCurrently Uniquebits uses proof-of-publication via the Bitcoin\nblockchain directly for both guarantees. It could however make use of\nthe anti-replay function provided by Bitcoin to satisfy the first\nrequirement with the following protocol:\n\n0) Alice publishes record set R_i such that H(T_i + n_i) is committed in\n   R_i, where T_0 is a txout she controls, and n_i is a nonce.\n\n1) Alice creates T_{i+1}, another txout that she controls, and nonce\n   n_{i+1}\n\n2) Alice creates R_{i+1} which commits to H(T_{i+1} + n_i)\n\n3) Finally to publish R_{i+1} she spends T_i in a transaction X_{i+1}\n   that commits to R_{i+1} (e.g. in an OP_RETURN output, or with\n   pay-to-contract\u2075/sign-to-contract)\n\nThis process can be repeated again indefinitely, starting at step #1.\nWhen Alice wants to prove to Bob - who has R_i - she simply gives him a\nSPV proof that transaction X_{i+1} exists in the blockchain along with\nn_i. This proves that T_i was spent, which can only happen once, and\nthat it committed to R_{i+1}. As the output can only be spent once it is\nnot possible to create a valid-looking R_{i+1}'\n\nHowever to prove to Bob that R_{i+1} is the most recent set of records\nAlice still needs to use proof-of-publication, by showing him txout\nT_{i+1} is unspent.\n\n\nCase study: Fidelity-bonded Ledgers/Federated Sidechains\n========================================================\n\nThe author's Fidelity-Bonded Ledgers\u2076 and the more general idea of\nFederated Sidechains\u2077 both describe the notion of a trusted third party,\npossibly implemented as a federated majority set, who guarantees the\ncorrect maintenance of some financial ledger according to some set of\nrules. Coins can be moved to/from the ledger by payment to a specific\nset of scriptPubKey's. Federated sidechains proposes that the\nscriptPubKey simply be a n-of-m multisig; fidelity-bonded ledgers\nproposes new opcodes that allow redemption via proof-of-fraud.\n\nIn any case someone relying on a transaction within the ledger itself\nstill needs to be able to audit that their view of the ledger is the\nsame view everyone else sees; in short that there do not exist\ndouble-spends on the ledger. The author's fidelity-bonded ledgers paper\nproposed that the ledger be made available over a Tor-accessible website\nto prevent selective censorship. The federated sidechains proposal is\nmute on this issue.\n\nAs the state of the ledger is a specific instance of the more general\nset of records problem that Uniquebits solves as can use the same\nprinciples for fidelity-bonded ledgers/federated sidechains. The third\nparty periodically publishes the ledger state to the Bitcoin blockchain\nallowing anyone to detect if their copy of the ledger is incomplete; if\nnot there may be double-spends in it. Finally proof of such\ndouble-spends can trigger the destruction of a fidelity-bond\u2078 and/or\nreturn funds to their rightful owners. (with appropriate opcodes\u2077)\n\nCensorship of the ledger state publications is an issue, however in the\ncase of financial ledgers with pegged funds we can use the pegged funds\nthemselves in the publication. Censoring those publications by\npreventing the designated txouts from being spent then becomes\nequivalent to blacklisting funds. This requires a majority of hashing\npower supporting the blacklist, and is a highly politically charged\nissue\u2079 in the Bitcoin community.\n\n\nReferences\n==========\n\n1) Really Really ultimate blockchain compression: CoinWitness,\n   Gregory Maxwell, Aug 19th 2013, Accessed 2014-12-20,\n   https://bitcointalk.org/index.php?topic=277389.msg2961736\n\n2) Setting the record straight on Proof-of-Publication,\n   Peter Todd, Dec 12th 2014,\n   http://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg06570.html\n\n3) Decentralized digital asset exchange with honest pricing and market depth,\n   Peter Todd, Feb 9th 2014,\n   http://www.mail-archive.com/bitcoin-development%40lists.sourceforge.net/msg03892.html\n\n4) Uniquebits, Peter Todd, Accessed 2014-12-20,\n   https://github.com/petertodd/uniquebits/tree/b9213f6769d80305bdd192925e8bd7bd04239d1b\n\n5) Homomorphic Payment Addresses and the Pay-to-Contract Protocol,\n   Ilja Gerhardt and Timo Hanke, Dec 13th 2012,\n   http://arxiv.org/abs/1212.3257\n\n6) Fidelity-bonded ledgers, Peter Todd, Feb 25th 2013,\n   http://www.mail-archive.com/bitcoin-development%40lists.sourceforge.net/msg01786.html\n\n7) Enabling Blockchain Innovations with Pegged Sidechains,\n   Blockstream, Oct 22nd 2014,\n   SHA256: 680c71aef9ed578720e25c58fd50de5cdbee755c3800e7601dad9a745ca65cf3,\n   http://www.blockstream.com/sidechains.pdf\n\n8) Fidelity-bonded banks: decentralized, auditable, private, off-chain payments,\n   Peter Todd, Feb 23rd 2014,\n   https://bitcointalk.org/index.php?topic=146307.0\n\n9) WARNING: Bitcoin Address Blacklists have been forced into the Gentoo Linux bitcoind distribution by Luke-jr against the will of other core devs. Gentoo maintainers are clueless and not reversing the change.  Boycott Gentoo now.,\n   historian1111, Oct 10th 2014, Accessed 2014-12-20,\n   https://www.reddit.com/r/Bitcoin/comments/2ityg2/warning_bitcoin_address_blacklists_have_been/\n\n-- \n'peter'[:-1]@petertodd.org\n000000000000000001eeaba4cdadaf5b8338cb1b2ae0cf969de77437dd83faac\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141220/3895cdee/attachment.sig>"
            },
            {
                "author": "Adam Back",
                "date": "2014-12-21T10:01:37",
                "message_text_only": "On 20 December 2014 at 14:48, Peter Todd <pete at petertodd.org> wrote:\n> We need the following primitives operating on message m, pubkey p, and a\n> valid signature sig1 for m, p:\n>\n>     AntiReplaySign(m, p, sig1) -> sig2\n>     VerifyAntiReplaySig(m, p, sig2) -> True or False\n>\n> Additionally once AntiReplaySign() has been used once for a given pubkey\n> it is impossible to re-run the primitive on a different message m'. This\n> is of course impossible to implement with math alone, but we can\n> implement it with a trusted third party.\n\nWell while you cant prevent it you could render it insecure enabling\nminers to take funds.\n\nThat could work via a one-show signature; normal ECDSA being address\na=H(Q), public key Q=dG, R=kG, r=R.x, s=(H(m)+rd)/k, signature (r,s),\nverify: a=?H(Q) and sR=?H(m)G+rQ one-show being: a=H(Q,R), verify\nbeing: a=?H(Q,R) and sR=?H(m)G+rQ.  Now that is unsafe to double-spend\nby design as only that specific R is usable and as we know reusing R\nwith different messages leaks the private key because: s=(H(m)+rd)/k\nand s'=(H(m')+rd)/k implies sk=H(m)+rd and s'k=H(m')+rd so\nk=(H(m)-H(m'))/(s'-s), and d=(sk-H(m))/r.\n\nAdam"
            },
            {
                "author": "Peter Todd",
                "date": "2014-12-21T15:29:37",
                "message_text_only": "On Sun, Dec 21, 2014 at 10:01:37AM +0000, Adam Back wrote:\n> On 20 December 2014 at 14:48, Peter Todd <pete at petertodd.org> wrote:\n> > We need the following primitives operating on message m, pubkey p, and a\n> > valid signature sig1 for m, p:\n> >\n> >     AntiReplaySign(m, p, sig1) -> sig2\n> >     VerifyAntiReplaySig(m, p, sig2) -> True or False\n> >\n> > Additionally once AntiReplaySign() has been used once for a given pubkey\n> > it is impossible to re-run the primitive on a different message m'. This\n> > is of course impossible to implement with math alone, but we can\n> > implement it with a trusted third party.\n> \n> Well while you cant prevent it you could render it insecure enabling\n> miners to take funds.\n> \n> That could work via a one-show signature; normal ECDSA being address\n> a=H(Q), public key Q=dG, R=kG, r=R.x, s=(H(m)+rd)/k, signature (r,s),\n> verify: a=?H(Q) and sR=?H(m)G+rQ one-show being: a=H(Q,R), verify\n> being: a=?H(Q,R) and sR=?H(m)G+rQ.  Now that is unsafe to double-spend\n> by design as only that specific R is usable and as we know reusing R\n> with different messages leaks the private key because: s=(H(m)+rd)/k\n> and s'=(H(m')+rd)/k implies sk=H(m)+rd and s'k=H(m')+rd so\n> k=(H(m)-H(m'))/(s'-s), and d=(sk-H(m))/r.\n\nThere's no need to get into the specifics of crypto math so early; you\ncan just as easily and only slightly less efficiently obtain the same\nresult with a few extensions to the Bitcoin scripting system to verify\nECDSA signatures directly.\n\nThe interesting question is how \"risky\" this actually is? Sybil attacks\nare reasonably easy to pull off, and users have little incentive to\nvalidate if 99% of the time everything works, so you don't want to\ncreate a system where an actual attack will likely go undetected.\nTalking about the low level details of how double-spend punishment is\nactually detailed is just premature optimization.\n\nAs usual in Bitcoin, the hard part is *not* the math.\n\n-- \n'peter'[:-1]@petertodd.org\n000000000000000012f5511833a1304a72a754df8afef26f5712438bcc40826b\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/5b4ce534/attachment.sig>"
            },
            {
                "author": "paul snow",
                "date": "2014-12-21T13:49:17",
                "message_text_only": "On Dec 20, 2014 8:49 AM, \"Peter Todd\" <pete at petertodd.org> wrote:\n>\n> However the converse is not possible: anti-replay cannot be used to\nimplement proof-of-publication. Knowing that no conflicting message exists\nsays nothing about who be in posession of that message, or indeed, any\nmessage at all. Thus anti-replay is not sufficient to implement other uses\nof proof-of-publication such as decentralized exchange\u00b3.\n\nHow does proof of publication prove who is in possession of that message?\nOr of any message at all?  The data written in an anti-replay system and\nthe data written in a proof of publication system differs in that you can't\nrepeat data in an anti-replay system according to some understanding of the\nrules of the meaning of the data (if I am following your description\ncorrectly).\n\nObviously you can publish the same data as many times as you like in a\nproof-of-publication system; the interpretation of what that data means\nwould be the responsibility of the observers, not the \"publishing\nvehicle\".  Repeated entries thus can be written, and the user of PoP can\nvalidate and prove they did so.\n\nIf the data itself defines possession, the \"ownership of the message\" (it\nisn't even clear to me what you mean by that phrase) isn't defined by\neither proof, but by the message itself.  And the message itself isn't\nconstrained by either to prohibit proving ownership (what ever you mean by\nthat).\n\nOf course, I do assume I can test a message (or a set of messages sharing\nsome feature like a particular input on a transaction) as being publishable\nin an anti-replay system without actually publishing it.  That does allow\none to prove non-publishing.  You can determine if a message exists that\nwould preclude the publishing of a message; the very purpose of an\nanti-replay proof.\n\nAnd I would assert that such a search (i.e. the idea that such a search has\nmeaning in a anti-replay system) is already incorporating the assumption\nthat such a search is possible and must be possible for an anti-replay\nsystem.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/793952f0/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2014-12-21T15:22:56",
                "message_text_only": "On Sun, Dec 21, 2014 at 07:49:17AM -0600, paul snow wrote:\n> On Dec 20, 2014 8:49 AM, \"Peter Todd\" <pete at petertodd.org> wrote:\n> >\n> > However the converse is not possible: anti-replay cannot be used to\n> implement proof-of-publication. Knowing that no conflicting message exists\n> says nothing about who be in posession of that message, or indeed, any\n> message at all. Thus anti-replay is not sufficient to implement other uses\n> of proof-of-publication such as decentralized exchange\u00b3.\n> \n> How does proof of publication prove who is in possession of that message?\n> Or of any message at all?\n\nWith the blockchain you prove the message in in the blockchain; anyone\nin posession of the blockchain will be in posession of the message.\nSecondly determining if you are in posession of the blockchain is\npossible subject to the usual considerations about attacker size,\nwhether or not your local clock is up-to-date, etc.\n\n> The data written in an anti-replay system and\n> the data written in a proof of publication system differs in that you can't\n> repeat data in an anti-replay system according to some understanding of the\n> rules of the meaning of the data (if I am following your description\n> correctly).\n\nI'm not sure you understand what an anti-replay system is; data isn't\nwritten to them; they're an abstract mathematical model that may be\nactually implemented in a variety of ways.\n\nNow it is true that any conceivable implementation must involve some\ntype of storage, but that storage can easily 100% local to the\nanti-replay oracle and need not store the data itself. For instance a\ntrusted computer in a vault that maintains an extremely large bloom\nfilter of previously used keys would be a perfectly reasonable\nimplementation.\n\n> If the data itself defines possession, the \"ownership of the message\" (it\n> isn't even clear to me what you mean by that phrase) isn't defined by\n> either proof, but by the message itself.  And the message itself isn't\n> constrained by either to prohibit proving ownership (what ever you mean by\n> that).\n\nWait, where did I say \"ownership of the message\"? What you quoted above\nsays *posession*, which != ownership.\n\n> Of course, I do assume I can test a message (or a set of messages sharing\n> some feature like a particular input on a transaction) as being publishable\n> in an anti-replay system without actually publishing it.  That does allow\n> one to prove non-publishing.  You can determine if a message exists that\n> would preclude the publishing of a message; the very purpose of an\n> anti-replay proof.\n>\n> And I would assert that such a search (i.e. the idea that such a search has\n> meaning in a anti-replay system) is already incorporating the assumption\n> that such a search is possible and must be possible for an anti-replay\n> system.\n\nYou're confused about what an anti-replay system actually is - you're\nreally talking about a specific implementation of one based on\nproof-of-publication, not the concept itself.\n\n-- \n'peter'[:-1]@petertodd.org\n00000000000000001b728df6414af5ef95388557f1c3e5d29c569d7636b93681\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/f938d68b/attachment.sig>"
            },
            {
                "author": "paul snow",
                "date": "2014-12-21T15:41:08",
                "message_text_only": "I could play the game where I say, \"You don't understand,\" and, like you,\nnot address any of your points.\n\nFirst, there is no dependence on implementation in my arguments.  If a\nsystem can prevent replay by some set of rules, it necessarily must be able\nto answer the question if a message is publishable.  Non publishing proofs\nare thus possible and even required.\n\nThe argument that proof of audience isn't part of an anti-replay system is\nnot one I picked up on, but an publicly auditable anti replay system\nnecessarily must define its audience. Again, not an issue for an auditable\nsystem.\nOn Dec 21, 2014 9:23 AM, \"Peter Todd\" <pete at petertodd.org> wrote:\n\n> On Sun, Dec 21, 2014 at 07:49:17AM -0600, paul snow wrote:\n> > On Dec 20, 2014 8:49 AM, \"Peter Todd\" <pete at petertodd.org> wrote:\n> > >\n> > > However the converse is not possible: anti-replay cannot be used to\n> > implement proof-of-publication. Knowing that no conflicting message\n> exists\n> > says nothing about who be in posession of that message, or indeed, any\n> > message at all. Thus anti-replay is not sufficient to implement other\n> uses\n> > of proof-of-publication such as decentralized exchange\u00b3.\n> >\n> > How does proof of publication prove who is in possession of that message?\n> > Or of any message at all?\n>\n> With the blockchain you prove the message in in the blockchain; anyone\n> in posession of the blockchain will be in posession of the message.\n> Secondly determining if you are in posession of the blockchain is\n> possible subject to the usual considerations about attacker size,\n> whether or not your local clock is up-to-date, etc.\n>\n> > The data written in an anti-replay system and\n> > the data written in a proof of publication system differs in that you\n> can't\n> > repeat data in an anti-replay system according to some understanding of\n> the\n> > rules of the meaning of the data (if I am following your description\n> > correctly).\n>\n> I'm not sure you understand what an anti-replay system is; data isn't\n> written to them; they're an abstract mathematical model that may be\n> actually implemented in a variety of ways.\n>\n> Now it is true that any conceivable implementation must involve some\n> type of storage, but that storage can easily 100% local to the\n> anti-replay oracle and need not store the data itself. For instance a\n> trusted computer in a vault that maintains an extremely large bloom\n> filter of previously used keys would be a perfectly reasonable\n> implementation.\n>\n> > If the data itself defines possession, the \"ownership of the message\" (it\n> > isn't even clear to me what you mean by that phrase) isn't defined by\n> > either proof, but by the message itself.  And the message itself isn't\n> > constrained by either to prohibit proving ownership (what ever you mean\n> by\n> > that).\n>\n> Wait, where did I say \"ownership of the message\"? What you quoted above\n> says *posession*, which != ownership.\n>\n> > Of course, I do assume I can test a message (or a set of messages sharing\n> > some feature like a particular input on a transaction) as being\n> publishable\n> > in an anti-replay system without actually publishing it.  That does allow\n> > one to prove non-publishing.  You can determine if a message exists that\n> > would preclude the publishing of a message; the very purpose of an\n> > anti-replay proof.\n> >\n> > And I would assert that such a search (i.e. the idea that such a search\n> has\n> > meaning in a anti-replay system) is already incorporating the assumption\n> > that such a search is possible and must be possible for an anti-replay\n> > system.\n>\n> You're confused about what an anti-replay system actually is - you're\n> really talking about a specific implementation of one based on\n> proof-of-publication, not the concept itself.\n>\n> --\n> 'peter'[:-1]@petertodd.org\n> 00000000000000001b728df6414af5ef95388557f1c3e5d29c569d7636b93681\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/d3022b3a/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2014-12-22T00:11:37",
                "message_text_only": "On Sat, Dec 20, 2014 at 09:48:01AM -0500, Peter Todd wrote:\n\nAndrew Miller asked me to publish the following to the mailing list on his\nbehalf: (https://twitter.com/socrates1024/status/546819355565391872)\n\nOne of the main points in this note is that you can use a\n\"proof-of-publication\" system to implement an \"anti-replay\" system.\nHowever this isn't true - at least not given the description of\nproof-of-(non)-publication in 2) and the definition of \"anti-replay\"\ngiven here.\n\nIn 2), proof-of-*non*-publication allows you to prove that *some\nspecific message* has never been published. You can imagine having a\nfunction ProveNotPublished(m), which proves \"message m was not\npublished.\"\n\nHowever, the anti-replay mechanism is about proving that *no* message\nsatisfying some property has been published. Hence\nVerifyAntiReplaySig(m, p, s) checks that \"for all possible messages m'\n(distinct from m), AntiReplaySign(m', p) has not been called.\"\n\n\nThis isn't *just* splitting hairs, this distinction is actually\nrelevant for analyzing several cryptocurrency designs. You can imagine\nextending the definition of proof-of-(non)-publication to take in some\npredicate P, so that you can prove \"no message m such that P(m) holds\nhas ever been published.\" However, to do this efficiently requires\nanticipating some classes of P and building some appropriate indices.\n\n- As a baseline, as long as you have the whole blockchain available,\nyou can scan through the entire blockchain and evaluate P for every\ntransaction, but this is pretty inefficient.\n- Other tradeoffs are available if you are willing to trust some\n(quora of) servers to maintain indices for you\n- Bitcoin's UTXO set effectively supports a predicate for each txout,\nwhere P(x) = \"x is a valid tranasction that spends <txout>\"\n- Ethereum contracts, in a sense, allow for general purpose contracts\nto 'build-your-own\" index. On the other hand its key-value store\ndoesn't support range queries, so it's not necessarily \"universal\" or\nas expressive as SQL, for example.\n\n\nBut the point isn't to argue about design choices and tradeoffs in\nthis thread. The main point I want to make is:\n*Indexes and Validation Matter!*\nThe classic \"proof-of-publication\" system is to embed opaque data (as\nfar as bitcoin miners are concerned) in transactions using OP_RETURN.\nA significance of establishing \"proof-of-publication\" as a universal\nunderlying primitive is that this OP_RETURN trick is then sufficient\nfor anything you might want. But part of what Bitcoin provides is\nindexing and validation/exclusion, and this is important for\nsupporting efficient anti-replay proofs. Proof-of-(non)-publication\nalone isn't sufficient for this.\n\n-- \n'peter'[:-1]@petertodd.org\n00000000000000000a7b40becd0babbd64ec49b8b34823fb4f4b081c95188b66\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/f4d89c08/attachment.sig>"
            },
            {
                "author": "Adam Back",
                "date": "2014-12-22T20:05:40",
                "message_text_only": "(Again nothing new to say here, just putting my notes in this\ndiscussion, where I started with an earlier discussion that Peter\nwrote up with a subject of \"disentangling\" blockchain design).\n\nIn the discussion last year that started the analysis of\n\"disentangling\" blockchain design I had broken out the candidate layer\nproperties that one could use as building blocks to construct a\ndecentralised PoW-chain assured immutable history based ecash system\nas:\n\n- time-stamping (really just time-ordered as network time is weak)\n\n- namespace (first come first served name value pairs)\n\nI thought it was interesting to look at potential minimum enabling\nfunctionality in order to explore whether the consensus critical code\ncould be simplified for security, and also to understand the tradeoffs\ntowards seeing if there were any improvements that could be found.\n(And it seems its pretty hard to find any improvements was my\nconclusion).\n\n\nTime-stamping (or time-ordering) at a requirements level does not have\nto imply that there is a uniqueness guarantee, or even that the nodes\nsee what they are time-stamping (it could be committed with a random\nnonce) and indeed hiding the committed data from the service and\npublic view is a common property of time-stamping.  Time-ordering just\ncreates an immutable (and not strongly deduplicated) stream of data\nitems that came from various users and had a time-ordering placed on\nthem.\n\nMinimally the person who submitted the data item would need to know\nthe merkle path to it, and that might be achieved by publishing the\nmerkle tree, where some or all of the leaves are hidden commitments.\n\nFor bitcoin composability purposes you might require that there be no\nhidden commitments, and then other miners and full nodes could\ndownload all the merkle trees for each PoW-interval and ignore\nduplicates.\n\n\nNamespace service adds the uniqueness and first-come first-served\nproperty up-front (as its more efficient for people catching up to not\nhave to download and discard duplicates/double-spends), and this more\nstrict rule requires miners to know about (and presumably index) all\nprevious information to avoid violating this rule. I assume name\nattributes to hold information like a public key to approve changes in\nownership, an IP address, an email address etc.  For efficient proof\nreasons there is still a merkle tree per PoW time-interval binding\nnames into a hash-chain.\n\nFor bitcoin re-described using a namespace the unique coins are the\nnames, and values and ownership public key etc are attributes of the\nname; names (coins) are only added (via mining) or after deletion\n(spend/transfer) of previous names.  Transfers are approved via\ndigital signature.\n\nThe additional property bitcoin requires is that the values add up.\n\n\nI presume the phrase proof of publication means to draw out separately\nthat the full-node version of bitcoin requires a rule that miners\nshould not build on top of blocks unless they have copies of all data\ncommitted to.  Otherwise a malicious party can hide ownership\ntransfers that can be revealed later, so that no one is assured of\nownership: any possibility for a gap in the ownership chain calls into\nquestion ownership.  So from that perspective a miner consensus rule\nthat it should not build on top of blocks that it hasnt seen a full\ngap-free history for makes the PoW chain a kind of proof that the\nminer population at one time saw all data hashed into it.\n\nI think you need one more thing which is that the miners (and other\nfull nodes who have copies of the data) are willing to share that\nhistoric data with you.  There is some meta-incentive for bitcoin\nholders to help others catchup and be assured of the history and\ninformation has to be broadcast as there are many miners and\nfull-nodes.\n\n\nI presume anti-relay term is meant at system level, rather than node\nlevel, though technically bitcoin nodes in the current protocol\nversion dont relay double-spent transactions.  Particularly that\nminers wont bless double-spent transactions (and will do PoW only over\nnon double-spent transfers).\n\n\nWhile there does seem to be some confusion from some people perhaps\nnot realising that it is essential that there are no gaps in the\nownership chain, I am not sure there are necessarily any practical\nimplication of philosophical differences between proof of publication\n& anti-relay (or namespace for that matter).  It is also important\nthat there is no way to attack the insertion logic so that eg someone\ncant get a hash into an internal nor leaf node of the merkle tree\nwithout the miners first seeing that data.\n\nPresumably as they are all describing ways to think about bitcoin and\nassuming no one is confused about how bitcoin works, the distinction\njust comes down to what features are assumed to be naturally included\nin the layer definition, and what features have to be added.  For\nexample I think its relatively normally assumed that people can look\nup names.\n\n\nI suppose it might be possible to put a self-authenticating access\nhandle for the data item into the data set which points into a\nredundant immutable data store.  In effect that is what the bitcoin\nnodes do provide (with full redundancy).  But, more efficiently though\nperhaps with less redundancy and assurance, one could put the data\ninto tahoe-lafs which implements immutability, append-only and\nself-authenticating urls and such properties.  From that perspective\nit does make sense to say there is a layer that provides assurance of\navailability of history; the PoW-chain and merkle-tree in the header\nassures already immutability.  The remaining thing that has to be\nassured is availability.\n\nAdam\n\nOn 20 December 2014 at 14:48, Peter Todd <pete at petertodd.org> wrote:\n> Gregory Maxwell recently pointed out to me in private conservation that\n> there potentially existed a fundemental disagreement between him and I\n> on our philosophical approaches to blockchains, in that he prioritised\n> the notion of the blockchain as an anti-replay oracle, and I prioritised\n> it as a publication layer. Here I'll talk about the differences and\n> simularities between those two approaches."
            },
            {
                "author": "Peter Todd",
                "date": "2014-12-21T05:52:20",
                "message_text_only": "On Sun, Dec 21, 2014 at 11:57:51AM +0800, Mark Friedenbach wrote:\n> On Sat, Dec 20, 2014 at 10:48 PM, Peter Todd <pete at petertodd.org> wrote:\n> \n> > However the converse is not possible: anti-replay cannot be used to\n> > implement proof-of-publication. Knowing that no conflicting message\n> > exists says nothing about who be in posession of that message, or\n> > indeed, any message at all. Thus anti-replay is not sufficient to\n> > implement other uses of proof-of-publication such as decentralized\n> > exchange\u00b3.\n> >\n> \n> I think you are trying to say something more specific / limited than that,\n> and I suggest you adjust your wording accordingly. Decentralized exchange\n> would be possible today with vanilla bitcoin using SIGHASH_SINGLE if only\n> the protocol supported multiple validated assets (which it could, but\n> doesn't). Rather straightforward further extensions to the protocol would\n> enable market participants to use a wider class of orders, as well as\n> enable the buyer rather than the seller to dictate order sizes via partial\n> redemption, as we demonstrate in our Freimarkets paper.\n\nDo you realise that all those Freimarket's uses are either based on\nproof-of-publication, or insecure due to sybil attacks?\n\n-- \n'peter'[:-1]@petertodd.org\n000000000000000017d70ee98f4cee509d95c4f31d5b998bae6deb09df1088fc\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/0a2a8521/attachment.sig>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2014-12-21T11:25:36",
                "message_text_only": "st\n\nOn Sun, Dec 21, 2014 at 6:52 AM, Peter Todd <pete at petertodd.org> wrote:\n> On Sun, Dec 21, 2014 at 11:57:51AM +0800, Mark Friedenbach wrote:\n>> I think you are trying to say something more specific / limited than that,\n>> and I suggest you adjust your wording accordingly. Decentralized exchange\n>> would be possible today with vanilla bitcoin using SIGHASH_SINGLE if only\n>> the protocol supported multiple validated assets (which it could, but\n>> doesn't). Rather straightforward further extensions to the protocol would\n>> enable market participants to use a wider class of orders, as well as\n>> enable the buyer rather than the seller to dictate order sizes via partial\n>> redemption, as we demonstrate in our Freimarkets paper.\n>\n> Do you realise that all those Freimarket's uses are either based on\n> proof-of-publication, or insecure due to sybil attacks?\n\nSo let's go through an example to see in which ways\nnon-proof-of-publication orders are \"insecure\".\n\nAlice the seller wants to sell 1 unit of A for 100 units of B.\nBob is willing to pay up to 200 Bs for 1 A.\n\nLet's assume a proof of publication system first, in which the\nexecution price is the mean between bid and ask.\nAlice publishes her order.\nBob could publish his order at price 200 Bs and the order would\nexecute at 150 Bs.\nBut after seeing Alice's order he knows he doesn't need to pay that\nmuch, so he publishes and order buying for 100 Bs.\n\nAlice gets 100 Bs (what she signed she wanted) and Bob pays less than\nhe was wiling to pay, he pays 100 Bs. Everybody happy.\n\nNow let's assume native assets and sighash_single.\n\nAlice publishes her order (out of band, using various channels).\nBob could publish his order at price 200 Bs and then a miner would\nexecute at 100 Bs for Alice, at 200 Bs for Bob and pocket 100 Bs as\nmining fees.\nBut after seeing Alice's order he knows he doesn't need to pay that\nmuch, so he publishes and order buying for 100 Bs.\n\nAgain, Alice gets 100 Bs (what she signed she wanted) and Bob pays pays 100 Bs.\nThe main difference is that Alice didn't had to pay a fee to publish\nher binding order.\n\nNow let's try to articulate your concerns.\nYour concern is that Carol, isolates Bob preventing him from seeing\nAlice's order.\nThen maybe Bob publishes his own order at 200 Bs.\nIf Carol sees both orders while preventing the other participants from\nseeing them, she can build a tx in which Alice sells at 100, Bob buys\nat 200, and Carol pockets the difference.\nBut...any smart miner will replace Carol's address with his own when\nprocessing the trade, so Carol cannot win this way.\n\nAnother thing Carol can do is to buy the A herself for 100 Bs, leaving\nBob without them.\nIf Alice cares about Bob getting the deal instead of Carol she can do\ntwo things:\n1) Establish a direct communication channel with Bob\n2) Move to a proof of publication system and start paying fees for\npublishing binding orders.\n\nSo again, what's the advantage that proof-of-publication provides TO\nALICE so that she will be so eager to pay the higher costs to get the\nsame deal?\nIf this example is not enough to be able to explain the advantage of\nproof-of-publication markets feel free to write a more complex one."
            },
            {
                "author": "Peter Todd",
                "date": "2014-12-21T16:07:13",
                "message_text_only": "On Sun, Dec 21, 2014 at 12:25:36PM +0100, Jorge Tim\u00f3n wrote:\n> So let's go through an example to see in which ways\n> non-proof-of-publication orders are \"insecure\".\n> \n> Alice the seller wants to sell 1 unit of A for 100 units of B.\n> Bob is willing to pay up to 200 Bs for 1 A.\n> \n> Let's assume a proof of publication system first, in which the\n> execution price is the mean between bid and ask.\n> Alice publishes her order.\n> Bob could publish his order at price 200 Bs and the order would\n> execute at 150 Bs.\n> But after seeing Alice's order he knows he doesn't need to pay that\n> much, so he publishes and order buying for 100 Bs.\n> \n> Alice gets 100 Bs (what she signed she wanted) and Bob pays less than\n> he was wiling to pay, he pays 100 Bs. Everybody happy.\n> \n> Now let's assume native assets and sighash_single.\n\nIncidentally, SIGHASH_SINGLE is just as usable in embedded consensus;\nit's not specific to native assets.\n\n> So again, what's the advantage that proof-of-publication provides TO\n> ALICE so that she will be so eager to pay the higher costs to get the\n> same deal?\n\nLike I said the last time this issue was discused on the mailing list,\nit's silly to think the seller of an asset starts off with a specific\nprice they want to sell it at and is happy no matter what happens or how\nit gets fufilled. In the real world sellers and buyers want to know\nthey're connected to actual sellers and buyers - not sybil attackers\ntrying to shave off a margin for themselves - and are willing to pay a\npremium for that. Note all the hatred and vitrol directed towards\nhigh-frequency traders...\n\nHow *much* of a premium is an interesting question, and depends a lot on\nthe specific scenario. For instance I fully expect to see a whole\nvariety of mediums become used for the proof-of-publication needed,\nranging from directly on a major blockchain to minor/less secure\nblockchains like Bitmessage over treechains to centralized-but-audited\nproof-of-publication schemes - AKA centralized exchanges - to standard\nexchanges. Point is, the concept of proof-of-publication makes these\ntradeoffs and options available and lets end-users pick the right one\nfor their needs.\n\nAccurate unbiased price information is worth money. In systems that\nallow third-parties to republish asset bids and offers we'll even see\nthird-parties republishing bids and offers from less secure systems to\nmore secure systems to get better price discovery.\n\n> If this example is not enough to be able to explain the advantage of\n> proof-of-publication markets feel free to write a more complex one.\n\nI gotta ask, have you actually run the design and tradeoffs of\nFriemarket's past actual finance types? I have, and it's remarkable how\nexcited many of them are about cryptographically provable fair price\ndiscovery.\n\n-- \n'peter'[:-1]@petertodd.org\n000000000000000002661192e72bdc83e6c8101371520159531301aa1437cc2c\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/5262d433/attachment.sig>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2014-12-21T19:39:46",
                "message_text_only": "On Sun, Dec 21, 2014 at 5:07 PM, Peter Todd <pete at petertodd.org> wrote:\n> On Sun, Dec 21, 2014 at 12:25:36PM +0100, Jorge Tim\u00f3n wrote:\n>> So let's go through an example to see in which ways\n>> non-proof-of-publication orders are \"insecure\".\n>>\n>> Alice the seller wants to sell 1 unit of A for 100 units of B.\n>> Bob is willing to pay up to 200 Bs for 1 A.\n>>\n>> Let's assume a proof of publication system first, in which the\n>> execution price is the mean between bid and ask.\n>> Alice publishes her order.\n>> Bob could publish his order at price 200 Bs and the order would\n>> execute at 150 Bs.\n>> But after seeing Alice's order he knows he doesn't need to pay that\n>> much, so he publishes and order buying for 100 Bs.\n>>\n>> Alice gets 100 Bs (what she signed she wanted) and Bob pays less than\n>> he was wiling to pay, he pays 100 Bs. Everybody happy.\n>>\n>> Now let's assume native assets and sighash_single.\n>\n> Incidentally, SIGHASH_SINGLE is just as usable in embedded consensus;\n> it's not specific to native assets.\n>\n>> So again, what's the advantage that proof-of-publication provides TO\n>> ALICE so that she will be so eager to pay the higher costs to get the\n>> same deal?\n>\n> Like I said the last time this issue was discused on the mailing list,\n> it's silly to think the seller of an asset starts off with a specific\n> price they want to sell it at and is happy no matter what happens or how\n> it gets fufilled. In the real world sellers and buyers want to know\n> they're connected to actual sellers and buyers - not sybil attackers\n> trying to shave off a margin for themselves - and are willing to pay a\n> premium for that. Note all the hatred and vitrol directed towards\n> high-frequency traders...\n\nAnd like last time we discussed this on the mailing list my opinion\ndiffers from yours.\nYou talk about \"real world sellers and buyers\" but ignore Alice the\nseller and Bob the buyer in my example.\nYou failed to explain how sybil attackers (Carol) get all those\nmargins. In my example I claim miners get them, what am I missing?\nHow is the same example with a proof-of-publication market any better?\nMiners can reorder the orders with proof of publication too.\nIf getting orders into mined blocks faster has an advantage miners can\ncharge privileged traders for privileged connections (just like it\nhappens today with \"perfectly fair\" centralized markets today that\nfeature the high-frequency trading you mention).\nThey could even charge for moving transactions around within the same\nblock if that has any effect on the execution rules.\nI prefer that miners can get the difference between bids and asks\ndirectly to compensate for their hashing power.\n\n> How *much* of a premium is an interesting question, and depends a lot on\n> the specific scenario. For instance I fully expect to see a whole\n> variety of mediums become used for the proof-of-publication needed,\n> ranging from directly on a major blockchain to minor/less secure\n> blockchains like Bitmessage over treechains to centralized-but-audited\n> proof-of-publication schemes - AKA centralized exchanges - to standard\n> exchanges. Point is, the concept of proof-of-publication makes these\n> tradeoffs and options available and lets end-users pick the right one\n> for their needs.\n\nThe point is that there's more models for p2p markets beyond those\nthat require proof of publication for their orders, and you're\nclaiming that only those using proof of publication are secure.\nThat's incorrect.\n\n> Accurate unbiased price information is worth money.\n\nCan you define \"Accurate unbiased price information\"?\n\n> In systems that\n> allow third-parties to republish asset bids and offers we'll even see\n> third-parties republishing bids and offers from less secure systems to\n> more secure systems to get better price discovery.\n\nTraders want to trade. The primary function of markets is exchange,\nnot price discovery.\n\n>> If this example is not enough to be able to explain the advantage of\n>> proof-of-publication markets feel free to write a more complex one.\n>\n> I gotta ask, have you actually run the design and tradeoffs of\n> Friemarket's past actual finance types? I have, and it's remarkable how\n> excited many of them are about cryptographically provable fair price\n> discovery.\n\n\"Provably fair price discovery\" is probably impossible. But I can\nimagine how many people could get excited about such a technology.\nCan you formally define what you mean by this?\nYou see, \"fair\" implies morality and therefore it's a very subjective\nterm, so it's not obvious to me what you may mean by that.\n\n\n> --\n> 'peter'[:-1]@petertodd.org\n> 000000000000000002661192e72bdc83e6c8101371520159531301aa1437cc2c"
            },
            {
                "author": "Peter Todd",
                "date": "2014-12-21T07:01:54",
                "message_text_only": "On Sun, Dec 21, 2014 at 02:18:18PM +0800, Mark Friedenbach wrote:\n> Care to expand?\n> \n> Freimarkets does not require proof of publication of bids or asks, which\n> are distributed out of band from the block chain until a match is made. It\n> does not guarantee ordering of market transactions. Indeed, front-running\n> is embraced as the mechanism for generating miner fees to pay for the\n> service.\n\nRight, so Freimarkets is delibrately insecure.\n\nBest of luck on that.\n\n> Sybil attacks? I'm not sure what you could be referring to. In Freimarkets\n> a bid or ask is valid when received; a double-spend is required to cancel\n> it. You could only flood the network with actual executable orders, and the\n> counter-party to the order doesn't care if they all came from the same\n> person or not.\n> \n> Can you explain what it is you are objecting to?\n\nRead my paper\u00b9 - proof-of-publication is what allows you to detect\nfront-running robustly within certain parameters. Protecting against\nthat is widely considered to be a very important goal by people actually\nin finance, to the point where I've had discussions with people where\nanti-front-running protection might be the *only* thing they use a\ndecentralized system for.\n\n\n1) Decentralized digital asset exchange with honest pricing and market depth,\n   Peter Todd, Feb 9th 2014,\n   http://www.mail-archive.com/bitcoin-development%40lists.sourceforge.net/msg03892.html\n\n-- \n'peter'[:-1]@petertodd.org\n000000000000000000c879729eae178096b092248706a407ec1b18eb62a792e9\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/bb56fbc7/attachment.sig>"
            },
            {
                "author": "Peter Todd",
                "date": "2014-12-21T15:32:41",
                "message_text_only": "On Sun, Dec 21, 2014 at 03:11:32PM +0800, Mark Friedenbach wrote:\n> On Sun, Dec 21, 2014 at 3:01 PM, Peter Todd <pete at petertodd.org> wrote:\n> \n> > Right, so Freimarkets is deliberately insecure.\n> >\n> \n> Please define your terms, particularly what your security requirements are\n> here. In the architecture we created users remain in control of their funds\n> at all times, and miners have incentives to mine the host chain. So I don't\n> know what insecurity you are possibly talking about, and seem unwilling to\n> elaborate.\n\nSybil attacks leading to front-running.\n\nYou may not be aware of this, but not being able to get the best price\ndue to a sybil attack *is* considered to be a security issue by the\nusers of these systems.\n\n> I have read your posting and engaged with you in that very thread, where I\n> point out that global ordering of bids & asks is a superfluous requirement.\n\nIt's superfluous until you have real businesses actually using these\nsystems.\n\n> As to front-running, there is a distinct difference between centralized\n> systems where front-running is essentially theft, and a distributed block\n> chain system with actual costs paid by fees captured from the spread.\n\nAmong other things, ever noticed how this incentivises people to sybil\nattack the entire system? Not good.\n\n-- \n'peter'[:-1]@petertodd.org\n000000000000000012f5511833a1304a72a754df8afef26f5712438bcc40826b\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/5accbf50/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "The relationship between Proof-of-Publication and Anti-Replay Oracles",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Adam Back",
                "paul snow",
                "Jorge Tim\u00f3n",
                "Peter Todd"
            ],
            "messages_count": 14,
            "total_messages_chars_count": 47806
        }
    },
    {
        "title": "[Bitcoin-development] Near-zero fee transactions with hub-and-spoke micropayments",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2014-12-13T02:34:58",
                "message_text_only": "From the So-Obvious-No-one-Has-Bothered-to-Write-It-Down-Department:\n\ntl;dr: Micropayment channels can be extended to arbitrary numbers of\nparties using a nearly completley untrusted hub, greatly decreasing\ntransaction fees and greatly increasing the maximum number of financial\ntransactions per second that Bitcoin can support.\n\n\nSo a micropayment channel enables a payor to incrementally pay a payee\nby first locking a deposit of Bitcoins in a scriptPubKey of the\nfollowing form:\n\n    IF\n        <timeout> CHECKLOCKTIMEVERIFY OP_DROP\n    ELSE\n        <payee> CHECKSIGVERIFY\n    ENDIF\n    <payor> CHECKSIGVERIFY\n\n(obviously many other forms are possible, e.g. multisig)\n\nOnce the funds are confirmed, creating txout1, the payor creates\ntransactions spending txout1 sending some fraction of the txout value to\nthe payee and gives that half-signed transaction to the payee. Each time\nthe payor wants to send more money to the payee they sign a new\nhalf-signed transaction double-spending the previous one.\n\nWhen the payee is satisfied they can close the channel by signing the\nmost recent, highest value, tx with their key, thus making it valid. If\nthe payee vanishes the payor can get all the funds back once the timeout\nis reached using just their key.\n\nSince confirmation is controlled by the payee once the initial deposit\nconfirms subsequent increases in funds sent happen instantly in that the\npayor can not double-spend the input until the timeout is reached.\n\n(there's another formulation from Jeremy Spilman that can be almost\nimplemented right now using a signed refund transaction, however it is\nvulnerable to transaction mutability)\n\n\nHub-and-Spoke Payments\n======================\n\nUsing a nearly completely untrusted hub we can allow any number of\nparties to mutually send and receive Bitcoins instantly with near-zero\ntransaction fees. Each participant creates one or two micropayment\nchannels with the hub; for Alice to send Bob some funds Alice first\nsends the funds to the hub in some small increment, the hub sends the\nfunds to Bob, and finally the hub gives proof of that send to Alice. The\nincremental amount of Bitcoins sent can be set arbitrarily low, limited\nonly by bandwidth and CPU time, and Bob does not necessarily need to\nactually be online. The worst that the hub can do is leave user's funds\nlocked until the timeout expires.\n\n\nMultiple Hubs\n=============\n\nOf course, hubs can in turn send to each other, again in a trustless\nmanner; multiple hops could act as a onion-style privacy scheme. The\nmicropayments could also use an additional chaum token layer for\nprivacy, although note that the k-anonymity set involves a trade-off\nbetween privacy and total # of Bitcoins that could be stolen by the hub.\n\nOf course, in general the micropayment hub breaks the linkage between\npayor and payee, with respect to the data available from the blockchain.\n\n\nCapital Requirements\n====================\n\nA business disadvantage with a hub-and-spoke system is that it ties up\ncapital, creating a tradeoff between fees saved and Bitcoins tied up.\nHow exactly to handle this is a business decision - for instance opening\nthe micropayment channel could involve a small initial payment to\naccount fo rthe time-value-of-money.\n\n\nEmbedded consensus/Colored coins\n================================\n\nNote how many embedded consensus schemes like colored coins are\ncompatible with micropayment channels. (though have fun figuring out who\ndeserves the dividends!)\n\n-- \n'peter'[:-1]@petertodd.org\n000000000000000012367d385ad11358a4a1eee86cf8ebe06a76add36dfb4622\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141213/0bc51275/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Near-zero fee transactions with hub-and-spoke micropayments",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Peter Todd"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3842
        }
    },
    {
        "title": "[Bitcoin-development] Recent EvalScript() changes mean CHECKLOCKTIMEVERIFY can't be merged",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2014-12-15T12:47:30",
                "message_text_only": "BtcDrak was working on rebasing my CHECKLOCKTIMEVERIFY\u00b9 patch to master a few\ndays ago and found a fairly large design change that makes merging it currently\nimpossible. Pull-req #4890\u00b2, specifically commit c7829ea7, changed the\nEvalScript() function to take an abstract SignatureChecker object, removing the\ntxTo and nIn arguments that used to contain the transaction the script was in\nand the txin # respectively. CHECKLOCKTIMEVERIFY needs txTo to obtain the\nnLockTime field of the transaction, and it needs nIn to obtain the nSequence of\nthe txin.\n\nWe need to fix this if CHECKLOCKTIMEVERIFY is to be merged.\n\nSecondly, that this change was made, and the manner in which is was made, is I\nthink indicative of a development process that has been taking significant\nrisks with regard to refactoring the consensus critical codebase. I know I\npersonally have had a hard time keeping up with the very large volume of code\nbeing moved and changed for the v0.10 release, and I know BtcDrak - who is\nkeeping Viacoin up to date with v0.10 - has also had a hard time giving the\nchanges reasonable review. The #4890 pull-req in question had no ACKs at all,\nand only two untested utACKS, which I find worrying for something that made\nsignificant consensus critical code changes.\n\nWhile it would be nice to have a library encapsulating the consensus code, this\nshouldn't come at the cost of safety, especially when the actual users of that\nlibrary or their needs is still uncertain. This is after all a multi-billion\nproject where a simple fork will cost miners alone tens of thousands of dollars\nan hour; easily much more if it results in users being defrauded. That's also\nnot taking into account the significant negative PR impact and loss of trust. I\npersonally would recommend *not* upgrading to v0.10 due to these issues.\n\nA much safer approach would be to keep the code changes required for a\nconsensus library to only simple movements of code for this release, accept\nthat the interface to that library won't be ideal, and wait until we have\nfeedback from multiple opensource projects with publicly evaluatable code on\nwhere to go next with the API.\n\n1) https://github.com/bitcoin/bips/blob/master/bip-0065.mediawiki\n2) https://github.com/bitcoin/bitcoin/pull/4890\n\n-- \n'peter'[:-1]@petertodd.org\n00000000000000001b18a596ecadd07c0e49620fb71b16f9e41131df9fc52fa6\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/c0b5116e/attachment.sig>"
            },
            {
                "author": "Btc Drak",
                "date": "2014-12-15T14:57:07",
                "message_text_only": "This is a pretty good example about refactoring discipline as well as\npremature/over optimisation.\n\nWe all want to see more modular code, but the first steps should just be to\nrelocate blocks of code so everything is more logically organised in\nsmaller files (especially for consensus critical code). Refactoring should\ncome in a second wave preferably after a stable release. Refactoring should\nbe in the pure sense, optimising code with absolutely no change in\nbehaviour.\n\nWhen it comes to actual API changes, I think we need to be a lot more\ncareful and should be considered feature requests and get a lot more\nscrutiny as we are essentially breaking backwards compatibility. #4890 was\npretty much merged with no discussion or thought yet other really simple\nand uncontroversial PRs remain unmerged for months. A key question in the\ncase of EvalScript() would have been, \"why are we passing txTo and nIn\nhere, and are there any future use cases that might require them? Why\nshould this be removed from the API and the entire method signature\nchanged?\". BC breaks always need strong justification.\n\nSo I've expressed my concern a few times about the speed and frequency of\nrefactoring and also the way it's being done. I am not alone, as others not\ndirectly connected with the Bitcoin Core project have also expressed\nconcerns about the number of refactorings \"for the sake of refactoring\",\nespecially of consensus critical code. Careful as we may be, we know from\nhistory that small edge case bugs can creep in very easily and cause a lot\nof unforeseen problems.\n\nBtcDrak\n\n\nOn Mon, Dec 15, 2014 at 12:47 PM, Peter Todd <pete at petertodd.org> wrote:\n>\n> BtcDrak was working on rebasing my CHECKLOCKTIMEVERIFY\u00b9 patch to master a\n> few\n> days ago and found a fairly large design change that makes merging it\n> currently\n> impossible. Pull-req #4890\u00b2, specifically commit c7829ea7, changed the\n> EvalScript() function to take an abstract SignatureChecker object,\n> removing the\n> txTo and nIn arguments that used to contain the transaction the script was\n> in\n> and the txin # respectively. CHECKLOCKTIMEVERIFY needs txTo to obtain the\n> nLockTime field of the transaction, and it needs nIn to obtain the\n> nSequence of\n> the txin.\n>\n> We need to fix this if CHECKLOCKTIMEVERIFY is to be merged.\n>\n> Secondly, that this change was made, and the manner in which is was made,\n> is I\n> think indicative of a development process that has been taking significant\n> risks with regard to refactoring the consensus critical codebase. I know I\n> personally have had a hard time keeping up with the very large volume of\n> code\n> being moved and changed for the v0.10 release, and I know BtcDrak - who is\n> keeping Viacoin up to date with v0.10 - has also had a hard time giving the\n> changes reasonable review. The #4890 pull-req in question had no ACKs at\n> all,\n> and only two untested utACKS, which I find worrying for something that made\n> significant consensus critical code changes.\n>\n> While it would be nice to have a library encapsulating the consensus code,\n> this\n> shouldn't come at the cost of safety, especially when the actual users of\n> that\n> library or their needs is still uncertain. This is after all a\n> multi-billion\n> project where a simple fork will cost miners alone tens of thousands of\n> dollars\n> an hour; easily much more if it results in users being defrauded. That's\n> also\n> not taking into account the significant negative PR impact and loss of\n> trust. I\n> personally would recommend *not* upgrading to v0.10 due to these issues.\n>\n> A much safer approach would be to keep the code changes required for a\n> consensus library to only simple movements of code for this release, accept\n> that the interface to that library won't be ideal, and wait until we have\n> feedback from multiple opensource projects with publicly evaluatable code\n> on\n> where to go next with the API.\n>\n> 1) https://github.com/bitcoin/bips/blob/master/bip-0065.mediawiki\n> 2) https://github.com/bitcoin/bitcoin/pull/4890\n>\n> --\n> 'peter'[:-1]@petertodd.org\n> 00000000000000001b18a596ecadd07c0e49620fb71b16f9e41131df9fc52fa6\n>\n>\n> ------------------------------------------------------------------------------\n> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n> from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n> with Interactivity, Sharing, Native Excel Exports, App Integration & more\n> Get technology previously reserved for billion-dollar corporations, FREE\n>\n> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n> _______________________________________________\n> Bitcoin-development mailing list\n> Bitcoin-development at lists.sourceforge.net\n> https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/d2a843f5/attachment.html>"
            },
            {
                "author": "Jeff Garzik",
                "date": "2014-12-15T15:20:47",
                "message_text_only": "On Mon, Dec 15, 2014 at 9:57 AM, Btc Drak <btcdrak at gmail.com> wrote:\n\n> We all want to see more modular code, but the first steps should just be\n> to relocate blocks of code so everything is more logically organised in\n> smaller files (especially for consensus critical code). Refactoring should\n> come in a second wave preferably after a stable release.\n>\n\nThis is my opinion as well.  In the Linux kernel, we often were faced with\na situation where you have a One Big File driver with > 1MB of source\ncode.  The first step was -always- raw code movement, a brain-dead breaking\nup of code into logical source code files.\n\nRefactoring of data structures comes after that.\n\nWhile not always money-critical, these drivers Had To Keep Working.  We had\nseveral situations where we had active users, but zero hardware access for\ndebugging, and zero access to the vendor knowledge (hardware documentation,\nengineers).  Failure was not an option.  ;p\n\nPerforming the dumb Break Up Files step first means that future, more\ninvasive data structures are easier to review, logically segregated, and\nnot obscured by further code movement changes down the line.  In code such\nas Bitcoin Core, it is important to think about the _patch stream_ and how\nto optimize for reviewer bandwidth.\n\nThe current stream of refactoring is really a turn-off in terms of\nreviewing, sapping reviewer bandwidth by IMO being reviewer-unfriendly.  It\nis a seemingly never-ending series of tiny\nrefactor-and-then-stuff-in-a-class-and-make-it-pretty-and-do-all-the-work.\nSome change is in order, gentlemen.\n\n-- \nJeff Garzik\nBitcoin core developer and open source evangelist\nBitPay, Inc.      https://bitpay.com/\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/fa588b20/attachment.html>"
            },
            {
                "author": "Cory Fields",
                "date": "2014-12-15T18:42:27",
                "message_text_only": "On Mon, Dec 15, 2014 at 10:20 AM, Jeff Garzik <jgarzik at bitpay.com> wrote:\n> On Mon, Dec 15, 2014 at 9:57 AM, Btc Drak <btcdrak at gmail.com> wrote:\n>>\n>> We all want to see more modular code, but the first steps should just be\n>> to relocate blocks of code so everything is more logically organised in\n>> smaller files (especially for consensus critical code). Refactoring should\n>> come in a second wave preferably after a stable release.\n>\n>\n> This is my opinion as well.  In the Linux kernel, we often were faced with a\n> situation where you have a One Big File driver with > 1MB of source code.\n> The first step was -always- raw code movement, a brain-dead breaking up of\n> code into logical source code files.\n>\n> Refactoring of data structures comes after that.\n>\n> While not always money-critical, these drivers Had To Keep Working.  We had\n> several situations where we had active users, but zero hardware access for\n> debugging, and zero access to the vendor knowledge (hardware documentation,\n> engineers).  Failure was not an option.  ;p\n>\n> Performing the dumb Break Up Files step first means that future, more\n> invasive data structures are easier to review, logically segregated, and not\n> obscured by further code movement changes down the line.  In code such as\n> Bitcoin Core, it is important to think about the _patch stream_ and how to\n> optimize for reviewer bandwidth.\n>\n> The current stream of refactoring is really a turn-off in terms of\n> reviewing, sapping reviewer bandwidth by IMO being reviewer-unfriendly.  It\n> is a seemingly never-ending series of tiny\n> refactor-and-then-stuff-in-a-class-and-make-it-pretty-and-do-all-the-work.\n> Some change is in order, gentlemen.\n>\n> --\n> Jeff Garzik\n> Bitcoin core developer and open source evangelist\n> BitPay, Inc.      https://bitpay.com/\n\nThat's exactly what happened during the modularization process, with\nthe exception that the code movement and refactors happened in\nparallel rather than in series. But they _were_ done in separate\nlogical chunks for the sake of easier review. The commit tag\n\"MOVEONLY\" developed organically out of this process, and a grep of\nthe 0.10 branch for \"MOVEONLY\" is a testament to exactly how much code\nmoved 1:1 out of huge files and into logically separated places and/or\nnew files.\n\nPerhaps it's worth making \"MOVEONLY\" (which as the name implies, means\nthat code has been copied 1:1 to a new location) use an official dev\nguideline for use in future refactors.\n\nCory"
            },
            {
                "author": "Jeff Garzik",
                "date": "2014-12-15T19:35:00",
                "message_text_only": "On Mon, Dec 15, 2014 at 1:42 PM, Cory Fields <lists at coryfields.com> wrote:\n\n> That's exactly what happened during the modularization process, with\n> the exception that the code movement and refactors happened in\n> parallel rather than in series. But they _were_ done in separate\n> logical chunks for the sake of easier review.\n>\n\n\"That's exactly what was done except it wasn't\"\n\nYes, in micro, at the pull request level, this happened\n* Code movement\n* Refactor\n\nAt a macro level, that cycle was repeated many times, leading to the\nopposite end result:  a lot of tiny movement/refactor/movement/refactor\nproducing the review and patch annoyances described.\n\nIt produces a blizzard of new files and new data structures, breaking a\nbunch of out-of-tree patches, complicating review quite a bit.  If the vast\nmajority of code movement is up front, followed by algebraic\nsimplifications, followed by data structure work, further patches are easy\nto review/apply with less impact on unrelated code.\n\nThe flow of patches into the tree over time should be examined.  Simply\ntagging patches as movement-only does not address the described problem at\nall.\n\n-- \nJeff Garzik\nBitcoin core developer and open source evangelist\nBitPay, Inc.      https://bitpay.com/\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/e2cb4696/attachment.html>"
            },
            {
                "author": "Cory Fields",
                "date": "2014-12-15T21:19:16",
                "message_text_only": "On Mon, Dec 15, 2014 at 2:35 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:\n> On Mon, Dec 15, 2014 at 1:42 PM, Cory Fields <lists at coryfields.com> wrote:\n>>\n>> That's exactly what happened during the modularization process, with\n>> the exception that the code movement and refactors happened in\n>> parallel rather than in series. But they _were_ done in separate\n>> logical chunks for the sake of easier review.\n>\n>\n> \"That's exactly what was done except it wasn't\"\n>\n> Yes, in micro, at the pull request level, this happened\n> * Code movement\n> * Refactor\n>\n> At a macro level, that cycle was repeated many times, leading to the\n> opposite end result:  a lot of tiny movement/refactor/movement/refactor\n> producing the review and patch annoyances described.\n>\n> It produces a blizzard of new files and new data structures, breaking a\n> bunch of out-of-tree patches, complicating review quite a bit.  If the vast\n> majority of code movement is up front, followed by algebraic\n> simplifications, followed by data structure work, further patches are easy\n> to review/apply with less impact on unrelated code.\n>\n\nI won't argue that at all because it's perfectly logical, but in\npractice that doesn't translate from the macro level to the micro\nlevel very well. At the micro level, minor code changes are almost\nalways needed to accommodate useful code movement. Even if they're not\nrequired, it's often hard to justify code movement for the sake of\ncode movement with the promise that it will be useful later.\n\nRather than arguing hypotheticals, let's use a real example:\nhttps://github.com/bitcoin/bitcoin/pull/5118 . That one's pretty\nsimple. The point of the PR was to unchain our openssl wrapper so that\nkey operations could be performed by the consensus lib without\ndragging in bitcoind's structures. The first commit severs the\ndependencies. The second commit does the code movement from the\nnow-freed wrapper.\n\nI'm having a hard time coming up with a workflow that would handle\nthese two changes as _separate_ events, while making review easier.\nNote that I'm not attempting to argue with you here, rather I'm\ngenuinely curious as to how you'd rather see this specific example\n(which is representative of most of my other code movement for the\nlibbitcoinconsensus work, i believe) handled.\n\nUsing your model above, I suppose we'd do the code movement first with\nthe dependencies still intact as a pull request. At some later date,\nwe'd sever the dependencies in the new files. I suppose you'd also\nprefer that I group a bunch of code-movement changes together into a\nsingle PR which needs little scrutiny, only verification that it's\nmove-only. Once the code-movement PRs are merged, I can begin the\ncleanups which actually fix something.\n\nIn practice, though, that'd be a massive headache for different\nreasons. Lots in flux with seemingly no benefits until some later\ndate. My PR's can't depend on eachother because they don't actually\nfix issues in a linear fashion. That means that other devs can't\ndepend on my PRs either for the same reason. And what have we gained?\n\nDo you find that assessment unreasonable?\n\nCory"
            },
            {
                "author": "Btc Drak",
                "date": "2014-12-15T21:57:27",
                "message_text_only": "On Mon, Dec 15, 2014 at 7:35 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:\n>\n> At a macro level, that cycle was repeated many times, leading to the\n> opposite end result:  a lot of tiny movement/refactor/movement/refactor\n> producing the review and patch annoyances described.\n>\n> It produces a blizzard of new files and new data structures, breaking a\n> bunch of out-of-tree patches, complicating review quite a bit.  If the vast\n> majority of code movement is up front, followed by algebraic\n> simplifications, followed by data structure work, further patches are easy\n> to review/apply with less impact on unrelated code.\n>\n> The flow of patches into the tree over time should be examined.  Simply\n> tagging patches as movement-only does not address the described problem at\n> all.\n>\n\nI think we can all agree that if the process is made more friendly for\nreviewers, everyone wins. It's been hard to even know where everything is\nbecause it moves so often. e.g. In the last couple weeks stuff moved from\ncore.h to core/block.h to primitive/block.h or something to that effect.\nAnyway, Jeff said this quite elegantly.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/7cf75389/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2014-12-15T17:38:57",
                "message_text_only": "On Mon, Dec 15, 2014 at 12:47 PM, Peter Todd <pete at petertodd.org> wrote:\n[snip]\n> Pull-req #4890\u00b2, specifically commit c7829ea7, changed the\n\nThis change was authored more than three months ago and merged more\nthan two months ago.\n[And also, AFAICT, prior to you authoring BIP65]\n\nI didn't participate in that pull-req, though I saw it... it had five\nother contributors working on it and I try to have minimal opinions on\ncode organization and formatting.\n\nBut the idea sounded (and still sounds) reasonable to me.  Of course,\nanything could still be backed out if it turned out to be ill-advised\n(even post 0.10, as I think now we've had months of testing with this\ncode in place and removing it may be more risky)... but your comments\nhere are really not timely.\nEveryone has limited resources, which is understandable, but the\nconcerns you are here are ones that didn't involve looking at the code\nto raise, and would have been better process wise raised earlier.\n\n> We need to fix this if CHECKLOCKTIMEVERIFY is to be merged.\n\nI don't see why you conclude this. Rather than violating the layering\nby re-parsing the transaction as the lower level, just make this data\nadditional information that is needed available.\nYes, does mean that rebasing an altcoin that made modifications here\nwill take more effort and understanding of the code than a purely\nmechanical change.\n\n> Secondly, that this change was made, and the manner in which is was made, is I\n> think indicative of a development process that has been taking significant\n> risks with regard to refactoring the consensus critical codebase.\n\nI don't agree. The character of this change is fairly narrow. We have\nmoderately good test coverage here, and there were five participants\non the PR.\n\n> While it would be nice to have a library encapsulating the consensus code, this\n> shouldn't come at the cost of safety, especially when the actual users of that\n\nThis is all true stuff, but the fact of it doesn't follow that any\nparticular change was especially risky.\n\nBeyond the general 'things were changed in a way that made rebasing\nan-altcoin take more work' do you have a specific concern here?\n\nOther than travling back in time three months and doing something\ndifferently, do you have any suggestions to ameliorate that concern?\nE.g. are their additional tests we don't already have that you think\nwould increase your confidence with respect to specific safety\nconcerns?\n\n> A much safer approach would be to keep the code changes required for a\n> consensus library to only simple movements of code for this release, accept\n> that the interface to that library won't be ideal, and wait until we have\n> feedback from multiple opensource projects with publicly evaluatable code on\n> where to go next with the API.\n\nThere won't be any public users of the library until there can\nactually _be_ a library.\n\nPR4890's primary objective was disentangling the script validation\nfrom the node state introduced by the the signature caching changes a\ncouple years ago, making it possible to build the consensus components\nwithout application specific threading logic... and makes it possible\nto have a plain script evaluator call without having to replicate all\nof bitcoind's threading, signature cache, etc. logic.  Without a\nchange like this you can't invoke the script engine without having a\nmuch larger chunk of bitcoind running.\n\n0.10 is a major release, not a maintenance release. It's specifically\nin major releases that we make changes which are not purely code\nmotion and narrow bugfixes (Though many of the changes in 0.10 were\nnicely factored into verify pure code motion changes from behavioral\nchanges). There are many very important, even critical, behavioural\nchanges in 0.10.  That these changes have their own risks are part of\nwhy they aren't in 0.9.x."
            },
            {
                "author": "Wladimir",
                "date": "2014-12-15T17:46:41",
                "message_text_only": "> While it would be nice to have a library encapsulating the consensus code, this\n> shouldn't come at the cost of safety, especially when the actual users of that\n> library or their needs is still uncertain.\n\nWhile I agree that it shouldn't come at unreasonable risk, my whole\nreason for prioritizing the consensus library is that it is the first\nstep toward the goal of isolating the consensus code completely. As\nsoon as it exists in a repository by itself, it is easier to enforce a\ndifferent regime of change control there, or even freeze it completely\nover time. To keep track of consensus changes one'd only have to\nfollow that repository, instead of filter it between tons of GUI, RPC\nor utility commits.\n\nIMO having the consensus isolated into a portable self-contained\nlibrary is the most important goal of Bitcoin Core project at this\npoint. I've tried to keep the amount of unnecessary refactoring down,\nbut some is unfortunately unavoidable.\n\nI'm sure we can find a way to rebase CHECKLOCKTIMEVERIFY so that it\ncan land in 0.11.\n\nWladimir"
            },
            {
                "author": "Pieter Wuille",
                "date": "2014-12-15T18:10:08",
                "message_text_only": "On Mon, Dec 15, 2014 at 1:47 PM, Peter Todd <pete at petertodd.org> wrote:\n\n> BtcDrak was working on rebasing my CHECKLOCKTIMEVERIFY\u00b9 patch to master a few\n> days ago and found a fairly large design change that makes merging it currently\n> impossible. Pull-req #4890\u00b2, specifically commit c7829ea7, changed the\n> EvalScript() function to take an abstract SignatureChecker object, removing the\n> txTo and nIn arguments that used to contain the transaction the script was in\n> and the txin # respectively. CHECKLOCKTIMEVERIFY needs txTo to obtain the\n> nLockTime field of the transaction, and it needs nIn to obtain the nSequence of\n> the txin.\n\nI agree, and I was thinking earlier that some rebasing would be needed\nfor CLTV when the change was made. I think this is a good thing\nthough: #4890 introduced a clear separation between the script\nevaluation code and what it can access out of its environment (the\ntransaction being verified). As CLTV changes the amount available out\nof the environment, this indeed requires changing the interface.\n\n> We need to fix this if CHECKLOCKTIMEVERIFY is to be merged.\n\nDone. See https://github.com/sipa/bitcoin/commit/cltv2 for a rebased\nversion of the BIP65 code on top of 0.10 and master. I haven't ported\nany tests you may have that are not in the BIP, to avoid doing double\nwork. Those should apply cleanly. There is a less clean version (IMHO)\nwith smaller code changes wrt to the BIP code in my 'cltv' branch too.\n\n> Secondly, that this change was made, and the manner in which is was made, is I\n> think indicative of a development process that has been taking significant\n> risks with regard to refactoring the consensus critical codebase.\n\nI fully agree that we shouldn't be taking unnecessary risks when\nchanging consensus code. For example, I closed #5091 (which I would\nvery much have liked as a code improvement) when realizing the risks.\nThat said, I don't believe we are at a point where we can just freeze\nanything that touches consensus-related, and sometimes refactorings\nare necessary. In particular, #4890 introduced separation between a\nvery fundamental part of consensus logic (script logic) and an\noptional optimization for it (caching). If we ever want to get to a\nseparate consensus code tree or repository, possibly with more strict\nreviews, I think changes like this are inevitable.\n\n> I know I\n> personally have had a hard time keeping up with the very large volume of code\n> being moved and changed for the v0.10 release, and I know BtcDrak - who is\n> keeping Viacoin up to date with v0.10 - has also had a hard time giving the\n> changes reasonable review. The #4890 pull-req in question had no ACKs at all,\n> and only two untested utACKS, which I find worrying for something that made\n> significant consensus critical code changes.\n\nI'm sorry to hear that that, and I do understand that many code\nmovements make this harder. If this is a concern shared by many\npeople, we can always decide to roll back some refactorings in the\n0.10 branch. On the other hand, we don't even have release candidates\nyet (which are a pretty important part of the testing and reviewing\nprocess), and doing so would delay things further. 0.10 has many very\nsignificant improvements which are beneficial to the network too,\nwhich I'm sure you're aware of.\n\nIt's perfectly reasonable that not everyone has the same bandwidth\navailable to keep up with changes, and perhaps that means slowing\nthings down. Again, I don't want to say \"this was reviewed before, we\ncan't go back to this\" - but did you really need 3 months to realize\nthis change? I also see that elsewhere you're complaining about #5421\nof yours which hasn't made it in yet - after less than 2 weeks. Yes, I\nlike the change, and I will review it. Surely you are not arguing it\ncan be merged without decent review?\n\n> While it would be nice to have a library encapsulating the consensus code, this\n> shouldn't come at the cost of safety, especially when the actual users of that\n> library or their needs is still uncertain. This is after all a multi-billion\n> project where a simple fork will cost miners alone tens of thousands of dollars\n> an hour; easily much more if it results in users being defrauded. That's also\n> not taking into account the significant negative PR impact and loss of trust. I\n> personally would recommend *not* upgrading to v0.10 due to these issues.\n\nI have been very much in favor of a libconsensus library, and for\nseveral reasons. It's a step towards separating out the\nconsensus-critical parts from optional pieces of the codebase, and it\nis a step towards avoiding the \"reimplementing consensus code is very\ndangerous! ... but we really don't have a way to allow you to reuse\nthe existing code either\" argument. It does not fully accomplish\neither of those goals, but gradual steps with time to let changes\nmature in between are nice.\n\n> A much safer approach would be to keep the code changes required for a\n> consensus library to only simple movements of code for this release, accept\n> that the interface to that library won't be ideal, and wait until we have\n> feedback from multiple opensource projects with publicly evaluatable code on\n> where to go next with the API.\n\nIf at this point the consensus code was nicely separated, I would\nargue to *copy* it (despite all normal engineering practices that\nargue against code duplication), into a frozen separate directory or\neven repository, and have all validation related code use the\nconsensus version, while everything else can use a normal tree\nversion, which then can evolve at a normal pace, and undergo cleanups,\nAPI changes and feature improvements along with the rest of the code.\n\nUnfortunately, it is not. The consensus code is mixed all over the\nplace, and this forces unnecessary strain on all development of the\ncodebase. I hope people agree that getting to a point where this is no\nlonger the case is important.\n\n-- \nPieter"
            },
            {
                "author": "Cory Fields",
                "date": "2014-12-15T18:35:11",
                "message_text_only": "On Mon, Dec 15, 2014 at 7:47 AM, Peter Todd <pete at petertodd.org> wrote:\n> BtcDrak was working on rebasing my CHECKLOCKTIMEVERIFY\u00b9 patch to master a few\n> days ago and found a fairly large design change that makes merging it currently\n> impossible. Pull-req #4890\u00b2, specifically commit c7829ea7, changed the\n> EvalScript() function to take an abstract SignatureChecker object, removing the\n> txTo and nIn arguments that used to contain the transaction the script was in\n> and the txin # respectively. CHECKLOCKTIMEVERIFY needs txTo to obtain the\n> nLockTime field of the transaction, and it needs nIn to obtain the nSequence of\n> the txin.\n>\n> We need to fix this if CHECKLOCKTIMEVERIFY is to be merged.\n>\n> Secondly, that this change was made, and the manner in which is was made, is I\n> think indicative of a development process that has been taking significant\n> risks with regard to refactoring the consensus critical codebase. I know I\n> personally have had a hard time keeping up with the very large volume of code\n> being moved and changed for the v0.10 release, and I know BtcDrak - who is\n> keeping Viacoin up to date with v0.10 - has also had a hard time giving the\n> changes reasonable review. The #4890 pull-req in question had no ACKs at all,\n> and only two untested utACKS, which I find worrying for something that made\n> significant consensus critical code changes.\n>\n> While it would be nice to have a library encapsulating the consensus code, this\n> shouldn't come at the cost of safety, especially when the actual users of that\n> library or their needs is still uncertain. This is after all a multi-billion\n> project where a simple fork will cost miners alone tens of thousands of dollars\n> an hour; easily much more if it results in users being defrauded. That's also\n> not taking into account the significant negative PR impact and loss of trust. I\n> personally would recommend *not* upgrading to v0.10 due to these issues.\n>\n> A much safer approach would be to keep the code changes required for a\n> consensus library to only simple movements of code for this release, accept\n> that the interface to that library won't be ideal, and wait until we have\n> feedback from multiple opensource projects with publicly evaluatable code on\n> where to go next with the API.\n>\n> 1) https://github.com/bitcoin/bips/blob/master/bip-0065.mediawiki\n> 2) https://github.com/bitcoin/bitcoin/pull/4890\n>\n> --\n> 'peter'[:-1]@petertodd.org\n> 00000000000000001b18a596ecadd07c0e49620fb71b16f9e41131df9fc52fa6\n\nIt would appear as though you're trying to drum up controversy here,\nbut the argument is quite a stretch, and contrary to some other\narguments you're making in parallel. There seem to be three themes in\nyour above complaint, so I'd like to address them individually.\n\n1. Pr #4890 specifically. The argument seems to be that this was not\nproperly reviewed/tested, and that it is an unnecessary risk to the\nconsensus codebase.\n\nLooking at the PR at github, while I certainly don't agree with those\nconclusions, I suppose I can understand where they're coming from.\nThere's plenty of context missing, as well as sidebar discussions on\nIRC and other PRs. To an outside observer, these changes may look\nunder-tested and unnecessary.\n\nThe context that's missing is the flurry of work that was going on in\nparallel to modularize this (and surrounding code). #4890 was one of\nthe first pieces necessary for that, so some of the discussion about\nit was happening in dependent pull requests.\n\nYou can point to a lack ACKs in one place for that PR, but that\ndoesn't mean that the changes weren't tested/reviewed/necessary. You\ncould also argue that ACKs should've been mirrored on the PR in\nquestion for posterity, which would be a perfectly reasonable argument\nthat I would agree with.\n\n\n2. These changes conflict with a rebased version of your\nCHECKLOCKTIMEVERIFY changes. OK? You have a tree that's a few months\nold, and you find that you have conflicts when rebasing to master. It\nhappens to all of us. Do as the rest of us do and update your changes\nto fit. If you missed the review of #4890 and think it should be\nreverted, then call for a revert. But please give a concrete reason\nother than \"I've picked this commit series for a crusade because it\ngave me merge conflicts\".\n\nWhat is the conspiracy here? There's a signature cache that is\nimplementation-specific, and in a parallel universe, you might be\narguing that we should rip it out because it adds unnecessary\ncomplexity to the consensus code. The PR provides a path around that\ncomplexity. For some reason, your reaction is to cry foul months later\nbecause you missed reviewing it at the time, rather than cheering for\nthe reduced complexity.\n\n3. You seem to think that 1. and 2. seem to point to a systemic\nfailure of the review process because modularization \"shouldn't come\nat the cost of safety\". I agree that it shouldn't come at the cost of\nsafety, but I see no failure here. There has been a HUGE effort to\nmodularize the code with a combination of pure-code-movement and small\ninterface reworks. Please take a moment to grep the git logs for\n\"MOVEONLY\" in the 0.10 branch.\n\nYou'll notice that script verification is now 100% free of bitcoind\nstate, threading, and third-party libraries (other than openssl for\nnow). That constitutes a massive reduction in code complexity, future\nreview overhead, etc. I'll point out here that those were my reasons\nfor my contributions to the libbitcoinconsensus effort. I have no\ninterest in altcoins or sidechains.\n\nThose milestones were thanks to an effort which included #4890. If you\nhave issues with these changes and/or how they were made, please call\nout individual failures and proposed solutions _in context_. That they\nconflict with CHECKLOCKTIMEVERIFY may be a valid concern, and it may\nbe worth evaluating how separate coding efforts may more effectively\nparallelized.\n\nWithout pointers to specific failures or solutions, I'm not sure what\nyou were trying to communicate here, other than maybe stirring the\nsocial networks with: \"I\npersonally would recommend *not* upgrading to v0.10 due to these\nissues.\" That's fine I suppose, but it does nothing to solve whatever\nissue you're trying to call out here.\n\nCory"
            },
            {
                "author": "Jeff Garzik",
                "date": "2014-12-15T21:54:20",
                "message_text_only": "If code movement is not compressed into a tight time window, code movement\nbecomes a constant stream during development.  A constant stream of code\nmovement is a constant stream of patch breakage, for any patch or project\nnot yet in-tree.  The result is to increase the work and cost on any\ncontributor whose patches are not immediately merged.\n\nFor the record, since this is trending reddit, I __do__ support the end\nresult of 0.10 refactoring, the work towards the consensus lib.\n\nMy criticism is of a merge flow which _unintentionally_ rewards only\ncertain types of patches, and creates disincentives for working on other\ntypes of patches.\n\n\n\n\n\n\n\nOn Mon, Dec 15, 2014 at 4:19 PM, Cory Fields <lists at coryfields.com> wrote:\n>\n> On Mon, Dec 15, 2014 at 2:35 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:\n> > On Mon, Dec 15, 2014 at 1:42 PM, Cory Fields <lists at coryfields.com>\n> wrote:\n> >>\n> >> That's exactly what happened during the modularization process, with\n> >> the exception that the code movement and refactors happened in\n> >> parallel rather than in series. But they _were_ done in separate\n> >> logical chunks for the sake of easier review.\n> >\n> >\n> > \"That's exactly what was done except it wasn't\"\n> >\n> > Yes, in micro, at the pull request level, this happened\n> > * Code movement\n> > * Refactor\n> >\n> > At a macro level, that cycle was repeated many times, leading to the\n> > opposite end result:  a lot of tiny movement/refactor/movement/refactor\n> > producing the review and patch annoyances described.\n> >\n> > It produces a blizzard of new files and new data structures, breaking a\n> > bunch of out-of-tree patches, complicating review quite a bit.  If the\n> vast\n> > majority of code movement is up front, followed by algebraic\n> > simplifications, followed by data structure work, further patches are\n> easy\n> > to review/apply with less impact on unrelated code.\n> >\n>\n> I won't argue that at all because it's perfectly logical, but in\n> practice that doesn't translate from the macro level to the micro\n> level very well. At the micro level, minor code changes are almost\n> always needed to accommodate useful code movement. Even if they're not\n> required, it's often hard to justify code movement for the sake of\n> code movement with the promise that it will be useful later.\n>\n> Rather than arguing hypotheticals, let's use a real example:\n> https://github.com/bitcoin/bitcoin/pull/5118 . That one's pretty\n> simple. The point of the PR was to unchain our openssl wrapper so that\n> key operations could be performed by the consensus lib without\n> dragging in bitcoind's structures. The first commit severs the\n> dependencies. The second commit does the code movement from the\n> now-freed wrapper.\n>\n> I'm having a hard time coming up with a workflow that would handle\n> these two changes as _separate_ events, while making review easier.\n> Note that I'm not attempting to argue with you here, rather I'm\n> genuinely curious as to how you'd rather see this specific example\n> (which is representative of most of my other code movement for the\n> libbitcoinconsensus work, i believe) handled.\n>\n> Using your model above, I suppose we'd do the code movement first with\n> the dependencies still intact as a pull request. At some later date,\n> we'd sever the dependencies in the new files. I suppose you'd also\n> prefer that I group a bunch of code-movement changes together into a\n> single PR which needs little scrutiny, only verification that it's\n> move-only. Once the code-movement PRs are merged, I can begin the\n> cleanups which actually fix something.\n>\n> In practice, though, that'd be a massive headache for different\n> reasons. Lots in flux with seemingly no benefits until some later\n> date. My PR's can't depend on eachother because they don't actually\n> fix issues in a linear fashion. That means that other devs can't\n> depend on my PRs either for the same reason. And what have we gained?\n>\n> Do you find that assessment unreasonable?\n>\n> Cory\n>\n\n\n-- \nJeff Garzik\nBitcoin core developer and open source evangelist\nBitPay, Inc.      https://bitpay.com/\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/86432848/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Recent EvalScript() changes mean CHECKLOCKTIMEVERIFY can't be merged",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Jeff Garzik",
                "Wladimir",
                "Peter Todd",
                "Btc Drak",
                "Gregory Maxwell",
                "Pieter Wuille",
                "Cory Fields"
            ],
            "messages_count": 12,
            "total_messages_chars_count": 39122
        }
    },
    {
        "title": "[Bitcoin-development] Open development processes and reddit charms",
        "thread_messages": [
            {
                "author": "Jeff Garzik",
                "date": "2014-12-16T17:59:06",
                "message_text_only": "It can be useful to review open source development processes from time to\ntime.  This reddit thread[1] serves use both as a case study, and also a\nmoment of OSS process introduction for newbies.\n[1]\nhttp://www.reddit.com/r/Bitcoin/comments/2pd0zy/peter_todd_is_saying_shoddy_development_on_v010/\n\n\n\n\n*Dirty Laundry*\nWhen building businesses or commercial software projects, outsiders\ntypically hear little about the internals of project development.  The\npublic only hears what the companies release, which is prepped and\npolished. Internal disagreements, schedule slips, engineer fistfights are\nall unseen.\n\nOpen source development is the opposite.  The goal is radical\ntransparency.  Inevitably there is private chatter (0day bugs etc.), but\nthe default is openness.  This means that is it normal practice to \"air\ndirty laundry in public.\"  Engineers will disagree, sometimes quietly,\nsometimes loudly, sometimes rudely and with ad hominem attacks.  On the\nInternet, there is a pile-on effect, where informed and uninformed\nsupporters add their 0.02 BTC.\n\nCompeting interests cloud the issues further.  Engineers are typically\nemployed by an organization, as a technology matures.  Those organizations\nhave different strategies and motivations.  These organizations will\nsponsor work they find beneficial.  Sometimes those orgs are non-profit\nfoundations, sometimes for-profit corporations.  Sometimes that work is\nmaintenance (\"keep it running\"), sometimes that work is developing new,\ncompetitive features that company feels will give it a better market\nposition.  In a transparent development environment, all parties are\nhyperaware of these competing interests.  Internet natterers painstakingly\ndocument and repeat every conspiracy theory about Bitcoin Foundation,\nBlockstream, BitPay, various altcoin developers, and more as a result of\nthese competing interests.\n\nBitcoin and altcoin development adds an interesting new dimension.\nSometimes engineers have a more direct conflict of interest, in that the\ntechnology they are developing is also potentially their road to instant\n$millions.  Investors, amateur and professional, have direct stakes in a\ncertain coin or coin technology.  Engineers also have an emotional stake in\ntechnology they design and nurture.  This results in incentives where\nsupporters of a non-bitcoin technology work very hard to thump bitcoin.\nAnd vice versa.  Even inside bitcoin, you see \"tree chains vs. side chains\"\nthreads of a similar stripe.  This can lead to a very skewed debate.\n\nThat should not distract from the engineering discussion.  Starting from\nfirst principles, Assume Good Faith[2].  Most engineers in open source tend\nto mean what they say.  Typically they speak for themselves first, and\ntheir employers value that engineer's freedom of opinion.  Pay attention to\nthe engineers actually working on the technology, and less attention to the\nnoise bubbling around the Internet like the kindergarten game of grapevine.\n[2] http://en.wikipedia.org/wiki/Wikipedia:Assume_good_faith\n\nBeing open and transparent means engineering disagreements happen in\npublic.  This is normal.  Open source engineers live an aquarium life[3].\n[3] https://www.youtube.com/watch?v=QKe-aO44R7k\n\n\n\n\n*What the fork?*\nIn this case, a tweet suggests consensus bug risks, which reddit account\n\"treeorsidechains\" hyperbolizes into a dramatic headline[1].  However, the\nheadline would seem to be the opposite of the truth.  Several changes were\nmerged during 0.10 development which move snippets of source code into new\nfiles and new sub-directories.  The general direction of this work is\ncreating a \"libconsensus\" library that carefully encapsulates consensus\ncode in a manner usable by external projects.  This is a good thing.\n\nThe development was performed quite responsible:  Multiple developers would\nverify each cosmetic change, ensuring no behavior changes had been\naccidentally (or maliciously!) introduced.  Each pull request receives a\nfull multi-platform build + automated testing, over and above individual\ndev testing.  Comparisons at the assembly language level were sometimes\nmade in critical areas, to ensure zero before-and-after change.  Each\ntransformation gets the Bitcoin Core codebase to a more sustainable, more\nreusable state.\n\nCertainly zero-change is the most conservative approach. Strictly speaking,\nthat has the lowest consensus risk.  But that is a short term mentality.\nBoth Bitcoin Core and the larger ecosystem will benefit when the \"hairball\"\npile of source code is cleaned up.  Progress has been made on that front in\nthe past 2 years, and continues.   *Long term*, combined with the\n\"libconsensus\" work, that leads to less community-wide risk.\n\nThe key is balance.  Continue software engineering practices -- like those\njust mentioned above -- that enable change with least consensus risk.  Part\nof those practices is review at each step of the development process:\nsocial media thought bubble, mailing list post, pull request, git merge,\npre-release & release.  It probably seems chaotic at times.  In effect,\ngit[hub] and the Internet enable a dynamic system of review and feedback,\nwhere each stage provides a check-and-balance for bad ideas and bad\nsoftware changes.  It's a human process, designed to acknowledge and handle\nthat human engineers are fallible and might make mistakes (or be\ncoerced/under duress!).  History and field experience will be the ultimate\njudge, but I think Bitcoin Core is doing good on this score, all things\nconsidered.\n\nAt the end of the day, while no change is without risk, version 0.10 work\nwas done with attention to consensus risk at multiple levels (not just\nshort term).\n\n\n\n\n*Technical and social debt*\nWorking on the Linux kernel was an interesting experience that combined\ngit-driven parallel development and a similar source code hairball.  One of\nthe things that quickly became apparent is that cosmetic patches,\nespecially code movement, was hugely disruptive.  Some even termed it\nanti-social.  To understand why, it is important to consider how modern\nsoftware changes are developed:\n\nDevelopers work in parallel on their personal computers to develop XYZ\nchange, then submit their change \"upstream\" as a github pull request.  Then\ntime passes.  If code movement and refactoring changes are accepted\nupstream before XYZ, then the developer is forced update XYZ -- typically\ntrivial fixes, re-review XYZ, and re-test XYZ to ensure it remains in a\nknown-working state.\n\nSeemingly cosmetic changes such as code movement have a ripple effect on\nparticipating developers, and wider developer community.  Every developer\nwho is *not* immediately merged upstream must bear the costs of updating\ntheir unmerged work.\n\nNormally, this is expected.  Encouraging developers to build on top of\n\"upstream\" produces virtuous cycles.\n\nHowever, a constant stream of code movement and cosmetic changes may\nproduce a constant stream of disruption to developers working on\nnon-trivial features that take a bit longer to develop before going\nupstream.  Trivial changes are encouraged, and non-trivial changes face a\nbinary choice of (a) be merged immediately or (b) bear added re-base,\nre-view, re-test costs.\n\nTaken over a timescale of months, I argue that a steady stream of cosmetic\ncode movement changes serves as a disincentive to developers working with\nupstream.  Each upstream breakage has a ripple effect to all developers\ndownstream, and imposes some added chance of newly introduced bugs on\ndownstream developers.  I'll call this \"social debt\", a sort of technical\ndebt[4] for developers.\n[4] http://en.wikipedia.org/wiki/Technical_debt\n\nAs mentioned above, the libconsensus and code movement work is a net gain.\nThe codebase needs cleaning up.  Each change however incurs a little bit of\nsocial debt.  Life is a little bit harder on people trying to get work into\nthe tree.  Developers are a little bit more discouraged at the busy-work\nthey must perform.  Non-trivial pull requests take a little bit longer to\napprove, because they take a little bit more work to rebase (again).\n\nA steady flow of code movement and cosmetic breakage into the tree may be a\nnet gain, but it also incurs a *lot* of social debt.  In such situations,\ndevelopers find that tested, working out-of-tree code repeatedly stops\nworking *during the process of trying to get that work in-tree*.  Taken\nover time, it discourages working on the tree.  It is rational to sit back,\n*not* work on the tree, let the breakage stop, and then pick up the pieces.\n\n\n\n\n*Paradox Unwound*\nBitcoin Core, then, is pulled in opposite directions by a familiar\nproblem.  It is generally agreed that the codebase needs further\nrefactoring.  That's not just isolated engineer nit-picking.  However, for\nnon-trivial projects, refactoring is always anti-social in the short term.\nIt impacts projects other than your own, projects you don't even know\nabout. One change causes work for N developers.  Given these twin opposing\ngoals, the key, as ever, is finding the right balance.\n\nMuch like \"feature freeze\" in other software projects, developing a policy\nthat opens and closes windows for code movement and major disruptive\nchanges seems prudent.  One week of code movement & cosmetics followed by 3\nweeks without, for example.  Part of open source parallel development\nis *social\nsignalling*:  Signal to developers when certain changes are favored or not,\nthen trust they can handle the rest from there.\n\nWhile recent code movement commits themselves are individually ACK-worthy,\nprofessionally executed and moving towards a positive goal, I think the\nproject could strike a better balance when it comes to disruptive cosmetic\nchanges, a balance that better encourages developers to work on more\ninvolved Bitcoin Core projects.\n\n\n-- \nJeff Garzik\nBitcoin core developer and open source evangelist\nBitPay, Inc.      https://bitpay.com/\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/949232b1/attachment.html>"
            },
            {
                "author": "Troy Benjegerdes",
                "date": "2014-12-16T19:24:15",
                "message_text_only": "Thank you Jeff.\n\nHaving looked at a lot of linux code, and now a lot of bitcoin code, the\nbiggest long-term systemic risk I see is that Bitcoin has is the lack of \ncode janitors.\n\nThe problem is that janitoring was *disruptive* for non-x86 linux architectures\nwhen it first got going, and it's going to be very disruptive for bitcoin as\nwell, but it **needs** to happen. \n\nThe code is too complex and hard to follow as it is now. (now, I could just\nbe speaking because I haven't paid the social debt of looking at the latest\nbitcoin code, including libconsensus), but there really needs to be a focus\non readability, maintainability, and (as much as I hate to say it) a rather\nhard-line policy on coding standards.\n\nI don't care which tabbing style or column width you pick, but **pick one**,\nand enforce it across the entire codebase.\n\nMaybe this should be bitcoin-stable, and bitcoin-devel, with a 6-9 month\nsocial expectation of minimal cosmetic changes in -stable, with a 1 month\n'merge window' where -devel turns into -stable.\n\n\nOn Tue, Dec 16, 2014 at 12:59:06PM -0500, Jeff Garzik wrote:\n> It can be useful to review open source development processes from time to\n> time.  This reddit thread[1] serves use both as a case study, and also a\n> moment of OSS process introduction for newbies.\n> [1]\n> http://www.reddit.com/r/Bitcoin/comments/2pd0zy/peter_todd_is_saying_shoddy_development_on_v010/\n> \n> \n> \n> \n> *Dirty Laundry*\n> When building businesses or commercial software projects, outsiders\n> typically hear little about the internals of project development.  The\n> public only hears what the companies release, which is prepped and\n> polished. Internal disagreements, schedule slips, engineer fistfights are\n> all unseen.\n> \n> Open source development is the opposite.  The goal is radical\n> transparency.  Inevitably there is private chatter (0day bugs etc.), but\n> the default is openness.  This means that is it normal practice to \"air\n> dirty laundry in public.\"  Engineers will disagree, sometimes quietly,\n> sometimes loudly, sometimes rudely and with ad hominem attacks.  On the\n> Internet, there is a pile-on effect, where informed and uninformed\n> supporters add their 0.02 BTC.\n> \n> Competing interests cloud the issues further.  Engineers are typically\n> employed by an organization, as a technology matures.  Those organizations\n> have different strategies and motivations.  These organizations will\n> sponsor work they find beneficial.  Sometimes those orgs are non-profit\n> foundations, sometimes for-profit corporations.  Sometimes that work is\n> maintenance (\"keep it running\"), sometimes that work is developing new,\n> competitive features that company feels will give it a better market\n> position.  In a transparent development environment, all parties are\n> hyperaware of these competing interests.  Internet natterers painstakingly\n> document and repeat every conspiracy theory about Bitcoin Foundation,\n> Blockstream, BitPay, various altcoin developers, and more as a result of\n> these competing interests.\n> \n> Bitcoin and altcoin development adds an interesting new dimension.\n> Sometimes engineers have a more direct conflict of interest, in that the\n> technology they are developing is also potentially their road to instant\n> $millions.  Investors, amateur and professional, have direct stakes in a\n> certain coin or coin technology.  Engineers also have an emotional stake in\n> technology they design and nurture.  This results in incentives where\n> supporters of a non-bitcoin technology work very hard to thump bitcoin.\n> And vice versa.  Even inside bitcoin, you see \"tree chains vs. side chains\"\n> threads of a similar stripe.  This can lead to a very skewed debate.\n> \n> That should not distract from the engineering discussion.  Starting from\n> first principles, Assume Good Faith[2].  Most engineers in open source tend\n> to mean what they say.  Typically they speak for themselves first, and\n> their employers value that engineer's freedom of opinion.  Pay attention to\n> the engineers actually working on the technology, and less attention to the\n> noise bubbling around the Internet like the kindergarten game of grapevine.\n> [2] http://en.wikipedia.org/wiki/Wikipedia:Assume_good_faith\n> \n> Being open and transparent means engineering disagreements happen in\n> public.  This is normal.  Open source engineers live an aquarium life[3].\n> [3] https://www.youtube.com/watch?v=QKe-aO44R7k\n> \n> \n> \n> \n> *What the fork?*\n> In this case, a tweet suggests consensus bug risks, which reddit account\n> \"treeorsidechains\" hyperbolizes into a dramatic headline[1].  However, the\n> headline would seem to be the opposite of the truth.  Several changes were\n> merged during 0.10 development which move snippets of source code into new\n> files and new sub-directories.  The general direction of this work is\n> creating a \"libconsensus\" library that carefully encapsulates consensus\n> code in a manner usable by external projects.  This is a good thing.\n> \n> The development was performed quite responsible:  Multiple developers would\n> verify each cosmetic change, ensuring no behavior changes had been\n> accidentally (or maliciously!) introduced.  Each pull request receives a\n> full multi-platform build + automated testing, over and above individual\n> dev testing.  Comparisons at the assembly language level were sometimes\n> made in critical areas, to ensure zero before-and-after change.  Each\n> transformation gets the Bitcoin Core codebase to a more sustainable, more\n> reusable state.\n> \n> Certainly zero-change is the most conservative approach. Strictly speaking,\n> that has the lowest consensus risk.  But that is a short term mentality.\n> Both Bitcoin Core and the larger ecosystem will benefit when the \"hairball\"\n> pile of source code is cleaned up.  Progress has been made on that front in\n> the past 2 years, and continues.   *Long term*, combined with the\n> \"libconsensus\" work, that leads to less community-wide risk.\n> \n> The key is balance.  Continue software engineering practices -- like those\n> just mentioned above -- that enable change with least consensus risk.  Part\n> of those practices is review at each step of the development process:\n> social media thought bubble, mailing list post, pull request, git merge,\n> pre-release & release.  It probably seems chaotic at times.  In effect,\n> git[hub] and the Internet enable a dynamic system of review and feedback,\n> where each stage provides a check-and-balance for bad ideas and bad\n> software changes.  It's a human process, designed to acknowledge and handle\n> that human engineers are fallible and might make mistakes (or be\n> coerced/under duress!).  History and field experience will be the ultimate\n> judge, but I think Bitcoin Core is doing good on this score, all things\n> considered.\n> \n> At the end of the day, while no change is without risk, version 0.10 work\n> was done with attention to consensus risk at multiple levels (not just\n> short term).\n> \n> \n> \n> \n> *Technical and social debt*\n> Working on the Linux kernel was an interesting experience that combined\n> git-driven parallel development and a similar source code hairball.  One of\n> the things that quickly became apparent is that cosmetic patches,\n> especially code movement, was hugely disruptive.  Some even termed it\n> anti-social.  To understand why, it is important to consider how modern\n> software changes are developed:\n> \n> Developers work in parallel on their personal computers to develop XYZ\n> change, then submit their change \"upstream\" as a github pull request.  Then\n> time passes.  If code movement and refactoring changes are accepted\n> upstream before XYZ, then the developer is forced update XYZ -- typically\n> trivial fixes, re-review XYZ, and re-test XYZ to ensure it remains in a\n> known-working state.\n> \n> Seemingly cosmetic changes such as code movement have a ripple effect on\n> participating developers, and wider developer community.  Every developer\n> who is *not* immediately merged upstream must bear the costs of updating\n> their unmerged work.\n> \n> Normally, this is expected.  Encouraging developers to build on top of\n> \"upstream\" produces virtuous cycles.\n> \n> However, a constant stream of code movement and cosmetic changes may\n> produce a constant stream of disruption to developers working on\n> non-trivial features that take a bit longer to develop before going\n> upstream.  Trivial changes are encouraged, and non-trivial changes face a\n> binary choice of (a) be merged immediately or (b) bear added re-base,\n> re-view, re-test costs.\n> \n> Taken over a timescale of months, I argue that a steady stream of cosmetic\n> code movement changes serves as a disincentive to developers working with\n> upstream.  Each upstream breakage has a ripple effect to all developers\n> downstream, and imposes some added chance of newly introduced bugs on\n> downstream developers.  I'll call this \"social debt\", a sort of technical\n> debt[4] for developers.\n> [4] http://en.wikipedia.org/wiki/Technical_debt\n> \n> As mentioned above, the libconsensus and code movement work is a net gain.\n> The codebase needs cleaning up.  Each change however incurs a little bit of\n> social debt.  Life is a little bit harder on people trying to get work into\n> the tree.  Developers are a little bit more discouraged at the busy-work\n> they must perform.  Non-trivial pull requests take a little bit longer to\n> approve, because they take a little bit more work to rebase (again).\n> \n> A steady flow of code movement and cosmetic breakage into the tree may be a\n> net gain, but it also incurs a *lot* of social debt.  In such situations,\n> developers find that tested, working out-of-tree code repeatedly stops\n> working *during the process of trying to get that work in-tree*.  Taken\n> over time, it discourages working on the tree.  It is rational to sit back,\n> *not* work on the tree, let the breakage stop, and then pick up the pieces.\n> \n> \n> \n> \n> *Paradox Unwound*\n> Bitcoin Core, then, is pulled in opposite directions by a familiar\n> problem.  It is generally agreed that the codebase needs further\n> refactoring.  That's not just isolated engineer nit-picking.  However, for\n> non-trivial projects, refactoring is always anti-social in the short term.\n> It impacts projects other than your own, projects you don't even know\n> about. One change causes work for N developers.  Given these twin opposing\n> goals, the key, as ever, is finding the right balance.\n> \n> Much like \"feature freeze\" in other software projects, developing a policy\n> that opens and closes windows for code movement and major disruptive\n> changes seems prudent.  One week of code movement & cosmetics followed by 3\n> weeks without, for example.  Part of open source parallel development\n> is *social\n> signalling*:  Signal to developers when certain changes are favored or not,\n> then trust they can handle the rest from there.\n> \n> While recent code movement commits themselves are individually ACK-worthy,\n> professionally executed and moving towards a positive goal, I think the\n> project could strike a better balance when it comes to disruptive cosmetic\n> changes, a balance that better encourages developers to work on more\n> involved Bitcoin Core projects."
            },
            {
                "author": "Wladimir",
                "date": "2014-12-17T08:53:16",
                "message_text_only": "> I don't care which tabbing style or column width you pick, but **pick one**,\n> and enforce it across the entire codebase.\n\nSee https://github.com/bitcoin/bitcoin/pull/5387\n\nWladimir"
            },
            {
                "author": "21E14",
                "date": "2014-12-18T05:56:18",
                "message_text_only": "I'll pick up where you left off, Jeff. The thought process behind the\nBitcoin Core threading model, platform support, libification, dependency\nmanagement, core data structures, DoS mitigation, script evolution,\nscalability roadmap... just to scratch the surface, is likely never going\nto be apparent entirely from the source code itself, and will not, in its\ncurrent form, be easily understood before digesting repository docs, repo\nissues, pull requests, IRC logs, mailing list archives (open and closed),\nforum posts, wiki articles, historical repositories, the foundation's\ntechnical blog, whitepapers, to name a few. I'd rather not guess how many\nhave got a grip on it. If any, across the entire spectrum. It may be the\nbottleneck to address. I encourage everyone to take a look at the C#\nLanguage Design Notes* on codeplex. We'll know we've met the challenge when\nfolks are no longer digging up gmaxwell's IRC comments to understand the\nrationale on nScriptCheckThreads, nor having to refer to sipa's\nstackexchange to figure out chainstate & blockindex key/value pairs.\n\n*\nhttps://roslyn.codeplex.com/wikipage?title=CSharp%20Language%20Design%20Notes&referringTitle=Documentation\n\n\nOn Tue, Dec 16, 2014 at 5:59 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:\n>\n>\n> It can be useful to review open source development processes from time to\n> time.  This reddit thread[1] serves use both as a case study, and also a\n> moment of OSS process introduction for newbies.\n> [1]\n> http://www.reddit.com/r/Bitcoin/comments/2pd0zy/peter_todd_is_saying_shoddy_development_on_v010/\n>\n>\n>\n>\n> *Dirty Laundry*\n> When building businesses or commercial software projects, outsiders\n> typically hear little about the internals of project development.  The\n> public only hears what the companies release, which is prepped and\n> polished. Internal disagreements, schedule slips, engineer fistfights are\n> all unseen.\n>\n> Open source development is the opposite.  The goal is radical\n> transparency.  Inevitably there is private chatter (0day bugs etc.), but\n> the default is openness.  This means that is it normal practice to \"air\n> dirty laundry in public.\"  Engineers will disagree, sometimes quietly,\n> sometimes loudly, sometimes rudely and with ad hominem attacks.  On the\n> Internet, there is a pile-on effect, where informed and uninformed\n> supporters add their 0.02 BTC.\n>\n> Competing interests cloud the issues further.  Engineers are typically\n> employed by an organization, as a technology matures.  Those organizations\n> have different strategies and motivations.  These organizations will\n> sponsor work they find beneficial.  Sometimes those orgs are non-profit\n> foundations, sometimes for-profit corporations.  Sometimes that work is\n> maintenance (\"keep it running\"), sometimes that work is developing new,\n> competitive features that company feels will give it a better market\n> position.  In a transparent development environment, all parties are\n> hyperaware of these competing interests.  Internet natterers painstakingly\n> document and repeat every conspiracy theory about Bitcoin Foundation,\n> Blockstream, BitPay, various altcoin developers, and more as a result of\n> these competing interests.\n>\n> Bitcoin and altcoin development adds an interesting new dimension.\n> Sometimes engineers have a more direct conflict of interest, in that the\n> technology they are developing is also potentially their road to instant\n> $millions.  Investors, amateur and professional, have direct stakes in a\n> certain coin or coin technology.  Engineers also have an emotional stake in\n> technology they design and nurture.  This results in incentives where\n> supporters of a non-bitcoin technology work very hard to thump bitcoin.\n> And vice versa.  Even inside bitcoin, you see \"tree chains vs. side chains\"\n> threads of a similar stripe.  This can lead to a very skewed debate.\n>\n> That should not distract from the engineering discussion.  Starting from\n> first principles, Assume Good Faith[2].  Most engineers in open source tend\n> to mean what they say.  Typically they speak for themselves first, and\n> their employers value that engineer's freedom of opinion.  Pay attention to\n> the engineers actually working on the technology, and less attention to the\n> noise bubbling around the Internet like the kindergarten game of grapevine.\n> [2] http://en.wikipedia.org/wiki/Wikipedia:Assume_good_faith\n>\n> Being open and transparent means engineering disagreements happen in\n> public.  This is normal.  Open source engineers live an aquarium life[3].\n> [3] https://www.youtube.com/watch?v=QKe-aO44R7k\n>\n>\n>\n>\n> *What the fork?*\n> In this case, a tweet suggests consensus bug risks, which reddit account\n> \"treeorsidechains\" hyperbolizes into a dramatic headline[1].  However, the\n> headline would seem to be the opposite of the truth.  Several changes were\n> merged during 0.10 development which move snippets of source code into new\n> files and new sub-directories.  The general direction of this work is\n> creating a \"libconsensus\" library that carefully encapsulates consensus\n> code in a manner usable by external projects.  This is a good thing.\n>\n> The development was performed quite responsible:  Multiple developers\n> would verify each cosmetic change, ensuring no behavior changes had been\n> accidentally (or maliciously!) introduced.  Each pull request receives a\n> full multi-platform build + automated testing, over and above individual\n> dev testing.  Comparisons at the assembly language level were sometimes\n> made in critical areas, to ensure zero before-and-after change.  Each\n> transformation gets the Bitcoin Core codebase to a more sustainable, more\n> reusable state.\n>\n> Certainly zero-change is the most conservative approach. Strictly\n> speaking, that has the lowest consensus risk.  But that is a short term\n> mentality.  Both Bitcoin Core and the larger ecosystem will benefit when\n> the \"hairball\" pile of source code is cleaned up.  Progress has been made\n> on that front in the past 2 years, and continues.   *Long term*, combined\n> with the \"libconsensus\" work, that leads to less community-wide risk.\n>\n> The key is balance.  Continue software engineering practices -- like those\n> just mentioned above -- that enable change with least consensus risk.  Part\n> of those practices is review at each step of the development process:\n> social media thought bubble, mailing list post, pull request, git merge,\n> pre-release & release.  It probably seems chaotic at times.  In effect,\n> git[hub] and the Internet enable a dynamic system of review and feedback,\n> where each stage provides a check-and-balance for bad ideas and bad\n> software changes.  It's a human process, designed to acknowledge and handle\n> that human engineers are fallible and might make mistakes (or be\n> coerced/under duress!).  History and field experience will be the ultimate\n> judge, but I think Bitcoin Core is doing good on this score, all things\n> considered.\n>\n> At the end of the day, while no change is without risk, version 0.10 work\n> was done with attention to consensus risk at multiple levels (not just\n> short term).\n>\n>\n>\n>\n> *Technical and social debt*\n> Working on the Linux kernel was an interesting experience that combined\n> git-driven parallel development and a similar source code hairball.  One of\n> the things that quickly became apparent is that cosmetic patches,\n> especially code movement, was hugely disruptive.  Some even termed it\n> anti-social.  To understand why, it is important to consider how modern\n> software changes are developed:\n>\n> Developers work in parallel on their personal computers to develop XYZ\n> change, then submit their change \"upstream\" as a github pull request.  Then\n> time passes.  If code movement and refactoring changes are accepted\n> upstream before XYZ, then the developer is forced update XYZ -- typically\n> trivial fixes, re-review XYZ, and re-test XYZ to ensure it remains in a\n> known-working state.\n>\n> Seemingly cosmetic changes such as code movement have a ripple effect on\n> participating developers, and wider developer community.  Every developer\n> who is *not* immediately merged upstream must bear the costs of updating\n> their unmerged work.\n>\n> Normally, this is expected.  Encouraging developers to build on top of\n> \"upstream\" produces virtuous cycles.\n>\n> However, a constant stream of code movement and cosmetic changes may\n> produce a constant stream of disruption to developers working on\n> non-trivial features that take a bit longer to develop before going\n> upstream.  Trivial changes are encouraged, and non-trivial changes face a\n> binary choice of (a) be merged immediately or (b) bear added re-base,\n> re-view, re-test costs.\n>\n> Taken over a timescale of months, I argue that a steady stream of cosmetic\n> code movement changes serves as a disincentive to developers working with\n> upstream.  Each upstream breakage has a ripple effect to all developers\n> downstream, and imposes some added chance of newly introduced bugs on\n> downstream developers.  I'll call this \"social debt\", a sort of technical\n> debt[4] for developers.\n> [4] http://en.wikipedia.org/wiki/Technical_debt\n>\n> As mentioned above, the libconsensus and code movement work is a net\n> gain.  The codebase needs cleaning up.  Each change however incurs a little\n> bit of social debt.  Life is a little bit harder on people trying to get\n> work into the tree.  Developers are a little bit more discouraged at the\n> busy-work they must perform.  Non-trivial pull requests take a little bit\n> longer to approve, because they take a little bit more work to rebase\n> (again).\n>\n> A steady flow of code movement and cosmetic breakage into the tree may be\n> a net gain, but it also incurs a *lot* of social debt.  In such\n> situations, developers find that tested, working out-of-tree code\n> repeatedly stops working *during the process of trying to get that work\n> in-tree*.  Taken over time, it discourages working on the tree.  It is\n> rational to sit back, *not* work on the tree, let the breakage stop, and\n> then pick up the pieces.\n>\n>\n>\n>\n> *Paradox Unwound*\n> Bitcoin Core, then, is pulled in opposite directions by a familiar\n> problem.  It is generally agreed that the codebase needs further\n> refactoring.  That's not just isolated engineer nit-picking.  However, for\n> non-trivial projects, refactoring is always anti-social in the short term.\n> It impacts projects other than your own, projects you don't even know\n> about. One change causes work for N developers.  Given these twin opposing\n> goals, the key, as ever, is finding the right balance.\n>\n> Much like \"feature freeze\" in other software projects, developing a policy\n> that opens and closes windows for code movement and major disruptive\n> changes seems prudent.  One week of code movement & cosmetics followed by 3\n> weeks without, for example.  Part of open source parallel development is *social\n> signalling*:  Signal to developers when certain changes are favored or\n> not, then trust they can handle the rest from there.\n>\n> While recent code movement commits themselves are individually ACK-worthy,\n> professionally executed and moving towards a positive goal, I think the\n> project could strike a better balance when it comes to disruptive cosmetic\n> changes, a balance that better encourages developers to work on more\n> involved Bitcoin Core projects.\n>\n>\n> --\n> Jeff Garzik\n> Bitcoin core developer and open source evangelist\n> BitPay, Inc.      https://bitpay.com/\n>\n>\n> ------------------------------------------------------------------------------\n> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n> from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n> with Interactivity, Sharing, Native Excel Exports, App Integration & more\n> Get technology previously reserved for billion-dollar corporations, FREE\n>\n> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n> _______________________________________________\n> Bitcoin-development mailing list\n> Bitcoin-development at lists.sourceforge.net\n> https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141218/2fbf1055/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Open development processes and reddit charms",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Jeff Garzik",
                "Troy Benjegerdes",
                "21E14",
                "Wladimir"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 33838
        }
    },
    {
        "title": "[Bitcoin-development] Area of Focus",
        "thread_messages": [
            {
                "author": "Will Bickford",
                "date": "2014-12-20T07:42:23",
                "message_text_only": "Hi all, I'm looking to help with Bitcoin core development in my spare time\n(a few hours per week).\n\nA little bit about me:\n* I use C++ and Qt daily\n* I love to automate and enhance software systems\n* I enjoy root causing and fixing issues\n\nI saw Gavin say we needed help with testing in a Reddit AMA a while ago.\nI'm curious where I can make the best impact. Any feedback would be\nappreciated. Thanks!\n\nWill Bickford\n\"In Google We Trust\"\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141220/e2726c10/attachment.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2014-12-20T08:57:53",
                "message_text_only": "There was recently some discussion around dnsseeds. Currently some\ndnsseeds are getting blocked by ISPs because the hosts they pick up\n(which run bitcoin core nodes) often run rather web servers alongside\nwhich serve malware or whatever else and thus end up on IP-based malware\nblacklists.\n\nOf course we really dont want to move off of DNS because it has this big\nbuilt-in anonymity network where the DNS seed servers only get\ninformation about your ISP, not you, and its cached so you dont get as\nmuch information about how many users are making those requests.\n\nA potential solution might be supporting some subdomain which has\nresults XORed with some constant mask to tweak the real IP.\n\nAdditionally, it might be cool to stuff a TXT/AAAA/whatever record with\na signature of the results provided by the DNSseed operator.\n\nMatt\n\nOn 12/20/14 07:42, Will Bickford wrote:\n> Hi all, I'm looking to help with Bitcoin core development in my spare\n> time (a few hours per week).\n> \n> A little bit about me:\n> * I use C++ and Qt daily\n> * I love to automate and enhance software systems\n> * I enjoy root causing and fixing issues\n> \n> I saw Gavin say we needed help with testing in a Reddit AMA a while ago.\n> I'm curious where I can make the best impact. Any feedback would be\n> appreciated. Thanks!\n> \n> Will Bickford\n> \"In Google We Trust\"\n> \n> \n> ------------------------------------------------------------------------------\n> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n> from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n> with Interactivity, Sharing, Native Excel Exports, App Integration & more\n> Get technology previously reserved for billion-dollar corporations, FREE\n> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n> \n> \n> \n> _______________________________________________\n> Bitcoin-development mailing list\n> Bitcoin-development at lists.sourceforge.net\n> https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n>"
            },
            {
                "author": "Roy Badami",
                "date": "2014-12-20T10:08:17",
                "message_text_only": "Why would we want to have anything to do with people who are hosting\nmalware?  Or do I misunderstand?\n\nOn Sat, Dec 20, 2014 at 08:57:53AM +0000, Matt Corallo wrote:\n> There was recently some discussion around dnsseeds. Currently some\n> dnsseeds are getting blocked by ISPs because the hosts they pick up\n> (which run bitcoin core nodes) often run rather web servers alongside\n> which serve malware or whatever else and thus end up on IP-based malware\n> blacklists.\n> \n> Of course we really dont want to move off of DNS because it has this big\n> built-in anonymity network where the DNS seed servers only get\n> information about your ISP, not you, and its cached so you dont get as\n> much information about how many users are making those requests.\n> \n> A potential solution might be supporting some subdomain which has\n> results XORed with some constant mask to tweak the real IP.\n> \n> Additionally, it might be cool to stuff a TXT/AAAA/whatever record with\n> a signature of the results provided by the DNSseed operator.\n> \n> Matt\n> \n> On 12/20/14 07:42, Will Bickford wrote:\n> > Hi all, I'm looking to help with Bitcoin core development in my spare\n> > time (a few hours per week).\n> > \n> > A little bit about me:\n> > * I use C++ and Qt daily\n> > * I love to automate and enhance software systems\n> > * I enjoy root causing and fixing issues\n> > \n> > I saw Gavin say we needed help with testing in a Reddit AMA a while ago.\n> > I'm curious where I can make the best impact. Any feedback would be\n> > appreciated. Thanks!\n> > \n> > Will Bickford\n> > \"In Google We Trust\"\n> > \n> > \n> > ------------------------------------------------------------------------------\n> > Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n> > from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n> > with Interactivity, Sharing, Native Excel Exports, App Integration & more\n> > Get technology previously reserved for billion-dollar corporations, FREE\n> > http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n> > \n> > \n> > \n> > _______________________________________________\n> > Bitcoin-development mailing list\n> > Bitcoin-development at lists.sourceforge.net\n> > https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n> > \n> \n> ------------------------------------------------------------------------------\n> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n> from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n> with Interactivity, Sharing, Native Excel Exports, App Integration & more\n> Get technology previously reserved for billion-dollar corporations, FREE\n> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n> _______________________________________________\n> Bitcoin-development mailing list\n> Bitcoin-development at lists.sourceforge.net\n> https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n>"
            },
            {
                "author": "Jeremy Spilman",
                "date": "2014-12-20T11:14:28",
                "message_text_only": "On Sat, Dec 20, 2014 at 08:57:53AM +0000, Matt Corallo wrote:\n>> There was recently some discussion around dnsseeds. Currently some\n>> dnsseeds are getting blocked by ISPs because the hosts they pick up\n>> (which run bitcoin core nodes) often run rather web servers alongside\n>> which serve malware or whatever else and thus end up on IP-based malware\n>> blacklists.\n\nOn Sat, 20 Dec 2014 02:08:17 -0800, Roy Badami <roy at gnomon.org.uk> wrote:\n> Why would we want to have anything to do with people who are hosting\n> malware?  Or do I misunderstand?\n\nIt sounds like Matt is saying the nodes the dnsseed is pointing to as  \nvalid full nodes, that those IPs are hosting the malware. Since the  \ndnsseed picks up any stable nodes it can find without auditing, it's  \nperhaps not surprising some servers in the world are running a full node  \nand a malware server together.\n\nI guess what confused me about this though, how are ISPs reading the  \ndnsseed's node list, scanning *those* IPs for malware, and then ending up  \nblocking the dnsseed? Seems like a pretty winding path to end up blocking  \na DNS server?\n\nSince when do ISPs null-route a DNS server for happening to resolve some  \ndomains to IPs which happen to also be hosting some malware? Null-route  \nthose endpoint IPs sure, but the DNS server too? I guess there was that  \nincident of Microsoft taking over No-IP.com -- are dnsseeds being blocked  \nostensibly because they are acting as dyanamic DNS infrastructure for  \nmalware sites?"
            },
            {
                "author": "Matt Corallo",
                "date": "2014-12-20T21:20:53",
                "message_text_only": "Well, some ISPs, when they see an IP address serving malware, will\n(apparently) simply replace DNS results for anything returning that IP\nwith a warning page.\n\nOne solutions is to just blindly block everything with HTTP(S), as\nChristian has done, but this is a rather ugly solution, since many\nperfectly good nodes will get caught in the crossfire. Hiding what\nactual IPs we're returning in the results seems much cleaner, despite\nbeing an ugly hack.\n\nOn 12/20/14 11:14, Jeremy Spilman wrote:\n> On Sat, Dec 20, 2014 at 08:57:53AM +0000, Matt Corallo wrote:\n>>> There was recently some discussion around dnsseeds. Currently some\n>>> dnsseeds are getting blocked by ISPs because the hosts they pick up\n>>> (which run bitcoin core nodes) often run rather web servers alongside\n>>> which serve malware or whatever else and thus end up on IP-based malware\n>>> blacklists.\n> \n> On Sat, 20 Dec 2014 02:08:17 -0800, Roy Badami <roy at gnomon.org.uk> wrote:\n>> Why would we want to have anything to do with people who are hosting\n>> malware?  Or do I misunderstand?\n> \n> It sounds like Matt is saying the nodes the dnsseed is pointing to as  \n> valid full nodes, that those IPs are hosting the malware. Since the  \n> dnsseed picks up any stable nodes it can find without auditing, it's  \n> perhaps not surprising some servers in the world are running a full node  \n> and a malware server together.\n> \n> I guess what confused me about this though, how are ISPs reading the  \n> dnsseed's node list, scanning *those* IPs for malware, and then ending up  \n> blocking the dnsseed? Seems like a pretty winding path to end up blocking  \n> a DNS server?\n> \n> Since when do ISPs null-route a DNS server for happening to resolve some  \n> domains to IPs which happen to also be hosting some malware? Null-route  \n> those endpoint IPs sure, but the DNS server too? I guess there was that  \n> incident of Microsoft taking over No-IP.com -- are dnsseeds being blocked  \n> ostensibly because they are acting as dyanamic DNS infrastructure for  \n> malware sites?\n> \n> \n> ------------------------------------------------------------------------------\n> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n> from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n> with Interactivity, Sharing, Native Excel Exports, App Integration & more\n> Get technology previously reserved for billion-dollar corporations, FREE\n> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n> _______________________________________________\n> Bitcoin-development mailing list\n> Bitcoin-development at lists.sourceforge.net\n> https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2014-12-20T21:30:03",
                "message_text_only": "On Sat, Dec 20, 2014 at 11:14 AM, Jeremy Spilman <jeremy at taplink.co> wrote:\n>> are dnsseeds being blocked\n> ostensibly because they are acting as dyanamic DNS infrastructure for\n> malware sites?\n\nPretty much appears to be the case. In every instance it appears to be\nautomated. This predates the msft no-ip.com stuff.\nWe also had similar problems with the IRC based method that the\nsoftware originally used.\n\nIt's the same story for mail relay spam blacklisting.  There is a\nwhole industry out there selling people semi-snake-oil blocking\nsolutions to make the baddness of the internet go away. The low margin\nbusiness demands a cheap and highly automated approach... lots of\ninappropriate things get blocked. Nagging people to fix things is time\nconsuming, better to move out of their sights a bit, so that they at\nleast have to specifically target Bitcoin. If they do, it'll at least\nbe worth the time spent fixing it.\n\nI believe opendns is blocking all of sipa.be still as we speak, so if\nyou'd like to see it for yourself try to load http://bitcoin.sipa.be\nwhile using opendns."
            },
            {
                "author": "Christian Decker",
                "date": "2014-12-20T18:27:53",
                "message_text_only": "Thanks for bringing this to my attention.\n\nI added a safety check to my crawler and seed.bitcoinstats.com should\nnot return IPs that also run HTTP or HTTPS, hopefully this'll keep it\noff blacklists :-)\n--\nChristian Decker\n\n\nOn Sat, Dec 20, 2014 at 9:57 AM, Matt Corallo <bitcoin-list at bluematt.me> wrote:\n> There was recently some discussion around dnsseeds. Currently some\n> dnsseeds are getting blocked by ISPs because the hosts they pick up\n> (which run bitcoin core nodes) often run rather web servers alongside\n> which serve malware or whatever else and thus end up on IP-based malware\n> blacklists.\n>\n> Of course we really dont want to move off of DNS because it has this big\n> built-in anonymity network where the DNS seed servers only get\n> information about your ISP, not you, and its cached so you dont get as\n> much information about how many users are making those requests.\n>\n> A potential solution might be supporting some subdomain which has\n> results XORed with some constant mask to tweak the real IP.\n>\n> Additionally, it might be cool to stuff a TXT/AAAA/whatever record with\n> a signature of the results provided by the DNSseed operator.\n>\n> Matt\n>\n> On 12/20/14 07:42, Will Bickford wrote:\n>> Hi all, I'm looking to help with Bitcoin core development in my spare\n>> time (a few hours per week).\n>>\n>> A little bit about me:\n>> * I use C++ and Qt daily\n>> * I love to automate and enhance software systems\n>> * I enjoy root causing and fixing issues\n>>\n>> I saw Gavin say we needed help with testing in a Reddit AMA a while ago.\n>> I'm curious where I can make the best impact. Any feedback would be\n>> appreciated. Thanks!\n>>\n>> Will Bickford\n>> \"In Google We Trust\"\n>>\n>>\n>> ------------------------------------------------------------------------------\n>> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n>> from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n>> with Interactivity, Sharing, Native Excel Exports, App Integration & more\n>> Get technology previously reserved for billion-dollar corporations, FREE\n>> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n>>\n>>\n>>\n>> _______________________________________________\n>> Bitcoin-development mailing list\n>> Bitcoin-development at lists.sourceforge.net\n>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n>>\n>\n> ------------------------------------------------------------------------------\n> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n> from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n> with Interactivity, Sharing, Native Excel Exports, App Integration & more\n> Get technology previously reserved for billion-dollar corporations, FREE\n> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n> _______________________________________________\n> Bitcoin-development mailing list\n> Bitcoin-development at lists.sourceforge.net\n> https://lists.sourceforge.net/lists/listinfo/bitcoin-development"
            },
            {
                "author": "Jeff Garzik",
                "date": "2014-12-20T21:26:20",
                "message_text_only": "Getting back to the original topic...\n\nI would recommend first taking a look at how the current tests are built\n(via autoconf/automake) in src/test.  There are several surfaces to test,\nRPC, REST, P2P, internal unit tests, and more.  Then, Travis applies a\nsecond level of testing via the bitcoinj-based regression tests.\n\nSome automated tests that operate at the Qt level would be interesting.  In\ngeneral, the current tests only scratch the surface of what Needs To Be\nTested...  but part of figuring out a good test is (a) knowing bitcoin and\n(b) knowing the current test regimes.\n\nJoin #bitcoin-dev IRC and ask questions.  Read the bitcoin wiki.\n\n\n\n\nOn Sat, Dec 20, 2014 at 2:42 AM, Will Bickford <wbic16 at gmail.com> wrote:\n>\n> Hi all, I'm looking to help with Bitcoin core development in my spare time\n> (a few hours per week).\n>\n> A little bit about me:\n> * I use C++ and Qt daily\n> * I love to automate and enhance software systems\n> * I enjoy root causing and fixing issues\n>\n> I saw Gavin say we needed help with testing in a Reddit AMA a while ago.\n> I'm curious where I can make the best impact. Any feedback would be\n> appreciated. Thanks!\n>\n> Will Bickford\n> \"In Google We Trust\"\n>\n>\n> ------------------------------------------------------------------------------\n> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n> from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n> with Interactivity, Sharing, Native Excel Exports, App Integration & more\n> Get technology previously reserved for billion-dollar corporations, FREE\n>\n> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n> _______________________________________________\n> Bitcoin-development mailing list\n> Bitcoin-development at lists.sourceforge.net\n> https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n>\n>\n\n-- \nJeff Garzik\nBitcoin core developer and open source evangelist\nBitPay, Inc.      https://bitpay.com/\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141220/9609c701/attachment.html>"
            },
            {
                "author": "Will Bickford",
                "date": "2014-12-20T22:37:58",
                "message_text_only": "Thanks Jeff. I'll start looking there.\n\nWill Bickford\n\"In Google We Trust\"\n\nOn Sat, Dec 20, 2014 at 3:26 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:\n\n> Getting back to the original topic...\n>\n> I would recommend first taking a look at how the current tests are built\n> (via autoconf/automake) in src/test.  There are several surfaces to test,\n> RPC, REST, P2P, internal unit tests, and more.  Then, Travis applies a\n> second level of testing via the bitcoinj-based regression tests.\n>\n> Some automated tests that operate at the Qt level would be interesting.\n> In general, the current tests only scratch the surface of what Needs To Be\n> Tested...  but part of figuring out a good test is (a) knowing bitcoin and\n> (b) knowing the current test regimes.\n>\n> Join #bitcoin-dev IRC and ask questions.  Read the bitcoin wiki.\n>\n>\n>\n>\n> On Sat, Dec 20, 2014 at 2:42 AM, Will Bickford <wbic16 at gmail.com> wrote:\n>\n>> Hi all, I'm looking to help with Bitcoin core development in my spare\n>> time (a few hours per week).\n>>\n>> A little bit about me:\n>> * I use C++ and Qt daily\n>> * I love to automate and enhance software systems\n>> * I enjoy root causing and fixing issues\n>>\n>> I saw Gavin say we needed help with testing in a Reddit AMA a while ago.\n>> I'm curious where I can make the best impact. Any feedback would be\n>> appreciated. Thanks!\n>>\n>> Will Bickford\n>> \"In Google We Trust\"\n>>\n>>\n>> ------------------------------------------------------------------------------\n>> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server\n>> from Actuate! Instantly Supercharge Your Business Reports and Dashboards\n>> with Interactivity, Sharing, Native Excel Exports, App Integration & more\n>> Get technology previously reserved for billion-dollar corporations, FREE\n>>\n>> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk\n>> _______________________________________________\n>> Bitcoin-development mailing list\n>> Bitcoin-development at lists.sourceforge.net\n>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n>>\n>>\n>\n> --\n> Jeff Garzik\n> Bitcoin core developer and open source evangelist\n> BitPay, Inc.      https://bitpay.com/\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141220/ca76d3fa/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Area of Focus",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Jeff Garzik",
                "Roy Badami",
                "Jeremy Spilman",
                "Gregory Maxwell",
                "Matt Corallo",
                "Will Bickford",
                "Christian Decker"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 18368
        }
    },
    {
        "title": "[Bitcoin-development] one-show signatures (Re: The relationship between Proof-of-Publication and Anti-Replay Oracles)",
        "thread_messages": [
            {
                "author": "Adam Back",
                "date": "2014-12-21T18:10:47",
                "message_text_only": "Yes you could for example define a new rule that two signatures\n(double-spend) authorises something - eg miners to take funds. (And\nthis would work with existing ECDSA addresses & unrestricted R-value\nchoices).\n\nI wasnt really making a point other than an aside that it maybe is\nsort-of possible to do with math what you said was not possible where\nyou said \"This [preventing signing more than one message] is\nimpossible to implement with math alone\".\n\nAdam\n\nOn 21 December 2014 at 15:29, Peter Todd <pete at petertodd.org>\n> There's no need to get into the specifics of crypto math so early; you\n> can just as easily and only slightly less efficiently obtain the same\n> result with a few extensions to the Bitcoin scripting system to verify\n> ECDSA signatures directly."
            },
            {
                "author": "Peter Todd",
                "date": "2014-12-21T18:51:26",
                "message_text_only": "On Sun, Dec 21, 2014 at 06:10:47PM +0000, Adam Back wrote:\n> Yes you could for example define a new rule that two signatures\n> (double-spend) authorises something - eg miners to take funds. (And\n> this would work with existing ECDSA addresses & unrestricted R-value\n> choices).\n> \n> I wasnt really making a point other than an aside that it maybe is\n> sort-of possible to do with math what you said was not possible where\n> you said \"This [preventing signing more than one message] is\n> impossible to implement with math alone\".\n\nIntroducing a bunch of clever ECDSA math doesn't change the fact that\nthe clever math isn't what is preventing double-spending, clever\neconomics is. Just like Bitcoin itself.\n\nNo sense getting people potentially confused by a bunch of complex\nequations that aren't relevant to the more fundemental and much more\nimportant principle that math alone can't prevent double-spending.\n\n-- \n'peter'[:-1]@petertodd.org\n00000000000000001bc21486eb6e305efc085daa6b9acd37305feba64327342e\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/a20fc8eb/attachment.sig>"
            },
            {
                "author": "paul snow",
                "date": "2014-12-22T00:56:28",
                "message_text_only": "On Sun, Dec 21, 2014 at 12:51 PM, Peter Todd <pete at petertodd.org> wrote:\n\n> On Sun, Dec 21, 2014 at 06:10:47PM +0000, Adam Back wrote:\n> > Yes you could for example define a new rule that two signatures\n> > (double-spend) authorises something - eg miners to take funds. (And\n> > this would work with existing ECDSA addresses & unrestricted R-value\n> > choices).\n> >\n> > I wasnt really making a point other than an aside that it maybe is\n> > sort-of possible to do with math what you said was not possible where\n> > you said \"This [preventing signing more than one message] is\n> > impossible to implement with math alone\".\n>\n> Introducing a bunch of clever ECDSA math doesn't change the fact that\n> the clever math isn't what is preventing double-spending, clever\n> economics is. Just like Bitcoin itself.\n>\n> No sense getting people potentially confused by a bunch of complex\n> equations that aren't relevant to the more fundemental and much more\n> important principle that math alone can't prevent double-spending.\n\n\nMath alone describes all of Bitcoin's structure; as math is a way to model\nreality, it has no limits. Saying Math can't prevent double-spending is\nnear equivalent to saying it cannot be done.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/15e13227/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "one-show signatures (Re: The relationship between Proof-of-Publication and Anti-Replay Oracles)",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Adam Back",
                "paul snow",
                "Peter Todd"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 3447
        }
    },
    {
        "title": "[Bitcoin-development] Reading List for Getting Up to Speed",
        "thread_messages": [
            {
                "author": "Will Bickford",
                "date": "2014-12-24T17:08:59",
                "message_text_only": "I've started to familiarize myself with the source code and build tools.\nI'll be posting regular status updates on my blog (linked below) for others\nto follow getting started with bitcoin development.\n\nhttp://hewo.xedoloh.com/bitcoin-dev/\n\nA tally from August indicated that I may need to slog through 280,000 lines\nof code to get up to speed. I sampled\nhttps://github.com/bitcoin/bitcoin/blob/master/src/key.cpp and skimmed it\nin about 5 minutes, putting me at 2600 lines per hour. At that rate, I\nwould need to devote 110 hours to read the entire code base.\n\nWith that time investment I could get a fair amount of testing done, so I'm\ncurious if we have a map of the most important areas to study for new\ndevelopers and automated test writers.\n\nThanks for your time,\n\nWill Bickford\n\"In Google We Trust\"\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141224/948de5e7/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2014-12-24T19:44:37",
                "message_text_only": "On Wed, Dec 24, 2014 at 5:08 PM, Will Bickford <wbic16 at gmail.com> wrote:\n> A tally from August indicated that I may need to slog through 280,000 lines\n\nYou're counting 170kloc of machine generated code with the translation\nstrings there.\n\nThe top level (/src) and libconsensus are only about 36kloc. This is\nsmall enough that I would strongly recommend at least skimming all of\nit."
            },
            {
                "author": "Will Bickford",
                "date": "2014-12-24T19:58:02",
                "message_text_only": "Gotcha. That's much more manageable. Thanks!\n\nWill Bickford\n\"In Google We Trust\"\n\nOn Wed, Dec 24, 2014 at 1:44 PM, Gregory Maxwell <gmaxwell at gmail.com> wrote:\n\n> On Wed, Dec 24, 2014 at 5:08 PM, Will Bickford <wbic16 at gmail.com> wrote:\n> > A tally from August indicated that I may need to slog through 280,000\n> lines\n>\n> You're counting 170kloc of machine generated code with the translation\n> strings there.\n>\n> The top level (/src) and libconsensus are only about 36kloc. This is\n> small enough that I would strongly recommend at least skimming all of\n> it.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141224/513a60a7/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Reading List for Getting Up to Speed",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Will Bickford",
                "Gregory Maxwell"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 2121
        }
    },
    {
        "title": "[Bitcoin-development] Bitcoin 0.10.0c1 available for download",
        "thread_messages": [
            {
                "author": "Wladimir",
                "date": "2014-12-26T18:28:12",
                "message_text_only": "Signed executables are available for 0.10.0 release candidate 1, at\n\nhttps://bitcoin.org/bin/0.10.0/test/\n\nPreliminary release notes for the 0.10 release can be found here:\nhttps://github.com/bitcoin/bitcoin/blob/0.10/doc/release-notes.md\n\nPlease report bugs using the issue tracker at github:\nhttps://github.com/bitcoin/bitcoin/issues\n\nCheers,\nWladimir"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin 0.10.0c1 available for download",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Wladimir"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 353
        }
    },
    {
        "title": "[Bitcoin-development] Bitcoin XT",
        "thread_messages": [
            {
                "author": "Mike Hearn",
                "date": "2014-12-28T18:04:08",
                "message_text_only": "Hi there,\n\nI hope everyone who celebrates Christmas is having a relaxing and enjoyable\nbreak! :)\n\nI'd like to announce Bitcoin XT <https://github.com/bitcoinxt/bitcoinxt>, a\npatch set on top of Bitcoin Core 0.10rc1 that focuses on enhancements to\nthe peer to peer protocol. It is reproducibly built with gitian and there\nare binaries for Linux, OS X and Windows (code signed). It currently\ncontains the following two features:\n\n   1. Double spend relaying, by Gavin Andresen and Tom Harding. This is\n   useful for merchants that currently connect to thousands of nodes to spot\n   double spends, which is wasteful of resources.\n\n   2. BIP 64 support (the getutxo message). This is useful for Lighthouse\n   to render a more helpful GUI.\n\nBy running XT you provide additional services to users of the P2P network,\ntest the features more thoroughly and help build the case for inclusion in\nBitcoin Core.\n\nThere is a mailing list for discussion of patch inclusion\n<https://groups.google.com/forum/#!forum/bitcoin-xt/>, and another list for\nannouncements <https://groups.google.com/forum/#!forum/bitcoin-xt-announce>.\nBecause XT is a patch set the feature branches will be rebased from time to\ntime. If you branch from them, be aware of that and plan accordingly.\n\nXT nodes advertise themselves by using the getutxo service bit (i.e. bit\n2). You can find them by querying a Cartographer, which I will describe in\nanother email.\n\n\n\nA brief note about the goals of this project. The XT project is intended to\nprovide a friendly environment where [SPV] app developers and merchants can\nexperiment with new features and explore new directions for the protocol,\nif there is demand for that. Those upgrades could then be considered for\ninclusion into Core at a later date. I do not expect there to be thousands\nof XT users any time soon, but that's OK. Because the patch set contains\nfeatures that don't require everyone to opt in (e.g. changes to the\ntx/block formats), even just a few nodes can be useful.\n\n\nThanks for reading, and have a great new year's eve!\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141228/35ae8c7b/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin XT",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Mike Hearn"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2233
        }
    },
    {
        "title": "[Bitcoin-development] Cartographer",
        "thread_messages": [
            {
                "author": "Mike Hearn",
                "date": "2014-12-28T18:25:29",
                "message_text_only": "Hi there!\n\nLately we have been bumping up against the limitations of DNS as a protocol\nfor learning about the p2p network. As a proposal for how to address this,\nI have written a new network crawler and seed:\n\nhttps://github.com/mikehearn/httpseed\n\nIt implements a standard DNS seed with a minimal embedded DNS server (you\ncan find one running at dnsseed.vinumeris.com) and also has the following\nextra features:\n\n\n   - Can serve seed data using gzipped, timestamped digitally signed\n   protocol buffers over HTTP. This fixes authentication, auditability,\n   malware false positives and extensibility. The signature uses secp256k1.\n   SSL is *not* used, to simplify deployment and to allow ISPs to cache the\n   results transparently when a future version sets cache control headers.\n   - Can additionally serve data in JSON, XML and HTML (examples for json\n   <http://vinumeris.com:8081/peers.json> xml\n   <http://vinumeris.com:8081/peers.xml> html\n   <http://vinumeris.com:8081/peers.html>) for ease of use with other\n   tools, like web browsers.\n   - Results can be restricted using query parameters, e.g. for a service\n   flags bit mask. Cartographer tests nodes that set service bit 2 to see if\n   they really support BIP 64, and this requirement can also be specified as\n   an argument to the query.\n   - Crawl speed can be specified in terms of successful connects per\n   second, rather than the number-of-threads approach used by other crawlers.\n   - Can export statistics and controls using JMX, so you can reconfigure\n   it at runtime and view charts of things like connects/sec or CPU usage\n   using any JMX console, like Mission Control.\n   - A client for it is in bitcoinj master branch.\n\nTo provide all these features Cartographer relies heavily on libraries and\nis written in a concise new language called Kotlin <http://kotlinlang.org/>,\nso it fits in about 650 lines of code. Kotlin is easy to learn for anyone\nwho knows Scala or Java, so it should be straightforward to hack on and\nthere is no chance of any buffer/heap exploits in the DNS, HTTP or Bitcoin\nprotocol stacks.\n\nIn the new year I will probably write a BIP describing the protocol. For\nnow you can see the definition here\n<https://github.com/mikehearn/httpseed/blob/master/src/main/peerseeds.proto>\nor just read the textual forms from the links above. It's pretty self\nexplanatory. I hope that in future other DNS seeds will start supporting\nthis protocol too, as it has many advantages.\n\nFuture versions might include data like how long the peer has been around,\nnode keys if we add auth/encrypt support to the p2p protocol and so on.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141228/f79042e7/attachment.html>"
            },
            {
                "author": "Thomas Zander",
                "date": "2014-12-29T08:47:29",
                "message_text_only": "On Sunday 28. December 2014 18.25.29 Mike Hearn wrote:\n> Lately we have been bumping up against the limitations of DNS as a protocol\n> for learning about the p2p network.\n\nCan you explain further where limitations and problems were hit?\n\n-- \nThomas Zander"
            },
            {
                "author": "Peter Todd",
                "date": "2014-12-29T10:39:52",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\nA big one is the privacy is way too good: every DNS request goes through multiple levels of caching and indirection, so there's no way to figure out who made the request to subject them additional targeting.\n\nA connection-oriented protocol gets rid of all those protections, giving us seed operators monetisation opportunities like selling usage statistics, per-client targeted results, etc. We recently got rid of all the \"call-home\" functionality that previously gave this type of insight; a connecyion-oriented seed protocol gives us this right back.\n\nThere's also this pesky problem of ISP's censoring DNS results with dumb automated systems to block malware - easily fixed with Gregory Maxwell's suggestion of permuting the results with XOR - but that kind of end-user driven solution really misses out in the needs of other Bitcoin stakeholders like law enforcement and marketing companies.\n\n\nOn 29 December 2014 09:47:29 CET, Thomas Zander <thomas at thomaszander.se> wrote:\n>On Sunday 28. December 2014 18.25.29 Mike Hearn wrote:\n>> Lately we have been bumping up against the limitations of DNS as a\n>protocol\n>> for learning about the p2p network.\n>\n>Can you explain further where limitations and problems were hit?\n-----BEGIN PGP SIGNATURE-----\nVersion: APG v1.1.1\n\niQFQBAEBCAA6BQJUoS94MxxQZXRlciBUb2RkIChsb3cgc2VjdXJpdHkga2V5KSA8\ncGV0ZUBwZXRlcnRvZGQub3JnPgAKCRAZnIM7qOfwhQzHB/97jRf4iX0v/zDW0EkT\n8My2ExCdOqwYToxqTF0DQhwBjVzh2OHH9tVFKPXfgg87xtIxYZjx70yQpw7O4anw\n7E5eJpFRjTayafclzRupgMn2AVT9AN45zjxkEutAEO27mxJ2p0OQPkNKzVR38sGW\n95siatZMej68jflr0o0JrRePaDn3jufZEYQ5IvS80HxEwjzLCx/qCnPKkiKEQjr0\nEHbovZo/5DNmJys4an+hoZkPeDRGw30w86kxXaY2SQP8aefswfg6rTOcrfkuQQfQ\nAEYRZCZb6XxkL/gLU1dSgidswg+wgt/JW7QB+n6Z0fMGnX92EAxpwrvQUxDm55sC\nHhOT\n=dRuK\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "Mike Hearn",
                "date": "2014-12-29T11:30:42",
                "message_text_only": ">\n> Can you explain further where limitations and problems were hit?\n>\n\nWell, look at the feature list :)\n\nThe biggest need from my POV is querying support. It's awkward to try and\nretrofit flexible key=value pair queries onto DNS, it just wasn't designed\nfor that. With HTTP it's easy. This will become more important in future as\nthe protocol evolves. For example, some nodes will soon stop serving the\nblock chain because they start pruning. Today this is managed with a hack:\npruning nodes just stop providing *all* services to the p2p network. This\ntakes them out of the DNS seeds entirely. But they can actually still\nprovide download of the parts of the chain they still have, and they can\nprovide transaction filtering and relay support, along with misc other\nthings.\n\nWith the current DNS protocol you get an all or nothing choice - so\nprobably seeds that only support it will elect to only show nodes that have\nthe entire block chain, because that's what Bitcoin Core would find most\nuseful. SPV wallets have slightly different needs.\n\nIn theory you could come up with a pile of hacks to specify what the client\nneeds in the DNS query, but then you have a v2 protocol anyway and might as\nwell go the whole way.\n\nAdditionally, with DNS it's awkward to provide extra data in the responses\nbeyond IP address and it's VERY awkward to sign the responses. Signing the\nresponses has a couple of benefits. The biggest is, in future it'd be nice\nto have an authenticated and encrypted network, to raise the bar for sybil\nand MITM attacks. DNS seeding can't be upgraded to support that with any\nreasonable level of effort. And DNS is awkward to configure/set up.\nActually DNS is just awkward, period.\n\nThe second benefit of signing is it provides audibility. If you see a seed\ngive bad answers, you can now prove it to other people.\n\nThere is also the previously discussed issue that DNS seeds sometimes get\nblocked by aggressive networks because they start serving IPs that are\ninfected with malware i.e. they look like fast-flux sites.\n\nUsing a simple HTTP based protocol fixes all of these problems in one go.\n\nNow, re: privacy.\n\nFirstly, Peter, get help. I'm serious. You are starting to sound like an\nauto-generated parody of yourself. When you can't debate something as\nboring as HTTP vs DNS without trying to raise an angry mob using bizarre\nconspiracy theories, that's not normal.\n\nI don't think the \"DNS has caches\" issue is worth worrying about for a lot\nof reasons:\n\n   1. Full nodes try as hard as they can to open ports and advertise their\n   IP addresses to everyone. Even if you change the defaults to disable that,\n   you're about to connect to a bunch of random computers with no reputation\n   anyway.\n\n   2. Lists of stale IP addresses are hardly useful to regular people and\n   network operators can identify Bitcoin users by looking for traffic on port\n   8333, so it's unclear what threat model is being addressed here.\n\n   3. The biggest users of the seeds are all SPV wallets. Every single one\n   of these already phones home to check for online updates.\n\n   4. DNS proxying only hides part of the IP address. If you're serious\n   about this you want to be doing lookups via Tor. Whilst it's possible to\n   use the DNS seeds via Tor in a reasonable way with exit diversity (and\n   bitcoinj does), doing it requires low level Tor protocol programming\n   <https://github.com/bitcoinj/bitcoinj/blob/42f9d7c193fcd56fda7691b0ea934bae9d23f2d6/core/src/main/java/org/bitcoinj/net/discovery/TorDiscovery.java#L260>\n   that is out of reach for most implementors. An HTTP lookup is trivial with\n   any HTTP stack that supports SOCKS.\n\n   5. ISPs also deploy transparent HTTP caches. The Cartographer protocol\n   uses HTTP with inline signing so responses can be cached, once the right\n   headers are being set.\n\ntl;dr it's unclear that DNS caching actually solves any real privacy\nproblem but regardless, you can get the same distributed caching with HTTP\nas with DNS. So in the end it makes little difference.\n\nI believe that Cartographer is a better protocol all round and there are no\ncosts beyond the one-time upgrades, but even if for some reason you\ndisagree with the five privacy points above, I think the benefits still\nmassively outweigh the costs.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141229/c1277067/attachment.html>"
            },
            {
                "author": "Thomas Zander",
                "date": "2014-12-29T11:49:45",
                "message_text_only": "On Monday 29. December 2014 11.30.42 Mike Hearn wrote:\n> With the current DNS protocol you get an all or nothing choice\n\nIts a seed. Not the protocol itself.\n\n> Firstly, Peter, get help. I'm serious.\nI think most would agree with me that, Mike, this answer is not just a little \nover the line, its unacceptable behavior in any collaborative group.\nPlease be respectful and avoid ad-hominem attacks.\n\n-- \nThomas Zander"
            },
            {
                "author": "Peter Todd",
                "date": "2014-12-29T11:59:16",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\n\n\nOn 29 December 2014 12:49:45 CET, Thomas Zander <thomas at thomaszander.se> wrote:\n>On Monday 29. December 2014 11.30.42 Mike Hearn wrote:\n>> With the current DNS protocol you get an all or nothing choice\n>\n>Its a seed. Not the protocol itself.\n>\n>> Firstly, Peter, get help. I'm serious.\n>I think most would agree with me that, Mike, this answer is not just a\n>little\n>over the line, its unacceptable behavior in any collaborative group.\n>Please be respectful and avoid ad-hominem attacks.\n\nYes I agree, Mike shouldn't be making ad-hominim attacks by calling people \"a parody\"\n\nYou'll note my response however carefully avoiding talking about the person who originated the idea, and merely stuck to criticising - via parody - the idea itself.\n\n-----BEGIN PGP SIGNATURE-----\nVersion: APG v1.1.1\n\niQFQBAEBCAA6BQJUoUIUMxxQZXRlciBUb2RkIChsb3cgc2VjdXJpdHkga2V5KSA8\ncGV0ZUBwZXRlcnRvZGQub3JnPgAKCRAZnIM7qOfwhfnpB/9JMcBtq7nCudCvXWgZ\nTyKiSrK811L1PxtPih6UtzskFzNIKIVOgJrZcc0Cs7AoFoXiIPVEqzsqOOjZbhst\nOp2w2scUoQhvhweNLAUdAH5dY+GFJoOn5fol4BD95SuFuao/t1J8G4Ma4b+JGXR5\nvlXtDD/dBJNWJeSVKN/Mgcp7eis3lXp1/rzc9/Ka45oXvUHFSxvQq2v/KgFeHKJ7\nonx551+41MS7R1bedg+dPOtCFBFycW51Obt7vS8GudRqwKyuKoKIQzY910gHYdXL\ngTdQ16wXvp06fYlR4nJJPosE7ADP1udKJZNskVObJsX5z9sukI3r7noHNDDg3ZjH\nbS9/\n=ouap\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "Btc Drak",
                "date": "2014-12-29T12:13:41",
                "message_text_only": "Mike,\n\nIn all seriousness, are you on the payroll of the NSA or similar to\nrepeatedly attempt to introduce privacy leaks[1] and weaknesses[2] into the\necosystem not to mention logical fallacies like ad hominem attacks;\ndisruption[3] and FUD[4]?\n\nWhy do you answer objections by hand waving and misdirection as opposed to\nsound technical reasoning? Remember how hand waving ended for you the last\ntime with your p2p getutxo pull-request[5] and the public flogging the\nensued because you refused to accept your implementation was not only\nflawed but critically vulnerable to attack[6].\n\nGiven your intelligence, education and experience, it would seem logical\nthat your behaviour is not random or irrational, but in fact calculated and\nplanned.\n\nreferences:\n[1]\nhttp://www.reddit.com/r/Bitcoin/comments/2byqz0/mike_hearn_proposes_to_build_vulnerable/\n[2]\nhttps://www.reddit.com/r/Bitcoin/comments/1qmbtu/mike_hearn_chair_of_the_bitcoin_foundations_law/\n[3]\nhttp://www.reddit.com/r/Bitcoin/comments/28zts3/mike_hearn_interview_quotes_progress_on_the/\n[4] https://www.youtube.com/watch?v=iMIzMVABFxQ\n[5] https://github.com/bitcoin/bitcoin/pull/4351\n[6]\nhttp://www.reddit.com/r/Bitcoin/comments/2eq8gi/getutxos_a_convenient_way_to_crash_bitcoind/\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141229/e9e1441f/attachment.html>"
            },
            {
                "author": "Mistr Bigs",
                "date": "2014-12-29T13:08:52",
                "message_text_only": "As an outside observer, I have to say I also found Peter's sardonic message\ntone inappropriate for furthering the discussion.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141229/05f09336/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Cartographer",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Mike Hearn",
                "Peter Todd",
                "Thomas Zander",
                "Mistr Bigs",
                "Btc Drak"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 12812
        }
    },
    {
        "title": "[Bitcoin-development] BIP: Voluntary deposit bonds",
        "thread_messages": [
            {
                "author": "Sergio Lerner",
                "date": "2014-12-29T19:21:02",
                "message_text_only": "I propose to allow miners to voluntarily lock funds by letting miners\nadd additional inputs to the coinbase transaction. Currently the\ncoinbase transaction does not allow any real input  to be added (only a\npseudo-input).\nThis is a hard-fork, and we could include it the next time a hardfork is\nmade.\nThe modifications to the code are minimal (no more than 12 lines\nmodified where IsCoinBase() is called), and they generally involve\nremoving code, not adding.\n\nWhy ?\n\nBecause sometime in the future (maybe 5-10 years) we may have to deal\nwith problems of securing the blockchain, as the subsidy is lowered. We\ndon't want the number of confirmation blocks to be increased in\ncompensation because Bitcoin won't be able to compete with other payment\nnetworks.\nThen by having this hardfork now, we will be able to soft-fork later to\nany rule we may came come up with involving deposit bonds,\nproof-of-stake, and the penalization of double-mining (mining two blocks\nat the same height) to prevent short-range attacks.\n\nCan it hurt?\n\nNo. I doesn't not change the incentives or the security in any way, as\nadding additional inputs to the coinbase transaction would be voluntary\nuntil the time for a soft-fork comes.\nWe shouldn't hard-fork for this change only, but maybe we could do this\nchange when the next hard-fork is scheduled (when we increase the block\nsize?).\n\nRegards, S."
            },
            {
                "author": "Mike Hearn",
                "date": "2014-12-29T21:10:20",
                "message_text_only": "Could you explain a bit further Sergio? I'm not sure I fully understand the\nproposal.\n\nHow does adding inputs to a coinbase differ from just having pay-to-fee\ntransactions in the block?\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141229/9a0dc72b/attachment.html>"
            },
            {
                "author": "Justus Ranvier",
                "date": "2014-12-29T21:34:07",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\nOn 12/29/2014 09:10 PM, Mike Hearn wrote:\n> How does adding inputs to a coinbase differ from just having\n> pay-to-fee transactions in the block?\n\nIf a miner includes pay-to-fee transactions in a block, those fees\ncould be claimed by another miner in the case the first miner's block\nis orphaned.\n\nInputs to a generation transaction can not be similarly poached.\n\nThat difference makes some services possible that would can not be\nsafely achieved with pay-to-fee transactions.\n\n- -- \nJustus Ranvier                   | Monetas <http://monetas.net/>\n<mailto:justus at monetas.net>      | Public key ID : C3F7BB2638450DB5\n                                 | BM-2cTepVtZ6AyJAs2Y8LpcvZB8KbdaWLwKqc\n-----BEGIN PGP SIGNATURE-----\n\niQEcBAEBCAAGBQJUocjPAAoJEMP3uyY4RQ21zrMH/1f3vjac9XqOZbDItjiD6XXU\nEkpRUROjyQAs6/tO6dwWAIcXgulYREAJsU/udQNkTYteIDFlDzwkYL+NLXpYtwHs\nBiZJEEwmAEHFgOD3QmmqhTx867zIbEYIB/dpHlMOppE6fhTKFr9z6JdqAKlNcHHW\ntkW5sq8q9uq7StiUs3/mmZ0XXeEb84N+bPiJ9S7kuTm9QWnrF1oMLhAk4M6yX8hn\n7MUowmfc9RZ4uIFkqxk6gkWJSRx7dlnCRP2TRhyABpZwAcZANuPhqBOZ6eJ6T9Fs\nDOJ14c5JYachXW5z8GqR+abeq0JPE76kEQt145B4degJ4DTQLLhlfdvjbuJvzy4=\n=Kfe2\n-----END PGP SIGNATURE-----\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: 0x38450DB5.asc\nType: application/pgp-keys\nSize: 14542 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141229/66a61d85/attachment.bin>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2014-12-30T10:47:46",
                "message_text_only": "On Mon, Dec 29, 2014 at 10:34 PM, Justus Ranvier\n<justus.ranvier at monetas.net> wrote:\n> -----BEGIN PGP SIGNED MESSAGE-----\n> Hash: SHA256\n>\n> On 12/29/2014 09:10 PM, Mike Hearn wrote:\n>> How does adding inputs to a coinbase differ from just having\n>> pay-to-fee transactions in the block?\n>\n> If a miner includes pay-to-fee transactions in a block, those fees\n> could be claimed by another miner in the case the first miner's block\n> is orphaned.\n>\n> Inputs to a generation transaction can not be similarly poached.\n>\n> That difference makes some services possible that would can not be\n> safely achieved with pay-to-fee transactions.\n\nWhat services?\nI must be missing something obvious about the motivation.\nI understand the difference between \"paying to myself only when I mine\nthe next block\" and \"offering fees to whoever mines this tx\".\nBut how does allowing miners to pay to themselves in this way help\nwith security and future lower subsidies at all?"
            },
            {
                "author": "Justus Ranvier",
                "date": "2014-12-30T13:16:56",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\nOn 12/30/2014 10:47 AM, Jorge Tim\u00f3n wrote:\n> What services? I must be missing something obvious about the\n> motivation. I understand the difference between \"paying to myself\n> only when I mine the next block\" and \"offering fees to whoever\n> mines this tx\". But how does allowing miners to pay to themselves\n> in this way help with security and future lower subsidies at all?\n\nI don't know what Sergio Lernet meant about miners paying themselves\nand future network security.\n\nIf miners wanted to offer value-added services, especially if those\nservices involved adding specific scripts to the outputs of the\ngeneration transaction, the most natural way for their customers to\npay them is to allow inputs to the generation transaction.\n\nIt could also be done with pay-to-fee transactions, but that would\nmake the services more expensive due to risk premium.\n\n- -- \nJustus Ranvier                   | Monetas <http://monetas.net/>\n<mailto:justus at monetas.net>      | Public key ID : C3F7BB2638450DB5\n                                 | BM-2cTepVtZ6AyJAs2Y8LpcvZB8KbdaWLwKqc\n-----BEGIN PGP SIGNATURE-----\n\niQEcBAEBCAAGBQJUoqXIAAoJEMP3uyY4RQ21OZUH/iI9N9bQ3TLPnmCVW6bkIitD\nWT6uBUhBREls2NMjyDQ//UN9F9nt+aU7jN/I0AMrdB8ngFb4r1gfxSpld9KVp6Yw\nk3jW8Lo3WhTnCCE0a1MbBqomsAfIwDdksZoH73QW+sGYD+cShgFC55QWfE6gy3OF\npge1dsWNPlMSHmWn9+g7g3+FjkhKeZFNSb0MKzIvEBE7iJOf85etJpMs9a/425sx\nUcJX33bVdhG51Au3PSs+0jUljoFby28EM717otq8Tkjei2hw1yNNmtws4/NcQlh3\nW6TGBZLb188hUrOOH52p2Cckm8gGgw9hTc9nSLSjQS2pPjVRpTRR4smxMTKND9E=\n=QBYE\n-----END PGP SIGNATURE-----\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: 0x38450DB5.asc\nType: application/pgp-keys\nSize: 14542 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141230/ae058422/attachment.bin>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2014-12-29T22:36:48",
                "message_text_only": "On Monday, December 29, 2014 9:10:20 PM Mike Hearn wrote:\n> How does adding inputs to a coinbase differ from just having pay-to-fee\n> transactions in the block?\n\nPay-to-fee transactions can be \"stolen\" by another block at the same or \ngreater height. Additional inputs to the generation transaction are tied to \nthat block alone.\n\nLuke"
            },
            {
                "author": "Luke Dashjr",
                "date": "2014-12-29T22:35:04",
                "message_text_only": "On Monday, December 29, 2014 7:21:02 PM Sergio Lerner wrote:\n> I propose to allow miners to voluntarily lock funds by letting miners\n> add additional inputs to the coinbase transaction. Currently the\n> coinbase transaction does not allow any real input  to be added (only a\n> pseudo-input).\n\nThis is something I've wanted since 2011, but hasn't been a priority.\n\n> Because sometime in the future (maybe 5-10 years) we may have to deal\n> with problems of securing the blockchain, as the subsidy is lowered. We\n> don't want the number of confirmation blocks to be increased in\n> compensation because Bitcoin won't be able to compete with other payment\n> networks.\n> Then by having this hardfork now, we will be able to soft-fork later to\n> any rule we may came come up with involving deposit bonds,\n> proof-of-stake, and the penalization of double-mining (mining two blocks\n> at the same height) to prevent short-range attacks.\n\nI'm not sure this increases the priority of it.\n\nIf someone feels it's worth the time, I'd suggest coding up a branch that \nhardforks it in at some far-off block height. Even if it doesn't get merged \nright away, at least the code will be available for testing and ready to go \nwhen/if that time comes.\n\nLuke"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2014-12-30T04:51:51",
                "message_text_only": "On Mon, Dec 29, 2014 at 7:21 PM, Sergio Lerner\n<sergiolerner at certimix.com> wrote:\n> I propose to allow miners to voluntarily lock funds by letting miners\n> add additional inputs to the coinbase transaction. Currently the\n> coinbase transaction does not allow any real input  to be added (only a\n> pseudo-input).\n> This is a hard-fork, and we could include it the next time a hardfork is\n> made.\n> The modifications to the code are minimal (no more than 12 lines\n> modified where IsCoinBase() is called), and they generally involve\n> removing code, not adding.\n\n\nIf the motivation is purely enabling different rules in a soft-fork\nthan I think nothing needs to be done.\n\nInstead of providing inputs to a coinbase: you provide an unusual\nanyone can spend transaction in the block which pays to fees; and\nsimultaneously add a soft-forking rule that makes that anyone can\nspend rule no longer anyone can spend.\n\nTo make that more concrete.  E.g. You make your anyone can spend\noutput   \"PUSH<hash of coinbase output script_pubkeys> OP_NOP3\".  Now\nthis anyone can pay transaction is really just a coinbase input.\n\nThe construction is reasonably efficient, and also more flexible-- in\nthat it could control the data under the hash in more flexible ways\nthan available in the existing sighash flags.\n\n\nAs an aside, I'm not sure that I agree with the claim that making\ncoinbases have inputs is a simple modification... as we use one of the\ninputs already as the special coinbase field and at least that must be\nspecial cased."
            },
            {
                "author": "Sergio Lerner",
                "date": "2014-12-30T16:25:24",
                "message_text_only": "On 30/12/2014 01:51 a.m., Gregory Maxwell wrote:\n> On Mon, Dec 29, 2014 at 7:21 PM, Sergio Lerner\n> <sergiolerner at certimix.com> wrote:\n>> I propose to allow miners to voluntarily lock funds by letting miners\n>> add additional inputs to the coinbase transaction. Currently the\n>> coinbase transaction does not allow any real input  to be added (only a\n>> pseudo-input).\n>>\n>\n> To make that more concrete.  E.g. You make your anyone can spend\n> output   \"PUSH<hash of coinbase output script_pubkeys> OP_NOP3\".  Now\n> this anyone can pay transaction is really just a coinbase input.\n\nSlight off-topic:\nThat looks like an abuse of the VM. Even P2SH is an abuse of the VM.\nGavin's OP_EVAL (hard-fork) should had been chosen. I'm taking about a\nsimple change that goes along the lines of Satoshi's original design.\nBitcoin was a beautiful design, and extra complexity is making it ugly.\nWe need Bitcoin to be simple to understand for new programmers so they\ncan keep the project going. It doesn't help the project that one needs\nto be a guru to code for Bitcoin."
            },
            {
                "author": "Gregory Maxwell",
                "date": "2014-12-30T18:28:54",
                "message_text_only": "On Tue, Dec 30, 2014 at 4:25 PM, Sergio Lerner\n<sergiolerner at certimix.com> wrote:\n> Slight off-topic:\n> That looks like an abuse of the VM. Even P2SH is an abuse of the VM.\n> Gavin's OP_EVAL (hard-fork) should had been chosen. I'm taking about a\n> simple change that goes along the lines of Satoshi's original design.\n> Bitcoin was a beautiful design, and extra complexity is making it ugly.\n> We need Bitcoin to be simple to understand for new programmers so they\n> can keep the project going. It doesn't help the project that one needs\n> to be a guru to code for Bitcoin.\n\nSergio there is no \"abuse\" there,  OP_NOP3 in that case would be\nredefined to OP_COINBASE_FOO_CONSISTENCY.\n\n(I say FOO because it's not clear what rule you actually hope to apply there.)\n\nWhat you suggested has no purpose by itself: it would need an\nadditional change which overlays functionality in order to actually do\nsomething. Such a change would likely be \"ugly\"-- it's easy to be\nelegant when you do nothing."
            },
            {
                "author": "Stephen Morse",
                "date": "2014-12-31T18:25:41",
                "message_text_only": "I agree with Gregory Maxwell, I don't think it would be as easy as just\nchanging IsCoinBase(), since there are places where the code assumes that\nthe coinbase's vin doesn't spend any prevouts and/or has size 1. For\nexample, here\n<https://github.com/bitcoin/bitcoin/blob/v0.9.3/src/main.cpp#L617-620> and\nhere <https://github.com/bitcoin/bitcoin/blob/v0.9.3/src/main.cpp#L785-L808>\n.\n\nI think the motivation behind the original suggestion is to have a way to\npay specific miners upon solving a block without risking possibly paying\nother miners through pay-to-fee. What I'm not sure about, though, is why\nnot just send them a transaction once you see that the miner has solved a\nblock? Not a pay-to-fee transaction, a pay to pubkeyhash or whatever type\nof transaction you need to make to send the miner some coins.\n\nAlthough I don't completely understand the motivation for making such\ntransactions, maybe this would this work. Have outputs in the coinbase\ntransaction which have nValue == 0, then only apply the COINBASE_MATURITY\nrule to spending coinbase outputs which have non-zero value. That way you\ncould make a transactions which is only valid after the miner specified\nsolves a block with the coinbase having the same TxID referenced by the new\ntransaction's input. It's still a hard fork, but might be easier than\nallowing the coinbase to spend prevouts. I guess, at that point though, why\nnot just hard fork to allow the coinbase to spend prevouts...\n\nBest,\nStephen\n\nOn Tue, Dec 30, 2014 at 1:28 PM, Gregory Maxwell <gmaxwell at gmail.com> wrote:\n\n> On Tue, Dec 30, 2014 at 4:25 PM, Sergio Lerner\n> <sergiolerner at certimix.com> wrote:\n> > Slight off-topic:\n> > That looks like an abuse of the VM. Even P2SH is an abuse of the VM.\n> > Gavin's OP_EVAL (hard-fork) should had been chosen. I'm taking about a\n> > simple change that goes along the lines of Satoshi's original design.\n> > Bitcoin was a beautiful design, and extra complexity is making it ugly.\n> > We need Bitcoin to be simple to understand for new programmers so they\n> > can keep the project going. It doesn't help the project that one needs\n> > to be a guru to code for Bitcoin.\n>\n> Sergio there is no \"abuse\" there,  OP_NOP3 in that case would be\n> redefined to OP_COINBASE_FOO_CONSISTENCY.\n>\n> (I say FOO because it's not clear what rule you actually hope to apply\n> there.)\n>\n> What you suggested has no purpose by itself: it would need an\n> additional change which overlays functionality in order to actually do\n> something. Such a change would likely be \"ugly\"-- it's easy to be\n> elegant when you do nothing.\n>\n>\n> ------------------------------------------------------------------------------\n> Dive into the World of Parallel Programming! The Go Parallel Website,\n> sponsored by Intel and developed in partnership with Slashdot Media, is\n> your\n> hub for all things parallel software development, from weekly thought\n> leadership blogs to news, videos, case studies, tutorials and more. Take a\n> look and join the conversation now. http://goparallel.sourceforge.net\n> _______________________________________________\n> Bitcoin-development mailing list\n> Bitcoin-development at lists.sourceforge.net\n> https://lists.sourceforge.net/lists/listinfo/bitcoin-development\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141231/83b8f521/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP: Voluntary deposit bonds",
            "categories": [
                "Bitcoin-development"
            ],
            "authors": [
                "Stephen Morse",
                "Mike Hearn",
                "Sergio Lerner",
                "Jorge Tim\u00f3n",
                "Luke Dashjr",
                "Gregory Maxwell",
                "Justus Ranvier"
            ],
            "messages_count": 11,
            "total_messages_chars_count": 14586
        }
    }
]