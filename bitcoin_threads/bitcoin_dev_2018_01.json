[
    {
        "title": "[bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks",
        "thread_messages": [
            {
                "author": "Damian Williamson",
                "date": "2018-01-01T11:04:57",
                "message_text_only": "Happy New Year all.\n\nThis proposal has been further amended with several minor changes and a\nfew additions.\n\nI believe that all known issues raised so far have been sufficiently\naddressed. Either that or, I still have more work to do.\n\n## BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For\nOrdering Transactions In Blocks\n\nSchema: \u00a0\n########## \u00a0\nDocument: BIP Proposal \u00a0\nTitle: UTPFOTIB - Use Transaction Priority For Ordering Transactions In\nBlocks \u00a0\nPublished: 26-12-2017 \u00a0\nRevised: 01-01-2018 \u00a0\nAuthor: Damian Williamson <willtech at live.com.au>\u00a0\u00a0\nLicence: Creative Commons Attribution-ShareAlike 4.0 International\nLicense. \u00a0\nURL: http://thekingjameshrmh.tumblr.com/post/168948530950/bip-proposal-\nutpfotib-use-transaction-priority-for-order\u00a0\u00a0\n##########\n\n### 1. Abstract\n\nThis document proposes to address the issue of transactional\nreliability in Bitcoin, where valid transactions may be stuck in the\ntransaction pool for extended periods or never confirm.\n\nThere are two key issues to be resolved to achieve this:\n\n1.\u00a0\u00a0The current transaction bandwidth limit.\n2.\u00a0\u00a0The current ad-hoc methods of including transactions in blocks\nresulting in variable and confusing confirmation times for valid\ntransactions, including transactions with a valid fee that may never\nconfirm.\n\nIt is important with any change to protect the value of fees as these\nwill eventually be the only payment that miners receive. Rather than an\nauction model for limited bandwidth, the proposal results in a fee for\npriority service auction model.\n\nIt would not be true to suggest that all feedback received so far has\nbeen entirely positive although, most of it has been constructive.\n\nThe previous threads for this proposal are available here: \u00a0\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/s\nubject.html\n\nIn all parts of this proposal, references to a transaction, a valid\ntransaction, a transaction with a valid fee, a valid fee, etc. is\ndefined as any transaction that is otherwise valid with a fee of at\nleast 0.00001000 BTC/KB as defined as the dust level, interpreting from\nBitcoin Core GUI. Transactions with a fee lower than this rate are\nconsidered dust.\n\nIn all parts of this proposal, dust and zero-fee transactions are\nalways ignored and/or excluded unless specifically mentioned.\n\nIt is generally assumed that miners currently prefer to include\ntransactions with higher fees.\n\n### 2. The need for this proposal\n\nWe all must learn to admit that transaction bandwidth is still lurking\nas a serious issue for the operation, reliability, safety, consumer\nacceptance, uptake and, for the value of Bitcoin.\n\nI recently sent a payment which was not urgent so; I chose three-day\ntarget confirmation from the fee recommendation. That transaction has\nstill not confirmed after now more than six days - even waiting twice\nas long seems quite reasonable to me (note for accuracy: it did\neventually confirm). That transaction is a valid transaction; it is not\nrubbish, junk or, spam. Under the current model with transaction\nbandwidth limitation, the longer a transaction waits, the less likely\nit is ever to confirm due to rising transaction numbers and being\npushed back by transactions with rising fees.\n\nI argue that no transactions with fees above the dust level are rubbish\nor junk, only some zero fee transactions might be spam. Having an ever-\nincreasing number of valid transactions that do not confirm as more new\ntransactions with higher fees are created is the opposite of operating\na robust, reliable transaction system.\n\nWhile the miners have discovered a gold mine, it is the service they\nprovide that is valuable. If the service is unreliable they are not\nworth the gold that they mine. This is reflected in the value of\nBitcoin.\n\nBusiness cannot operate with a model where transactions may or may not\nconfirm. Even a business choosing a modest fee has no guarantee that\ntheir valid transaction will not be shuffled down by new transactions\nto the realm of never confirming after it is created. Consumers also\nwill not accept this model as Bitcoin expands. If Bitcoin cannot be a\nreliable payment system for confirmed transactions then consumers, by\nand large, will simply not accept the model once they understand.\nBitcoin will be a dirty payment system, and this will kill the value of\nBitcoin.\n\nUnder the current system, a minority of transactions will eventually be\nthe lucky few who have fees high enough to escape being pushed down the\nlist.\n\nOnce there are more than x transactions (transaction bandwidth limit)\nevery ten minutes, only those choosing twenty-minute confirmation (2\nblocks) from the fee recommendations will have initially at most a\nfifty percent chance of ever having their payment confirm by the time\n2x transactions is reached. Presently, not even using fee\nrecommendations can ensure a sufficiently high fee is paid to ensure\ntransaction confirmation.\n\nI also argue that the current auction model for limited transaction\nbandwidth is wrong, is not suitable for a reliable transaction system\nand, is wrong for Bitcoin. All transactions with valid fees must\nconfirm in due time. Currently, Bitcoin is not a safe way to send\npayments.\n\nI do not believe that consumers and business are against paying fees,\neven high fees. What is required is operational reliability.\n\nThis great issue needs to be resolved for the safety and reliability of\nBitcoin. The time to resolve issues in commerce is before they become\ngreat big issues. The time to resolve this issue is now. We must have\nthe foresight to identify and resolve problems before they trip us\nover.\u00a0\u00a0Simply doubling block sizes every so often is reactionary and is\nnot a reliable permanent solution.\n\nI have written this proposal for a technical solution but, need your\nhelp to write it up to an acceptable standard to be a full BIP.\n\n### 3. The problem\n\nEverybody wants value. Miners want to maximise revenue from fees (and\nwe presume, to minimise block size). Consumers need transaction\nreliability and, (we presume) want low fees.\n\nThe current transaction bandwidth limit is a limiting factor for both.\nAs the operational safety of transactions is limited, so is consumer\nconfidence as they realise the issue and, accordingly, uptake is\nlimited. Fees are artificially inflated due to bandwidth limitations\nwhile failing to provide a full confirmation service for all valid\ntransactions.\n\nCurrent fee recommendations provide no satisfaction for transaction\nreliability and, as Bitcoin scales, this will worsen.\n\nTransactions are included in blocks by miners using whatever basis they\nprefer. We expect that this is usually a fee-based priority. However,\neven transactions with a valid fee may be left in the transaction pool\nfor some time. As transaction bandwidth becomes an issue, not even\nextreme fees can ensure a transaction is processed in a timely manner\nor at all.\n\nBitcoin must be a fully scalable and reliable service, providing full\ntransaction confirmation for every valid transaction.\n\nThe possibility to send a transaction with a fee lower than one that is\nacceptable to allow eventual transaction confirmation should be removed\nfrom the protocol and also from the user interface.\n\nBitcoin should be capable of reliably and inexpensively processing\ncasual transactions, and also priority processing of fee paying at\nauction for priority transactions in the shortest possible timeframe.\n\n### 4. Solution summary\n\n#### Main solution\n\nProvide each valid transaction in the mempool with an individual\ntransaction priority each time before choosing transactions to include\nin the current block. The priority being a function of the fee (on a\ncurve), and the time waiting in the transaction pool (also on a curve)\nout to n days (n = 60 days ?), and extending past n days. The value for\nfee on a curve may need an upper limit. The transaction priority to\nserve as the likelihood of a transaction being included in the current\nblock, and for determining the order in which transactions are tried to\nsee if they will be included.\n\nNodes will need to keep track of when a transaction is first seen. It\nis satisfactory for each node to do this independently provided the\nfull mempool and information survives node restart. If there is a more\nreliable way to determine when a transaction was first seen on the\nnetwork then it should be utilised.\n\n> My current default installation of Bitcoin Core v0.15.1 does not\ncurrently seem to save and load the mempool on restart, despite the\nnotes in the command line options panel that the default for\npersistmempool is 1. In the debug panel, some 90,000 transactions\nbefore restart, some 200 odd shortly after. Manually setting\npersistmempool=1 in the conf file does not seem to make any difference.\nPerhaps it is operating as expected and I am not sure what to observe,\nbut does not seem to be observably saving and loading the mempool on\nrestart. This will need to be resolved.\n\nUse a dynamic target block size to make the current block. This marks a\nshift from using block size or weight to a count of transactions.\nDetermine the target block size using; pre-rollout(current average\nvalid transaction pool size) x ( 1 / (144 x n days ) ) = number of\ntransactions to be included in the current block. The block created\nshould be a minimum 1MB in size regardless if the target block size is\nlower.\n\nIf the created block size consistently contains too few transactions\nand the number of new transactions created is continuously greater than\nthe block size will accommodate then I expect eventually ageing\ntransactions will be over-represented as a portion of the block\ncontents. Once another new node conforming to the proposal makes a\nblock, the block size will be proportionately larger as the transaction\npool has grown.\u00a0\u00a0If block size is too large on average then this will\nshrink the transaction pool.\n\nMiners will likely want to conform to the proposal, since making blocks\nlarger than necessary makes more room in each block potentially\nlowering the highest fees paid for priority service. Always making\nblocks smaller than the proposal requires will in time lower the\nutility value of Bitcoin, a different situation but akin to the\ncurrent. Transactions will still always confirm but with longer and\nlonger wait periods. The auction at the front of the queue for priority\nwill be destroyed as there will be eventually no room in blocks besides\nageing transations and, there will be little value paying higher than\nthe minimum fee. Obviously, neither of these scenarios are in a miner's\ninterests.\n\nWithout a consensus as to what size dynamic block to create,\nenforcement of dynamic block size is not currently possible. It may be\npossible for a consensus to be formed in the future but here I cannot\nspeculate. I can only suggest that it is in the interest of Bitcoin as\na whole and, in the interest of each node to conform to the proposal.\nSome nodes failing to conform to the proposed requirements of dynamic\nsize or transaction priority in this proposal will not be destructive\nto the operation of the proposal.\n\nIf necessary, nodes that have not yet adopted the proposal will just\ncontinue to create standard fixed size unordered blocks, although, if\nthe current mechanisms of block validation include the fixed block size\nthen it is unlikely that these nodes will be able to validate the\nblockchain going forward. In this case a hard fork and a full transfer\nto the new method should be required. If dynamic blocks with ordered\ntransactions will be valid to existing nodes then only a soft fork is\nrequired. There is no proposed change to the internal construction of\nblocks, only to the block size and using an ordered method of\ntransaction selection.\n\n> The default value for mempoolexpiry in Bitcoin Core may in future\nneed to be adjusted to match something more than n days or, perhaps\nusing less than n = 14 days may be a more sensible approach?\n\nAll block created with dynamic size should be verified to ensure\nconformity to a probability distribution curve resulting from the\npriority method. Since the input is a probability, the output should\nconform to a probability distribution.\n\nThe curves used for the priority of transactions would have to be\nappropriate. Perhaps a mathematician with experience in probability can\ndevelop the right formulae. My thinking is a steep curve. I suppose\nthat the probability of all transactions should probably account for a\nsufficient number of inclusions that the target block size is met on\naverage although, it may not always be. As a suggestion, consider\nincluding some dust or zero-fee transactions to pad if each valid\ntransaction is tried and the target block size is not yet met, highest\nBTC transaction value first?\n\n**Explanation of the operation of priority:**\n\n> If transaction priority is, for example, a number between one (low)\nand one-hundred (high) it can be directly understood as the percentage\nchance in one-hundred of a transaction being included in the block.\nUsing probability or likelihood infers that there is some function of\nrandom. Try the transactions in priority order from highest to lowest,\nif random (100) < transaction priority then the transaction is included\nuntil the target block size is met.\u00a0\n\n> To break it down further, if both the fee on a curve value and the\ntime waiting on a curve value are each a number between one and one-\nhundred, a rudimentary method may be to simply multiply those two\nnumbers, to find the priority number. For example, a middle fee\ntransaction waiting thirty days (if n = 60 days) may have a value of\nfive for each part\u00a0\u00a0(yes, just five, the values are on a curve). When\nmultiplied that will give a priority value of twenty-five, or, a\ntwenty-five percent chance at that moment of being included in the\nblock; it will likely be included in one of the next four blocks,\ngetting more likely each chance. If it is still not included then the\nvalue of time waiting will be higher, making for more probability. A\nvery low fee transaction would have a value for the fee of one. It\nwould not be until near sixty-days that the particular low fee\ntransaction has a high likelihood of being included in the block.\n\nIn practice it may be more useful to use numbers representative of one-\nhundred for the highest fee priority curve down to a small fraction of\none for the lowest fee and, from one for a newly seen transaction up to\na proportionately high number above one-hundred for the time waiting\ncurve. It is truely beyond my level of math to resolve probability\ncurves accurately without much trial and error.\n\nThe primary reason for addressing the issue is to ensure transactional\nreliability and scalability while having each valid transaction confirm\nin due time.\n\n#### Pros\n\n*\u00a0\u00a0\u00a0Maximizes transaction reliability.\n*\u00a0\u00a0\u00a0Overcomes transaction bandwidth limit.\n*\u00a0\u00a0\u00a0Fully scalable.\n*\u00a0\u00a0\u00a0Maximizes possibility for consumer and business uptake.\n*\u00a0\u00a0\u00a0Maximizes total fees paid per block without reducing reliability;\nbecause of reliability, in time confidence and overall uptake are\ngreater; therefore, more transactions.\n*\u00a0\u00a0\u00a0Market determines fee paid for transaction priority.\n*\u00a0\u00a0\u00a0Fee recommendations work all the way out to 30 days or greater.\n*\u00a0\u00a0\u00a0Provides additional block entropy; greater security since there is\nless probability of predicting the next block. _Although this is not\nnecessary it is a product of the operation of this proposal._\n\n#### Cons\n\n*\u00a0\u00a0\u00a0Could initially lower total transaction fees per block.\n*\u00a0\u00a0\u00a0Must be first be programmed.\n\n#### Pre-rollout\n\nNodes need to have at a minimum a loose understanding of the average\n(since there is no consensus) size of the transaction pool as a\nrequirement to enable future changes to the way blocks are constructed.\n\nA new network service should be constructed to meet this need. This\nservice makes no changes to any existing operation or function of the\nnode. Initially, Bitcoin Core is a suitable candidate.\n\nFor all operations we count only valid transactions.\n\n**The service must:**\n\n*\u00a0\u00a0\u00a0Have an individual temporary (runtime permanent only) Serial Node\nID.\n*\u00a0\u00a0\u00a0Accept communication of the number of valid transactions in the\nmempool of another valid Bitcoin node along with the Serial Node ID of\nthe node whose value is provided.\n*\u00a0\u00a0\u00a0Disconnect the service from any non-Bitcoin node. Bitcoin Core may\nhandle this already?\n*\u00a0\u00a0\u00a0Expire any value not updated for k minutes (k = 30 minutes?).\n*\u00a0\u00a0\u00a0Broadcast all mempool information the node has every m minutes (m =\n10 minutes?), including its own.\n*\u00a0\u00a0\u00a0Nodes own mempool information should not be broadcast or used in\ncalculation until the node has been up long enough for the mempool to\nnormalise for at least o minutes (o = 300 minutes ?)\n*\u00a0\u00a0\u00a0Alternatively, if loading nodes own full mempool from disk on node\nrestart (o = 30 minutes ?)\n*\u00a0\u00a0\u00a0Only new or updated mempool values should be transmitted to the\nsame node. Updated includes updated with no change.\n*\u00a0\u00a0\u00a0All known mempool information must survive node restart.\n*\u00a0\u00a0\u00a0If the nodes own mempool is not normalised and network information\nis not available to calculate an average just display zero.\n*\u00a0\u00a0\u00a0Internally, the average transaction pool size must return the\ncalculated average if an average is available or, if none is available\njust the number of valid transactions in the node's own mempool\nregardless if it is normalised.\n\nBitcoin Core must use all collated information on mempool size to\ncalculate a figure for the average mempool size.\n\nThe calculated figure should be displayed in the appropriate place in\nthe Debug window alongside the text Network average transactions.\n\nConsideration must be given before development of the network bandwidth\nthis would require. All programming must be consistent with the current\noperation and conventions of Bitcoin Core. Methods must work on all\nplatforms.\n\nAs this new service does not affect any existing service or feature of\nBitcoin or Bitcoin Core, this can technically be programmed now and\nincluded in Bitcoin Core at any time.\n\n### 5. Solution operation\n\nThis is a simplistic view of the operation. The actual operation will\nneed to be determined accurately in a spec for the programmer.\n\n1.\u00a0\u00a0Determine the target block size for the current block.\n2.\u00a0\u00a0Assign a transaction priority to each valid transaction in the\nmempool.\n3.\u00a0\u00a0Select transactions to include in the current block using\nprobability in transaction priority order until the target block size\nis met. If target block size is not met, include dust and zero-fee\ntransactions to pad.\n4.\u00a0\u00a0Solve block.\n5.\u00a0\u00a0Broadcast the current block when it is solved.\n6.\u00a0\u00a0Block is received.\n7.\u00a0\u00a0Block verification process.\n8.\u00a0\u00a0Accept/reject block based on verification result.\n9.\u00a0\u00a0Repeat.\n\n### 6. Closing comments\n\nIt may be possible to verify blocks conform to the proposal by showing\nthat the probability for all transactions included in the block\nstatistically conforms to a probability distribution curve, *if* the\nindividual transaction priority can be recreated. I am not that deep\ninto the mathematics; however, it may also be possible to use a similar\nmethod to do this just based on the fee, that statistically, the block\nconforms to a fee distribution. Any dust and zero-fee transactions\nwould have to be ignored. This solution needs a competent mathematician\nwith experience in probability and statistical distribution.\n\nIt is trivial to this proposal to offer that a node provides the next\nblock size with a block when it is solved. I am not sure that this\ncreates any actual benefit since the provided next block size is only\none node's view, as it is the node may seemingly just as well use its\nown view and create the block. Providing a next block size only adds\nadditional complexity to the required operation, however, perhaps\nproviding the next block size is not trivial in what is accomplished\nand the feature can be included in the operation.\n\nInstead of the pre-rollout network service providing data as to valid\ntransactions in mempool, it could directly provide data as to the\nsuggested next block size if that is preferred, using a similar\noperation as is suggested now and averaging all received suggested next\nblock sizes.\n\nIt may be foreseeable in the future for Bitcoin to operate with a\nnetwork of dedicated full blockchain & mempool servers. This would not\nbe without challenges to overcome but would offer several benefits,\nincluding to the operation of this proposal, and especially as the RAM\nand storage requirements of a full node grows. It is easy to foresee\nthat in just another seven years of operation a Bitcoin Full Node will\nrequire at least 300GB of storage and, if the mempool only doubles in\nsize, over 1GB of RAM.\n\nThere has been some concern expressed over spam and very low fee\ntransactions, and an infinite block size resulting. I hope that for\nthose concerned using the dust level addresses the issue, especially as\nthe value of Bitcoin grows.\n\nNotwithstanding this proposal, all blocks including those with dynamic\nsize each have limited transaction space per block. This proposal\nresults in a fee for priority service auction, where the probability of\na transaction to be included in limited space in the next available\nblock is auctioned to the highest bidders and all other transactions\nmust wait until they reach priority by ageing to gain significant\nprobability. Under this proposal the mempool can grow quite large while\nthe confirmation service continues in a stable and reliable manner.\nSeveral incentives for attackers are removed, where there is no longer\nmultiple potential incentives for unnecessarily filling blocks or\nflooding the mempool with transactions, whether such transactions are\nfraudulent, valid or, otherwise. Adoption of this proposal and\nadherence results in a reliable, stable fee paying transaction\nconfirmation service and a beneficial auction.\n\nThis proposal is necessary. I implore, at the very least, that we use\nsome method that validates full transaction reliability and enables\nscalability of Bitcoin. If not this proposal, an alternative.\n\nI have done as much with this proposal as I feel that I am able so far\nbut continue to take your feedback.\n\nRegards, \u00a0\nDamian Williamson\n\n[![Creative Commons License](https://i.creativecommons.org/l/by-sa/4.0/\n88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/) \u00a0\n<span xmlns:dct=\"http://purl.org/dc/terms/\"\nhref=\"http://purl.org/dc/dcmitype/Text\" property=\"dct:title\"\nrel=\"dct:type\">BIP Proposal: UTPFOTIB - Use Transaction Priority For\nOrdering Transactions In Blocks</span> by [Damian Williamson\n&lt;willtech at live.com.au&gt;](http://thekingjameshrmh.tumblr.com/post/1\n68948530950/bip-proposal-utpfotib-use-transaction-priority-for-order)\nis licensed under a [Creative Commons Attribution-ShareAlike 4.0\nInternational License](http://creativecommons.org/licenses/by-sa/4.0/).\nBased on a work at https://lists.linuxfoundation.org/pipermail/bitcoin-\ndev/2017-\nDecember/015371.html](https://lists.linuxfoundation.org/pipermail/bitco\nin-dev/2017-December/015371.html).\nPermissions beyond the scope of this license may be available at [https\n://opensource.org/licenses/BSD-3-\nClause](https://opensource.org/licenses/BSD-3-Clause)."
            },
            {
                "author": "Damian Williamson",
                "date": "2018-01-04T09:01:10",
                "message_text_only": "This proposal has a new update, mostly minor edits. Additionally, I had a logic flaw in the hard fork / soft fork declaration statement. The specific terms of the CC-BY-SA-4.0 licence the document is published under have now been updated to include additional permissions available under the MIT licence.\n\n\nRecently, on Twitter:\n\nI am looking for a capable analyst/programmer to work on a BIP proposal as co-author. Will need to format several Full BIP's per these BIP process requirements: ( https://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki ) from a BIP Proposal, being two initially for non-consensus full-interoperable pre-rollout on peer service layer & API/RPC layer and, a reference implementation for Bitcoin Core per: ( https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md ). Interested parties please reply via this list thread: ( https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015485.html ) #Bitcoin #BIP\n\n\nRegards,\n\nDamian Williamson\n\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Monday, 1 January 2018 10:04 PM\nTo: bitcoin-dev at lists.linuxfoundation.org\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\nHappy New Year all.\n\nThis proposal has been further amended with several minor changes and a\nfew additions.\n\nI believe that all known issues raised so far have been sufficiently\naddressed. Either that or, I still have more work to do.\n\n## BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For\nOrdering Transactions In Blocks\n\nSchema:\n##########\nDocument: BIP Proposal\nTitle: UTPFOTIB - Use Transaction Priority For Ordering Transactions In\nBlocks\nPublished: 26-12-2017\nRevised: 01-01-2018\nAuthor: Damian Williamson <willtech at live.com.au>\nLicence: Creative Commons Attribution-ShareAlike 4.0 International\nLicense.\nURL: http://thekingjameshrmh.tumblr.com/post/168948530950/bip-proposal-\nutpfotib-use-transaction-priority-for-order\n##########\n\n### 1. Abstract\n\nThis document proposes to address the issue of transactional\nreliability in Bitcoin, where valid transactions may be stuck in the\ntransaction pool for extended periods or never confirm.\n\nThere are two key issues to be resolved to achieve this:\n\n1.  The current transaction bandwidth limit.\n2.  The current ad-hoc methods of including transactions in blocks\nresulting in variable and confusing confirmation times for valid\ntransactions, including transactions with a valid fee that may never\nconfirm.\n\nIt is important with any change to protect the value of fees as these\nwill eventually be the only payment that miners receive. Rather than an\nauction model for limited bandwidth, the proposal results in a fee for\npriority service auction model.\n\nIt would not be true to suggest that all feedback received so far has\nbeen entirely positive although, most of it has been constructive.\n\nThe previous threads for this proposal are available here:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/s\nubject.html\n\nIn all parts of this proposal, references to a transaction, a valid\ntransaction, a transaction with a valid fee, a valid fee, etc. is\ndefined as any transaction that is otherwise valid with a fee of at\nleast 0.00001000 BTC/KB as defined as the dust level, interpreting from\nBitcoin Core GUI. Transactions with a fee lower than this rate are\nconsidered dust.\n\nIn all parts of this proposal, dust and zero-fee transactions are\nalways ignored and/or excluded unless specifically mentioned.\n\nIt is generally assumed that miners currently prefer to include\ntransactions with higher fees.\n\n### 2. The need for this proposal\n\nWe all must learn to admit that transaction bandwidth is still lurking\nas a serious issue for the operation, reliability, safety, consumer\nacceptance, uptake and, for the value of Bitcoin.\n\nI recently sent a payment which was not urgent so; I chose three-day\ntarget confirmation from the fee recommendation. That transaction has\nstill not confirmed after now more than six days - even waiting twice\nas long seems quite reasonable to me (note for accuracy: it did\neventually confirm). That transaction is a valid transaction; it is not\nrubbish, junk or, spam. Under the current model with transaction\nbandwidth limitation, the longer a transaction waits, the less likely\nit is ever to confirm due to rising transaction numbers and being\npushed back by transactions with rising fees.\n\nI argue that no transactions with fees above the dust level are rubbish\nor junk, only some zero fee transactions might be spam. Having an ever-\nincreasing number of valid transactions that do not confirm as more new\ntransactions with higher fees are created is the opposite of operating\na robust, reliable transaction system.\n\nWhile the miners have discovered a gold mine, it is the service they\nprovide that is valuable. If the service is unreliable they are not\nworth the gold that they mine. This is reflected in the value of\nBitcoin.\n\nBusiness cannot operate with a model where transactions may or may not\nconfirm. Even a business choosing a modest fee has no guarantee that\ntheir valid transaction will not be shuffled down by new transactions\nto the realm of never confirming after it is created. Consumers also\nwill not accept this model as Bitcoin expands. If Bitcoin cannot be a\nreliable payment system for confirmed transactions then consumers, by\nand large, will simply not accept the model once they understand.\nBitcoin will be a dirty payment system, and this will kill the value of\nBitcoin.\n\nUnder the current system, a minority of transactions will eventually be\nthe lucky few who have fees high enough to escape being pushed down the\nlist.\n\nOnce there are more than x transactions (transaction bandwidth limit)\nevery ten minutes, only those choosing twenty-minute confirmation (2\nblocks) from the fee recommendations will have initially at most a\nfifty percent chance of ever having their payment confirm by the time\n2x transactions is reached. Presently, not even using fee\nrecommendations can ensure a sufficiently high fee is paid to ensure\ntransaction confirmation.\n\nI also argue that the current auction model for limited transaction\nbandwidth is wrong, is not suitable for a reliable transaction system\nand, is wrong for Bitcoin. All transactions with valid fees must\nconfirm in due time. Currently, Bitcoin is not a safe way to send\npayments.\n\nI do not believe that consumers and business are against paying fees,\neven high fees. What is required is operational reliability.\n\nThis great issue needs to be resolved for the safety and reliability of\nBitcoin. The time to resolve issues in commerce is before they become\ngreat big issues. The time to resolve this issue is now. We must have\nthe foresight to identify and resolve problems before they trip us\nover.  Simply doubling block sizes every so often is reactionary and is\nnot a reliable permanent solution.\n\nI have written this proposal for a technical solution but, need your\nhelp to write it up to an acceptable standard to be a full BIP.\n\n### 3. The problem\n\nEverybody wants value. Miners want to maximise revenue from fees (and\nwe presume, to minimise block size). Consumers need transaction\nreliability and, (we presume) want low fees.\n\nThe current transaction bandwidth limit is a limiting factor for both.\nAs the operational safety of transactions is limited, so is consumer\nconfidence as they realise the issue and, accordingly, uptake is\nlimited. Fees are artificially inflated due to bandwidth limitations\nwhile failing to provide a full confirmation service for all valid\ntransactions.\n\nCurrent fee recommendations provide no satisfaction for transaction\nreliability and, as Bitcoin scales, this will worsen.\n\nTransactions are included in blocks by miners using whatever basis they\nprefer. We expect that this is usually a fee-based priority. However,\neven transactions with a valid fee may be left in the transaction pool\nfor some time. As transaction bandwidth becomes an issue, not even\nextreme fees can ensure a transaction is processed in a timely manner\nor at all.\n\nBitcoin must be a fully scalable and reliable service, providing full\ntransaction confirmation for every valid transaction.\n\nThe possibility to send a transaction with a fee lower than one that is\nacceptable to allow eventual transaction confirmation should be removed\nfrom the protocol and also from the user interface.\n\nBitcoin should be capable of reliably and inexpensively processing\ncasual transactions, and also priority processing of fee paying at\nauction for priority transactions in the shortest possible timeframe.\n\n### 4. Solution summary\n\n#### Main solution\n\nProvide each valid transaction in the mempool with an individual\ntransaction priority each time before choosing transactions to include\nin the current block. The priority being a function of the fee (on a\ncurve), and the time waiting in the transaction pool (also on a curve)\nout to n days (n = 60 days ?), and extending past n days. The value for\nfee on a curve may need an upper limit. The transaction priority to\nserve as the likelihood of a transaction being included in the current\nblock, and for determining the order in which transactions are tried to\nsee if they will be included.\n\nNodes will need to keep track of when a transaction is first seen. It\nis satisfactory for each node to do this independently provided the\nfull mempool and information survives node restart. If there is a more\nreliable way to determine when a transaction was first seen on the\nnetwork then it should be utilised.\n\n> My current default installation of Bitcoin Core v0.15.1 does not\ncurrently seem to save and load the mempool on restart, despite the\nnotes in the command line options panel that the default for\npersistmempool is 1. In the debug panel, some 90,000 transactions\nbefore restart, some 200 odd shortly after. Manually setting\npersistmempool=1 in the conf file does not seem to make any difference.\nPerhaps it is operating as expected and I am not sure what to observe,\nbut does not seem to be observably saving and loading the mempool on\nrestart. This will need to be resolved.\n\nUse a dynamic target block size to make the current block. This marks a\nshift from using block size or weight to a count of transactions.\nDetermine the target block size using; pre-rollout(current average\nvalid transaction pool size) x ( 1 / (144 x n days ) ) = number of\ntransactions to be included in the current block. The block created\nshould be a minimum 1MB in size regardless if the target block size is\nlower.\n\nIf the created block size consistently contains too few transactions\nand the number of new transactions created is continuously greater than\nthe block size will accommodate then I expect eventually ageing\ntransactions will be over-represented as a portion of the block\ncontents. Once another new node conforming to the proposal makes a\nblock, the block size will be proportionately larger as the transaction\npool has grown.  If block size is too large on average then this will\nshrink the transaction pool.\n\nMiners will likely want to conform to the proposal, since making blocks\nlarger than necessary makes more room in each block potentially\nlowering the highest fees paid for priority service. Always making\nblocks smaller than the proposal requires will in time lower the\nutility value of Bitcoin, a different situation but akin to the\ncurrent. Transactions will still always confirm but with longer and\nlonger wait periods. The auction at the front of the queue for priority\nwill be destroyed as there will be eventually no room in blocks besides\nageing transations and, there will be little value paying higher than\nthe minimum fee. Obviously, neither of these scenarios are in a miner's\ninterests.\n\nWithout a consensus as to what size dynamic block to create,\nenforcement of dynamic block size is not currently possible. It may be\npossible for a consensus to be formed in the future but here I cannot\nspeculate. I can only suggest that it is in the interest of Bitcoin as\na whole and, in the interest of each node to conform to the proposal.\nSome nodes failing to conform to the proposed requirements of dynamic\nsize or transaction priority in this proposal will not be destructive\nto the operation of the proposal.\n\nIf necessary, nodes that have not yet adopted the proposal will just\ncontinue to create standard fixed size unordered blocks, although, if\nthe current mechanisms of block validation include the fixed block size\nthen it is unlikely that these nodes will be able to validate the\nblockchain going forward. In this case a hard fork and a full transfer\nto the new method should be required. If dynamic blocks with ordered\ntransactions will be valid to existing nodes then only a soft fork is\nrequired. There is no proposed change to the internal construction of\nblocks, only to the block size and using an ordered method of\ntransaction selection.\n\n> The default value for mempoolexpiry in Bitcoin Core may in future\nneed to be adjusted to match something more than n days or, perhaps\nusing less than n = 14 days may be a more sensible approach?\n\nAll block created with dynamic size should be verified to ensure\nconformity to a probability distribution curve resulting from the\npriority method. Since the input is a probability, the output should\nconform to a probability distribution.\n\nThe curves used for the priority of transactions would have to be\nappropriate. Perhaps a mathematician with experience in probability can\ndevelop the right formulae. My thinking is a steep curve. I suppose\nthat the probability of all transactions should probably account for a\nsufficient number of inclusions that the target block size is met on\naverage although, it may not always be. As a suggestion, consider\nincluding some dust or zero-fee transactions to pad if each valid\ntransaction is tried and the target block size is not yet met, highest\nBTC transaction value first?\n\n**Explanation of the operation of priority:**\n\n> If transaction priority is, for example, a number between one (low)\nand one-hundred (high) it can be directly understood as the percentage\nchance in one-hundred of a transaction being included in the block.\nUsing probability or likelihood infers that there is some function of\nrandom. Try the transactions in priority order from highest to lowest,\nif random (100) < transaction priority then the transaction is included\nuntil the target block size is met.\n\n> To break it down further, if both the fee on a curve value and the\ntime waiting on a curve value are each a number between one and one-\nhundred, a rudimentary method may be to simply multiply those two\nnumbers, to find the priority number. For example, a middle fee\ntransaction waiting thirty days (if n = 60 days) may have a value of\nfive for each part  (yes, just five, the values are on a curve). When\nmultiplied that will give a priority value of twenty-five, or, a\ntwenty-five percent chance at that moment of being included in the\nblock; it will likely be included in one of the next four blocks,\ngetting more likely each chance. If it is still not included then the\nvalue of time waiting will be higher, making for more probability. A\nvery low fee transaction would have a value for the fee of one. It\nwould not be until near sixty-days that the particular low fee\ntransaction has a high likelihood of being included in the block.\n\nIn practice it may be more useful to use numbers representative of one-\nhundred for the highest fee priority curve down to a small fraction of\none for the lowest fee and, from one for a newly seen transaction up to\na proportionately high number above one-hundred for the time waiting\ncurve. It is truely beyond my level of math to resolve probability\ncurves accurately without much trial and error.\n\nThe primary reason for addressing the issue is to ensure transactional\nreliability and scalability while having each valid transaction confirm\nin due time.\n\n#### Pros\n\n*   Maximizes transaction reliability.\n*   Overcomes transaction bandwidth limit.\n*   Fully scalable.\n*   Maximizes possibility for consumer and business uptake.\n*   Maximizes total fees paid per block without reducing reliability;\nbecause of reliability, in time confidence and overall uptake are\ngreater; therefore, more transactions.\n*   Market determines fee paid for transaction priority.\n*   Fee recommendations work all the way out to 30 days or greater.\n*   Provides additional block entropy; greater security since there is\nless probability of predicting the next block. _Although this is not\nnecessary it is a product of the operation of this proposal._\n\n#### Cons\n\n*   Could initially lower total transaction fees per block.\n*   Must be first be programmed.\n\n#### Pre-rollout\n\nNodes need to have at a minimum a loose understanding of the average\n(since there is no consensus) size of the transaction pool as a\nrequirement to enable future changes to the way blocks are constructed.\n\nA new network service should be constructed to meet this need. This\nservice makes no changes to any existing operation or function of the\nnode. Initially, Bitcoin Core is a suitable candidate.\n\nFor all operations we count only valid transactions.\n\n**The service must:**\n\n*   Have an individual temporary (runtime permanent only) Serial Node\nID.\n*   Accept communication of the number of valid transactions in the\nmempool of another valid Bitcoin node along with the Serial Node ID of\nthe node whose value is provided.\n*   Disconnect the service from any non-Bitcoin node. Bitcoin Core may\nhandle this already?\n*   Expire any value not updated for k minutes (k = 30 minutes?).\n*   Broadcast all mempool information the node has every m minutes (m =\n10 minutes?), including its own.\n*   Nodes own mempool information should not be broadcast or used in\ncalculation until the node has been up long enough for the mempool to\nnormalise for at least o minutes (o = 300 minutes ?)\n*   Alternatively, if loading nodes own full mempool from disk on node\nrestart (o = 30 minutes ?)\n*   Only new or updated mempool values should be transmitted to the\nsame node. Updated includes updated with no change.\n*   All known mempool information must survive node restart.\n*   If the nodes own mempool is not normalised and network information\nis not available to calculate an average just display zero.\n*   Internally, the average transaction pool size must return the\ncalculated average if an average is available or, if none is available\njust the number of valid transactions in the node's own mempool\nregardless if it is normalised.\n\nBitcoin Core must use all collated information on mempool size to\ncalculate a figure for the average mempool size.\n\nThe calculated figure should be displayed in the appropriate place in\nthe Debug window alongside the text Network average transactions.\n\nConsideration must be given before development of the network bandwidth\nthis would require. All programming must be consistent with the current\noperation and conventions of Bitcoin Core. Methods must work on all\nplatforms.\n\nAs this new service does not affect any existing service or feature of\nBitcoin or Bitcoin Core, this can technically be programmed now and\nincluded in Bitcoin Core at any time.\n\n### 5. Solution operation\n\nThis is a simplistic view of the operation. The actual operation will\nneed to be determined accurately in a spec for the programmer.\n\n1.  Determine the target block size for the current block.\n2.  Assign a transaction priority to each valid transaction in the\nmempool.\n3.  Select transactions to include in the current block using\nprobability in transaction priority order until the target block size\nis met. If target block size is not met, include dust and zero-fee\ntransactions to pad.\n4.  Solve block.\n5.  Broadcast the current block when it is solved.\n6.  Block is received.\n7.  Block verification process.\n8.  Accept/reject block based on verification result.\n9.  Repeat.\n\n### 6. Closing comments\n\nIt may be possible to verify blocks conform to the proposal by showing\nthat the probability for all transactions included in the block\nstatistically conforms to a probability distribution curve, *if* the\nindividual transaction priority can be recreated. I am not that deep\ninto the mathematics; however, it may also be possible to use a similar\nmethod to do this just based on the fee, that statistically, the block\nconforms to a fee distribution. Any dust and zero-fee transactions\nwould have to be ignored. This solution needs a competent mathematician\nwith experience in probability and statistical distribution.\n\nIt is trivial to this proposal to offer that a node provides the next\nblock size with a block when it is solved. I am not sure that this\ncreates any actual benefit since the provided next block size is only\none node's view, as it is the node may seemingly just as well use its\nown view and create the block. Providing a next block size only adds\nadditional complexity to the required operation, however, perhaps\nproviding the next block size is not trivial in what is accomplished\nand the feature can be included in the operation.\n\nInstead of the pre-rollout network service providing data as to valid\ntransactions in mempool, it could directly provide data as to the\nsuggested next block size if that is preferred, using a similar\noperation as is suggested now and averaging all received suggested next\nblock sizes.\n\nIt may be foreseeable in the future for Bitcoin to operate with a\nnetwork of dedicated full blockchain & mempool servers. This would not\nbe without challenges to overcome but would offer several benefits,\nincluding to the operation of this proposal, and especially as the RAM\nand storage requirements of a full node grows. It is easy to foresee\nthat in just another seven years of operation a Bitcoin Full Node will\nrequire at least 300GB of storage and, if the mempool only doubles in\nsize, over 1GB of RAM.\n\nThere has been some concern expressed over spam and very low fee\ntransactions, and an infinite block size resulting. I hope that for\nthose concerned using the dust level addresses the issue, especially as\nthe value of Bitcoin grows.\n\nNotwithstanding this proposal, all blocks including those with dynamic\nsize each have limited transaction space per block. This proposal\nresults in a fee for priority service auction, where the probability of\na transaction to be included in limited space in the next available\nblock is auctioned to the highest bidders and all other transactions\nmust wait until they reach priority by ageing to gain significant\nprobability. Under this proposal the mempool can grow quite large while\nthe confirmation service continues in a stable and reliable manner.\nSeveral incentives for attackers are removed, where there is no longer\nmultiple potential incentives for unnecessarily filling blocks or\nflooding the mempool with transactions, whether such transactions are\nfraudulent, valid or, otherwise. Adoption of this proposal and\nadherence results in a reliable, stable fee paying transaction\nconfirmation service and a beneficial auction.\n\nThis proposal is necessary. I implore, at the very least, that we use\nsome method that validates full transaction reliability and enables\nscalability of Bitcoin. If not this proposal, an alternative.\n\nI have done as much with this proposal as I feel that I am able so far\nbut continue to take your feedback.\n\nRegards,\nDamian Williamson\n\n[![Creative Commons License](https://i.creativecommons.org/l/by-sa/4.0/\n88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)\n<span xmlns:dct=\"http://purl.org/dc/terms/\"\nhref=\"http://purl.org/dc/dcmitype/Text\" property=\"dct:title\"\nrel=\"dct:type\">BIP Proposal: UTPFOTIB - Use Transaction Priority For\nOrdering Transactions In Blocks</span> by [Damian Williamson\n&lt;willtech at live.com.au&gt;](http://thekingjameshrmh.tumblr.com/post/1\n68948530950/bip-proposal-utpfotib-use-transaction-priority-for-order)\nis licensed under a [Creative Commons Attribution-ShareAlike 4.0\nInternational License](http://creativecommons.org/licenses/by-sa/4.0/).\nBased on a work at https://lists.linuxfoundation.org/pipermail/bitcoin-\ndev/2017-\nDecember/015371.html](https://lists.linuxfoundation.org/pipermail/bitco\nin-dev/2017-December/015371.html).\nPermissions beyond the scope of this license may be available at [https\n://opensource.org/licenses/BSD-3-\nClause](https://opensource.org/licenses/BSD-3-Clause).\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180104/fd3232c0/attachment-0001.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2018-01-19T23:25:43",
                "message_text_only": "An example curve:\n\nThe curve curently described here is ineffective at acheiving the requirements. It seems to be not nearly steep enough resulting in too many inclusions (as it happens, this may not metter - needs further evaluation) and, the lower end values seem problematically small but, results in a number between 100 for the highest fee BTC/KB and a small fraction of 1 for the lowest. This math needs to be improved.\n\n\npf(tx) = sin2((fx-(fl-0.00000001))/(fh-(fl-0.00000001))*1.570796326795)*100\n\n\npf is the calculated priority number for the fee for tx the specifc valid transaction.\nfx is the fee in BTC/KB for the specific transaction.\nfl is the lowest valid fee in BTC/KB currently in the nodes mempool.\nfh is the highest valid fee in BTC/KB currently in the nodes mempool.\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Thursday, 4 January 2018 8:01:10 PM\nTo: Bitcoin Protocol Discussion\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n\nThis proposal has a new update, mostly minor edits. Additionally, I had a logic flaw in the hard fork / soft fork declaration statement. The specific terms of the CC-BY-SA-4.0 licence the document is published under have now been updated to include additional permissions available under the MIT licence.\n\n\nRecently, on Twitter:\n\nI am looking for a capable analyst/programmer to work on a BIP proposal as co-author. Will need to format several Full BIP's per these BIP process requirements: ( https://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki ) from a BIP Proposal, being two initially for non-consensus full-interoperable pre-rollout on peer service layer & API/RPC layer and, a reference implementation for Bitcoin Core per: ( https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md ). Interested parties please reply via this list thread: ( https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015485.html ) #Bitcoin #BIP\n\n\nRegards,\n\nDamian Williamson\n\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Monday, 1 January 2018 10:04 PM\nTo: bitcoin-dev at lists.linuxfoundation.org\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\nHappy New Year all.\n\nThis proposal has been further amended with several minor changes and a\nfew additions.\n\nI believe that all known issues raised so far have been sufficiently\naddressed. Either that or, I still have more work to do.\n\n## BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For\nOrdering Transactions In Blocks\n\nSchema:\n##########\nDocument: BIP Proposal\nTitle: UTPFOTIB - Use Transaction Priority For Ordering Transactions In\nBlocks\nPublished: 26-12-2017\nRevised: 01-01-2018\nAuthor: Damian Williamson <willtech at live.com.au>\nLicence: Creative Commons Attribution-ShareAlike 4.0 International\nLicense.\nURL: http://thekingjameshrmh.tumblr.com/post/168948530950/bip-proposal-\nutpfotib-use-transaction-priority-for-order\n##########\n\n### 1. Abstract\n\nThis document proposes to address the issue of transactional\nreliability in Bitcoin, where valid transactions may be stuck in the\ntransaction pool for extended periods or never confirm.\n\nThere are two key issues to be resolved to achieve this:\n\n1.  The current transaction bandwidth limit.\n2.  The current ad-hoc methods of including transactions in blocks\nresulting in variable and confusing confirmation times for valid\ntransactions, including transactions with a valid fee that may never\nconfirm.\n\nIt is important with any change to protect the value of fees as these\nwill eventually be the only payment that miners receive. Rather than an\nauction model for limited bandwidth, the proposal results in a fee for\npriority service auction model.\n\nIt would not be true to suggest that all feedback received so far has\nbeen entirely positive although, most of it has been constructive.\n\nThe previous threads for this proposal are available here:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/s\nubject.html\n\nIn all parts of this proposal, references to a transaction, a valid\ntransaction, a transaction with a valid fee, a valid fee, etc. is\ndefined as any transaction that is otherwise valid with a fee of at\nleast 0.00001000 BTC/KB as defined as the dust level, interpreting from\nBitcoin Core GUI. Transactions with a fee lower than this rate are\nconsidered dust.\n\nIn all parts of this proposal, dust and zero-fee transactions are\nalways ignored and/or excluded unless specifically mentioned.\n\nIt is generally assumed that miners currently prefer to include\ntransactions with higher fees.\n\n### 2. The need for this proposal\n\nWe all must learn to admit that transaction bandwidth is still lurking\nas a serious issue for the operation, reliability, safety, consumer\nacceptance, uptake and, for the value of Bitcoin.\n\nI recently sent a payment which was not urgent so; I chose three-day\ntarget confirmation from the fee recommendation. That transaction has\nstill not confirmed after now more than six days - even waiting twice\nas long seems quite reasonable to me (note for accuracy: it did\neventually confirm). That transaction is a valid transaction; it is not\nrubbish, junk or, spam. Under the current model with transaction\nbandwidth limitation, the longer a transaction waits, the less likely\nit is ever to confirm due to rising transaction numbers and being\npushed back by transactions with rising fees.\n\nI argue that no transactions with fees above the dust level are rubbish\nor junk, only some zero fee transactions might be spam. Having an ever-\nincreasing number of valid transactions that do not confirm as more new\ntransactions with higher fees are created is the opposite of operating\na robust, reliable transaction system.\n\nWhile the miners have discovered a gold mine, it is the service they\nprovide that is valuable. If the service is unreliable they are not\nworth the gold that they mine. This is reflected in the value of\nBitcoin.\n\nBusiness cannot operate with a model where transactions may or may not\nconfirm. Even a business choosing a modest fee has no guarantee that\ntheir valid transaction will not be shuffled down by new transactions\nto the realm of never confirming after it is created. Consumers also\nwill not accept this model as Bitcoin expands. If Bitcoin cannot be a\nreliable payment system for confirmed transactions then consumers, by\nand large, will simply not accept the model once they understand.\nBitcoin will be a dirty payment system, and this will kill the value of\nBitcoin.\n\nUnder the current system, a minority of transactions will eventually be\nthe lucky few who have fees high enough to escape being pushed down the\nlist.\n\nOnce there are more than x transactions (transaction bandwidth limit)\nevery ten minutes, only those choosing twenty-minute confirmation (2\nblocks) from the fee recommendations will have initially at most a\nfifty percent chance of ever having their payment confirm by the time\n2x transactions is reached. Presently, not even using fee\nrecommendations can ensure a sufficiently high fee is paid to ensure\ntransaction confirmation.\n\nI also argue that the current auction model for limited transaction\nbandwidth is wrong, is not suitable for a reliable transaction system\nand, is wrong for Bitcoin. All transactions with valid fees must\nconfirm in due time. Currently, Bitcoin is not a safe way to send\npayments.\n\nI do not believe that consumers and business are against paying fees,\neven high fees. What is required is operational reliability.\n\nThis great issue needs to be resolved for the safety and reliability of\nBitcoin. The time to resolve issues in commerce is before they become\ngreat big issues. The time to resolve this issue is now. We must have\nthe foresight to identify and resolve problems before they trip us\nover.  Simply doubling block sizes every so often is reactionary and is\nnot a reliable permanent solution.\n\nI have written this proposal for a technical solution but, need your\nhelp to write it up to an acceptable standard to be a full BIP.\n\n### 3. The problem\n\nEverybody wants value. Miners want to maximise revenue from fees (and\nwe presume, to minimise block size). Consumers need transaction\nreliability and, (we presume) want low fees.\n\nThe current transaction bandwidth limit is a limiting factor for both.\nAs the operational safety of transactions is limited, so is consumer\nconfidence as they realise the issue and, accordingly, uptake is\nlimited. Fees are artificially inflated due to bandwidth limitations\nwhile failing to provide a full confirmation service for all valid\ntransactions.\n\nCurrent fee recommendations provide no satisfaction for transaction\nreliability and, as Bitcoin scales, this will worsen.\n\nTransactions are included in blocks by miners using whatever basis they\nprefer. We expect that this is usually a fee-based priority. However,\neven transactions with a valid fee may be left in the transaction pool\nfor some time. As transaction bandwidth becomes an issue, not even\nextreme fees can ensure a transaction is processed in a timely manner\nor at all.\n\nBitcoin must be a fully scalable and reliable service, providing full\ntransaction confirmation for every valid transaction.\n\nThe possibility to send a transaction with a fee lower than one that is\nacceptable to allow eventual transaction confirmation should be removed\nfrom the protocol and also from the user interface.\n\nBitcoin should be capable of reliably and inexpensively processing\ncasual transactions, and also priority processing of fee paying at\nauction for priority transactions in the shortest possible timeframe.\n\n### 4. Solution summary\n\n#### Main solution\n\nProvide each valid transaction in the mempool with an individual\ntransaction priority each time before choosing transactions to include\nin the current block. The priority being a function of the fee (on a\ncurve), and the time waiting in the transaction pool (also on a curve)\nout to n days (n = 60 days ?), and extending past n days. The value for\nfee on a curve may need an upper limit. The transaction priority to\nserve as the likelihood of a transaction being included in the current\nblock, and for determining the order in which transactions are tried to\nsee if they will be included.\n\nNodes will need to keep track of when a transaction is first seen. It\nis satisfactory for each node to do this independently provided the\nfull mempool and information survives node restart. If there is a more\nreliable way to determine when a transaction was first seen on the\nnetwork then it should be utilised.\n\n> My current default installation of Bitcoin Core v0.15.1 does not\ncurrently seem to save and load the mempool on restart, despite the\nnotes in the command line options panel that the default for\npersistmempool is 1. In the debug panel, some 90,000 transactions\nbefore restart, some 200 odd shortly after. Manually setting\npersistmempool=1 in the conf file does not seem to make any difference.\nPerhaps it is operating as expected and I am not sure what to observe,\nbut does not seem to be observably saving and loading the mempool on\nrestart. This will need to be resolved.\n\nUse a dynamic target block size to make the current block. This marks a\nshift from using block size or weight to a count of transactions.\nDetermine the target block size using; pre-rollout(current average\nvalid transaction pool size) x ( 1 / (144 x n days ) ) = number of\ntransactions to be included in the current block. The block created\nshould be a minimum 1MB in size regardless if the target block size is\nlower.\n\nIf the created block size consistently contains too few transactions\nand the number of new transactions created is continuously greater than\nthe block size will accommodate then I expect eventually ageing\ntransactions will be over-represented as a portion of the block\ncontents. Once another new node conforming to the proposal makes a\nblock, the block size will be proportionately larger as the transaction\npool has grown.  If block size is too large on average then this will\nshrink the transaction pool.\n\nMiners will likely want to conform to the proposal, since making blocks\nlarger than necessary makes more room in each block potentially\nlowering the highest fees paid for priority service. Always making\nblocks smaller than the proposal requires will in time lower the\nutility value of Bitcoin, a different situation but akin to the\ncurrent. Transactions will still always confirm but with longer and\nlonger wait periods. The auction at the front of the queue for priority\nwill be destroyed as there will be eventually no room in blocks besides\nageing transations and, there will be little value paying higher than\nthe minimum fee. Obviously, neither of these scenarios are in a miner's\ninterests.\n\nWithout a consensus as to what size dynamic block to create,\nenforcement of dynamic block size is not currently possible. It may be\npossible for a consensus to be formed in the future but here I cannot\nspeculate. I can only suggest that it is in the interest of Bitcoin as\na whole and, in the interest of each node to conform to the proposal.\nSome nodes failing to conform to the proposed requirements of dynamic\nsize or transaction priority in this proposal will not be destructive\nto the operation of the proposal.\n\nIf necessary, nodes that have not yet adopted the proposal will just\ncontinue to create standard fixed size unordered blocks, although, if\nthe current mechanisms of block validation include the fixed block size\nthen it is unlikely that these nodes will be able to validate the\nblockchain going forward. In this case a hard fork and a full transfer\nto the new method should be required. If dynamic blocks with ordered\ntransactions will be valid to existing nodes then only a soft fork is\nrequired. There is no proposed change to the internal construction of\nblocks, only to the block size and using an ordered method of\ntransaction selection.\n\n> The default value for mempoolexpiry in Bitcoin Core may in future\nneed to be adjusted to match something more than n days or, perhaps\nusing less than n = 14 days may be a more sensible approach?\n\nAll block created with dynamic size should be verified to ensure\nconformity to a probability distribution curve resulting from the\npriority method. Since the input is a probability, the output should\nconform to a probability distribution.\n\nThe curves used for the priority of transactions would have to be\nappropriate. Perhaps a mathematician with experience in probability can\ndevelop the right formulae. My thinking is a steep curve. I suppose\nthat the probability of all transactions should probably account for a\nsufficient number of inclusions that the target block size is met on\naverage although, it may not always be. As a suggestion, consider\nincluding some dust or zero-fee transactions to pad if each valid\ntransaction is tried and the target block size is not yet met, highest\nBTC transaction value first?\n\n**Explanation of the operation of priority:**\n\n> If transaction priority is, for example, a number between one (low)\nand one-hundred (high) it can be directly understood as the percentage\nchance in one-hundred of a transaction being included in the block.\nUsing probability or likelihood infers that there is some function of\nrandom. Try the transactions in priority order from highest to lowest,\nif random (100) < transaction priority then the transaction is included\nuntil the target block size is met.\n\n> To break it down further, if both the fee on a curve value and the\ntime waiting on a curve value are each a number between one and one-\nhundred, a rudimentary method may be to simply multiply those two\nnumbers, to find the priority number. For example, a middle fee\ntransaction waiting thirty days (if n = 60 days) may have a value of\nfive for each part  (yes, just five, the values are on a curve). When\nmultiplied that will give a priority value of twenty-five, or, a\ntwenty-five percent chance at that moment of being included in the\nblock; it will likely be included in one of the next four blocks,\ngetting more likely each chance. If it is still not included then the\nvalue of time waiting will be higher, making for more probability. A\nvery low fee transaction would have a value for the fee of one. It\nwould not be until near sixty-days that the particular low fee\ntransaction has a high likelihood of being included in the block.\n\nIn practice it may be more useful to use numbers representative of one-\nhundred for the highest fee priority curve down to a small fraction of\none for the lowest fee and, from one for a newly seen transaction up to\na proportionately high number above one-hundred for the time waiting\ncurve. It is truely beyond my level of math to resolve probability\ncurves accurately without much trial and error.\n\nThe primary reason for addressing the issue is to ensure transactional\nreliability and scalability while having each valid transaction confirm\nin due time.\n\n#### Pros\n\n*   Maximizes transaction reliability.\n*   Overcomes transaction bandwidth limit.\n*   Fully scalable.\n*   Maximizes possibility for consumer and business uptake.\n*   Maximizes total fees paid per block without reducing reliability;\nbecause of reliability, in time confidence and overall uptake are\ngreater; therefore, more transactions.\n*   Market determines fee paid for transaction priority.\n*   Fee recommendations work all the way out to 30 days or greater.\n*   Provides additional block entropy; greater security since there is\nless probability of predicting the next block. _Although this is not\nnecessary it is a product of the operation of this proposal._\n\n#### Cons\n\n*   Could initially lower total transaction fees per block.\n*   Must be first be programmed.\n\n#### Pre-rollout\n\nNodes need to have at a minimum a loose understanding of the average\n(since there is no consensus) size of the transaction pool as a\nrequirement to enable future changes to the way blocks are constructed.\n\nA new network service should be constructed to meet this need. This\nservice makes no changes to any existing operation or function of the\nnode. Initially, Bitcoin Core is a suitable candidate.\n\nFor all operations we count only valid transactions.\n\n**The service must:**\n\n*   Have an individual temporary (runtime permanent only) Serial Node\nID.\n*   Accept communication of the number of valid transactions in the\nmempool of another valid Bitcoin node along with the Serial Node ID of\nthe node whose value is provided.\n*   Disconnect the service from any non-Bitcoin node. Bitcoin Core may\nhandle this already?\n*   Expire any value not updated for k minutes (k = 30 minutes?).\n*   Broadcast all mempool information the node has every m minutes (m =\n10 minutes?), including its own.\n*   Nodes own mempool information should not be broadcast or used in\ncalculation until the node has been up long enough for the mempool to\nnormalise for at least o minutes (o = 300 minutes ?)\n*   Alternatively, if loading nodes own full mempool from disk on node\nrestart (o = 30 minutes ?)\n*   Only new or updated mempool values should be transmitted to the\nsame node. Updated includes updated with no change.\n*   All known mempool information must survive node restart.\n*   If the nodes own mempool is not normalised and network information\nis not available to calculate an average just display zero.\n*   Internally, the average transaction pool size must return the\ncalculated average if an average is available or, if none is available\njust the number of valid transactions in the node's own mempool\nregardless if it is normalised.\n\nBitcoin Core must use all collated information on mempool size to\ncalculate a figure for the average mempool size.\n\nThe calculated figure should be displayed in the appropriate place in\nthe Debug window alongside the text Network average transactions.\n\nConsideration must be given before development of the network bandwidth\nthis would require. All programming must be consistent with the current\noperation and conventions of Bitcoin Core. Methods must work on all\nplatforms.\n\nAs this new service does not affect any existing service or feature of\nBitcoin or Bitcoin Core, this can technically be programmed now and\nincluded in Bitcoin Core at any time.\n\n### 5. Solution operation\n\nThis is a simplistic view of the operation. The actual operation will\nneed to be determined accurately in a spec for the programmer.\n\n1.  Determine the target block size for the current block.\n2.  Assign a transaction priority to each valid transaction in the\nmempool.\n3.  Select transactions to include in the current block using\nprobability in transaction priority order until the target block size\nis met. If target block size is not met, include dust and zero-fee\ntransactions to pad.\n4.  Solve block.\n5.  Broadcast the current block when it is solved.\n6.  Block is received.\n7.  Block verification process.\n8.  Accept/reject block based on verification result.\n9.  Repeat.\n\n### 6. Closing comments\n\nIt may be possible to verify blocks conform to the proposal by showing\nthat the probability for all transactions included in the block\nstatistically conforms to a probability distribution curve, *if* the\nindividual transaction priority can be recreated. I am not that deep\ninto the mathematics; however, it may also be possible to use a similar\nmethod to do this just based on the fee, that statistically, the block\nconforms to a fee distribution. Any dust and zero-fee transactions\nwould have to be ignored. This solution needs a competent mathematician\nwith experience in probability and statistical distribution.\n\nIt is trivial to this proposal to offer that a node provides the next\nblock size with a block when it is solved. I am not sure that this\ncreates any actual benefit since the provided next block size is only\none node's view, as it is the node may seemingly just as well use its\nown view and create the block. Providing a next block size only adds\nadditional complexity to the required operation, however, perhaps\nproviding the next block size is not trivial in what is accomplished\nand the feature can be included in the operation.\n\nInstead of the pre-rollout network service providing data as to valid\ntransactions in mempool, it could directly provide data as to the\nsuggested next block size if that is preferred, using a similar\noperation as is suggested now and averaging all received suggested next\nblock sizes.\n\nIt may be foreseeable in the future for Bitcoin to operate with a\nnetwork of dedicated full blockchain & mempool servers. This would not\nbe without challenges to overcome but would offer several benefits,\nincluding to the operation of this proposal, and especially as the RAM\nand storage requirements of a full node grows. It is easy to foresee\nthat in just another seven years of operation a Bitcoin Full Node will\nrequire at least 300GB of storage and, if the mempool only doubles in\nsize, over 1GB of RAM.\n\nThere has been some concern expressed over spam and very low fee\ntransactions, and an infinite block size resulting. I hope that for\nthose concerned using the dust level addresses the issue, especially as\nthe value of Bitcoin grows.\n\nNotwithstanding this proposal, all blocks including those with dynamic\nsize each have limited transaction space per block. This proposal\nresults in a fee for priority service auction, where the probability of\na transaction to be included in limited space in the next available\nblock is auctioned to the highest bidders and all other transactions\nmust wait until they reach priority by ageing to gain significant\nprobability. Under this proposal the mempool can grow quite large while\nthe confirmation service continues in a stable and reliable manner.\nSeveral incentives for attackers are removed, where there is no longer\nmultiple potential incentives for unnecessarily filling blocks or\nflooding the mempool with transactions, whether such transactions are\nfraudulent, valid or, otherwise. Adoption of this proposal and\nadherence results in a reliable, stable fee paying transaction\nconfirmation service and a beneficial auction.\n\nThis proposal is necessary. I implore, at the very least, that we use\nsome method that validates full transaction reliability and enables\nscalability of Bitcoin. If not this proposal, an alternative.\n\nI have done as much with this proposal as I feel that I am able so far\nbut continue to take your feedback.\n\nRegards,\nDamian Williamson\n\n[![Creative Commons License](https://i.creativecommons.org/l/by-sa/4.0/\n88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)\n<span xmlns:dct=\"http://purl.org/dc/terms/\"\nhref=\"http://purl.org/dc/dcmitype/Text\" property=\"dct:title\"\nrel=\"dct:type\">BIP Proposal: UTPFOTIB - Use Transaction Priority For\nOrdering Transactions In Blocks</span> by [Damian Williamson\n&lt;willtech at live.com.au&gt;](http://thekingjameshrmh.tumblr.com/post/1\n68948530950/bip-proposal-utpfotib-use-transaction-priority-for-order)\nis licensed under a [Creative Commons Attribution-ShareAlike 4.0\nInternational License](http://creativecommons.org/licenses/by-sa/4.0/).\nBased on a work at https://lists.linuxfoundation.org/pipermail/bitcoin-\ndev/2017-\nDecember/015371.html](https://lists.linuxfoundation.org/pipermail/bitco\nin-dev/2017-December/015371.html).\nPermissions beyond the scope of this license may be available at [https\n://opensource.org/licenses/BSD-3-\nClause](https://opensource.org/licenses/BSD-3-Clause).\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180119/bfea8a86/attachment-0001.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2018-01-20T12:04:20",
                "message_text_only": "Tried a different approach for the curves, would appreciate it if someone has the energy to work on this and help me to resolve it a bit more scientifically:\n\n\np(tx) = (((((fx - (fl - 0.00000001)) / (fh - (fl - 0.00000001))) * 100) + 1) ^ y) + (((((wx - 0.9) / ((86400 * n) - 0.9)) * 100) + 1) ^ y)\n\np is the calculated priority number for tx the specific valid transaction.\nfx is the fee in BTC/KB for the specific transaction.\nfl is the lowest valid fee in BTC/KB currently in the nodes mempool.\nfh is the highest valid fee in BTC/KB currently in the nodes mempool.\nwx is the current wait in seconds for tx the specific valid transaction.\nn is the number of days maximum wait consensus value.\ny can be 10 or, y can be a further developed to be a formula based on the number of required inclusions to vary the steepness of the curve as the mempool size varies.\n\nIn the next step, the random value must be:\nif random(101^y) < p then transaction is included;\n\nRegards,\nDamian Williamson\n\n\n________________________________\nFrom: Damian Williamson <willtech at live.com.au>\nSent: Saturday, 20 January 2018 10:25:43 AM\nTo: Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n\nAn example curve:\n\nThe curve curently described here is ineffective at acheiving the requirements. It seems to be not nearly steep enough resulting in too many inclusions (as it happens, this may not metter - needs further evaluation) and, the lower end values seem problematically small but, results in a number between 100 for the highest fee BTC/KB and a small fraction of 1 for the lowest. This math needs to be improved.\n\n\npf(tx) = sin2((fx-(fl-0.00000001))/(fh-(fl-0.00000001))*1.570796326795)*100\n\n\npf is the calculated priority number for the fee for tx the specifc valid transaction.\nfx is the fee in BTC/KB for the specific transaction.\nfl is the lowest valid fee in BTC/KB currently in the nodes mempool.\nfh is the highest valid fee in BTC/KB currently in the nodes mempool.\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Thursday, 4 January 2018 8:01:10 PM\nTo: Bitcoin Protocol Discussion\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n\nThis proposal has a new update, mostly minor edits. Additionally, I had a logic flaw in the hard fork / soft fork declaration statement. The specific terms of the CC-BY-SA-4.0 licence the document is published under have now been updated to include additional permissions available under the MIT licence.\n\n\nRecently, on Twitter:\n\nI am looking for a capable analyst/programmer to work on a BIP proposal as co-author. Will need to format several Full BIP's per these BIP process requirements: ( https://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki ) from a BIP Proposal, being two initially for non-consensus full-interoperable pre-rollout on peer service layer & API/RPC layer and, a reference implementation for Bitcoin Core per: ( https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md ). Interested parties please reply via this list thread: ( https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015485.html ) #Bitcoin #BIP\n\n\nRegards,\n\nDamian Williamson\n\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Monday, 1 January 2018 10:04 PM\nTo: bitcoin-dev at lists.linuxfoundation.org\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\nHappy New Year all.\n\nThis proposal has been further amended with several minor changes and a\nfew additions.\n\nI believe that all known issues raised so far have been sufficiently\naddressed. Either that or, I still have more work to do.\n\n## BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For\nOrdering Transactions In Blocks\n\nSchema:\n##########\nDocument: BIP Proposal\nTitle: UTPFOTIB - Use Transaction Priority For Ordering Transactions In\nBlocks\nPublished: 26-12-2017\nRevised: 01-01-2018\nAuthor: Damian Williamson <willtech at live.com.au>\nLicence: Creative Commons Attribution-ShareAlike 4.0 International\nLicense.\nURL: http://thekingjameshrmh.tumblr.com/post/168948530950/bip-proposal-\nutpfotib-use-transaction-priority-for-order\n##########\n\n### 1. Abstract\n\nThis document proposes to address the issue of transactional\nreliability in Bitcoin, where valid transactions may be stuck in the\ntransaction pool for extended periods or never confirm.\n\nThere are two key issues to be resolved to achieve this:\n\n1.  The current transaction bandwidth limit.\n2.  The current ad-hoc methods of including transactions in blocks\nresulting in variable and confusing confirmation times for valid\ntransactions, including transactions with a valid fee that may never\nconfirm.\n\nIt is important with any change to protect the value of fees as these\nwill eventually be the only payment that miners receive. Rather than an\nauction model for limited bandwidth, the proposal results in a fee for\npriority service auction model.\n\nIt would not be true to suggest that all feedback received so far has\nbeen entirely positive although, most of it has been constructive.\n\nThe previous threads for this proposal are available here:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/s\nubject.html\n\nIn all parts of this proposal, references to a transaction, a valid\ntransaction, a transaction with a valid fee, a valid fee, etc. is\ndefined as any transaction that is otherwise valid with a fee of at\nleast 0.00001000 BTC/KB as defined as the dust level, interpreting from\nBitcoin Core GUI. Transactions with a fee lower than this rate are\nconsidered dust.\n\nIn all parts of this proposal, dust and zero-fee transactions are\nalways ignored and/or excluded unless specifically mentioned.\n\nIt is generally assumed that miners currently prefer to include\ntransactions with higher fees.\n\n### 2. The need for this proposal\n\nWe all must learn to admit that transaction bandwidth is still lurking\nas a serious issue for the operation, reliability, safety, consumer\nacceptance, uptake and, for the value of Bitcoin.\n\nI recently sent a payment which was not urgent so; I chose three-day\ntarget confirmation from the fee recommendation. That transaction has\nstill not confirmed after now more than six days - even waiting twice\nas long seems quite reasonable to me (note for accuracy: it did\neventually confirm). That transaction is a valid transaction; it is not\nrubbish, junk or, spam. Under the current model with transaction\nbandwidth limitation, the longer a transaction waits, the less likely\nit is ever to confirm due to rising transaction numbers and being\npushed back by transactions with rising fees.\n\nI argue that no transactions with fees above the dust level are rubbish\nor junk, only some zero fee transactions might be spam. Having an ever-\nincreasing number of valid transactions that do not confirm as more new\ntransactions with higher fees are created is the opposite of operating\na robust, reliable transaction system.\n\nWhile the miners have discovered a gold mine, it is the service they\nprovide that is valuable. If the service is unreliable they are not\nworth the gold that they mine. This is reflected in the value of\nBitcoin.\n\nBusiness cannot operate with a model where transactions may or may not\nconfirm. Even a business choosing a modest fee has no guarantee that\ntheir valid transaction will not be shuffled down by new transactions\nto the realm of never confirming after it is created. Consumers also\nwill not accept this model as Bitcoin expands. If Bitcoin cannot be a\nreliable payment system for confirmed transactions then consumers, by\nand large, will simply not accept the model once they understand.\nBitcoin will be a dirty payment system, and this will kill the value of\nBitcoin.\n\nUnder the current system, a minority of transactions will eventually be\nthe lucky few who have fees high enough to escape being pushed down the\nlist.\n\nOnce there are more than x transactions (transaction bandwidth limit)\nevery ten minutes, only those choosing twenty-minute confirmation (2\nblocks) from the fee recommendations will have initially at most a\nfifty percent chance of ever having their payment confirm by the time\n2x transactions is reached. Presently, not even using fee\nrecommendations can ensure a sufficiently high fee is paid to ensure\ntransaction confirmation.\n\nI also argue that the current auction model for limited transaction\nbandwidth is wrong, is not suitable for a reliable transaction system\nand, is wrong for Bitcoin. All transactions with valid fees must\nconfirm in due time. Currently, Bitcoin is not a safe way to send\npayments.\n\nI do not believe that consumers and business are against paying fees,\neven high fees. What is required is operational reliability.\n\nThis great issue needs to be resolved for the safety and reliability of\nBitcoin. The time to resolve issues in commerce is before they become\ngreat big issues. The time to resolve this issue is now. We must have\nthe foresight to identify and resolve problems before they trip us\nover.  Simply doubling block sizes every so often is reactionary and is\nnot a reliable permanent solution.\n\nI have written this proposal for a technical solution but, need your\nhelp to write it up to an acceptable standard to be a full BIP.\n\n### 3. The problem\n\nEverybody wants value. Miners want to maximise revenue from fees (and\nwe presume, to minimise block size). Consumers need transaction\nreliability and, (we presume) want low fees.\n\nThe current transaction bandwidth limit is a limiting factor for both.\nAs the operational safety of transactions is limited, so is consumer\nconfidence as they realise the issue and, accordingly, uptake is\nlimited. Fees are artificially inflated due to bandwidth limitations\nwhile failing to provide a full confirmation service for all valid\ntransactions.\n\nCurrent fee recommendations provide no satisfaction for transaction\nreliability and, as Bitcoin scales, this will worsen.\n\nTransactions are included in blocks by miners using whatever basis they\nprefer. We expect that this is usually a fee-based priority. However,\neven transactions with a valid fee may be left in the transaction pool\nfor some time. As transaction bandwidth becomes an issue, not even\nextreme fees can ensure a transaction is processed in a timely manner\nor at all.\n\nBitcoin must be a fully scalable and reliable service, providing full\ntransaction confirmation for every valid transaction.\n\nThe possibility to send a transaction with a fee lower than one that is\nacceptable to allow eventual transaction confirmation should be removed\nfrom the protocol and also from the user interface.\n\nBitcoin should be capable of reliably and inexpensively processing\ncasual transactions, and also priority processing of fee paying at\nauction for priority transactions in the shortest possible timeframe.\n\n### 4. Solution summary\n\n#### Main solution\n\nProvide each valid transaction in the mempool with an individual\ntransaction priority each time before choosing transactions to include\nin the current block. The priority being a function of the fee (on a\ncurve), and the time waiting in the transaction pool (also on a curve)\nout to n days (n = 60 days ?), and extending past n days. The value for\nfee on a curve may need an upper limit. The transaction priority to\nserve as the likelihood of a transaction being included in the current\nblock, and for determining the order in which transactions are tried to\nsee if they will be included.\n\nNodes will need to keep track of when a transaction is first seen. It\nis satisfactory for each node to do this independently provided the\nfull mempool and information survives node restart. If there is a more\nreliable way to determine when a transaction was first seen on the\nnetwork then it should be utilised.\n\n> My current default installation of Bitcoin Core v0.15.1 does not\ncurrently seem to save and load the mempool on restart, despite the\nnotes in the command line options panel that the default for\npersistmempool is 1. In the debug panel, some 90,000 transactions\nbefore restart, some 200 odd shortly after. Manually setting\npersistmempool=1 in the conf file does not seem to make any difference.\nPerhaps it is operating as expected and I am not sure what to observe,\nbut does not seem to be observably saving and loading the mempool on\nrestart. This will need to be resolved.\n\nUse a dynamic target block size to make the current block. This marks a\nshift from using block size or weight to a count of transactions.\nDetermine the target block size using; pre-rollout(current average\nvalid transaction pool size) x ( 1 / (144 x n days ) ) = number of\ntransactions to be included in the current block. The block created\nshould be a minimum 1MB in size regardless if the target block size is\nlower.\n\nIf the created block size consistently contains too few transactions\nand the number of new transactions created is continuously greater than\nthe block size will accommodate then I expect eventually ageing\ntransactions will be over-represented as a portion of the block\ncontents. Once another new node conforming to the proposal makes a\nblock, the block size will be proportionately larger as the transaction\npool has grown.  If block size is too large on average then this will\nshrink the transaction pool.\n\nMiners will likely want to conform to the proposal, since making blocks\nlarger than necessary makes more room in each block potentially\nlowering the highest fees paid for priority service. Always making\nblocks smaller than the proposal requires will in time lower the\nutility value of Bitcoin, a different situation but akin to the\ncurrent. Transactions will still always confirm but with longer and\nlonger wait periods. The auction at the front of the queue for priority\nwill be destroyed as there will be eventually no room in blocks besides\nageing transations and, there will be little value paying higher than\nthe minimum fee. Obviously, neither of these scenarios are in a miner's\ninterests.\n\nWithout a consensus as to what size dynamic block to create,\nenforcement of dynamic block size is not currently possible. It may be\npossible for a consensus to be formed in the future but here I cannot\nspeculate. I can only suggest that it is in the interest of Bitcoin as\na whole and, in the interest of each node to conform to the proposal.\nSome nodes failing to conform to the proposed requirements of dynamic\nsize or transaction priority in this proposal will not be destructive\nto the operation of the proposal.\n\nIf necessary, nodes that have not yet adopted the proposal will just\ncontinue to create standard fixed size unordered blocks, although, if\nthe current mechanisms of block validation include the fixed block size\nthen it is unlikely that these nodes will be able to validate the\nblockchain going forward. In this case a hard fork and a full transfer\nto the new method should be required. If dynamic blocks with ordered\ntransactions will be valid to existing nodes then only a soft fork is\nrequired. There is no proposed change to the internal construction of\nblocks, only to the block size and using an ordered method of\ntransaction selection.\n\n> The default value for mempoolexpiry in Bitcoin Core may in future\nneed to be adjusted to match something more than n days or, perhaps\nusing less than n = 14 days may be a more sensible approach?\n\nAll block created with dynamic size should be verified to ensure\nconformity to a probability distribution curve resulting from the\npriority method. Since the input is a probability, the output should\nconform to a probability distribution.\n\nThe curves used for the priority of transactions would have to be\nappropriate. Perhaps a mathematician with experience in probability can\ndevelop the right formulae. My thinking is a steep curve. I suppose\nthat the probability of all transactions should probably account for a\nsufficient number of inclusions that the target block size is met on\naverage although, it may not always be. As a suggestion, consider\nincluding some dust or zero-fee transactions to pad if each valid\ntransaction is tried and the target block size is not yet met, highest\nBTC transaction value first?\n\n**Explanation of the operation of priority:**\n\n> If transaction priority is, for example, a number between one (low)\nand one-hundred (high) it can be directly understood as the percentage\nchance in one-hundred of a transaction being included in the block.\nUsing probability or likelihood infers that there is some function of\nrandom. Try the transactions in priority order from highest to lowest,\nif random (100) < transaction priority then the transaction is included\nuntil the target block size is met.\n\n> To break it down further, if both the fee on a curve value and the\ntime waiting on a curve value are each a number between one and one-\nhundred, a rudimentary method may be to simply multiply those two\nnumbers, to find the priority number. For example, a middle fee\ntransaction waiting thirty days (if n = 60 days) may have a value of\nfive for each part  (yes, just five, the values are on a curve). When\nmultiplied that will give a priority value of twenty-five, or, a\ntwenty-five percent chance at that moment of being included in the\nblock; it will likely be included in one of the next four blocks,\ngetting more likely each chance. If it is still not included then the\nvalue of time waiting will be higher, making for more probability. A\nvery low fee transaction would have a value for the fee of one. It\nwould not be until near sixty-days that the particular low fee\ntransaction has a high likelihood of being included in the block.\n\nIn practice it may be more useful to use numbers representative of one-\nhundred for the highest fee priority curve down to a small fraction of\none for the lowest fee and, from one for a newly seen transaction up to\na proportionately high number above one-hundred for the time waiting\ncurve. It is truely beyond my level of math to resolve probability\ncurves accurately without much trial and error.\n\nThe primary reason for addressing the issue is to ensure transactional\nreliability and scalability while having each valid transaction confirm\nin due time.\n\n#### Pros\n\n*   Maximizes transaction reliability.\n*   Overcomes transaction bandwidth limit.\n*   Fully scalable.\n*   Maximizes possibility for consumer and business uptake.\n*   Maximizes total fees paid per block without reducing reliability;\nbecause of reliability, in time confidence and overall uptake are\ngreater; therefore, more transactions.\n*   Market determines fee paid for transaction priority.\n*   Fee recommendations work all the way out to 30 days or greater.\n*   Provides additional block entropy; greater security since there is\nless probability of predicting the next block. _Although this is not\nnecessary it is a product of the operation of this proposal._\n\n#### Cons\n\n*   Could initially lower total transaction fees per block.\n*   Must be first be programmed.\n\n#### Pre-rollout\n\nNodes need to have at a minimum a loose understanding of the average\n(since there is no consensus) size of the transaction pool as a\nrequirement to enable future changes to the way blocks are constructed.\n\nA new network service should be constructed to meet this need. This\nservice makes no changes to any existing operation or function of the\nnode. Initially, Bitcoin Core is a suitable candidate.\n\nFor all operations we count only valid transactions.\n\n**The service must:**\n\n*   Have an individual temporary (runtime permanent only) Serial Node\nID.\n*   Accept communication of the number of valid transactions in the\nmempool of another valid Bitcoin node along with the Serial Node ID of\nthe node whose value is provided.\n*   Disconnect the service from any non-Bitcoin node. Bitcoin Core may\nhandle this already?\n*   Expire any value not updated for k minutes (k = 30 minutes?).\n*   Broadcast all mempool information the node has every m minutes (m =\n10 minutes?), including its own.\n*   Nodes own mempool information should not be broadcast or used in\ncalculation until the node has been up long enough for the mempool to\nnormalise for at least o minutes (o = 300 minutes ?)\n*   Alternatively, if loading nodes own full mempool from disk on node\nrestart (o = 30 minutes ?)\n*   Only new or updated mempool values should be transmitted to the\nsame node. Updated includes updated with no change.\n*   All known mempool information must survive node restart.\n*   If the nodes own mempool is not normalised and network information\nis not available to calculate an average just display zero.\n*   Internally, the average transaction pool size must return the\ncalculated average if an average is available or, if none is available\njust the number of valid transactions in the node's own mempool\nregardless if it is normalised.\n\nBitcoin Core must use all collated information on mempool size to\ncalculate a figure for the average mempool size.\n\nThe calculated figure should be displayed in the appropriate place in\nthe Debug window alongside the text Network average transactions.\n\nConsideration must be given before development of the network bandwidth\nthis would require. All programming must be consistent with the current\noperation and conventions of Bitcoin Core. Methods must work on all\nplatforms.\n\nAs this new service does not affect any existing service or feature of\nBitcoin or Bitcoin Core, this can technically be programmed now and\nincluded in Bitcoin Core at any time.\n\n### 5. Solution operation\n\nThis is a simplistic view of the operation. The actual operation will\nneed to be determined accurately in a spec for the programmer.\n\n1.  Determine the target block size for the current block.\n2.  Assign a transaction priority to each valid transaction in the\nmempool.\n3.  Select transactions to include in the current block using\nprobability in transaction priority order until the target block size\nis met. If target block size is not met, include dust and zero-fee\ntransactions to pad.\n4.  Solve block.\n5.  Broadcast the current block when it is solved.\n6.  Block is received.\n7.  Block verification process.\n8.  Accept/reject block based on verification result.\n9.  Repeat.\n\n### 6. Closing comments\n\nIt may be possible to verify blocks conform to the proposal by showing\nthat the probability for all transactions included in the block\nstatistically conforms to a probability distribution curve, *if* the\nindividual transaction priority can be recreated. I am not that deep\ninto the mathematics; however, it may also be possible to use a similar\nmethod to do this just based on the fee, that statistically, the block\nconforms to a fee distribution. Any dust and zero-fee transactions\nwould have to be ignored. This solution needs a competent mathematician\nwith experience in probability and statistical distribution.\n\nIt is trivial to this proposal to offer that a node provides the next\nblock size with a block when it is solved. I am not sure that this\ncreates any actual benefit since the provided next block size is only\none node's view, as it is the node may seemingly just as well use its\nown view and create the block. Providing a next block size only adds\nadditional complexity to the required operation, however, perhaps\nproviding the next block size is not trivial in what is accomplished\nand the feature can be included in the operation.\n\nInstead of the pre-rollout network service providing data as to valid\ntransactions in mempool, it could directly provide data as to the\nsuggested next block size if that is preferred, using a similar\noperation as is suggested now and averaging all received suggested next\nblock sizes.\n\nIt may be foreseeable in the future for Bitcoin to operate with a\nnetwork of dedicated full blockchain & mempool servers. This would not\nbe without challenges to overcome but would offer several benefits,\nincluding to the operation of this proposal, and especially as the RAM\nand storage requirements of a full node grows. It is easy to foresee\nthat in just another seven years of operation a Bitcoin Full Node will\nrequire at least 300GB of storage and, if the mempool only doubles in\nsize, over 1GB of RAM.\n\nThere has been some concern expressed over spam and very low fee\ntransactions, and an infinite block size resulting. I hope that for\nthose concerned using the dust level addresses the issue, especially as\nthe value of Bitcoin grows.\n\nNotwithstanding this proposal, all blocks including those with dynamic\nsize each have limited transaction space per block. This proposal\nresults in a fee for priority service auction, where the probability of\na transaction to be included in limited space in the next available\nblock is auctioned to the highest bidders and all other transactions\nmust wait until they reach priority by ageing to gain significant\nprobability. Under this proposal the mempool can grow quite large while\nthe confirmation service continues in a stable and reliable manner.\nSeveral incentives for attackers are removed, where there is no longer\nmultiple potential incentives for unnecessarily filling blocks or\nflooding the mempool with transactions, whether such transactions are\nfraudulent, valid or, otherwise. Adoption of this proposal and\nadherence results in a reliable, stable fee paying transaction\nconfirmation service and a beneficial auction.\n\nThis proposal is necessary. I implore, at the very least, that we use\nsome method that validates full transaction reliability and enables\nscalability of Bitcoin. If not this proposal, an alternative.\n\nI have done as much with this proposal as I feel that I am able so far\nbut continue to take your feedback.\n\nRegards,\nDamian Williamson\n\n[![Creative Commons License](https://i.creativecommons.org/l/by-sa/4.0/\n88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)\n<span xmlns:dct=\"http://purl.org/dc/terms/\"\nhref=\"http://purl.org/dc/dcmitype/Text\" property=\"dct:title\"\nrel=\"dct:type\">BIP Proposal: UTPFOTIB - Use Transaction Priority For\nOrdering Transactions In Blocks</span> by [Damian Williamson\n&lt;willtech at live.com.au&gt;](http://thekingjameshrmh.tumblr.com/post/1\n68948530950/bip-proposal-utpfotib-use-transaction-priority-for-order)\nis licensed under a [Creative Commons Attribution-ShareAlike 4.0\nInternational License](http://creativecommons.org/licenses/by-sa/4.0/).\nBased on a work at https://lists.linuxfoundation.org/pipermail/bitcoin-\ndev/2017-\nDecember/015371.html](https://lists.linuxfoundation.org/pipermail/bitco\nin-dev/2017-December/015371.html).\nPermissions beyond the scope of this license may be available at [https\n://opensource.org/licenses/BSD-3-\nClause](https://opensource.org/licenses/BSD-3-Clause).\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180120/4ce97afd/attachment-0001.html>"
            },
            {
                "author": "Alan Evans",
                "date": "2018-01-20T14:46:41",
                "message_text_only": "I don't see any modifications to the proposal that addresses the issue that\nminers will always be free to choose their own priority that a few people\nbrought up before.\n\nI understand you think it's in the miners best long-term interest to follow\nthese rules, but even if a miner agrees with you, if that miner thinks the\nother miners are following the fee curve, they will know it makes no\noverall difference if they cheat (you can't prove how long a miner has had\na transaction in their mempool).\n\nThe opportunity to cheat, the anonymity of mining, the low negative effect\nof a single cheating instance, all combined with a financial incentive to\ncheat means that cheating will be rife.\n\n\nOn Sat, Jan 20, 2018 at 8:04 AM, Damian Williamson via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Tried a different approach for the curves, would appreciate it if someone\n> has the energy to work on this and help me to resolve it a bit more\n> scientifically:\n>\n>\n> p(tx) = (((((fx - (fl - 0.00000001)) / (fh - (fl - 0.00000001))) * 100) +\n> 1) ^ y) + (((((wx - 0.9) / ((86400 * n) - 0.9)) * 100) + 1) ^ y)\n>\n> p is the calculated priority number for tx the specific valid transaction.\n> fx is the fee in BTC/KB for the specific transaction.\n> fl is the lowest valid fee in BTC/KB currently in the nodes mempool.\n> fh is the highest valid fee in BTC/KB currently in the nodes mempool.\n> wx is the current wait in seconds for tx the specific valid transaction.\n> n is the number of days maximum wait consensus value.\n> y can be 10 or, y can be a further developed to be a formula based on the\n> number of required inclusions to vary the steepness of the curve as the\n> mempool size varies.\n>\n> In the next step, the random value must be:\n> if random(101^y) < p then transaction is included;\n>\n> Regards,\n> Damian Williamson\n>\n> ------------------------------\n> *From:* Damian Williamson <willtech at live.com.au>\n> *Sent:* Saturday, 20 January 2018 10:25:43 AM\n> *To:* Bitcoin Protocol Discussion\n> *Subject:* Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use\n> Transaction Priority For Ordering Transactions In Blocks\n>\n>\n> An example curve:\n>\n> The curve curently described here is ineffective at acheiving the\n> requirements. It seems to be not nearly steep enough resulting in too many\n> inclusions (as it happens, this may not metter - needs further evaluation)\n> and, the lower end values seem problematically small but, results in a\n> number between 100 for the highest fee BTC/KB and a small fraction of 1 for\n> the lowest. This math needs to be improved.\n>\n>\n> pf(tx) = sin2((fx-(fl-0.00000001))/(fh-(fl-0.00000001))*1.\n> 570796326795)*100\n>\n>\n> pf is the calculated priority number for the fee for tx the specifc valid\n> transaction.\n> fx is the fee in BTC/KB for the specific transaction.\n> fl is the lowest valid fee in BTC/KB currently in the nodes mempool.\n> fh is the highest valid fee in BTC/KB currently in the nodes mempool.\n>\n> ------------------------------\n> *From:* bitcoin-dev-bounces at lists.linuxfoundation.org <\n> bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian\n> Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n> *Sent:* Thursday, 4 January 2018 8:01:10 PM\n> *To:* Bitcoin Protocol Discussion\n> *Subject:* [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use\n> Transaction Priority For Ordering Transactions In Blocks\n>\n>\n> This proposal has a new update, mostly minor edits. Additionally, I had a\n> logic flaw in the hard fork / soft fork declaration statement. The specific\n> terms of the CC-BY-SA-4.0 licence the document is published under have\n> now been updated to include additional permissions available under the MIT\n> licence.\n>\n>\n> Recently, on Twitter:\n>\n> I am looking for a capable analyst/programmer to work on a BIP proposal as\n> co-author. Will need to format several Full BIP's per these BIP process\n> requirements: ( https://github.com/bitcoin/bips/blob/master/bip-0002.\n> mediawiki ) from a BIP Proposal, being two initially for non-consensus\n> full-interoperable pre-rollout on peer service layer & API/RPC layer and, a\n> reference implementation for Bitcoin Core per: (\n> https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md ).\n> Interested parties please reply via this list thread: (\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/\n> 2017-December/015485.html ) #Bitcoin #BIP\n>\n>\n> Regards,\n>\n> Damian Williamson\n>\n>\n> ------------------------------\n> *From:* bitcoin-dev-bounces at lists.linuxfoundation.org <\n> bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian\n> Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n> *Sent:* Monday, 1 January 2018 10:04 PM\n> *To:* bitcoin-dev at lists.linuxfoundation.org\n> *Subject:* [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use\n> Transaction Priority For Ordering Transactions In Blocks\n>\n> Happy New Year all.\n>\n> This proposal has been further amended with several minor changes and a\n> few additions.\n>\n> I believe that all known issues raised so far have been sufficiently\n> addressed. Either that or, I still have more work to do.\n>\n> ## BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For\n> Ordering Transactions In Blocks\n>\n> Schema:\n> ##########\n> Document: BIP Proposal\n> Title: UTPFOTIB - Use Transaction Priority For Ordering Transactions In\n> Blocks\n> Published: 26-12-2017\n> Revised: 01-01-2018\n> Author: Damian Williamson <willtech at live.com.au>\n> Licence: Creative Commons Attribution-ShareAlike 4.0 International\n> License.\n> URL: http://thekingjameshrmh.tumblr.com/post/168948530950/bip-proposal-\n> utpfotib-use-transaction-priority-for-order\n> ##########\n>\n> ### 1. Abstract\n>\n> This document proposes to address the issue of transactional\n> reliability in Bitcoin, where valid transactions may be stuck in the\n> transaction pool for extended periods or never confirm.\n>\n> There are two key issues to be resolved to achieve this:\n>\n> 1.  The current transaction bandwidth limit.\n> 2.  The current ad-hoc methods of including transactions in blocks\n> resulting in variable and confusing confirmation times for valid\n> transactions, including transactions with a valid fee that may never\n> confirm.\n>\n> It is important with any change to protect the value of fees as these\n> will eventually be the only payment that miners receive. Rather than an\n> auction model for limited bandwidth, the proposal results in a fee for\n> priority service auction model.\n>\n> It would not be true to suggest that all feedback received so far has\n> been entirely positive although, most of it has been constructive.\n>\n> The previous threads for this proposal are available here:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/s\n> ubject.html\n>\n> In all parts of this proposal, references to a transaction, a valid\n> transaction, a transaction with a valid fee, a valid fee, etc. is\n> defined as any transaction that is otherwise valid with a fee of at\n> least 0.00001000 BTC/KB as defined as the dust level, interpreting from\n> Bitcoin Core GUI. Transactions with a fee lower than this rate are\n> considered dust.\n>\n> In all parts of this proposal, dust and zero-fee transactions are\n> always ignored and/or excluded unless specifically mentioned.\n>\n> It is generally assumed that miners currently prefer to include\n> transactions with higher fees.\n>\n> ### 2. The need for this proposal\n>\n> We all must learn to admit that transaction bandwidth is still lurking\n> as a serious issue for the operation, reliability, safety, consumer\n> acceptance, uptake and, for the value of Bitcoin.\n>\n> I recently sent a payment which was not urgent so; I chose three-day\n> target confirmation from the fee recommendation. That transaction has\n> still not confirmed after now more than six days - even waiting twice\n> as long seems quite reasonable to me (note for accuracy: it did\n> eventually confirm). That transaction is a valid transaction; it is not\n> rubbish, junk or, spam. Under the current model with transaction\n> bandwidth limitation, the longer a transaction waits, the less likely\n> it is ever to confirm due to rising transaction numbers and being\n> pushed back by transactions with rising fees.\n>\n> I argue that no transactions with fees above the dust level are rubbish\n> or junk, only some zero fee transactions might be spam. Having an ever-\n> increasing number of valid transactions that do not confirm as more new\n> transactions with higher fees are created is the opposite of operating\n> a robust, reliable transaction system.\n>\n> While the miners have discovered a gold mine, it is the service they\n> provide that is valuable. If the service is unreliable they are not\n> worth the gold that they mine. This is reflected in the value of\n> Bitcoin.\n>\n> Business cannot operate with a model where transactions may or may not\n> confirm. Even a business choosing a modest fee has no guarantee that\n> their valid transaction will not be shuffled down by new transactions\n> to the realm of never confirming after it is created. Consumers also\n> will not accept this model as Bitcoin expands. If Bitcoin cannot be a\n> reliable payment system for confirmed transactions then consumers, by\n> and large, will simply not accept the model once they understand.\n> Bitcoin will be a dirty payment system, and this will kill the value of\n> Bitcoin.\n>\n> Under the current system, a minority of transactions will eventually be\n> the lucky few who have fees high enough to escape being pushed down the\n> list.\n>\n> Once there are more than x transactions (transaction bandwidth limit)\n> every ten minutes, only those choosing twenty-minute confirmation (2\n> blocks) from the fee recommendations will have initially at most a\n> fifty percent chance of ever having their payment confirm by the time\n> 2x transactions is reached. Presently, not even using fee\n> recommendations can ensure a sufficiently high fee is paid to ensure\n> transaction confirmation.\n>\n> I also argue that the current auction model for limited transaction\n> bandwidth is wrong, is not suitable for a reliable transaction system\n> and, is wrong for Bitcoin. All transactions with valid fees must\n> confirm in due time. Currently, Bitcoin is not a safe way to send\n> payments.\n>\n> I do not believe that consumers and business are against paying fees,\n> even high fees. What is required is operational reliability.\n>\n> This great issue needs to be resolved for the safety and reliability of\n> Bitcoin. The time to resolve issues in commerce is before they become\n> great big issues. The time to resolve this issue is now. We must have\n> the foresight to identify and resolve problems before they trip us\n> over.  Simply doubling block sizes every so often is reactionary and is\n> not a reliable permanent solution.\n>\n> I have written this proposal for a technical solution but, need your\n> help to write it up to an acceptable standard to be a full BIP.\n>\n> ### 3. The problem\n>\n> Everybody wants value. Miners want to maximise revenue from fees (and\n> we presume, to minimise block size). Consumers need transaction\n> reliability and, (we presume) want low fees.\n>\n> The current transaction bandwidth limit is a limiting factor for both.\n> As the operational safety of transactions is limited, so is consumer\n> confidence as they realise the issue and, accordingly, uptake is\n> limited. Fees are artificially inflated due to bandwidth limitations\n> while failing to provide a full confirmation service for all valid\n> transactions.\n>\n> Current fee recommendations provide no satisfaction for transaction\n> reliability and, as Bitcoin scales, this will worsen.\n>\n> Transactions are included in blocks by miners using whatever basis they\n> prefer. We expect that this is usually a fee-based priority. However,\n> even transactions with a valid fee may be left in the transaction pool\n> for some time. As transaction bandwidth becomes an issue, not even\n> extreme fees can ensure a transaction is processed in a timely manner\n> or at all.\n>\n> Bitcoin must be a fully scalable and reliable service, providing full\n> transaction confirmation for every valid transaction.\n>\n> The possibility to send a transaction with a fee lower than one that is\n> acceptable to allow eventual transaction confirmation should be removed\n> from the protocol and also from the user interface.\n>\n> Bitcoin should be capable of reliably and inexpensively processing\n> casual transactions, and also priority processing of fee paying at\n> auction for priority transactions in the shortest possible timeframe.\n>\n> ### 4. Solution summary\n>\n> #### Main solution\n>\n> Provide each valid transaction in the mempool with an individual\n> transaction priority each time before choosing transactions to include\n> in the current block. The priority being a function of the fee (on a\n> curve), and the time waiting in the transaction pool (also on a curve)\n> out to n days (n = 60 days ?), and extending past n days. The value for\n> fee on a curve may need an upper limit. The transaction priority to\n> serve as the likelihood of a transaction being included in the current\n> block, and for determining the order in which transactions are tried to\n> see if they will be included.\n>\n> Nodes will need to keep track of when a transaction is first seen. It\n> is satisfactory for each node to do this independently provided the\n> full mempool and information survives node restart. If there is a more\n> reliable way to determine when a transaction was first seen on the\n> network then it should be utilised.\n>\n> > My current default installation of Bitcoin Core v0.15.1 does not\n> currently seem to save and load the mempool on restart, despite the\n> notes in the command line options panel that the default for\n> persistmempool is 1. In the debug panel, some 90,000 transactions\n> before restart, some 200 odd shortly after. Manually setting\n> persistmempool=1 in the conf file does not seem to make any difference.\n> Perhaps it is operating as expected and I am not sure what to observe,\n> but does not seem to be observably saving and loading the mempool on\n> restart. This will need to be resolved.\n>\n> Use a dynamic target block size to make the current block. This marks a\n> shift from using block size or weight to a count of transactions.\n> Determine the target block size using; pre-rollout(current average\n> valid transaction pool size) x ( 1 / (144 x n days ) ) = number of\n> transactions to be included in the current block. The block created\n> should be a minimum 1MB in size regardless if the target block size is\n> lower.\n>\n> If the created block size consistently contains too few transactions\n> and the number of new transactions created is continuously greater than\n> the block size will accommodate then I expect eventually ageing\n> transactions will be over-represented as a portion of the block\n> contents. Once another new node conforming to the proposal makes a\n> block, the block size will be proportionately larger as the transaction\n> pool has grown.  If block size is too large on average then this will\n> shrink the transaction pool.\n>\n> Miners will likely want to conform to the proposal, since making blocks\n> larger than necessary makes more room in each block potentially\n> lowering the highest fees paid for priority service. Always making\n> blocks smaller than the proposal requires will in time lower the\n> utility value of Bitcoin, a different situation but akin to the\n> current. Transactions will still always confirm but with longer and\n> longer wait periods. The auction at the front of the queue for priority\n> will be destroyed as there will be eventually no room in blocks besides\n> ageing transations and, there will be little value paying higher than\n> the minimum fee. Obviously, neither of these scenarios are in a miner's\n> interests.\n>\n> Without a consensus as to what size dynamic block to create,\n> enforcement of dynamic block size is not currently possible. It may be\n> possible for a consensus to be formed in the future but here I cannot\n> speculate. I can only suggest that it is in the interest of Bitcoin as\n> a whole and, in the interest of each node to conform to the proposal.\n> Some nodes failing to conform to the proposed requirements of dynamic\n> size or transaction priority in this proposal will not be destructive\n> to the operation of the proposal.\n>\n> If necessary, nodes that have not yet adopted the proposal will just\n> continue to create standard fixed size unordered blocks, although, if\n> the current mechanisms of block validation include the fixed block size\n> then it is unlikely that these nodes will be able to validate the\n> blockchain going forward. In this case a hard fork and a full transfer\n> to the new method should be required. If dynamic blocks with ordered\n> transactions will be valid to existing nodes then only a soft fork is\n> required. There is no proposed change to the internal construction of\n> blocks, only to the block size and using an ordered method of\n> transaction selection.\n>\n> > The default value for mempoolexpiry in Bitcoin Core may in future\n> need to be adjusted to match something more than n days or, perhaps\n> using less than n = 14 days may be a more sensible approach?\n>\n> All block created with dynamic size should be verified to ensure\n> conformity to a probability distribution curve resulting from the\n> priority method. Since the input is a probability, the output should\n> conform to a probability distribution.\n>\n> The curves used for the priority of transactions would have to be\n> appropriate. Perhaps a mathematician with experience in probability can\n> develop the right formulae. My thinking is a steep curve. I suppose\n> that the probability of all transactions should probably account for a\n> sufficient number of inclusions that the target block size is met on\n> average although, it may not always be. As a suggestion, consider\n> including some dust or zero-fee transactions to pad if each valid\n> transaction is tried and the target block size is not yet met, highest\n> BTC transaction value first?\n>\n> **Explanation of the operation of priority:**\n>\n> > If transaction priority is, for example, a number between one (low)\n> and one-hundred (high) it can be directly understood as the percentage\n> chance in one-hundred of a transaction being included in the block.\n> Using probability or likelihood infers that there is some function of\n> random. Try the transactions in priority order from highest to lowest,\n> if random (100) < transaction priority then the transaction is included\n> until the target block size is met.\n>\n> > To break it down further, if both the fee on a curve value and the\n> time waiting on a curve value are each a number between one and one-\n> hundred, a rudimentary method may be to simply multiply those two\n> numbers, to find the priority number. For example, a middle fee\n> transaction waiting thirty days (if n = 60 days) may have a value of\n> five for each part  (yes, just five, the values are on a curve). When\n> multiplied that will give a priority value of twenty-five, or, a\n> twenty-five percent chance at that moment of being included in the\n> block; it will likely be included in one of the next four blocks,\n> getting more likely each chance. If it is still not included then the\n> value of time waiting will be higher, making for more probability. A\n> very low fee transaction would have a value for the fee of one. It\n> would not be until near sixty-days that the particular low fee\n> transaction has a high likelihood of being included in the block.\n>\n> In practice it may be more useful to use numbers representative of one-\n> hundred for the highest fee priority curve down to a small fraction of\n> one for the lowest fee and, from one for a newly seen transaction up to\n> a proportionately high number above one-hundred for the time waiting\n> curve. It is truely beyond my level of math to resolve probability\n> curves accurately without much trial and error.\n>\n> The primary reason for addressing the issue is to ensure transactional\n> reliability and scalability while having each valid transaction confirm\n> in due time.\n>\n> #### Pros\n>\n> *   Maximizes transaction reliability.\n> *   Overcomes transaction bandwidth limit.\n> *   Fully scalable.\n> *   Maximizes possibility for consumer and business uptake.\n> *   Maximizes total fees paid per block without reducing reliability;\n> because of reliability, in time confidence and overall uptake are\n> greater; therefore, more transactions.\n> *   Market determines fee paid for transaction priority.\n> *   Fee recommendations work all the way out to 30 days or greater.\n> *   Provides additional block entropy; greater security since there is\n> less probability of predicting the next block. _Although this is not\n> necessary it is a product of the operation of this proposal._\n>\n> #### Cons\n>\n> *   Could initially lower total transaction fees per block.\n> *   Must be first be programmed.\n>\n> #### Pre-rollout\n>\n> Nodes need to have at a minimum a loose understanding of the average\n> (since there is no consensus) size of the transaction pool as a\n> requirement to enable future changes to the way blocks are constructed.\n>\n> A new network service should be constructed to meet this need. This\n> service makes no changes to any existing operation or function of the\n> node. Initially, Bitcoin Core is a suitable candidate.\n>\n> For all operations we count only valid transactions.\n>\n> **The service must:**\n>\n> *   Have an individual temporary (runtime permanent only) Serial Node\n> ID.\n> *   Accept communication of the number of valid transactions in the\n> mempool of another valid Bitcoin node along with the Serial Node ID of\n> the node whose value is provided.\n> *   Disconnect the service from any non-Bitcoin node. Bitcoin Core may\n> handle this already?\n> *   Expire any value not updated for k minutes (k = 30 minutes?).\n> *   Broadcast all mempool information the node has every m minutes (m =\n> 10 minutes?), including its own.\n> *   Nodes own mempool information should not be broadcast or used in\n> calculation until the node has been up long enough for the mempool to\n> normalise for at least o minutes (o = 300 minutes ?)\n> *   Alternatively, if loading nodes own full mempool from disk on node\n> restart (o = 30 minutes ?)\n> *   Only new or updated mempool values should be transmitted to the\n> same node. Updated includes updated with no change.\n> *   All known mempool information must survive node restart.\n> *   If the nodes own mempool is not normalised and network information\n> is not available to calculate an average just display zero.\n> *   Internally, the average transaction pool size must return the\n> calculated average if an average is available or, if none is available\n> just the number of valid transactions in the node's own mempool\n> regardless if it is normalised.\n>\n> Bitcoin Core must use all collated information on mempool size to\n> calculate a figure for the average mempool size.\n>\n> The calculated figure should be displayed in the appropriate place in\n> the Debug window alongside the text Network average transactions.\n>\n> Consideration must be given before development of the network bandwidth\n> this would require. All programming must be consistent with the current\n> operation and conventions of Bitcoin Core. Methods must work on all\n> platforms.\n>\n> As this new service does not affect any existing service or feature of\n> Bitcoin or Bitcoin Core, this can technically be programmed now and\n> included in Bitcoin Core at any time.\n>\n> ### 5. Solution operation\n>\n> This is a simplistic view of the operation. The actual operation will\n> need to be determined accurately in a spec for the programmer.\n>\n> 1.  Determine the target block size for the current block.\n> 2.  Assign a transaction priority to each valid transaction in the\n> mempool.\n> 3.  Select transactions to include in the current block using\n> probability in transaction priority order until the target block size\n> is met. If target block size is not met, include dust and zero-fee\n> transactions to pad.\n> 4.  Solve block.\n> 5.  Broadcast the current block when it is solved.\n> 6.  Block is received.\n> 7.  Block verification process.\n> 8.  Accept/reject block based on verification result.\n> 9.  Repeat.\n>\n> ### 6. Closing comments\n>\n> It may be possible to verify blocks conform to the proposal by showing\n> that the probability for all transactions included in the block\n> statistically conforms to a probability distribution curve, *if* the\n> individual transaction priority can be recreated. I am not that deep\n> into the mathematics; however, it may also be possible to use a similar\n> method to do this just based on the fee, that statistically, the block\n> conforms to a fee distribution. Any dust and zero-fee transactions\n> would have to be ignored. This solution needs a competent mathematician\n> with experience in probability and statistical distribution.\n>\n> It is trivial to this proposal to offer that a node provides the next\n> block size with a block when it is solved. I am not sure that this\n> creates any actual benefit since the provided next block size is only\n> one node's view, as it is the node may seemingly just as well use its\n> own view and create the block. Providing a next block size only adds\n> additional complexity to the required operation, however, perhaps\n> providing the next block size is not trivial in what is accomplished\n> and the feature can be included in the operation.\n>\n> Instead of the pre-rollout network service providing data as to valid\n> transactions in mempool, it could directly provide data as to the\n> suggested next block size if that is preferred, using a similar\n> operation as is suggested now and averaging all received suggested next\n> block sizes.\n>\n> It may be foreseeable in the future for Bitcoin to operate with a\n> network of dedicated full blockchain & mempool servers. This would not\n> be without challenges to overcome but would offer several benefits,\n> including to the operation of this proposal, and especially as the RAM\n> and storage requirements of a full node grows. It is easy to foresee\n> that in just another seven years of operation a Bitcoin Full Node will\n> require at least 300GB of storage and, if the mempool only doubles in\n> size, over 1GB of RAM.\n>\n> There has been some concern expressed over spam and very low fee\n> transactions, and an infinite block size resulting. I hope that for\n> those concerned using the dust level addresses the issue, especially as\n> the value of Bitcoin grows.\n>\n> Notwithstanding this proposal, all blocks including those with dynamic\n> size each have limited transaction space per block. This proposal\n> results in a fee for priority service auction, where the probability of\n> a transaction to be included in limited space in the next available\n> block is auctioned to the highest bidders and all other transactions\n> must wait until they reach priority by ageing to gain significant\n> probability. Under this proposal the mempool can grow quite large while\n> the confirmation service continues in a stable and reliable manner.\n> Several incentives for attackers are removed, where there is no longer\n> multiple potential incentives for unnecessarily filling blocks or\n> flooding the mempool with transactions, whether such transactions are\n> fraudulent, valid or, otherwise. Adoption of this proposal and\n> adherence results in a reliable, stable fee paying transaction\n> confirmation service and a beneficial auction.\n>\n> This proposal is necessary. I implore, at the very least, that we use\n> some method that validates full transaction reliability and enables\n> scalability of Bitcoin. If not this proposal, an alternative.\n>\n> I have done as much with this proposal as I feel that I am able so far\n> but continue to take your feedback.\n>\n> Regards,\n> Damian Williamson\n>\n> [![Creative Commons License](https://i.creativecommons.org/l/by-sa/4.0/\n> 88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)\n> <span xmlns:dct=\"http://purl.org/dc/terms/\"\n> href=\"http://purl.org/dc/dcmitype/Text\" property=\"dct:title\"\n> rel=\"dct:type\">BIP Proposal: UTPFOTIB - Use Transaction Priority For\n> Ordering Transactions In Blocks</span> by [Damian Williamson\n> &lt;willtech at live.com.au&gt;](http://thekingjameshrmh.tumblr.com/post/1\n> 68948530950/bip-proposal-utpfotib-use-transaction-priority-for-order)\n> is licensed under a [Creative Commons Attribution-ShareAlike 4.0\n> International License](http://creativecommons.org/licenses/by-sa/4.0/).\n> Based on a work at https://lists.linuxfoundation.org/pipermail/bitcoin-\n> dev/2017-\n> December/015371.html](https://lists.linuxfoundation.org/pipermail/bitco\n> in-dev/2017-December/015371.html).\n> Permissions beyond the scope of this license may be available at [https\n> ://opensource.org/licenses/BSD-3-\n> Clause](https://opensource.org/licenses/BSD-3-Clause).\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180120/e17640ac/attachment-0001.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2018-01-21T05:49:25",
                "message_text_only": "Good afternoon Alan,\n\n\nIt is stated in the proposal that it is intended for blocks to be validated as the output of the priority method, to ensure that they conform. Unfortunately, the math necessary for this sort of statistical function is outside the scope of my formal education and I will need to rely on someone to develop what is necessary. If it does turn out that this is not ultimately possible then I suppose at that stage the proposal would need to be abandoned since I agree - validation must be necessary. Blocks created with cheating should be too unlikely.\n\n\n>All block created with dynamic size should be verified to ensure\nconformity to a probability distribution curve resulting from the\npriority method. Since the input is a probability, the output should\nconform to a probability distribution.\n\n\nRegards,\n\nDamian Williamson\n\n________________________________\nFrom: Alan Evans <thealanevans at gmail.com>\nSent: Sunday, 21 January 2018 1:46:41 AM\nTo: Damian Williamson; Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\nI don't see any modifications to the proposal that addresses the issue that miners will always be free to choose their own priority that a few people brought up before.\n\nI understand you think it's in the miners best long-term interest to follow these rules, but even if a miner agrees with you, if that miner thinks the other miners are following the fee curve, they will know it makes no overall difference if they cheat (you can't prove how long a miner has had a transaction in their mempool).\n\nThe opportunity to cheat, the anonymity of mining, the low negative effect of a single cheating instance, all combined with a financial incentive to cheat means that cheating will be rife.\n\n\nOn Sat, Jan 20, 2018 at 8:04 AM, Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n\nTried a different approach for the curves, would appreciate it if someone has the energy to work on this and help me to resolve it a bit more scientifically:\n\n\np(tx) = (((((fx - (fl - 0.00000001)) / (fh - (fl - 0.00000001))) * 100) + 1) ^ y) + (((((wx - 0.9) / ((86400 * n) - 0.9)) * 100) + 1) ^ y)\n\np is the calculated priority number for tx the specific valid transaction.\nfx is the fee in BTC/KB for the specific transaction.\nfl is the lowest valid fee in BTC/KB currently in the nodes mempool.\nfh is the highest valid fee in BTC/KB currently in the nodes mempool.\nwx is the current wait in seconds for tx the specific valid transaction.\nn is the number of days maximum wait consensus value.\ny can be 10 or, y can be a further developed to be a formula based on the number of required inclusions to vary the steepness of the curve as the mempool size varies.\n\nIn the next step, the random value must be:\nif random(101^y) < p then transaction is included;\n\nRegards,\nDamian Williamson\n\n\n________________________________\nFrom: Damian Williamson <willtech at live.com.au<mailto:willtech at live.com.au>>\nSent: Saturday, 20 January 2018 10:25:43 AM\nTo: Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n\nAn example curve:\n\nThe curve curently described here is ineffective at acheiving the requirements. It seems to be not nearly steep enough resulting in too many inclusions (as it happens, this may not metter - needs further evaluation) and, the lower end values seem problematically small but, results in a number between 100 for the highest fee BTC/KB and a small fraction of 1 for the lowest. This math needs to be improved.\n\n\npf(tx) = sin2((fx-(fl-0.00000001))/(fh-(fl-0.00000001))*1.570796326795)*100\n\n\npf is the calculated priority number for the fee for tx the specifc valid transaction.\nfx is the fee in BTC/KB for the specific transaction.\nfl is the lowest valid fee in BTC/KB currently in the nodes mempool.\nfh is the highest valid fee in BTC/KB currently in the nodes mempool.\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org> <bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org>> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>\nSent: Thursday, 4 January 2018 8:01:10 PM\nTo: Bitcoin Protocol Discussion\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\n\nThis proposal has a new update, mostly minor edits. Additionally, I had a logic flaw in the hard fork / soft fork declaration statement. The specific terms of the CC-BY-SA-4.0 licence the document is published under have now been updated to include additional permissions available under the MIT licence.\n\n\nRecently, on Twitter:\n\nI am looking for a capable analyst/programmer to work on a BIP proposal as co-author. Will need to format several Full BIP's per these BIP process requirements: ( https://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki ) from a BIP Proposal, being two initially for non-consensus full-interoperable pre-rollout on peer service layer & API/RPC layer and, a reference implementation for Bitcoin Core per: ( https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md ). Interested parties please reply via this list thread: ( https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015485.html ) #Bitcoin #BIP\n\n\nRegards,\n\nDamian Williamson\n\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org> <bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org>> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>\nSent: Monday, 1 January 2018 10:04 PM\nTo: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nSubject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks\n\nHappy New Year all.\n\nThis proposal has been further amended with several minor changes and a\nfew additions.\n\nI believe that all known issues raised so far have been sufficiently\naddressed. Either that or, I still have more work to do.\n\n## BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For\nOrdering Transactions In Blocks\n\nSchema:\n##########\nDocument: BIP Proposal\nTitle: UTPFOTIB - Use Transaction Priority For Ordering Transactions In\nBlocks\nPublished: 26-12-2017\nRevised: 01-01-2018\nAuthor: Damian Williamson <willtech at live.com.au<mailto:willtech at live.com.au>>\nLicence: Creative Commons Attribution-ShareAlike 4.0 International\nLicense.\nURL: http://thekingjameshrmh.tumblr.com/post/168948530950/bip-proposal-\nutpfotib-use-transaction-priority-for-order\n##########\n\n### 1. Abstract\n\nThis document proposes to address the issue of transactional\nreliability in Bitcoin, where valid transactions may be stuck in the\ntransaction pool for extended periods or never confirm.\n\nThere are two key issues to be resolved to achieve this:\n\n1.  The current transaction bandwidth limit.\n2.  The current ad-hoc methods of including transactions in blocks\nresulting in variable and confusing confirmation times for valid\ntransactions, including transactions with a valid fee that may never\nconfirm.\n\nIt is important with any change to protect the value of fees as these\nwill eventually be the only payment that miners receive. Rather than an\nauction model for limited bandwidth, the proposal results in a fee for\npriority service auction model.\n\nIt would not be true to suggest that all feedback received so far has\nbeen entirely positive although, most of it has been constructive.\n\nThe previous threads for this proposal are available here:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/s\nubject.html\n\nIn all parts of this proposal, references to a transaction, a valid\ntransaction, a transaction with a valid fee, a valid fee, etc. is\ndefined as any transaction that is otherwise valid with a fee of at\nleast 0.00001000 BTC/KB as defined as the dust level, interpreting from\nBitcoin Core GUI. Transactions with a fee lower than this rate are\nconsidered dust.\n\nIn all parts of this proposal, dust and zero-fee transactions are\nalways ignored and/or excluded unless specifically mentioned.\n\nIt is generally assumed that miners currently prefer to include\ntransactions with higher fees.\n\n### 2. The need for this proposal\n\nWe all must learn to admit that transaction bandwidth is still lurking\nas a serious issue for the operation, reliability, safety, consumer\nacceptance, uptake and, for the value of Bitcoin.\n\nI recently sent a payment which was not urgent so; I chose three-day\ntarget confirmation from the fee recommendation. That transaction has\nstill not confirmed after now more than six days - even waiting twice\nas long seems quite reasonable to me (note for accuracy: it did\neventually confirm). That transaction is a valid transaction; it is not\nrubbish, junk or, spam. Under the current model with transaction\nbandwidth limitation, the longer a transaction waits, the less likely\nit is ever to confirm due to rising transaction numbers and being\npushed back by transactions with rising fees.\n\nI argue that no transactions with fees above the dust level are rubbish\nor junk, only some zero fee transactions might be spam. Having an ever-\nincreasing number of valid transactions that do not confirm as more new\ntransactions with higher fees are created is the opposite of operating\na robust, reliable transaction system.\n\nWhile the miners have discovered a gold mine, it is the service they\nprovide that is valuable. If the service is unreliable they are not\nworth the gold that they mine. This is reflected in the value of\nBitcoin.\n\nBusiness cannot operate with a model where transactions may or may not\nconfirm. Even a business choosing a modest fee has no guarantee that\ntheir valid transaction will not be shuffled down by new transactions\nto the realm of never confirming after it is created. Consumers also\nwill not accept this model as Bitcoin expands. If Bitcoin cannot be a\nreliable payment system for confirmed transactions then consumers, by\nand large, will simply not accept the model once they understand.\nBitcoin will be a dirty payment system, and this will kill the value of\nBitcoin.\n\nUnder the current system, a minority of transactions will eventually be\nthe lucky few who have fees high enough to escape being pushed down the\nlist.\n\nOnce there are more than x transactions (transaction bandwidth limit)\nevery ten minutes, only those choosing twenty-minute confirmation (2\nblocks) from the fee recommendations will have initially at most a\nfifty percent chance of ever having their payment confirm by the time\n2x transactions is reached. Presently, not even using fee\nrecommendations can ensure a sufficiently high fee is paid to ensure\ntransaction confirmation.\n\nI also argue that the current auction model for limited transaction\nbandwidth is wrong, is not suitable for a reliable transaction system\nand, is wrong for Bitcoin. All transactions with valid fees must\nconfirm in due time. Currently, Bitcoin is not a safe way to send\npayments.\n\nI do not believe that consumers and business are against paying fees,\neven high fees. What is required is operational reliability.\n\nThis great issue needs to be resolved for the safety and reliability of\nBitcoin. The time to resolve issues in commerce is before they become\ngreat big issues. The time to resolve this issue is now. We must have\nthe foresight to identify and resolve problems before they trip us\nover.  Simply doubling block sizes every so often is reactionary and is\nnot a reliable permanent solution.\n\nI have written this proposal for a technical solution but, need your\nhelp to write it up to an acceptable standard to be a full BIP.\n\n### 3. The problem\n\nEverybody wants value. Miners want to maximise revenue from fees (and\nwe presume, to minimise block size). Consumers need transaction\nreliability and, (we presume) want low fees.\n\nThe current transaction bandwidth limit is a limiting factor for both.\nAs the operational safety of transactions is limited, so is consumer\nconfidence as they realise the issue and, accordingly, uptake is\nlimited. Fees are artificially inflated due to bandwidth limitations\nwhile failing to provide a full confirmation service for all valid\ntransactions.\n\nCurrent fee recommendations provide no satisfaction for transaction\nreliability and, as Bitcoin scales, this will worsen.\n\nTransactions are included in blocks by miners using whatever basis they\nprefer. We expect that this is usually a fee-based priority. However,\neven transactions with a valid fee may be left in the transaction pool\nfor some time. As transaction bandwidth becomes an issue, not even\nextreme fees can ensure a transaction is processed in a timely manner\nor at all.\n\nBitcoin must be a fully scalable and reliable service, providing full\ntransaction confirmation for every valid transaction.\n\nThe possibility to send a transaction with a fee lower than one that is\nacceptable to allow eventual transaction confirmation should be removed\nfrom the protocol and also from the user interface.\n\nBitcoin should be capable of reliably and inexpensively processing\ncasual transactions, and also priority processing of fee paying at\nauction for priority transactions in the shortest possible timeframe.\n\n### 4. Solution summary\n\n#### Main solution\n\nProvide each valid transaction in the mempool with an individual\ntransaction priority each time before choosing transactions to include\nin the current block. The priority being a function of the fee (on a\ncurve), and the time waiting in the transaction pool (also on a curve)\nout to n days (n = 60 days ?), and extending past n days. The value for\nfee on a curve may need an upper limit. The transaction priority to\nserve as the likelihood of a transaction being included in the current\nblock, and for determining the order in which transactions are tried to\nsee if they will be included.\n\nNodes will need to keep track of when a transaction is first seen. It\nis satisfactory for each node to do this independently provided the\nfull mempool and information survives node restart. If there is a more\nreliable way to determine when a transaction was first seen on the\nnetwork then it should be utilised.\n\n> My current default installation of Bitcoin Core v0.15.1 does not\ncurrently seem to save and load the mempool on restart, despite the\nnotes in the command line options panel that the default for\npersistmempool is 1. In the debug panel, some 90,000 transactions\nbefore restart, some 200 odd shortly after. Manually setting\npersistmempool=1 in the conf file does not seem to make any difference.\nPerhaps it is operating as expected and I am not sure what to observe,\nbut does not seem to be observably saving and loading the mempool on\nrestart. This will need to be resolved.\n\nUse a dynamic target block size to make the current block. This marks a\nshift from using block size or weight to a count of transactions.\nDetermine the target block size using; pre-rollout(current average\nvalid transaction pool size) x ( 1 / (144 x n days ) ) = number of\ntransactions to be included in the current block. The block created\nshould be a minimum 1MB in size regardless if the target block size is\nlower.\n\nIf the created block size consistently contains too few transactions\nand the number of new transactions created is continuously greater than\nthe block size will accommodate then I expect eventually ageing\ntransactions will be over-represented as a portion of the block\ncontents. Once another new node conforming to the proposal makes a\nblock, the block size will be proportionately larger as the transaction\npool has grown.  If block size is too large on average then this will\nshrink the transaction pool.\n\nMiners will likely want to conform to the proposal, since making blocks\nlarger than necessary makes more room in each block potentially\nlowering the highest fees paid for priority service. Always making\nblocks smaller than the proposal requires will in time lower the\nutility value of Bitcoin, a different situation but akin to the\ncurrent. Transactions will still always confirm but with longer and\nlonger wait periods. The auction at the front of the queue for priority\nwill be destroyed as there will be eventually no room in blocks besides\nageing transations and, there will be little value paying higher than\nthe minimum fee. Obviously, neither of these scenarios are in a miner's\ninterests.\n\nWithout a consensus as to what size dynamic block to create,\nenforcement of dynamic block size is not currently possible. It may be\npossible for a consensus to be formed in the future but here I cannot\nspeculate. I can only suggest that it is in the interest of Bitcoin as\na whole and, in the interest of each node to conform to the proposal.\nSome nodes failing to conform to the proposed requirements of dynamic\nsize or transaction priority in this proposal will not be destructive\nto the operation of the proposal.\n\nIf necessary, nodes that have not yet adopted the proposal will just\ncontinue to create standard fixed size unordered blocks, although, if\nthe current mechanisms of block validation include the fixed block size\nthen it is unlikely that these nodes will be able to validate the\nblockchain going forward. In this case a hard fork and a full transfer\nto the new method should be required. If dynamic blocks with ordered\ntransactions will be valid to existing nodes then only a soft fork is\nrequired. There is no proposed change to the internal construction of\nblocks, only to the block size and using an ordered method of\ntransaction selection.\n\n> The default value for mempoolexpiry in Bitcoin Core may in future\nneed to be adjusted to match something more than n days or, perhaps\nusing less than n = 14 days may be a more sensible approach?\n\nAll block created with dynamic size should be verified to ensure\nconformity to a probability distribution curve resulting from the\npriority method. Since the input is a probability, the output should\nconform to a probability distribution.\n\nThe curves used for the priority of transactions would have to be\nappropriate. Perhaps a mathematician with experience in probability can\ndevelop the right formulae. My thinking is a steep curve. I suppose\nthat the probability of all transactions should probably account for a\nsufficient number of inclusions that the target block size is met on\naverage although, it may not always be. As a suggestion, consider\nincluding some dust or zero-fee transactions to pad if each valid\ntransaction is tried and the target block size is not yet met, highest\nBTC transaction value first?\n\n**Explanation of the operation of priority:**\n\n> If transaction priority is, for example, a number between one (low)\nand one-hundred (high) it can be directly understood as the percentage\nchance in one-hundred of a transaction being included in the block.\nUsing probability or likelihood infers that there is some function of\nrandom. Try the transactions in priority order from highest to lowest,\nif random (100) < transaction priority then the transaction is included\nuntil the target block size is met.\n\n> To break it down further, if both the fee on a curve value and the\ntime waiting on a curve value are each a number between one and one-\nhundred, a rudimentary method may be to simply multiply those two\nnumbers, to find the priority number. For example, a middle fee\ntransaction waiting thirty days (if n = 60 days) may have a value of\nfive for each part  (yes, just five, the values are on a curve). When\nmultiplied that will give a priority value of twenty-five, or, a\ntwenty-five percent chance at that moment of being included in the\nblock; it will likely be included in one of the next four blocks,\ngetting more likely each chance. If it is still not included then the\nvalue of time waiting will be higher, making for more probability. A\nvery low fee transaction would have a value for the fee of one. It\nwould not be until near sixty-days that the particular low fee\ntransaction has a high likelihood of being included in the block.\n\nIn practice it may be more useful to use numbers representative of one-\nhundred for the highest fee priority curve down to a small fraction of\none for the lowest fee and, from one for a newly seen transaction up to\na proportionately high number above one-hundred for the time waiting\ncurve. It is truely beyond my level of math to resolve probability\ncurves accurately without much trial and error.\n\nThe primary reason for addressing the issue is to ensure transactional\nreliability and scalability while having each valid transaction confirm\nin due time.\n\n#### Pros\n\n*   Maximizes transaction reliability.\n*   Overcomes transaction bandwidth limit.\n*   Fully scalable.\n*   Maximizes possibility for consumer and business uptake.\n*   Maximizes total fees paid per block without reducing reliability;\nbecause of reliability, in time confidence and overall uptake are\ngreater; therefore, more transactions.\n*   Market determines fee paid for transaction priority.\n*   Fee recommendations work all the way out to 30 days or greater.\n*   Provides additional block entropy; greater security since there is\nless probability of predicting the next block. _Although this is not\nnecessary it is a product of the operation of this proposal._\n\n#### Cons\n\n*   Could initially lower total transaction fees per block.\n*   Must be first be programmed.\n\n#### Pre-rollout\n\nNodes need to have at a minimum a loose understanding of the average\n(since there is no consensus) size of the transaction pool as a\nrequirement to enable future changes to the way blocks are constructed.\n\nA new network service should be constructed to meet this need. This\nservice makes no changes to any existing operation or function of the\nnode. Initially, Bitcoin Core is a suitable candidate.\n\nFor all operations we count only valid transactions.\n\n**The service must:**\n\n*   Have an individual temporary (runtime permanent only) Serial Node\nID.\n*   Accept communication of the number of valid transactions in the\nmempool of another valid Bitcoin node along with the Serial Node ID of\nthe node whose value is provided.\n*   Disconnect the service from any non-Bitcoin node. Bitcoin Core may\nhandle this already?\n*   Expire any value not updated for k minutes (k = 30 minutes?).\n*   Broadcast all mempool information the node has every m minutes (m =\n10 minutes?), including its own.\n*   Nodes own mempool information should not be broadcast or used in\ncalculation until the node has been up long enough for the mempool to\nnormalise for at least o minutes (o = 300 minutes ?)\n*   Alternatively, if loading nodes own full mempool from disk on node\nrestart (o = 30 minutes ?)\n*   Only new or updated mempool values should be transmitted to the\nsame node. Updated includes updated with no change.\n*   All known mempool information must survive node restart.\n*   If the nodes own mempool is not normalised and network information\nis not available to calculate an average just display zero.\n*   Internally, the average transaction pool size must return the\ncalculated average if an average is available or, if none is available\njust the number of valid transactions in the node's own mempool\nregardless if it is normalised.\n\nBitcoin Core must use all collated information on mempool size to\ncalculate a figure for the average mempool size.\n\nThe calculated figure should be displayed in the appropriate place in\nthe Debug window alongside the text Network average transactions.\n\nConsideration must be given before development of the network bandwidth\nthis would require. All programming must be consistent with the current\noperation and conventions of Bitcoin Core. Methods must work on all\nplatforms.\n\nAs this new service does not affect any existing service or feature of\nBitcoin or Bitcoin Core, this can technically be programmed now and\nincluded in Bitcoin Core at any time.\n\n### 5. Solution operation\n\nThis is a simplistic view of the operation. The actual operation will\nneed to be determined accurately in a spec for the programmer.\n\n1.  Determine the target block size for the current block.\n2.  Assign a transaction priority to each valid transaction in the\nmempool.\n3.  Select transactions to include in the current block using\nprobability in transaction priority order until the target block size\nis met. If target block size is not met, include dust and zero-fee\ntransactions to pad.\n4.  Solve block.\n5.  Broadcast the current block when it is solved.\n6.  Block is received.\n7.  Block verification process.\n8.  Accept/reject block based on verification result.\n9.  Repeat.\n\n### 6. Closing comments\n\nIt may be possible to verify blocks conform to the proposal by showing\nthat the probability for all transactions included in the block\nstatistically conforms to a probability distribution curve, *if* the\nindividual transaction priority can be recreated. I am not that deep\ninto the mathematics; however, it may also be possible to use a similar\nmethod to do this just based on the fee, that statistically, the block\nconforms to a fee distribution. Any dust and zero-fee transactions\nwould have to be ignored. This solution needs a competent mathematician\nwith experience in probability and statistical distribution.\n\nIt is trivial to this proposal to offer that a node provides the next\nblock size with a block when it is solved. I am not sure that this\ncreates any actual benefit since the provided next block size is only\none node's view, as it is the node may seemingly just as well use its\nown view and create the block. Providing a next block size only adds\nadditional complexity to the required operation, however, perhaps\nproviding the next block size is not trivial in what is accomplished\nand the feature can be included in the operation.\n\nInstead of the pre-rollout network service providing data as to valid\ntransactions in mempool, it could directly provide data as to the\nsuggested next block size if that is preferred, using a similar\noperation as is suggested now and averaging all received suggested next\nblock sizes.\n\nIt may be foreseeable in the future for Bitcoin to operate with a\nnetwork of dedicated full blockchain & mempool servers. This would not\nbe without challenges to overcome but would offer several benefits,\nincluding to the operation of this proposal, and especially as the RAM\nand storage requirements of a full node grows. It is easy to foresee\nthat in just another seven years of operation a Bitcoin Full Node will\nrequire at least 300GB of storage and, if the mempool only doubles in\nsize, over 1GB of RAM.\n\nThere has been some concern expressed over spam and very low fee\ntransactions, and an infinite block size resulting. I hope that for\nthose concerned using the dust level addresses the issue, especially as\nthe value of Bitcoin grows.\n\nNotwithstanding this proposal, all blocks including those with dynamic\nsize each have limited transaction space per block. This proposal\nresults in a fee for priority service auction, where the probability of\na transaction to be included in limited space in the next available\nblock is auctioned to the highest bidders and all other transactions\nmust wait until they reach priority by ageing to gain significant\nprobability. Under this proposal the mempool can grow quite large while\nthe confirmation service continues in a stable and reliable manner.\nSeveral incentives for attackers are removed, where there is no longer\nmultiple potential incentives for unnecessarily filling blocks or\nflooding the mempool with transactions, whether such transactions are\nfraudulent, valid or, otherwise. Adoption of this proposal and\nadherence results in a reliable, stable fee paying transaction\nconfirmation service and a beneficial auction.\n\nThis proposal is necessary. I implore, at the very least, that we use\nsome method that validates full transaction reliability and enables\nscalability of Bitcoin. If not this proposal, an alternative.\n\nI have done as much with this proposal as I feel that I am able so far\nbut continue to take your feedback.\n\nRegards,\nDamian Williamson\n\n[![Creative Commons License](https://i.creativecommons.org/l/by-sa/4.0/\n88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)\n<span xmlns:dct=\"http://purl.org/dc/terms/\"\nhref=\"http://purl.org/dc/dcmitype/Text\" property=\"dct:title\"\nrel=\"dct:type\">BIP Proposal: UTPFOTIB - Use Transaction Priority For\nOrdering Transactions In Blocks</span> by [Damian Williamson\n&lt;willtech at live.com.au<mailto:lt%3Bwilltech at live.com.au>&gt;](http://thekingjameshrmh.tumblr.com/post/1\n68948530950/bip-proposal-utpfotib-use-transaction-priority-for-order)\nis licensed under a [Creative Commons Attribution-ShareAlike 4.0\nInternational License](http://creativecommons.org/licenses/by-sa/4.0/).\nBased on a work at https://lists.linuxfoundation.org/pipermail/bitcoin-\ndev/2017-\nDecember/015371.html](https://lists.linuxfoundation.org/pipermail/bitco\nin-dev/2017-December/015371.html).\nPermissions beyond the scope of this license may be available at [https\n://opensource.org/licenses/BSD-3-<http://opensource.org/licenses/BSD-3->\nClause](https://opensource.org/licenses/BSD-3-Clause).\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180121/20f0a541/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Damian Williamson",
                "Alan Evans"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 161555
        }
    },
    {
        "title": "[bitcoin-dev] Decoupling BIP70 Payment Protocol from Wallets",
        "thread_messages": [
            {
                "author": "James Hilliard",
                "date": "2018-01-01T18:50:04",
                "message_text_only": "Recently a large merchant payment processor has decided to drop\nsupport for BIP21 payment URI's in favor of accepting exclusively\nBIP70 payments which has brought to light a number of problems with\nBIP70:\n\n1. Many wallets do not support BIP70 and have no near term intention\nof doing so.\n2. BIP70 requires large complex PKI dependencies such as X.509 and TLS\nsupport(usually via openssl) which have a large attack surface and\npoor track record when it comes to vulnerabilities.\n3. Signing transactions with keys resident in the same application as\nthat which handles TLS greatly increases the possibility of keys being\nleaked due to vulnerabilities in TLS libraries such as\nopenssl(heartbleed etc).\n4. Sending payments first to a BIP70 compatible wallet before sending\nto the merchant increases fees and uses more block space than sending\ndirectly since it is often not feasible for users to fully migrate\nfunds to a BIP70 compatible wallet.\n5. Paying a BIP70 invoice with an incompatible wallet currently\nrequires manual non-user-friendly workarounds such as\nhttps://github.com/achow101/payment-proto-interface\n\nI propose that we move the BIP70 protocol implementation into a\nbrowser extension that can communicate with wallets over a simple IPC\nmechanism such as\nhttps://developer.mozilla.org/en-US/Add-ons/WebExtensions/Native_messaging\nin addition to acting as a translation layer that can convert BIP70\nURL's into standard BIP21 URI's for wallets that do not wish to\nsupport BIP70 or other custom schemes.\n\nThis will provide a number of advantages over the current method of\nimplementing BIP70 directly within wallets:\n\n1. It removes complex/risky dependencies from wallets and moves them\ninto the browser which already has to implement full PKI support.\n2. It re-enables payment support for wallets that only support\nBIP21/normal addresses.\n3. It makes offline/custom signing schemes easier to use with BIP70."
            },
            {
                "author": "Ryan Grant",
                "date": "2018-01-02T11:31:51",
                "message_text_only": "On Mon, Jan 1, 2018 at 1:50 PM, James Hilliard via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> I propose that we move the BIP70 protocol implementation into a\n> browser extension that can communicate with wallets over a simple IPC\n> mechanism [...]\n\nAs a reminder, there is a W3C Payments API, currently proceeding along\nthe W3C Recommendation track, which registers \"payment handlers\" in\nthe browser, and selects one to complete a transaction:\n\n  https://w3c.github.io/payment-handler/\n\nThe purpose of the payments API is to automate all data entry and\nhandle choices related to common transactions on the Web.  Payment\nrequests will often ask for information that Bitcoin wallets have no\ncurrent need to provide, such as a shipping address.  If shipping\noptions or other personally identifying information (such as an email\naddress and a return payment address) are involved, then it is the\nchosen payment type's *handler* that is tasked with negotiating with\nthe user how to reveal the supposedly necessary information.\n\n  https://www.w3.org/TR/payment-request/#the-options-argument\n\nAlthough it may seem early for wallet makers to consider integration\nwith a mere W3C Recommendation, it would not be early to choose the\nright architecture to build code on, given that this is in the works\nfor the major browsers.  Development can proceed even in browsers that\nhave not implemented anything, through an HTML5 Javascript polyfill.\nA demonstration which includes payment in bitcoins is already\navailable, although it leaves as an exercise for the reader exactly\nhow the txid would be made known to the handler (whether manually\ninput by paste buffer after copying from an external app, or returned\nthrough IPC):\n\n  https://web-payments.io/\n  https://github.com/digitalbazaar/payment-handler-polyfill\n\n>From my brief inspection: not bad.  I don't see anything in this spec\nthat would preclude the workflow of a Bitcoin transaction, whether\non-chain (with the seller's backend marking off confirmations) or\nusing the Lightning Network.  It even allows the seller to offer a\ndiscount on certain payment methods:\n\n  https://www.w3.org/TR/payment-request/#dom-paymentdetailsmodifier"
            }
        ],
        "thread_summary": {
            "title": "Decoupling BIP70 Payment Protocol from Wallets",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Ryan Grant",
                "James Hilliard"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 4113
        }
    },
    {
        "title": "[bitcoin-dev] Raise default datacarriersize to 220 byte or higher",
        "thread_messages": [
            {
                "author": "mbde at bitwatch.co",
                "date": "2018-01-04T09:37:42",
                "message_text_only": "Hi guys,\n\nthere are several ways to embed arbitrary data into the blockchain, and\nthis is used by several meta-protocols. Most protocols at this point use\nOP_RETURN scripts for this.\n\nTo disincentivize the use of other and more harmful methods to embed\ndata into the chain, in particular via P2SH, I propose to raise the\ndefault datacarriersize to 220 byte, so it becomes the \"cheapest\" way of\nembedding data into the chain.\n\nThe following graph shows the relation between transaction sizes and\npayload sizes: http://i.imgur.com/VAGZWBK.png\n\nEmbedding data with bare-multisig and P2SH can be cheaper in terms of\neffective transaction size, compared to OP_RETURN with a payload limit\nof 80 byte. Both methods of embedding data, via bare-multisig and P2SH,\nwere heavily used by the major two meta-protocols on top of Bitcoin:\nOmni and Counterparty, but both protocols started to use OP_RETRUN data\nembedding a long time ago.\n\nHowever, currently token sends are usually done one by one, each with a\nsingle transaction, and this is a heavy burden for the whole network,\ne.g. when an exchange sends out withdrawals.\n\nWe have solutions for \"multi-sends with multi-inputs\" and also\nconsidered moving destinations into the payload for token sends, but we\nneed more space, otherwise this solution is limited to very few recipients.\n\nI therefore propose to raise the default datacarriersize to 220 byte or\nhigher and I'd be happy to provide a pull request doing so, if this gets\npositive feedback.\n\n- dexx"
            },
            {
                "author": "mbde at bitwatch.co",
                "date": "2018-01-04T19:38:23",
                "message_text_only": "To add some information about the relevance of this:\n\nDuring December 2017 there were roughly 210.000 Omni Layer transactions,\nwith more than 12.000 transactions on peak days, and the numbers are\ngrowing.\n\nI assume there is a similar number of Counterparty transactions, which\nmost likely benefit from additional payload space, too.\n\nmbde--- via bitcoin-dev wrote:\n> Hi guys,\n> \n> there are several ways to embed arbitrary data into the blockchain, and\n> this is used by several meta-protocols. Most protocols at this point use\n> OP_RETURN scripts for this.\n> \n> To disincentivize the use of other and more harmful methods to embed\n> data into the chain, in particular via P2SH, I propose to raise the\n> default datacarriersize to 220 byte, so it becomes the \"cheapest\" way of\n> embedding data into the chain.\n> \n> The following graph shows the relation between transaction sizes and\n> payload sizes: http://i.imgur.com/VAGZWBK.png\n> \n> Embedding data with bare-multisig and P2SH can be cheaper in terms of\n> effective transaction size, compared to OP_RETURN with a payload limit\n> of 80 byte. Both methods of embedding data, via bare-multisig and P2SH,\n> were heavily used by the major two meta-protocols on top of Bitcoin:\n> Omni and Counterparty, but both protocols started to use OP_RETRUN data\n> embedding a long time ago.\n> \n> However, currently token sends are usually done one by one, each with a\n> single transaction, and this is a heavy burden for the whole network,\n> e.g. when an exchange sends out withdrawals.\n> \n> We have solutions for \"multi-sends with multi-inputs\" and also\n> considered moving destinations into the payload for token sends, but we\n> need more space, otherwise this solution is limited to very few recipients.\n> \n> I therefore propose to raise the default datacarriersize to 220 byte or\n> higher and I'd be happy to provide a pull request doing so, if this gets\n> positive feedback.\n> \n> - dexx\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            }
        ],
        "thread_summary": {
            "title": "Raise default datacarriersize to 220 byte or higher",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "mbde at bitwatch.co"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 3610
        }
    },
    {
        "title": "[bitcoin-dev] Update links (use ssl-variant) to opensource.org/[..x..]MIT ?",
        "thread_messages": [
            {
                "author": "Felix Wolfsteller",
                "date": "2018-01-04T10:08:08",
                "message_text_only": "Hey there\nMost source files contain the \"default\" copyright-header (also build by a\nscript in devtools/copyright_header.py), which points out that the MIT\nlicense can be found in the COPYING file or at\nhttp://www.opensource.org/licenses/mit-license.php.\n\nHowever, the provided link is 1) using http where it could use https, 2)\nresulting in a redirect (https://opensource.org/licenses/mit-license.php)\nanyway.\nI am strongly in favor of using https where possible (I guess there are\nmany other non-ssl links in the code base, but lets tackle the easier ones\nfirst).\n\nI propose that I\n1) create a issue on github,\n2) `sed -i` the relevant links,\n3) create a PR on github,\n4) come back to the mailing list.\n\nThis change would affect a few hundred files I guess.\n\nA question remaining is this change would require a\ncopyright-year-extension (to 2018), too.\n\nAn example header can be seen e.g. here\nhttps://github.com/bitcoin/bitcoin/blob/a9a49e6e7e8df13d80a6dc3245ce7ef041942e9b/src/consensus/merkle.cpp#L3\n\nI'd be happy about quick feedback - do not know the culture here, yet.\n\nHave fun\nFelix\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180104/e83674fd/attachment.html>"
            },
            {
                "author": "Felix Wolfsteller",
                "date": "2018-01-15T14:33:28",
                "message_text_only": "I am a bit disappointed about the feedback (just received one off-list ;)\n), but understand now that this mailing list is protocol-only discussions.\nSo - sorry for that. Anybody interested can follow progress here:\nhttps://github.com/bitcoin/bitcoin/issues/12190\nThanks, Felix\n\nOn Thu, Jan 4, 2018 at 11:08 AM, Felix Wolfsteller <\nfelix.wolfsteller at gmail.com> wrote:\n\n> Hey there\n> Most source files contain the \"default\" copyright-header (also build by a\n> script in devtools/copyright_header.py), which points out that the MIT\n> license can be found in the COPYING file or at http://www.opensource.org/\n> licenses/mit-license.php.\n>\n> However, the provided link is 1) using http where it could use https, 2)\n> resulting in a redirect (https://opensource.org/licenses/mit-license.php)\n> anyway.\n> I am strongly in favor of using https where possible (I guess there are\n> many other non-ssl links in the code base, but lets tackle the easier ones\n> first).\n>\n> I propose that I\n> 1) create a issue on github,\n> 2) `sed -i` the relevant links,\n> 3) create a PR on github,\n> 4) come back to the mailing list.\n>\n> This change would affect a few hundred files I guess.\n>\n> A question remaining is this change would require a\n> copyright-year-extension (to 2018), too.\n>\n> An example header can be seen e.g. here\n> https://github.com/bitcoin/bitcoin/blob/a9a49e6e7e8df13d80a6dc3245ce7e\n> f041942e9b/src/consensus/merkle.cpp#L3\n>\n> I'd be happy about quick feedback - do not know the culture here, yet.\n>\n> Have fun\n> Felix\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180115/9d29b778/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Update links (use ssl-variant) to opensource.org/MIT ?",
            "categories": [
                "bitcoin-dev",
                "..x.."
            ],
            "authors": [
                "Felix Wolfsteller"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 2978
        }
    },
    {
        "title": "[bitcoin-dev] Proof-of-Loss",
        "thread_messages": [
            {
                "author": "Mirelo",
                "date": "2018-01-04T10:54:31",
                "message_text_only": "Hi,\n\nThe paper now includes the pseudocode for block validation:\n\nhttps://proof-of-loss.money/\n\nAgain, please direct any feedback to my email.\n\nRegards,\n\nMirelo\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180104/823d03d1/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Proof-of-Loss",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Mirelo"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 343
        }
    },
    {
        "title": "[bitcoin-dev] Bech32 and P2SH\u00b2",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2018-01-04T14:23:05",
                "message_text_only": "I know I'm super-late to bring this up, but was there a reason Bech32 omitted \nthe previously-discussed P2SH\u00b2 improvements? Since deployment isn't too \nwidespread yet, maybe it'd be worth a quick revision to add this?\n\nFor those unfamiliar with the concept, the idea is to have the address include \nthe *single* SHA256 hash of the public key or script, rather than \nRIPEMD160(SHA256(pubkey)) or SHA256(SHA256(script)). The sender would then \nperform the second hash to produce the output. Doing this would in the future \nenable relaying the \"middle-hash\" as a way to prove the final hash is in fact \na hash itself, thereby proving it is not embedded data spam.\n\nBech32 seems like a huge missed opportunity to add this, since everyone will \nprobably be upgrading to it at some point.\n\nLuke"
            },
            {
                "author": "Luke Dashjr",
                "date": "2018-01-06T00:26:51",
                "message_text_only": "I've posted an initial draft of a possible Bech32 revision/replacement here:\n\nhttps://github.com/luke-jr/bips/blob/new_bech32_p2sh2/bip-bech32-p2sh2.mediawiki\n\nOn Thursday 04 January 2018 2:23:05 PM Luke Dashjr via bitcoin-dev wrote:\n> I know I'm super-late to bring this up, but was there a reason Bech32\n> omitted the previously-discussed P2SH\u00b2 improvements? Since deployment\n> isn't too widespread yet, maybe it'd be worth a quick revision to add\n> this?\n> \n> For those unfamiliar with the concept, the idea is to have the address\n> include the *single* SHA256 hash of the public key or script, rather than\n> RIPEMD160(SHA256(pubkey)) or SHA256(SHA256(script)). The sender would then\n> perform the second hash to produce the output. Doing this would in the\n> future enable relaying the \"middle-hash\" as a way to prove the final hash\n> is in fact a hash itself, thereby proving it is not embedded data spam.\n> \n> Bech32 seems like a huge missed opportunity to add this, since everyone\n> will probably be upgrading to it at some point.\n> \n> Luke\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-06T00:44:20",
                "message_text_only": "P2SH^2 wasn't a serious proposal-- I just suggested it as a thought\nexperiment. I don't think it offers much useful in the context of\nBitcoin today. Particularly since weight calculations have made output\nspace relatively more expensive and fees are at quite non-negligible\nrates interest in \"storing data\" in outputs should at least not be\nincreasing.\n\nMoreover, unfortunately, people already rushed bech32 to market in\nadvance of practically any public review-- regrettable but it is what\nit is... I don't think adding more address diversity at this time\nwouldn't be good for the ecosystem.\n\nWhat we might want to do is consider working on an address-next\nproposal that has an explicit timeframe of N years out, and very loud\ndon't deploy this--- layered hashing is just one very minor slightly\nnice to have... things like coded expiration times, abilities to have\namounts under checksum, etc. are probably more worth consideration.\n\n\n\nOn Thu, Jan 4, 2018 at 2:23 PM, Luke Dashjr via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> I know I'm super-late to bring this up, but was there a reason Bech32 omitted\n> the previously-discussed P2SH\u00b2 improvements? Since deployment isn't too\n> widespread yet, maybe it'd be worth a quick revision to add this?\n>\n> For those unfamiliar with the concept, the idea is to have the address include\n> the *single* SHA256 hash of the public key or script, rather than\n> RIPEMD160(SHA256(pubkey)) or SHA256(SHA256(script)). The sender would then\n> perform the second hash to produce the output. Doing this would in the future\n> enable relaying the \"middle-hash\" as a way to prove the final hash is in fact\n> a hash itself, thereby proving it is not embedded data spam.\n>\n> Bech32 seems like a huge missed opportunity to add this, since everyone will\n> probably be upgrading to it at some point.\n>\n> Luke\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Adam Ritter",
                "date": "2018-01-06T10:05:11",
                "message_text_only": "The question that I didn't see answered in the Bech32 proposal is why\nsomething like the BIP39 mnemoic format is not used for addresses as well.\nThere was a lot of math involved in creating it, but I'm not sure how much\nuser experience testing.\n\nI realized how much harder it is to copy random letters and numbers than\nsimple words only when I copied an addresses and a private keys by hand,\nand even after I knew that I made a mistake, it took significant effort to\nfind the place of the mistake.\n\nIn contrast with BIP39 seeds I never made a mistake when writing down\n(although I have seen a case where somebody made a mistake because a word\nwas twice in the same seed, but this is something that could be fixed).\n\n\nOn Fri, Jan 5, 2018 at 10:44 PM, Gregory Maxwell via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> P2SH^2 wasn't a serious proposal-- I just suggested it as a thought\n> experiment. I don't think it offers much useful in the context of\n> Bitcoin today. Particularly since weight calculations have made output\n> space relatively more expensive and fees are at quite non-negligible\n> rates interest in \"storing data\" in outputs should at least not be\n> increasing.\n>\n> Moreover, unfortunately, people already rushed bech32 to market in\n> advance of practically any public review-- regrettable but it is what\n> it is... I don't think adding more address diversity at this time\n> wouldn't be good for the ecosystem.\n>\n> What we might want to do is consider working on an address-next\n> proposal that has an explicit timeframe of N years out, and very loud\n> don't deploy this--- layered hashing is just one very minor slightly\n> nice to have... things like coded expiration times, abilities to have\n> amounts under checksum, etc. are probably more worth consideration.\n>\n>\n>\n> On Thu, Jan 4, 2018 at 2:23 PM, Luke Dashjr via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > I know I'm super-late to bring this up, but was there a reason Bech32\n> omitted\n> > the previously-discussed P2SH\u00b2 improvements? Since deployment isn't too\n> > widespread yet, maybe it'd be worth a quick revision to add this?\n> >\n> > For those unfamiliar with the concept, the idea is to have the address\n> include\n> > the *single* SHA256 hash of the public key or script, rather than\n> > RIPEMD160(SHA256(pubkey)) or SHA256(SHA256(script)). The sender would\n> then\n> > perform the second hash to produce the output. Doing this would in the\n> future\n> > enable relaying the \"middle-hash\" as a way to prove the final hash is in\n> fact\n> > a hash itself, thereby proving it is not embedded data spam.\n> >\n> > Bech32 seems like a huge missed opportunity to add this, since everyone\n> will\n> > probably be upgrading to it at some point.\n> >\n> > Luke\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180106/db3386a6/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Bech32 and P2SH\u00b2",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Adam Ritter",
                "Luke Dashjr",
                "Gregory Maxwell"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 7392
        }
    },
    {
        "title": "[bitcoin-dev] BIP 39: Add language identifier strings for wordlists",
        "thread_messages": [
            {
                "author": "nullius",
                "date": "2018-01-05T13:58:37",
                "message_text_only": "I propose and request as an enhancement that the BIP 39 wordlist set \nshould specify canonical native language strings to identify each \nwordlist, as well as short ASCII language codes.  At present, the \nlanguages are identified only by their names in English.\n\nStrings properly vetted and recommended by native speakers should \nfacilitate language identification in user interface options or menus.  \nSpecification of language identifier strings would also promote \ninterface consistency between implementations; this may be important if \na user creates a mnemonic in Implementation A, then restores a wallet \nusing that mnemonic in Implementation B.\n\nAs an independent implementer who does not know *all* these different \nlanguages, I monkey-pasted language-native strings from a popular wiki \nsite.  I cannot guarantee that they be all accurate, sensible, or even \nnon-embarrassing.\n\nhttps://github.com/nym-zone/easyseed/blob/1a6e48bbdac9366d9d5d1912dc062dfc3f0db2c6/easyseed.c#L99\n```\n\tLANG(english,\t\t\tu8\"English\",\t\"en\",\tascii_space ),\n\tLANG(chinese_simplified,\tu8\"\u6c49\u8bed\",\t\"zh-CN\",ascii_space ),\n\tLANG(chinese_traditional,\tu8\"\u6f22\u8a9e\",\t\"zh-TW\",ascii_space ),\n\tLANG(french,\t\t\tu8\"Fran\u00e7ais\",\t\"fr\",\tascii_space ),\n\tLANG(italian,\t\t\tu8\"Italiano\",\t\"it\",\tascii_space ),\n\tLANG(japanese,\t\t\tu8\"\u65e5\u672c\u8a9e\",\t\"ja\",\tu8\"\\u3000\"  ),\n\tLANG(korean,\t\t\tu8\"\ud55c\uad6d\uc5b4\",\t\"ko\",\tascii_space ),\n\tLANG(spanish,\t\t\tu8\"Espa\u00f1ol\",\t\"es\",\tascii_space )\n```\n\nPer the comment at #L85 of the quoted file, I also know that for my \nshort identifiers for Chinese, \u201czh-CN\u201d and \u201czh-TW\u201d, are imprecise at \nbest\u2014insofar as Hong Kong uses Traditional; and overseas Chinese may use \neither.  For differentiating the two Chinese writing variants, are there \nany appropriate standardized or customary short ASCII language IDs \nsimilar to ISO 3166-1 alpha-2 which are purely linguistic, and not fit \nto present-day political boundaries?\n\nMy general suggestion is that the specification of appropriate strings \nin bitcoin:bips/bip-0039/bip-0039-wordlists.md be made part of the \nprocess for accepting new wordlists.  My specific request is that such \nstrings be ascertained for the wordlists already existing, preferably \nfrom the persons involved in the original pull requests therefor.\n\nShould this proposal be \u201cconcept ACKed\u201d by appropriate parties, then I \nmay open a pull request suggesting an appropriate format for specifying \nthis information in the repository.  However, I will must needs leave \nthe vetting of appropriate strings to native speakers or experts in the \nrespective languages.\n\nPrior references:  The wordlist additions at PRs #92, #130 (Japanese); \n#100 (Spanish); #114 (Chinese, both variants); #152 (French); #306 \n(Italian); #570 (Korean); #621 (Indonesian, *proposed*, open).\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 228 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180105/c0a9128b/attachment.sig>"
            },
            {
                "author": "Sjors Provoost",
                "date": "2018-01-05T16:04:10",
                "message_text_only": "I\u2019m not a fan of language specific word lists within the current BIP-39 standard. Very few wallets support anything other than English, which can lead to vendor lock-in and long term loss of funds if a rare non-English wallet disappears.\n\nHowever, because people can memorize things better in their native tongue, supporting multiple languages seems quite useful.\n\nI would prefer a new standard where words are mapped to integers rather than to a literal string. For each language a mapping from words to integers would be published. In addition to that, there would be a mapping from original language words to matching (in terms of integer value, not meaning) English words that people can print on an A4 paper. This would allow them to enter a mnemonic into e.g. a hardware wallet that only support English. Such lists are more likely to be around 100 years from now than some ancient piece of software.\n\nThis would not work with the current BIP-39 (duress) password, but this feature could be replaced by appending words (with or without a checksum for that addition).\n\nA replacement for BIP-39 would be a good opportunity to produce a better English dictionary as Nic Johnson suggested a while ago:\n\t\u2022 all words are 4-8 characters\n\t\u2022 all 4-character prefixes are unique (very useful for hardware wallets)\n\t\u2022 no two words have edit distance < 2\n\nWallets need to be able to distinguish between the old and new standard, so un-upgraded BIP 39 wallets should consider all new mnemonics invalid. At the same time, some new wallets may not wish to support BIP39. They shouldn't be burdened with storing the old word list.\n\nA solution is to sort the new word list such that reused words appear first. When generating a mnemonic, at least one word unique to the new list must be present. A wallet only needs to know the index of the last BIP39 overlapping word. They reject a proposed mnemonic if none of the elements use a word with a higher index.\n\nFor my above point and some related ideas, see: https://github.com/satoshilabs/slips/issues/103\n\nSjors\n\n> Op 5 jan. 2018, om 14:58 heeft nullius via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:\n> \n> I propose and request as an enhancement that the BIP 39 wordlist set should specify canonical native language strings to identify each wordlist, as well as short ASCII language codes.  At present, the languages are identified only by their names in English.\n> \n> Strings properly vetted and recommended by native speakers should facilitate language identification in user interface options or menus.  Specification of language identifier strings would also promote interface consistency between implementations; this may be important if a user creates a mnemonic in Implementation A, then restores a wallet using that mnemonic in Implementation B.\n> \n> As an independent implementer who does not know *all* these different languages, I monkey-pasted language-native strings from a popular wiki site.  I cannot guarantee that they be all accurate, sensible, or even non-embarrassing.\n> \n> https://github.com/nym-zone/easyseed/blob/1a6e48bbdac9366d9d5d1912dc062dfc3f0db2c6/easyseed.c#L99\n> ```\n> \tLANG(english,\t\t\tu8\"English\",\t\"en\",\tascii_space ),\n> \tLANG(chinese_simplified,\tu8\"\u6c49\u8bed\",\t\"zh-CN\",ascii_space ),\n> \tLANG(chinese_traditional,\tu8\"\u6f22\u8a9e\",\t\"zh-TW\",ascii_space ),\n> \tLANG(french,\t\t\tu8\"Fran\u00e7ais\",\t\"fr\",\tascii_space ),\n> \tLANG(italian,\t\t\tu8\"Italiano\",\t\"it\",\tascii_space ),\n> \tLANG(japanese,\t\t\tu8\"\u65e5\u672c\u8a9e\",\t\"ja\",\tu8\"\\u3000\"  ),\n> \tLANG(korean,\t\t\tu8\"\ud55c\uad6d\uc5b4\",\t\"ko\",\tascii_space ),\n> \tLANG(spanish,\t\t\tu8\"Espa\u00f1ol\",\t\"es\",\tascii_space )\n> ```\n> \n> Per the comment at #L85 of the quoted file, I also know that for my short identifiers for Chinese, \u201czh-CN\u201d and \u201czh-TW\u201d, are imprecise at best\u2014insofar as Hong Kong uses Traditional; and overseas Chinese may use either.  For differentiating the two Chinese writing variants, are there any appropriate standardized or customary short ASCII language IDs similar to ISO 3166-1 alpha-2 which are purely linguistic, and not fit to present-day political boundaries?\n> \n> My general suggestion is that the specification of appropriate strings in bitcoin:bips/bip-0039/bip-0039-wordlists.md be made part of the process for accepting new wordlists.  My specific request is that such strings be ascertained for the wordlists already existing, preferably from the persons involved in the original pull requests therefor.\n> \n> Should this proposal be \u201cconcept ACKed\u201d by appropriate parties, then I may open a pull request suggesting an appropriate format for specifying this information in the repository.  However, I will must needs leave the vetting of appropriate strings to native speakers or experts in the respective languages.\n> \n> Prior references:  The wordlist additions at PRs #92, #130 (Japanese); #100 (Spanish); #114 (Chinese, both variants); #152 (French); #306 (Italian); #570 (Korean); #621 (Indonesian, *proposed*, open).\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180105/988669cf/attachment.sig>"
            },
            {
                "author": "nullius",
                "date": "2018-01-05T18:08:50",
                "message_text_only": "On 2018-01-05 at 16:04:10 +0000, Sjors Provoost <sjors at sprovoost.nl> \nwrote:\n>I\u2019m not a fan of language specific word lists within the current BIP-39 \n>standard. Very few wallets support anything other than English, which \n>can lead to vendor lock-in and long term loss of funds if a rare \n>non-English wallet disappears.\n>\n>However, because people can memorize things better in their native \n>tongue, supporting multiple languages seems quite useful.\n>\n>I would prefer a new standard [...] A replacement for BIP-39 [...]\n>\n>[snip]\n>For my above point and some related ideas, see: \n>https://github.com/satoshilabs/slips/issues/103\n\nYou present some interesting ideas; and I will be much interested in the \nGithub issue you referenced\u2014thanks for that.  However, this discussion \nis *far* beyond the scope of my simple proposal and request to add \nstandardized native language and short-ASCII identifier strings to the \nBIP repository.  I suggest that readers solely interested in the \nexisting BIP 39 standard and its direct application to Bitcoin should \nstop reading right here.\n\n----\n\nThat being said, I should briefly address some of the issues you raise \n(with further discussion best continued elsewhere):\n\nI *strongly* urge the importance of language-specific standardized \nwordlists.  Even an individual who has secondarily acquired reasonable \nfluency in English will most likely have the least difficulty \nmemorizing, transcribing, and otherwise handling a \u201cmother-tongue\u201d \nmnemonic.  Such an advantage is important in applications whereby even \nslight errors can be fatal, and every bit counts.  This is to say \nnothing of persons who have limited or no English-language knowledge.\n\nYet for multiple reasons, multilanguage support is only feasible with \nstandardization.  Wordlist creation is a highly specialized task.  \nIndependent implementation of standards is imperative for avoiding \nimplementation lock-in; and independent implementors (such as I) would \nbe unable to create sets multi-language wordlists on their own, anyway.  \nFor a view of the language-specific process involved in creating a \nwordlist, I invite everybody following this discussion to review BIP \nrepository PRs #92, #130 (Japanese); #100 (Spanish); #114 (Chinese, both \nvariants); #152 (French); #306 (Italian); #544 (Korean, rejected); and \n#570 (Korean).  The rejection of #544 for Korean, and its superseding \nwith #570 is particularly instructive.\n\nWith standardized wordlists, independent implementation is easy.  In my \nown implementation, the language switching backend (excluding the UI[1]) \nfor multilingual mnemonic generation required only relatively small C \ncode changes, as seen here[0]:\n\n[0] https://github.com/nym-zone/easyseed/commit/5b6a6668458d96d6ccc4bf19e4fd40fe6ea72fec#diff-20dcf1782b7568b85ea01ed695abeb02\n\n[1] https://github.com/nym-zone/easyseed/commit/1a6e48bbdac9366d9d5d1912dc062dfc3f0db2c6#diff-20dcf1782b7568b85ea01ed695abeb02\n\nAdmittedly, the multilingual requirements for seed generation will take \na bit more; and my nonstandard, non-BIP39 ideas which require decoding \nwords directly back to bits will take yet more.  But it is still not \nproblematic.\n\nI only began writing this tool one week ago, as of today; and it has \nbeen a side project requiring small amounts of time, not a full-time \ndedicated task.  When I fully complete all aspects of seed generation, \nthen users will have the option of another simple open-source tool which \n*will* be able to output a binary or BIP-32-formatted (\u201cxprv\u201d) 512-bit \nseed, given input of an existing mnemonic in any language supported by \nofficial BIP 39 wordlists.  Output can then be imported to any wallet \nsoftware which supports BIP 32, regardless of the wallet\u2019s langauge \nsupport (and whether or not the wallet supports BIP 39 at all).\n\n**The ease of creating such tools squarely answers your concerns about \nvendor lock-in.**  And yes, it\u2019s easy.  I can attest as a lone coder, \nit\u2019s easy for me to create \u201ceasyseed\u201d as a side project!\n\nFinally, aside:  In the discussion at SLIP repository issue #103, I see \nmention of m-of-n SSSS.  I have been mentally whiteboarding just such an \napplication involving mnemonics.  Watch for it.  <g>  It is likely that \nI will crib the BIP 39 wordlists, given the impossibility that I could \ncreate my own set of wordlists in many languages.  I only wish that the \nBIP repository had support for more languages.  More!  Adding each new \nlanguage to my implementation(s) will require approximately one-line \ncode changes for me.\n\n(Aside further:  Why is there not a Dutch wordlist?  I should like to \nadd that, please\u2014meneer Provoost.  More wordlists!)\n\nAside still yet further:  Should you be interested in more general \napplications of mnemonic phrases for pseudorandom strings, I think you \nwill like this future feature which currently exists only as an Easter \negg, (un)documented in my commit log:\n\nhttps://github.com/nym-zone/easyseed/commit/ba77be1b1a1f0c6af50ceba5c89f4adece7e5dff\n\nFurther discussion is invited by private mail, in an appropriate public \nvenue, or otherwise not on a bitcoin-dev thread which makes a simple \nrequest and proposal as to the existing BIP 39 standard\u2014thanks.\n\n-- \nnullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\nBitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n\u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\nNo!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 228 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180105/7673c033/attachment.sig>"
            },
            {
                "author": "Pavol Rusnak",
                "date": "2018-01-07T15:16:47",
                "message_text_only": "On 05/01/18 14:58, nullius via bitcoin-dev wrote:\n> I propose and request as an enhancement that the BIP 39 wordlist set\n> should specify canonical native language strings to identify each\n> wordlist, as well as short ASCII language codes.\u00a0 At present, the\n> languages are identified only by their names in English.\n\nI am advising not to use any other language than English for BIP39. I\ngot persuaded to allow more languages when writing BIP39 spec, but I\nlearned that it was something I should've been more persistently against.\n\nI am currently drafting a new standard[1] which will allow also Shamir\nSecret Scheme Splitting and there we disallow usage of a custom wordlist\nin order to eradicate this mess. Will try to push this as BIP too once\nwe get it to the point we are OK with the contents.\n\nhttps://github.com/satoshilabs/slips/blob/master/slip-0039.md\n\n-- \nBest Regards / S pozdravom,\n\nPavol \"stick\" Rusnak\nCTO, SatoshiLabs\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180107/8eef9b25/attachment.sig>"
            },
            {
                "author": "\u6728\u30ce\u4e0b\u3058\u3087\u306a",
                "date": "2018-01-08T07:35:52",
                "message_text_only": "This is very sad.\n\nThe number one problem in Japan with BIP39 seeds is with English words.\n\nI have seen a 60 year old Japanese man writing down his phrase (because he\nkept on failing recovery), and watched him write down \"aneter\" for\n\"amateur\"...\nSo instead I had him use Copay which generates Japanese words, wrote it\ndown 20x faster, and perfectly. Was able to recovery on the first try.\nImagine if I didn't tell him to try recovery before using it? (iirc Trezor\ndoesn't say to wipe and recover before using???)\n\nIf you understand English and can spell, you read a word, your brain\nprocesses the word, and you can spell it on your own when writing down.\nNot many Japanese people can do that, so they need to copy letter for\nletter, taking a long time, and still messing up on occasion.\nEven native English speakers who can't spell can mess it up badly too.\n\nTo be honest, a key storage format that doesn't support multiple languages\nis much more dangerous than any doomsday situation you can think of for\nsupporting them.\n\nBIP39 states that seed derivation is INDEPENDENT of wordlists, and that\nfailure to verify checksum (not knowing the wordlist falls under this)\nshould \"WARN\" the user and not fail, continuing to derive the seed anyways.\nCurrently the only wallet I know of following this part of the BIP is,\nironically Electrum. I can recover any BIP39 phrase from any wordlist even\nif Electrum doesn't know it.\n\nI really hope you reconsider multi-language support for everything moving\nforward.\n\nI understand it's a nightmare to plan for and support, which is fine if you\nwere just developing a piece of software sold by a company based in a\nwestern country... but you are trying to make a standard for an\ninternational currency. Defining \"everyone should only use English, because\nASCII is easier to plan for\" is not a good way to move forward as a\ncurrency.\n\nI am just thinking of all the users I will have to help out down the road\nwhen they come crying to me saying they can't recover, and it turns out\nthey wrote down some non-English gibberish in roman characters claiming \"I\nwrote the English just as it was on the screen!\" and I have to write a\nbrute force script to try all the word combinations for the mystery words.\n(I have done this before)\n\nJust my two cents. Not to be accusatory or anything.\nPlease reconsider. Thanks.\n\n2018-01-08 0:16 GMT+09:00 Pavol Rusnak via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org>:\n\n> On 05/01/18 14:58, nullius via bitcoin-dev wrote:\n> > I propose and request as an enhancement that the BIP 39 wordlist set\n> > should specify canonical native language strings to identify each\n> > wordlist, as well as short ASCII language codes.  At present, the\n> > languages are identified only by their names in English.\n>\n> I am advising not to use any other language than English for BIP39. I\n> got persuaded to allow more languages when writing BIP39 spec, but I\n> learned that it was something I should've been more persistently against.\n>\n> I am currently drafting a new standard[1] which will allow also Shamir\n> Secret Scheme Splitting and there we disallow usage of a custom wordlist\n> in order to eradicate this mess. Will try to push this as BIP too once\n> we get it to the point we are OK with the contents.\n>\n> https://github.com/satoshilabs/slips/blob/master/slip-0039.md\n>\n> --\n> Best Regards / S pozdravom,\n>\n> Pavol \"stick\" Rusnak\n> CTO, SatoshiLabs\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n\n\n-- \n-----BEGIN PGP PUBLIC KEY BLOCK-----\nComment: http://openpgpjs.org\n\nxsBNBFTmJ8oBB/9rd+7XLxZG/x/KnhkVK2WBG8ySx91fs+qQfHIK1JrakSV3\nx6x0cK3XLClASLLDomm7Od3Q/fMFzdwCEqj6z60T8wgKxsjWYSGL3mq8ucdv\niBjC3wGauk5dQKtT7tkCFyQQbX/uMsBM4ccGBICoDmIJlwJIj7fAZVqGxGOM\nbO1RhYb4dbQA2qxYP7wSsHJ6/ZNAXyEphOj6blUzdqO0exAbCOZWWF+E/1SC\nEuKO4RmL7Imdep7uc2Qze1UpJCZx7ASHl2IZ4UD0G3Qr3pI6/jvNlaqCTa3U\n3/YeJwEubFsd0AVy0zs809RcKKgX3W1q+hVDTeWinem9RiOG/vT+Eec/ABEB\nAAHNI2tpbm9zaGl0YSA8a2lub3NoaXRham9uYUBnbWFpbC5jb20+wsByBBAB\nCAAmBQJU5ifRBgsJCAcDAgkQRB9iZ30dlisEFQgCCgMWAgECGwMCHgEAAC6Z\nB/9otobf0ASHYdlUBeIPXdDopyjQhR2RiZGYaS0VZ5zzHYLDDMW6ZIYm5CjO\nFc09ETLGKFxH2RcCOK2dzwz+KRU4xqOrt/l5gyd50cFE1nOhUN9+/XaPgrou\nWhyT9xLeGit7Xqhht93z2+VanTtJAG6lWbAZLIZAMGMuLX6sJDCO0GiO5zxa\n02Q2D3kh5GL57A5+oVOna12JBRaIA5eBGKVCp3KToT/z48pxBe3WAmLo0zXr\nhEgTSzssfb2zTwtB3Ogoedj+cU2bHJvJ8upS/jMr3TcdguySmxJlGpocVC/e\nqxq12Njv+LiETOrD8atGmXCnA+nFNljBkz+l6ADl93jHzsBNBFTmJ9EBCACu\nQq9ZnP+aLU/Rt6clAfiHfTFBsJvLKsdIKeE6qHzsU1E7A7bGQKTtLEnhCCQE\nW+OQP+sgbOWowIdH9PpwLJ3Op+NhvLlMxRvbT36LwCmBL0yD7bMqxxmmVj8n\nvlMMRSe4wDSIG19Oy7701imnHZPm/pnPlneg/Meu/UffpcDWYBbAFX8nrXPY\nvkVULcI/qTcCxW/+S9fwoXjQhWHaiJJ6y3cYOSitN31W9zgcMvLwLX3JgDxE\nflkwq/M+ZkfCYnS3GAPEt8GkVKy2eHtCJuNkGFlCAmKMX0yWzHRAkqOMN5KP\nLFbkKY2GQl13ztWp82QYJZpj5af6dmyUosurn6AZABEBAAHCwF8EGAEIABMF\nAlTmJ9QJEEQfYmd9HZYrAhsMAABKbgf/Ulu5JAk4fXgH0DtkMmdkFiKEFdkW\n0Wkw7Vhd5eZ4NzeP9kOkD01OGweT9hqzwhfT2CNXCGxh4UnvEM1ZMFypIKdq\n0XpLLJMrDOQO021UjAa56vHZPAVmAM01z5VzHJ7ekjgwrgMLmVkm0jWKEKaO\nn/MW7CyphG7QcZ6cJX2f6uJcekBlZRw9TNYRnojMjkutlOVhYJ3J78nc/k0p\nkcgV63GB6D7wHRF4TVe4xIBqKpbBhhN+ISwFN1z+gx3lfyRMSmiTSrGdKEQe\nXSIQKG8XZQZUDhLNkqPS+7EMV1g7+lOfT4GhLL68dUXDa1e9YxGH6zkpVECw\nSpe3vsHZr6CqFg==\n=/vUJ\n-----END PGP PUBLIC KEY BLOCK-----\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180108/af0471be/attachment.html>"
            },
            {
                "author": "nullius",
                "date": "2018-01-08T11:13:28",
                "message_text_only": "On 2018-01-08 at 07:35:52 +0000, \u6728\u30ce\u4e0b\u3058\u3087\u306a <kinoshitajona at gmail.com> \nwrote:\n>This is very sad.\n>\n>The number one problem in Japan with BIP39 seeds is with English words.\n>\n>I have seen a 60 year old Japanese man writing down his phrase (because \n>he kept on failing recovery), and watched him write down \"aneter\" for \n>\"amateur\"...\n>\n>[...]\n>\n>If you understand English and can spell, you read a word, your brain \n>processes the word, and you can spell it on your own when writing down.  \n>Not many Japanese people can do that, so they need to copy letter for \n>letter, taking a long time, and still messing up on occasion.\n>\n>[...]\n>\n>Defining \"everyone should only use English, because ASCII is easier to \n>plan for\" is not a good way to move forward as a currency.\n\nWell said.  Thank you for telling of these experiences.  Now please, \nlet\u2019s put the shoe on the other foot.\n\nI ask everybody who wants an English-only mnemonic standard to entrust \n*their own money* to their abilities to very, very carefully write this \ndown\u2014then later, type it back in:\n\n\u3059\u3055\u3093\u3000\u305f\u3093\u308d\u3000\u308a\u3086\u3046\u3000\u3057\u3082\u3093\u3000\u3066\u3044\u304a\u3093\u3000\u3057\u3068\u3046\n\u3068\u3053\u3084\u3000\u306f\u3084\u3044\u3000\u304a\u3046\u3055\u307e\u3000\u307b\u304f\u308d\u3000\u3051\u3061\u3083\u3063\u3075\u3000\u305f\u3082\u3064\n\n(Approximate translation:  \u201cWhatever would you do if Bitcoin had been \ninvented by somebody named Satoshi Nakamoto?\u201d)\n\nNo, wait:  That is only a 12-word mnemonic.  We are probably talking \nabout a Trezor; so now, hey you there, stake the backup of your life\u2019s \nsavings on your ability to handwrite *this*:\n\n\u306b\u3042\u3046\u3000\u3057\u3072\u3087\u3046\u3000\u306b\u3093\u3059\u3046\u3000\u3072\u3048\u308b\u3000\u304b\u3044\u3053\u3046\u3000\u3044\u306e\u308b\u3000\u306d\u3093\u3057\u3000\u306f\u3042\u3055\u3093\u3000\u3072\u3053\u304f\n\u3068\u3046\u304f\u3000\u304d\u3082\u305f\u3081\u3057\u3000\u305d\u306a\u305f\u3000\u3053\u306a\u3053\u306a\u3000\u306b\u3055\u3093\u304b\u305f\u3093\u305d\u3000\u308d\u3093\u304d\u3000\u3081\u3044\u3042\u3093\u3000\u307f\u308f\u304f\n\u3078\u3053\u3080\u3000\u3059\u3072\u3087\u3046\u3000\u304a\u3084\u3086\u3072\u3000\u3075\u305b\u304f\u3000\u3051\u3055\u304d\u3000\u3081\u3044\u304d\u3087\u304f\u3000\u3053\u3093\u307e\u3051\n\nReady to bet your money on *that* as a backup phrase in your own hands?  \nNo?  Then please, stop demanding that others risk *their* money on the \ninverse case.\n\n----\n\nIf you cheat here by having studied Japanese, then remember that many \nJapanese people know English and other European languages, too.  Then \nthink of how much money would be lost by your non-Japanese-literate \nfamily and friends\u2014if BIP 39 had only Japanese wordlists, and your folks \nneeded to wrestle with the above phrases as their \u201cmnemonics\u201d.\n\nIn such cases, the phrases cannot be called \u201cmnemonics\u201d at all.  A \n\u201cmnemonic\u201d implies aid to memory.  Gibberish in a wholly alien writing \nsystem is much worse even than transcribing pseudorandom hex strings.  \nThe Japanese man in the quoted story, who wrote \u201caneter\u201d for \u201camateur\u201d, \nwas not dealing with a *mnemonic*:  He was using the world\u2019s most \ninefficient means of making cryptic bitstrings *less* userfriendly.\n\n----\n\nI began this thread with a quite simple request:  Is \u201c\u65e5\u672c\u8a9e\u201d an \nappropriate string for identifying the Japanese language to Japanese \nusers?  And what of the other strings I posted for other languages?\n\nI asked this as an implementer working on my own instance of the \ngreatest guard against vendor lock-in and stale software:  Independent \nimplementations.  \u2014  I asked, because obviously, I myself do not speak \nall these different languages; and I want to implement them all.  *All.*\n\nSome replies have been interesting in their own right; but thus far, \nnobody has squarely addressed the substance of my question.\n\nMost worrisome is that much of the discussion has veered into criticism \nof multi-language support.  I opened with a question about other \nlanguages, and I am getting replies which raise a hue and cry of \n\u201cEnglish only!\u201d\n\nThough I am fluent and literate in English, I am uninterested in ever \nimplementing any standard of this nature which is artificially \nrestricted to English.  I am fortunate; for as of this moment, we have a \nstandard called \u201cBIP 39\u201d which has seven non-English wordlists, and four \nmore pending in open pull requests (#432, #442, #493, #621).\n\nI request discussion of language identification strings appropriate for \nuse with that standard.\n\n(P.S., I hope that my system did not mangle anything in the foregoing.  \nI have seen weird copypaste behaviour mess up decomposed characters.  I \nthought of this after I searched for and collected some visually \nfascinating phrases; so I tried to normalize these to NFC...  It should \ngo without saying, easyseed output the Japanese perfectly!)\n\n-- \nnullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\nBitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n\u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\nNo!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 228 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180108/8bba0a34/attachment.sig>"
            },
            {
                "author": "Greg Sanders",
                "date": "2018-01-08T14:34:39",
                "message_text_only": "Has anyone actually used the multilingual support in bip39?\n\nIf a feature of the standard has not been(widely?) used in years, and isn't\nsupported in any major wallet(?), it seems indicative it was a mistake to\nadd it in the first place, since it's a footgun in the making for some poor\nsap who can't even read English letters when almost all documentation is\nwritten in English.\n\nOn Mon, Jan 8, 2018 at 6:13 AM, nullius via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On 2018-01-08 at 07:35:52 +0000, \u6728\u30ce\u4e0b\u3058\u3087\u306a <kinoshitajona at gmail.com> wrote:\n>\n>> This is very sad.\n>>\n>> The number one problem in Japan with BIP39 seeds is with English words.\n>>\n>> I have seen a 60 year old Japanese man writing down his phrase (because\n>> he kept on failing recovery), and watched him write down \"aneter\" for\n>> \"amateur\"...\n>>\n>> [...]\n>>\n>> If you understand English and can spell, you read a word, your brain\n>> processes the word, and you can spell it on your own when writing down.\n>> Not many Japanese people can do that, so they need to copy letter for\n>> letter, taking a long time, and still messing up on occasion.\n>>\n>> [...]\n>>\n>> Defining \"everyone should only use English, because ASCII is easier to\n>> plan for\" is not a good way to move forward as a currency.\n>>\n>\n> Well said.  Thank you for telling of these experiences.  Now please, let\u2019s\n> put the shoe on the other foot.\n>\n> I ask everybody who wants an English-only mnemonic standard to entrust\n> *their own money* to their abilities to very, very carefully write this\n> down\u2014then later, type it back in:\n>\n> \u3059\u3055\u3093 \u305f\u3093\u308d \u308a\u3086\u3046 \u3057\u3082\u3093 \u3066\u3044\u304a\u3093 \u3057\u3068\u3046\n> \u3068\u3053\u3084 \u306f\u3084\u3044 \u304a\u3046\u3055\u307e \u307b\u304f\u308d \u3051\u3061\u3083\u3063\u3075 \u305f\u3082\u3064\n>\n> (Approximate translation:  \u201cWhatever would you do if Bitcoin had been\n> invented by somebody named Satoshi Nakamoto?\u201d)\n>\n> No, wait:  That is only a 12-word mnemonic.  We are probably talking about\n> a Trezor; so now, hey you there, stake the backup of your life\u2019s savings on\n> your ability to handwrite *this*:\n>\n> \u306b\u3042\u3046 \u3057\u3072\u3087\u3046 \u306b\u3093\u3059\u3046 \u3072\u3048\u308b \u304b\u3044\u3053\u3046 \u3044\u306e\u308b \u306d\u3093\u3057 \u306f\u3042\u3055\u3093 \u3072\u3053\u304f\n> \u3068\u3046\u304f \u304d\u3082\u305f\u3081\u3057 \u305d\u306a\u305f \u3053\u306a\u3053\u306a \u306b\u3055\u3093\u304b\u305f\u3093\u305d \u308d\u3093\u304d \u3081\u3044\u3042\u3093 \u307f\u308f\u304f\n> \u3078\u3053\u3080 \u3059\u3072\u3087\u3046 \u304a\u3084\u3086\u3072 \u3075\u305b\u304f \u3051\u3055\u304d \u3081\u3044\u304d\u3087\u304f \u3053\u3093\u307e\u3051\n>\n> Ready to bet your money on *that* as a backup phrase in your own hands?\n> No?  Then please, stop demanding that others risk *their* money on the\n> inverse case.\n>\n> ----\n>\n> If you cheat here by having studied Japanese, then remember that many\n> Japanese people know English and other European languages, too.  Then think\n> of how much money would be lost by your non-Japanese-literate family and\n> friends\u2014if BIP 39 had only Japanese wordlists, and your folks needed to\n> wrestle with the above phrases as their \u201cmnemonics\u201d.\n>\n> In such cases, the phrases cannot be called \u201cmnemonics\u201d at all.  A\n> \u201cmnemonic\u201d implies aid to memory.  Gibberish in a wholly alien writing\n> system is much worse even than transcribing pseudorandom hex strings.  The\n> Japanese man in the quoted story, who wrote \u201caneter\u201d for \u201camateur\u201d, was not\n> dealing with a *mnemonic*:  He was using the world\u2019s most inefficient means\n> of making cryptic bitstrings *less* userfriendly.\n>\n> ----\n>\n> I began this thread with a quite simple request:  Is \u201c\u65e5\u672c\u8a9e\u201d an appropriate\n> string for identifying the Japanese language to Japanese users?  And what\n> of the other strings I posted for other languages?\n>\n> I asked this as an implementer working on my own instance of the greatest\n> guard against vendor lock-in and stale software:  Independent\n> implementations.  \u2014  I asked, because obviously, I myself do not speak all\n> these different languages; and I want to implement them all.  *All.*\n>\n> Some replies have been interesting in their own right; but thus far,\n> nobody has squarely addressed the substance of my question.\n>\n> Most worrisome is that much of the discussion has veered into criticism of\n> multi-language support.  I opened with a question about other languages,\n> and I am getting replies which raise a hue and cry of \u201cEnglish only!\u201d\n>\n> Though I am fluent and literate in English, I am uninterested in ever\n> implementing any standard of this nature which is artificially restricted\n> to English.  I am fortunate; for as of this moment, we have a standard\n> called \u201cBIP 39\u201d which has seven non-English wordlists, and four more\n> pending in open pull requests (#432, #442, #493, #621).\n>\n> I request discussion of language identification strings appropriate for\n> use with that standard.\n>\n> (P.S., I hope that my system did not mangle anything in the foregoing.  I\n> have seen weird copypaste behaviour mess up decomposed characters.  I\n> thought of this after I searched for and collected some visually\n> fascinating phrases; so I tried to normalize these to NFC...  It should go\n> without saying, easyseed output the Japanese perfectly!)\n>\n>\n> --\n> nullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\n> Bitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n> 3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n> \u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\n> No!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180108/b348f42f/attachment.html>"
            },
            {
                "author": "Matias Alejo Garcia",
                "date": "2018-01-08T14:52:20",
                "message_text_only": "On Mon, Jan 8, 2018 at 11:34 AM, Greg Sanders via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Has anyone actually used the multilingual support in bip39?\n>\n\n\nCopay (and all its clones) use it.\n\n\n\n\n\n>\n> If a feature of the standard has not been(widely?) used in years, and\n> isn't supported in any major wallet(?), it seems indicative it was a\n> mistake to add it in the first place, since it's a footgun in the making\n> for some poor sap who can't even read English letters when almost all\n> documentation is written in English.\n>\n> On Mon, Jan 8, 2018 at 6:13 AM, nullius via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> On 2018-01-08 at 07:35:52 +0000, \u6728\u30ce\u4e0b\u3058\u3087\u306a <kinoshitajona at gmail.com> wrote:\n>>\n>>> This is very sad.\n>>>\n>>> The number one problem in Japan with BIP39 seeds is with English words.\n>>>\n>>> I have seen a 60 year old Japanese man writing down his phrase (because\n>>> he kept on failing recovery), and watched him write down \"aneter\" for\n>>> \"amateur\"...\n>>>\n>>> [...]\n>>>\n>>> If you understand English and can spell, you read a word, your brain\n>>> processes the word, and you can spell it on your own when writing down.\n>>> Not many Japanese people can do that, so they need to copy letter for\n>>> letter, taking a long time, and still messing up on occasion.\n>>>\n>>> [...]\n>>>\n>>> Defining \"everyone should only use English, because ASCII is easier to\n>>> plan for\" is not a good way to move forward as a currency.\n>>>\n>>\n>> Well said.  Thank you for telling of these experiences.  Now please,\n>> let\u2019s put the shoe on the other foot.\n>>\n>> I ask everybody who wants an English-only mnemonic standard to entrust\n>> *their own money* to their abilities to very, very carefully write this\n>> down\u2014then later, type it back in:\n>>\n>> \u3059\u3055\u3093 \u305f\u3093\u308d \u308a\u3086\u3046 \u3057\u3082\u3093 \u3066\u3044\u304a\u3093 \u3057\u3068\u3046\n>> \u3068\u3053\u3084 \u306f\u3084\u3044 \u304a\u3046\u3055\u307e \u307b\u304f\u308d \u3051\u3061\u3083\u3063\u3075 \u305f\u3082\u3064\n>>\n>> (Approximate translation:  \u201cWhatever would you do if Bitcoin had been\n>> invented by somebody named Satoshi Nakamoto?\u201d)\n>>\n>> No, wait:  That is only a 12-word mnemonic.  We are probably talking\n>> about a Trezor; so now, hey you there, stake the backup of your life\u2019s\n>> savings on your ability to handwrite *this*:\n>>\n>> \u306b\u3042\u3046 \u3057\u3072\u3087\u3046 \u306b\u3093\u3059\u3046 \u3072\u3048\u308b \u304b\u3044\u3053\u3046 \u3044\u306e\u308b \u306d\u3093\u3057 \u306f\u3042\u3055\u3093 \u3072\u3053\u304f\n>> \u3068\u3046\u304f \u304d\u3082\u305f\u3081\u3057 \u305d\u306a\u305f \u3053\u306a\u3053\u306a \u306b\u3055\u3093\u304b\u305f\u3093\u305d \u308d\u3093\u304d \u3081\u3044\u3042\u3093 \u307f\u308f\u304f\n>> \u3078\u3053\u3080 \u3059\u3072\u3087\u3046 \u304a\u3084\u3086\u3072 \u3075\u305b\u304f \u3051\u3055\u304d \u3081\u3044\u304d\u3087\u304f \u3053\u3093\u307e\u3051\n>>\n>> Ready to bet your money on *that* as a backup phrase in your own hands?\n>> No?  Then please, stop demanding that others risk *their* money on the\n>> inverse case.\n>>\n>> ----\n>>\n>> If you cheat here by having studied Japanese, then remember that many\n>> Japanese people know English and other European languages, too.  Then think\n>> of how much money would be lost by your non-Japanese-literate family and\n>> friends\u2014if BIP 39 had only Japanese wordlists, and your folks needed to\n>> wrestle with the above phrases as their \u201cmnemonics\u201d.\n>>\n>> In such cases, the phrases cannot be called \u201cmnemonics\u201d at all.  A\n>> \u201cmnemonic\u201d implies aid to memory.  Gibberish in a wholly alien writing\n>> system is much worse even than transcribing pseudorandom hex strings.  The\n>> Japanese man in the quoted story, who wrote \u201caneter\u201d for \u201camateur\u201d, was not\n>> dealing with a *mnemonic*:  He was using the world\u2019s most inefficient means\n>> of making cryptic bitstrings *less* userfriendly.\n>>\n>> ----\n>>\n>> I began this thread with a quite simple request:  Is \u201c\u65e5\u672c\u8a9e\u201d an appropriate\n>> string for identifying the Japanese language to Japanese users?  And what\n>> of the other strings I posted for other languages?\n>>\n>> I asked this as an implementer working on my own instance of the greatest\n>> guard against vendor lock-in and stale software:  Independent\n>> implementations.  \u2014  I asked, because obviously, I myself do not speak all\n>> these different languages; and I want to implement them all.  *All.*\n>>\n>> Some replies have been interesting in their own right; but thus far,\n>> nobody has squarely addressed the substance of my question.\n>>\n>> Most worrisome is that much of the discussion has veered into criticism\n>> of multi-language support.  I opened with a question about other languages,\n>> and I am getting replies which raise a hue and cry of \u201cEnglish only!\u201d\n>>\n>> Though I am fluent and literate in English, I am uninterested in ever\n>> implementing any standard of this nature which is artificially restricted\n>> to English.  I am fortunate; for as of this moment, we have a standard\n>> called \u201cBIP 39\u201d which has seven non-English wordlists, and four more\n>> pending in open pull requests (#432, #442, #493, #621).\n>>\n>> I request discussion of language identification strings appropriate for\n>> use with that standard.\n>>\n>> (P.S., I hope that my system did not mangle anything in the foregoing.  I\n>> have seen weird copypaste behaviour mess up decomposed characters.  I\n>> thought of this after I searched for and collected some visually\n>> fascinating phrases; so I tried to normalize these to NFC...  It should go\n>> without saying, easyseed output the Japanese perfectly!)\n>>\n>>\n>> --\n>> nullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\n>> Bitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n>> 3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n>> \u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\n>> No!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n\n\n-- \nMat\u00edas Alejo Garcia\n@ematiu\nRoads? Where we're going, we don't need roads!\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180108/eaa842ab/attachment.html>"
            },
            {
                "author": "Sjors Provoost",
                "date": "2018-01-05T17:13:23",
                "message_text_only": "I don\u2019t know about Electrum but many wallets validate the English words, which helps in catching typos.\n\nHardware wallets without a full keyboard, like the Ledger Nano S, won\u2019t even let you freely type characters; you have to select words from a list.\n\nSo although the standard technically allows what you say, if you use anything other than 12, 16 or 24 English words, you\u2019ll have fewer wallets to choose from.\n\nI think it\u2019s better to come up with a new standard than trying to patch BIP-39 at this point, which is why I brought it up.\n\nSjors\n\n> Op 5 jan. 2018, om 17:27 heeft Alan Evans <thealanevans at gmail.com> het volgende geschreven:\n> \n> \"Very few wallets support anything other than English\"\n> \n> By support do you mean allow recovery, validation or generation or all three? For if you can freely type a phrase in (such as Electrum), or even word by word, then the likely-hood is it is supported if they remembered to normalize.\n> \n> Seed generation in BIP0039 requires no dictionary what-so-ever! So there is no word list to lose in the first place. Your funds are accessible with just the characters and the algorithm as described in BIP0039.\n> \n> But your proposal is a million miles away from simply adding some standard in-language names to some word lists feels like it's derailing the OP's simple proposal. Maybe start own email chain about it.\n> \n> Alan\n> \n> On Fri, Jan 5, 2018 at 12:04 PM, Sjors Provoost via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> I\u2019m not a fan of language specific word lists within the current BIP-39 standard. Very few wallets support anything other than English, which can lead to vendor lock-in and long term loss of funds if a rare non-English wallet disappears.\n> \n> However, because people can memorize things better in their native tongue, supporting multiple languages seems quite useful.\n> \n> I would prefer a new standard where words are mapped to integers rather than to a literal string. For each language a mapping from words to integers would be published. In addition to that, there would be a mapping from original language words to matching (in terms of integer value, not meaning) English words that people can print on an A4 paper. This would allow them to enter a mnemonic into e.g. a hardware wallet that only support English. Such lists are more likely to be around 100 years from now than some ancient piece of software.\n> \n> This would not work with the current BIP-39 (duress) password, but this feature could be replaced by appending words (with or without a checksum for that addition).\n> \n> A replacement for BIP-39 would be a good opportunity to produce a better English dictionary as Nic Johnson suggested a while ago:\n>         \u2022 all words are 4-8 characters\n>         \u2022 all 4-character prefixes are unique (very useful for hardware wallets)\n>         \u2022 no two words have edit distance < 2\n> \n> Wallets need to be able to distinguish between the old and new standard, so un-upgraded BIP 39 wallets should consider all new mnemonics invalid. At the same time, some new wallets may not wish to support BIP39. They shouldn't be burdened with storing the old word list.\n> \n> A solution is to sort the new word list such that reused words appear first. When generating a mnemonic, at least one word unique to the new list must be present. A wallet only needs to know the index of the last BIP39 overlapping word. They reject a proposed mnemonic if none of the elements use a word with a higher index.\n> \n> For my above point and some related ideas, see: https://github.com/satoshilabs/slips/issues/103\n> \n> Sjors\n> \n> > Op 5 jan. 2018, om 14:58 heeft nullius via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:\n> >\n> > I propose and request as an enhancement that the BIP 39 wordlist set should specify canonical native language strings to identify each wordlist, as well as short ASCII language codes.  At present, the languages are identified only by their names in English.\n> >\n> > Strings properly vetted and recommended by native speakers should facilitate language identification in user interface options or menus.  Specification of language identifier strings would also promote interface consistency between implementations; this may be important if a user creates a mnemonic in Implementation A, then restores a wallet using that mnemonic in Implementation B.\n> >\n> > As an independent implementer who does not know *all* these different languages, I monkey-pasted language-native strings from a popular wiki site.  I cannot guarantee that they be all accurate, sensible, or even non-embarrassing.\n> >\n> > https://github.com/nym-zone/easyseed/blob/1a6e48bbdac9366d9d5d1912dc062dfc3f0db2c6/easyseed.c#L99\n> > ```\n> >       LANG(english,                   u8\"English\",    \"en\",   ascii_space ),\n> >       LANG(chinese_simplified,        u8\"\u6c49\u8bed\", \"zh-CN\",ascii_space ),\n> >       LANG(chinese_traditional,       u8\"\u6f22\u8a9e\", \"zh-TW\",ascii_space ),\n> >       LANG(french,                    u8\"Fran\u00e7ais\",   \"fr\",   ascii_space ),\n> >       LANG(italian,                   u8\"Italiano\",   \"it\",   ascii_space ),\n> >       LANG(japanese,                  u8\"\u65e5\u672c\u8a9e\",        \"ja\",   u8\"\\u3000\"  ),\n> >       LANG(korean,                    u8\"\ud55c\uad6d\uc5b4\",        \"ko\",   ascii_space ),\n> >       LANG(spanish,                   u8\"Espa\u00f1ol\",    \"es\",   ascii_space )\n> > ```\n> >\n> > Per the comment at #L85 of the quoted file, I also know that for my short identifiers for Chinese, \u201czh-CN\u201d and \u201czh-TW\u201d, are imprecise at best\u2014insofar as Hong Kong uses Traditional; and overseas Chinese may use either.  For differentiating the two Chinese writing variants, are there any appropriate standardized or customary short ASCII language IDs similar to ISO 3166-1 alpha-2 which are purely linguistic, and not fit to present-day political boundaries?\n> >\n> > My general suggestion is that the specification of appropriate strings in bitcoin:bips/bip-0039/bip-0039-wordlists.md be made part of the process for accepting new wordlists.  My specific request is that such strings be ascertained for the wordlists already existing, preferably from the persons involved in the original pull requests therefor.\n> >\n> > Should this proposal be \u201cconcept ACKed\u201d by appropriate parties, then I may open a pull request suggesting an appropriate format for specifying this information in the repository.  However, I will must needs leave the vetting of appropriate strings to native speakers or experts in the respective languages.\n> >\n> > Prior references:  The wordlist additions at PRs #92, #130 (Japanese); #100 (Spanish); #114 (Chinese, both variants); #152 (French); #306 (Italian); #570 (Korean); #621 (Indonesian, *proposed*, open).\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n> \n> <signature.asc>\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180105/b4e144f7/attachment.sig>"
            },
            {
                "author": "Aymeric Vitte",
                "date": "2018-01-05T18:08:29",
                "message_text_only": "See: https://github.com/Ayms/bitcoin-transactions/issues/3\n\nOK, maybe it's my fault, I did not foresee this case, and now it's\nworking for p2sh (non segwit)\n\nFrom my standpoint this just means that BIP39/44 stuff should be\neradicated (not BIP141 but see what happened...), this is of no use,\nconfusing people, doing dangerous things to recover\n\nReally is it easier to save x words instead of a seed? Knowing that\npeople are creating several wallets not understanding that this is not\nthe purpose of BIP32?\n\nMultisig wallets (like Electrum) have created a big mess too, on purpose\nor no, I don't know, but multisig is for different parties involved, not\njust one\n\n\nLe 05/01/2018 \u00e0 18:13, Sjors Provoost via bitcoin-dev a \u00e9crit\u00a0:\n> I don\u2019t know about Electrum but many wallets validate the English words, which helps in catching typos.\n>\n> Hardware wallets without a full keyboard, like the Ledger Nano S, won\u2019t even let you freely type characters; you have to select words from a list.\n>\n> So although the standard technically allows what you say, if you use anything other than 12, 16 or 24 English words, you\u2019ll have fewer wallets to choose from.\n>\n> I think it\u2019s better to come up with a new standard than trying to patch BIP-39 at this point, which is why I brought it up.\n>\n> Sjors\n>\n>> Op 5 jan. 2018, om 17:27 heeft Alan Evans <thealanevans at gmail.com> het volgende geschreven:\n>>\n>> \"Very few wallets support anything other than English\"\n>>\n>> By support do you mean allow recovery, validation or generation or all three? For if you can freely type a phrase in (such as Electrum), or even word by word, then the likely-hood is it is supported if they remembered to normalize.\n>>\n>> Seed generation in BIP0039 requires no dictionary what-so-ever! So there is no word list to lose in the first place. Your funds are accessible with just the characters and the algorithm as described in BIP0039.\n>>\n>> But your proposal is a million miles away from simply adding some standard in-language names to some word lists feels like it's derailing the OP's simple proposal. Maybe start own email chain about it.\n>>\n>> Alan\n>>\n>> On Fri, Jan 5, 2018 at 12:04 PM, Sjors Provoost via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> I\u2019m not a fan of language specific word lists within the current BIP-39 standard. Very few wallets support anything other than English, which can lead to vendor lock-in and long term loss of funds if a rare non-English wallet disappears.\n>>\n>> However, because people can memorize things better in their native tongue, supporting multiple languages seems quite useful.\n>>\n>> I would prefer a new standard where words are mapped to integers rather than to a literal string. For each language a mapping from words to integers would be published. In addition to that, there would be a mapping from original language words to matching (in terms of integer value, not meaning) English words that people can print on an A4 paper. This would allow them to enter a mnemonic into e.g. a hardware wallet that only support English. Such lists are more likely to be around 100 years from now than some ancient piece of software.\n>>\n>> This would not work with the current BIP-39 (duress) password, but this feature could be replaced by appending words (with or without a checksum for that addition).\n>>\n>> A replacement for BIP-39 would be a good opportunity to produce a better English dictionary as Nic Johnson suggested a while ago:\n>>         \u2022 all words are 4-8 characters\n>>         \u2022 all 4-character prefixes are unique (very useful for hardware wallets)\n>>         \u2022 no two words have edit distance < 2\n>>\n>> Wallets need to be able to distinguish between the old and new standard, so un-upgraded BIP 39 wallets should consider all new mnemonics invalid. At the same time, some new wallets may not wish to support BIP39. They shouldn't be burdened with storing the old word list.\n>>\n>> A solution is to sort the new word list such that reused words appear first. When generating a mnemonic, at least one word unique to the new list must be present. A wallet only needs to know the index of the last BIP39 overlapping word. They reject a proposed mnemonic if none of the elements use a word with a higher index.\n>>\n>> For my above point and some related ideas, see: https://github.com/satoshilabs/slips/issues/103\n>>\n>> Sjors\n>>\n>>> Op 5 jan. 2018, om 14:58 heeft nullius via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:\n>>>\n>>> I propose and request as an enhancement that the BIP 39 wordlist set should specify canonical native language strings to identify each wordlist, as well as short ASCII language codes.  At present, the languages are identified only by their names in English.\n>>>\n>>> Strings properly vetted and recommended by native speakers should facilitate language identification in user interface options or menus.  Specification of language identifier strings would also promote interface consistency between implementations; this may be important if a user creates a mnemonic in Implementation A, then restores a wallet using that mnemonic in Implementation B.\n>>>\n>>> As an independent implementer who does not know *all* these different languages, I monkey-pasted language-native strings from a popular wiki site.  I cannot guarantee that they be all accurate, sensible, or even non-embarrassing.\n>>>\n>>> https://github.com/nym-zone/easyseed/blob/1a6e48bbdac9366d9d5d1912dc062dfc3f0db2c6/easyseed.c#L99\n>>> ```\n>>>       LANG(english,                   u8\"English\",    \"en\",   ascii_space ),\n>>>       LANG(chinese_simplified,        u8\"\u6c49\u8bed\", \"zh-CN\",ascii_space ),\n>>>       LANG(chinese_traditional,       u8\"\u6f22\u8a9e\", \"zh-TW\",ascii_space ),\n>>>       LANG(french,                    u8\"Fran\u00e7ais\",   \"fr\",   ascii_space ),\n>>>       LANG(italian,                   u8\"Italiano\",   \"it\",   ascii_space ),\n>>>       LANG(japanese,                  u8\"\u65e5\u672c\u8a9e\",        \"ja\",   u8\"\\u3000\"  ),\n>>>       LANG(korean,                    u8\"\ud55c\uad6d\uc5b4\",        \"ko\",   ascii_space ),\n>>>       LANG(spanish,                   u8\"Espa\u00f1ol\",    \"es\",   ascii_space )\n>>> ```\n>>>\n>>> Per the comment at #L85 of the quoted file, I also know that for my short identifiers for Chinese, \u201czh-CN\u201d and \u201czh-TW\u201d, are imprecise at best\u2014insofar as Hong Kong uses Traditional; and overseas Chinese may use either.  For differentiating the two Chinese writing variants, are there any appropriate standardized or customary short ASCII language IDs similar to ISO 3166-1 alpha-2 which are purely linguistic, and not fit to present-day political boundaries?\n>>>\n>>> My general suggestion is that the specification of appropriate strings in bitcoin:bips/bip-0039/bip-0039-wordlists.md be made part of the process for accepting new wordlists.  My specific request is that such strings be ascertained for the wordlists already existing, preferably from the persons involved in the original pull requests therefor.\n>>>\n>>> Should this proposal be \u201cconcept ACKed\u201d by appropriate parties, then I may open a pull request suggesting an appropriate format for specifying this information in the repository.  However, I will must needs leave the vetting of appropriate strings to native speakers or experts in the respective languages.\n>>>\n>>> Prior references:  The wordlist additions at PRs #92, #130 (Japanese); #100 (Spanish); #114 (Chinese, both variants); #152 (French); #306 (Italian); #570 (Korean); #621 (Indonesian, *proposed*, open).\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>> <signature.asc>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-- \nBitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions\nZcash wallets made simple: https://github.com/Ayms/zcash-wallets\nBitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets\nGet the torrent dynamic blocklist: http://peersm.com/getblocklist\nCheck the 10 M passwords list: http://peersm.com/findmyass\nAnti-spies and private torrents, dynamic blocklist: http://torrent-live.org\nPeersm : http://www.peersm.com\ntorrent-live: https://github.com/Ayms/torrent-live\nnode-Tor : https://www.github.com/Ayms/node-Tor\nGitHub : https://www.github.com/Ayms\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180105/82eb1beb/attachment-0001.html>"
            },
            {
                "author": "Aymeric Vitte",
                "date": "2018-01-05T19:56:19",
                "message_text_only": "No that's not, some parts of the answer might be but this related, this\njust shows how people use wrongly BIP39 and subsequent BIPs (and\nglobally other things), misleading them, while the advantage of using it\nis quite dubious compared to backing up a seed, unless you can convince\nme of the contrary\n\n\nLe 05/01/2018 \u00e0 19:16, Alan Evans a \u00e9crit\u00a0:\n> Sjors, well in Electrum, validation is optional, but English only. As\n> for the Ledger-S, that sounds like a Ledger problem.\n>\n> Aymeric, that is way off topic, did you reply to wrong email?\n>\n> On Fri, Jan 5, 2018 at 2:08 PM, Aymeric Vitte <vitteaymeric at gmail.com\n> <mailto:vitteaymeric at gmail.com>> wrote:\n>\n>     See: https://github.com/Ayms/bitcoin-transactions/issues/3\n>     <https://github.com/Ayms/bitcoin-transactions/issues/3>\n>\n>     OK, maybe it's my fault, I did not foresee this case, and now it's\n>     working for p2sh (non segwit)\n>\n>     From my standpoint this just means that BIP39/44 stuff should be\n>     eradicated (not BIP141 but see what happened...), this is of no\n>     use, confusing people, doing dangerous things to recover\n>\n>     Really is it easier to save x words instead of a seed? Knowing\n>     that people are creating several wallets not understanding that\n>     this is not the purpose of BIP32?\n>\n>     Multisig wallets (like Electrum) have created a big mess too, on\n>     purpose or no, I don't know, but multisig is for different parties\n>     involved, not just one\n>\n>\n>     Le 05/01/2018 \u00e0 18:13, Sjors Provoost via bitcoin-dev a \u00e9crit\u00a0:\n>>     I don\u2019t know about Electrum but many wallets validate the English words, which helps in catching typos.\n>>\n>>     Hardware wallets without a full keyboard, like the Ledger Nano S, won\u2019t even let you freely type characters; you have to select words from a list.\n>>\n>>     So although the standard technically allows what you say, if you use anything other than 12, 16 or 24 English words, you\u2019ll have fewer wallets to choose from.\n>>\n>>     I think it\u2019s better to come up with a new standard than trying to patch BIP-39 at this point, which is why I brought it up.\n>>\n>>     Sjors\n>>\n>>>     Op 5 jan. 2018, om 17:27 heeft Alan Evans <thealanevans at gmail.com> <mailto:thealanevans at gmail.com> het volgende geschreven:\n>>>\n>>>     \"Very few wallets support anything other than English\"\n>>>\n>>>     By support do you mean allow recovery, validation or generation or all three? For if you can freely type a phrase in (such as Electrum), or even word by word, then the likely-hood is it is supported if they remembered to normalize.\n>>>\n>>>     Seed generation in BIP0039 requires no dictionary what-so-ever! So there is no word list to lose in the first place. Your funds are accessible with just the characters and the algorithm as described in BIP0039.\n>>>\n>>>     But your proposal is a million miles away from simply adding some standard in-language names to some word lists feels like it's derailing the OP's simple proposal. Maybe start own email chain about it.\n>>>\n>>>     Alan\n>>>\n>>>     On Fri, Jan 5, 2018 at 12:04 PM, Sjors Provoost via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n>>>     <mailto:bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>     I\u2019m not a fan of language specific word lists within the current BIP-39 standard. Very few wallets support anything other than English, which can lead to vendor lock-in and long term loss of funds if a rare non-English wallet disappears.\n>>>\n>>>     However, because people can memorize things better in their native tongue, supporting multiple languages seems quite useful.\n>>>\n>>>     I would prefer a new standard where words are mapped to integers rather than to a literal string. For each language a mapping from words to integers would be published. In addition to that, there would be a mapping from original language words to matching (in terms of integer value, not meaning) English words that people can print on an A4 paper. This would allow them to enter a mnemonic into e.g. a hardware wallet that only support English. Such lists are more likely to be around 100 years from now than some ancient piece of software.\n>>>\n>>>     This would not work with the current BIP-39 (duress) password, but this feature could be replaced by appending words (with or without a checksum for that addition).\n>>>\n>>>     A replacement for BIP-39 would be a good opportunity to produce a better English dictionary as Nic Johnson suggested a while ago:\n>>>             \u2022 all words are 4-8 characters\n>>>             \u2022 all 4-character prefixes are unique (very useful for hardware wallets)\n>>>             \u2022 no two words have edit distance < 2\n>>>\n>>>     Wallets need to be able to distinguish between the old and new standard, so un-upgraded BIP 39 wallets should consider all new mnemonics invalid. At the same time, some new wallets may not wish to support BIP39. They shouldn't be burdened with storing the old word list.\n>>>\n>>>     A solution is to sort the new word list such that reused words appear first. When generating a mnemonic, at least one word unique to the new list must be present. A wallet only needs to know the index of the last BIP39 overlapping word. They reject a proposed mnemonic if none of the elements use a word with a higher index.\n>>>\n>>>     For my above point and some related ideas, see: https://github.com/satoshilabs/slips/issues/103\n>>>     <https://github.com/satoshilabs/slips/issues/103>\n>>>\n>>>     Sjors\n>>>\n>>>>     Op 5 jan. 2018, om 14:58 heeft nullius via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n>>>>     <mailto:bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:\n>>>>\n>>>>     I propose and request as an enhancement that the BIP 39 wordlist set should specify canonical native language strings to identify each wordlist, as well as short ASCII language codes.  At present, the languages are identified only by their names in English.\n>>>>\n>>>>     Strings properly vetted and recommended by native speakers should facilitate language identification in user interface options or menus.  Specification of language identifier strings would also promote interface consistency between implementations; this may be important if a user creates a mnemonic in Implementation A, then restores a wallet using that mnemonic in Implementation B.\n>>>>\n>>>>     As an independent implementer who does not know *all* these different languages, I monkey-pasted language-native strings from a popular wiki site.  I cannot guarantee that they be all accurate, sensible, or even non-embarrassing.\n>>>>\n>>>>     https://github.com/nym-zone/easyseed/blob/1a6e48bbdac9366d9d5d1912dc062dfc3f0db2c6/easyseed.c#L99\n>>>>     <https://github.com/nym-zone/easyseed/blob/1a6e48bbdac9366d9d5d1912dc062dfc3f0db2c6/easyseed.c#L99>\n>>>>     ```\n>>>>           LANG(english,                   u8\"English\",    \"en\",   ascii_space ),\n>>>>           LANG(chinese_simplified,        u8\"\u6c49\u8bed\", \"zh-CN\",ascii_space ),\n>>>>           LANG(chinese_traditional,       u8\"\u6f22\u8a9e\", \"zh-TW\",ascii_space ),\n>>>>           LANG(french,                    u8\"Fran\u00e7ais\",   \"fr\",   ascii_space ),\n>>>>           LANG(italian,                   u8\"Italiano\",   \"it\",   ascii_space ),\n>>>>           LANG(japanese,                  u8\"\u65e5\u672c\u8a9e\",        \"ja\",   u8\"\\u3000\"  ),\n>>>>           LANG(korean,                    u8\"\ud55c\uad6d\uc5b4\",        \"ko\",   ascii_space ),\n>>>>           LANG(spanish,                   u8\"Espa\u00f1ol\",    \"es\",   ascii_space )\n>>>>     ```\n>>>>\n>>>>     Per the comment at #L85 of the quoted file, I also know that for my short identifiers for Chinese, \u201czh-CN\u201d and \u201czh-TW\u201d, are imprecise at best\u2014insofar as Hong Kong uses Traditional; and overseas Chinese may use either.  For differentiating the two Chinese writing variants, are there any appropriate standardized or customary short ASCII language IDs similar to ISO 3166-1 alpha-2 which are purely linguistic, and not fit to present-day political boundaries?\n>>>>\n>>>>     My general suggestion is that the specification of appropriate strings in bitcoin:bips/bip-0039/bip-0039-wordlists.md be made part of the process for accepting new wordlists.  My specific request is that such strings be ascertained for the wordlists already existing, preferably from the persons involved in the original pull requests therefor.\n>>>>\n>>>>     Should this proposal be \u201cconcept ACKed\u201d by appropriate parties, then I may open a pull request suggesting an appropriate format for specifying this information in the repository.  However, I will must needs leave the vetting of appropriate strings to native speakers or experts in the respective languages.\n>>>>\n>>>>     Prior references:  The wordlist additions at PRs #92, #130 (Japanese); #100 (Spanish); #114 (Chinese, both variants); #152 (French); #306 (Italian); #570 (Korean); #621 (Indonesian, *proposed*, open).\n>>>>     _______________________________________________\n>>>>     bitcoin-dev mailing list\n>>>>     bitcoin-dev at lists.linuxfoundation.org\n>>>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>>>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>>>     _______________________________________________\n>>>     bitcoin-dev mailing list\n>>>     bitcoin-dev at lists.linuxfoundation.org\n>>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>>>\n>>>\n>>>     <signature.asc>\n>>\n>>\n>>     _______________________________________________\n>>     bitcoin-dev mailing list\n>>     bitcoin-dev at lists.linuxfoundation.org\n>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>\n>     -- \n>     Bitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions\n>     <https://github.com/Ayms/bitcoin-transactions>\n>     Zcash wallets made simple: https://github.com/Ayms/zcash-wallets\n>     <https://github.com/Ayms/zcash-wallets>\n>     Bitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets\n>     <https://github.com/Ayms/bitcoin-wallets>\n>     Get the torrent dynamic blocklist: http://peersm.com/getblocklist\n>     Check the 10 M passwords list: http://peersm.com/findmyass\n>     Anti-spies and private torrents, dynamic blocklist: http://torrent-live.org\n>     Peersm : http://www.peersm.com\n>     torrent-live: https://github.com/Ayms/torrent-live\n>     <https://github.com/Ayms/torrent-live>\n>     node-Tor : https://www.github.com/Ayms/node-Tor\n>     <https://www.github.com/Ayms/node-Tor>\n>     GitHub : https://www.github.com/Ayms\n>\n>\n\n-- \nBitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions\nZcash wallets made simple: https://github.com/Ayms/zcash-wallets\nBitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets\nGet the torrent dynamic blocklist: http://peersm.com/getblocklist\nCheck the 10 M passwords list: http://peersm.com/findmyass\nAnti-spies and private torrents, dynamic blocklist: http://torrent-live.org\nPeersm : http://www.peersm.com\ntorrent-live: https://github.com/Ayms/torrent-live\nnode-Tor : https://www.github.com/Ayms/node-Tor\nGitHub : https://www.github.com/Ayms\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180105/1c88fd57/attachment-0001.html>"
            },
            {
                "author": "Aymeric Vitte",
                "date": "2018-01-06T17:40:40",
                "message_text_only": "Unfortunately, even \"yourself\" seems not to know what he is talking\nabout (so imagine for other people, 256 bits is advised --> 32B),\nprobably that's why you brought this discussion off the list, then\nmaking recommendations to improve something that is misleading and messy\nis quite dubious\n\nAnd maybe you should take a look at what people you are talking to are\ndoing before arguing stuff that you apparently don't know very well (ie\n\"the length of the *derived *key\", not the seed), cf\nhttps://github.com/Ayms/bitcoin-wallets\n<https://github.com/Ayms/bitcoin-wallets> and even\nhttps://github.com/Ayms/zcash-wallets (not official but\nhttps://github.com/zcash/zips/issues/95)\n<https://github.com/Ayms/zcash-wallets>\n\nBut as you can notice there is a missing feature, ie to derive the\nwallets from xpriv, there is a comment in the repo why I don't like some\nthings \"Surprisingly from ~32 bytes keys BIP32 ends up with a 78 bytes\nformat to describe them with all the necessary information like indexes,\nparent to possibly allow to revert the tree\"\n\nThat's another thing I completely dislike with BIP39, it ends up with\nxpriv, not the 32B seed, there are many, many, many posts in forums of\npeople fighting to figure out their private keys derived from bip39/44/etc\n\n\"No offence too\" but please keep your advises for yourself, I indeed\ndon't read closely inept BIPs, and never said I did not like BIP32,\nthat's the contrary, I really like it\n\nBefore firing plenty of BIPs that do not fit together people maybe\nshould take a break and see what people are doing today (this is quite\namazing) and why they got stolen\n\nAnd you seem to know very little about security, if you suspect you home\nprinter, then suspect you OS, your hw, etc, (you really envision to\ngenerate a seed from a mobile device ???) writing 64 characters is not\nvery difficult for a human being, even easier than writing x words of y\nlength\n\nSee this too\nhttps://bitcointalk.org/index.php?topic=2550529.msg26133887#msg26133887,\nthe tutorial was corrected, but basic things are still missing, an\noffline version is when you disconnect from the internet, not when you\nuse the \"offline version\"\u00a0 (assuming that the browser storage or other\nstuff are not used...)\n\nRe-ccing the list because again at a certain point of time the theory\nshould look at the reality and adapt accordingly, part of the example I\ngave is off topic for this thread but globally (which could become\nanother thread) the message is: the bitcoin community should stop making\nthings complicate for people, releasing BIPs of no use just ends up with\ncomplicating things more than it helps, people deserve to understand\nwhat they are doing, manage their keys by their own and stop syncing\nuseless full nodes for every coin to sync their wallets, that's why I\nmade the tool, the first people that used it made some outstanding\nmistakes that I did not envision now it's not possible any longer,\nexcept if they give wrong destination addresses and nobody can't do\nanything about this (btw the primary intent of the tool was for myself\nand you are right for once, I did not know that people could do so big\nmistakes, that's not their fault, I see it now, my mistake for\nunderestimating this)\n\nLe 06/01/2018 \u00e0 16:00, Alan Evans a \u00e9crit\u00a0:\n> You're mistaken. BIP32 does not require a particular\u00a0length. It\n> recommends:\n>\n>   * Generate a seed byte sequence S of a chosen length (between 128\n>     and 512 bits; 256 bits is advised) from a (P)RNG\n>\n> But BIP39 produces a\u00a064 byte\u00a0seed:\n>\n> The length of the derived key is 512 bits (= 64 bytes).\n>\n> If you don't believe me, why don't you just try it? That seed will\n> derive the same keys as that mnemonic, it's a real example.\n>\n> ---------\n>\n> About printing, there is a huge security risk involved in printing\n> anything. Networks, printers may have memory. People will print to PDF\n> when they don't have a printer on hand. Mobile users often can't print.\n>\n> I wrote mine down, by hand, generated from an offline computer booted\n> with a\u00a0readonly\u00a0OS.\u00a0\n>\n> Feel free to produce a recommendation to replace BIP39/32/44 if you\n> like, but it's not broken just because someone had trouble using your\n> tool/following your instructions. And no offence but I'd be wary using\n> a tool from someone who doesn't read the BIPs closely yet is so\n> confident about how other people are wrong.\n>\n>\n> On Sat, Jan 6, 2018 at 6:57 AM, Aymeric Vitte <vitteaymeric at gmail.com\n> <mailto:vitteaymeric at gmail.com>> wrote:\n>\n>     And Alan, btw, a BIP32 seed is 32 bytes, then 64 characters, not 64\n>     bytes as your wrote below, which probably corresponds to xprv,\n>     which is\n>     another misleading element of BIP39\n>\n>\n>     Le 06/01/2018 \u00e0 02:56, Aymeric Vitte a \u00e9crit\u00a0:\n>     > The fact is indeed that \"we should really find a way to overhaul\n>     this\n>     > whole BIP 39 / 43/ 44 etc ad hoc mess\"\n>     >\n>     > Because the git example I provided is about someone that knows (to a\n>     > certain extent) what he is doing, then made a mistake for the\n>     > destination address, which is not related to this discussion\n>     >\n>     > This just shows how complicate it can become even for people knowing\n>     > this to retrieve their wallet and how wallets made it \"the easy\n>     way\" (ie\n>     > bip39, 44, multisig...)\n>     >\n>     > If people prefer to store mnemonics, why not, but \"writing down\"\n>     in both\n>     > messages above is not accurate, you would better print it and\n>     cut it in\n>     > n pieces if you like, then the point of using mnemonics that you\n>     can't\n>     > remember more than an hex string still remains useless from my\n>     standpoint\n>     >\n>     > Beside the theory we should look now if BIP39 & all brought more\n>     good\n>     > than the contrary in practice, I think that the later wins\n>     >\n>     >\n>     > Le 05/01/2018 \u00e0 21:38, Sjors Provoost a \u00e9crit\u00a0:\n>     >> Hi Alan,\n>     >>\n>     >> The Github issue is arguably unrelated, which is why I put it\n>     at the end and said \u201csome related\u201d.\n>     >>\n>     >> However it does all tie together; we should really find a way\n>     to overhaul this whole BIP 39 / 43/ 44 etc ad hoc mess, ideally in\n>     a way that even Bitcoin Core would be willing to use it. When you\n>     change the word list, it\u2019s best to change everything else at the\n>     same time. Otherwise you\u2019d have too many different standards,\n>     which is a pain for wallets to implement.\n>     >>\n>     >> I share your view than a mnemonic is better than a bunch of hex\n>     numbers. It\u2019s easier to memorize and easier to write down. Some\n>     people don\u2019t like it when users write down phrases, but they\u2019re\n>     much, much more likely to lose their coins than some burglar to\n>     find the piece of paper. My issue is only with the way derivation\n>     currently works.\n>     >>\n>     >> Sjors\n>     >>\n>     >>> Op 5 jan. 2018, om 21:05 heeft Alan Evans\n>     <thealanevans at gmail.com <mailto:thealanevans at gmail.com>> het\n>     volgende geschreven:\n>     >>>\n>     >>> Taking it off the board. I can't read all of that issue.\n>     BIP0039 mnemonic generates a seed. Everything past there to do\n>     with addresses (BIP32/44/49/141 whatever) is the same as if you\n>     started with the seed. So you can't blaim BIP0039 for that\n>     person's misunderstanding, and the way different wallets use\n>     different derivation paths.\n>     >>>\n>     >>> If someone has a BIP0039 mnemonic and would rather back up the\n>     seed, they can go ahead. But one tiny mistake in writing it down\n>     and you may have a hell of a time finding out what's wrong as\n>     every seed is valid. A mistake in writing down words is far harder\n>     to make. You can also memorize a mnemonic (hence the name), the\n>     average person cannot memorize a seed.\n>     >>>\n>     >>> fork canal mad beyond spike pool expire fuel region impose\n>     ceiling video\n>     >>>\n>     >>> vs:\n>     >>>\n>     >>>\n>     f54b80812b3a6f1834095370df82a2123aece2d6089da67d7871477c004684fbc399a6155e53de0b783a9be6388354846e51f59e4869984f0c554e6469788c64\n>     >>>\n>     >>> But they lead to the same addresses.\n>     >>>\n>     >>> Need I say more?\n>     >>>\n>     >>>\n>     >>> On Fri, Jan 5, 2018 at 3:56 PM, Aymeric Vitte\n>     <vitteaymeric at gmail.com <mailto:vitteaymeric at gmail.com>> wrote:\n>     >>> No that's not, some parts of the answer might be but this\n>     related, this just shows how people use wrongly BIP39 and\n>     subsequent BIPs (and globally other things), misleading them,\n>     while the advantage of using it is quite dubious compared to\n>     backing up a seed, unless you can convince me of the contrary\n>     >>>\n>     >>> Le 05/01/2018 \u00e0 19:16, Alan Evans a \u00e9crit :\n>     >>>> Sjors, well in Electrum, validation is optional, but English\n>     only. As for the Ledger-S, that sounds like a Ledger problem.\n>     >>>>\n>     >>>> Aymeric, that is way off topic, did you reply to wrong email?\n>     >>>>\n>     >>>> On Fri, Jan 5, 2018 at 2:08 PM, Aymeric Vitte\n>     <vitteaymeric at gmail.com <mailto:vitteaymeric at gmail.com>> wrote:\n>     >>>> See: https://github.com/Ayms/bitcoin-transactions/issues/3\n>     <https://github.com/Ayms/bitcoin-transactions/issues/3>\n>     >>>>\n>     >>>> OK, maybe it's my fault, I did not foresee this case, and now\n>     it's working for p2sh (non segwit)\n>     >>>> From my standpoint this just means that BIP39/44 stuff should\n>     be eradicated (not BIP141 but see what happened...), this is of no\n>     use, confusing people, doing dangerous things to recover\n>     >>>> Really is it easier to save x words instead of a seed?\n>     Knowing that people are creating several wallets not understanding\n>     that this is not the purpose of BIP32?\n>     >>>>\n>     >>>> Multisig wallets (like Electrum) have created a big mess too,\n>     on purpose or no, I don't know, but multisig is for different\n>     parties involved, not just one\n>     >>>>\n>     >>>> Le 05/01/2018 \u00e0 18:13, Sjors Provoost via bitcoin-dev a \u00e9crit :\n>     >>>>> I don\u2019t know about Electrum but many wallets validate the\n>     English words, which helps in catching typos.\n>     >>>>>\n>     >>>>> Hardware wallets without a full keyboard, like the Ledger\n>     Nano S, won\u2019t even let you freely type characters; you have to\n>     select words from a list.\n>     >>>>>\n>     >>>>> So although the standard technically allows what you say, if\n>     you use anything other than 12, 16 or 24 English words, you\u2019ll\n>     have fewer wallets to choose from.\n>     >>>>>\n>     >>>>> I think it\u2019s better to come up with a new standard than\n>     trying to patch BIP-39 at this point, which is why I brought it up.\n>     >>>>>\n>     >>>>> Sjors\n>     >>>>>\n>     >>>>>\n>     >>>>>> Op 5 jan. 2018, om 17:27 heeft Alan Evans\n>     <thealanevans at gmail.com <mailto:thealanevans at gmail.com>>\n>     >>>>>>\u00a0 het volgende geschreven:\n>     >>>>>>\n>     >>>>>> \"Very few wallets support anything other than English\"\n>     >>>>>>\n>     >>>>>> By support do you mean allow recovery, validation or\n>     generation or all three? For if you can freely type a phrase in\n>     (such as Electrum), or even word by word, then the likely-hood is\n>     it is supported if they remembered to normalize.\n>     >>>>>>\n>     >>>>>> Seed generation in BIP0039 requires no dictionary\n>     what-so-ever! So there is no word list to lose in the first place.\n>     Your funds are accessible with just the characters and the\n>     algorithm as described in BIP0039.\n>     >>>>>>\n>     >>>>>> But your proposal is a million miles away from simply\n>     adding some standard in-language names to some word lists feels\n>     like it's derailing the OP's simple proposal. Maybe start own\n>     email chain about it.\n>     >>>>>>\n>     >>>>>> Alan\n>     >>>>>>\n>     >>>>>> On Fri, Jan 5, 2018 at 12:04 PM, Sjors Provoost via bitcoin-dev\n>     >>>>>> <bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>>\n>     >>>>>>\u00a0 wrote:\n>     >>>>>> I\u2019m not a fan of language specific word lists within the\n>     current BIP-39 standard. Very few wallets support anything other\n>     than English, which can lead to vendor lock-in and long term loss\n>     of funds if a rare non-English wallet disappears.\n>     >>>>>>\n>     >>>>>> However, because people can memorize things better in their\n>     native tongue, supporting multiple languages seems quite useful.\n>     >>>>>>\n>     >>>>>> I would prefer a new standard where words are mapped to\n>     integers rather than to a literal string. For each language a\n>     mapping from words to integers would be published. In addition to\n>     that, there would be a mapping from original language words to\n>     matching (in terms of integer value, not meaning) English words\n>     that people can print on an A4 paper. This would allow them to\n>     enter a mnemonic into e.g. a hardware wallet that only support\n>     English. Such lists are more likely to be around 100 years from\n>     now than some ancient piece of software.\n>     >>>>>>\n>     >>>>>> This would not work with the current BIP-39 (duress)\n>     password, but this feature could be replaced by appending words\n>     (with or without a checksum for that addition).\n>     >>>>>>\n>     >>>>>> A replacement for BIP-39 would be a good opportunity to\n>     produce a better English dictionary as Nic Johnson suggested a\n>     while ago:\n>     >>>>>>\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2022 all words are 4-8 characters\n>     >>>>>>\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2022 all 4-character prefixes are unique (very useful\n>     for hardware wallets)\n>     >>>>>>\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2022 no two words have edit distance < 2\n>     >>>>>>\n>     >>>>>> Wallets need to be able to distinguish between the old and\n>     new standard, so un-upgraded BIP 39 wallets should consider all\n>     new mnemonics invalid. At the same time, some new wallets may not\n>     wish to support BIP39. They shouldn't be burdened with storing the\n>     old word list.\n>     >>>>>>\n>     >>>>>> A solution is to sort the new word list such that reused\n>     words appear first. When generating a mnemonic, at least one word\n>     unique to the new list must be present. A wallet only needs to\n>     know the index of the last BIP39 overlapping word. They reject a\n>     proposed mnemonic if none of the elements use a word with a higher\n>     index.\n>     >>>>>>\n>     >>>>>> For my above point and some related ideas, see:\n>     >>>>>> https://github.com/satoshilabs/slips/issues/103\n>     <https://github.com/satoshilabs/slips/issues/103>\n>     >>>>>>\n>     >>>>>>\n>     >>>>>> Sjors\n>     >>>>>>\n>     >>>>>>\n>     >>>>>>> Op 5 jan. 2018, om 14:58 heeft nullius via bitcoin-dev\n>     <bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>>\n>     >>>>>>>\u00a0 het volgende geschreven:\n>     >>>>>>>\n>     >>>>>>> I propose and request as an enhancement that the BIP 39\n>     wordlist set should specify canonical native language strings to\n>     identify each wordlist, as well as short ASCII language codes.\u00a0 At\n>     present, the languages are identified only by their names in English.\n>     >>>>>>>\n>     >>>>>>> Strings properly vetted and recommended by native speakers\n>     should facilitate language identification in user interface\n>     options or menus.\u00a0 Specification of language identifier strings\n>     would also promote interface consistency between implementations;\n>     this may be important if a user creates a mnemonic in\n>     Implementation A, then restores a wallet using that mnemonic in\n>     Implementation B.\n>     >>>>>>>\n>     >>>>>>> As an independent implementer who does not know *all*\n>     these different languages, I monkey-pasted language-native strings\n>     from a popular wiki site.\u00a0 I cannot guarantee that they be all\n>     accurate, sensible, or even non-embarrassing.\n>     >>>>>>>\n>     >>>>>>>\n>     >>>>>>>\n>     https://github.com/nym-zone/easyseed/blob/1a6e48bbdac9366d9d5d1912dc062dfc3f0db2c6/easyseed.c#L99\n>     <https://github.com/nym-zone/easyseed/blob/1a6e48bbdac9366d9d5d1912dc062dfc3f0db2c6/easyseed.c#L99>\n>     >>>>>>>\n>     >>>>>>> ```\n>     >>>>>>>\u00a0 \u00a0 \u00a0 \u00a0LANG(english,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0u8\"English\",\u00a0 \u00a0\n>     \"en\",\u00a0 \u00a0ascii_space ),\n>     >>>>>>>\u00a0 \u00a0 \u00a0 \u00a0LANG(chinese_simplified,\u00a0 \u00a0 \u00a0 \u00a0 u8\"\u6c49\u8bed\",\n>     \"zh-CN\",ascii_space ),\n>     >>>>>>>\u00a0 \u00a0 \u00a0 \u00a0LANG(chinese_traditional,\u00a0 \u00a0 \u00a0 \u00a0u8\"\u6f22\u8a9e\",\n>     \"zh-TW\",ascii_space ),\n>     >>>>>>>\u00a0 \u00a0 \u00a0 \u00a0LANG(french,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 u8\"Fran\u00e7ais\",\u00a0\n>     \u00a0\"fr\",\u00a0 \u00a0ascii_space ),\n>     >>>>>>>\u00a0 \u00a0 \u00a0 \u00a0LANG(italian,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0u8\"Italiano\",\u00a0\n>     \u00a0\"it\",\u00a0 \u00a0ascii_space ),\n>     >>>>>>>\u00a0 \u00a0 \u00a0 \u00a0LANG(japanese,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 u8\"\u65e5\u672c\u8a9e\",\u00a0 \u00a0 \u00a0 \u00a0\n>     \"ja\",\u00a0 \u00a0u8\"\\u3000\"\u00a0 ),\n>     >>>>>>>\u00a0 \u00a0 \u00a0 \u00a0LANG(korean,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 u8\"\ud55c\uad6d\uc5b4\",\u00a0 \u00a0 \u00a0 \u00a0\n>     \"ko\",\u00a0 \u00a0ascii_space ),\n>     >>>>>>>\u00a0 \u00a0 \u00a0 \u00a0LANG(spanish,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0u8\"Espa\u00f1ol\",\u00a0 \u00a0\n>     \"es\",\u00a0 \u00a0ascii_space )\n>     >>>>>>> ```\n>     >>>>>>>\n>     >>>>>>> Per the comment at #L85 of the quoted file, I also know\n>     that for my short identifiers for Chinese, \u201czh-CN\u201d and \u201czh-TW\u201d,\n>     are imprecise at best\u2014insofar as Hong Kong uses Traditional; and\n>     overseas Chinese may use either.\u00a0 For differentiating the two\n>     Chinese writing variants, are there any appropriate standardized\n>     or customary short ASCII language IDs similar to ISO 3166-1\n>     alpha-2 which are purely linguistic, and not fit to present-day\n>     political boundaries?\n>     >>>>>>>\n>     >>>>>>> My general suggestion is that the specification of\n>     appropriate strings in\n>     >>>>>>> bitcoin:bips/bip-0039/bip-0039-wordlists.md\n>     <http://bip-0039-wordlists.md>\n>     >>>>>>>\u00a0 be made part of the process for accepting new wordlists.\u00a0\n>     My specific request is that such strings be ascertained for the\n>     wordlists already existing, preferably from the persons involved\n>     in the original pull requests therefor.\n>     >>>>>>>\n>     >>>>>>> Should this proposal be \u201cconcept ACKed\u201d by appropriate\n>     parties, then I may open a pull request suggesting an appropriate\n>     format for specifying this information in the repository.\u00a0\n>     However, I will must needs leave the vetting of appropriate\n>     strings to native speakers or experts in the respective languages.\n>     >>>>>>>\n>     >>>>>>> Prior references:\u00a0 The wordlist additions at PRs #92, #130\n>     (Japanese); #100 (Spanish); #114 (Chinese, both variants); #152\n>     (French); #306 (Italian); #570 (Korean); #621 (Indonesian,\n>     *proposed*, open).\n>     >>>>>>> ______________________________\n>     >>>>>>> _________________\n>     >>>>>>> bitcoin-dev mailing list\n>     >>>>>>>\n>     >>>>>>> bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>     >>>>>>>\n>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>     >>>>>> ______________________________\n>     >>>>>> _________________\n>     >>>>>> bitcoin-dev mailing list\n>     >>>>>>\n>     >>>>>> bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>     >>>>>>\n>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>     >>>>>>\n>     >>>>>>\n>     >>>>>>\n>     >>>>>> <signature.asc>\n>     >>>>>>\n>     >>>>> ______________________________\n>     >>>>> _________________\n>     >>>>> bitcoin-dev mailing list\n>     >>>>>\n>     >>>>> bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>     >>>>>\n>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>     >>>> --\n>     >>>> Bitcoin transactions made simple:\n>     >>>> https://github.com/Ayms/bitcoin-transactions\n>     <https://github.com/Ayms/bitcoin-transactions>\n>     >>>>\n>     >>>> Zcash wallets made simple:\n>     >>>> https://github.com/Ayms/zcash-wallets\n>     <https://github.com/Ayms/zcash-wallets>\n>     >>>>\n>     >>>> Bitcoin wallets made simple:\n>     >>>> https://github.com/Ayms/bitcoin-wallets\n>     <https://github.com/Ayms/bitcoin-wallets>\n>     >>>>\n>     >>>> Get the torrent dynamic blocklist:\n>     >>>> http://peersm.com/getblocklist\n>     >>>>\n>     >>>> Check the 10 M passwords list:\n>     >>>> http://peersm.com/findmyass\n>     >>>>\n>     >>>> Anti-spies and private torrents, dynamic blocklist:\n>     >>>> http://torrent-live.org\n>     >>>>\n>     >>>> Peersm :\n>     >>>> http://www.peersm.com\n>     >>>>\n>     >>>> torrent-live:\n>     >>>> https://github.com/Ayms/torrent-live\n>     <https://github.com/Ayms/torrent-live>\n>     >>>>\n>     >>>> node-Tor :\n>     >>>> https://www.github.com/Ayms/node-Tor\n>     <https://www.github.com/Ayms/node-Tor>\n>     >>>>\n>     >>>> GitHub :\n>     >>>> https://www.github.com/Ayms\n>     >>>>\n>     >>> --\n>     >>> Bitcoin transactions made simple:\n>     >>> https://github.com/Ayms/bitcoin-transactions\n>     <https://github.com/Ayms/bitcoin-transactions>\n>     >>>\n>     >>> Zcash wallets made simple:\n>     >>> https://github.com/Ayms/zcash-wallets\n>     <https://github.com/Ayms/zcash-wallets>\n>     >>>\n>     >>> Bitcoin wallets made simple:\n>     >>> https://github.com/Ayms/bitcoin-wallets\n>     <https://github.com/Ayms/bitcoin-wallets>\n>     >>>\n>     >>> Get the torrent dynamic blocklist:\n>     >>> http://peersm.com/getblocklist\n>     >>>\n>     >>> Check the 10 M passwords list:\n>     >>> http://peersm.com/findmyass\n>     >>>\n>     >>> Anti-spies and private torrents, dynamic blocklist:\n>     >>> http://torrent-live.org\n>     >>>\n>     >>> Peersm :\n>     >>> http://www.peersm.com\n>     >>>\n>     >>> torrent-live:\n>     >>> https://github.com/Ayms/torrent-live\n>     <https://github.com/Ayms/torrent-live>\n>     >>>\n>     >>> node-Tor :\n>     >>> https://www.github.com/Ayms/node-Tor\n>     <https://www.github.com/Ayms/node-Tor>\n>     >>>\n>     >>> GitHub :\n>     >>> https://www.github.com/Ayms\n>     >>>\n>\n>     --\n>     Bitcoin transactions made simple:\n>     https://github.com/Ayms/bitcoin-transactions\n>     <https://github.com/Ayms/bitcoin-transactions>\n>     Zcash wallets made simple: https://github.com/Ayms/zcash-wallets\n>     <https://github.com/Ayms/zcash-wallets>\n>     Bitcoin wallets made simple:\n>     https://github.com/Ayms/bitcoin-wallets\n>     <https://github.com/Ayms/bitcoin-wallets>\n>     Get the torrent dynamic blocklist: http://peersm.com/getblocklist\n>     Check the 10 M passwords list: http://peersm.com/findmyass\n>     Anti-spies and private torrents, dynamic blocklist:\n>     http://torrent-live.org\n>     Peersm : http://www.peersm.com\n>     torrent-live: https://github.com/Ayms/torrent-live\n>     node-Tor <https://github.com/Ayms/torrent-live%0Anode-Tor> :\n>     https://www.github.com/Ayms/node-Tor\n>     <https://www.github.com/Ayms/node-Tor>\n>     GitHub : https://www.github.com/Ayms\n>\n>\n\n-- \nBitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions\nZcash wallets made simple: https://github.com/Ayms/zcash-wallets\nBitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets\nGet the torrent dynamic blocklist: http://peersm.com/getblocklist\nCheck the 10 M passwords list: http://peersm.com/findmyass\nAnti-spies and private torrents, dynamic blocklist: http://torrent-live.org\nPeersm : http://www.peersm.com\ntorrent-live: https://github.com/Ayms/torrent-live\nnode-Tor : https://www.github.com/Ayms/node-Tor\nGitHub : https://www.github.com/Ayms\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180106/74d8e042/attachment-0001.html>"
            },
            {
                "author": "Aymeric Vitte",
                "date": "2018-01-06T19:46:43",
                "message_text_only": "Calm down now and stop your \"do you want a\" or \"link\" stupid comments,\nwhether you are really willing to propose some improvements, whether you\nare just posting for nothing\n\nBIP39:\n\n\"The length of the derived key is 512 bits (= 64 bytes).\n\nThis seed can be later used to generate deterministic wallets using\nBIP-0032 or similar methods.\"\n\nSo the derived key is the seed? (derived key... this seed, really?\n\"similar methods\",funny) That's not clear, then why everybody is using\nxpriv which corresponds to the first step of the derivation (ie the\nderived key)? And why BIP39 does not follow BIP32 recommendation (32B seed)?\n\nAnyway, I don't really care about this stuff in fact, the only\ninteresting thing in this discussion beside arguing around unclear specs\nmisleading many people would be if you can convince that BIP39 & co are\nreally usefull for people (and easier than writing a seed): what\nfeedback do you have, don't you see how it's a pain in the xss for\neverybody?\n\nAnd if the answer is positive how can you can make it easier for people\n(I am amazed too that people know about BIPXYZ, they should not),\nprobably this discussion will bore people and get moderated, but as\nmentioned below, even maybe off topic, the subject is wider\n\nLe 06/01/2018 \u00e0 19:28, Alan Evans a \u00e9crit\u00a0:\n> >\u00a0Unfortunately, even \"yourself\" seems not to know what he is talking\n> about (so imagine for other people, 256 bits is advised --> 32B),\n> probably that's why you brought this discussion off the list, then\n> making recommendations to improve something that is misleading and\n> messy is quite dubious\n>\n> And yet you still fail to read the BIP, do you want a\n> link?\u00a0https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki I\n> repeat it says:\n>\n> between 128 and 512 bits\n>\n> So, that's between 16 and 64 bytes, the advisory of 256 is clearly a\n> minimum.\n>\n> >\u00a0That's another thing I completely dislike with BIP39, it ends up\n> with xpriv, not the 32B seed\n>\n> Please also read\n> BIP0039\u00a0https://github.com/bitcoin/bips/blob/master/bip-0039.mediawiki,\n> it generates *a BIP32 seed only*, no xpriv,\u00a0that's completely\u00a0false,\n> then you use BIP0032 as normal with the seed. Because BIP0039 produces\n> a seed, your whole argument goes out of the window, you can write the\n> seed if that's what you want to do, and throw away the mnemonic.\n>\n>\n>\n> On Sat, Jan 6, 2018 at 1:40 PM, Aymeric Vitte <vitteaymeric at gmail.com\n> <mailto:vitteaymeric at gmail.com>> wrote:\n>\n>     Unfortunately, even \"yourself\" seems not to know what he is\n>     talking about (so imagine for other people, 256 bits is advised\n>     --> 32B), probably that's why you brought this discussion off the\n>     list, then making recommendations to improve something that is\n>     misleading and messy is quite dubious\n>\n>     And maybe you should take a look at what people you are talking to\n>     are doing before arguing stuff that you apparently don't know very\n>     well (ie \"the length of the *derived *key\", not the seed), cf\n>     https://github.com/Ayms/bitcoin-wallets\n>     <https://github.com/Ayms/bitcoin-wallets> and even\n>     https://github.com/Ayms/zcash-wallets (not official but\n>     https://github.com/zcash/zips/issues/95)\n>     <https://github.com/Ayms/zcash-wallets>\n>\n>     But as you can notice there is a missing feature, ie to derive the\n>     wallets from xpriv, there is a comment in the repo why I don't\n>     like some things \"Surprisingly from ~32 bytes keys BIP32 ends up\n>     with a 78 bytes format to describe them with all the necessary\n>     information like indexes, parent to possibly allow to revert the tree\"\n>\n>     That's another thing I completely dislike with BIP39, it ends up\n>     with xpriv, not the 32B seed, there are many, many, many posts in\n>     forums of people fighting to figure out their private keys derived\n>     from bip39/44/etc\n>\n>     \"No offence too\" but please keep your advises for yourself, I\n>     indeed don't read closely inept BIPs, and never said I did not\n>     like BIP32, that's the contrary, I really like it\n>\n>     Before firing plenty of BIPs that do not fit together people maybe\n>     should take a break and see what people are doing today (this is\n>     quite amazing) and why they got stolen\n>\n>     And you seem to know very little about security, if you suspect\n>     you home printer, then suspect you OS, your hw, etc, (you really\n>     envision to generate a seed from a mobile device ???) writing 64\n>     characters is not very difficult for a human being, even easier\n>     than writing x words of y length\n>\n>     See this too\n>     https://bitcointalk.org/index.php?topic=2550529.msg26133887#msg26133887\n>     <https://bitcointalk.org/index.php?topic=2550529.msg26133887#msg26133887>,\n>     the tutorial was corrected, but basic things are still missing, an\n>     offline version is when you disconnect from the internet, not when\n>     you use the \"offline version\"\u00a0 (assuming that the browser storage\n>     or other stuff are not used...)\n>\n>     Re-ccing the list because again at a certain point of time the\n>     theory should look at the reality and adapt accordingly, part of\n>     the example I gave is off topic for this thread but globally\n>     (which could become another thread) the message is: the bitcoin\n>     community should stop making things complicate for people,\n>     releasing BIPs of no use just ends up with complicating things\n>     more than it helps, people deserve to understand what they are\n>     doing, manage their keys by their own and stop syncing useless\n>     full nodes for every coin to sync their wallets, that's why I made\n>     the tool, the first people that used it made some outstanding\n>     mistakes that I did not envision now it's not possible any longer,\n>     except if they give wrong destination addresses and nobody can't\n>     do anything about this (btw the primary intent of the tool was for\n>     myself and you are right for once, I did not know that people\n>     could do so big mistakes, that's not their fault, I see it now, my\n>     mistake for underestimating this)\n>\n>\n>     Le 06/01/2018 \u00e0 16:00, Alan Evans a \u00e9crit\u00a0:\n>>     You're mistaken. BIP32 does not require a particular\u00a0length. It\n>>     recommends:\n>>\n>>       * Generate a seed byte sequence S of a chosen length (between\n>>         128 and 512 bits; 256 bits is advised) from a (P)RNG\n>>\n>>     But BIP39 produces a\u00a064 byte\u00a0seed:\n>>\n>>     The length of the derived key is 512 bits (= 64 bytes).\n>>\n>>     If you don't believe me, why don't you just try it? That seed\n>>     will derive the same keys as that mnemonic, it's a real example.\n>>\n>>     ---------\n>>\n>>     About printing, there is a huge security risk involved in\n>>     printing anything. Networks, printers may have memory. People\n>>     will print to PDF when they don't have a printer on hand. Mobile\n>>     users often can't print.\n>>\n>>     I wrote mine down, by hand, generated from an offline computer\n>>     booted with a\u00a0readonly\u00a0OS.\u00a0\n>>\n>>     Feel free to produce a recommendation to replace BIP39/32/44 if\n>>     you like, but it's not broken just because someone had trouble\n>>     using your tool/following your instructions. And no offence but\n>>     I'd be wary using a tool from someone who doesn't read the BIPs\n>>     closely yet is so confident about how other people are wrong.\n>>\n>>\n>>     On Sat, Jan 6, 2018 at 6:57 AM, Aymeric Vitte\n>>     <vitteaymeric at gmail.com <mailto:vitteaymeric at gmail.com>> wrote:\n>>\n>>         And Alan, btw, a BIP32 seed is 32 bytes, then 64 characters,\n>>         not 64\n>>         bytes as your wrote below, which probably corresponds to\n>>         xprv, which is\n>>         another misleading element of BIP39\n>>\n>>\n>>         Le 06/01/2018 \u00e0 02:56, Aymeric Vitte a \u00e9crit\u00a0:\n>>         > The fact is indeed that \"we should really find a way to\n>>         overhaul this\n>>         > whole BIP 39 / 43/ 44 etc ad hoc mess\"\n>>         >\n>>         > Because the git example I provided is about someone that\n>>         knows (to a\n>>         > certain extent) what he is doing, then made a mistake for the\n>>         > destination address, which is not related to this discussion\n>>         >\n>>         > This just shows how complicate it can become even for\n>>         people knowing\n>>         > this to retrieve their wallet and how wallets made it \"the\n>>         easy way\" (ie\n>>         > bip39, 44, multisig...)\n>>         >\n>>         > If people prefer to store mnemonics, why not, but \"writing\n>>         down\" in both\n>>         > messages above is not accurate, you would better print it\n>>         and cut it in\n>>         > n pieces if you like, then the point of using mnemonics\n>>         that you can't\n>>         > remember more than an hex string still remains useless from\n>>         my standpoint\n>>         >\n>>         > Beside the theory we should look now if BIP39 & all brought\n>>         more good\n>>         > than the contrary in practice, I think that the later wins\n>>         >\n>>         >\n>>         > Le 05/01/2018 \u00e0 21:38, Sjors Provoost a \u00e9crit\u00a0:\n>>         >> Hi Alan,\n>>         >>\n>>         >> The Github issue is arguably unrelated, which is why I put\n>>         it at the end and said \u201csome related\u201d.\n>>         >>\n>>         >> However it does all tie together; we should really find a\n>>         way to overhaul this whole BIP 39 / 43/ 44 etc ad hoc mess,\n>>         ideally in a way that even Bitcoin Core would be willing to\n>>         use it. When you change the word list, it\u2019s best to change\n>>         everything else at the same time. Otherwise you\u2019d have too\n>>         many different standards, which is a pain for wallets to\n>>         implement.\n>>         >>\n>>         >> I share your view than a mnemonic is better than a bunch\n>>         of hex numbers. It\u2019s easier to memorize and easier to write\n>>         down. Some people don\u2019t like it when users write down\n>>         phrases, but they\u2019re much, much more likely to lose their\n>>         coins than some burglar to find the piece of paper. My issue\n>>         is only with the way derivation currently works.\n>>         >>\n>>         >> Sjors\n>>         >>\n>>         >>> Op 5 jan. 2018, om 21:05 heeft Alan Evans\n>>         <thealanevans at gmail.com <mailto:thealanevans at gmail.com>> het\n>>         volgende geschreven:\n>>         >>>\n>>         >>> Taking it off the board. I can't read all of that issue.\n>>         BIP0039 mnemonic generates a seed. Everything past there to\n>>         do with addresses (BIP32/44/49/141 whatever) is the same as\n>>         if you started with the seed. So you can't blaim BIP0039 for\n>>         that person's misunderstanding, and the way different wallets\n>>         use different derivation paths.\n>>         >>>\n>>         >>> If someone has a BIP0039 mnemonic and would rather back\n>>         up the seed, they can go ahead. But one tiny mistake in\n>>         writing it down and you may have a hell of a time finding out\n>>         what's wrong as every seed is valid. A mistake in writing\n>>         down words is far harder to make. You can also memorize a\n>>         mnemonic (hence the name), the average person cannot memorize\n>>         a seed.\n>>         >>>\n>>         >>> fork canal mad beyond spike pool expire fuel region\n>>         impose ceiling video\n>>         >>>\n>>         >>> vs:\n>>         >>>\n>>         >>>\n>>         f54b80812b3a6f1834095370df82a2123aece2d6089da67d7871477c004684fbc399a6155e53de0b783a9be6388354846e51f59e4869984f0c554e6469788c64\n>>         >>>\n>>         >>> But they lead to the same addresses.\n>>         >>>\n>>         >>> Need I say more?\n>>         >>>\n>>         >>>\n>>         >>> On Fri, Jan 5, 2018 at 3:56 PM, Aymeric Vitte\n>>         <vitteaymeric at gmail.com <mailto:vitteaymeric at gmail.com>> wrote:\n>>         >>> No that's not, some parts of the answer might be but this\n>>         related, this just shows how people use wrongly BIP39 and\n>>         subsequent BIPs (and globally other things), misleading them,\n>>         while the advantage of using it is quite dubious compared to\n>>         backing up a seed, unless you can convince me of the contrary\n>>         >>>\n>>         >>> Le 05/01/2018 \u00e0 19:16, Alan Evans a \u00e9crit :\n>>         >>>> Sjors, well in Electrum, validation is optional, but\n>>         English only. As for the Ledger-S, that sounds like a Ledger\n>>         problem.\n>>         >>>>\n>>         >>>> Aymeric, that is way off topic, did you reply to wrong\n>>         email?\n>>         >>>>\n>>         >>>> On Fri, Jan 5, 2018 at 2:08 PM, Aymeric Vitte\n>>         <vitteaymeric at gmail.com <mailto:vitteaymeric at gmail.com>> wrote:\n>>         >>>> See:\n>>         https://github.com/Ayms/bitcoin-transactions/issues/3\n>>         <https://github.com/Ayms/bitcoin-transactions/issues/3>\n>>         >>>>\n>>         >>>> OK, maybe it's my fault, I did not foresee this case,\n>>         and now it's working for p2sh (non segwit)\n>>         >>>> From my standpoint this just means that BIP39/44 stuff\n>>         should be eradicated (not BIP141 but see what happened...),\n>>         this is of no use, confusing people, doing dangerous things\n>>         to recover\n>>         >>>> Really is it easier to save x words instead of a seed?\n>>         Knowing that people are creating several wallets not\n>>         understanding that this is not the purpose of BIP32?\n>>         >>>>\n>>         >>>> Multisig wallets (like Electrum) have created a big mess\n>>         too, on purpose or no, I don't know, but multisig is for\n>>         different parties involved, not just one\n>>         >>>>\n>>         >>>> Le 05/01/2018 \u00e0 18:13, Sjors Provoost via bitcoin-dev a\n>>         \u00e9crit :\n>>         >>>>> I don\u2019t know about Electrum but many wallets validate\n>>         the English words, which helps in catching typos.\n>>         >>>>>\n>>         >>>>> Hardware wallets without a full keyboard, like the\n>>         Ledger Nano S, won\u2019t even let you freely type characters; you\n>>         have to select words from a list.\n>>         >>>>>\n>>         >>>>> So although the standard technically allows what you\n>>         say, if you use anything other than 12, 16 or 24 English\n>>         words, you\u2019ll have fewer wallets to choose from.\n>>         >>>>>\n>>         >>>>> I think it\u2019s better to come up with a new standard than\n>>         trying to patch BIP-39 at this point, which is why I brought\n>>         it up.\n>>         >>>>>\n>>         >>>>> Sjors\n>>         >>>>>\n>>         >>>>>\n>>         >>>>>> Op 5 jan. 2018, om 17:27 heeft Alan Evans\n>>         <thealanevans at gmail.com <mailto:thealanevans at gmail.com>>\n>>         >>>>>>\u00a0 het volgende geschreven:\n>>         >>>>>>\n>>         >>>>>> \"Very few wallets support anything other than English\"\n>>         >>>>>>\n>>         >>>>>> By support do you mean allow recovery, validation or\n>>         generation or all three? For if you can freely type a phrase\n>>         in (such as Electrum), or even word by word, then the\n>>         likely-hood is it is supported if they remembered to normalize.\n>>         >>>>>>\n>>         >>>>>> Seed generation in BIP0039 requires no dictionary\n>>         what-so-ever! So there is no word list to lose in the first\n>>         place. Your funds are accessible with just the characters and\n>>         the algorithm as described in BIP0039.\n>>         >>>>>>\n>>         >>>>>> But your proposal is a million miles away from simply\n>>         adding some standard in-language names to some word lists\n>>         feels like it's derailing the OP's simple proposal. Maybe\n>>         start own email chain about it.\n>>         >>>>>>\n>>         >>>>>> Alan\n>>         >>>>>>\n>>         >>>>>> On Fri, Jan 5, 2018 at 12:04 PM, Sjors Provoost via\n>>         bitcoin-dev\n>>         >>>>>> <bitcoin-dev at lists.linuxfoundation.org\n>>         <mailto:bitcoin-dev at lists.linuxfoundation.org>>\n>>         >>>>>>\u00a0 wrote:\n>>         >>>>>> I\u2019m not a fan of language specific word lists within\n>>         the current BIP-39 standard. Very few wallets support\n>>         anything other than English, which can lead to vendor lock-in\n>>         and long term loss of funds if a rare non-English wallet\n>>         disappears.\n>>         >>>>>>\n>>         >>>>>> However, because people can memorize things better in\n>>         their native tongue, supporting multiple languages seems\n>>         quite useful.\n>>         >>>>>>\n>>         >>>>>> I would prefer a new standard where words are mapped\n>>         to integers rather than to a literal string. For each\n>>         language a mapping from words to integers would be published.\n>>         In addition to that, there would be a mapping from original\n>>         language words to matching (in terms of integer value, not\n>>         meaning) English words that people can print on an A4 paper.\n>>         This would allow them to enter a mnemonic into e.g. a\n>>         hardware wallet that only support English. Such lists are\n>>         more likely to be around 100 years from now than some ancient\n>>         piece of software.\n>>         >>>>>>\n>>         >>>>>> This would not work with the current BIP-39 (duress)\n>>         password, but this feature could be replaced by appending\n>>         words (with or without a checksum for that addition).\n>>         >>>>>>\n>>         >>>>>> A replacement for BIP-39 would be a good opportunity\n>>         to produce a better English dictionary as Nic Johnson\n>>         suggested a while ago:\n>>         >>>>>>\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2022 all words are 4-8 characters\n>>         >>>>>>\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2022 all 4-character prefixes are unique (very\n>>         useful for hardware wallets)\n>>         >>>>>>\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2022 no two words have edit distance < 2\n>>         >>>>>>\n>>         >>>>>> Wallets need to be able to distinguish between the old\n>>         and new standard, so un-upgraded BIP 39 wallets should\n>>         consider all new mnemonics invalid. At the same time, some\n>>         new wallets may not wish to support BIP39. They shouldn't be\n>>         burdened with storing the old word list.\n>>         >>>>>>\n>>         >>>>>> A solution is to sort the new word list such that\n>>         reused words appear first. When generating a mnemonic, at\n>>         least one word unique to the new list must be present. A\n>>         wallet only needs to know the index of the last BIP39\n>>         overlapping word. They reject a proposed mnemonic if none of\n>>         the elements use a word with a higher index.\n>>         >>>>>>\n>>         >>>>>> For my above point and some related ideas, see:\n>>         >>>>>> https://github.com/satoshilabs/slips/issues/103\n>>         <https://github.com/satoshilabs/slips/issues/103>\n>>         >>>>>>\n>>         >>>>>>\n>>         >>>>>> Sjors\n>>         >>>>>>\n>>         >>>>>>\n>>         >>>>>>> Op 5 jan. 2018, om 14:58 heeft nullius via\n>>         bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org\n>>         <mailto:bitcoin-dev at lists.linuxfoundation.org>>\n>>         >>>>>>>\u00a0 het volgende geschreven:\n>>         >>>>>>>\n>>         >>>>>>> I propose and request as an enhancement that the BIP\n>>         39 wordlist set should specify canonical native language\n>>         strings to identify each wordlist, as well as short ASCII\n>>         language codes.\u00a0 At present, the languages are identified\n>>         only by their names in English.\n>>         >>>>>>>\n>>         >>>>>>> Strings properly vetted and recommended by native\n>>         speakers should facilitate language identification in user\n>>         interface options or menus.\u00a0 Specification of language\n>>         identifier strings would also promote interface consistency\n>>         between implementations; this may be important if a user\n>>         creates a mnemonic in Implementation A, then restores a\n>>         wallet using that mnemonic in Implementation B.\n>>         >>>>>>>\n>>         >>>>>>> As an independent implementer who does not know *all*\n>>         these different languages, I monkey-pasted language-native\n>>         strings from a popular wiki site.\u00a0 I cannot guarantee that\n>>         they be all accurate, sensible, or even non-embarrassing.\n>>         >>>>>>>\n>>         >>>>>>>\n>>         >>>>>>>\n>>         https://github.com/nym-zone/easyseed/blob/1a6e48bbdac9366d9d5d1912dc062dfc3f0db2c6/easyseed.c#L99\n>>         <https://github.com/nym-zone/easyseed/blob/1a6e48bbdac9366d9d5d1912dc062dfc3f0db2c6/easyseed.c#L99>\n>>         >>>>>>>\n>>         >>>>>>> ```\n>>         >>>>>>>\u00a0 \u00a0 \u00a0 \u00a0LANG(english,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0u8\"English\",\u00a0 \u00a0\n>>         \"en\",\u00a0 \u00a0ascii_space ),\n>>         >>>>>>>\u00a0 \u00a0 \u00a0 \u00a0LANG(chinese_simplified,\u00a0 \u00a0 \u00a0 \u00a0 u8\"\u6c49\u8bed\",\n>>         \"zh-CN\",ascii_space ),\n>>         >>>>>>>\u00a0 \u00a0 \u00a0 \u00a0LANG(chinese_traditional,\u00a0 \u00a0 \u00a0 \u00a0u8\"\u6f22\u8a9e\",\n>>         \"zh-TW\",ascii_space ),\n>>         >>>>>>>\u00a0 \u00a0 \u00a0 \u00a0LANG(french,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 u8\"Fran\u00e7ais\",\u00a0\n>>         \u00a0\"fr\",\u00a0 \u00a0ascii_space ),\n>>         >>>>>>>\u00a0 \u00a0 \u00a0 \u00a0LANG(italian,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0u8\"Italiano\",\u00a0\n>>         \u00a0\"it\",\u00a0 \u00a0ascii_space ),\n>>         >>>>>>>\u00a0 \u00a0 \u00a0 \u00a0LANG(japanese,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 u8\"\u65e5\u672c\u8a9e\",\u00a0 \u00a0 \u00a0 \u00a0\n>>         \"ja\",\u00a0 \u00a0u8\"\\u3000\"\u00a0 ),\n>>         >>>>>>>\u00a0 \u00a0 \u00a0 \u00a0LANG(korean,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 u8\"\ud55c\uad6d\uc5b4\",\u00a0 \u00a0 \u00a0 \u00a0\n>>         \"ko\",\u00a0 \u00a0ascii_space ),\n>>         >>>>>>>\u00a0 \u00a0 \u00a0 \u00a0LANG(spanish,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0u8\"Espa\u00f1ol\",\u00a0 \u00a0\n>>         \"es\",\u00a0 \u00a0ascii_space )\n>>         >>>>>>> ```\n>>         >>>>>>>\n>>         >>>>>>> Per the comment at #L85 of the quoted file, I also\n>>         know that for my short identifiers for Chinese, \u201czh-CN\u201d and\n>>         \u201czh-TW\u201d, are imprecise at best\u2014insofar as Hong Kong uses\n>>         Traditional; and overseas Chinese may use either.\u00a0 For\n>>         differentiating the two Chinese writing variants, are there\n>>         any appropriate standardized or customary short ASCII\n>>         language IDs similar to ISO 3166-1 alpha-2 which are purely\n>>         linguistic, and not fit to present-day political boundaries?\n>>         >>>>>>>\n>>         >>>>>>> My general suggestion is that the specification of\n>>         appropriate strings in\n>>         >>>>>>> bitcoin:bips/bip-0039/bip-0039-wordlists.md\n>>         <http://bip-0039-wordlists.md>\n>>         >>>>>>>\u00a0 be made part of the process for accepting new\n>>         wordlists.\u00a0 My specific request is that such strings be\n>>         ascertained for the wordlists already existing, preferably\n>>         from the persons involved in the original pull requests therefor.\n>>         >>>>>>>\n>>         >>>>>>> Should this proposal be \u201cconcept ACKed\u201d by\n>>         appropriate parties, then I may open a pull request\n>>         suggesting an appropriate format for specifying this\n>>         information in the repository.\u00a0 However, I will must needs\n>>         leave the vetting of appropriate strings to native speakers\n>>         or experts in the respective languages.\n>>         >>>>>>>\n>>         >>>>>>> Prior references:\u00a0 The wordlist additions at PRs #92,\n>>         #130 (Japanese); #100 (Spanish); #114 (Chinese, both\n>>         variants); #152 (French); #306 (Italian); #570 (Korean); #621\n>>         (Indonesian, *proposed*, open).\n>>         >>>>>>> ______________________________\n>>\n>\n\n-- \nBitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions\nZcash wallets made simple: https://github.com/Ayms/zcash-wallets\nBitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets\nGet the torrent dynamic blocklist: http://peersm.com/getblocklist\nCheck the 10 M passwords list: http://peersm.com/findmyass\nAnti-spies and private torrents, dynamic blocklist: http://torrent-live.org\nPeersm : http://www.peersm.com\ntorrent-live: https://github.com/Ayms/torrent-live\nnode-Tor : https://www.github.com/Ayms/node-Tor\nGitHub : https://www.github.com/Ayms\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180106/54801027/attachment-0001.html>"
            },
            {
                "author": "Greg Sanders",
                "date": "2018-01-08T14:54:38",
                "message_text_only": "Let me re-phrase: Is it a known thing for users to actually use it?\n\nOn Mon, Jan 8, 2018 at 9:52 AM, Matias Alejo Garcia <ematiu at gmail.com>\nwrote:\n\n>\n>\n> On Mon, Jan 8, 2018 at 11:34 AM, Greg Sanders via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Has anyone actually used the multilingual support in bip39?\n>>\n>\n>\n> Copay (and all its clones) use it.\n>\n>\n>\n>\n>\n>>\n>> If a feature of the standard has not been(widely?) used in years, and\n>> isn't supported in any major wallet(?), it seems indicative it was a\n>> mistake to add it in the first place, since it's a footgun in the making\n>> for some poor sap who can't even read English letters when almost all\n>> documentation is written in English.\n>>\n>> On Mon, Jan 8, 2018 at 6:13 AM, nullius via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> On 2018-01-08 at 07:35:52 +0000, \u6728\u30ce\u4e0b\u3058\u3087\u306a <kinoshitajona at gmail.com> wrote:\n>>>\n>>>> This is very sad.\n>>>>\n>>>> The number one problem in Japan with BIP39 seeds is with English words.\n>>>>\n>>>> I have seen a 60 year old Japanese man writing down his phrase (because\n>>>> he kept on failing recovery), and watched him write down \"aneter\" for\n>>>> \"amateur\"...\n>>>>\n>>>> [...]\n>>>>\n>>>> If you understand English and can spell, you read a word, your brain\n>>>> processes the word, and you can spell it on your own when writing down.\n>>>> Not many Japanese people can do that, so they need to copy letter for\n>>>> letter, taking a long time, and still messing up on occasion.\n>>>>\n>>>> [...]\n>>>>\n>>>> Defining \"everyone should only use English, because ASCII is easier to\n>>>> plan for\" is not a good way to move forward as a currency.\n>>>>\n>>>\n>>> Well said.  Thank you for telling of these experiences.  Now please,\n>>> let\u2019s put the shoe on the other foot.\n>>>\n>>> I ask everybody who wants an English-only mnemonic standard to entrust\n>>> *their own money* to their abilities to very, very carefully write this\n>>> down\u2014then later, type it back in:\n>>>\n>>> \u3059\u3055\u3093 \u305f\u3093\u308d \u308a\u3086\u3046 \u3057\u3082\u3093 \u3066\u3044\u304a\u3093 \u3057\u3068\u3046\n>>> \u3068\u3053\u3084 \u306f\u3084\u3044 \u304a\u3046\u3055\u307e \u307b\u304f\u308d \u3051\u3061\u3083\u3063\u3075 \u305f\u3082\u3064\n>>>\n>>> (Approximate translation:  \u201cWhatever would you do if Bitcoin had been\n>>> invented by somebody named Satoshi Nakamoto?\u201d)\n>>>\n>>> No, wait:  That is only a 12-word mnemonic.  We are probably talking\n>>> about a Trezor; so now, hey you there, stake the backup of your life\u2019s\n>>> savings on your ability to handwrite *this*:\n>>>\n>>> \u306b\u3042\u3046 \u3057\u3072\u3087\u3046 \u306b\u3093\u3059\u3046 \u3072\u3048\u308b \u304b\u3044\u3053\u3046 \u3044\u306e\u308b \u306d\u3093\u3057 \u306f\u3042\u3055\u3093 \u3072\u3053\u304f\n>>> \u3068\u3046\u304f \u304d\u3082\u305f\u3081\u3057 \u305d\u306a\u305f \u3053\u306a\u3053\u306a \u306b\u3055\u3093\u304b\u305f\u3093\u305d \u308d\u3093\u304d \u3081\u3044\u3042\u3093 \u307f\u308f\u304f\n>>> \u3078\u3053\u3080 \u3059\u3072\u3087\u3046 \u304a\u3084\u3086\u3072 \u3075\u305b\u304f \u3051\u3055\u304d \u3081\u3044\u304d\u3087\u304f \u3053\u3093\u307e\u3051\n>>>\n>>> Ready to bet your money on *that* as a backup phrase in your own hands?\n>>> No?  Then please, stop demanding that others risk *their* money on the\n>>> inverse case.\n>>>\n>>> ----\n>>>\n>>> If you cheat here by having studied Japanese, then remember that many\n>>> Japanese people know English and other European languages, too.  Then think\n>>> of how much money would be lost by your non-Japanese-literate family and\n>>> friends\u2014if BIP 39 had only Japanese wordlists, and your folks needed to\n>>> wrestle with the above phrases as their \u201cmnemonics\u201d.\n>>>\n>>> In such cases, the phrases cannot be called \u201cmnemonics\u201d at all.  A\n>>> \u201cmnemonic\u201d implies aid to memory.  Gibberish in a wholly alien writing\n>>> system is much worse even than transcribing pseudorandom hex strings.  The\n>>> Japanese man in the quoted story, who wrote \u201caneter\u201d for \u201camateur\u201d, was not\n>>> dealing with a *mnemonic*:  He was using the world\u2019s most inefficient means\n>>> of making cryptic bitstrings *less* userfriendly.\n>>>\n>>> ----\n>>>\n>>> I began this thread with a quite simple request:  Is \u201c\u65e5\u672c\u8a9e\u201d an\n>>> appropriate string for identifying the Japanese language to Japanese\n>>> users?  And what of the other strings I posted for other languages?\n>>>\n>>> I asked this as an implementer working on my own instance of the\n>>> greatest guard against vendor lock-in and stale software:  Independent\n>>> implementations.  \u2014  I asked, because obviously, I myself do not speak all\n>>> these different languages; and I want to implement them all.  *All.*\n>>>\n>>> Some replies have been interesting in their own right; but thus far,\n>>> nobody has squarely addressed the substance of my question.\n>>>\n>>> Most worrisome is that much of the discussion has veered into criticism\n>>> of multi-language support.  I opened with a question about other languages,\n>>> and I am getting replies which raise a hue and cry of \u201cEnglish only!\u201d\n>>>\n>>> Though I am fluent and literate in English, I am uninterested in ever\n>>> implementing any standard of this nature which is artificially restricted\n>>> to English.  I am fortunate; for as of this moment, we have a standard\n>>> called \u201cBIP 39\u201d which has seven non-English wordlists, and four more\n>>> pending in open pull requests (#432, #442, #493, #621).\n>>>\n>>> I request discussion of language identification strings appropriate for\n>>> use with that standard.\n>>>\n>>> (P.S., I hope that my system did not mangle anything in the foregoing.\n>>> I have seen weird copypaste behaviour mess up decomposed characters.  I\n>>> thought of this after I searched for and collected some visually\n>>> fascinating phrases; so I tried to normalize these to NFC...  It should go\n>>> without saying, easyseed output the Japanese perfectly!)\n>>>\n>>>\n>>> --\n>>> nullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\n>>> Bitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n>>> 3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n>>> \u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\n>>> No!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n>>>\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>\n>\n> --\n> Mat\u00edas Alejo Garcia\n> @ematiu\n> Roads? Where we're going, we don't need roads!\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180108/a95eac7a/attachment-0001.html>"
            },
            {
                "author": "Matias Alejo Garcia",
                "date": "2018-01-08T15:23:53",
                "message_text_only": "> Let me re-phrase: Is it a known thing for users to actually use it?\n\nyes. Based on language stats from the app stores, roughly 30% to 40% of\nCopay users have their backup on a language\nother than English, and we constantly get requests to support new languages\nin BIP39.\n\nOn Mon, Jan 8, 2018 at 11:54 AM, Greg Sanders <gsanders87 at gmail.com> wrote:\n\n> Let me re-phrase: Is it a known thing for users to actually use it?\n>\n> On Mon, Jan 8, 2018 at 9:52 AM, Matias Alejo Garcia <ematiu at gmail.com>\n> wrote:\n>\n>>\n>>\n>> On Mon, Jan 8, 2018 at 11:34 AM, Greg Sanders via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Has anyone actually used the multilingual support in bip39?\n>>>\n>>\n>>\n>> Copay (and all its clones) use it.\n>>\n>>\n>>\n>>\n>>\n>>>\n>>> If a feature of the standard has not been(widely?) used in years, and\n>>> isn't supported in any major wallet(?), it seems indicative it was a\n>>> mistake to add it in the first place, since it's a footgun in the making\n>>> for some poor sap who can't even read English letters when almost all\n>>> documentation is written in English.\n>>>\n>>> On Mon, Jan 8, 2018 at 6:13 AM, nullius via bitcoin-dev <\n>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> On 2018-01-08 at 07:35:52 +0000, \u6728\u30ce\u4e0b\u3058\u3087\u306a <kinoshitajona at gmail.com>\n>>>> wrote:\n>>>>\n>>>>> This is very sad.\n>>>>>\n>>>>> The number one problem in Japan with BIP39 seeds is with English words.\n>>>>>\n>>>>> I have seen a 60 year old Japanese man writing down his phrase\n>>>>> (because he kept on failing recovery), and watched him write down \"aneter\"\n>>>>> for \"amateur\"...\n>>>>>\n>>>>> [...]\n>>>>>\n>>>>> If you understand English and can spell, you read a word, your brain\n>>>>> processes the word, and you can spell it on your own when writing down.\n>>>>> Not many Japanese people can do that, so they need to copy letter for\n>>>>> letter, taking a long time, and still messing up on occasion.\n>>>>>\n>>>>> [...]\n>>>>>\n>>>>> Defining \"everyone should only use English, because ASCII is easier to\n>>>>> plan for\" is not a good way to move forward as a currency.\n>>>>>\n>>>>\n>>>> Well said.  Thank you for telling of these experiences.  Now please,\n>>>> let\u2019s put the shoe on the other foot.\n>>>>\n>>>> I ask everybody who wants an English-only mnemonic standard to entrust\n>>>> *their own money* to their abilities to very, very carefully write this\n>>>> down\u2014then later, type it back in:\n>>>>\n>>>> \u3059\u3055\u3093 \u305f\u3093\u308d \u308a\u3086\u3046 \u3057\u3082\u3093 \u3066\u3044\u304a\u3093 \u3057\u3068\u3046\n>>>> \u3068\u3053\u3084 \u306f\u3084\u3044 \u304a\u3046\u3055\u307e \u307b\u304f\u308d \u3051\u3061\u3083\u3063\u3075 \u305f\u3082\u3064\n>>>>\n>>>> (Approximate translation:  \u201cWhatever would you do if Bitcoin had been\n>>>> invented by somebody named Satoshi Nakamoto?\u201d)\n>>>>\n>>>> No, wait:  That is only a 12-word mnemonic.  We are probably talking\n>>>> about a Trezor; so now, hey you there, stake the backup of your life\u2019s\n>>>> savings on your ability to handwrite *this*:\n>>>>\n>>>> \u306b\u3042\u3046 \u3057\u3072\u3087\u3046 \u306b\u3093\u3059\u3046 \u3072\u3048\u308b \u304b\u3044\u3053\u3046 \u3044\u306e\u308b \u306d\u3093\u3057 \u306f\u3042\u3055\u3093 \u3072\u3053\u304f\n>>>> \u3068\u3046\u304f \u304d\u3082\u305f\u3081\u3057 \u305d\u306a\u305f \u3053\u306a\u3053\u306a \u306b\u3055\u3093\u304b\u305f\u3093\u305d \u308d\u3093\u304d \u3081\u3044\u3042\u3093 \u307f\u308f\u304f\n>>>> \u3078\u3053\u3080 \u3059\u3072\u3087\u3046 \u304a\u3084\u3086\u3072 \u3075\u305b\u304f \u3051\u3055\u304d \u3081\u3044\u304d\u3087\u304f \u3053\u3093\u307e\u3051\n>>>>\n>>>> Ready to bet your money on *that* as a backup phrase in your own\n>>>> hands?  No?  Then please, stop demanding that others risk *their* money on\n>>>> the inverse case.\n>>>>\n>>>> ----\n>>>>\n>>>> If you cheat here by having studied Japanese, then remember that many\n>>>> Japanese people know English and other European languages, too.  Then think\n>>>> of how much money would be lost by your non-Japanese-literate family and\n>>>> friends\u2014if BIP 39 had only Japanese wordlists, and your folks needed to\n>>>> wrestle with the above phrases as their \u201cmnemonics\u201d.\n>>>>\n>>>> In such cases, the phrases cannot be called \u201cmnemonics\u201d at all.  A\n>>>> \u201cmnemonic\u201d implies aid to memory.  Gibberish in a wholly alien writing\n>>>> system is much worse even than transcribing pseudorandom hex strings.  The\n>>>> Japanese man in the quoted story, who wrote \u201caneter\u201d for \u201camateur\u201d, was not\n>>>> dealing with a *mnemonic*:  He was using the world\u2019s most inefficient means\n>>>> of making cryptic bitstrings *less* userfriendly.\n>>>>\n>>>> ----\n>>>>\n>>>> I began this thread with a quite simple request:  Is \u201c\u65e5\u672c\u8a9e\u201d an\n>>>> appropriate string for identifying the Japanese language to Japanese\n>>>> users?  And what of the other strings I posted for other languages?\n>>>>\n>>>> I asked this as an implementer working on my own instance of the\n>>>> greatest guard against vendor lock-in and stale software:  Independent\n>>>> implementations.  \u2014  I asked, because obviously, I myself do not speak all\n>>>> these different languages; and I want to implement them all.  *All.*\n>>>>\n>>>> Some replies have been interesting in their own right; but thus far,\n>>>> nobody has squarely addressed the substance of my question.\n>>>>\n>>>> Most worrisome is that much of the discussion has veered into criticism\n>>>> of multi-language support.  I opened with a question about other languages,\n>>>> and I am getting replies which raise a hue and cry of \u201cEnglish only!\u201d\n>>>>\n>>>> Though I am fluent and literate in English, I am uninterested in ever\n>>>> implementing any standard of this nature which is artificially restricted\n>>>> to English.  I am fortunate; for as of this moment, we have a standard\n>>>> called \u201cBIP 39\u201d which has seven non-English wordlists, and four more\n>>>> pending in open pull requests (#432, #442, #493, #621).\n>>>>\n>>>> I request discussion of language identification strings appropriate for\n>>>> use with that standard.\n>>>>\n>>>> (P.S., I hope that my system did not mangle anything in the foregoing.\n>>>> I have seen weird copypaste behaviour mess up decomposed characters.  I\n>>>> thought of this after I searched for and collected some visually\n>>>> fascinating phrases; so I tried to normalize these to NFC...  It should go\n>>>> without saying, easyseed output the Japanese perfectly!)\n>>>>\n>>>>\n>>>> --\n>>>> nullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\n>>>> Bitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n>>>> 3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n>>>> \u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\n>>>> No!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n>>>>\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>\n>>>>\n>>>\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>>\n>>\n>>\n>> --\n>> Mat\u00edas Alejo Garcia\n>> @ematiu\n>> Roads? Where we're going, we don't need roads!\n>>\n>\n>\n\n\n-- \nMat\u00edas Alejo Garcia\n@ematiu\nRoads? Where we're going, we don't need roads!\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180108/6928a411/attachment-0001.html>"
            },
            {
                "author": "AJ West",
                "date": "2018-01-08T15:26:38",
                "message_text_only": "Greg yes, there were already examples in this very thread of people\nexplaining how they use languages other than English. I'm shocked that so\nmany people are resisting the idea that just *maybe* there could be people\nin other parts of the world who do not want to use or cannot use the strict\nset of latin characters and words from the English language.\n\nI agree with Sjors and maybe I'm simplifying too much, but can't we just\nmap an existing ISO/UTF language character standard to the seeds? Why is\nthere a word list at all? Choose a flexible encoding standard, create a\nclever map to the bytes, make sure to include a checksum.\n\nAs an aside, I know there are some conventions which add space for error\ncorrection but I personally don't love the idea of somebody inputting what\nthey think is the proper seed, only to have it auto-corrected and thus\nreinforcing their erroneously saved/written seed backup.\n\nPavol, why do you say \"I learned that it was something I should've been\nmore persistently against?\" I still can't see any good arguments as to why\nwe should limit this to English other than \"It's easier to support a single\nlanguage\" which comes at the cost of \"It's hard for me to backup my seed\"\nfor those who don't speak English.\n\nOn Mon, Jan 8, 2018 at 10:23 AM, Matias Alejo Garcia via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> > Let me re-phrase: Is it a known thing for users to actually use it?\n>\n> yes. Based on language stats from the app stores, roughly 30% to 40% of\n> Copay users have their backup on a language\n> other than English, and we constantly get requests to support new\n> languages in BIP39.\n>\n> On Mon, Jan 8, 2018 at 11:54 AM, Greg Sanders <gsanders87 at gmail.com>\n> wrote:\n>\n>> Let me re-phrase: Is it a known thing for users to actually use it?\n>>\n>> On Mon, Jan 8, 2018 at 9:52 AM, Matias Alejo Garcia <ematiu at gmail.com>\n>> wrote:\n>>\n>>>\n>>>\n>>> On Mon, Jan 8, 2018 at 11:34 AM, Greg Sanders via bitcoin-dev <\n>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> Has anyone actually used the multilingual support in bip39?\n>>>>\n>>>\n>>>\n>>> Copay (and all its clones) use it.\n>>>\n>>>\n>>>\n>>>\n>>>\n>>>>\n>>>> If a feature of the standard has not been(widely?) used in years, and\n>>>> isn't supported in any major wallet(?), it seems indicative it was a\n>>>> mistake to add it in the first place, since it's a footgun in the making\n>>>> for some poor sap who can't even read English letters when almost all\n>>>> documentation is written in English.\n>>>>\n>>>> On Mon, Jan 8, 2018 at 6:13 AM, nullius via bitcoin-dev <\n>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>\n>>>>> On 2018-01-08 at 07:35:52 +0000, \u6728\u30ce\u4e0b\u3058\u3087\u306a <kinoshitajona at gmail.com>\n>>>>> wrote:\n>>>>>\n>>>>>> This is very sad.\n>>>>>>\n>>>>>> The number one problem in Japan with BIP39 seeds is with English\n>>>>>> words.\n>>>>>>\n>>>>>> I have seen a 60 year old Japanese man writing down his phrase\n>>>>>> (because he kept on failing recovery), and watched him write down \"aneter\"\n>>>>>> for \"amateur\"...\n>>>>>>\n>>>>>> [...]\n>>>>>>\n>>>>>> If you understand English and can spell, you read a word, your brain\n>>>>>> processes the word, and you can spell it on your own when writing down.\n>>>>>> Not many Japanese people can do that, so they need to copy letter for\n>>>>>> letter, taking a long time, and still messing up on occasion.\n>>>>>>\n>>>>>> [...]\n>>>>>>\n>>>>>> Defining \"everyone should only use English, because ASCII is easier\n>>>>>> to plan for\" is not a good way to move forward as a currency.\n>>>>>>\n>>>>>\n>>>>> Well said.  Thank you for telling of these experiences.  Now please,\n>>>>> let\u2019s put the shoe on the other foot.\n>>>>>\n>>>>> I ask everybody who wants an English-only mnemonic standard to entrust\n>>>>> *their own money* to their abilities to very, very carefully write this\n>>>>> down\u2014then later, type it back in:\n>>>>>\n>>>>> \u3059\u3055\u3093 \u305f\u3093\u308d \u308a\u3086\u3046 \u3057\u3082\u3093 \u3066\u3044\u304a\u3093 \u3057\u3068\u3046\n>>>>> \u3068\u3053\u3084 \u306f\u3084\u3044 \u304a\u3046\u3055\u307e \u307b\u304f\u308d \u3051\u3061\u3083\u3063\u3075 \u305f\u3082\u3064\n>>>>>\n>>>>> (Approximate translation:  \u201cWhatever would you do if Bitcoin had been\n>>>>> invented by somebody named Satoshi Nakamoto?\u201d)\n>>>>>\n>>>>> No, wait:  That is only a 12-word mnemonic.  We are probably talking\n>>>>> about a Trezor; so now, hey you there, stake the backup of your life\u2019s\n>>>>> savings on your ability to handwrite *this*:\n>>>>>\n>>>>> \u306b\u3042\u3046 \u3057\u3072\u3087\u3046 \u306b\u3093\u3059\u3046 \u3072\u3048\u308b \u304b\u3044\u3053\u3046 \u3044\u306e\u308b \u306d\u3093\u3057 \u306f\u3042\u3055\u3093 \u3072\u3053\u304f\n>>>>> \u3068\u3046\u304f \u304d\u3082\u305f\u3081\u3057 \u305d\u306a\u305f \u3053\u306a\u3053\u306a \u306b\u3055\u3093\u304b\u305f\u3093\u305d \u308d\u3093\u304d \u3081\u3044\u3042\u3093 \u307f\u308f\u304f\n>>>>> \u3078\u3053\u3080 \u3059\u3072\u3087\u3046 \u304a\u3084\u3086\u3072 \u3075\u305b\u304f \u3051\u3055\u304d \u3081\u3044\u304d\u3087\u304f \u3053\u3093\u307e\u3051\n>>>>>\n>>>>> Ready to bet your money on *that* as a backup phrase in your own\n>>>>> hands?  No?  Then please, stop demanding that others risk *their* money on\n>>>>> the inverse case.\n>>>>>\n>>>>> ----\n>>>>>\n>>>>> If you cheat here by having studied Japanese, then remember that many\n>>>>> Japanese people know English and other European languages, too.  Then think\n>>>>> of how much money would be lost by your non-Japanese-literate family and\n>>>>> friends\u2014if BIP 39 had only Japanese wordlists, and your folks needed to\n>>>>> wrestle with the above phrases as their \u201cmnemonics\u201d.\n>>>>>\n>>>>> In such cases, the phrases cannot be called \u201cmnemonics\u201d at all.  A\n>>>>> \u201cmnemonic\u201d implies aid to memory.  Gibberish in a wholly alien writing\n>>>>> system is much worse even than transcribing pseudorandom hex strings.  The\n>>>>> Japanese man in the quoted story, who wrote \u201caneter\u201d for \u201camateur\u201d, was not\n>>>>> dealing with a *mnemonic*:  He was using the world\u2019s most inefficient means\n>>>>> of making cryptic bitstrings *less* userfriendly.\n>>>>>\n>>>>> ----\n>>>>>\n>>>>> I began this thread with a quite simple request:  Is \u201c\u65e5\u672c\u8a9e\u201d an\n>>>>> appropriate string for identifying the Japanese language to Japanese\n>>>>> users?  And what of the other strings I posted for other languages?\n>>>>>\n>>>>> I asked this as an implementer working on my own instance of the\n>>>>> greatest guard against vendor lock-in and stale software:  Independent\n>>>>> implementations.  \u2014  I asked, because obviously, I myself do not speak all\n>>>>> these different languages; and I want to implement them all.  *All.*\n>>>>>\n>>>>> Some replies have been interesting in their own right; but thus far,\n>>>>> nobody has squarely addressed the substance of my question.\n>>>>>\n>>>>> Most worrisome is that much of the discussion has veered into\n>>>>> criticism of multi-language support.  I opened with a question about other\n>>>>> languages, and I am getting replies which raise a hue and cry of \u201cEnglish\n>>>>> only!\u201d\n>>>>>\n>>>>> Though I am fluent and literate in English, I am uninterested in ever\n>>>>> implementing any standard of this nature which is artificially restricted\n>>>>> to English.  I am fortunate; for as of this moment, we have a standard\n>>>>> called \u201cBIP 39\u201d which has seven non-English wordlists, and four more\n>>>>> pending in open pull requests (#432, #442, #493, #621).\n>>>>>\n>>>>> I request discussion of language identification strings appropriate\n>>>>> for use with that standard.\n>>>>>\n>>>>> (P.S., I hope that my system did not mangle anything in the\n>>>>> foregoing.  I have seen weird copypaste behaviour mess up decomposed\n>>>>> characters.  I thought of this after I searched for and collected some\n>>>>> visually fascinating phrases; so I tried to normalize these to NFC...  It\n>>>>> should go without saying, easyseed output the Japanese perfectly!)\n>>>>>\n>>>>>\n>>>>> --\n>>>>> nullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\n>>>>> Bitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n>>>>> 3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n>>>>> \u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\n>>>>> No!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n>>>>>\n>>>>> _______________________________________________\n>>>>> bitcoin-dev mailing list\n>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>\n>>>>>\n>>>>\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>\n>>>>\n>>>\n>>>\n>>> --\n>>> Mat\u00edas Alejo Garcia\n>>> @ematiu\n>>> Roads? Where we're going, we don't need roads!\n>>>\n>>\n>>\n>\n>\n> --\n> Mat\u00edas Alejo Garcia\n> @ematiu\n> Roads? Where we're going, we don't need roads!\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180108/67000d6f/attachment.html>"
            },
            {
                "author": "Greg Sanders",
                "date": "2018-01-08T15:32:58",
                "message_text_only": ">I'm shocked that so many people are resisting the idea that just *maybe* there\ncould be people in other parts of the world who do not want to use or\ncannot use the strict set of latin characters and words from the English\nlanguage.\n\n\nYou're mistaking concern for users potentially losing money with disdain\nfor them. I can read a few languages, yet I would not advise users to use a\nwordlist that might not have support across multiple wallet\nimplementations, resulting in lock-in or worse.\n\nIf I'm wrong, great, more people can use software strictly in their native\nlanguage in a safe manner!\n\nOn Mon, Jan 8, 2018 at 10:26 AM, AJ West <ajwest at gmail.com> wrote:\n\n> Greg yes, there were already examples in this very thread of people\n> explaining how they use languages other than English. I'm shocked that so\n> many people are resisting the idea that just *maybe* there could be\n> people in other parts of the world who do not want to use or cannot use the\n> strict set of latin characters and words from the English language.\n>\n> I agree with Sjors and maybe I'm simplifying too much, but can't we just\n> map an existing ISO/UTF language character standard to the seeds? Why is\n> there a word list at all? Choose a flexible encoding standard, create a\n> clever map to the bytes, make sure to include a checksum.\n>\n> As an aside, I know there are some conventions which add space for error\n> correction but I personally don't love the idea of somebody inputting what\n> they think is the proper seed, only to have it auto-corrected and thus\n> reinforcing their erroneously saved/written seed backup.\n>\n> Pavol, why do you say \"I learned that it was something I should've been\n> more persistently against?\" I still can't see any good arguments as to why\n> we should limit this to English other than \"It's easier to support a single\n> language\" which comes at the cost of \"It's hard for me to backup my seed\"\n> for those who don't speak English.\n>\n> On Mon, Jan 8, 2018 at 10:23 AM, Matias Alejo Garcia via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> > Let me re-phrase: Is it a known thing for users to actually use it?\n>>\n>> yes. Based on language stats from the app stores, roughly 30% to 40% of\n>> Copay users have their backup on a language\n>> other than English, and we constantly get requests to support new\n>> languages in BIP39.\n>>\n>> On Mon, Jan 8, 2018 at 11:54 AM, Greg Sanders <gsanders87 at gmail.com>\n>> wrote:\n>>\n>>> Let me re-phrase: Is it a known thing for users to actually use it?\n>>>\n>>> On Mon, Jan 8, 2018 at 9:52 AM, Matias Alejo Garcia <ematiu at gmail.com>\n>>> wrote:\n>>>\n>>>>\n>>>>\n>>>> On Mon, Jan 8, 2018 at 11:34 AM, Greg Sanders via bitcoin-dev <\n>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>\n>>>>> Has anyone actually used the multilingual support in bip39?\n>>>>>\n>>>>\n>>>>\n>>>> Copay (and all its clones) use it.\n>>>>\n>>>>\n>>>>\n>>>>\n>>>>\n>>>>>\n>>>>> If a feature of the standard has not been(widely?) used in years, and\n>>>>> isn't supported in any major wallet(?), it seems indicative it was a\n>>>>> mistake to add it in the first place, since it's a footgun in the making\n>>>>> for some poor sap who can't even read English letters when almost all\n>>>>> documentation is written in English.\n>>>>>\n>>>>> On Mon, Jan 8, 2018 at 6:13 AM, nullius via bitcoin-dev <\n>>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>>\n>>>>>> On 2018-01-08 at 07:35:52 +0000, \u6728\u30ce\u4e0b\u3058\u3087\u306a <kinoshitajona at gmail.com>\n>>>>>> wrote:\n>>>>>>\n>>>>>>> This is very sad.\n>>>>>>>\n>>>>>>> The number one problem in Japan with BIP39 seeds is with English\n>>>>>>> words.\n>>>>>>>\n>>>>>>> I have seen a 60 year old Japanese man writing down his phrase\n>>>>>>> (because he kept on failing recovery), and watched him write down \"aneter\"\n>>>>>>> for \"amateur\"...\n>>>>>>>\n>>>>>>> [...]\n>>>>>>>\n>>>>>>> If you understand English and can spell, you read a word, your brain\n>>>>>>> processes the word, and you can spell it on your own when writing down.\n>>>>>>> Not many Japanese people can do that, so they need to copy letter for\n>>>>>>> letter, taking a long time, and still messing up on occasion.\n>>>>>>>\n>>>>>>> [...]\n>>>>>>>\n>>>>>>> Defining \"everyone should only use English, because ASCII is easier\n>>>>>>> to plan for\" is not a good way to move forward as a currency.\n>>>>>>>\n>>>>>>\n>>>>>> Well said.  Thank you for telling of these experiences.  Now please,\n>>>>>> let\u2019s put the shoe on the other foot.\n>>>>>>\n>>>>>> I ask everybody who wants an English-only mnemonic standard to\n>>>>>> entrust *their own money* to their abilities to very, very carefully write\n>>>>>> this down\u2014then later, type it back in:\n>>>>>>\n>>>>>> \u3059\u3055\u3093 \u305f\u3093\u308d \u308a\u3086\u3046 \u3057\u3082\u3093 \u3066\u3044\u304a\u3093 \u3057\u3068\u3046\n>>>>>> \u3068\u3053\u3084 \u306f\u3084\u3044 \u304a\u3046\u3055\u307e \u307b\u304f\u308d \u3051\u3061\u3083\u3063\u3075 \u305f\u3082\u3064\n>>>>>>\n>>>>>> (Approximate translation:  \u201cWhatever would you do if Bitcoin had been\n>>>>>> invented by somebody named Satoshi Nakamoto?\u201d)\n>>>>>>\n>>>>>> No, wait:  That is only a 12-word mnemonic.  We are probably talking\n>>>>>> about a Trezor; so now, hey you there, stake the backup of your life\u2019s\n>>>>>> savings on your ability to handwrite *this*:\n>>>>>>\n>>>>>> \u306b\u3042\u3046 \u3057\u3072\u3087\u3046 \u306b\u3093\u3059\u3046 \u3072\u3048\u308b \u304b\u3044\u3053\u3046 \u3044\u306e\u308b \u306d\u3093\u3057 \u306f\u3042\u3055\u3093 \u3072\u3053\u304f\n>>>>>> \u3068\u3046\u304f \u304d\u3082\u305f\u3081\u3057 \u305d\u306a\u305f \u3053\u306a\u3053\u306a \u306b\u3055\u3093\u304b\u305f\u3093\u305d \u308d\u3093\u304d \u3081\u3044\u3042\u3093 \u307f\u308f\u304f\n>>>>>> \u3078\u3053\u3080 \u3059\u3072\u3087\u3046 \u304a\u3084\u3086\u3072 \u3075\u305b\u304f \u3051\u3055\u304d \u3081\u3044\u304d\u3087\u304f \u3053\u3093\u307e\u3051\n>>>>>>\n>>>>>> Ready to bet your money on *that* as a backup phrase in your own\n>>>>>> hands?  No?  Then please, stop demanding that others risk *their* money on\n>>>>>> the inverse case.\n>>>>>>\n>>>>>> ----\n>>>>>>\n>>>>>> If you cheat here by having studied Japanese, then remember that many\n>>>>>> Japanese people know English and other European languages, too.  Then think\n>>>>>> of how much money would be lost by your non-Japanese-literate family and\n>>>>>> friends\u2014if BIP 39 had only Japanese wordlists, and your folks needed to\n>>>>>> wrestle with the above phrases as their \u201cmnemonics\u201d.\n>>>>>>\n>>>>>> In such cases, the phrases cannot be called \u201cmnemonics\u201d at all.  A\n>>>>>> \u201cmnemonic\u201d implies aid to memory.  Gibberish in a wholly alien writing\n>>>>>> system is much worse even than transcribing pseudorandom hex strings.  The\n>>>>>> Japanese man in the quoted story, who wrote \u201caneter\u201d for \u201camateur\u201d, was not\n>>>>>> dealing with a *mnemonic*:  He was using the world\u2019s most inefficient means\n>>>>>> of making cryptic bitstrings *less* userfriendly.\n>>>>>>\n>>>>>> ----\n>>>>>>\n>>>>>> I began this thread with a quite simple request:  Is \u201c\u65e5\u672c\u8a9e\u201d an\n>>>>>> appropriate string for identifying the Japanese language to Japanese\n>>>>>> users?  And what of the other strings I posted for other languages?\n>>>>>>\n>>>>>> I asked this as an implementer working on my own instance of the\n>>>>>> greatest guard against vendor lock-in and stale software:  Independent\n>>>>>> implementations.  \u2014  I asked, because obviously, I myself do not speak all\n>>>>>> these different languages; and I want to implement them all.  *All.*\n>>>>>>\n>>>>>> Some replies have been interesting in their own right; but thus far,\n>>>>>> nobody has squarely addressed the substance of my question.\n>>>>>>\n>>>>>> Most worrisome is that much of the discussion has veered into\n>>>>>> criticism of multi-language support.  I opened with a question about other\n>>>>>> languages, and I am getting replies which raise a hue and cry of \u201cEnglish\n>>>>>> only!\u201d\n>>>>>>\n>>>>>> Though I am fluent and literate in English, I am uninterested in ever\n>>>>>> implementing any standard of this nature which is artificially restricted\n>>>>>> to English.  I am fortunate; for as of this moment, we have a standard\n>>>>>> called \u201cBIP 39\u201d which has seven non-English wordlists, and four more\n>>>>>> pending in open pull requests (#432, #442, #493, #621).\n>>>>>>\n>>>>>> I request discussion of language identification strings appropriate\n>>>>>> for use with that standard.\n>>>>>>\n>>>>>> (P.S., I hope that my system did not mangle anything in the\n>>>>>> foregoing.  I have seen weird copypaste behaviour mess up decomposed\n>>>>>> characters.  I thought of this after I searched for and collected some\n>>>>>> visually fascinating phrases; so I tried to normalize these to NFC...  It\n>>>>>> should go without saying, easyseed output the Japanese perfectly!)\n>>>>>>\n>>>>>>\n>>>>>> --\n>>>>>> nullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00\n>>>>>> 591B2F307E0C\n>>>>>> Bitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n>>>>>> 3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n>>>>>> \u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\n>>>>>> No!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n>>>>>>\n>>>>>> _______________________________________________\n>>>>>> bitcoin-dev mailing list\n>>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>>\n>>>>>>\n>>>>>\n>>>>> _______________________________________________\n>>>>> bitcoin-dev mailing list\n>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>\n>>>>>\n>>>>\n>>>>\n>>>> --\n>>>> Mat\u00edas Alejo Garcia\n>>>> @ematiu\n>>>> Roads? Where we're going, we don't need roads!\n>>>>\n>>>\n>>>\n>>\n>>\n>> --\n>> Mat\u00edas Alejo Garcia\n>> @ematiu\n>> Roads? Where we're going, we don't need roads!\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180108/97965c8c/attachment-0001.html>"
            },
            {
                "author": "Aymeric Vitte",
                "date": "2018-01-08T16:02:02",
                "message_text_only": "That's the point indeed and the scope is wider than XYZIP-39, even if\nwhat I mean is the very contrary of your point (really bitcoin is\nreserved to an elite understanding english/ascii letters?)\n\nThis proposal is tailor made for Trezor and does not simplify anything\nfor people, that's the contrary again\n\nAs I suggested in another response to this thread (which was moderated\ndue probably to some uninteresting parts of the discussion) it's time to\ntake a break and really make a survey worldwide of what people need,\nwhat they understand and what they need to secure their coins, nobody\nhas any feedback about this (and maybe does not even care)\n\nWallets created a big mess implementing non standard things (or things\nthey thought standard but that are not), or things not intended for the\nfinal use, or things that people can't understand, it's time to correct\nthis, unless wallets want to keep people tied forever to them (when I\nread Trezor or other wallets docs, it's quite misleading, \"sending coins\nto your wallet\", what does it mean? Nothing, and people think it means\nsomething, this should stop now)\n\nAnd again, I don't see the point of wordlist (in addition in a language\nthat they don't understand) compared to backing up a 32B hex string\n(that you can encrypt different ways at different places), assuming that\nthe hex format can be made available in all languages\n\n\"yet I would not advise users to use a wordlist that might not have\nsupport across multiple wallet implementations, resulting in lock-in or\nworse\"--> this single sentence shows how the whole model is wrong and\nhow you think that you can lock people\n\nLe 08/01/2018 \u00e0 15:54, Greg Sanders via bitcoin-dev a \u00e9crit\u00a0:\n> Let me re-phrase: Is it a known thing for users to actually use it?\n>\n> On Mon, Jan 8, 2018 at 9:52 AM, Matias Alejo Garcia <ematiu at gmail.com\n> <mailto:ematiu at gmail.com>> wrote:\n>\n>\n>\n>     On Mon, Jan 8, 2018 at 11:34 AM, Greg Sanders via bitcoin-dev\n>     <bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>\n>         Has anyone actually used the multilingual support in bip39?\n>\n>\n>\n>     Copay (and all its clones) use it.\u00a0\n>\n>\n>\n>     \u00a0\n>\n>\n>         If a feature of the standard has not been(widely?) used in\n>         years, and isn't supported in any major wallet(?), it seems\n>         indicative it was a mistake to add it in the first place,\n>         since it's a footgun in the making for some poor sap who can't\n>         even read English letters when almost all documentation is\n>         written in English.\n>\n>         On Mon, Jan 8, 2018 at 6:13 AM, nullius via bitcoin-dev\n>         <bitcoin-dev at lists.linuxfoundation.org\n>         <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>\n>             On 2018-01-08 at 07:35:52 +0000, \u6728\u30ce\u4e0b\u3058\u3087\u306a\n>             <kinoshitajona at gmail.com <mailto:kinoshitajona at gmail.com>>\n>             wrote:\n>\n>                 This is very sad.\n>\n>                 The number one problem in Japan with BIP39 seeds is\n>                 with English words.\n>\n>                 I have seen a 60 year old Japanese man writing down\n>                 his phrase (because he kept on failing recovery), and\n>                 watched him write down \"aneter\" for \"amateur\"...\n>\n>                 [...]\n>\n>                 If you understand English and can spell, you read a\n>                 word, your brain processes the word, and you can spell\n>                 it on your own when writing down.\u00a0 Not many Japanese\n>                 people can do that, so they need to copy letter for\n>                 letter, taking a long time, and still messing up on\n>                 occasion.\n>\n>                 [...]\n>\n>                 Defining \"everyone should only use English, because\n>                 ASCII is easier to plan for\" is not a good way to move\n>                 forward as a currency.\n>\n>\n>             Well said.\u00a0 Thank you for telling of these experiences.\u00a0\n>             Now please, let\u2019s put the shoe on the other foot.\n>\n>             I ask everybody who wants an English-only mnemonic\n>             standard to entrust *their own money* to their abilities\n>             to very, very carefully write this down\u2014then later, type\n>             it back in:\n>\n>             \u3059\u3055\u3093\u3000\u305f\u3093\u308d\u3000\u308a\u3086\u3046\u3000\u3057\u3082\u3093\u3000\u3066\u3044\u304a\u3093\u3000\u3057\u3068\u3046\n>             \u3068\u3053\u3084\u3000\u306f\u3084\u3044\u3000\u304a\u3046\u3055\u307e\u3000\u307b\u304f\u308d\u3000\u3051\u3061\u3083\u3063\u3075\u3000\u305f\u3082\u3064\n>\n>             (Approximate translation:\u00a0 \u201cWhatever would you do if\n>             Bitcoin had been invented by somebody named Satoshi\n>             Nakamoto?\u201d)\n>\n>             No, wait:\u00a0 That is only a 12-word mnemonic.\u00a0 We are\n>             probably talking about a Trezor; so now, hey you there,\n>             stake the backup of your life\u2019s savings on your ability to\n>             handwrite *this*:\n>\n>             \u306b\u3042\u3046\u3000\u3057\u3072\u3087\u3046\u3000\u306b\u3093\u3059\u3046\u3000\u3072\u3048\u308b\u3000\u304b\u3044\u3053\u3046\u3000\u3044\u306e\u308b\u3000\u306d\u3093\u3057\u3000\u306f\u3042\u3055\u3093\u3000\u3072\u3053\u304f\n>             \u3068\u3046\u304f\u3000\u304d\u3082\u305f\u3081\u3057\u3000\u305d\u306a\u305f\u3000\u3053\u306a\u3053\u306a\u3000\u306b\u3055\u3093\u304b\u305f\u3093\u305d\u3000\u308d\u3093\u304d\u3000\u3081\u3044\u3042\u3093\u3000\u307f\u308f\u304f\n>             \u3078\u3053\u3080\u3000\u3059\u3072\u3087\u3046\u3000\u304a\u3084\u3086\u3072\u3000\u3075\u305b\u304f\u3000\u3051\u3055\u304d\u3000\u3081\u3044\u304d\u3087\u304f\u3000\u3053\u3093\u307e\u3051\n>\n>             Ready to bet your money on *that* as a backup phrase in\n>             your own hands?\u00a0 No?\u00a0 Then please, stop demanding that\n>             others risk *their* money on the inverse case.\n>\n>             ----\n>\n>             If you cheat here by having studied Japanese, then\n>             remember that many Japanese people know English and other\n>             European languages, too.\u00a0 Then think of how much money\n>             would be lost by your non-Japanese-literate family and\n>             friends\u2014if BIP 39 had only Japanese wordlists, and your\n>             folks needed to wrestle with the above phrases as their\n>             \u201cmnemonics\u201d.\n>\n>             In such cases, the phrases cannot be called \u201cmnemonics\u201d at\n>             all.\u00a0 A \u201cmnemonic\u201d implies aid to memory.\u00a0 Gibberish in a\n>             wholly alien writing system is much worse even than\n>             transcribing pseudorandom hex strings.\u00a0 The Japanese man\n>             in the quoted story, who wrote \u201caneter\u201d for \u201camateur\u201d, was\n>             not dealing with a *mnemonic*:\u00a0 He was using the world\u2019s\n>             most inefficient means of making cryptic bitstrings *less*\n>             userfriendly.\n>\n>             ----\n>\n>             I began this thread with a quite simple request:\u00a0 Is \u201c\u65e5\u672c\u8a9e\u201d\n>             an appropriate string for identifying the Japanese\n>             language to Japanese users?\u00a0 And what of the other strings\n>             I posted for other languages?\n>\n>             I asked this as an implementer working on my own instance\n>             of the greatest guard against vendor lock-in and stale\n>             software:\u00a0 Independent implementations.\u00a0 \u2014\u00a0 I asked,\n>             because obviously, I myself do not speak all these\n>             different languages; and I want to implement them all.\u00a0 *All.*\n>\n>             Some replies have been interesting in their own right; but\n>             thus far, nobody has squarely addressed the substance of\n>             my question.\n>\n>             Most worrisome is that much of the discussion has veered\n>             into criticism of multi-language support.\u00a0 I opened with a\n>             question about other languages, and I am getting replies\n>             which raise a hue and cry of \u201cEnglish only!\u201d\n>\n>             Though I am fluent and literate in English, I am\n>             uninterested in ever implementing any standard of this\n>             nature which is artificially restricted to English.\u00a0 I am\n>             fortunate; for as of this moment, we have a standard\n>             called \u201cBIP 39\u201d which has seven non-English wordlists, and\n>             four more pending in open pull requests (#432, #442, #493,\n>             #621).\n>\n>             I request discussion of language identification strings\n>             appropriate for use with that standard.\n>\n>             (P.S., I hope that my system did not mangle anything in\n>             the foregoing.\u00a0 I have seen weird copypaste behaviour mess\n>             up decomposed characters.\u00a0 I thought of this after I\n>             searched for and collected some visually fascinating\n>             phrases; so I tried to normalize these to NFC...\u00a0 It\n>             should go without saying, easyseed output the Japanese\n>             perfectly!)\n>\n>\n>             -- \n>             nullius at nym.zone | PGP ECC:\n>             0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\n>             Bitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h |\n>             (Segwit nested:\n>             3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)\u00a0 (PGP RSA:\n>             0x36EBB4AB699A10EE)\n>             \u201c\u2018If you\u2019re not doing anything wrong, you have nothing to\n>             hide.\u2019\n>             No!\u00a0 Because I do nothing wrong, I have nothing to show.\u201d\n>             \u2014 nullius\n>\n>             _______________________________________________\n>             bitcoin-dev mailing list\n>             bitcoin-dev at lists.linuxfoundation.org\n>             <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>             https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>             <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>\n>\n>\n>         _______________________________________________\n>         bitcoin-dev mailing list\n>         bitcoin-dev at lists.linuxfoundation.org\n>         <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>         <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>\n>\n>\n>\n>     -- \n>     Mat\u00edas Alejo Garcia\n>     @ematiu\n>     Roads? Where we're going, we don't need roads!\n>\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-- \nBitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions\nZcash wallets made simple: https://github.com/Ayms/zcash-wallets\nBitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets\nGet the torrent dynamic blocklist: http://peersm.com/getblocklist\nCheck the 10 M passwords list: http://peersm.com/findmyass\nAnti-spies and private torrents, dynamic blocklist: http://torrent-live.org\nPeersm : http://www.peersm.com\ntorrent-live: https://github.com/Ayms/torrent-live\nnode-Tor : https://www.github.com/Ayms/node-Tor\nGitHub : https://www.github.com/Ayms\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180108/605d1ef0/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP 39: Add language identifier strings for wordlists",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Matias Alejo Garcia",
                "\u6728\u30ce\u4e0b\u3058\u3087\u306a",
                "Pavol Rusnak",
                "Aymeric Vitte",
                "Sjors Provoost",
                "nullius",
                "AJ West",
                "Greg Sanders"
            ],
            "messages_count": 18,
            "total_messages_chars_count": 154738
        }
    },
    {
        "title": "[bitcoin-dev] Satoshilabs secret shared private key scheme",
        "thread_messages": [
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-08T04:22:43",
                "message_text_only": "On Sun, Jan 7, 2018 at 3:16 PM, Pavol Rusnak via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> On 05/01/18 14:58, nullius via bitcoin-dev wrote:\n> I am currently drafting a new standard[1] which will allow also Shamir\n> Secret Scheme Splitting and there we disallow usage of a custom wordlist\n> in order to eradicate this mess. Will try to push this as BIP too once\n> we get it to the point we are OK with the contents.\n>\n> https://github.com/satoshilabs/slips/blob/master/slip-0039.md\n\nThis specification forces the key being used through a one way\nfunction, -- so you cannot take a pre-existing key and encode it with\nthis scheme.  The KDF it specifies is unconfigurable and fairly weak\n(20000xhmac-sha2-- which can be cracked at about 0.7M passwords a\nsecond on a single motherboard GPU cracker).  The construction also\nwill silently result in the user getting a different private key if\nthey enter the wrong passphrase-- which could lead to funds loss. It\nis again, unversioned-- so it kinda of seems like it is intentionally\nconstructed in a way that will prevent interoperable use, since the\nlack of versioning was a primary complaint from other perspective\nusers.  Of course, it fine if you want to make a trezor only thing,\nbut why bother BIPing something that was not intended for\ninteroperability?  Even for a single vendor spec the lack of\nversioning seems to make things harder to support new key-related\nfeatures such as segwit.\n\nThe 16-bit \"checksum\" based on sha2 seems pretty poor since basing\nsmall checksums on a cryptographic hash results in a fairly poor\nchecksum that is surprisingly likely to accept an errored string. Your\nwordlist is 10 bits and you have much less than 1023*10 bits of input,\nso you could easily have a 20 bit code (two words) which guaranteed\nthat up to two errored words would always be detected, and probably\ncould choose one which catches three words much more often 1:2^20\n(sipa's crc tools can help find codes like this).\n\nThe metadata seems to make fairly little affordance to help users\navoid accidentally mixing shares from distinct sharings of the same\nkey. Is it the idea that this is the only likely cause of a checksum\nerror? (1:2^16 chance of silently returning the wrong key seems kinda\nbad). -- I'm not sure much could be done here, though, since\nadditional payload is precious.\n\nAs an aside, your specification might want to give some better advice\nabout the SSS since my experience virtually everyone gets it wrong in\nways that degrade or destroy its properties e.g. many fail to generate\nthe additional coefficients of the polynominal randomly which results\nin insecurity (see armory for an example).   Oh, also, I believe it is\nnormally refereed to as \"SSS\" (three S)-- four S is the name of a\nlinux program for secret sharing.\n\nI'm happy to see that there is no obvious way to abuse this one as a\nbrainwallet scheme!"
            },
            {
                "author": "nullius",
                "date": "2018-01-08T06:33:44",
                "message_text_only": "On 2018-01-08 at 04:22:43 +0000 Gregory Maxwell <greg at xiph.org> wrote:\n>I'm happy to see that there is no obvious way to abuse this one as a \n>brainwallet scheme!\n\nBIP 39 was designed to make brainwallets secure!  If a user generates a \nweakling 12-word mnemonic from 16 tiny octets of entropy drawn off the \nnon-artistic /dev/urandom, then protects its seed with a creative \npassphrase haiku about the power of human stupidity, then the result \nwill have a 128-bit security level.  PROVE ME WRONG.\n\n-- \nnullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\nBIP 39 tool in progress, currently growing brainw^H^H^H^H^Hpassphrase \nsupport to help poor /dev/urandom: https://github.com/nym-zone/easyseed\nBitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 228 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180108/1992463a/attachment-0001.sig>"
            },
            {
                "author": "Pavol Rusnak",
                "date": "2018-01-08T12:39:20",
                "message_text_only": "On 08/01/18 05:22, Gregory Maxwell wrote:\n>> https://github.com/satoshilabs/slips/blob/master/slip-0039.md\n\nHey Gregory!\n\nThanks for looking into the scheme. I appreciate your time!\n\n> This specification forces the key being used through a one way\n> function, -- so you cannot take a pre-existing key and encode it with\n> this scheme.\n\nOriginally, we used a bi-directional function to be able to encode and\ndecode the key in both directions using the passphrase. We stretched the\npassphrase using KDF and then applied AES or other symmetric cipher\n\nWe found the following (theoretical) problem:\n\nIf an attacker has knowledge of few words from the beginning of shares,\nthey are able to reconstruct the beginning of the master secret and if\nthe size of the reconstruced master secret is bigger then the cipher\nblocksize (for block ciphers; for stream ciphers 1 bit is enough), then\nthey can reconstruct the beginning of the seed.\n\nCan you find a scheme which does not have this problem? Or you think\nthis problem is not worth solving?\n\n> The KDF it specifies is unconfigurable and fairly weak\n> (20000xhmac-sha2-- which can be cracked at about 0.7M passwords a\n> second on a single motherboard GPU cracker).\n\nYes. We want this to be possible to be computed on TREZOR-like devices\non boot, similarly how we compute BIP39 on boot right now.\n\n> The construction also\n> will silently result in the user getting a different private key if\n> they enter the wrong passphrase-- which could lead to funds loss.\n\nAgain, this is by design and it is main point why plausible deniability\nis achieved both in BIP39 and SLIP39. If we used a different\nconstruction we'd loose plausible deniability.\n\n> It\n> is again, unversioned-- so it kinda of seems like it is intentionally\n> constructed in a way that will prevent interoperable use, since the\n> lack of versioning was a primary complaint from other perspective\n> users.  Of course, it fine if you want to make a trezor only thing,\n> but why bother BIPing something that was not intended for\n> interoperability?  Even for a single vendor spec the lack of\n> versioning seems to make things harder to support new key-related\n> features such as segwit.\n\nThis is argument I keep having all the time.\n\nSuppose we'd introduce a version to encode PBKDF2 rounds or even\ndifferent KDFs. We'll end up with different SLIP39 mnemonics, but they\nwill not be compatible among implementations (because TREZOR can only up\nto 100.000 rounds of PBKDF2 and does not support Argon2 at all, while\nother desktop implementation would rather use memory-hard Argon2).\n\nMy gut feeling is that this would lead to WORSE interoperability, not\nbetter. Look at BIP32 for example. There are lots of wallet that claim\nthey are BIP32 compatible, but in reality they use different paths, so\nthey are not compatible. BIP32 is a good standard, but in reality\n\"BIP32-compatible\" does not mean anything, whereas when you say the\nwallet is \"BIP44-compatible\" you can be sure the migration path works.\n\n> The 16-bit \"checksum\" based on sha2 seems pretty poor since basing\n> small checksums on a cryptographic hash results in a fairly poor\n> checksum that is surprisingly likely to accept an errored string. Your\n> wordlist is 10 bits and you have much less than 1023*10 bits of input,\n> so you could easily have a 20 bit code (two words) which guaranteed\n> that up to two errored words would always be detected, and probably\n> could choose one which catches three words much more often 1:2^20\n> (sipa's crc tools can help find codes like this).\n\nOriginally, we wanted to use 16-bit of CRC32 for checksum, but after the\ndiscussion with Daan Sprenkels we were suggested to change this for\ncryptographically strong function. The argument was that CRC32 contains\nless entropy and mixing high-entropy data (secret) with low-entropy data\n(checksum) is not a good idea.\n\nAlso, there is an argument between a checksum and ECC. We discussed that\nECC might not be a good idea, because it helps the attacker to compute\nmissing information, while we only want to check for integrity. Also the\nword mnemonic is itself a ECC, because if you see the word \"acadornic\"\nit is probably the word \"academic\".\n\n> The metadata seems to make fairly little affordance to help users\n> avoid accidentally mixing shares from distinct sharings of the same\n> key. Is it the idea that this is the only likely cause of a checksum\n> error? (1:2^16 chance of silently returning the wrong key seems kinda\n> bad). -- I'm not sure much could be done here, though, since\n> additional payload is precious.\n\nYes, checksum is supposed to prevent that.\n\n> As an aside, your specification might want to give some better advice\n> about the SSS since my experience virtually everyone gets it wrong in\n> ways that degrade or destroy its properties e.g. many fail to generate\n> the additional coefficients of the polynominal randomly which results\n> in insecurity (see armory for an example).   Oh, also, I believe it is\n> normally refereed to as \"SSS\" (three S)-- four S is the name of a\n> linux program for secret sharing.\n\nWill fix the spelling. About the generic advice about SSS, anyone is\nwelcome to contribute to the text.\n\n> I'm happy to see that there is no obvious way to abuse this one as a\n> brainwallet scheme!\n\nAgreed!\n\n-- \nBest Regards / S pozdravom,\n\nPavol \"stick\" Rusnak\nCTO, SatoshiLabs"
            },
            {
                "author": "Peter Todd",
                "date": "2018-01-08T12:45:06",
                "message_text_only": "On Mon, Jan 08, 2018 at 01:39:20PM +0100, Pavol Rusnak via bitcoin-dev wrote:\n> > The construction also\n> > will silently result in the user getting a different private key if\n> > they enter the wrong passphrase-- which could lead to funds loss.\n> \n> Again, this is by design and it is main point why plausible deniability\n> is achieved both in BIP39 and SLIP39. If we used a different\n> construction we'd loose plausible deniability.\n\nCan you explain _exactly_ what scenario the \"plausible deniability\" feature\nrefers to?\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180108/a83273e6/attachment.sig>"
            },
            {
                "author": "Pavol Rusnak",
                "date": "2018-01-08T13:00:17",
                "message_text_only": "On 08/01/18 13:45, Peter Todd wrote:\n> Can you explain _exactly_ what scenario the \"plausible deniability\" feature\n> refers to?\n\n\nhttps://doc.satoshilabs.com/trezor-user/advanced_settings.html#multi-passphrase-encryption-hidden-wallets\n\n\n-- \nBest Regards / S pozdravom,\n\nPavol \"stick\" Rusnak\nCTO, SatoshiLabs\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180108/41cd23c4/attachment.sig>"
            },
            {
                "author": "Peter Todd",
                "date": "2018-01-08T19:37:14",
                "message_text_only": "On Mon, Jan 08, 2018 at 02:00:17PM +0100, Pavol Rusnak wrote:\n> On 08/01/18 13:45, Peter Todd wrote:\n> > Can you explain _exactly_ what scenario the \"plausible deniability\" feature\n> > refers to?\n> \n> \n> https://doc.satoshilabs.com/trezor-user/advanced_settings.html#multi-passphrase-encryption-hidden-wallets\n\nThis sounds very dangerous. As Gregory Maxwell pointed out, the key derivation\nfunction is weak enough that passphrases could be easily brute forced, at which\npoint the bad guys have cryptographic proof that you tried to lie to them and\ncover up funds.\n\n\nWhat model of human memory are you assuming here? What specifically are you\nassuming is easy to remember, and hard to remember? What psychology research\nbacks up your assumptions?\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180108/d27b5300/attachment.sig>"
            },
            {
                "author": "Ben Kloester",
                "date": "2018-01-08T22:26:17",
                "message_text_only": "> This sounds very dangerous. As Gregory Maxwell pointed out, the key\nderivation\n> function is weak enough that passphrases could be easily brute forced\n\nSo you are essentially imagining that a perpetrator will combine the\ncrypto-nerd fantasy (brute forcing the passphrase) *with* the 5-dollar\nwrench attack, merging both panes of Randall Munroe's comic? Seems\nvanishingly unlikely to me - attackers are generally either the wrench\ntype, or the crypto-nerd type.\n\nThis thread started by you asking Pavol to give an example of a real-life\nscenario in which this functionality would be used, and your rebuttal is a\nscenario that is even less likely to occur. \"Very dangerous\" is a huge\nstretch.\n\nWhen living in Brazil I often carried two (IRL) wallets - one a decoy to\ngive to muggers, the other with more value stored in it. I heard of plenty\nof people getting mugged, but I never heard of anyone who gave a decoy\nwallet getting more thoroughly searched and the second wallet found,\ndespite the relative ease with which a mugger could do this. I'm sure it\nhas happened, probably many times, but point is there is rarely time for\ncontemplation in a shakedown, and most perpetrators will take things at\nface value and be satisfied with getting something. And searching a\nphysical person's body is a hell of a lot simpler than cracking a\npassphrase.\n\nMoreover, there's no limit to the number of passphrases you can use. If you\nwere an atttacker, at what point would you stop, satisfied? After the\nfirst, second, third, fourth wallet that you find/they admit to owning?\nGoing beyond two is already Bond-supervillain level implausible.\n\n*Ben Kloester*\n\nOn 9 January 2018 at 06:37, Peter Todd via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Mon, Jan 08, 2018 at 02:00:17PM +0100, Pavol Rusnak wrote:\n> > On 08/01/18 13:45, Peter Todd wrote:\n> > > Can you explain _exactly_ what scenario the \"plausible deniability\"\n> feature\n> > > refers to?\n> >\n> >\n> > https://doc.satoshilabs.com/trezor-user/advanced_settings.\n> html#multi-passphrase-encryption-hidden-wallets\n>\n> This sounds very dangerous. As Gregory Maxwell pointed out, the key\n> derivation\n> function is weak enough that passphrases could be easily brute forced, at\n> which\n> point the bad guys have cryptographic proof that you tried to lie to them\n> and\n> cover up funds.\n>\n>\n> What model of human memory are you assuming here? What specifically are you\n> assuming is easy to remember, and hard to remember? What psychology\n> research\n> backs up your assumptions?\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180109/4701a311/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2018-01-09T00:37:25",
                "message_text_only": "On Tue, Jan 09, 2018 at 09:26:17AM +1100, Ben Kloester wrote:\n> > This sounds very dangerous. As Gregory Maxwell pointed out, the key\n> derivation\n> > function is weak enough that passphrases could be easily brute forced\n> \n> So you are essentially imagining that a perpetrator will combine the\n> crypto-nerd fantasy (brute forcing the passphrase) *with* the 5-dollar\n> wrench attack, merging both panes of Randall Munroe's comic? Seems\n> vanishingly unlikely to me - attackers are generally either the wrench\n> type, or the crypto-nerd type.\n\nWe're talking about seeds here, not hardware wallets.\n\nFor a hardware wallet theft scenario, if you're worried about muggers you can\nmake the hardware have secret accounts with different seeds, *without* risking\nuser funds getting lost - a much more likely scenario - due to mistyped\npasswords.\n\nIn any case, even if you were to do this type of design, a much better idea is\nto use a checksum by default to reject invalid passwords, while having an\nadvanced-use-only option to override that checksum. The virtual file encryption\nfilesystem encfs does exactly this with its --anykey flag. This allows advanced\nusers to do their thing, while protecting the majority of users for whome this\nfeature is dangerous.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180108/32a295b0/attachment-0001.sig>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-08T23:47:02",
                "message_text_only": "On Mon, Jan 8, 2018 at 12:39 PM, Pavol Rusnak <stick at satoshilabs.com> wrote:\n> On 08/01/18 05:22, Gregory Maxwell wrote:\n>>> https://github.com/satoshilabs/slips/blob/master/slip-0039.md\n>\n> Hey Gregory!\n>\n> Thanks for looking into the scheme. I appreciate your time!\n>\n>> This specification forces the key being used through a one way\n>> function, -- so you cannot take a pre-existing key and encode it with\n>> this scheme.\n>\n> Originally, we used a bi-directional function to be able to encode and\n> decode the key in both directions using the passphrase. We stretched the\n> passphrase using KDF and then applied AES or other symmetric cipher\n>\n> We found the following (theoretical) problem:\n>\n> If an attacker has knowledge of few words from the beginning of shares,\n> they are able to reconstruct the beginning of the master secret and if\n> the size of the reconstruced master secret is bigger then the cipher\n> blocksize (for block ciphers; for stream ciphers 1 bit is enough), then\n> they can reconstruct the beginning of the seed.\n>\n> Can you find a scheme which does not have this problem? Or you think\n> this problem is not worth solving?\n\nYou can use a large block cipher. E.g. CMC cipher mode.\n\nThough I am doubtful that this is a very relevant concern: What\nconsequence is it if someone with partial access to more than a\nthreshold of the shares can recover part of the seed?  This doesn't\nseem like a very interesting threat.   A large block mode would be\nmore complete, but this isn't something that would keep me up at night\nin the slightest.\n\nPerhaps I'm missing something, -- but the only real attack I see here\nis that a enduser mistakenly shows the first or couple words of all\ntheir shares on national television or what not... but doing so would\nnot really harm their security unless they showed almost all of them,\nand in that case an attacker could simply search the remaining couple\nwords.\n\nAlso, if we are going to assume that users will leak parts, the\nmnemonic encoding ends up being pretty bad... since just leaking a\nletter or two of each word would quite likely give the whole thing\naway.\n\nIn any case, to whatever extent partial leaks are a concern, using a\nlarge block cipher would be the obvious approach.\n\n> Yes. We want this to be possible to be computed on TREZOR-like devices\n> on boot, similarly how we compute BIP39 on boot right now.\n\nUnder this constraint it might be arguably to just eliminate the KDF.\nI think it provides false security and makes the implementation much\nmore complicated.\n\nHave you considered using blind host-delegated KDFs, where the KDF\nruns on the user's computer instead of the hardware wallet, but the\ncomputer doesn't learn anything about they keys?\n\n> Again, this is by design and it is main point why plausible deniability\n> is achieved both in BIP39 and SLIP39. If we used a different\n> construction we'd loose plausible deniability.\n\nI don't believe you can justify this design decision with any kind of\nrigorous threat model.\n\nThe probability that a user loses funds because they have at some\npoint recovered with the wrong key and don't know it would almost\ncertainly dwarf the probability that the user face some kind of\nmovie-plot threat where someone is attempting to forcibly extract a\nkey and yet somehow has no information about the user's actual\nwallet-- through, for example, leaked data on the users computers, the\nusers past payments to online accounts, or through a compromise or\nlawful order to satoshilab's web service which the users send private\ninformation to-- which would allow them to determine the key they were\ngiven was not correct.\n\nBut even there, given the weak level of false input rejection that you\nhave used (16 bits), it would be fairly straight forward to grind out\nan alternative passphrase that also passed the test.  Might that not\nmake for a better compromise?\n\nAnother thing to consider is that the main advantage of SSS over\nordinary computational secret sharing is that it's possible to\ngenerate alternative shares to an sub-threshold set of primary shares\nthat decodes to arbitrarily selected alternative data-- but it seems\nthe proposal makes no use of this fact.\n\n>> It\n>> is again, unversioned-- so it kinda of seems like it is intentionally\n>> constructed in a way that will prevent interoperable use, since the\n>> lack of versioning was a primary complaint from other perspective\n>> users.  Of course, it fine if you want to make a trezor only thing,\n>> but why bother BIPing something that was not intended for\n>> interoperability?  Even for a single vendor spec the lack of\n>> versioning seems to make things harder to support new key-related\n>> features such as segwit.\n>\n> This is argument I keep having all the time.\n>\n> Suppose we'd introduce a version to encode PBKDF2 rounds or even\n> different KDFs. We'll end up with different SLIP39 mnemonics, but they\n> will not be compatible among implementations (because TREZOR can only up\n> to 100.000 rounds of PBKDF2 and does not support Argon2 at all, while\n> other desktop implementation would rather use memory-hard Argon2).\n>\n> My gut feeling is that this would lead to WORSE interoperability, not\n> better. Look at BIP32 for example. There are lots of wallet that claim\n> they are BIP32 compatible, but in reality they use different paths, so\n> they are not compatible. BIP32 is a good standard, but in reality\n> \"BIP32-compatible\" does not mean anything, whereas when you say the\n> wallet is \"BIP44-compatible\" you can be sure the migration path works.\n\nThe end result is no better-- I think.  If you compromise\nfunctionality or security (e.g. pretextual KDF) because your product\ndoesn't yet support -- say, aggregate signatures-- or won't ever\nsupport a strong KDF; then other software will just not be\ninteroperable.  In cases were you won't ever support it, that doesn't\nmatter-- but presumably you would later support new signature styles\nand the loss of interoperability would potentially be gratitious.\n\nThat said, I'm generally skeptical of key interoperability to begin\nwith. Wallets can't share keys unless their functionality is\nidentical, half-interoperability can lead to funds loss. Identical\nfunctionality would mean constraining to the least common denominator.\n\nBut even if we exclude cross vendor interoperability entirely,\nwouldn't you want your next version of your firmware to be able to\nsupport new and old key styles (e.g. aggregate signatures vs plain\nsegwit) without having to define a whole new encoding?\n\n> Originally, we wanted to use 16-bit of CRC32 for checksum, but after the\n> discussion with Daan Sprenkels we were suggested to change this for\n> cryptographically strong function. The argument was that CRC32 contains\n> less entropy and mixing high-entropy data (secret) with low-entropy data\n> (checksum) is not a good idea.\n\nThat sounds like a kind of hand-wave and cargo cult argument-- pleas\nbe more specific, because that just sounds like amateur block cipher\ndesign.\n\nThere isn't any difference in \"entropy\" in either of these cases.\n\nAs an aside, using \"n bits of a longer CRC\" usually results in a low\nquality code for error detection similar to using a cryptographic\nhash.\n\n> Also, there is an argument between a checksum and ECC. We discussed that\n> ECC might not be a good idea, because it helps the attacker to compute\n> missing information, while we only want to check for integrity. Also the\n\nNot meaningfully more than the truncated cryptographic hash.\n\nThe best possible code of that length would allow you to list decode\nto around two errors with a lot of computation.\nWith the cryptographic hash the attacker need only check the 2^28\ntwo-error candidates to do exactly the same thing.\n\nSo the attacker there is no real difference-- he can brute force\nsearch to the same radius as correction would allow, but for the\nhonest users and software the probability of undetected error is\ngreater.  Similarly, while 2^28 operations is nothing to an attacker,\nif user software wants to use the correction for error hinting,\nrunning a hash 2^28 times would lead to a somewhat unfriendly user\nexperience so non-attack tools would be pretty unlikely to implement\nit."
            },
            {
                "author": "Rhavar",
                "date": "2018-01-09T00:40:38",
                "message_text_only": "I think you're under-appreciating how useful the \"plausible deniability\". Someone I know was (solo) traveling to the United States when a border agent asked her to unlocked her phone; thumbed through her apps, ended up finding tinder and went through all her recent conversations to make sure she wasn't involved in any \"pay for sex things\".\n\nIn the same light, I travel frequently and constantly have my trezor on me. If I am asked to unlock it, I will have no problems doing so (as refusal will no doubt lead to deportation) and showing my personal wallet (which sadly hasn't had much use since fees became ridiculous).\n\nAnd by doing so, I won't be revealing the half a dozen other accounts I keep. Which is the other big of such \"plausible deniability\" schemes, they make it trivial to create multiple wallets that are all firewalled away from each other.\n\nI will hypothesize that if one of my wallets was for something like buying stuff on dark markets there's simply no way anyone is going to ever know way you're going to be to tell short of some movie-plot level police effort. \n\n\n\n\u200b-Ryan\n\n\u200b\n\n>-------- Original Message --------\n>Subject: Re: [bitcoin-dev] Satoshilabs secret shared private key scheme\n>Local Time: January 8, 2018 5:47 PM\n>UTC Time: January 8, 2018 11:47 PM\n>From: bitcoin-dev at lists.linuxfoundation.org\n>To: Pavol Rusnak <stick at satoshilabs.com>\n>Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\n>\n>On Mon, Jan 8, 2018 at 12:39 PM, Pavol Rusnak stick at satoshilabs.com wrote:\n>>On 08/01/18 05:22, Gregory Maxwell wrote:\n>>>>https://github.com/satoshilabs/slips/blob/master/slip-0039.md\n>>>>Hey Gregory!\n>>Thanks for looking into the scheme. I appreciate your time!\n>>>This specification forces the key being used through a one way\n>>> function, -- so you cannot take a pre-existing key and encode it with\n>>> this scheme.\n>>>Originally, we used a bi-directional function to be able to encode and\n>> decode the key in both directions using the passphrase. We stretched the\n>> passphrase using KDF and then applied AES or other symmetric cipher\n>>We found the following (theoretical) problem:\n>>If an attacker has knowledge of few words from the beginning of shares,\n>> they are able to reconstruct the beginning of the master secret and if\n>> the size of the reconstruced master secret is bigger then the cipher\n>> blocksize (for block ciphers; for stream ciphers 1 bit is enough), then\n>> they can reconstruct the beginning of the seed.\n>>Can you find a scheme which does not have this problem? Or you think\n>> this problem is not worth solving?\n>>\n> You can use a large block cipher. E.g. CMC cipher mode.\n>\n> Though I am doubtful that this is a very relevant concern: What\n> consequence is it if someone with partial access to more than a\n> threshold of the shares can recover part of the seed?  This doesn't\n> seem like a very interesting threat.   A large block mode would be\n> more complete, but this isn't something that would keep me up at night\n> in the slightest.\n>\n> Perhaps I'm missing something, -- but the only real attack I see here\n> is that a enduser mistakenly shows the first or couple words of all\n> their shares on national television or what not... but doing so would\n> not really harm their security unless they showed almost all of them,\n> and in that case an attacker could simply search the remaining couple\n> words.\n>\n> Also, if we are going to assume that users will leak parts, the\n> mnemonic encoding ends up being pretty bad... since just leaking a\n> letter or two of each word would quite likely give the whole thing\n> away.\n>\n> In any case, to whatever extent partial leaks are a concern, using a\n> large block cipher would be the obvious approach.\n>\n>>Yes. We want this to be possible to be computed on TREZOR-like devices\n>> on boot, similarly how we compute BIP39 on boot right now.\n>>\n> Under this constraint it might be arguably to just eliminate the KDF.\n> I think it provides false security and makes the implementation much\n> more complicated.\n>\n> Have you considered using blind host-delegated KDFs, where the KDF\n> runs on the user's computer instead of the hardware wallet, but the\n> computer doesn't learn anything about they keys?\n>\n>>Again, this is by design and it is main point why plausible deniability\n>> is achieved both in BIP39 and SLIP39. If we used a different\n>> construction we'd loose plausible deniability.\n>>\n> I don't believe you can justify this design decision with any kind of\n> rigorous threat model.\n>\n> The probability that a user loses funds because they have at some\n> point recovered with the wrong key and don't know it would almost\n> certainly dwarf the probability that the user face some kind of\n> movie-plot threat where someone is attempting to forcibly extract a\n> key and yet somehow has no information about the user's actual\n> wallet-- through, for example, leaked data on the users computers, the\n> users past payments to online accounts, or through a compromise or\n> lawful order to satoshilab's web service which the users send private\n> information to-- which would allow them to determine the key they were\n> given was not correct.\n>\n> But even there, given the weak level of false input rejection that you\n> have used (16 bits), it would be fairly straight forward to grind out\n> an alternative passphrase that also passed the test.  Might that not\n> make for a better compromise?\n>\n> Another thing to consider is that the main advantage of SSS over\n> ordinary computational secret sharing is that it's possible to\n> generate alternative shares to an sub-threshold set of primary shares\n> that decodes to arbitrarily selected alternative data-- but it seems\n> the proposal makes no use of this fact.\n>\n>>>It\n>>> is again, unversioned-- so it kinda of seems like it is intentionally\n>>> constructed in a way that will prevent interoperable use, since the\n>>> lack of versioning was a primary complaint from other perspective\n>>> users.  Of course, it fine if you want to make a trezor only thing,\n>>> but why bother BIPing something that was not intended for\n>>> interoperability?  Even for a single vendor spec the lack of\n>>> versioning seems to make things harder to support new key-related\n>>> features such as segwit.\n>>>This is argument I keep having all the time.\n>>Suppose we'd introduce a version to encode PBKDF2 rounds or even\n>> different KDFs. We'll end up with different SLIP39 mnemonics, but they\n>> will not be compatible among implementations (because TREZOR can only up\n>> to 100.000 rounds of PBKDF2 and does not support Argon2 at all, while\n>> other desktop implementation would rather use memory-hard Argon2).\n>>My gut feeling is that this would lead to WORSE interoperability, not\n>> better. Look at BIP32 for example. There are lots of wallet that claim\n>> they are BIP32 compatible, but in reality they use different paths, so\n>> they are not compatible. BIP32 is a good standard, but in reality\n>> \"BIP32-compatible\" does not mean anything, whereas when you say the\n>> wallet is \"BIP44-compatible\" you can be sure the migration path works.\n>>\n> The end result is no better-- I think.  If you compromise\n> functionality or security (e.g. pretextual KDF) because your product\n> doesn't yet support -- say, aggregate signatures-- or won't ever\n> support a strong KDF; then other software will just not be\n> interoperable.  In cases were you won't ever support it, that doesn't\n> matter-- but presumably you would later support new signature styles\n> and the loss of interoperability would potentially be gratitious.\n>\n> That said, I'm generally skeptical of key interoperability to begin\n> with. Wallets can't share keys unless their functionality is\n> identical, half-interoperability can lead to funds loss. Identical\n> functionality would mean constraining to the least common denominator.\n>\n> But even if we exclude cross vendor interoperability entirely,\n> wouldn't you want your next version of your firmware to be able to\n> support new and old key styles (e.g. aggregate signatures vs plain\n> segwit) without having to define a whole new encoding?\n>\n>>Originally, we wanted to use 16-bit of CRC32 for checksum, but after the\n>> discussion with Daan Sprenkels we were suggested to change this for\n>> cryptographically strong function. The argument was that CRC32 contains\n>> less entropy and mixing high-entropy data (secret) with low-entropy data\n>> (checksum) is not a good idea.\n>>\n> That sounds like a kind of hand-wave and cargo cult argument-- pleas\n> be more specific, because that just sounds like amateur block cipher\n> design.\n>\n> There isn't any difference in \"entropy\" in either of these cases.\n>\n> As an aside, using \"n bits of a longer CRC\" usually results in a low\n> quality code for error detection similar to using a cryptographic\n> hash.\n>\n>>Also, there is an argument between a checksum and ECC. We discussed that\n>> ECC might not be a good idea, because it helps the attacker to compute\n>> missing information, while we only want to check for integrity. Also the\n>>\n> Not meaningfully more than the truncated cryptographic hash.\n>\n> The best possible code of that length would allow you to list decode\n> to around two errors with a lot of computation.\n> With the cryptographic hash the attacker need only check the 2^28\n> two-error candidates to do exactly the same thing.\n>\n> So the attacker there is no real difference-- he can brute force\n> search to the same radius as correction would allow, but for the\n> honest users and software the probability of undetected error is\n> greater.  Similarly, while 2^28 operations is nothing to an attacker,\n> if user software wants to use the correction for error hinting,\n> running a hash 2^28 times would lead to a somewhat unfriendly user\n> experience so non-attack tools would be pretty unlikely to implement\n> it.\n>\n>bitcoin-dev mailing list\n>bitcoin-dev at lists.linuxfoundation.org\n>https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Peter Todd",
                "date": "2018-01-09T01:13:35",
                "message_text_only": "On Mon, Jan 08, 2018 at 07:40:38PM -0500, Rhavar via bitcoin-dev wrote:\n> I think you're under-appreciating how useful the \"plausible deniability\". Someone I know was (solo) traveling to the United States when a border agent asked her to unlocked her phone; thumbed through her apps, ended up finding tinder and went through all her recent conversations to make sure she wasn't involved in any \"pay for sex things\".\n> \n> In the same light, I travel frequently and constantly have my trezor on me. If I am asked to unlock it, I will have no problems doing so (as refusal will no doubt lead to deportation) and showing my personal wallet (which sadly hasn't had much use since fees became ridiculous).\n\nTrezor's \"plausible deniability\" scheme could very well result in you going to\njail for lying to border security, because it's so easy for them to simply\nbrute force alternate passwords based on your seeds. With that, they have proof\nthat you lied to customs, a serious offense.\n\nI would strongly advise you not to use it in that situation.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180108/8bcd1aad/attachment.sig>"
            },
            {
                "author": "jens",
                "date": "2018-01-09T12:44:56",
                "message_text_only": "> Trezor's \"plausible deniability\" scheme could very well result in you going to\n> jail for lying to border security, because it's so easy for them to simply\n> brute force alternate passwords based on your seeds. With that, they have proof\n> that you lied to customs, a serious offense.\nThe passphrase scheme as I understand it allows a maximum of 50 \ncharacters to be used.\u00a0 Surely even with the HD seed, that search space \nis too large to brute force.\u00a0 Or is there a weakness in the scheme I \nhaven't clocked?\n\nOn 09/01/18 01:13, Peter Todd via bitcoin-dev wrote:\n> On Mon, Jan 08, 2018 at 07:40:38PM -0500, Rhavar via bitcoin-dev wrote:\n>> I think you're under-appreciating how useful the \"plausible deniability\". Someone I know was (solo) traveling to the United States when a border agent asked her to unlocked her phone; thumbed through her apps, ended up finding tinder and went through all her recent conversations to make sure she wasn't involved in any \"pay for sex things\".\n>>\n>> In the same light, I travel frequently and constantly have my trezor on me. If I am asked to unlock it, I will have no problems doing so (as refusal will no doubt lead to deportation) and showing my personal wallet (which sadly hasn't had much use since fees became ridiculous).\n> Trezor's \"plausible deniability\" scheme could very well result in you going to\n> jail for lying to border security, because it's so easy for them to simply\n> brute force alternate passwords based on your seeds. With that, they have proof\n> that you lied to customs, a serious offense.\n>\n> I would strongly advise you not to use it in that situation.\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180109/10f78fce/attachment-0001.html>"
            },
            {
                "author": "Pavol Rusnak",
                "date": "2018-01-09T15:12:58",
                "message_text_only": "On 09/01/18 00:47, Gregory Maxwell wrote:\n> Have you considered using blind host-delegated KDFs, where the KDF\n> runs on the user's computer instead of the hardware wallet, but the\n> computer doesn't learn anything about they keys?\n\nAny examples of these?\n\n\n-- \nBest Regards / S pozdravom,\n\nPavol \"stick\" Rusnak\nCTO, SatoshiLabs"
            },
            {
                "author": "Pavol Rusnak",
                "date": "2018-01-10T20:28:10",
                "message_text_only": "On 09/01/18 16:12, Pavol Rusnak via bitcoin-dev wrote:\n> On 09/01/18 00:47, Gregory Maxwell wrote:\n>> Have you considered using blind host-delegated KDFs, where the KDF\n>> runs on the user's computer instead of the hardware wallet, but the\n>> computer doesn't learn anything about they keys?\n> \n> Any examples of these?\n\nActually, scratch that. HW wallet would not know whether the host\ncomputer is lying or not. The computer would not learn about the keys,\nbut still could be malicious and provide invalid result. Is that correct?\n\n-- \nBest Regards / S pozdravom,\n\nPavol \"stick\" Rusnak\nCTO, SatoshiLabs"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-10T23:47:23",
                "message_text_only": "On Wed, Jan 10, 2018 at 8:28 PM, Pavol Rusnak <stick at satoshilabs.com> wrote:\n> On 09/01/18 16:12, Pavol Rusnak via bitcoin-dev wrote:\n>> On 09/01/18 00:47, Gregory Maxwell wrote:\n>>> Have you considered using blind host-delegated KDFs, where the KDF\n>>> runs on the user's computer instead of the hardware wallet, but the\n>>> computer doesn't learn anything about they keys?\n>>\n>> Any examples of these?\n\nYes, this scheme.\nhttps://bitcointalk.org/index.php?topic=311000.msg3342217#msg3342217\n\n> Actually, scratch that. HW wallet would not know whether the host\n> computer is lying or not. The computer would not learn about the keys,\n> but still could be malicious and provide invalid result. Is that correct?\n\n\nI believe that can be avoided by having the computer do somewhat more\nwork and checking the consistency after the fact.\n\n(or for decode time, having a check value under the encryption...)"
            },
            {
                "author": "Pavol Rusnak",
                "date": "2018-01-11T09:55:08",
                "message_text_only": "On 11/01/18 00:47, Gregory Maxwell wrote:\n> I believe that can be avoided by having the computer do somewhat more\n> work and checking the consistency after the fact.\n>\n> (or for decode time, having a check value under the encryption...)\n\nCan you describe these two methods more in detail? How exactly would\nthey work? What crypto primitives would you use and how?\n\n\n-- \nBest Regards / S pozdravom,\n\nPavol \"stick\" Rusnak\nCTO, SatoshiLabs"
            },
            {
                "author": "Russell O'Connor",
                "date": "2018-01-09T16:20:20",
                "message_text_only": "On Mon, Jan 8, 2018 at 7:39 AM, Pavol Rusnak via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On 08/01/18 05:22, Gregory Maxwell wrote:\n> >> https://github.com/satoshilabs/slips/blob/master/slip-0039.md\n>\n>\n> > The 16-bit \"checksum\" based on sha2 seems pretty poor since basing\n> > small checksums on a cryptographic hash results in a fairly poor\n> > checksum that is surprisingly likely to accept an errored string. Your\n> > wordlist is 10 bits and you have much less than 1023*10 bits of input,\n> > so you could easily have a 20 bit code (two words) which guaranteed\n> > that up to two errored words would always be detected, and probably\n> > could choose one which catches three words much more often 1:2^20\n> > (sipa's crc tools can help find codes like this).\n>\n> Originally, we wanted to use 16-bit of CRC32 for checksum, but after the\n> discussion with Daan Sprenkels we were suggested to change this for\n> cryptographically strong function. The argument was that CRC32 contains\n> less entropy and mixing high-entropy data (secret) with low-entropy data\n> (checksum) is not a good idea.\n>\n\nThis entropy argument seems confused.  Ignoring constant factors, the\nentropy of a checksum is the sum over all possible checksums, i, of\n-n_i*log(n_i), where n_i is the number of times the ith checksum occurs\nover the space of all possible data being checksummed.  In this application\nthe checksum is being applied to a fixed m-bit blob of uniformly random\ndata.\n\nThe entropy is maximized when every possible checksum occurs equally as\nfrequently, that is we achieve maximum entropy when all the n_i values are\nequal to each other.  Any error correcting code worth it's salt will try to\nachieve this property because the designers want every checksum value to\nhave as much error correcting power as every other checksum value.  I'm\nalmost certain that the algebraic properties of your typical error\ncorrecting codes allow you to prove that maximum entropy is perfectly\nachieved whenever the data-blob size is at least as large as the checksum\nsize.\n\nMeanwhile the truncated value of a cryptographic hash function is expected\nto be slightly under the maximum entropy value, under the assumption that\nthe hash function it behaves like a random function.\n\nThe main properties of a \"strong cryptographic hash function\" is that it is\ninfeasible to find collisions and preimages.  However these properties are\nlost when you truncate the hash down to 16-bits.  At this point is it\nentirely feasible to find collisions and preimages.\n\nSo using a truncated cryptographic hash function doesn't provide you with\nmore entropy (and, in fact, probably a sliver less entropy), and doesn't\nprovide you with any of the befits of strong cryptographic hash function.\n\n\n> Also, there is an argument between a checksum and ECC. We discussed that\n> ECC might not be a good idea, because it helps the attacker to compute\n> missing information, while we only want to check for integrity. Also the\n> word mnemonic is itself a ECC, because if you see the word \"acadornic\"\n> it is probably the word \"academic\".\n>\n\nEvery checksum is error correcting.  Given an failed checksum, all you have\nto do is search around the space of edits to find the smallest set edits\nthat yield a valid checksum.  With a 2^16 bit checksum one will expect to\nfind a nearby checksum within 2^16 trails, even when using a truncated hash\nfunction.\n\nWhat an error-correcting codes gives you isn't the ability to correct\nerrors, which we have seen is something that all short checksums provide,\nrather they provide *guarantees* about the ability to detect (and correct)\ncertain common classes of errors.  For example we can have an ECC that\nguarantees to find the error where are word is accidentally written down\ntwice (see\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-January/015506.html\n).\n\nThe advice you have been given will only result in losing any guarantees\nabout detecting common classes or errors; it won't stop attackers from\nrecovering missing information, and it won't provide a cryptographically\nstrong function.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180109/5f03431f/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2018-01-12T09:50:58",
                "message_text_only": "On Tue, Jan 09, 2018 at 12:43:48PM +0000, Perry Gibson wrote:\n> >Trezor's \"plausible deniability\" scheme could very well result in you going to\n> >jail for lying to border security, because it's so easy for them to simply\n> >brute force alternate passwords based on your seeds. With that, they have proof\n> >that you lied to customs, a serious offense.\n> The passphrase scheme as I understand it allows a maximum of 50 characters\n> to be used.\u00a0 Surely even with the HD seed, that search space is too large to\n> brute force.\u00a0 Or is there a weakness in the scheme I haven't clocked?\n\nWhile passphrases *can* be long, most user's aren't going to understand the\nrisk. For example, Trezors blog(1) doesn't make it clear that the passphrases\ncould be bruteforced and used as evidence against you, and even suggests the\ncontrary:\n\n    Since the passphrase is never saved on the device, this means that there is no\n    wrong passphrase. The device does not know which one you have chosen, and\n    therefore all of them are correct! Given the same seed, for each and every\n    letter combination used as a passphrase, a different wallet will be generated.\n\nand:\n\n    Since there is no way to prove that there is any wallet beyond the ones\n    that you have admitted to, the \u201cattacker\u201d will have to be satisfied with\n    the revealed ones.\n\n\nAlso note how this blog doesn't mention anti-forensics: the wallet software\nitself may leave traces of the other wallets on the computer. Have they really\naudited it sufficiently to be sure this isn't the case?\n\n1) https://blog.trezor.io/hide-your-trezor-wallets-with-multiple-passphrases-f2e0834026eb\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180112/a6ee71b2/attachment.sig>"
            },
            {
                "author": "Ond\u0159ej Vejpustek",
                "date": "2018-01-17T11:39:42",
                "message_text_only": "The entropy argument is as follows:\n\nThere is a rule of thumb which says it is safer plaintext to have low\nredundancy, see\nhttps://en.wikipedia.org/wiki/Redundancy_(information_theory), i. e.\nit's better to encrypt random or compressed data than natural language.\nThis rule is based on Shannon's information theory which means that a\nbreach of the rule usually doesn't induce a vulnerability (there is no\nknown generic attack). This rule is application of a precautionary\nprinciple.\n\nNevertheless, here are some examples of cryptographic attacks which may\nbe considered as a consequence of the breach of the rule:\n  * Related Message Attack by Coppersmith, Franklin, Patarin, Reiter\n(https://pdfs.semanticscholar.org/899a/4fdc048102471875e24f7fecb3fb8998d754.pdf)\n- given RSA ciphertext of two plaintexts x and a*x + b, where a, b are\nknown, it's possible to effectively compute x provided public exponent\nis three. From the informaton-theoretic point of view the second message\nis redundant, because it's determined by the first one. Which means that\nrelative redundancy of both messages is at least one half.\n  * Stereotyped Messages by Coppersmith\n(https://www.di.ens.fr/~fouque/ens-rennes/coppersmith.pdf, section 7) -\ngiven RSA ciphertext and (1-1/e) fraction of plaintext (where e is\npublic exponent), it's possible to effectively compute x. Message is\nhighly redundant, because only 1/e of the message is unknown. Relative\nredundancy of the message is at least (1-1/e).\n\nConsider a few notes:\n  * Nowadays there exists more complicated variants of mentioned attacks\nwhich have weaker premisses.\n  * There is a considerable similarity between RSA and SSS. Both schemes\nare algebraically-based (rather than boolean function based).\n  * CRCs (and error-correcting codes generally) introduce redundancy\ninto the message. Moreover the redundancy is induced by a linear\nrelationship among message (compare with the premise of the Related\nMessage Attack).\n  * Related Message Attack wouldn't be possible if you had two\nplaintexts x and hash(x). The relationship between messages has to be\n(algebraically) uncomplicated. From the information-theoretic point of\nview the situation is the same, but from the practical point of view it\nis completely different.\n\nTo sum it up, there is a precautionary principle which tells us not to\nincrease redundancy of a message unless it is introduced in a\ncomplicated way (for example by a hash function). That's why we use SHA\nrather than CRC. One more reason why we stick to the principle is that\nthere's no randomisation in our scheme (such as padding or\ninitialisation vector). We understood advantages of error-correctings\ncodes over hash functions (minimal codewords distance property,\nperformance) and we considered it thoroughly.\n\nOnd\u0159ej Vejpustek"
            },
            {
                "author": "Russell O'Connor",
                "date": "2018-01-17T15:28:15",
                "message_text_only": "Hi Ond\u0159ej,\n\n1. There is no similarity between SSS and RSA or any other public-key or\nsymmetric crypto.  SSS is effectively a one-time pad and is\ninformation-theoretically secure.\n\n2. Even if there were a problem (which there cannot be, due to (1)), using\nerror correcting codes and truncated hash functions create identical\namounts of information theoretic redundancy.\n\nLet me repeat that SSS is \"information-theoretically secure\"!  It isn't\nonly computationally infeasible to break SSS; it is impossible to break\nSSS.  If you have all but one necessary share of SSS, there is no\ninformation leaked about the the hidden data, because for every possible\nmessage that could be encoded, there exists some final share that would\ndecode to that message.  Any of the possibilities for the missing final\nshare are equally as likely.\n\nIt is of no use to apply the precautionary principle against impossible\nattacks, especially at the cost of losing the useful properties of a real\nerror correcting codes that would provide actual guarantees against likely\nerrors.\n\nOn Wed, Jan 17, 2018 at 6:39 AM, Ond\u0159ej Vejpustek via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> The entropy argument is as follows:\n>\n> There is a rule of thumb which says it is safer plaintext to have low\n> redundancy, see\n> https://en.wikipedia.org/wiki/Redundancy_(information_theory), i. e.\n> it's better to encrypt random or compressed data than natural language.\n> This rule is based on Shannon's information theory which means that a\n> breach of the rule usually doesn't induce a vulnerability (there is no\n> known generic attack). This rule is application of a precautionary\n> principle.\n>\n> Nevertheless, here are some examples of cryptographic attacks which may\n> be considered as a consequence of the breach of the rule:\n>   * Related Message Attack by Coppersmith, Franklin, Patarin, Reiter\n> (https://pdfs.semanticscholar.org/899a/4fdc048102471875e24f7fecb3fb89\n> 98d754.pdf)\n> - given RSA ciphertext of two plaintexts x and a*x + b, where a, b are\n> known, it's possible to effectively compute x provided public exponent\n> is three. From the informaton-theoretic point of view the second message\n> is redundant, because it's determined by the first one. Which means that\n> relative redundancy of both messages is at least one half.\n>   * Stereotyped Messages by Coppersmith\n> (https://www.di.ens.fr/~fouque/ens-rennes/coppersmith.pdf, section 7) -\n> given RSA ciphertext and (1-1/e) fraction of plaintext (where e is\n> public exponent), it's possible to effectively compute x. Message is\n> highly redundant, because only 1/e of the message is unknown. Relative\n> redundancy of the message is at least (1-1/e).\n>\n> Consider a few notes:\n>   * Nowadays there exists more complicated variants of mentioned attacks\n> which have weaker premisses.\n>   * There is a considerable similarity between RSA and SSS. Both schemes\n> are algebraically-based (rather than boolean function based).\n>   * CRCs (and error-correcting codes generally) introduce redundancy\n> into the message. Moreover the redundancy is induced by a linear\n> relationship among message (compare with the premise of the Related\n> Message Attack).\n>   * Related Message Attack wouldn't be possible if you had two\n> plaintexts x and hash(x). The relationship between messages has to be\n> (algebraically) uncomplicated. From the information-theoretic point of\n> view the situation is the same, but from the practical point of view it\n> is completely different.\n>\n> To sum it up, there is a precautionary principle which tells us not to\n> increase redundancy of a message unless it is introduced in a\n> complicated way (for example by a hash function). That's why we use SHA\n> rather than CRC. One more reason why we stick to the principle is that\n> there's no randomisation in our scheme (such as padding or\n> initialisation vector). We understood advantages of error-correctings\n> codes over hash functions (minimal codewords distance property,\n> performance) and we considered it thoroughly.\n>\n> Ond\u0159ej Vejpustek\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180117/4ce36a81/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-17T15:36:25",
                "message_text_only": "On Wed, Jan 17, 2018 at 3:28 PM, Russell O'Connor via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> it is impossible to break SSS.\n\nObligatory repeated point: if the scheme being used actually is SSS\nand not a Shamir-Shaped-Sharing instead. This should go without\nmention by my experience is that a great many things which claim to be\nSSS aren't. Sometimes precisely because they stuck in some hashes in\narbitrary places and destroyed the properties (in fact, the really old\nbroken armory implementation effectively did that, and in fact\nresulted in a real weakness not just a theoretical one)."
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-17T15:31:44",
                "message_text_only": "On Wed, Jan 17, 2018 at 11:39 AM, Ond\u0159ej Vejpustek via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Consider a few notes:\n>   * Nowadays there exists more complicated variants of mentioned attacks\n> which have weaker premisses.\n>   * There is a considerable similarity between RSA and SSS. Both schemes\n> are algebraically-based (rather than boolean function based).\n\nI'm sorry but I must not be following your message. I read the above\nas \"these are similar because they are based on math\"...\n\nShamir secret sharing, correctly implemented (which indeed seems to be\nmany parties problem...) achieves information theoretic security. In\nthis critical sense it is utterly unrelated to RSA.\n\nIn fact this applies generally given any fixed threashold-1 set of\nshares there is an value of the final remaining share which decodes to\nevery possible message. So without knowing of an extra share you know\nnothing of the message.\n\nThe simplest demonstration is the 2 of 2 case, which can most simply\nbe constructed over GF(2) as in the traditional \"one time pad\":\nmessage = share1 xor share2.  For any given share1 or given share2\nthere exist a value of share2 or share1 respectively which yields\nevery possible message.\n\nIf the generalization isn't obvious, it might be helpful to make a\nlittle test utility that tries all possible one byte messages with all\npossible share values using the GF(256) sharing scheme proposed in the\ndraft-- in this case information theory is why we can know SSS (and\nsimilar) have (within their limited scope) _perfect_ security, rather\nthan it being a reason to speculate that they might not turn out to be\nsecure at all. (or, instead of a test utility just work through some\nexamples on paper in a small field).\n\nThis doesn't change when you add additional conditionals on it-- e.g.\nSay you a 2-of-3 sharing where you have your choice of any of the\nthree shares but do not know the others and assume you know every bit\nof the plaintext save one bit or any linear or non-linear relationship\nbetween plaintext bits (excepting for actually knowing the secret)...\n\nIn these case there can still be no attack arising out of this\ncharitably bad plaintext structure because-- as pointed out above--\nall possible plaintexts are equal-probable you know nothing of which\nof the two possible solutions is correct without knowing about the\nother shares because for each possible value there exists a value for\nthe unknown shares which would cause that decoding-- there is no\nleakage at all, the share doesn't teach you anything you didn't\nalready know.\n\nIn my view any SSS tool should also include a forgery utility which\ndemonstrates this property, both as a critical test-- but also because\nbeing able to forge an alternative answer to deceive an attacker which\nhas compromised some of your shares is one of the (at least\ntheoretical) arguments for using SSS over computational secret\nsharing.\n\n> unless it is introduced in a complicated way\n\nComplicated does not mean secure. And from an information theoretic\nperspective the hash does almost nothing (other then some small\ndestruction of entropy due to its lack of perfect uniformity which is\ninformation theoretically equivalent to using a smaller perfect code).\nThere are many cases where I too am more comfortable using a hash --\nwhere it may destroy some structure which I cannot _prove_ would be\nsafe to retain, but this is not one of those cases.\n\n>   * CRCs (and error-correcting codes generally) introduce redundancy\ninto the message\n\nThe discussion of using a proper code was primarily related to the\nouter check value which protects the shares themselves and is sitting\nunprotected in plaintext; not so much the one inside the sharing in\nany case; since its the outer one which could be structured to provide\nperfect detection of errors that align with words (e.g. transposing\ntwo words)."
            },
            {
                "author": "Matt Corallo",
                "date": "2018-01-18T05:00:28",
                "message_text_only": "Or make it a part of your secret-split logic... Gotta love how fast GF(2^8) is:\nhttps://github.com/TheBlueMatt/shamirs/blob/master/main.c#L57\n\nOn January 17, 2018 3:31:44 PM UTC, Gregory Maxwell via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>If the generalization isn't obvious, it might be helpful to make a\n>little test utility that tries all possible one byte messages with all\n>possible share values using the GF(256) sharing scheme proposed in the\n>draft-- in this case information theory is why we can know SSS (and\n>similar) have (within their limited scope) _perfect_ security, rather\n>than it being a reason to speculate that they might not turn out to be\n>secure at all. (or, instead of a test utility just work through some\n>examples on paper in a small field).\n>"
            },
            {
                "author": "Ond\u0159ej Vejpustek",
                "date": "2018-01-18T13:50:41",
                "message_text_only": "Thank you for your comments, Gregory and Russell!\n\nGregory, thank you for you explanation of perfect secrecy, there is no\nneed for that, however. I'm professional mathematician and cryptographer.\n\n> I read the above\n> as \"these are similar because they are based on math\"...\nThey are based on algebra (group and commutative ring theory), which is\na great similarity. RSA and SHA, for example, are based on completely\ndistinct parts of mathematics.\n\n> Complicated does not mean secure. And from an information theoretic\n> perspective the hash does almost nothing (other then some small\n> destruction of entropy due to its lack of perfect uniformity which is\n> information theoretically equivalent to using a smaller perfect code).\n> using error correcting codes and truncated hash functions create\nidentical amounts of information theoretic redundancy\nI agree, see my last note in the previous mail. Adding redundancy by a\nhash function is more secure than adding redundancy by a linear\nrelations. Just my opinion.\n\nI see the difference between RSA and SSS you mentioned and I understand\nyour arguments about perfect secrecy. Just two comments:\n  (1) Our proposal doesn't use SSS for the whole secret, but it divides\nthe secret into bytes and uses SSS for every byte separately. This\nscheme is weaker because to reconstruct n-th byte it suffices to have\nn-th bytes from k shares.\n  (2) SSS is information-theoretic secure if you know k-1 or less\nshares, where k is the threshold. But the proof doesn't hold if you know\nfor example a small part of every share.\n\n> It is of no use to apply the precautionary principle against\nimpossible attacks, especially at the cost of losing the useful\nproperties of a real error correcting codes that would provide actual\nguarantees against likely errors.\nThe discussion isn't about mathematics or about security proofs but\nabout cryptographic scheme design. In our use case you cannot assume\nthat all premises of security proof theorems (including SSS's perfect\nsecrecy) hold true (see the comment above).\n\nIn my opinion, to make a cryptographic scheme more robust it's better to\nstick to general \"intuitive\" principles. Of course you have to consider\nthe advantages and disadvantages of this approach. That's why we\ndisclosed our draft and welcome all comments.\n\n> The discussion of using a proper code was primarily related to the\n> outer check value which protects the shares themselves and is sitting\n> unprotected in plaintext\nOK then. I was defending the hash in the inner check value."
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-18T14:34:24",
                "message_text_only": "On Thu, Jan 18, 2018 at 1:50 PM, Ond\u0159ej Vejpustek\n<ondrej.vejpustek at satoshilabs.com> wrote:\n>   (1) Our proposal doesn't use SSS for the whole secret, but it divides\n> the secret into bytes and uses SSS for every byte separately. This\n> scheme is weaker because to reconstruct n-th byte it suffices to have\n> n-th bytes from k shares.\n\nIf being secure against partial share leakage is really part of your\nthreat model the current proposal is gratuitously insecure against it.\nAnd the choice of check algorithm really doesn't matter for that.\n\nFor example,  in a 2-of-3 share  say I have the first half of shares\n1,2 and the second half of shares 2,3  with the current proposal the\nsecret is directly revealed, even though I didn't have any single\ncomplete share.\n\nIf partial share disclosure were an actual concern, I would recommend\nthat after sharing and before encoding for transmission (e.g. before\napplying check values and word encoding to the share) the individual\nshares be passed through a large block unkeyed cryptographic\npermutation.  Under reasonable-ish assumptions about the difficulty of\ninverting the permutation with partial knowledge, this transformation\nwould prevent attacks from leaks of partial share information."
            },
            {
                "author": "Ond\u0159ej Vejpustek",
                "date": "2018-01-18T16:59:09",
                "message_text_only": "> If being secure against partial share leakage is really part of your\n> threat model the current proposal is gratuitously insecure against it.\n\nI don't think that is true. Shared secret is an input of KDF which\nshould prevent this kind of attack.\n\n> If partial share disclosure were an actual concern, I would recommend\n> that after sharing and before encoding for transmission (e.g. before\n> applying check values and word encoding to the share) the individual\n> shares be passed through a large block unkeyed cryptographic\n> permutation.  Under reasonable-ish assumptions about the difficulty of\n> inverting the permutation with partial knowledge, this transformation\n> would prevent attacks from leaks of partial share information.\n\nActually, we've been considering something like that. We concluded that\nit is to much \"rolling your own crypto\". Instead of diffusion layer we\ndecided to apply KDF on the shared secret."
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-18T18:58:14",
                "message_text_only": "On Thu, Jan 18, 2018 at 4:59 PM, Ond\u0159ej Vejpustek\n<ondrej.vejpustek at satoshilabs.com> wrote:\n>> If being secure against partial share leakage is really part of your\n>> threat model the current proposal is gratuitously insecure against it.\n>\n> I don't think that is true. Shared secret is an input of KDF which\n> should prevent this kind of attack.\n\nMy post provided a concrete example. I'd be happy to answer any\nquestions about it, but otherwise I'm not sure how to make it more\nclear.\n\n> Actually, we've been considering something like that. We concluded that it is to much \"rolling your own crypto\". Instead of diffusion layer we decided to apply KDF on the shared secret.\n\n\nQuite the opposite-- a large block cipher is a standard\nconstruction... and the off-label application of a KDF that you've\nused here doesn't provide any protection against the example I gave."
            },
            {
                "author": "Ond\u0159ej Vejpustek",
                "date": "2018-01-22T15:00:25",
                "message_text_only": "> \n> My post provided a concrete example. I'd be happy to answer any\n> questions about it, but otherwise I'm not sure how to make it more\n> clear.\n\nMy apologies, I didn't read it carefully. You are absolutely right. Our\nscheme doesn't protect against the scenario.\n\n> Quite the opposite-- a large block cipher is a standard\n> construction\n\nI'm happy to hear it. Nevertheless, I didn't find any standartisation or\nimplementation of the CMC mode (excluding the paper).\n\nDo you have some experience with other modes (such as HCTR, HEH)?"
            },
            {
                "author": "Russell O'Connor",
                "date": "2018-01-22T19:21:14",
                "message_text_only": "On Thu, Jan 18, 2018 at 1:58 PM, Gregory Maxwell via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Thu, Jan 18, 2018 at 4:59 PM, Ond\u0159ej Vejpustek\n> <ondrej.vejpustek at satoshilabs.com> wrote:\n> >> If being secure against partial share leakage is really part of your\n> >> threat model the current proposal is gratuitously insecure against it.\n> >\n> > I don't think that is true. Shared secret is an input of KDF which\n> > should prevent this kind of attack.\n>\n> My post provided a concrete example. I'd be happy to answer any\n> questions about it, but otherwise I'm not sure how to make it more\n> clear.\n>\n> > Actually, we've been considering something like that. We concluded that\n> it is to much \"rolling your own crypto\". Instead of diffusion layer we\n> decided to apply KDF on the shared secret.\n>\n>\n> Quite the opposite-- a large block cipher is a standard\n> construction... and the off-label application of a KDF that you've\n> used here doesn't provide any protection against the example I gave.\n>\n\nAt this point, is it better just to use GF(2^256+n)?  Is GF(2^256+n) going\nto be that much slower than GF(2^8) that we care to make things this\ncomplicated?  (I honestly don't know the answer.)\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180122/c8799a13/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-23T01:05:44",
                "message_text_only": "On Mon, Jan 22, 2018 at 7:21 PM, Russell O'Connor\n<roconnor at blockstream.io> wrote:\n> At this point, is it better just to use GF(2^256+n)?  Is GF(2^256+n) going\n> to be that much slower than GF(2^8) that we care to make things this\n> complicated?  (I honestly don't know the answer.)\n\nI expect it would be especially since operations must be implemented\nin sidechannel resistant manners.\n\nAlso, binary extension fields are doing to have linear subgroup\nproperties where leaking part of elements wouldn't be good. Not as\nobviously broken as the example I gave above, but still in the domain\nof \"get chunks of a lot of a supra threshold set of shares, and setup\na latices basis problem that can provide an efficient subspace to\nsearch\"."
            },
            {
                "author": "Ond\u0159ej Vejpustek",
                "date": "2018-01-23T13:54:48",
                "message_text_only": "> Yes, this scheme.\n> https://bitcointalk.org/index.php?topic=311000.msg3342217#msg3342217\n\nIn addition to the scheme, I found out, that Makwa\n(https://www.bolet.org/makwa/), a hashing function which received a\nspecial recognition in the Password Hashing Competition, supports a\ndelegation. In fact, Makwa is similar to the suggested scheme.\n\nUnfortunately, both schemes have two drawbacks:\n  (1) There is no proof that the host computes what he's suppose to do.\n  (2) The delegation is far more slower than the normal computation.\nAccording to the Makwa paper\n(https://www.bolet.org/makwa/makwa-spec-20150422.pdf) the delegation is\ntypically 100 to 1000 slower. So I see little advantage in delegating.\n\nI doubt there is a scheme that suits our needs."
            },
            {
                "author": "Adam Back",
                "date": "2018-01-23T14:16:22",
                "message_text_only": "Makwa sites [1] https://bitcointalk.org/index.php?topic=311000.0\n\nSeems like they independently rediscovered it.\n\nAdam\n\n\nOn 23 January 2018 at 05:54, Ond\u0159ej Vejpustek via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> Yes, this scheme.\n>> https://bitcointalk.org/index.php?topic=311000.msg3342217#msg3342217\n>\n> In addition to the scheme, I found out, that Makwa\n> (https://www.bolet.org/makwa/), a hashing function which received a\n> special recognition in the Password Hashing Competition, supports a\n> delegation. In fact, Makwa is similar to the suggested scheme.\n>\n> Unfortunately, both schemes have two drawbacks:\n>   (1) There is no proof that the host computes what he's suppose to do.\n>   (2) The delegation is far more slower than the normal computation.\n> According to the Makwa paper\n> (https://www.bolet.org/makwa/makwa-spec-20150422.pdf) the delegation is\n> typically 100 to 1000 slower. So I see little advantage in delegating.\n>\n> I doubt there is a scheme that suits our needs.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            }
        ],
        "thread_summary": {
            "title": "Satoshilabs secret shared private key scheme",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "jens",
                "Adam Back",
                "Pavol Rusnak",
                "Ben Kloester",
                "Peter Todd",
                "Russell O'Connor",
                "Ond\u0159ej Vejpustek",
                "Gregory Maxwell",
                "Matt Corallo",
                "nullius",
                "Rhavar"
            ],
            "messages_count": 32,
            "total_messages_chars_count": 69143
        }
    },
    {
        "title": "[bitcoin-dev] Suggestion to remove word from BIP39 English wordlist",
        "thread_messages": [
            {
                "author": "Ronald van der Meer",
                "date": "2018-01-09T11:20:55",
                "message_text_only": "Hello guys,\n\nAfter reviewing some bitcoin improvement proposals, I noticed that one of the words that can be found on the BIP39 English wordlist is \u201csatoshi\u201d. \nI suggest removing this word from the list so it\u2019s less obvious that it\u2019s a bitcoin seed when found by a malicious third party.\n\nRegards, \nRonald van der Meer\n \nE: ronald at vandermeer.frl | W: https://www.vandermeer.frl\nS: https://twitter.com/truly_secure\n \nGPG: 8203 CE3E 064D C462 1D22 F635 A1EC 45F9 645F 878D"
            },
            {
                "author": "Weiwu Zhang",
                "date": "2018-01-18T01:07:53",
                "message_text_only": "2018-01-09 19:20 GMT+08:00 Ronald van der Meer via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org>:\n> After reviewing some bitcoin improvement proposals, I noticed that one of the words that can be found on the BIP39 English wordlist is \u201csatoshi\u201d.\n> I suggest removing this word from the list so it\u2019s less obvious that it\u2019s a bitcoin seed when found by a malicious third party.\n\nIf a malicious third party discovers a word list that look like a\nseed, they would try using it as Bitcoin seed first anyway, with or\nwithout finding the word 'satoshi' in it. The security threat is that\na malicious third party may index what they found and test every\noccurrence of 'satoshi' for a lead to a seed.\n\nFor example, a hard-disk recycling service would add this word to\ntheir salvage tools. Any successfully hacked gmail account will be\n'satoshi' tested too.\n\nSo I see this as a reasonable improvement:)"
            },
            {
                "author": "CryptAxe",
                "date": "2018-01-18T01:14:51",
                "message_text_only": "Why wouldn't they just test the frequency of words from the wordlist in\nentirety?\n\nOn Jan 17, 2018 5:10 PM, \"Weiwu Zhang via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> 2018-01-09 19:20 GMT+08:00 Ronald van der Meer via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org>:\n> > After reviewing some bitcoin improvement proposals, I noticed that one\n> of the words that can be found on the BIP39 English wordlist is \u201csatoshi\u201d.\n> > I suggest removing this word from the list so it\u2019s less obvious that\n> it\u2019s a bitcoin seed when found by a malicious third party.\n>\n> If a malicious third party discovers a word list that look like a\n> seed, they would try using it as Bitcoin seed first anyway, with or\n> without finding the word 'satoshi' in it. The security threat is that\n> a malicious third party may index what they found and test every\n> occurrence of 'satoshi' for a lead to a seed.\n>\n> For example, a hard-disk recycling service would add this word to\n> their salvage tools. Any successfully hacked gmail account will be\n> 'satoshi' tested too.\n>\n> So I see this as a reasonable improvement:)\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180117/ae8bb6fa/attachment.html>"
            },
            {
                "author": "Jonathan Sterling",
                "date": "2018-01-18T06:55:28",
                "message_text_only": "All the more reason to only use the most common words that meet the other\ncriteria:\nhttps://github.com/bitcoin/bips/blob/master/bip-0039.mediawiki#Wordlist\n\nI agree - keeping \"satoshi\" in there is an unnecessary security risk.\n\nKind Regards,\n\nJonathan Sterling\n\nOn Thu, Jan 18, 2018 at 8:14 AM, CryptAxe via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Why wouldn't they just test the frequency of words from the wordlist in\n> entirety?\n>\n> On Jan 17, 2018 5:10 PM, \"Weiwu Zhang via bitcoin-dev\" <bitcoin-dev at lists.\n> linuxfoundation.org> wrote:\n>\n>> 2018-01-09 19:20 GMT+08:00 Ronald van der Meer via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org>:\n>> > After reviewing some bitcoin improvement proposals, I noticed that one\n>> of the words that can be found on the BIP39 English wordlist is \u201csatoshi\u201d.\n>> > I suggest removing this word from the list so it\u2019s less obvious that\n>> it\u2019s a bitcoin seed when found by a malicious third party.\n>>\n>> If a malicious third party discovers a word list that look like a\n>> seed, they would try using it as Bitcoin seed first anyway, with or\n>> without finding the word 'satoshi' in it. The security threat is that\n>> a malicious third party may index what they found and test every\n>> occurrence of 'satoshi' for a lead to a seed.\n>>\n>> For example, a hard-disk recycling service would add this word to\n>> their salvage tools. Any successfully hacked gmail account will be\n>> 'satoshi' tested too.\n>>\n>> So I see this as a reasonable improvement:)\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n\n\n-- \nKind Regards,\n\nJonathan Sterling\n+44 (0)7415 512691\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180118/de50dfb5/attachment.html>"
            },
            {
                "author": "Alan Evans",
                "date": "2018-01-18T19:50:24",
                "message_text_only": "> so it\u2019s less obvious that it\u2019s a bitcoin seed when found by a malicious\nthird party\n1. The same words are used for wallets of all kinds of coins, so it's not\nobvious it's for bitcoin.\n\n2. Anyone recognising the word \"satoshi\" as related to cryptocurrency in\ngeneral, would also recognise any mnemonic.\n\n3. You could elect to skip a mnemonic that includes the word if it was a\npersonal concern (but I would discourage selecting a mnemonic base on\npersonal preference, as could get dangerously close to being a brain wallet\nin effect).\n\n4. You could choose to record just the first 4 characters of each word,\n\"sato\" is enough.\n\n5. Where do we stop? the words \"coin\", \"cash\", \"rich\" are in there too.\n\n6. About automated data-recovery, if you are storing mnemonics on HDDs or\nother digial media, then you have larger security concerns than it just\nbeing found during HDD recycling.\n\nBut most of all:\n\n7. Removing a word or changing a list *is impossible* as verification of an\nexisting mnemonic requires the list. To change one word, you would need to\nprovide an alternative to BIP0039 to cope with alternative words, or change\nall the words to a completely new set of 2048 English words so that it is\nclear which wordlist is in use.\n\nRegards,\n\nAlan\n\nOn Thu, Jan 18, 2018 at 2:55 AM, Jonathan Sterling via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> All the more reason to only use the most common words that meet the other\n> criteria:  https://github.com/bitcoin/bips/blob/master/bip-\n> 0039.mediawiki#Wordlist\n>\n> I agree - keeping \"satoshi\" in there is an unnecessary security risk.\n>\n> Kind Regards,\n>\n> Jonathan Sterling\n>\n> On Thu, Jan 18, 2018 at 8:14 AM, CryptAxe via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Why wouldn't they just test the frequency of words from the wordlist in\n>> entirety?\n>>\n>> On Jan 17, 2018 5:10 PM, \"Weiwu Zhang via bitcoin-dev\" <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> 2018-01-09 19:20 GMT+08:00 Ronald van der Meer via bitcoin-dev\n>>> <bitcoin-dev at lists.linuxfoundation.org>:\n>>> > After reviewing some bitcoin improvement proposals, I noticed that one\n>>> of the words that can be found on the BIP39 English wordlist is \u201csatoshi\u201d.\n>>> > I suggest removing this word from the list so it\u2019s less obvious that\n>>> it\u2019s a bitcoin seed when found by a malicious third party.\n>>>\n>>> If a malicious third party discovers a word list that look like a\n>>> seed, they would try using it as Bitcoin seed first anyway, with or\n>>> without finding the word 'satoshi' in it. The security threat is that\n>>> a malicious third party may index what they found and test every\n>>> occurrence of 'satoshi' for a lead to a seed.\n>>>\n>>> For example, a hard-disk recycling service would add this word to\n>>> their salvage tools. Any successfully hacked gmail account will be\n>>> 'satoshi' tested too.\n>>>\n>>> So I see this as a reasonable improvement:)\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>\n>\n> --\n> Kind Regards,\n>\n> Jonathan Sterling\n> +44 (0)7415 512691 <+44%207415%20512691>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180118/418a49c6/attachment-0001.html>"
            },
            {
                "author": "Matthew Clancy",
                "date": "2018-01-18T20:49:35",
                "message_text_only": "I would disagree here:\n\n>But most of all:\n>7. Removing a word or changing a list *is impossible* as verification of an\n>existing mnemonic requires the list. To change one word, you would need to\n>provide an alternative to BIP0039 to cope with alternative words, or change\n>all the words to a completely new set of 2048 English words so that it is\n>clear which wordlist is in use.\n\nAll that really would need to be done is select another word that is not on\nthe 2048 list, and then agree that by convention,  the words 'satoshi' or\nthe alternative word will represent the same number on the list. It seems\nto be to be a fairly simple thing to implement.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180118/4e7d95ab/attachment.html>"
            },
            {
                "author": "Alan Evans",
                "date": "2018-01-18T21:29:27",
                "message_text_only": "> and then agree that by convention,  the words 'satoshi' or the\nalternative word will represent the same number on the list\n\nThat convention would be the alternative to BIP0039 I am referring to.\n\n\nOn Thu, Jan 18, 2018 at 4:49 PM, Matthew Clancy <matthewpclancy at gmail.com>\nwrote:\n\n> I would disagree here:\n>\n> >But most of all:\n> >7. Removing a word or changing a list *is impossible* as verification of\n> an\n> >existing mnemonic requires the list. To change one word, you would need to\n> >provide an alternative to BIP0039 to cope with alternative words, or\n> change\n> >all the words to a completely new set of 2048 English words so that it is\n> >clear which wordlist is in use.\n>\n> All that really would need to be done is select another word that is not\n> on the 2048 list, and then agree that by convention,  the words 'satoshi'\n> or the alternative word will represent the same number on the list. It\n> seems to be to be a fairly simple thing to implement.\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180118/3c429223/attachment.html>"
            },
            {
                "author": "Ronald van der Meer",
                "date": "2018-01-23T19:40:42",
                "message_text_only": "I\u2019m new to this so what is the next step?\n\n--\nRonald van der Meer\n\nE: ronald at vandermeer.frl<mailto:ronald at vandermeer.frl> | W: https://www.vandermeer.frl\nS: https://twitter.com/truly_secure\n\nGPG: 8203 CE3E 064D C462 1D22 F635 A1EC 45F9 645F 878D\n\n\n\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org [mailto:bitcoin-dev-bounces at lists.linuxfoundation.org] On Behalf Of Alan Evans via bitcoin-dev\nSent: donderdag 18 januari 2018 22:29\nTo: Matthew Clancy <matthewpclancy at gmail.com>\nCc: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\nSubject: Re: [bitcoin-dev] Suggestion to remove word from BIP39 English wordlist\n\n\n> and then agree that by convention,  the words 'satoshi' or the alternative word will represent the same number on the list\n\nThat convention would be the alternative to BIP0039 I am referring to.\n\n\nOn Thu, Jan 18, 2018 at 4:49 PM, Matthew Clancy <matthewpclancy at gmail.com<mailto:matthewpclancy at gmail.com>> wrote:\nI would disagree here:\n\n>But most of all:\n>7. Removing a word or changing a list *is impossible* as verification of an\n>existing mnemonic requires the list. To change one word, you would need to\n>provide an alternative to BIP0039 to cope with alternative words, or change\n>all the words to a completely new set of 2048 English words so that it is\n>clear which wordlist is in use.\n\nAll that really would need to be done is select another word that is not on the 2048 list, and then agree that by convention,  the words 'satoshi' or the alternative word will represent the same number on the list. It seems to be to be a fairly simple thing to implement.\n\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180123/2d79c60f/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Suggestion to remove word from BIP39 English wordlist",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "CryptAxe",
                "Ronald van der Meer",
                "Jonathan Sterling",
                "Weiwu Zhang",
                "Matthew Clancy",
                "Alan Evans"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 12625
        }
    },
    {
        "title": "[bitcoin-dev] BIP 117 Feedback",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-01-09T11:22:18",
                "message_text_only": "I've just re-read BIP 117, and I'm concerned about its flexibility.  It\nseems to be doing too much.\n\nThe use of altstack is awkward, and makes me query this entire approach.\nI understand that CLEANSTACK painted us into a corner here :(\n\nThe simplest implementation of tail recursion would be a single blob: if\na single element is left on the altstack, pop and execute it.  That\nseems trivial to specify.  The treatment of concatenation seems like\ntrying to run before we can walk.\n\nNote that if we restrict this for a specific tx version, we can gain\nexperience first and get fancier later.\n\nBIP 117 also drops SIGOP and opcode limits.  This requires more\njustification, in particular, measurements and bounds on execution\ntimes.  If this analysis has been done, I'm not aware of it.\n\nWe could restore statically analyzability by rules like so:\n1.  Only applied for tx version 3 segwit txs.\n2.  For version 3, top element of stack is counted for limits (perhaps\n    with discount).\n3.  The blob popped off for tail recursion must be identical to that top\n    element of the stack (ie. the one counted above).\n\nAgain, future tx versions could drop such restrictions.\n\nCheers,\nRusty."
            },
            {
                "author": "Mark Friedenbach",
                "date": "2018-01-09T12:40:30",
                "message_text_only": "The use of the alt stack is a hack for segwit script version 0 which has the clean stack rule. Anticipated future improvements here are to switch to a witness script version, and a new segwit output version which supports native MAST to save an additional 40 or so witness bytes. Either approach would allow getting rid of the alt stack hack. They are not part of the proposal now because it is better to do things incrementally, and because we anticipate usage of MAST to better inform these less generic changes.\n\nYour suggestion of \u201csingle blob on the stack\u201d seems to be exactly this proposal afaict? Note the witness data needs to be passed separately because signatures can\u2019t be included in that single blob if that blob is hashed and compared against something in the scriptPubKey.\n\nThe sigop and opcode limit drop can be justified with some back of the envelope calculations. Non-scriptPubKey scripts are fundamentally limited by blocksize/weight and the most damage you can do, as an adversary, is limited by space. The most expensive thing you can do check a signature. Our assumptions about block size safety are basically due to how much computation you can stuff in a block with checksigs \u2014 all the analysis there applies.\n\nMy suggestion is to limit the number of checksigs allowed in a script to size(script+witness)/64, but I wanted this to come up in review rather than complicate the code right off the bat.\n\nI will make a strong assertion: static analyzing the number of opcodes and sigops gets us absolutely nothing. It is cargo cult safety engineering. No need to perpetuate it when it is now in the way.\n\nSent from my iPhone\n\n> On Jan 9, 2018, at 8:22 PM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n> \n> I've just re-read BIP 117, and I'm concerned about its flexibility.  It\n> seems to be doing too much.\n> \n> The use of altstack is awkward, and makes me query this entire approach.\n> I understand that CLEANSTACK painted us into a corner here :(\n> \n> The simplest implementation of tail recursion would be a single blob: if\n> a single element is left on the altstack, pop and execute it.  That\n> seems trivial to specify.  The treatment of concatenation seems like\n> trying to run before we can walk.\n> \n> Note that if we restrict this for a specific tx version, we can gain\n> experience first and get fancier later.\n> \n> BIP 117 also drops SIGOP and opcode limits.  This requires more\n> justification, in particular, measurements and bounds on execution\n> times.  If this analysis has been done, I'm not aware of it.\n> \n> We could restore statically analyzability by rules like so:\n> 1.  Only applied for tx version 3 segwit txs.\n> 2.  For version 3, top element of stack is counted for limits (perhaps\n>    with discount).\n> 3.  The blob popped off for tail recursion must be identical to that top\n>    element of the stack (ie. the one counted above).\n> \n> Again, future tx versions could drop such restrictions.\n> \n> Cheers,\n> Rusty."
            },
            {
                "author": "Pieter Wuille",
                "date": "2018-01-09T14:21:08",
                "message_text_only": "On Jan 9, 2018 13:41, \"Mark Friedenbach via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\nThe use of the alt stack is a hack for segwit script version 0 which has\nthe clean stack rule. Anticipated future improvements here are to switch to\na witness script version, and a new segwit output version which supports\nnative MAST to save an additional 40 or so witness bytes. Either approach\nwould allow getting rid of the alt stack hack. They are not part of the\nproposal now because it is better to do things incrementally, and because\nwe anticipate usage of MAST to better inform these less generic changes.\n\n\nIf the goal is to introduce a native MAST output type later, what is gained\nby first having the tailcall semantics?\n\nAs far as I can see, this proposal does not have any benefits over Johnson\nLau's MAST idea [1]:\n* It is more compact, already giving us the space savings a native MAST\nversion of the tail call semantics would bring.\n* It does not need to work around limitations of push size limits or\ncleanstack rules.\n* The implementation (of code I've seen) is easier to reason about, as it's\njust another case in VerifyScript (which you'd need for a native MAST\noutput later too) without introducing jumps or loops inside EvalScript.\n* It can express the same, as even though the MBV opcode supports proving\nmultiple elements simultaneously, I don't see a way to use that in the tail\ncall. Every scenario that consists of some logic before deciding what the\ntail call is going to be can be rewritten to have that logic inside each of\nthe branches, I believe.\n* It does not interfere with static analysis (see further).\n* Tail call semantics may be easier to extend in the future to enable\nsemantics that are not compactly representable in either proposal right\nnow, by allowing a single top-level script may invoke multiple subscripts,\nor recursion. However, those sound even riskier and harder to analyse to\nme, and I don't think there is sufficient evidence they're needed.\n\nNative MAST outputs would need a new witness script version, which your\ncurrent proposal does indeed not need. However, I believe a new script\nversion will be desirable for other reasons regardless (returning invalid\nopcodes to the pool of NOPs available for softforks, for example).\n\nI will make a strong assertion: static analyzing the number of opcodes and\nsigops gets us absolutely nothing. It is cargo cult safety engineering. No\nneed to perpetuate it when it is now in the way.\n\n\nI'm not sure I agree here. While I'd like to see the separate execution\nlimits go away, removing them entirely and complicating future ability to\nintroduce unified costing towards weight of execution cost seems the wrong\nway to go.\n\nMy reasoning is this: perhaps you can currently make an argument that the\ncurrent weight limit is sufficient in preventing overly expensive block\nvalidation costs, due to a minimal ratio between script sizes and their\nexecution cost. But such an argument needs to rely on assumptions about\nsighash caching and low per-opcode CPU time, which may change in the\nfuture. In my view, tail call semantics gratuitously remove or complicate\nthe ability to reason about the executed code.\n\nOne suggestion to reduce the impact of this is limiting the per-script\nexecution to something proportional to the script size. However, I don't\nthink that addresses all potential concerns about static analysis (for\nexample, it doesn't easily let you prove all possible execution paths to a\nparticipant in a smart contract).\n\nAnother idea that has been suggested on this list is to mark pushes of\npotentially executable code on the stack/witness explicitly. This would\nretain all ability to analyse, while still leaving the flexibility of\nfuture extensions to tail call execution. If tail call semantics are\nadopted, I strongly prefer an approach like that to blindly throwing out\nall limits and analysis.\n\n  [1] https://github.com/jl2012/bips/blob/mast/bip-mast.mediawiki\n\nCheers,\n\n-- \nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180109/6c862414/attachment.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2018-01-09T22:57:34",
                "message_text_only": "I havent the hubris to suggest that we know exactly what a templated MAST *should* look like. It's not used in production anywhere. Even if we did have the foresight, the tail-call semantics allow for other constructions besides MAST and for the sake of the future we should allow such permission-less innovation. The proper sequence of events should be to enable features in a generic way, and then to create specialized templates to save space for common constructions. Not the other way around.\n\nWe've been down the route of templating new features, and have made mistakes. P2SH is a canonical example, which BIP 117 is fixing. P2SH only provides 80 bits of security to a multi-party construction. Had we been designing BIP 16 now we probably would have used double-SHA256 instead of RIPEMD160. I will also assert that had we been using single-use tail-call semantics *instead* of BIP 16, recognition of this limitation would have resulted in us immediately defining a longer '3...' address which used HASH256 instead, and we would have immediately benefited from the fix. Instead we had to wait years until segwit gave us the opportunity to fix it at the same time.\n\nTo take another example, in some ideal sense we probably shouldn't even be developing a programmable signature script framework. We should instead template a generic lightning-derived layer-2 protocol and use that for everything, including both payments (supporting cut-through) and payment channels for smart contracts. This may not be the majority technical opinion yet, but as someone working in this space I believe that's where we are headed: a single layer-2 protocol that's generic enough to use for all payment caching and smart contracts, while achieving a full anonymity set for all contracts, as closures look identical on the wire. Even if that's where things are headed, I hope it is clear that we are not yet at such a stage to standardize what that looks like. We still need many years of use of specialized lightning protocols and work to be done to make them more generic and applicable to other protocols.\n\nI believe the situation to be similar with MAST. Even if we have a better idea of what the MAST constructions will look like, *nobody* uses MAST in production yet, and there are bound to be implementation issues in rolling it out, or unique variants we do not have the foresight to see now. As a concrete example, BIP 116 has been modified since the initial proposal to allow multiple branches to be proven at once from a single Merkle tree root. To be honest, I don't know exactly how this will be used. We were able to come up with a couple of examples to justify inclusion of the feature, but I anticipate that someone down the line will come up with an even more creative use. Maybe a payment channel that uses a single tree to simultaneously commit to both the policy script and a sequence number. Or something like that. If we provide a templated, special-cased MAST now before it sees wide use then we will be locking in the protocol that we anticipate people using without having any production experience or ecosystem-wide review. Frankly that strikes me as a poor engineering decision.\n\nFinally, even if we had perfect foresight into how a feature will be used, which we don't, it is still the case that we would want to enable permission-less innovation with the generic construct, even if using it comes with a 40-byte or so witness hit. I make the argument for this in the \"intuitive explanation of MAST\" email I sent to this list back in September of last year. I will reproduce the argument below:\n\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-September/015028.html\n\nThe driving motivation for the tail-call and MBV proposals, and the reason they are presented and considered together is to enable Merklized Abstract Syntax Trees. However neither BIP actually defines a MAST template, except as an example use case of the primitive features. This is very much on purpose: it is the opinion of this author that new bitcoin consensus features should follow the UNIX philosophy as expressed by Peter Salus and Mike Gancarz and paraphrased by yours truly:\n\n  * Write features that do one thing and do it well.\n  * Write features to work together.\n  * Simple is beautiful.\n\nBy using modularity and composition of powerful but simple tools like MERKLEBRANCHVERIFY and single tail-call recursion to construct MAST we enable a complex and desirable feature while minimizing changes to the consensus code, review burden, and acquired technical debt.\n\nThe reusability of the underlying primitives also means that they can be combined with other modular features to support use cases other than vanilla MAST, or reused in series to work around various limits that might otherwise be imposed on a templated form of MAST. At the moment the chief utility of these proposals is the straightforward MAST script written above, but as primitives they do allow a few other use cases and also combine well with features in the pipeline or on\nthe drawing board. For example, in addition to MAST you can:\n\n1. Use MERKLEBRANCHVERIFY alone to support honeypot bounties, as\n   discussed in the BIP.\n\n2. Use a series of MERKLEBRANCHVERIFY opcodes to verify a branch with\n   split proofs to stay under script and witness push limitations.\n\n3. Combine MERKLEBRANCHVERIFY with key aggregation to get\n   Wuille-Maxwell tree signatures which support arbitrary signing\n   policies using a single, aggregatable signature.\n\n4. Combine tail-call execution semantics with CHECKSIGFROMSTACK to get\n   delegation and signature-time commitment to subscript policy.\n\n5. Combine MERKLEBRANCHVERIFY with a Merkle proof prefix check opcode\n   and Lamport signature support to get reusable Lamport keys.\n\nI believe these benefits and possible future expansions to be strong arguments in favor of extending bitcoin in the form of small, modular, incremental, and reusable changes that can be combined and used even in ways unforeseen even by their creators, creating a platform for unrestricted innovation.\n\nThe alternative approach of rigid templates achieves the stated goals, perhaps even with slightly better encoding efficiency, but at the cost of requiring workaround for each future innovation. P2SH is just such an example -- we couldn't even upgrade to 128-bit security without designing an entirely different implementation because of the limitations of template pattern matching.\n\n\n> On Jan 9, 2018, at 11:21 PM, Pieter Wuille <pieter.wuille at gmail.com> wrote:\n> \n> On Jan 9, 2018 13:41, \"Mark Friedenbach via bitcoin-dev\" <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> The use of the alt stack is a hack for segwit script version 0 which has the clean stack rule. Anticipated future improvements here are to switch to a witness script version, and a new segwit output version which supports native MAST to save an additional 40 or so witness bytes. Either approach would allow getting rid of the alt stack hack. They are not part of the proposal now because it is better to do things incrementally, and because we anticipate usage of MAST to better inform these less generic changes.\n> \n> If the goal is to introduce a native MAST output type later, what is gained by first having the tailcall semantics?\n> \n> As far as I can see, this proposal does not have any benefits over Johnson Lau's MAST idea [1]:\n> * It is more compact, already giving us the space savings a native MAST version of the tail call semantics would bring.\n> * It does not need to work around limitations of push size limits or cleanstack rules.\n> * The implementation (of code I've seen) is easier to reason about, as it's just another case in VerifyScript (which you'd need for a native MAST output later too) without introducing jumps or loops inside EvalScript.\n> * It can express the same, as even though the MBV opcode supports proving multiple elements simultaneously, I don't see a way to use that in the tail call. Every scenario that consists of some logic before deciding what the tail call is going to be can be rewritten to have that logic inside each of the branches, I believe.\n> * It does not interfere with static analysis (see further).\n> * Tail call semantics may be easier to extend in the future to enable semantics that are not compactly representable in either proposal right now, by allowing a single top-level script may invoke multiple subscripts, or recursion. However, those sound even riskier and harder to analyse to me, and I don't think there is sufficient evidence they're needed.\n> \n> Native MAST outputs would need a new witness script version, which your current proposal does indeed not need. However, I believe a new script version will be desirable for other reasons regardless (returning invalid opcodes to the pool of NOPs available for softforks, for example).\n> \n> I will make a strong assertion: static analyzing the number of opcodes and sigops gets us absolutely nothing. It is cargo cult safety engineering. No need to perpetuate it when it is now in the way.\n> \n> I'm not sure I agree here. While I'd like to see the separate execution limits go away, removing them entirely and complicating future ability to introduce unified costing towards weight of execution cost seems the wrong way to go.\n> \n> My reasoning is this: perhaps you can currently make an argument that the current weight limit is sufficient in preventing overly expensive block validation costs, due to a minimal ratio between script sizes and their execution cost. But such an argument needs to rely on assumptions about sighash caching and low per-opcode CPU time, which may change in the future. In my view, tail call semantics gratuitously remove or complicate the ability to reason about the executed code.\n> \n> One suggestion to reduce the impact of this is limiting the per-script execution to something proportional to the script size. However, I don't think that addresses all potential concerns about static analysis (for example, it doesn't easily let you prove all possible execution paths to a participant in a smart contract).\n> \n> Another idea that has been suggested on this list is to mark pushes of potentially executable code on the stack/witness explicitly. This would retain all ability to analyse, while still leaving the flexibility of future extensions to tail call execution. If tail call semantics are adopted, I strongly prefer an approach like that to blindly throwing out all limits and analysis.\n> \n>   [1] https://github.com/jl2012/bips/blob/mast/bip-mast.mediawiki <https://github.com/jl2012/bips/blob/mast/bip-mast.mediawiki>\n> \n> Cheers,\n> \n> -- \n> Pieter\n> \n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180110/030d4279/attachment-0001.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2018-01-12T10:48:33",
                "message_text_only": "Putting aside for the moment the concerns that Pieter and Rusty have raised\nabout BIP 117 (concerns which I agree with), is BIP 117 even a viable soft\nfork to begin with?\n\nWhen it comes to soft forks of Script, in the past there have been two\nkinds.\n\nThe first kind is soft-forking new script semantics into NOPn codes.  In\nthis case, everyone ought to know that these op codes are reserved for\nfuture extensions and no one should be writing script that depends on NOPn\nhaving NOP behavior (For users who want real nop behaviour, there does\nexist a real NOP opcode).\n\nThe second kind of soft-forking new script semantics is the\nreinterpretation of various wholesale scripts (historically via\ntemplates).  Examples of this are Segwit and P2SH.  In the case of Segwit,\nthe scripts gaining new semantics were applied to a form of completely\nunsecured \"anyone-can-spend\" programs.  Anyone who created such output\nprior to the activation of Segwit would know that anyone could claim\nownership of those outputs, and therefore the possibility of losing the\nability to spend legacy forms of these segwit-style outputs is arguably not\nharmful as no one in particular had ownership of such funds.  The story for\nP2SH is somewhat similar: Prior to the activation of P2SH the creator of of\nP2SH style outputs would know that anyone could claim ownership of that\nstyle of output as soon as the hash preimage is published (in the mempool,\nfor example).\n\nHowever, if I understand correctly, the situation for BIP 117 is entirely\ndifferent.  As far as I understand there is currently no restrictions about\nterminating a v0 witness program with a non-empty alt-stack, and there are\nno restrictions on leaving non-canonical boolean values on the main stack.\nThere could already be commitments to V0 witness programs that, when\nexecuted in some reasonable context, leave a non-empty alt-stack and/or\nleave a non-canonical true value on the main stack.  Unlike the P2SH or\nSegwit soft-forks, these existing commitments could be real outputs that\ncurrently confer non-trivial ownership over their associated funds.  If BIP\n117 were activated, these commitments would be subject to a new set of\nrules that didn't exist when the commitments were made.  In particular,\nthese funds could be rendered unspendable.  Because segwit commitments are\nhashes of segwit programs, there is no way to even analyze the blockchain\nto determine if these commitments currently exist (and even if we could it\nprobably woudln't be adequate protection).\n\nNaturally we shouldn't be making new rules that could, in principle,\nretroactively remove ownership of existing user's funds.\n\n\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180112/c5442637/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-01-16T01:06:14",
                "message_text_only": "\"Russell O'Connor\" <roconnor at blockstream.io> writes:\n> However, if I understand correctly, the situation for BIP 117 is entirely\n> different.  As far as I understand there is currently no restrictions about\n> terminating a v0 witness program with a non-empty alt-stack, and there are\n> no restrictions on leaving non-canonical boolean values on the main stack.\n\nBIP-141: \"The script must not fail, and result in exactly a single TRUE\non the stack.\"  And it has long been non-standard for P2SH scripts to\nnot do the same (don't know exactly when).\n\n> There could already be commitments to V0 witness programs that, when\n> executed in some reasonable context, leave a non-empty alt-stack and/or\n> leave a non-canonical true value on the main stack.  Unlike the P2SH or\n> Segwit soft-forks, these existing commitments could be real outputs that\n> currently confer non-trivial ownership over their associated funds.  If BIP\n> 117 were activated, these commitments would be subject to a new set of\n> rules that didn't exist when the commitments were made.  In particular,\n> these funds could be rendered unspendable.  Because segwit commitments are\n> hashes of segwit programs, there is no way to even analyze the blockchain\n> to determine if these commitments currently exist (and even if we could it\n> probably woudln't be adequate protection).\n\nThe rule AFAICT is \"standard transactions must still work\".  This was\nviolated with low-S, but the transformation was arguably trivial.  \n\nOTOH, use of altstack is completely standard, though in practice it's\nunused and so only a theoretical concern.\n\nMy concern remains unanswered: I want hard numbers on the worst-case\ntime taken by sigops with the limit removed.  It's about 120 usec per\nsigop (from [1]), so how bad could it be?  I think Russell had an\nestimate like 1 in 3 ops, so 160 seconds to validate a block?\n\nThanks,\nRusty.\n[1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015346.html"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-16T03:27:26",
                "message_text_only": "On Tue, Jan 16, 2018 at 1:06 AM, Rusty Russell via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> The rule AFAICT is \"standard transactions must still work\".  This was\n> violated with low-S, but the transformation was arguably trivial.\n\nThat is my view, generally.  Like any other principle, its\napplicability is modulated by the specific facts.\n\nFor low-s the most critical mitigating specific facts were (in order\nof importance):  Any third party could malleate non-conforming\ntransactions to make them conform and that code to do this was written\nand run,  that S-value malleation was being actively attacked at the\ntime, and that the intention to eventually enforce lowS had been made\nclear a long time ahead and the vast majority of transactions were\nalready conforming.\n\nIn particular these facts meant that the change could not result in\nthe confiscation of funds except in the case of a key-destroyed\nunconfirmed chain of timelock transactions which was already highly\nvulnerable due to the malleation attacks -- and even there, the\nnon-standardness step itself wouldn't destroy the funds esp. given the\nmalleation risk redemption of that sort of chain would probably be\nbest accomplished with the collaboration of a miner."
            },
            {
                "author": "Luke Dashjr",
                "date": "2018-01-16T04:15:54",
                "message_text_only": "On Tuesday 16 January 2018 1:06:14 AM Rusty Russell via bitcoin-dev wrote:\n> \"Russell O'Connor\" <roconnor at blockstream.io> writes:\n> > However, if I understand correctly, the situation for BIP 117 is entirely\n> > different.  As far as I understand there is currently no restrictions\n> > about terminating a v0 witness program with a non-empty alt-stack, and\n> > there are no restrictions on leaving non-canonical boolean values on the\n> > main stack.\n> \n> BIP-141: \"The script must not fail, and result in exactly a single TRUE\n> on the stack.\"  And it has long been non-standard for P2SH scripts to\n> not do the same (don't know exactly when).\n\nThis doesn't affect the alt-stack (it's a completely separate stack).\n\n> The rule AFAICT is \"standard transactions must still work\".  This was\n> violated with low-S, but the transformation was arguably trivial.\n> \n> OTOH, use of altstack is completely standard, though in practice it's\n> unused and so only a theoretical concern.\n\nI'm not aware of a single standard/BIP that uses the altstack at all.\n\nLuke"
            },
            {
                "author": "Russell O'Connor",
                "date": "2018-01-16T08:39:28",
                "message_text_only": "On Mon, Jan 15, 2018 at 11:15 PM, Luke Dashjr <luke at dashjr.org> wrote:\n\n> On Tuesday 16 January 2018 1:06:14 AM Rusty Russell via bitcoin-dev wrote:\n> > The rule AFAICT is \"standard transactions must still work\".  This was\n> > violated with low-S, but the transformation was arguably trivial.\n> >\n> > OTOH, use of altstack is completely standard, though in practice it's\n> > unused and so only a theoretical concern.\n>\n> I'm not aware of a single standard/BIP that uses the altstack at all.\n>\n\nBy \"standard transaction\" here, Rusty means that (P2SH or Segwit) scripts\nthat use the alt-stack pass the standardness checks and will be relayed by\nrecent Bitcoin Core software.\n\n----\n\nRegarding lowS:  I think the more severe standardness change was the added\nrequirement that (some of the) pubkeys in a multisig must be parsable.  I\nhave talked with people who cannot retrieve their funds now, when before\nthey could.  However, like lowS, this was only a change to the standardness\nrules and not a consensus change, so these funds are not necessarily\npermanently lost.  They can be retrieved with miner help.\n\nI don't see how BIP 117, which is a change in consensus rules that could\ncause permanent loss of otherwise well-secured funds (in addition to the\nother issues raised about BIP 117), is even comparable to the previous\nchanges in only the standardness rules.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180116/ac9e85b8/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP 117 Feedback",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Russell O'Connor",
                "Gregory Maxwell",
                "Luke Dashjr",
                "Mark Friedenbach",
                "Pieter Wuille"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 27888
        }
    },
    {
        "title": "[bitcoin-dev] JSONRPC vulnerability in Electrum 2.6 to 3.0.4",
        "thread_messages": [
            {
                "author": "Thomas Voegtlin",
                "date": "2018-01-10T17:44:02",
                "message_text_only": "A vulnerability has been found in Electrum, and patched in version\n3.0.5. Please update your software if you are running an earlier version.\n\nThe following is a copy of the summary and guidelines we posted on our\nwebsite: https://github.com/spesmilo/electrum-docs/blob/master/cve.rst\n\nA CVE number for the issue has been requested 2 days ago, and has not\nbeen attributed yet.\n\n\n\nJSONRPC vulnerability in Electrum 2.6 to 3.0.4\n==============================================\n\nOn January 6th, a vulnerability was disclosed in the Electrum wallet\nsoftware, that allows malicious websites to execute wallet commands\nthrough JSONRPC executed in a web browser. The bug affects versions\n2.6 to 3.0.4 of Electrum, on all platforms. It also affects clones of\nElectrum such as Electron Cash.\n\n\nCan funds be stolen?\n--------------------\n\nWallets that are not password protected are at risk of theft, if they\nare opened with a version of Electrum older than 3.0.5 while a web\nbrowser is active.\n\nIn addition, the vulnerability allows an attacker to modify user\nsettings, the list of contacts in a wallet, and the \"payto\" and\n\"amount\" fields of the user interface while Electrum is running.\n\nAlthough there is no known occurrence of Bitcoin theft occurring\nbecause of this vulnerability, the risk increases substantially now\nthat the vulnerability has been made public.\n\n\nCan wallet data be leaked?\n--------------------------\n\nYes, an attacker can obtain private data, such as: Bitcoin addresses,\ntransaction labels, address labels, wallet contacts and master public\nkeys.\n\n\nCan a password-protected wallet be bruteforced?\n-----------------------------------------------\n\nNot realistically. The vulnerability does not allow an attacker to\naccess encrypted seed or private keys, which would be needed in order\nto perform an efficient brute force attack. Without the encrypted\nseed, an attacker must try passwords using the JSONRPC interface,\nwhile the user is visiting a malicious page. This is several orders of\nmagnitude slower than an attack with the encrypted seed, and\nrestricted in time. Even a weak password will protect against that.\n\n\nWhat should users do?\n---------------------\n\nAll users should upgrade their Electrum software, and stop using old\nversions.\n\nUsers who did not protect their wallet with a password should create a\nnew wallet, and move their funds to that wallet. Even if it never\nreceived any funds, a wallet without password should not be used\nanymore, because its seed might have been compromised.\n\nIn addition, users should review their settings, and delete all\ncontacts from their contacts list, because the Bitcoin addresses of\ntheir contacts might have been modified.\n\n\nHow to upgrade Electrum\n-----------------------\n\nStop running any version of Electrum older than 3.0.5, and install\nElectrum the most recent version. On desktop, make sure you download\nElectrum from https://electrum.org and no other website. On Android,\nthe most recent version is available in Google Play.\n\nIf Electrum 3.0.5 (or any later version) cannot be installed or does\nnot work on your computer, stop using Electrum on that computer, and\naccess your funds from a device that can run Electrum 3.0.5. If you\nreally need to use an older version of Electrum, for example in order\nto access wallet seed, make sure that your computer is offline, and\nthat no web browser is running on the computer at the same time.\n\n\nShould all users move their funds to a new address?\n---------------------------------------------------\n\nWe do not recommend moving funds from password protected wallets. For\nwallets that were not password protected, moving funds is an extreme\nprecaution, that might not be necessary; indeed, if a wallet was\ncompromised, it is very likely that the attacker would have stolen the\nfunds immediately.\n\n\nWhen was the issue reported and fixed?\n--------------------------------------\n\nThe absence of password protection in the JSONRPC interface was\nreported on November 25th, 2017 by user jsmad:\nhttps://github.com/spesmilo/electrum/issues/3374\n\njsmad's report was about the Electrum daemon, a piece of software that\nruns on web servers and is used by merchants in order to receive\nBitcoin payments. In that context, connections to the daemon from the\noutside world must be explicitly authorized, by setting 'rpchost' and\n'rpcport' in the Electrum configuration.\n\nOn January 6th, 2018, Tavis Ormandy demonstrated that the JSONRPC\ninterface could be exploited against the Electrum GUI, and that the\nattack could be carried out by a web browser running locally, visiting\na webpage with specially crafted JavaScript.\n\nWe released a new version (3.0.4) in the hours following Tavis' post,\nwith a patch written by mithrandi (Debian packager), that addressed\nthe attack demonstrated by Tavis. In addition, the Github issue\nremained open, because mithrandi's patch was not adding password\nprotection to the JSONRPC interface.\n\nShortly after the 3.0.4 release we started to work on adding proper\npassword protection to the JSONRPC interface of the daemon, and that\npart was ready on Sunday, January 7th. We also learned on Sunday\nafternoon that the first patch was not effective against another,\nsimilar attack, using POST. This is why we did not delay the 3.0.5\nrelease, which includes password protection, and completely disables\nJSONRPC in the GUI.\n\n\n\n\n\n\n-- \nElectrum Technologies GmbH / Waldemarstr 37a / 10999 Berlin / Germany\nSitz, Registergericht: Berlin, Amtsgericht Charlottenburg, HRB 164636\nGesch\u00e4ftsf\u00fchrer: Thomas Voegtlin"
            }
        ],
        "thread_summary": {
            "title": "JSONRPC vulnerability in Electrum 2.6 to 3.0.4",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Thomas Voegtlin"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 5527
        }
    },
    {
        "title": "[bitcoin-dev] New Bitcoin Core macOS signing key",
        "thread_messages": [
            {
                "author": "Cory Fields",
                "date": "2018-01-12T05:04:44",
                "message_text_only": "Hi all\n\nAs discussed in a few of the last weekly meetings, Bitcoin Core's\nmacOS code signing certificate expired today.\n\nWe are (Greg is ;) in the process of establishing a new threshold\nsigning scheme that will allow us to handle code signing without any\nsingle point of failure. But until then, releases will be signed as\nbefore, just with a new certificate.\n\nAs a matter of record, I used the old code-signing key/certificate to\nsign a message containing the pubkey that matches the new\nkey/certificate. It's attached at the end of this message.\n\nThe pkcs7 format is rather clunky, but I wanted to include the current\nsigning certificate to make verification easier. I'll leave it to the\nreader to extract the certificate from a previous release in order to\nmake sure that they match. It was also in the Core git repo until it\nwas removed recently.\n\nTo verify, you can use something like:\nopenssl smime -verify -in sig.pkcs7 -inform pem -ignore_critical -purpose any\n\n- \"ignore_critical\" setting tells openssl to ignore the Apple-specific\ncritical extensions that it doesn't understand.\n- \"-purpose any\" allows the \"purpose == smimesign\" check to be\nskipped. This would otherwise fail because this certificate is only\nauthorized to sign code, not arbitrary messages.\n\nBy now, the signature will probably fail to validate because the\ncertificate has expired.\n\nThe signed message below is timestamped on the Bitcoin blockchain\nusing OpenTimestamps. See the attached ots file containing the\ntimestamp proof. If the attachment gets scrubbed and doesn't make it\nto the list, don't be afraid to nag Peter Todd about a mail-friendly\nformat for these proofs :)\n\nRegards,\nCory\n\nexpire.txt.sig:\n-----BEGIN PKCS7-----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\njixGT1Xg83O4e3LL4Bww0rRY6w==\n-----END PKCS7-----\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: expire.txt.sig.ots\nType: application/vnd.oasis.opendocument.spreadsheet-template\nSize: 1740 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180112/6cf33db9/attachment.ots>"
            },
            {
                "author": "Peter Todd",
                "date": "2018-01-12T08:54:12",
                "message_text_only": "On Fri, Jan 12, 2018 at 12:04:44AM -0500, Cory Fields via bitcoin-dev wrote:\n> To verify, you can use something like:\n> openssl smime -verify -in sig.pkcs7 -inform pem -ignore_critical -purpose any\n> \n> - \"ignore_critical\" setting tells openssl to ignore the Apple-specific\n> critical extensions that it doesn't understand.\n> - \"-purpose any\" allows the \"purpose == smimesign\" check to be\n> skipped. This would otherwise fail because this certificate is only\n> authorized to sign code, not arbitrary messages.\n> \n> By now, the signature will probably fail to validate because the\n> certificate has expired.\n\nNote that you may need to add -noverify as well if your openssl doesn't have\nthe Apple Certificate Authority in the CA list.\n\nWhile a clunky way to do it, you can use the `-signer` option to tell OpenSSL\nto write the signer's certificate to a file. That certificate can then be\ncompared to the one from the repo, which was still in the repo as of the\n(signed!) v0.15.1 tag.\n\n\nFun fact: OpenTimestamps has git integration, which means you can extract a OTS\nproof from 2016 for that certificate from the repo:\n\n    $ git checkout v0.15.1\n    $ ots git-extract share/certs/BitcoinFoundation_Apple_Cert.pem share/certs/BitcoinFoundation_Apple_Cert.pem.ots 36f60a5d5b1bc9a12b87d6475e3245b8236775e4\n    $ ots verify share/certs/BitcoinFoundation_Apple_Cert.pem.ots\n    Assuming target filename is 'share/certs/BitcoinFoundation_Apple_Cert.pem'\n    Success! Bitcoin attests data existed as of Thu Oct 13 14:08:59 2016 EDT\n\nHomework problem: write a paragraph explaining how the proof generated by the\nabove three commands are crypto snakeoil that proved little. :)\n\n> The signed message below is timestamped on the Bitcoin blockchain\n> using OpenTimestamps. See the attached ots file containing the\n> timestamp proof. If the attachment gets scrubbed and doesn't make it\n> to the list, don't be afraid to nag Peter Todd about a mail-friendly\n> format for these proofs :)\n\nHa! Fortunately even the mailing list archives at lists.linuxfoundation.org\nseem to contain the attachment just fine.\n\nBut anyway, I'd suggest using base64:\n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\nK5YKNh1phfaY3Du/0i68CAgABYiWDXPXGQEDt98e\n\nOn Linux, the `base64 -d` command will decode the above just fine.\n\nThe _real_ issue is that asking the user to cut-n-paste that PKCS7-encoded\nmessage is problematic, as differences in whitespace and line endings will make\nthe verification fail. Works fine on Linux, but would probably have failed on\nWindows.\n\nWhat's nice about OpenPGP's \"clearsigned\" format is how it ignores whitespace;\na replica of that might be a nice thing for OTS to be able to do too. Though\nthat's on low priority, as there's some tricky design choices(1) to be made about\nhow to nicely nest clearsigned PGP within OTS.\n\n\n1) For example, I recently found a security hole related to clearsigned PGP\nrecently. Basically the issue was that gpg --verify will return true on a file\nthat looks like the following:\n\n    1d7a363ce12430881ec56c9cf1409c49c491043618e598c356e2959040872f5a  foo-v2.0.tar.gz\n    -----BEGIN PGP SIGNED MESSAGE-----\n    Hash: SHA256\n\n    e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855  foo-v1.0.tar.gz\n    -----BEGIN PGP SIGNATURE-----\n\n    <snip pgp stuff>\n    -----END PGP SIGNATURE-----\n\nThe system I was auditing then did something like this to verify that the file\nwas signed:\n\n    set -e # exit immediately on error\n    gpg --verify SHA256SUMS.asc\n    cat SHA256SUMS.asc | grep foo-v2.0.tar.gz\n    <do installation>\n\nWhile it makes it a bit less user friendly, the fact that PKCS7's encoding made\nit impossible to see the message you signed until it's been properly verified\nis a good thing re: security.\n\nAnd yes, I checked: Bitcoin Core's contrib/verifybinaries/verify.sh isn't\nvulnerable to this mistake. :)\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180112/bfd7c512/attachment.sig>"
            },
            {
                "author": "nullius",
                "date": "2018-01-12T10:14:11",
                "message_text_only": "On 2018-01-12 at 08:54:12 +0000, Peter Todd <pete at petertodd.org> wrote:\n>While a clunky way to do it, you can use the `-signer` option to tell \n>OpenSSL to write the signer's certificate to a file. That certificate \n>can then be compared to the one from the repo, which was still in the \n>repo as of the (signed!) v0.15.1 tag.\n>\n>\n>Fun fact: OpenTimestamps has git integration, which means you can \n>extract a OTS proof from 2016 for that certificate from the repo:\n>\n>    $ git checkout v0.15.1\n>    $ ots git-extract share/certs/BitcoinFoundation_Apple_Cert.pem share/certs/BitcoinFoundation_Apple_Cert.pem.ots 36f60a5d5b1bc9a12b87d6475e3245b8236775e4\n>    $ ots verify share/certs/BitcoinFoundation_Apple_Cert.pem.ots\n>    Assuming target filename is 'share/certs/BitcoinFoundation_Apple_Cert.pem'\n>    Success! Bitcoin attests data existed as of Thu Oct 13 14:08:59 2016 EDT\n>\n>Homework problem: write a paragraph explaining how the proof generated \n>by the above three commands are crypto snakeoil that proved little. :)\n\nIt says, \u201cBitcoin attests data existed\u201d.  Within the scope of those \nthree commands, I don\u2019t see any proof of who put it there.  Does OTS \ncheck the PGP signatures on *commits* when it does that `git-extract`?  \nThe signature on the v0.15.1 tag is irrelevant to that question; and \nFWIW, I don\u2019t see *that* signature being verified here, either.  \n\nSecond paragraph:  Moreover, with the breaking of SHA-1, it *may* be \nfeasible for some scenario to play out involving two different PEMs with \nthe same hash, but different public keys (and thus different \ncorresponding private keys).  I don\u2019t know off the top of my head if \nsomewhere could be found to stash the magic bits; and the overall \nscenario would need to be a bit convoluted.  I think a malicious \ncommitter who lacked access to the signing key *may* be able to create a \ncollision between the real certificate, and a certificate as for which \nhe has the private key\u2014then switch them, later.  Maybe.  I would not \ndiscount the possibility off-hand.  OTS would prove nothing, if he had \nthe foresight to obtain timestamps proving that both certificates \nexisted at the appropriate time (which they would need to anyway; it is \nnot a post facto preimage attack).\n\n>[...]\n>\n>What's nice about OpenPGP's \"clearsigned\" format is how it ignores \n>whitespace; a replica of that might be a nice thing for OTS to be able \n>to do too. Though that's on low priority, as there's some tricky design \n>choices(1) to be made about how to nicely nest clearsigned PGP within \n>OTS.\n>\n>\n>1) For example, I recently found a security hole related to clearsigned \n>PGP recently. Basically the issue was that gpg --verify will return \n>true on a file that looks like the following:\n>\n>    1d7a363ce12430881ec56c9cf1409c49c491043618e598c356e2959040872f5a  foo-v2.0.tar.gz\n>    -----BEGIN PGP SIGNED MESSAGE-----\n>    Hash: SHA256\n>\n>    e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855  foo-v1.0.tar.gz\n>    -----BEGIN PGP SIGNATURE-----\n>\n>    <snip pgp stuff>\n>    -----END PGP SIGNATURE-----\n>\n>The system I was auditing then did something like this to verify that \n>the file was signed:\n>\n>    set -e # exit immediately on error\n>    gpg --verify SHA256SUMS.asc\n>    cat SHA256SUMS.asc | grep foo-v2.0.tar.gz\n>    <do installation>\n>\n>While it makes it a bit less user friendly, the fact that PKCS7's \n>encoding made it impossible to see the message you signed until it's \n>been properly verified is a good thing re: security.\n\nPotential solutions using PGP:\n\n0. Don\u2019t use clearsigning.\n\n1. Use a detached signature.\n\n2. Use `gpg --verify -o -` and pipe that to `grep`, rather than \nillogically separating verification from use of data.  (By the way, \nwhere is the *hash* verified?  Was `grep` piped to `sha256sum -c`?)\n\n3. Have shell scripts written by somebody who knows how to think about \nsecurity, and/or who knows how to RTFM; quoting gpg(1):\n\n>Note: When verifying a cleartext signature, gpg verifies only what  \n>makes up the cleartext signed data and not any extra data outside of \n>the cleartext signature or the header lines directly following the dash \n>marker line.  The option --output may be used to write out the actual \n>signed data, but there are other pitfalls with this format as well.  It \n>is suggested to avoid cleartext signatures in favor of detached \n>signatures.\n\n4. Obtain an audit from Peter Todd.\n\n>And yes, I checked: Bitcoin Core's contrib/verifybinaries/verify.sh \n>isn't vulnerable to this mistake. :)\n\nP.S., oh my!  *Unsigned data:*\n\n>_______________________________________________\n>bitcoin-dev mailing list\n>bitcoin-dev at lists.linuxfoundation.org\n>https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-- \nnullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\nBitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n\u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\nNo!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 228 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180112/54009101/attachment-0001.sig>"
            }
        ],
        "thread_summary": {
            "title": "New Bitcoin Core macOS signing key",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "nullius",
                "Peter Todd",
                "Cory Fields"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 17771
        }
    },
    {
        "title": "[bitcoin-dev] Plausible Deniability (Re: Satoshilabs secret shared private key scheme)",
        "thread_messages": [
            {
                "author": "nullius",
                "date": "2018-01-12T11:06:33",
                "message_text_only": "On 2018-01-12 at 09:50:58 +0000, Peter Todd <pete at petertodd.org> wrote:\n>On Tue, Jan 09, 2018 at 12:43:48PM +0000, Perry Gibson wrote:\n>>>Trezor's \"plausible deniability\" scheme could very well result in you \n>>>going to jail for lying to border security, because it's so easy for \n>>>them to simply brute force alternate passwords based on your seeds.  \n>>>With that, they have proof that you lied to customs, a serious \n>>>offense.\n>>The passphrase scheme as I understand it allows a maximum of 50 \n>>characters to be used.\u00a0 Surely even with the HD seed, that search \n>>space is too large to brute force.\u00a0 Or is there a weakness in the \n>>scheme I haven't clocked?\n>\n>While passphrases *can* be long, most user's aren't going to understand \n>the risk. For example, Trezors blog(1) doesn't make it clear that the \n>passphrases could be bruteforced and used as evidence against you, and \n>even suggests the contrary:  [...quote...]\n\nI despise the term \u201cplausible deniability\u201d; and that\u2019s really the wrong \nterm to use in this discussion.\n\n\u201cPlausible deniability\u201d is a transparent excuse for explaining away an \nindisputable fact which arouses suspicion\u2014when you got some serious \n\u2019splain\u2019 to do.  This is usually used in the context of some pseudolegal \nargument about introducing \u201creasonable doubt\u201d, or even making \u201cprobable \ncause\u201d a wee bit less probable.\n\n\u201cWhy yes, officer:  I was seen carrying an axe down the street near the \nsite of an axe murder, at approximately the time of said axe murder.  \nBut I do have a fireplace; so it is plausible that I was simply out \ngathering wood.\u201d\n\nI rather suspect the concept of \u201cplausible deniability\u201d of having been \ninvented by a detective or agent provocateur.  There are few concepts \nmore useful for helping suspects shoot themselves in the foot, or \nfrankly, for entrapping people.\n\nOne of the worst examples I have seen is in discussions of Monero, \nwhereby I\u2019ve seen proponents claim that even under the worst known \nactive attacks, their mix scheme reduces transaction linking to a \nmaximum of 20\u201340% probability.  \u201cThat\u2019s not good enough to convince a \njury!\u201d  No, but it is certainly adequate for investigators to identify \nyou as a person of interest.  Then, your (mis)deeds can be subjected to \npowerful confirmation attacks based on other data; blockchains do not \nexist in isolation.  I usually stay out of such discussions; for I have \nno interest in helping the sorts of people whose greatest concern in \nlife is what story to foist on a jury.\n\nIn the context of devices such as Trezor, what is needed is not \n\u201cplausible deniability\u201d, but rather the ability to obviate any need to \ndeny anything at all.  I must repeat, information does not exist in \nisolation.\n\nIf you are publicly known to be deepy involved in Bitcoin, then nobody \nwill believe that your one-and-only wallet contains only 0.01 BTC.  \nThat\u2019s not even \u201cplausible\u201d.  But if you have overall privacy practices \nwhich leave nobody knowing or suspecting that you have any Bitcoin at \nall, then there is nothing to \u201cdeny\u201d; and should a Trezor with \n(supposedly) 0.01 BTC be found in your possession, that\u2019s much better \nthan \u201cplausible\u201d.  It\u2019s completely unremarkable.\n\nWhereas if you are known or believed to own large amounts of BTC, a \nrealistic bad guy\u2019s response to your \u201cdecoy\u201d wallet could be, \u201cI don\u2019t \nbelieve you; and it costs me nothing to keep beating you with rubber \nhose until you tell me the *real* password.\u201d\n\nIt could be worse, too.  In a kidnapping scenario, the bad guys could \nsay, \u201cI don\u2019t believe you.  Hey, I also read Trezor\u2019s website about \n\u2018plausible deniability\u2019.  Now, I will maim your kid for life just to \ntest whether you told me the *real* password.  And if you still don\u2019t \ntell me the real password after you see that little Johnny can no longer \nwalk, then I will kill him.\u201d\n\nThe worst part is that you have no means of proving that you really \n*did* give the real password.  Indeed, it can be proved if you\u2019re lying \nby finding a password which reveals a hidden wallet\u2014but *you* have no \nmeans of affirmatively proving that you are telling the truth!  If the \nbad guys overestimated your riches (or if they\u2019re in a bad mood), then \nlittle Johnny is dead either way.\n\nIn a legalistic scenario, if \u201cauthorities\u201d believe you have 1000 BTC and \nyou only reveal a password for 0.01 BTC, the likely response will not be \nto let you go.  Rather, \u201cYou will now sit in jail until you tell the \n*real* password.\u201d  And again:  You have no means of proving that you did \ngive the real password!\n\n\u201cPlausible deniability\u201d schemes can backfire quite badly.\n\n>Also note how this blog doesn't mention anti-forensics: the wallet \n>software itself may leave traces of the other wallets on the computer.  \n>Have they really audited it sufficiently to be sure this isn't the \n>case?\n\nWhat about data obtained via the network?  I don\u2019t *only* refer to \ndragnet surveillance.  See for but one e.g., Goldfelder, et al., \u201cWhen \nthe cookie meets the blockchain:  Privacy risks of web payments via \ncryptocurrencies\u201d https://arxiv.org/abs/1708.04748  Your identity can be \ntied to your wallet all sorts of ways, any of which could be used to \nprove that you have more Bitcoin than you\u2019re revealing.  Do you know \nwhat databases of cross-correlated analysis data customs agents have \nimmediate access to nowadays\u2014or will, tomorrow?  I don\u2019t.\n\nIn the scenario under discussion, that may not immediately prove \u201cbeyond \na reasonable doubt\u201d that you lied specifically about your Trezor.  But \nit could give plenty of cause to keep you locked up in a small room \nwhile your hard drive is examined for evidence that Trezor apps handled \n*addresses already known to be linked to you*.  Why even bother with \nbruteforce?  Low-hanging fruit abound.\n\n>1) https://blog.trezor.io/hide-your-trezor-wallets-with-multiple-passphrases-f2e0834026eb\n\n-- \nnullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\nBitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n\u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\nNo!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 228 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180112/862e70b3/attachment.sig>"
            },
            {
                "author": "Damian Williamson",
                "date": "2018-01-13T02:11:08",
                "message_text_only": "The same problems exist for users of whole disk encrypted operating systems. Once the device (or, the initial password authentication) is found, the adversary knows that there is something to see. The objective of plausible deniability is to present some acceptable (plausible) alternative while keeping the actual hidden (denied).\n\n\nIf the adversary does not believe you, you do indeed risk everything.\n\n\nRegards,\n\nDamian Williamson\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of nullius via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Friday, 12 January 2018 10:06:33 PM\nTo: Peter Todd; Bitcoin Protocol Discussion\nSubject: [bitcoin-dev] Plausible Deniability (Re: Satoshilabs secret shared private key scheme)\n\nOn 2018-01-12 at 09:50:58 +0000, Peter Todd <pete at petertodd.org> wrote:\n>On Tue, Jan 09, 2018 at 12:43:48PM +0000, Perry Gibson wrote:\n>>>Trezor's \"plausible deniability\" scheme could very well result in you\n>>>going to jail for lying to border security, because it's so easy for\n>>>them to simply brute force alternate passwords based on your seeds.\n>>>With that, they have proof that you lied to customs, a serious\n>>>offense.\n>>The passphrase scheme as I understand it allows a maximum of 50\n>>characters to be used.  Surely even with the HD seed, that search\n>>space is too large to brute force.  Or is there a weakness in the\n>>scheme I haven't clocked?\n>\n>While passphrases *can* be long, most user's aren't going to understand\n>the risk. For example, Trezors blog(1) doesn't make it clear that the\n>passphrases could be bruteforced and used as evidence against you, and\n>even suggests the contrary:  [...quote...]\n\nI despise the term \u201cplausible deniability\u201d; and that\u2019s really the wrong\nterm to use in this discussion.\n\n\u201cPlausible deniability\u201d is a transparent excuse for explaining away an\nindisputable fact which arouses suspicion\u2014when you got some serious\n\u2019splain\u2019 to do.  This is usually used in the context of some pseudolegal\nargument about introducing \u201creasonable doubt\u201d, or even making \u201cprobable\ncause\u201d a wee bit less probable.\n\n\u201cWhy yes, officer:  I was seen carrying an axe down the street near the\nsite of an axe murder, at approximately the time of said axe murder.\nBut I do have a fireplace; so it is plausible that I was simply out\ngathering wood.\u201d\n\nI rather suspect the concept of \u201cplausible deniability\u201d of having been\ninvented by a detective or agent provocateur.  There are few concepts\nmore useful for helping suspects shoot themselves in the foot, or\nfrankly, for entrapping people.\n\nOne of the worst examples I have seen is in discussions of Monero,\nwhereby I\u2019ve seen proponents claim that even under the worst known\nactive attacks, their mix scheme reduces transaction linking to a\nmaximum of 20\u201340% probability.  \u201cThat\u2019s not good enough to convince a\njury!\u201d  No, but it is certainly adequate for investigators to identify\nyou as a person of interest.  Then, your (mis)deeds can be subjected to\npowerful confirmation attacks based on other data; blockchains do not\nexist in isolation.  I usually stay out of such discussions; for I have\nno interest in helping the sorts of people whose greatest concern in\nlife is what story to foist on a jury.\n\nIn the context of devices such as Trezor, what is needed is not\n\u201cplausible deniability\u201d, but rather the ability to obviate any need to\ndeny anything at all.  I must repeat, information does not exist in\nisolation.\n\nIf you are publicly known to be deepy involved in Bitcoin, then nobody\nwill believe that your one-and-only wallet contains only 0.01 BTC.\nThat\u2019s not even \u201cplausible\u201d.  But if you have overall privacy practices\nwhich leave nobody knowing or suspecting that you have any Bitcoin at\nall, then there is nothing to \u201cdeny\u201d; and should a Trezor with\n(supposedly) 0.01 BTC be found in your possession, that\u2019s much better\nthan \u201cplausible\u201d.  It\u2019s completely unremarkable.\n\nWhereas if you are known or believed to own large amounts of BTC, a\nrealistic bad guy\u2019s response to your \u201cdecoy\u201d wallet could be, \u201cI don\u2019t\nbelieve you; and it costs me nothing to keep beating you with rubber\nhose until you tell me the *real* password.\u201d\n\nIt could be worse, too.  In a kidnapping scenario, the bad guys could\nsay, \u201cI don\u2019t believe you.  Hey, I also read Trezor\u2019s website about\n\u2018plausible deniability\u2019.  Now, I will maim your kid for life just to\ntest whether you told me the *real* password.  And if you still don\u2019t\ntell me the real password after you see that little Johnny can no longer\nwalk, then I will kill him.\u201d\n\nThe worst part is that you have no means of proving that you really\n*did* give the real password.  Indeed, it can be proved if you\u2019re lying\nby finding a password which reveals a hidden wallet\u2014but *you* have no\nmeans of affirmatively proving that you are telling the truth!  If the\nbad guys overestimated your riches (or if they\u2019re in a bad mood), then\nlittle Johnny is dead either way.\n\nIn a legalistic scenario, if \u201cauthorities\u201d believe you have 1000 BTC and\nyou only reveal a password for 0.01 BTC, the likely response will not be\nto let you go.  Rather, \u201cYou will now sit in jail until you tell the\n*real* password.\u201d  And again:  You have no means of proving that you did\ngive the real password!\n\n\u201cPlausible deniability\u201d schemes can backfire quite badly.\n\n>Also note how this blog doesn't mention anti-forensics: the wallet\n>software itself may leave traces of the other wallets on the computer.\n>Have they really audited it sufficiently to be sure this isn't the\n>case?\n\nWhat about data obtained via the network?  I don\u2019t *only* refer to\ndragnet surveillance.  See for but one e.g., Goldfelder, et al., \u201cWhen\nthe cookie meets the blockchain:  Privacy risks of web payments via\ncryptocurrencies\u201d https://arxiv.org/abs/1708.04748  Your identity can be\ntied to your wallet all sorts of ways, any of which could be used to\nprove that you have more Bitcoin than you\u2019re revealing.  Do you know\nwhat databases of cross-correlated analysis data customs agents have\nimmediate access to nowadays\u2014or will, tomorrow?  I don\u2019t.\n\nIn the scenario under discussion, that may not immediately prove \u201cbeyond\na reasonable doubt\u201d that you lied specifically about your Trezor.  But\nit could give plenty of cause to keep you locked up in a small room\nwhile your hard drive is examined for evidence that Trezor apps handled\n*addresses already known to be linked to you*.  Why even bother with\nbruteforce?  Low-hanging fruit abound.\n\n>1) https://blog.trezor.io/hide-your-trezor-wallets-with-multiple-passphrases-f2e0834026eb\n\n--\nnullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\nBitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n\u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\nNo!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180113/f8efb9d9/attachment-0001.html>"
            },
            {
                "author": "nullius",
                "date": "2018-01-13T03:44:03",
                "message_text_only": "Preface:  As a longstanding policy, whenever I buy a new hard disk or \ndecommission an old one, I immediately `dd` it from start to end with a \npseudorandom byte stream.  The result is indistinguishable from my disk \nencryption setup, which leaves no apparent on-disk headers.  I don\u2019t do \nthis for \u201cplausibility\u201d reasons, but rather, 0. to assure that \nimmediately upon use, any sectors written with disk encryption cannot be \ndistinguished from unwritten sectors, and 1. to make things overall more \nfun for potential cryptanalysts.  I do realize the small problem that I \ncan\u2019t affirmatively prove any particular disk in my possession to *not* \ncontain decryptable data; and many of them don\u2019t!\n\n(I think that next, I may start writing my disks with headers for LUKS, \nwhich I do not use...)\n\nWhereupon, I challenge plausible deniability designers to `dd` a 6TB \ndisk with pseudorandom bytes, then try walking it across the U.S. border \nuntil it gets searched.  What could possibly go wrong?  Should you be \nordered to decrypt it, the disk *could* be *plausibly* filled with \npseudorandom bytes; and you would not be committing the crime of lying \nto an officer, when you truly state that in fact, it *is* filled with \npseudorandom bytes.\n\nPlease, I want to see this \u201cplausible deniability\u201d theory in action.  \nYou owe it to your users to test the theory empirically, in \ncircumstances in which users have here reported applying it.\n\nNow, in reply:\n\nOn 2018-01-13 at 02:11:08 +0000, Damian Williamson \n<willtech at live.com.au> wrote:\n>The same problems exist for users of whole disk encrypted operating \n>systems. Once the device (or, the initial password authentication) is \n>found, the adversary knows that there is something to see.\n\nOr PGP.  Or in a broader sense, Tor.  Or in the physical world, a \nhigh-security safe bolted to your floor.  Security systems attract \nattention.  Smart people develop appropriate threat models, keep their \nsecurity systems confidential where it is practical to do so (don\u2019t brag \nabout your high-security safe), and work to increase the popularity of \nnetwork security systems (PGP, HTTPS, Tor...) to reduce how much they \nstand out.\n\nIn the context of this discussion, it does help that Bitcoin is becoming \npopular.  It would help much more if Trezors and similar devices were as \ncommonplace as iGadgets.  But when considering the potential threats to \nany specific individual, the only \u201cplausibility\u201d shield is to not seem \nlike someone who is likely to have *much*.  Of course, this is not a \nproblem specific to Bitcoin.  Depending on the threat, the same danger \napplies to owning a substantial amount of gold, cash, or even money in a \nbank.\n\n>The objective of plausible deniability is to present some acceptable \n>(plausible) alternative while keeping the actual hidden (denied).\n>\n>If the adversary does not believe you, you do indeed risk everything.\n\nAnd therein lies the trick.  Unsophisticated adversaries such as common \ncriminals may be fooled, or may not care if they can quickly grab \n*something* of value and run away.  But if your threat model may \npotentially include any adversaries possessed of both brains and \npatience, \u201cplausible deniability\u201d solves nothing.  Such an adversary \nwill not likely be satisfied with the standard of \u201cplausibility\u201d.  More \nlikely, the prevailing standard will be:  \u201cI wasn\u2019t born yesterday, and \nI *know* that you are hiding something.\u201d\n\n>[snip extended prior quotations]\n\n-- \nnullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\nBitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n\u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\nNo!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 228 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180113/31b7f887/attachment.sig>"
            },
            {
                "author": "Peter Todd",
                "date": "2018-01-13T06:11:12",
                "message_text_only": "On Sat, Jan 13, 2018 at 03:44:03AM +0000, nullius via bitcoin-dev wrote:\n> (I think that next, I may start writing my disks with headers for LUKS,\n> which I do not use...)\n> \n> Whereupon, I challenge plausible deniability designers to `dd` a 6TB disk\n> with pseudorandom bytes, then try walking it across the U.S. border until it\n> gets searched.  What could possibly go wrong?  Should you be ordered to\n> decrypt it, the disk *could* be *plausibly* filled with pseudorandom bytes;\n> and you would not be committing the crime of lying to an officer, when you\n> truly state that in fact, it *is* filled with pseudorandom bytes.\n\nIt's very common for disks to be filled with pseudorandom data; this is not\nsuspicious at all. For example:\n\n1) An encrypted partition that is filled, and later reformatted, will be left\nfull of random bytes. Even if you give border security your passphrase, the\nunused space in the encrypted partition will be random data. (an exception\nbeing most - but not all! - SSD's where TRIM has been used)\n\n2) Modern drives (SSD and HD) often implement fast secure erasure with\nencryption, which means that the actual data stored to disk or FLASH is\n*always* encrypted. If such a drive is wiped, the encryption keys are replaced,\nwhich means whatever data was stored becomes random noise (the encrypted data\nis usually not authenticated). This also means that such drives can arrive from\nthe factory filled with random noise.\n\n3) Software disk encryption schemes have the same property: reformatting\nresults in a drive filled with random noise.\n\nThe latter is particularly interesting with LUKS, as you can do all kinds of\nthings like erase the drive with luksErase, while keeping a backup of the LUKS\nheader elsewhere.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180113/d38b1f89/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Plausible Deniability (Re: Satoshilabs secret shared private key scheme)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "nullius",
                "Damian Williamson",
                "Peter Todd"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 19816
        }
    },
    {
        "title": "[bitcoin-dev] Ivy: a higher-level language targeting Bitcoin Script",
        "thread_messages": [
            {
                "author": "Matt Corallo",
                "date": "2018-01-14T22:41:55",
                "message_text_only": "I'm curious if you've considered adding some form of compiler-time enforcement to prevent witness malleability? With that, Ivy could help to resolve for it's users one of the things that can make Bitcoin scripts more complicated to write, instead of simply type-checking and providing a high-level language mapped 1-to-1 with Bitcoin script.\n\nOn December 18, 2017 8:32:17 PM UTC, Daniel Robinson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>Today, we\u2019re releasing Ivy, a prototype higher-level language and\n>development environment for creating custom Bitcoin Script programs.\n>You\n>can see the full announcement here\n><https://blog.chain.com/ivy-for-bitcoin-a-smart-contract-language-that-compiles-to-bitcoin-script-bec06377141a>,\n>or check out the docs <https://docs.ivy-lang.org/bitcoin/> and source\n>code\n><https://github.com/ivy-lang/ivy-bitcoin>.\n>\n>Ivy is a simple smart contract language that can compile to Bitcoin\n>Script.\n>It aims to improve on the useability of Bitcoin Script by adding\n>affordances like named variables and clauses, static (and\n>domain-specific)\n>types, and familiar syntax for function calls.\n>\n>To try out Ivy, you can use the Ivy Playground for Bitcoin\n><https://ivy-lang.org/bitcoin/>, which allows you to create and test\n>simulated contracts in a sandboxed environment.\n>\n>This is prototype software intended for educational and research\n>purposes\n>only. Please don't try to use Ivy to control real or testnet Bitcoins.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180114/530b8a17/attachment.html>"
            },
            {
                "author": "Daniel Robinson",
                "date": "2018-01-15T22:39:05",
                "message_text_only": "Hi Matt,\n\nThanks for raising this. Since the compiler only produces SegWit addresses,\nI hadn't worried at all about malleability, but as you pointed out\nout-of-band, malleability in the length of an argument can allow an\nattacker to deflate the feerate of a transaction.\n\nThere was in fact a minor witness malleability problem with how the\ncompiler was handling clause selection. It's now been fixed in version\n0.0.7 of the compiler.\n\nAs far as I can tell (and I haven't looked all that carefully), any\nsensible Ivy contract won't have any witness malleability problem. (A funny\nexception is the RevealCollision contract, since you can length-extend the\narguments to get another collision. But without a signature check, that one\nhas a more serious transaction malleability problem anyway.) But the\ncompiler currently doesn't prevent you from doing dumb unconstrained stuff\nlike:\n\n```\nclause spend(a: Bytes, b: Bytes, sig: Signature) {\n  verify a == b\n  verify checkSig(publicKey, sig)\n  unlock val\n}\n```\n\nMaybe it should, particularly since there's no reason to include a trivial\ncondition like that anyway. But I think it would probably be about as easy\n(and more generally useful) to build a static analyzer that solved this\nproblem for low-level Bitcoin Script.\n\nOn Sun, Jan 14, 2018 at 5:42 PM Matt Corallo <lf-lists at mattcorallo.com>\nwrote:\n\n> I'm curious if you've considered adding some form of compiler-time\n> enforcement to prevent witness malleability? With that, Ivy could help to\n> resolve for it's users one of the things that can make Bitcoin scripts more\n> complicated to write, instead of simply type-checking and providing a\n> high-level language mapped 1-to-1 with Bitcoin script.\n>\n>\n> On December 18, 2017 8:32:17 PM UTC, Daniel Robinson via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> Today, we\u2019re releasing Ivy, a prototype higher-level language and\n>> development environment for creating custom Bitcoin Script programs. You\n>> can see the full announcement here\n>> <https://blog.chain.com/ivy-for-bitcoin-a-smart-contract-language-that-compiles-to-bitcoin-script-bec06377141a>,\n>> or check out the docs <https://docs.ivy-lang.org/bitcoin/> and source\n>> code <https://github.com/ivy-lang/ivy-bitcoin>.\n>>\n>> Ivy is a simple smart contract language that can compile to Bitcoin\n>> Script. It aims to improve on the useability of Bitcoin Script by adding\n>> affordances like named variables and clauses, static (and domain-specific)\n>> types, and familiar syntax for function calls.\n>>\n>> To try out Ivy, you can use the Ivy Playground for Bitcoin\n>> <https://ivy-lang.org/bitcoin/>, which allows you to create and test\n>> simulated contracts in a sandboxed environment.\n>>\n>> This is prototype software intended for educational and research purposes\n>> only. Please don't try to use Ivy to control real or testnet Bitcoins.\n>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180115/ee189ac5/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Ivy: a higher-level language targeting Bitcoin Script",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Daniel Robinson",
                "Matt Corallo"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 4723
        }
    },
    {
        "title": "[bitcoin-dev] Proposal to reduce mining power bill",
        "thread_messages": [
            {
                "author": "Enrique Ariz\u00f3n Benito",
                "date": "2018-01-15T22:47:54",
                "message_text_only": "Hi all,\n\njust new to the list and curious to know if next proposal (or similar) for\nreducing mining-power consumption has already been discussed.\n\nThe objective is to reduce the power consumption required while keeping the\nnetwork safe and the miners \"motivated\" and cooperative to continue mining:\n\nThe global idea is to introduce the concept of \"next-coinbase\" for miners.\nThis will work something like as follow:\n\n- Any miner submitting a block will submit the \"next-coinbase\" for any new\nblock mined by itself. (This address can be the same one or different from\nthe just mined block). The miner keeps the private key associated with the\n\"next-coinbase\" secret.\n\n- The consensus algorithm will add next checks:\n A hash from, for example, the just mined block and the previous one, will\nhave to match up to N bits for the next \"next-coinbase\" from the next block\nto be valid.\n\n That means that for the next block only 1/2^N bitcoin addresses will be\naccepted from the previously submitted \"next-coinbase\" list.\n\nSince the last previous block hash can be considered random, miners know in\nadvance whether they will be able to participate or not in the next block\ndepending on the just submited \"next-coinbase\". And since the \"punishment\"\nis distributed uniformely random to all miners no one has any advantage\nover the other. But the global miner netwok will consume much less power.\n\nA detail rest: New miners are not allowed in such scheme so next addition\nis needed:\n\n- A miner with no previous \"next-coinbase\" will need to first mine an\nspecial block, \"new-miner-block\", that instead of normal transactions will\nregister the new miner and submit a \"next-coinbase\". This special block\nwill not be rewarded with new bitcoins. The only reward will be the\npermission to mine in following blocks. No reward is applied so only new\nminers wanting to \"enter\" the mining network are expected to create such\nblock.\n\nBest Regards,\n\nE. Ariz\u00f3n Benito\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180115/c70463fc/attachment.html>"
            },
            {
                "author": "nullius",
                "date": "2018-01-16T00:10:38",
                "message_text_only": "On 2018-01-15 at 22:47:54 +0000, Enrique Ariz\u00f3n Benito \n<enrique.arizonbenito at gmail.com> wrote:\n>Hi all,\n>\n>just new to the list and curious to know if next proposal (or similar) \n>for reducing mining-power consumption has already been discussed.\n>\n>The objective is to reduce the power consumption required while keeping \n>the network safe and the miners \"motivated\" and cooperative to continue \n>mining:\n>\n>The global idea is to introduce the concept of \"next-coinbase\" for \n>miners. This will work something like as follow:\n>\n>- Any miner submitting a block will submit the \"next-coinbase\" for any \n>new block mined by itself. (This address can be the same one or \n>different from the just mined block). The miner keeps the private key \n>associated with the \"next-coinbase\" secret.\n>\n>- The consensus algorithm will add next checks:\n> A hash from, for example, the just mined block and the previous one, \n>will have to match up to N bits for the next \"next-coinbase\" from the \n>next block to be valid.\n>\n> That means that for the next block only 1/2^N bitcoin addresses will \n>be accepted from the previously submitted \"next-coinbase\" list.\n>\n>Since the last previous block hash can be considered random, miners \n>know in advance whether they will be able to participate or not in the \n>next block depending on the just submited \"next-coinbase\". And since \n>the \"punishment\" is distributed uniformely random to all miners no one \n>has any advantage over the other. But the global miner netwok will \n>consume much less power.\n>\n>A detail rest: New miners are not allowed in such scheme so next \n>addition is needed:\n>\n>- A miner with no previous \"next-coinbase\" will need to first mine an \n>special block, \"new-miner-block\", that instead of normal transactions \n>will register the new miner and submit a \"next-coinbase\". This special \n>block will not be rewarded with new bitcoins. The only reward will be \n>the permission to mine in following blocks. No reward is applied so \n>only new miners wanting to \"enter\" the mining network are expected to \n>create such block.\n\nObservation:  This totally destroys Bitcoin\u2019s transaction-ordering \nsecurity.  A \u201c51% attack\u201d could be executed by any miner who has >50% of \nthe hashpower *proportionate to miners who are allowed to mine a \nparticular block*, rather than >50% of *global* hashpower.  (I infer \nthat this could be done retroactively, and wave my hands over some of \nthe details since you did not talk about reorgs.)  The same applies as \nfor attacks requiring 33% or 25% of total hashpower.\n\nPotential attack, assuming that N *must* be based partly or wholly on \nthe existing set of \u201cnext-coinbase\u201d addresses:  A large miner could \ngradually push N higher, by progressively committing new \u201cnext-coinbase\u201d \naddresses which differ in the next bit for all previously seen \ncombinations of bits.  Large miners would have a vast advantage over \nsmall miners, insofar as deliberately incrementing N by one more bit \ncould only be done by a miner who creates 2^(N+1) blocks (= 2 * 2^N).  \nBy such means, it may be possible for a very large miner to eventually \nlock out all other miners altogether, and monopolize all Bitcoin mining.\n\nNow, questions:\n\nHow is N determined?  By a wave of the hands?\n\nWhat part of which block hash is matched against N bits?  You were quite \nunclear about this, and other important details.  (Much of what I say \nhere is based on assumptions and inferences necessary to fill in the \nblanks.)\n\nHow, exactly, are reorgs handled?\n\nHow does this interact with the difficulty adjustment algorithm?  \nIndeed, how is difficulty determined at all under your scheme?\n\nWhat happens to coinbase fees from a \u201cnew-miner-block\u201d?  The way I read \nyour scheme, the \u201cnew-miner-block\u201d must necessarily have no payout \nwhatsoever.  But you discuss only \u201cnew bitcoins\u201d, which are a \ndiminishing portion of the block reward, and will eventually reach zero.  \nCoinbase from fees must go somewhere; but under your scheme, a \u201cnew \nminer\u201d has no payable address.\n\nWhat if no existing \u201cnext-coinbase\u201d address matches?  Is N constrained \nto be sufficiently short that a match is guaranteed from the existing \nset, then that makes it trivial for large mining farms to collect \naddresses and further dominate (or even monopolize) the network in the \nattack described above.  If it isn\u2019t, then the network could suddenly \nhalt when nobody is allowed to mine the next block; and that would \nenable *this* attack:\n\nWhat stops a malicious miner (including a \u201cnew miner\u201d creating a \n\u201cnew-miner block\u201d) from deliberately working to create a block with a \nhash which does not have N bits matching any of the existing \n\u201cnext-coinbase\u201d addresses?  Contra what you say, block hashes can\u2019t be \n\u201cconsidered random\u201d.  Indeed, partial preimage bruteforcing of block \nhashes is the entire basis of mining POW.\n\nAsking here more generally than as for the attack described above, what \nstops mining farms with large hashpower from submitting many different \n\u201cnext-coinbase\u201d addresses in many different blocks?  If N be small, then \nit should be feasible for a large mining farm to eventually register a \nset of \u201cnext-coinbase\u201d addresses which match any N.  **This increases \nmining centralization.**  If N be large, then this creates the \npossibility (or raises the probability) that no address will match, and \nnobody will be allowed to mine the next block.\n\nHow could miner anonymity be preserved under a scheme whereby each \n\u201cnext-coinbase\u201d address can be linked to a previous \u201cnext-coinbase\u201d \naddress?  The only way to start fresh would be with a prohibitively \nexpensive no-payout block.  Mining can be totally anonymous at present, \nand must so remain.  Miners are only identified by certain information \nthey choose to put in a block header, which they could choose to change \nor omit\u2014or by IP address, which is trivially changed and is never a \nreliable identifier.\n\nHow does this even save electricity, when there is much mining equipment \n(especially on large mining farms) which cannot be easily shut down and \nrestarted?  (Allegedly, this is one reason why some big miners \noccasionally mine empty blocks.)  Though I suppose that difficulty would \ndrop by unspecified means.\n\nFurther observations:\n\nThis scheme drastically increases the upfront investment required for a \nnew miner to start mining.  To mine even one new block all by oneself, \nwithout a pool, already requires a huge investment.  Add to that the \nuncompensated energy cost of mining that first block with *no* payout, \nand I expect that the bar would be prohibitive to almost all new \nentrants.  Mining costs and incentives are delicately balanced by the \ndesign of the network.  Whereas incumbents are much favoured by your \nscheme, further increasing miner centralization.  Large incumbents could \nalso use this to produce a mining permissions market, by selling the \nprivate keys to committed \u201cnext-coinbase\u201d addresses.\n\nI have not even tried to imagine what oddball attacks might be possible \nfor any miner with sufficient hashpower to deliberately cause a small \nreorg.\n\n-- \nnullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\nBitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n\u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\nNo!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 228 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180116/7325d4d4/attachment-0001.sig>"
            },
            {
                "author": "Enrique Ariz\u00f3n Benito",
                "date": "2018-01-17T22:34:11",
                "message_text_only": "Thanks \"nullius\" for your remarks. Notice my first post was not an RFC but\njust a blur idea to inspect if something similar had already been discussed\nin the group. In fact your post has helped me a lot to improve my first\nmail.\n\n> Observation:  This totally destroys Bitcoin\u2019s transaction-ordering\nsecurity.  A \u201c51% attack\u201d could be executed by any miner who has >50% of\nthe hashpower *proportionate to miners who are allowed to mine a particular\nblock*, rather than >50% of *global* hashpower.  (I infer that this could\nbe done retroactively, and wave my hands over some of the details since you\ndid not talk about reorgs.)  The same applies as for attacks requiring 33%\nor 25% of total hashpower.\n\nI'm not sure what you are referring to in this paragraph. Imagine for\nexample that there are a total of, let's say, 2^10 available\nnext-coinbase/miners and the algorithm just allow 50% or 2^9 of them to\nmine, \u00bfhow could it be possible that one among them could have 51% of power\nby chance? (Please, read comments bellow before replying)\n\n> Potential attack, assuming that N *must* be based partly or wholly on the\nexisting set of \u201cnext-coinbase\u201d addresses:  A large miner could gradually\npush N higher, by progressively committing new \u201cnext-coinbase\u201d addresses\nwhich differ in the next bit for all previously seen combinations of bits.\nLarge miners would have a vast advantage over small miners, insofar as\ndeliberately incrementing N by one more bit could only be done by a miner\nwho creates 2^(N+1) blocks (= 2 * 2^N).  By such means, it may be possible\nfor a very large miner to eventually lock out all other miners altogether,\nand monopolize all Bitcoin mining.\n\nI do not think it would be easy even for a large miner but that made me\nthink for an alternative algorithm. Let's introduce the concept of \"spent\"\nnext-coinbase versus \"un-spent\" one, something like similarly to UTXO. A\nnext-coinbase would only be valid if it has not been previously used to\nmine a block. Simplifying, with the spent vs unspent a large miner is\nrestricted to a single next-coinbase as anyone else. Being more precise\nit's allowed a single next-coinbase for each mined new-miner-block mined\ncreating a \"thread\" of mining blocks for each new new-miner-block.\nSchematically a thread would look like:\nnew-miner-block:next-coinbase_1 -> mined-block:next-coinbase_2 ->  ... ->\n(thread expired - see comment below about expiration)\n\nIn this case a large miner A with T times more power than another one B\ncould potentially spent mining power to create T parallel threads for each\nthread created by miner B. A solution that could fix this issue is to allow\na maximum life time for each thread expressed in number of blocks. After a\ngiven number of blocks have being mined the miner is forced to create new\nnew-miner-block to continue participating. The algorithm to choose the\nlife-time must be such that if a miner tries to create many parallel\nthreads (many new-miner-block), by the time it start mining transaction\nblocks the first new-miner-block will start to expire, so he will be\npunished.\n\nIf the famous phrase \"a degree of indirection solve all programming\nproblems\" I think this is an example applied to blockchain. First the\nconsensus chooses who can participate in the next round, then selected\nminers participate in the round.\n\n\n> Now, questions:\n>\n> How is N determined?  By a wave of the hands?\n>\n\nGreat question. I left it unspecified in the first mail. An algorithm comes\nto my mind (You are welcome to propose others). Let's imagine the list of\nregistered non-expired next-coinbase addresses  is 2^10. The consensus\nchecks that for N=1 there is *about* 1/2^N == 1/2 of unspent next-coinbase\naddresses that match (it must be close to 1/2 of the total 2^10 addresses\nwith maybe an small +/- 1% statistical deviation). Then N=1 will be\naccepted. Check now for N=2. If there are 1/(2^N) = 1/4 next-coinbase\naddresses matching then N=2 is accepted. The algorithm continues until some\n\"++N\" fails. Initially N=0 and so all miners are welcome to the game. They\nall will start producing next-coinbase addresses and when there are enough\ndifferent ones N will become 1, then 2, ... This system will will keep an\nequilibrium naturally. If new miners stop producing new new-miner-blocks,\neventually the threads will expire and N will be automatically be\ndecreased. Miners will act rationally to keep enough threads open in their\nown interest since that will decrease the electricity bill.\n\n> What part of which block hash is matched against N bits?  You were quite\nunclear about this, and other important details.  (Much of what I say here\nis based on assumptions and inferences necessary to fill in the blanks.)\n\nThinking about it, the hash must run over \"many\" different blocks and it\nmust include the next next-coinbase (to force calculating the hash after\nchoosing a next-coinbase). Since it's not expected that many blocks are\nmined by the same miner in a row (maybe no more than 2 o 3) the \"many\"\nnumber must be for example twice as much as the expected maximum numbers of\nblocks that a large miner can mine in average.\n\n> How, exactly, are reorgs handled?\nI think reorgs are not affected by this algorithm. The next-coinbase\nobjective is just to randomly choose which miner will be allowed for the\nnext round.\n\n> How does this interact with the difficulty adjustment algorithm?  Indeed,\nhow is difficulty determined at all under your scheme?\nAs I see it, if the network wants to keep the same pace of new blocks each\nN seconds, and N=1 (only half of the miners are allowed to mine)  then\ndifficulty/power-bill is lowered by two, for N=2 by 4, ...\n\n> What happens to coinbase fees from a \u201cnew-miner-block\u201d?  The way I read\nyour scheme, the \u201cnew-miner-block\u201d must necessarily have no payout\nwhatsoever.  But you discuss only \u201cnew bitcoins\u201d,which are a diminishing\nportion of the block reward, and will eventually reach zero.  Coinbase from\nfees must go somewhere; but under your scheme, a \u201cnew miner\u201d has no payable\naddress.\n\nThis new-miner-block will have NO transactions inside.\n\n> What if no existing \u201cnext-coinbase\u201d address matches?  Is N constrained to\nbe sufficiently short that a match is guaranteed from the existing set,\nthen that makes it trivial for large mining farms to collect addresses and\nfurther dominate (or even monopolize) the network in the attack described\nabove.  If it isn\u2019t, then the network could suddenly halt when nobody is\nallowed to mine the next block; and that would enable *this* attack:\n\nI think the previous algorithm I mention to replace the \"wave of hands\"\n(test N=1, then N=2,... ) plus the \"expiring threads\" would suffice to fix\nit.\n\n>  What stops a malicious miner (including a \u201cnew miner\u201d creating a\n\u201cnew-miner block\u201d) from deliberately working to create a block with a hash\nwhich does not have N bits matching any of the existing \u201cnext-coinbase\u201d\naddresses?  Contra what you say, block hashes can\u2019t be \u201cconsidered\nrandom\u201d.  Indeed, partial preimage bruteforcing of block hashes is the\nentire basis of mining POW.\n\nAgain, that is fixed by the previous algorithm\n\n\n> Asking here more generally than as for the attack described above, what\nstops mining farms with large hashpower from submitting many different\n\u201cnext-coinbase\u201d addresses in many different blocks?  If N be small, then it\nshould be feasible for a large mining farm to eventually register a set of\n\u201cnext-coinbase\u201d addresses which match any N.  **This increases mining\ncentralization.**  If N be large, then this creates the possibility (or\nraises the probability) that no address will match, and nobody will be\nallowed to mine the next block.\n\nFixed by the expiring thread model?\n\n\n> How could miner anonymity be preserved under a scheme whereby each\n> \u201cnext-coinbase\u201d address can be linked to a previous \u201cnext-coinbase\u201d\n> address?  The only way to start fresh would be with a prohibitively\n> expensive no-payout block.  Mining can be totally anonymous at present, and\n> must so remain.  Miners are only identified by certain information they\n> choose to put in a block header, which they could choose to change or\n> omit\u2014or by IP address, which is trivially changed and is never a reliable\n> identifier.\n>\n> The anonymity decreases in the sense that if you know a next-coinbase\naddress owner you know all its related next-coinbase for the expiring\n(physical-time-limited) thread. The anonymity increases in the sense that\nminer will consume fewer energy. Electricity bill is the easiest way today\nto trace miners.\n\n > How does this even save electricity, when there is much mining equipment\n(especially on large mining farms) which cannot be easily shut down and\nrestarted?  (Allegedly, this is one reason why some big miners occasionally\nmine empty blocks.)  Though I suppose that difficulty would drop by\nunspecified means.\n\nAs explained above, the difficulty is reduced by 1/2^N for each round. And\nof course, miners that want to save more energy will have to adapt to put\ntheir systems on stand-by while they  are not chosen for the next round. I\nthink based on my limited experience with ASIC mining that just by not\nsending new orders to the miner the power comsumption will decrease\ndramatically even if the equipment is still on.\n\n>\n> Further observations:\n>\n> This scheme drastically increases the upfront investment required for a\n> new miner to start mining.  To mine even one new block all by oneself,\n> without a pool, already requires a huge investment.\n\n\nOnce introduced the concept of \"expiring\" thread I think he will be pretty\nmuch in the same condition. To obtain bitcoins he will first need to mine a\nnew-miner-block to enter the game and then an standard block before the\nthread expires. Notice the expire time/block-length start just after the\nnew-miner-block has been mined so the probabilities to mine before the\nexpiration time will be proportional to its mining power, as for everyone\nelse.\n\n> Add to that the uncompensated energy cost of mining that first block with\n*no* payout,\n\nI think it could be clearly compensated by the save in energy for standards\nblocks.\n\n>and I expect that the bar would be prohibitive to almost all new\nentrants.Mining costs and incentives are delicately balanced by the design\nof the network.  Whereas incumbents are much favoured by your scheme,\nfurther increasing miner centralization.\n\nI don't think so after the new fixes. What do you think? My opinion is\nthat, based on the \"theory of games\", miners acting in their own interest\nwill try to maximize \"N\".\n\n> Large incumbents could also use this to produce a mining permissions\nmarket, by selling the private keys to committed \u201cnext-coinbase\u201d\naddresses.\n\nWith the addition of thread expiration, nobody will be really motivated to\nshell/buy \"next-coinbase\" addresses since their utility is limited.\n\nJust a remark: Notice this algorithm reduces the electricity bill, but the\nhardware needed stays the same, since for each round the miner participates\nin, it will try to mine as fast as possible and so use as much hardware as\npossible. No reduction costs are expected in hardware.\n\n\nBest Regards,\n\nEnrique Ariz\u00f3n Benito\n\n\n\nI have not even tried to imagine what oddball attacks might be possible for\n> any miner with sufficient hashpower to deliberately cause a small reorg.\n\n\n> --\n> nullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\n> Bitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n> 3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n> \u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\n> No!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180117/134c366d/attachment-0001.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2018-01-18T05:22:47",
                "message_text_only": "The energy cost of mining cannot be reduced, nor is it rational to consider it \u201ctoo high\u201d.\n\ne\n\n> On Jan 18, 2018, at 06:34, Enrique Ariz\u00f3n Benito via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Thanks \"nullius\" for your remarks. Notice my first post was not an RFC but just a blur idea to inspect if something similar had already been discussed in the group. In fact your post has helped me a lot to improve my first mail.\n> \n> > Observation:  This totally destroys Bitcoin\u2019s transaction-ordering security.  A \u201c51% attack\u201d could be executed by any miner who has >50% of the hashpower *proportionate to miners who are allowed to mine a particular block*, rather than >50% of *global* hashpower.  (I infer that this could be done retroactively, and wave my hands over some of the details since you did not talk about reorgs.)  The same applies as for attacks requiring 33% or 25% of total hashpower. \n> \n> I'm not sure what you are referring to in this paragraph. Imagine for example that there are a total of, let's say, 2^10 available next-coinbase/miners and the algorithm just allow 50% or 2^9 of them to mine, \u00bfhow could it be possible that one among them could have 51% of power by chance? (Please, read comments bellow before replying)\n> \n> > Potential attack, assuming that N *must* be based partly or wholly on the existing set of \u201cnext-coinbase\u201d addresses:  A large miner could gradually push N higher, by progressively committing new \u201cnext-coinbase\u201d addresses which differ in the next bit for all previously seen combinations of bits. Large miners would have a vast advantage over small miners, insofar as deliberately incrementing N by one more bit could only be done by a miner who creates 2^(N+1) blocks (= 2 * 2^N).  By such means, it may be possible for a very large miner to eventually lock out all other miners altogether, and monopolize all Bitcoin mining.\n> \n> I do not think it would be easy even for a large miner but that made me think for an alternative algorithm. Let's introduce the concept of \"spent\" next-coinbase versus \"un-spent\" one, something like similarly to UTXO. A next-coinbase would only be valid if it has not been previously used to mine a block. Simplifying, with the spent vs unspent a large miner is restricted to a single next-coinbase as anyone else. Being more precise it's allowed a single next-coinbase for each mined new-miner-block mined creating a \"thread\" of mining blocks for each new new-miner-block. Schematically a thread would look like: \n> new-miner-block:next-coinbase_1 -> mined-block:next-coinbase_2 ->  ... -> (thread expired - see comment below about expiration)\n> \n> In this case a large miner A with T times more power than another one B could potentially spent mining power to create T parallel threads for each thread created by miner B. A solution that could fix this issue is to allow a maximum life time for each thread expressed in number of blocks. After a given number of blocks have being mined the miner is forced to create new new-miner-block to continue participating. The algorithm to choose the life-time must be such that if a miner tries to create many parallel threads (many new-miner-block), by the time it start mining transaction blocks the first new-miner-block will start to expire, so he will be punished.\n> \n> If the famous phrase \"a degree of indirection solve all programming problems\" I think this is an example applied to blockchain. First the consensus chooses who can participate in the next round, then selected miners participate in the round.\n>  \n>> Now, questions:\n>> \n>> How is N determined?  By a wave of the hands?\n> \n> Great question. I left it unspecified in the first mail. An algorithm comes to my mind (You are welcome to propose others). Let's imagine the list of registered non-expired next-coinbase addresses  is 2^10. The consensus checks that for N=1 there is *about* 1/2^N == 1/2 of unspent next-coinbase addresses that match (it must be close to 1/2 of the total 2^10 addresses with maybe an small +/- 1% statistical deviation). Then N=1 will be accepted. Check now for N=2. If there are 1/(2^N) = 1/4 next-coinbase addresses matching then N=2 is accepted. The algorithm continues until some \"++N\" fails. Initially N=0 and so all miners are welcome to the game. They all will start producing next-coinbase addresses and when there are enough different ones N will become 1, then 2, ... This system will will keep an equilibrium naturally. If new miners stop producing new new-miner-blocks, eventually the threads will expire and N will be automatically be decreased. Miners will act rationally to keep enough threads open in their own interest since that will decrease the electricity bill.\n> \n> > What part of which block hash is matched against N bits?  You were quite unclear about this, and other important details.  (Much of what I say here is based on assumptions and inferences necessary to fill in the blanks.)\n> \n> Thinking about it, the hash must run over \"many\" different blocks and it must include the next next-coinbase (to force calculating the hash after choosing a next-coinbase). Since it's not expected that many blocks are mined by the same miner in a row (maybe no more than 2 o 3) the \"many\" number must be for example twice as much as the expected maximum numbers of blocks that a large miner can mine in average.\n>  \n> > How, exactly, are reorgs handled?\n> I think reorgs are not affected by this algorithm. The next-coinbase objective is just to randomly choose which miner will be allowed for the next round.\n>  \n> > How does this interact with the difficulty adjustment algorithm?  Indeed, how is difficulty determined at all under your scheme?\n> As I see it, if the network wants to keep the same pace of new blocks each N seconds, and N=1 (only half of the miners are allowed to mine)  then difficulty/power-bill is lowered by two, for N=2 by 4, ...\n> \n> > What happens to coinbase fees from a \u201cnew-miner-block\u201d?  The way I read your scheme, the \u201cnew-miner-block\u201d must necessarily have no payout whatsoever.  But you discuss only \u201cnew bitcoins\u201d,which are a diminishing portion of the block reward, and will eventually reach zero.  Coinbase from fees must go somewhere; but under your scheme, a \u201cnew miner\u201d has no payable address.\n> \n> This new-miner-block will have NO transactions inside.\n> \n> > What if no existing \u201cnext-coinbase\u201d address matches?  Is N constrained to be sufficiently short that a match is guaranteed from the existing set, then that makes it trivial for large mining farms to collect addresses and further dominate (or even monopolize) the network in the attack described above.  If it isn\u2019t, then the network could suddenly halt when nobody is allowed to mine the next block; and that would enable *this* attack:\n> \n> I think the previous algorithm I mention to replace the \"wave of hands\" (test N=1, then N=2,... ) plus the \"expiring threads\" would suffice to fix it.\n> \n> >  What stops a malicious miner (including a \u201cnew miner\u201d creating a \u201cnew-miner block\u201d) from deliberately working to create a block with a hash which does not have N bits matching any of the existing \u201cnext-coinbase\u201d addresses?  Contra what you say, block hashes can\u2019t be \u201cconsidered random\u201d.  Indeed, partial preimage bruteforcing of block hashes is the entire basis of mining POW.\n> \n> Again, that is fixed by the previous algorithm\n> \n> \n> > Asking here more generally than as for the attack described above, what stops mining farms with large hashpower from submitting many different \u201cnext-coinbase\u201d addresses in many different blocks?  If N be small, then it should be feasible for a large mining farm to eventually register a set of \u201cnext-coinbase\u201d addresses which match any N.  **This increases mining centralization.**  If N be large, then this creates the possibility (or raises the probability) that no address will match, and nobody will be allowed to mine the next block.\n> \n> Fixed by the expiring thread model?\n>  \n>> How could miner anonymity be preserved under a scheme whereby each \u201cnext-coinbase\u201d address can be linked to a previous \u201cnext-coinbase\u201d address?  The only way to start fresh would be with a prohibitively expensive no-payout block.  Mining can be totally anonymous at present, and must so remain.  Miners are only identified by certain information they choose to put in a block header, which they could choose to change or omit\u2014or by IP address, which is trivially changed and is never a reliable identifier.\n>> \n> The anonymity decreases in the sense that if you know a next-coinbase address owner you know all its related next-coinbase for the expiring (physical-time-limited) thread. The anonymity increases in the sense that miner will consume fewer energy. Electricity bill is the easiest way today to trace miners.\n> \n>  > How does this even save electricity, when there is much mining equipment (especially on large mining farms) which cannot be easily shut down and restarted?  (Allegedly, this is one reason why some big miners occasionally mine empty blocks.)  Though I suppose that difficulty would drop by unspecified means.\n> \n> As explained above, the difficulty is reduced by 1/2^N for each round. And of course, miners that want to save more energy will have to adapt to put their systems on stand-by while they  are not chosen for the next round. I think based on my limited experience with ASIC mining that just by not sending new orders to the miner the power comsumption will decrease dramatically even if the equipment is still on.\n>> \n>> Further observations:\n>> \n>> This scheme drastically increases the upfront investment required for a new miner to start mining.  To mine even one new block all by oneself, without a pool, already requires a huge investment. \n>  \n> Once introduced the concept of \"expiring\" thread I think he will be pretty much in the same condition. To obtain bitcoins he will first need to mine a new-miner-block to enter the game and then an standard block before the thread expires. Notice the expire time/block-length start just after the new-miner-block has been mined so the probabilities to mine before the expiration time will be proportional to its mining power, as for everyone else.  \n>  \n> > Add to that the uncompensated energy cost of mining that first block with *no* payout,\n> \n> I think it could be clearly compensated by the save in energy for standards blocks.\n> \n> >and I expect that the bar would be prohibitive to almost all new entrants.Mining costs and incentives are delicately balanced by the design of the network.  Whereas incumbents are much favoured by your scheme, further increasing miner centralization.\n> \n> I don't think so after the new fixes.  What do you think? My opinion is that, based on the \"theory of games\", miners acting in their own interest will try to maximize \"N\". \n>   \n> > Large incumbents could also use this to produce a mining permissions market, by selling the  private keys to committed \u201cnext-coinbase\u201d addresses.  \n> \n> With the addition of thread expiration, nobody will be really motivated to shell/buy \"next-coinbase\" addresses since their utility is limited.\n> \n> Just a remark: Notice this algorithm reduces the electricity bill, but the hardware needed stays the same, since for each round the miner participates in, it will try to mine as fast as possible and so use as much hardware as possible. No reduction costs are expected in hardware.\n> \n> \n> Best Regards,\n> \n> Enrique Ariz\u00f3n Benito\n> \n> \n> \n>> I have not even tried to imagine what oddball attacks might be possible for any miner with sufficient hashpower to deliberately cause a small reorg. \n>> \n>> -- \n>> nullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\n>> Bitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n>> 3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n>> \u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\n>> No!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n> \n> \n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180118/d2a32353/attachment-0001.html>"
            },
            {
                "author": "Damian Williamson",
                "date": "2018-01-18T08:24:40",
                "message_text_only": "It probably could be noted, although it is well known, pools, in some views, act as one large individual miner, not just when separately considering the actions of pools.\n\n\nGiven the operation of pools, would a pool be required to mine the new-miner-blocks, or would you propose operation in a pool be restricted individually? How would this operate?\n\n\nRegards,\n\nDamian Williamson\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Enrique Ariz\u00f3n Benito via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Thursday, 18 January 2018 9:34:11 AM\nTo: nullius at nym.zone; bitcoin-dev at lists.linuxfoundation.org\nSubject: Re: [bitcoin-dev] Proposal to reduce mining power bill\n\nThanks \"nullius\" for your remarks. Notice my first post was not an RFC but just a blur idea to inspect if something similar had already been discussed in the group. In fact your post has helped me a lot to improve my first mail.\n\n> Observation:  This totally destroys Bitcoin\u2019s transaction-ordering security.  A \u201c51% attack\u201d could be executed by any miner who has >50% of the hashpower *proportionate to miners who are allowed to mine a particular block*, rather than >50% of *global* hashpower.  (I infer that this could be done retroactively, and wave my hands over some of the details since you did not talk about reorgs.)  The same applies as for attacks requiring 33% or 25% of total hashpower.\n\nI'm not sure what you are referring to in this paragraph. Imagine for example that there are a total of, let's say, 2^10 available next-coinbase/miners and the algorithm just allow 50% or 2^9 of them to mine, \u00bfhow could it be possible that one among them could have 51% of power by chance? (Please, read comments bellow before replying)\n\n> Potential attack, assuming that N *must* be based partly or wholly on the existing set of \u201cnext-coinbase\u201d addresses:  A large miner could gradually push N higher, by progressively committing new \u201cnext-coinbase\u201d addresses which differ in the next bit for all previously seen combinations of bits. Large miners would have a vast advantage over small miners, insofar as deliberately incrementing N by one more bit could only be done by a miner who creates 2^(N+1) blocks (= 2 * 2^N).  By such means, it may be possible for a very large miner to eventually lock out all other miners altogether, and monopolize all Bitcoin mining.\n\nI do not think it would be easy even for a large miner but that made me think for an alternative algorithm. Let's introduce the concept of \"spent\" next-coinbase versus \"un-spent\" one, something like similarly to UTXO. A next-coinbase would only be valid if it has not been previously used to mine a block. Simplifying, with the spent vs unspent a large miner is restricted to a single next-coinbase as anyone else. Being more precise it's allowed a single next-coinbase for each mined new-miner-block mined creating a \"thread\" of mining blocks for each new new-miner-block. Schematically a thread would look like:\nnew-miner-block:next-coinbase_1 -> mined-block:next-coinbase_2 ->  ... -> (thread expired - see comment below about expiration)\n\nIn this case a large miner A with T times more power than another one B could potentially spent mining power to create T parallel threads for each thread created by miner B. A solution that could fix this issue is to allow a maximum life time for each thread expressed in number of blocks. After a given number of blocks have being mined the miner is forced to create new new-miner-block to continue participating. The algorithm to choose the life-time must be such that if a miner tries to create many parallel threads (many new-miner-block), by the time it start mining transaction blocks the first new-miner-block will start to expire, so he will be punished.\n\nIf the famous phrase \"a degree of indirection solve all programming problems\" I think this is an example applied to blockchain. First the consensus chooses who can participate in the next round, then selected miners participate in the round.\n\nNow, questions:\n\nHow is N determined?  By a wave of the hands?\n\nGreat question. I left it unspecified in the first mail. An algorithm comes to my mind (You are welcome to propose others). Let's imagine the list of registered non-expired next-coinbase addresses  is 2^10. The consensus checks that for N=1 there is *about* 1/2^N == 1/2 of unspent next-coinbase addresses that match (it must be close to 1/2 of the total 2^10 addresses with maybe an small +/- 1% statistical deviation). Then N=1 will be accepted. Check now for N=2. If there are 1/(2^N) = 1/4 next-coinbase addresses matching then N=2 is accepted. The algorithm continues until some \"++N\" fails. Initially N=0 and so all miners are welcome to the game. They all will start producing next-coinbase addresses and when there are enough different ones N will become 1, then 2, ... This system will will keep an equilibrium naturally. If new miners stop producing new new-miner-blocks, eventually the threads will expire and N will be automatically be decreased. Miners will act rationally to keep enough threads open in their own interest since that will decrease the electricity bill.\n\n> What part of which block hash is matched against N bits?  You were quite unclear about this, and other important details.  (Much of what I say here is based on assumptions and inferences necessary to fill in the blanks.)\n\nThinking about it, the hash must run over \"many\" different blocks and it must include the next next-coinbase (to force calculating the hash after choosing a next-coinbase). Since it's not expected that many blocks are mined by the same miner in a row (maybe no more than 2 o 3) the \"many\" number must be for example twice as much as the expected maximum numbers of blocks that a large miner can mine in average.\n\n> How, exactly, are reorgs handled?\nI think reorgs are not affected by this algorithm. The next-coinbase objective is just to randomly choose which miner will be allowed for the next round.\n\n> How does this interact with the difficulty adjustment algorithm?  Indeed, how is difficulty determined at all under your scheme?\nAs I see it, if the network wants to keep the same pace of new blocks each N seconds, and N=1 (only half of the miners are allowed to mine)  then difficulty/power-bill is lowered by two, for N=2 by 4, ...\n\n> What happens to coinbase fees from a \u201cnew-miner-block\u201d?  The way I read your scheme, the \u201cnew-miner-block\u201d must necessarily have no payout whatsoever.  But you discuss only \u201cnew bitcoins\u201d,which are a diminishing portion of the block reward, and will eventually reach zero.  Coinbase from fees must go somewhere; but under your scheme, a \u201cnew miner\u201d has no payable address.\n\nThis new-miner-block will have NO transactions inside.\n\n> What if no existing \u201cnext-coinbase\u201d address matches?  Is N constrained to be sufficiently short that a match is guaranteed from the existing set, then that makes it trivial for large mining farms to collect addresses and further dominate (or even monopolize) the network in the attack described above.  If it isn\u2019t, then the network could suddenly halt when nobody is allowed to mine the next block; and that would enable *this* attack:\n\nI think the previous algorithm I mention to replace the \"wave of hands\" (test N=1, then N=2,... ) plus the \"expiring threads\" would suffice to fix it.\n\n>  What stops a malicious miner (including a \u201cnew miner\u201d creating a \u201cnew-miner block\u201d) from deliberately working to create a block with a hash which does not have N bits matching any of the existing \u201cnext-coinbase\u201d addresses?  Contra what you say, block hashes can\u2019t be \u201cconsidered random\u201d.  Indeed, partial preimage bruteforcing of block hashes is the entire basis of mining POW.\n\nAgain, that is fixed by the previous algorithm\n\n\n> Asking here more generally than as for the attack described above, what stops mining farms with large hashpower from submitting many different \u201cnext-coinbase\u201d addresses in many different blocks?  If N be small, then it should be feasible for a large mining farm to eventually register a set of \u201cnext-coinbase\u201d addresses which match any N.  **This increases mining centralization.**  If N be large, then this creates the possibility (or raises the probability) that no address will match, and nobody will be allowed to mine the next block.\n\nFixed by the expiring thread model?\n\nHow could miner anonymity be preserved under a scheme whereby each \u201cnext-coinbase\u201d address can be linked to a previous \u201cnext-coinbase\u201d address?  The only way to start fresh would be with a prohibitively expensive no-payout block.  Mining can be totally anonymous at present, and must so remain.  Miners are only identified by certain information they choose to put in a block header, which they could choose to change or omit\u2014or by IP address, which is trivially changed and is never a reliable identifier.\n\nThe anonymity decreases in the sense that if you know a next-coinbase address owner you know all its related next-coinbase for the expiring (physical-time-limited) thread. The anonymity increases in the sense that miner will consume fewer energy. Electricity bill is the easiest way today to trace miners.\n\n > How does this even save electricity, when there is much mining equipment (especially on large mining farms) which cannot be easily shut down and restarted?  (Allegedly, this is one reason why some big miners occasionally mine empty blocks.)  Though I suppose that difficulty would drop by unspecified means.\n\nAs explained above, the difficulty is reduced by 1/2^N for each round. And of course, miners that want to save more energy will have to adapt to put their systems on stand-by while they  are not chosen for the next round. I think based on my limited experience with ASIC mining that just by not sending new orders to the miner the power comsumption will decrease dramatically even if the equipment is still on.\n\nFurther observations:\n\nThis scheme drastically increases the upfront investment required for a new miner to start mining.  To mine even one new block all by oneself, without a pool, already requires a huge investment.\n\nOnce introduced the concept of \"expiring\" thread I think he will be pretty much in the same condition. To obtain bitcoins he will first need to mine a new-miner-block to enter the game and then an standard block before the thread expires. Notice the expire time/block-length start just after the new-miner-block has been mined so the probabilities to mine before the expiration time will be proportional to its mining power, as for everyone else.\n\n> Add to that the uncompensated energy cost of mining that first block with *no* payout,\n\nI think it could be clearly compensated by the save in energy for standards blocks.\n\n>and I expect that the bar would be prohibitive to almost all new entrants.Mining costs and incentives are delicately balanced by the design of the network.  Whereas incumbents are much favoured by your scheme, further increasing miner centralization.\n\nI don't think so after the new fixes. What do you think? My opinion is that, based on the \"theory of games\", miners acting in their own interest will try to maximize \"N\".\n\n> Large incumbents could also use this to produce a mining permissions market, by selling the private keys to committed \u201cnext-coinbase\u201d addresses.\n\nWith the addition of thread expiration, nobody will be really motivated to shell/buy \"next-coinbase\" addresses since their utility is limited.\n\nJust a remark: Notice this algorithm reduces the electricity bill, but the hardware needed stays the same, since for each round the miner participates in, it will try to mine as fast as possible and so use as much hardware as possible. No reduction costs are expected in hardware.\n\n\nBest Regards,\n\nEnrique Ariz\u00f3n Benito\n\n\n\nI have not even tried to imagine what oddball attacks might be possible for any miner with sufficient hashpower to deliberately cause a small reorg.\n\n--\nnullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\nBitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n\u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\nNo!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180118/80187788/attachment-0001.html>"
            },
            {
                "author": "Natanael",
                "date": "2018-01-18T16:25:16",
                "message_text_only": "A large miner would only need to divide his hardware setup into clusters\nthat pretend to be different independent miners to create these \"miner\ntokens\", as explained before, to significantly raise his chances that he on\nnearly every single round would be able to mine.\n\nOnce each individual token is about the expire, the number just dedicates a\nfraction of his  mining power to renew it. At the same time he can even\ncreate multiple new tokens given enough hardware.\n\nThis does not reduce energy use. The only notable effect is to delay income\nfor new miners. This makes profitability calculations more annoying.\n\nLong term, it only behaves like an artificially raised difficulty target.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180118/fde019fe/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Proposal to reduce mining power bill",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Eric Voskuil",
                "Natanael",
                "Damian Williamson",
                "Enrique Ariz\u00f3n Benito",
                "nullius"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 47503
        }
    },
    {
        "title": "[bitcoin-dev] The DCS Theorem - theory for understanding blockchain scalability",
        "thread_messages": [
            {
                "author": "Tao Effect",
                "date": "2018-01-16T18:15:16",
                "message_text_only": "The DCS Triangle was independently discovered by myself and Trent McConaghy.\n\nIt is a useful tool for clearing confusion about blockchain scalability and blocksize-related debates.\n\nThe DCS Theorem is a probability proof of the triangle, and it's now on arXiv:\n\nhttps://arxiv.org/abs/1801.04335 <https://arxiv.org/abs/1801.04335>\n\nCheers,\nGreg\n\n--\nPlease do not email me anything that you are not comfortable also sharing with the NSA.\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180116/e3a21433/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180116/e3a21433/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "The DCS Theorem - theory for understanding blockchain scalability",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Tao Effect"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 906
        }
    },
    {
        "title": "[bitcoin-dev] Blockchain Voluntary Fork (Split) Proposal",
        "thread_messages": [
            {
                "author": "Chaofan Li",
                "date": "2018-01-17T07:55:54",
                "message_text_only": "Here I propose a simple method to solve the scalability issue of blockchain.\nIt is more like a financial trick rather than a technical solution.\n\nThe technical part is very simple:\nSplit ( hard fork ) the blockchain into two or more blockchains (e.g. two\nblockchain A and B), voluntarily.\nThe two blockchains are the same except for some identifiers to distinguish\nthe two blockchains.\nThe coins on one blockchains cannot be sent to the other one or interfered\nby the other blockchain (  considering so many hard forks in the last year,\nthe replay protection should work in this situation)\nEveryone get double bitcoins. Each has half  value of original one bitcoin.\nThen, we have two almost same blockchains and the capacity of the original\nblockchain is doubled theoretically.\nWhen sending coin, the wallet should select one blockchain randomly and try\nto send through only  one blockchain (If there is enough bitcoins)\nI think it is a  possible solution, if the community realize  no previously\nowned asset value  is lost.\n\nThe method is inspired by the stock split\n<https://en.wikipedia.org/wiki/Stock_split>.\nWhen a stock share is split, for example into two shares, the price halves.\nThe market capitalization remains the same.\nThere is no dilution of every shareholders' total assets.\n\nThe bitcoin often emphasizes that the total coin supply should not be\nchanged.\nIf the total supply increases, the value of a single coin will be diluted.\nThat is true.\nHowever, the bad part of inflation of fiat money is not  diluted value of\nevery unit of fiat money caused by total supply increase.\nThe problem is the increased supply is not delivered to everyone\nproportional to their previously owned money.\nThe increased supply is released through debt expansion.\nThe people that can borrow more money with low interest ratio (during QE,\nit was nearly 0) can invest  and get profit.\nOr they don't even need to pay back the debt. The debt is left to\ngovernment, which might never pay back the debt, and some  get more money\nfrom government.\nOthers' money are diluted.\n\nWith voluntary split of bitcoin, dilution of anyone's bitcoin assets won't\nhappen.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180117/914227fe/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-01-22T11:12:51",
                "message_text_only": "Good morning Chaofan Li,\n\nWhat enforces that bitcoin A is worth the same as bitcoin B?  Or are they allowed to eventually diverge in price?  If they diverge in price, how is that different from the current situation with Bitcoin, BCash, Bitcoin Gold, Bitcoin Hardfork-of-the-week, and so on?\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n-------- Original Message --------\nOn January 17, 2018 3:55 PM, Chaofan Li via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Here I propose a simple method to solve the scalability issue of blockchain.\n> It is more like a financial trick rather than a technical solution.\n>\n> The technical part is very simple:\n> Split ( hard fork ) the blockchain into two or more blockchains (e.g. two blockchain A and B), voluntarily.\n> The two blockchains are the same except for some identifiers to distinguish the two blockchains.\n> The coins on one blockchains cannot be sent to the other one or interfered by the other blockchain (  considering so many hard forks in the last year, the replay protection should work in this situation)\n> Everyone get double bitcoins. Each has half  value of original one bitcoin.\n> Then, we have two almost same blockchains and the capacity of the original blockchain is doubled theoretically.\n> When sending coin, the wallet should select one blockchain randomly and try to send through only  one blockchain (If there is enough bitcoins)\n> I think it is a  possible solution, if the community realize  no previously owned asset value  is lost.\n>\n> The method is inspired by the [stock split](https://en.wikipedia.org/wiki/Stock_split).\n> When a stock share is split, for example into two shares, the price halves.\n> The market capitalization remains the same.\n> There is no dilution of every shareholders' total assets.\n>\n> The bitcoin often emphasizes that the total coin supply should not be changed.\n> If the total supply increases, the value of a single coin will be diluted.\n> That is true.\n> However, the bad part of inflation of fiat money is not  diluted value of every unit of fiat money caused by total supply increase.\n> The problem is the increased supply is not delivered to everyone proportional to their previously owned money.\n> The increased supply is released through debt expansion.\n> The people that can borrow more money with low interest ratio (during QE, it was nearly 0) can invest  and get profit.\n> Or they don't even need to pay back the debt. The debt is left to government, which might never pay back the debt, and some  get more money from government.\n> Others' money are diluted.\n>\n> With voluntary split of bitcoin, dilution of anyone's bitcoin assets won't happen.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180122/7dd38f6f/attachment.html>"
            },
            {
                "author": "Chaofan Li",
                "date": "2018-01-22T18:46:06",
                "message_text_only": "Hi ZmnSCPxj\n\nI dont think they need to be ENFORCED to be worth the same.\nIf the two chains\u2019 algorithms are the same , except some identifiers (eg.\nbtc.0 btc.1\uff09, they have no reason to have different value. If so, the\nmarket will adjust the value.\n\nAlso, the total supply can be the same. The amount in blockchains  is just\nsome numbers. The  wallet can display correct amount, according to the\nidentifiers.\n\nThe voluntary split is also backward compatible with old version\ntransactions, they can be treated as tx for both chains and included in\nboth chains later. For new version Tx after fork, some identifiers must be\nadded , to mark the tx is for that chain only. The miners need to choose\none chain to mine.\n\nAfter several voluntary splits , the Blockchain basically become a\nblocktree, new blocks are added to the leaves(eg. btc.00 btc.01 btc.10\nbtc.11 ), providing even more capacity.\n\nChaofan\n\n\nOn Mon, Jan 22, 2018 at 5:13 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Chaofan Li,\n>\n> What enforces that bitcoin A is worth the same as bitcoin B?  Or are they\n> allowed to eventually diverge in price?  If they diverge in price, how is\n> that different from the current situation with Bitcoin, BCash, Bitcoin\n> Gold, Bitcoin Hardfork-of-the-week, and so on?\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> Sent with ProtonMail <https://protonmail.com> Secure Email.\n>\n> -------- Original Message --------\n> On January 17, 2018 3:55 PM, Chaofan Li via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>\n>\n> Here I propose a simple method to solve the scalability issue of\n> blockchain.\n> It is more like a financial trick rather than a technical solution.\n>\n> The technical part is very simple:\n> Split ( hard fork ) the blockchain into two or more blockchains (e.g. two\n> blockchain A and B), voluntarily.\n> The two blockchains are the same except for some identifiers to\n> distinguish the two blockchains.\n> The coins on one blockchains cannot be sent to the other one or interfered\n> by the other blockchain (  considering so many hard forks in the last year,\n> the replay protection should work in this situation)\n> Everyone get double bitcoins. Each has half  value of original one\n> bitcoin.\n> Then, we have two almost same blockchains and the capacity of the original\n> blockchain is doubled theoretically.\n> When sending coin, the wallet should select one blockchain randomly and\n> try to send through only  one blockchain (If there is enough bitcoins)\n> I think it is a  possible solution, if the community realize  no\n> previously owned asset value  is lost.\n>\n> The method is inspired by the stock split\n> <https://en.wikipedia.org/wiki/Stock_split>.\n> When a stock share is split, for example into two shares, the price halves.\n> The market capitalization remains the same.\n> There is no dilution of every shareholders' total assets.\n>\n> The bitcoin often emphasizes that the total coin supply should not be\n> changed.\n> If the total supply increases, the value of a single coin will be diluted.\n> That is true.\n> However, the bad part of inflation of fiat money is not  diluted value of\n> every unit of fiat money caused by total supply increase.\n> The problem is the increased supply is not delivered to everyone\n> proportional to their previously owned money.\n> The increased supply is released through debt expansion.\n> The people that can borrow more money with low interest ratio (during QE,\n> it was nearly 0) can invest  and get profit.\n> Or they don't even need to pay back the debt. The debt is left to\n> government, which might never pay back the debt, and some  get more money\n> from government.\n> Others' money are diluted.\n>\n> With voluntary split of bitcoin, dilution of anyone's bitcoin assets won't\n> happen.\n>\n>\n>\n>\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180122/46d6ce13/attachment-0001.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2018-01-22T20:40:58",
                "message_text_only": "Without enforcement liquidity will diverge.\n\nOn Mon, Jan 22, 2018 at 1:46 PM, Chaofan Li via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi ZmnSCPxj\n>\n> I dont think they need to be ENFORCED to be worth the same.\n> If the two chains\u2019 algorithms are the same , except some identifiers (eg.\n> btc.0 btc.1\uff09, they have no reason to have different value. If so, the\n> market will adjust the value.\n>\n> Also, the total supply can be the same. The amount in blockchains  is just\n> some numbers. The  wallet can display correct amount, according to the\n> identifiers.\n>\n> The voluntary split is also backward compatible with old version\n> transactions, they can be treated as tx for both chains and included in\n> both chains later. For new version Tx after fork, some identifiers must be\n> added , to mark the tx is for that chain only. The miners need to choose\n> one chain to mine.\n>\n> After several voluntary splits , the Blockchain basically become a\n> blocktree, new blocks are added to the leaves(eg. btc.00 btc.01 btc.10\n> btc.11 ), providing even more capacity.\n>\n> Chaofan\n>\n>\n> On Mon, Jan 22, 2018 at 5:13 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n>> Good morning Chaofan Li,\n>>\n>> What enforces that bitcoin A is worth the same as bitcoin B?  Or are they\n>> allowed to eventually diverge in price?  If they diverge in price, how is\n>> that different from the current situation with Bitcoin, BCash, Bitcoin\n>> Gold, Bitcoin Hardfork-of-the-week, and so on?\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>>\n>> Sent with ProtonMail <https://protonmail.com> Secure Email.\n>>\n>> -------- Original Message --------\n>> On January 17, 2018 3:55 PM, Chaofan Li via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>\n>>\n>> Here I propose a simple method to solve the scalability issue of\n>> blockchain.\n>> It is more like a financial trick rather than a technical solution.\n>>\n>> The technical part is very simple:\n>> Split ( hard fork ) the blockchain into two or more blockchains (e.g. two\n>> blockchain A and B), voluntarily.\n>> The two blockchains are the same except for some identifiers to\n>> distinguish the two blockchains.\n>> The coins on one blockchains cannot be sent to the other one or\n>> interfered by the other blockchain (  considering so many hard forks in the\n>> last year, the replay protection should work in this situation)\n>> Everyone get double bitcoins. Each has half  value of original one\n>> bitcoin.\n>> Then, we have two almost same blockchains and the capacity of the\n>> original blockchain is doubled theoretically.\n>> When sending coin, the wallet should select one blockchain randomly and\n>> try to send through only  one blockchain (If there is enough bitcoins)\n>> I think it is a  possible solution, if the community realize  no\n>> previously owned asset value  is lost.\n>>\n>> The method is inspired by the stock split\n>> <https://en.wikipedia.org/wiki/Stock_split>.\n>> When a stock share is split, for example into two shares, the price\n>> halves.\n>> The market capitalization remains the same.\n>> There is no dilution of every shareholders' total assets.\n>>\n>> The bitcoin often emphasizes that the total coin supply should not be\n>> changed.\n>> If the total supply increases, the value of a single coin will be diluted.\n>> That is true.\n>> However, the bad part of inflation of fiat money is not  diluted value of\n>> every unit of fiat money caused by total supply increase.\n>> The problem is the increased supply is not delivered to everyone\n>> proportional to their previously owned money.\n>> The increased supply is released through debt expansion.\n>> The people that can borrow more money with low interest ratio (during QE,\n>> it was nearly 0) can invest  and get profit.\n>> Or they don't even need to pay back the debt. The debt is left to\n>> government, which might never pay back the debt, and some  get more money\n>> from government.\n>> Others' money are diluted.\n>>\n>> With voluntary split of bitcoin, dilution of anyone's bitcoin assets\n>> won't happen.\n>>\n>>\n>>\n>>\n>>\n>>\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180122/f781f466/attachment-0001.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2018-01-22T22:43:22",
                "message_text_only": "All other things being equal, the money with the larger network is more useful due to the cost of exchange between them, which can only be eliminated by one absorbing the network of the other. According the Thiers\u2019 law (i.e. in the absence of currency controls), the more useful money will get used. It is not the case that they will just become the same value.\n\nHowever, all other things are not equal. As a Bitcoin becomes more useful its use rises. Rising use implies rising fees, which in turn reduces usefulness (stability property). While the better money prices out certain scenarios, they remain viable in the lesser money. But eventually this will happen there as well, and the better money will absorb the lesser.\n\nThe perpetual creation of new monies with exchange between them and the best money (largest network) could certainly exist, but layering proposes an approach that doesn\u2019t require all merchants to perpetually be accepting different monies. It has a similar security trade-off (lower security for transacting off of the better money), which is the source of decreased transaction cost. But without the exchange and overhead cost the layered money can be better than multiple monies.\n\nAlso, all splits are voluntary.\n\ne\n\n> On Jan 22, 2018, at 12:40, Erik Aronesty via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Without enforcement liquidity will diverge.   \n> \n>> On Mon, Jan 22, 2018 at 1:46 PM, Chaofan Li via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> Hi ZmnSCPxj\n>> \n>> I dont think they need to be ENFORCED to be worth the same. \n>> If the two chains\u2019 algorithms are the same , except some identifiers (eg. btc.0 btc.1\uff09, they have no reason to have different value. If so, the market will adjust the value.\n>> \n>> Also, the total supply can be the same. The amount in blockchains  is just some numbers. The  wallet can display correct amount, according to the identifiers.\n>> \n>> The voluntary split is also backward compatible with old version transactions, they can be treated as tx for both chains and included in both chains later. For new version Tx after fork, some identifiers must be added , to mark the tx is for that chain only. The miners need to choose one chain to mine.\n>> \n>> After several voluntary splits , the Blockchain basically become a blocktree, new blocks are added to the leaves(eg. btc.00 btc.01 btc.10 btc.11 ), providing even more capacity. \n>> \n>> Chaofan\n>> \n>> \n>>> On Mon, Jan 22, 2018 at 5:13 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>>> Good morning Chaofan Li,\n>>> \n>>> What enforces that bitcoin A is worth the same as bitcoin B?  Or are they allowed to eventually diverge in price?  If they diverge in price, how is that different from the current situation with Bitcoin, BCash, Bitcoin Gold, Bitcoin Hardfork-of-the-week, and so on?\n>>> \n>>> Regards,\n>>> ZmnSCPxj\n>>> \n>>> \n>>> Sent with ProtonMail Secure Email.\n>>> \n>>> -------- Original Message --------\n>>>> On January 17, 2018 3:55 PM, Chaofan Li via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>> \n>>>> \n>>>> \n>>>> Here I propose a simple method to solve the scalability issue of blockchain.\n>>>> It is more like a financial trick rather than a technical solution. \n>>>> \n>>>> The technical part is very simple: \n>>>> Split ( hard fork ) the blockchain into two or more blockchains (e.g. two blockchain A and B), voluntarily. \n>>>> The two blockchains are the same except for some identifiers to distinguish the two blockchains.\n>>>> The coins on one blockchains cannot be sent to the other one or interfered by the other blockchain (  considering so many hard forks in the last year, the replay protection should work in this situation)\n>>>> Everyone get double bitcoins. Each has half  value of original one bitcoin. \n>>>> Then, we have two almost same blockchains and the capacity of the original blockchain is doubled theoretically.\n>>>> When sending coin, the wallet should select one blockchain randomly and try to send through only  one blockchain (If there is enough bitcoins)\n>>>> I think it is a  possible solution, if the community realize  no previously owned asset value  is lost.\n>>>> \n>>>> The method is inspired by the stock split.\n>>>> When a stock share is split, for example into two shares, the price halves.\n>>>> The market capitalization remains the same.\n>>>> There is no dilution of every shareholders' total assets.\n>>>> \n>>>> The bitcoin often emphasizes that the total coin supply should not be changed.\n>>>> If the total supply increases, the value of a single coin will be diluted.\n>>>> That is true.\n>>>> However, the bad part of inflation of fiat money is not  diluted value of every unit of fiat money caused by total supply increase.\n>>>> The problem is the increased supply is not delivered to everyone proportional to their previously owned money.\n>>>> The increased supply is released through debt expansion.\n>>>> The people that can borrow more money with low interest ratio (during QE, it was nearly 0) can invest  and get profit.\n>>>> Or they don't even need to pay back the debt. The debt is left to government, which might never pay back the debt, and some  get more money from government.\n>>>> Others' money are diluted.\n>>>> \n>>>> With voluntary split of bitcoin, dilution of anyone's bitcoin assets won't happen.\n>>>> \n>>>> \n>>>> \n>>>> \n>>>> \n>>> \n>> \n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180122/952b355a/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Blockchain Voluntary Fork (Split) Proposal",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Eric Voskuil",
                "Chaofan Li",
                "Erik Aronesty"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 19570
        }
    },
    {
        "title": "[bitcoin-dev] Upgrading PoW algorithm",
        "thread_messages": [
            {
                "author": "Jefferson Carpenter",
                "date": "2018-01-17T22:31:52",
                "message_text_only": "Bitcoin's difficulty will be maxed out within about 400 years, by \nMoore's law.  (After that - supposing the software does not crash when \ndifficulty overflows - block time will start decreasing, and it will not \ntake long before blocks are mined faster than photons can be sent across \nthe planet).\n\nBitcoin is the dominant cryptocurrency today, as the first mover: the \nperfectly fair worldwide game of inventing the cryptocurrency has been \nplayed and won.  However, unfortunately, it has a built-in end date: \nabout 400 years from now.  After that, it won't necessarily be clear \nwhat the dominant cryptocurrency is.  It might be a lot like VHS vs \nBetamax, and a lot of people could lose a lot of money.  It seems to me, \nthis could be mitigated by planning today for what we are going to do \nwhen Bitcoin finally breaks 400 years from now.\n\nAre there any distinct plans today for migrating to a PoW supporting an \neven higher difficulty?"
            },
            {
                "author": "Peter Todd",
                "date": "2018-01-18T16:36:44",
                "message_text_only": "On Wed, Jan 17, 2018 at 04:31:52PM -0600, Jefferson Carpenter via bitcoin-dev wrote:\n> Bitcoin's difficulty will be maxed out within about 400 years, by Moore's\n> law.  (After that - supposing the software does not crash when difficulty\n\nThere's no reason to think Moore's law will last for 400 years; if it did\nmining Bitcoin blocks would require astronomical energy levels. I haven't\nactually done the math, but having to convert a mass-energy equivalance of a\nplanet or two per block is probably an accurate lower-bound even with quantum\ncomputers. Once we're at that point, the problem is the speed of light: we'll\nrun out of energy in our 10 minute light radius, and thus need to get it from\nfarther away, at which point the 10 minute block interval forces a hard fork\nanyway because mining no longer is in consensus.\n\ntl;dr: This is a topic for sci-fi writers, not bitcoin-dev\n\nAlso: https://xkcd.com/605/\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 488 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180118/487217e6/attachment.sig>"
            },
            {
                "author": "Jefferson Carpenter",
                "date": "2018-01-19T20:54:52",
                "message_text_only": "Actually here's something we could possibly do:\n\nFork off a blockchain that accepts Bitcoin blocks with strictly less \nthan max difficulty.  Because it does not accept max-difficulty blocks, \nit is a soft fork.  Additionally, if difficulty of a block is set to \nmax, then the difficulty field is extended so that it represents a \nhigher max difficulty under a different hashing function, maybe SHA512. \nBecause this blockchain also accepts differently-formatted blocks, it is \nalso a hard fork.\n\nThe idea is that this blockchain is identical to Bitcoin until the \ndifficulty goes too high, at which point it diverges.\n\nTransitioning from the current SHA256 to a higher-difficulty hashing \nfunction could be difficult, since they might be solvable at \nproportionally different hashrates.  In other words, max difficulty for \nSHA256 might be significantly faster than forcing the first 256 bits of \na SHA512 hash...\n\nOn 1/17/2018 4:31 PM, Jefferson Carpenter wrote:\n> Bitcoin's difficulty will be maxed out within about 400 years, by \n> Moore's law.\u00a0 (After that - supposing the software does not crash when \n> difficulty overflows - block time will start decreasing, and it will not \n> take long before blocks are mined faster than photons can be sent across \n> the planet).\n> \n> Bitcoin is the dominant cryptocurrency today, as the first mover: the \n> perfectly fair worldwide game of inventing the cryptocurrency has been \n> played and won.\u00a0 However, unfortunately, it has a built-in end date: \n> about 400 years from now.\u00a0 After that, it won't necessarily be clear \n> what the dominant cryptocurrency is.\u00a0 It might be a lot like VHS vs \n> Betamax, and a lot of people could lose a lot of money.\u00a0 It seems to me, \n> this could be mitigated by planning today for what we are going to do \n> when Bitcoin finally breaks 400 years from now.\n> \n> Are there any distinct plans today for migrating to a PoW supporting an \n> even higher difficulty?"
            },
            {
                "author": "nullius",
                "date": "2018-01-20T06:30:37",
                "message_text_only": "On 2018-01-17 at 22:31:52 +0000, Jefferson Carpenter \n<jeffersoncarpenter2 at gmail.com> wrote:\n>Bitcoin's difficulty will be maxed out within about 400 years, by \n>Moore's law.\n\nOn 2018-01-19 at 20:54:52 +0000, Jefferson Carpenter \n<jeffersoncarpenter2 at gmail.com> wrote:\n>In other words, max difficulty for SHA256 might be significantly faster \n>than forcing the first 256 bits of a SHA512 hash...\n\n\u201cMoore\u2019s law\u201d is not a law of nature.  Indeed, chipmakers began bumping \nup against the limitations of *actual* natural laws about 15\u201420 years \nago.  That is why instead of increasing core clock, they play the tricks \nwhich opened the way for Meltdown and Spectre.  Feature size, and thus \ntransistor counts, will soon enough run into physical limitations, too.\n\nBut the scenario you describe does not even require such a discussion.\n\n2^256 work for brute force is on the order of 10^77 hashes.  For the \nnumber of atoms in the observable universe, I\u2019ve seen estimates ranging \nfrom 10^78 to 10^82.  Thus, you are suggesting that within 400 years, \ncomputers will be able to compute one hash for every myriad of atoms in \nthe observable universe\u2014perhaps one hash for every *ten* atoms.  \nMoreover, you suggest that twenty-fourth century computers will do this \nfast enough to meet Bitcoin\u2019s ten-minute target rate.\n\nSuch a proposition bypasses science, leaps over science fiction, and \nlands in the realm of religion.  Perhaps a deity could do this\u2014using a \ncomputer made of other than matter, powered by other than energy.  \nHumans will *never* be capable of such a feat:  Not now, and not in a \nbillion years.  Certainly not a mere four centuries hence!\n\n(I do not here positively exclude the possibility, however slim, that \nmathematical breakthroughs may yield a preimage attack on SHA-256 which \nis significantly better than bruteforce.  I *do* positively declare it \nimpossible that Earth-beings will ever be capable of performing 2^256 \nwork.  Or even 2^128 work, for that matter.)\n\n-- \nnullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C\nBitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:\n3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)\n\u201c\u2018If you\u2019re not doing anything wrong, you have nothing to hide.\u2019\nNo!  Because I do nothing wrong, I have nothing to show.\u201d \u2014 nullius\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 228 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180120/a113bafd/attachment.sig>"
            },
            {
                "author": "Melvin Carvalho",
                "date": "2018-01-20T18:36:09",
                "message_text_only": "On 17 January 2018 at 23:31, Jefferson Carpenter via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Bitcoin's difficulty will be maxed out within about 400 years, by Moore's\n> law.  (After that - supposing the software does not crash when difficulty\n> overflows - block time will start decreasing, and it will not take long\n> before blocks are mined faster than photons can be sent across the planet).\n>\n> Bitcoin is the dominant cryptocurrency today, as the first mover: the\n> perfectly fair worldwide game of inventing the cryptocurrency has been\n> played and won.  However, unfortunately, it has a built-in end date: about\n> 400 years from now.  After that, it won't necessarily be clear what the\n> dominant cryptocurrency is.  It might be a lot like VHS vs Betamax, and a\n> lot of people could lose a lot of money.  It seems to me, this could be\n> mitigated by planning today for what we are going to do when Bitcoin\n> finally breaks 400 years from now.\n>\n> Are there any distinct plans today for migrating to a PoW supporting an\n> even higher difficulty?\n>\n\nCrypto algorithms have a lifetime, and consensus is no different.\n\nIs it likely to be more than a few years?  Yes.\n\nIs likely to be less than a few hundred years.  Yes.\n\nEvery algorithm involves trade offs and it's the job of a thoughtful dev\nteam to examine those trade offs and come to a consensus optimal solution.\n\nThis field is only 9 years old, and there is a large amount of R & D in\nthis area.  So we can evaluate what seems to working better and what seems\nto be working worse, transfer that to BIPs, create code, test it, try to\nachieve consensus.  The normal path that has served free software projects\nwell.\n\n\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180120/5007b1f4/attachment.html>"
            },
            {
                "author": "Glen Peterson",
                "date": "2018-01-21T15:29:26",
                "message_text_only": "Popular hashing algorithms have historically managed 10-15 years of\nintense use before flaws are found in the algorithm.  This chart\nsuggests SHA-256 is already aging:\nhttp://valerieaurora.org/hash.html\nIf history is any guide, any long-term cryptocurrency/blockchain will\nneed the cryptography updated every decade or so.\n\nOn Sat, Jan 20, 2018 at 1:36 PM, Melvin Carvalho via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>\n> On 17 January 2018 at 23:31, Jefferson Carpenter via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> Bitcoin's difficulty will be maxed out within about 400 years, by Moore's\n>> law.  (After that - supposing the software does not crash when difficulty\n>> overflows - block time will start decreasing, and it will not take long\n>> before blocks are mined faster than photons can be sent across the planet).\n>>\n>> Bitcoin is the dominant cryptocurrency today, as the first mover: the\n>> perfectly fair worldwide game of inventing the cryptocurrency has been\n>> played and won.  However, unfortunately, it has a built-in end date: about\n>> 400 years from now.  After that, it won't necessarily be clear what the\n>> dominant cryptocurrency is.  It might be a lot like VHS vs Betamax, and a\n>> lot of people could lose a lot of money.  It seems to me, this could be\n>> mitigated by planning today for what we are going to do when Bitcoin finally\n>> breaks 400 years from now.\n>>\n>> Are there any distinct plans today for migrating to a PoW supporting an\n>> even higher difficulty?\n>\n>\n> Crypto algorithms have a lifetime, and consensus is no different.\n>\n> Is it likely to be more than a few years?  Yes.\n>\n> Is likely to be less than a few hundred years.  Yes.\n>\n> Every algorithm involves trade offs and it's the job of a thoughtful dev\n> team to examine those trade offs and come to a consensus optimal solution.\n>\n> This field is only 9 years old, and there is a large amount of R & D in this\n> area.  So we can evaluate what seems to working better and what seems to be\n> working worse, transfer that to BIPs, create code, test it, try to achieve\n> consensus.  The normal path that has served free software projects well.\n>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n\n-- \nGlen K. Peterson\n(828) 393-0081"
            }
        ],
        "thread_summary": {
            "title": "Upgrading PoW algorithm",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Glen Peterson",
                "Jefferson Carpenter",
                "Peter Todd",
                "Melvin Carvalho",
                "nullius"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 11426
        }
    },
    {
        "title": "[bitcoin-dev] ScriptPubkey consensus translation",
        "thread_messages": [
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-18T19:30:09",
                "message_text_only": "A common question when discussing newer more efficient pubkey types--\nlike signature aggregation or even just segwit-- is \"will this thing\nmake the spending of already existing outputs more efficient\", which\nunfortunately gets an answer of No because the redemption instructions\nfor existing outputs have already been set, and don't incorporate\nthese new features.\n\nThis is good news in that no one ends up being forced to expose their\nown funds to new cryptosystems whos security they may not trust.  When\nsigagg is deployed, for example, any cryptographic risk in it is borne\nby people who opted into using it.\n\nLets imagine though that segwit-with-sigagg has been long deployed,\nwidely used, and is more or less universally accepted as at least as\ngood as an old P2PKH.\n\nIn that case, it might be plausible to include in a hardfork a\nconsensus rule that lets someone spend scriptPubkey's matching\nspecific templates as though they were an alternative template.  So\nthen an idiomatic P2PKH or perhaps even a P2SH-multisig could be spent\nas though it used the analogous p2w-sigagg script.\n\nThe main limitation is that there is some risk of breaking the\nsecurity assumptions of some complicated external protocol e.g. that\nassumed that having a schnorr oracle for a key wouldn't let you spend\ncoins connected to that key.  This seems like a pretty contrived\nconcern to me however, and it's one that can largely be addressed by\nample communication in advance.  (E.g. discouraging the creation of\nexcessively fragile things like that, and finding out if any exist so\nthey can be worked around).\n\nAm I missing any other arguments?"
            },
            {
                "author": "CryptAxe",
                "date": "2018-01-18T19:56:41",
                "message_text_only": "Technically the change would be an improvement. People should be allowed to\nopt-in to systems and big changes like that though, not have developers\nchange what their outputs mean or open them up to new security risks on\ntheir behalf.\n\nOn Jan 18, 2018 11:30 AM, \"Gregory Maxwell via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> A common question when discussing newer more efficient pubkey types--\n> like signature aggregation or even just segwit-- is \"will this thing\n> make the spending of already existing outputs more efficient\", which\n> unfortunately gets an answer of No because the redemption instructions\n> for existing outputs have already been set, and don't incorporate\n> these new features.\n>\n> This is good news in that no one ends up being forced to expose their\n> own funds to new cryptosystems whos security they may not trust.  When\n> sigagg is deployed, for example, any cryptographic risk in it is borne\n> by people who opted into using it.\n>\n> Lets imagine though that segwit-with-sigagg has been long deployed,\n> widely used, and is more or less universally accepted as at least as\n> good as an old P2PKH.\n>\n> In that case, it might be plausible to include in a hardfork a\n> consensus rule that lets someone spend scriptPubkey's matching\n> specific templates as though they were an alternative template.  So\n> then an idiomatic P2PKH or perhaps even a P2SH-multisig could be spent\n> as though it used the analogous p2w-sigagg script.\n>\n> The main limitation is that there is some risk of breaking the\n> security assumptions of some complicated external protocol e.g. that\n> assumed that having a schnorr oracle for a key wouldn't let you spend\n> coins connected to that key.  This seems like a pretty contrived\n> concern to me however, and it's one that can largely be addressed by\n> ample communication in advance.  (E.g. discouraging the creation of\n> excessively fragile things like that, and finding out if any exist so\n> they can be worked around).\n>\n> Am I missing any other arguments?\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180118/938ee169/attachment.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2018-01-18T21:00:03",
                "message_text_only": "The downsides could be mitigated somewhat by only making the dual interpretation apply to outputs older than a cutoff time after the activation of the new feature. For example, five years after the initial activation of the sigagg soft-fork, the sigagg rules will apply to pre-activation UTXOs as well. That would allow old UTXOs to be spent more cheaply, perhaps making some dust usable again, but anyone who purposefully sent funds to old-style outputs after the cutoff are not opened up to the dual interpretation.\n\n> On Jan 18, 2018, at 11:30 AM, Gregory Maxwell via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> A common question when discussing newer more efficient pubkey types--\n> like signature aggregation or even just segwit-- is \"will this thing\n> make the spending of already existing outputs more efficient\", which\n> unfortunately gets an answer of No because the redemption instructions\n> for existing outputs have already been set, and don't incorporate\n> these new features.\n> \n> This is good news in that no one ends up being forced to expose their\n> own funds to new cryptosystems whos security they may not trust.  When\n> sigagg is deployed, for example, any cryptographic risk in it is borne\n> by people who opted into using it.\n> \n> Lets imagine though that segwit-with-sigagg has been long deployed,\n> widely used, and is more or less universally accepted as at least as\n> good as an old P2PKH.\n> \n> In that case, it might be plausible to include in a hardfork a\n> consensus rule that lets someone spend scriptPubkey's matching\n> specific templates as though they were an alternative template.  So\n> then an idiomatic P2PKH or perhaps even a P2SH-multisig could be spent\n> as though it used the analogous p2w-sigagg script.\n> \n> The main limitation is that there is some risk of breaking the\n> security assumptions of some complicated external protocol e.g. that\n> assumed that having a schnorr oracle for a key wouldn't let you spend\n> coins connected to that key.  This seems like a pretty contrived\n> concern to me however, and it's one that can largely be addressed by\n> ample communication in advance.  (E.g. discouraging the creation of\n> excessively fragile things like that, and finding out if any exist so\n> they can be worked around).\n> \n> Am I missing any other arguments?\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            }
        ],
        "thread_summary": {
            "title": "ScriptPubkey consensus translation",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "CryptAxe",
                "Gregory Maxwell",
                "Mark Friedenbach"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 6542
        }
    },
    {
        "title": "[bitcoin-dev] Change in contact info",
        "thread_messages": [
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-19T02:59:17",
                "message_text_only": "Not really all that on-topic, but since it was suggested to me that\nthis would be an efficient venue to reach others who might care to\nknow:\n\nIn order to spend more time working independently on deep protocol\nwork, especially new cryptographic privacy and security technology for\nBitcoin, I resigned from Blockstream last November. It took until the\nend of December to wind down my involvement there.\n\nBack when we founded the company I was concerned that there was\nsignificant underinvestment in Bitcoin technology: Bitcoin had a\nhealthy technical community just as it does today, but lacked the kind\nof industry support that projects like Linux have. Without sustained\nfinancial support, some kinds of bigger projects seemed really hard to\npull off with developers needing to share time between non-bitcoin\nemployment, their families, and their other interests. For the most\npart, back then early Bitcoin companies weren't investing in public\ntechnology, at least not effectively.\n\nWe hoped that Blockstream could help act as an anchor of support for\ntechnology development, and in doing so help grow the community. I\nthink that has been a big success. The Bitcoin industry has matured a\nlot and today Bitcoin Core gets significant regular contributions from\nmany organizations (including Chaincode, DCI, Blockstream, Coinbase,\nBitmain, Blockchain, and probably others that I am forgetting or not\neven aware of) and a volunteer community much larger and more active\nthan it has ever been before.  From what I've been told Blockstream\nplans to continue to contribute to awesome technology in Bitcoin--as\ndemonstrated by their Lightning webstore this week--but if they\ndidn't, that wouldn't be a problem for Bitcoin.\n\nSo for me this means that I can go back to working on the things I\nfind most exciting ... without the overhead of managing staff or\ndealing with the many non-Bitcoin blockchain applications which are\nimportant to Blockstream's business. The maturing Bitcoin industry\nmeans I don't need to worry that Bitcoin development could be left\nwith inadequate financial support.\n\nI'm very excited about all the new and interesting technology that is\ncoming to production--Bulletproofs / CT, signature aggregation,\nimproved propagation and synchronization--as well as the continuing\nmaturation of Bitcoin as a viable subject matter for academic\nresearchers. I'll be spending more time helping with these and other\nthings, and will no longer have insight into Blockstream's activities\nor a Blockstream email address (I can continue to be reached at my\nxiph.org and gmail email addresses as I've used here in the past), but\notherwise this shouldn't change anything for anyone here.\n\n\nCheers,"
            }
        ],
        "thread_summary": {
            "title": "Change in contact info",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Gregory Maxwell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2696
        }
    },
    {
        "title": "[bitcoin-dev] [BIP Proposal] P2SH and Version 0 Segwit Script enforcement from genesis",
        "thread_messages": [
            {
                "author": "Suhas Daftuar",
                "date": "2018-01-19T20:38:34",
                "message_text_only": "Hi,\n\nI propose backdating the P2SH and Segwit version 0 script rules back to the\ngenesis block, as a way to simplify these consensus rules.  Here's the\nabstract from a draft BIP I wrote up to explain this change:\n\nThe Pay to Script Hash (P2SH, BIP 16) script rules and the Version 0\nWitness Program script rules (BIP 143/141) can be enforced from the genesis\nblock with only one historical exception. Doing so simplifies consensus\nrules and allows protocol implementers to avoid writing and testing code\npaths that are no longer relevant.\n\nThe full BIP draft can be found here:\nhttps://github.com/sdaftuar/bips/blob/p2sh-v0segwit-from-genesis/bip-sdaftuar-p2sh-v0segwit-from-genesis.mediawiki\n\nAnd the currently open pull request to Bitcoin Core which implements this\nchange can be found here: https://github.com/bitcoin/bitcoin/pull/11739\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180119/9e6d1bb7/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "P2SH and Version 0 Segwit Script enforcement from genesis",
            "categories": [
                "bitcoin-dev",
                "BIP Proposal"
            ],
            "authors": [
                "Suhas Daftuar"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1022
        }
    },
    {
        "title": "[bitcoin-dev] Transaction Merging (bip125 relaxation)",
        "thread_messages": [
            {
                "author": "Rhavar",
                "date": "2018-01-22T17:40:31",
                "message_text_only": "So my half-baked idea is very simple:\n\nAllow users to merge multiple unconfirmed transactions, stripping extraneous inputs and change as they go.\n\nThis is currently not possible because of the bip125 rule:\n\"The replacement transaction pays an absolute fee of at least the sum paid by the original transactions.\"\n\nBecause the size of the merged transaction is smaller than the original transactions, unless there is a considerable feerate bump, this rule isn't possible to observe.\n\nI my question is: is it possible or reasonable to relax this rule? If this rule was removed in its entirety, does it introduce any DoS vectors? Or can it be changed to allow my use-case?\n\n---\nFull backstory: I have been trying to use bip125 (Opt-in Full Replace-by-Fee) to do \"transaction merging\" on the fly. Let's say that I owe John 1 bitcoin, and have promised to pay him immediately: Instead of creating a whole new transaction if I have an in-flight (unconfirmed) transaction, I can follow the rules of bip125 to create a replacement that accomplishes this goal.\n\nFrom a \"coin selection\" point of view, this was significantly easier than\nI had anticipated. I was able to encode the rules in my linear model and\nfeed in all my unspent and in-flight transactions and it can solve it without difficulty.\n\nHowever, the real problem is tracking the mess. Consider this sequence of events:\n1) I have unconfirmed transaction A\n2) I replace it with B, which pays John 1 BTC\n3) Transaction A gets confirmed\n\nSo now I still owe John 1 BTC, however it's not immediately clear if\nit's safe to send to him without waiting $n transactions. However even\nfor a small $n, this breaks my promise to pay him immediately.\n\nOne possible solution is to only consider a transaction \"replaceable\" if it has change, so if the original transaction confirms -- payments can immediately be made that source the change, and provide safety in a reorg.\n\nHowever, this will only work <50% of the time for me (most transactions\ndon't have change) and opens a pandora's box of complexity.\n\nThere's a few other hacks you can do to make it work in a few more cases, but nothing that is realistic to expect anyone to implement any time soon.\n\nHowever, if there was a straight foward way to merge N unconfirmed transactions, it would be easy get into production, and potentially offer some pretty nice savings for everyone.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180122/75c4190e/attachment.html>"
            },
            {
                "author": "Alan Evans",
                "date": "2018-01-22T18:16:13",
                "message_text_only": "> So now I still owe John 1 BTC, however it's not immediately clear if it's\nsafe to send to him\n\nIf you spent your change from transaction A, that would be safe. There'd be\nno way you John could end up with 2 BTC from you then.\n\nOn Mon, Jan 22, 2018 at 1:40 PM, Rhavar via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> So my half-baked idea is very simple:\n>\n> Allow users to merge multiple unconfirmed transactions, stripping\n> extraneous inputs and change as they go.\n>\n> This is currently not possible because of the bip125 rule:\n> \"The replacement transaction pays an absolute fee of at least the sum paid\n> by the original transactions.\"\n>\n> Because the size of the merged transaction is smaller than the original\n> transactions, unless there is a considerable feerate bump, this rule isn't\n> possible to observe.\n>\n>\n> I my question is: is it possible or reasonable to relax this rule? If this\n> rule was removed in its entirety, does it introduce any DoS vectors? Or can\n> it be changed to allow my use-case?\n>\n>\n> ---\n> Full backstory: I have been trying to use bip125 (Opt-in Full\n> Replace-by-Fee) to do \"transaction merging\" on the fly. Let's say that I\n> owe John 1 bitcoin, and have promised to pay him immediately: Instead of\n> creating a whole new transaction if I have an in-flight (unconfirmed)\n> transaction, I can follow the rules of bip125 to create a replacement that\n> accomplishes this goal.\n>\n> From a \"coin selection\" point of view, this was significantly easier than\n> I had anticipated. I was able to encode the rules in my linear model and\n> feed in all my unspent and in-flight transactions and it can solve it\n> without difficulty.\n>\n> However, the real problem is tracking the mess. Consider this sequence of\n> events:\n> 1) I have unconfirmed transaction A\n> 2) I replace it with B, which pays John 1 BTC\n> 3) Transaction A gets confirmed\n>\n> So now I still owe John 1 BTC, however it's not immediately clear if\n> it's safe to send to him without waiting $n transactions. However even\n> for a small $n, this breaks my promise to pay him immediately.\n>\n> One possible solution is to only consider a transaction \"replaceable\" if\n> it has change, so if the original transaction confirms -- payments can\n> immediately be made that source the change, and provide safety in a reorg.\n>\n> However, this will only work <50% of the time for me (most transactions\n> don't have change) and opens a pandora's box of complexity.\n>\n> There's a few other hacks you can do to make it work in a few more cases,\n> but nothing that is realistic to expect anyone to implement any time soon.\n>\n> However, if there was a straight foward way to merge N unconfirmed\n> transactions, it would be easy get into production, and potentially offer\n> some pretty nice savings for everyone.\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180122/b5749d54/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2018-01-22T20:00:23",
                "message_text_only": "On Mon, Jan 22, 2018 at 12:40:31PM -0500, Rhavar via bitcoin-dev wrote:\n> So my half-baked idea is very simple:\n> \n> Allow users to merge multiple unconfirmed transactions, stripping extraneous inputs and change as they go.\n> \n> This is currently not possible because of the bip125 rule:\n> \"The replacement transaction pays an absolute fee of at least the sum paid by the original transactions.\"\n> \n> Because the size of the merged transaction is smaller than the original transactions, unless there is a considerable feerate bump, this rule isn't possible to observe.\n> \n> I my question is: is it possible or reasonable to relax this rule? If this rule was removed in its entirety, does it introduce any DoS vectors? Or can it be changed to allow my use-case?\n\nIt would definitely introduce DoS vectors by making it much cheaper to use\nrelay bandwidth. You'd also be able to push others' txs out of the mempool.\n\n> ---\n> Full backstory: I have been trying to use bip125 (Opt-in Full Replace-by-Fee) to do \"transaction merging\" on the fly. Let's say that I owe John 1 bitcoin, and have promised to pay him immediately: Instead of creating a whole new transaction if I have an in-flight (unconfirmed) transaction, I can follow the rules of bip125 to create a replacement that accomplishes this goal.\n> \n> From a \"coin selection\" point of view, this was significantly easier than\n> I had anticipated. I was able to encode the rules in my linear model and\n> feed in all my unspent and in-flight transactions and it can solve it without difficulty.\n> \n> However, the real problem is tracking the mess. Consider this sequence of events:\n> 1) I have unconfirmed transaction A\n> 2) I replace it with B, which pays John 1 BTC\n> 3) Transaction A gets confirmed\n> \n> So now I still owe John 1 BTC, however it's not immediately clear if\n> it's safe to send to him without waiting $n transactions. However even\n> for a small $n, this breaks my promise to pay him immediately.\n>\n> One possible solution is to only consider a transaction \"replaceable\" if it has change, so if the original transaction confirms -- payments can immediately be made that source the change, and provide safety in a reorg.\n> \n> However, this will only work <50% of the time for me (most transactions\n> don't have change) and opens a pandora's box of complexity.\n\nMost transactions don't have change?! Under what circumstance? For most\nuse-cases the reverse is true: almost all all transactions have change, because\nit's rare for the inputs to exactly math the requested payment.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180122/84f99d15/attachment-0001.sig>"
            },
            {
                "author": "Rhavar",
                "date": "2018-01-22T20:09:20",
                "message_text_only": "> Most transactions don't have change?! Under what circumstance? For most\n> use-cases the reverse is true: almost all all transactions have change, because\n> it's rare for the inputs to exactly math the requested payment.\n\nIt's actually a common misconception. With good coin selection, I am able to avoid change about ~75% of the time in my simulations (on my real world data). In practice it's a bit lower, probably about 40-50% of the time because of the need to keep the majority of my funds offline where they can't be used for coin selection, and I have not been able to accurate simulate how I consolidate.\n\nAlso the other misconception is that inputs don't need to match exactly the requested payment, it's totally fine to do something I call a \"miner sacrifice\" where you overpay txfees up to the amount that that would otherwise be the total cost (immediate + consolidation) of creating change.\n\nAlso another trick I use, is something I call \"output selection\". If I have N queued non-time sensitive payments, I don't really need to send them all at the same time. So I can pick the best combination of inputs+outputs.\n\nObviously none of this applies to consumer wallets, who typically have less than a handful of options. But for a service, avoiding change can be the norm with good coin selection.\n\n---\n\n-Ryan\n\n-------- Original Message --------\nOn January 22, 2018 3:00 PM, Peter Todd <pete at petertodd.org> wrote:\n\n> On Mon, Jan 22, 2018 at 12:40:31PM -0500, Rhavar via bitcoin-dev wrote:\n>\n>> So my half-baked idea is very simple:\n>> Allow users to merge multiple unconfirmed transactions, stripping extraneous inputs and change as they go.\n>> This is currently not possible because of the bip125 rule:\n>> \"The replacement transaction pays an absolute fee of at least the sum paid by the original transactions.\"\n>> Because the size of the merged transaction is smaller than the original transactions, unless there is a considerable feerate bump, this rule isn't possible to observe.\n>> I my question is: is it possible or reasonable to relax this rule? If this rule was removed in its entirety, does it introduce any DoS vectors? Or can it be changed to allow my use-case?\n>\n> It would definitely introduce DoS vectors by making it much cheaper to use\n> relay bandwidth. You'd also be able to push others' txs out of the mempool.\n>\n>> ---------------------------------------------------------------\n>>\n>> Full backstory: I have been trying to use bip125 (Opt-in Full Replace-by-Fee) to do \"transaction merging\" on the fly. Let's say that I owe John 1 bitcoin, and have promised to pay him immediately: Instead of creating a whole new transaction if I have an in-flight (unconfirmed) transaction, I can follow the rules of bip125 to create a replacement that accomplishes this goal.\n>> From a \"coin selection\" point of view, this was significantly easier than\n>> I had anticipated. I was able to encode the rules in my linear model and\n>> feed in all my unspent and in-flight transactions and it can solve it without difficulty.\n>> However, the real problem is tracking the mess. Consider this sequence of events:\n>>\n>> - I have unconfirmed transaction A\n>> - I replace it with B, which pays John 1 BTC\n>> - Transaction A gets confirmed\n>>\n>> So now I still owe John 1 BTC, however it's not immediately clear if\n>> it's safe to send to him without waiting $n transactions. However even\n>> for a small $n, this breaks my promise to pay him immediately.\n>> One possible solution is to only consider a transaction \"replaceable\" if it has change, so if the original transaction confirms -- payments can immediately be made that source the change, and provide safety in a reorg.\n>> However, this will only work <50% of the time for me (most transactions\n>> don't have change) and opens a pandora's box of complexity.\n>\n> Most transactions don't have change?! Under what circumstance? For most\n> use-cases the reverse is true: almost all all transactions have change, because\n> it's rare for the inputs to exactly math the requested payment.\n>\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180122/1abc39e2/attachment.html>"
            },
            {
                "author": "Rhavar",
                "date": "2018-01-23T16:31:36",
                "message_text_only": "Getting back on topic:\n\n> It would definitely introduce DoS vectors by making it much cheaper to use\n> relay bandwidth.\n\nI think I'm missing something, as I don't really understand this DoS vector. Relay bandwidth is already very cheap and easy to use by repeatedly fee bumping. And it's not obvious to me that requiring an absolute higher fee actually makes such an attack more expensive.\n\nI can see that my \"proposed\" change would make it cheaper to evict low-fee transactions from other node's mempool. Maybe I'm being naive, but I don't really see why this would be such a big deal.\n\nBut what about a compromise, and require that the absolute fee must be >= half the original fees. I know everyone hates magic values, but I think in practice it will allow legitimate and useful use of \"retroactive transaction merging\" without much downside.\n\nAnd really the great thing about \"retroactive transaction merging\" is just how easy it is to implement. In fact, right now it's quite possible to do -- but because of the \"higher absolute fee\" rule the benefits are pretty muted (although if you can compress 2 change into 1, that's still likely worthwhile)\n\n-Ryan\n\n-------- Original Message --------\nOn January 22, 2018 3:00 PM, Peter Todd <pete at petertodd.org> wrote:\n\n> On Mon, Jan 22, 2018 at 12:40:31PM -0500, Rhavar via bitcoin-dev wrote:\n>\n>> So my half-baked idea is very simple:\n>> Allow users to merge multiple unconfirmed transactions, stripping extraneous inputs and change as they go.\n>> This is currently not possible because of the bip125 rule:\n>> \"The replacement transaction pays an absolute fee of at least the sum paid by the original transactions.\"\n>> Because the size of the merged transaction is smaller than the original transactions, unless there is a considerable feerate bump, this rule isn't possible to observe.\n>> I my question is: is it possible or reasonable to relax this rule? If this rule was removed in its entirety, does it introduce any DoS vectors? Or can it be changed to allow my use-case?\n>\n> It would definitely introduce DoS vectors by making it much cheaper to use\n> relay bandwidth. You'd also be able to push others' txs out of the mempool.\n>\n>> ---------------------------------------------------------------\n>>\n>> Full backstory: I have been trying to use bip125 (Opt-in Full Replace-by-Fee) to do \"transaction merging\" on the fly. Let's say that I owe John 1 bitcoin, and have promised to pay him immediately: Instead of creating a whole new transaction if I have an in-flight (unconfirmed) transaction, I can follow the rules of bip125 to create a replacement that accomplishes this goal.\n>> From a \"coin selection\" point of view, this was significantly easier than\n>> I had anticipated. I was able to encode the rules in my linear model and\n>> feed in all my unspent and in-flight transactions and it can solve it without difficulty.\n>> However, the real problem is tracking the mess. Consider this sequence of events:\n>>\n>> - I have unconfirmed transaction A\n>> - I replace it with B, which pays John 1 BTC\n>> - Transaction A gets confirmed\n>>\n>> So now I still owe John 1 BTC, however it's not immediately clear if\n>> it's safe to send to him without waiting $n transactions. However even\n>> for a small $n, this breaks my promise to pay him immediately.\n>> One possible solution is to only consider a transaction \"replaceable\" if it has change, so if the original transaction confirms -- payments can immediately be made that source the change, and provide safety in a reorg.\n>> However, this will only work <50% of the time for me (most transactions\n>> don't have change) and opens a pandora's box of complexity.\n>\n> Most transactions don't have change?! Under what circumstance? For most\n> use-cases the reverse is true: almost all all transactions have change, because\n> it's rare for the inputs to exactly math the requested payment.\n>\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180123/aada91c2/attachment.html>"
            },
            {
                "author": "Moral Agent",
                "date": "2018-01-23T21:56:41",
                "message_text_only": "Another way to limit abuse would be to have the fee *rate* be required to\nincrease, which is kind of the spirit of RBF, applied to this situation.\n\nThat is to say, if you wished to replace transactions A and B with C which\nspends the same inputs as A and B, then the following must be true before C\nwill be relayed:\n\n(Fee_A + Fee_B) / (Weight_A + Weight_B) < Fee_C / Weight_C\n\nOn Tue, Jan 23, 2018 at 11:31 AM, Rhavar via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Getting back on topic:\n>\n>\n> It would definitely introduce DoS vectors by making it much cheaper to use\n> relay bandwidth.\n>\n>\n> I think I'm missing something, as I don't really understand this DoS\n> vector. Relay bandwidth is already very cheap and easy to use by repeatedly\n> fee bumping. And it's not obvious to me that requiring an absolute higher\n> fee actually makes such an attack more expensive.\n>\n> I can see that my \"proposed\" change would make it cheaper to evict low-fee\n> transactions from other node's mempool. Maybe I'm being naive, but I don't\n> really see why this would be such a big deal.\n>\n> But what about a compromise, and require that the absolute fee must be >=\n> half the original fees. I know everyone hates magic values, but I think in\n> practice it will allow legitimate and useful use of \"retroactive\n> transaction merging\" without much downside.\n>\n> And really the great thing about \"retroactive transaction merging\" is just\n> how easy it is to implement. In fact, right now it's quite possible to do\n> -- but because of the \"higher absolute fee\" rule the benefits are pretty\n> muted (although if you can compress 2 change into 1, that's still likely\n> worthwhile)\n>\n>\n>\n> -Ryan\n>\n>\n> -------- Original Message --------\n> On January 22, 2018 3:00 PM, Peter Todd <pete at petertodd.org> wrote:\n>\n> On Mon, Jan 22, 2018 at 12:40:31PM -0500, Rhavar via bitcoin-dev wrote:\n>\n> So my half-baked idea is very simple:\n> Allow users to merge multiple unconfirmed transactions, stripping\n> extraneous inputs and change as they go.\n> This is currently not possible because of the bip125 rule:\n> \"The replacement transaction pays an absolute fee of at least the sum paid\n> by the original transactions.\"\n> Because the size of the merged transaction is smaller than the original\n> transactions, unless there is a considerable feerate bump, this rule isn't\n> possible to observe.\n> I my question is: is it possible or reasonable to relax this rule? If this\n> rule was removed in its entirety, does it introduce any DoS vectors? Or can\n> it be changed to allow my use-case?\n>\n>\n> It would definitely introduce DoS vectors by making it much cheaper to use\n> relay bandwidth. You'd also be able to push others' txs out of the mempool.\n>\n>\n> ------------------------------\n>\n> Full backstory: I have been trying to use bip125 (Opt-in Full\n> Replace-by-Fee) to do \"transaction merging\" on the fly. Let's say that I\n> owe John 1 bitcoin, and have promised to pay him immediately: Instead of\n> creating a whole new transaction if I have an in-flight (unconfirmed)\n> transaction, I can follow the rules of bip125 to create a replacement that\n> accomplishes this goal.\n> From a \"coin selection\" point of view, this was significantly easier than\n> I had anticipated. I was able to encode the rules in my linear model and\n> feed in all my unspent and in-flight transactions and it can solve it\n> without difficulty.\n> However, the real problem is tracking the mess. Consider this sequence of\n> events:\n>\n>    1. I have unconfirmed transaction A\n>    2. I replace it with B, which pays John 1 BTC\n>    3. Transaction A gets confirmed\n>\n> So now I still owe John 1 BTC, however it's not immediately clear if\n> it's safe to send to him without waiting $n transactions. However even\n> for a small $n, this breaks my promise to pay him immediately.\n> One possible solution is to only consider a transaction \"replaceable\" if\n> it has change, so if the original transaction confirms -- payments can\n> immediately be made that source the change, and provide safety in a reorg.\n> However, this will only work <50% of the time for me (most transactions\n> don't have change) and opens a pandora's box of complexity.\n>\n>\n> Most transactions don't have change?! Under what circumstance? For most\n> use-cases the reverse is true: almost all all transactions have change,\n> because\n> it's rare for the inputs to exactly math the requested payment.\n>\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180123/bded9fb7/attachment.html>"
            },
            {
                "author": "Rhavar",
                "date": "2018-01-23T22:19:59",
                "message_text_only": "Interesting. I didn't think about this before, but it seems like bip125 is rather incentive incompatible right now? If we're assuming a competitive mempool, it really doesn't seem generally rational to accept a replacement transaction of a lower fee rate.\n\nSo how about if we change the fee requirement to bet at least:\n\nMIN(\n         $ORIGINAL_FEE_RATE * $REPLACEMENT_TX_SIZE + $RELAY_FEE * ( REPLACEMENT_TX_SIZE + $ORIGINAL_SIZE),\n        $ORIGINAL_ABS_FEE  / 3\n)  in fees\n\nThis could make it:\n* More incentive compatible\n* Support more use-cases (my transaction merging example)\n* Be resistant to any attacks (that I can see, there's no doubt cases I haven't thought about)\n\n-Ryan\n\n-------- Original Message --------\nOn January 23, 2018 4:56 PM, Moral Agent <ethan.scruples at gmail.com> wrote:\n\n> Another way to limit abuse would be to have the fee *rate* be required to increase, which is kind of the spirit of RBF, applied to this situation.\n>\n> That is to say, if you wished to replace transactions A and B with C which spends the same inputs as A and B, then the following must be true before C will be relayed:\n>\n> (Fee_A + Fee_B) / (Weight_A + Weight_B) < Fee_C / Weight_C\n>\n> On Tue, Jan 23, 2018 at 11:31 AM, Rhavar via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Getting back on topic:\n>>\n>>> It would definitely introduce DoS vectors by making it much cheaper to use\n>>> relay bandwidth.\n>>\n>> I think I'm missing something, as I don't really understand this DoS vector. Relay bandwidth is already very cheap and easy to use by repeatedly fee bumping. And it's not obvious to me that requiring an absolute higher fee actually makes such an attack more expensive.\n>>\n>> I can see that my \"proposed\" change would make it cheaper to evict low-fee transactions from other node's mempool. Maybe I'm being naive, but I don't really see why this would be such a big deal.\n>>\n>> But what about a compromise, and require that the absolute fee must be >= half the original fees. I know everyone hates magic values, but I think in practice it will allow legitimate and useful use of \"retroactive transaction merging\" without much downside.\n>>\n>> And really the great thing about \"retroactive transaction merging\" is just how easy it is to implement. In fact, right now it's quite possible to do -- but because of the \"higher absolute fee\" rule the benefits are pretty muted (although if you can compress 2 change into 1, that's still likely worthwhile)\n>>\n>> -Ryan\n>>\n>> -------- Original Message --------\n>> On January 22, 2018 3:00 PM, Peter Todd <pete at petertodd.org> wrote:\n>>\n>>> On Mon, Jan 22, 2018 at 12:40:31PM -0500, Rhavar via bitcoin-dev wrote:\n>>>\n>>>> So my half-baked idea is very simple:\n>>>> Allow users to merge multiple unconfirmed transactions, stripping extraneous inputs and change as they go.\n>>>> This is currently not possible because of the bip125 rule:\n>>>> \"The replacement transaction pays an absolute fee of at least the sum paid by the original transactions.\"\n>>>> Because the size of the merged transaction is smaller than the original transactions, unless there is a considerable feerate bump, this rule isn't possible to observe.\n>>>> I my question is: is it possible or reasonable to relax this rule? If this rule was removed in its entirety, does it introduce any DoS vectors? Or can it be changed to allow my use-case?\n>>>\n>>> It would definitely introduce DoS vectors by making it much cheaper to use\n>>> relay bandwidth. You'd also be able to push others' txs out of the mempool.\n>>>\n>>>> ---------------------------------------------------------------\n>>>> Full backstory: I have been trying to use bip125 (Opt-in Full Replace-by-Fee) to do \"transaction merging\" on the fly. Let's say that I owe John 1 bitcoin, and have promised to pay him immediately: Instead of creating a whole new transaction if I have an in-flight (unconfirmed) transaction, I can follow the rules of bip125 to create a replacement that accomplishes this goal.\n>>>> From a \"coin selection\" point of view, this was significantly easier than\n>>>> I had anticipated. I was able to encode the rules in my linear model and\n>>>> feed in all my unspent and in-flight transactions and it can solve it without difficulty.\n>>>> However, the real problem is tracking the mess. Consider this sequence of events:\n>>>>\n>>>> - I have unconfirmed transaction A\n>>>> - I replace it with B, which pays John 1 BTC\n>>>> - Transaction A gets confirmed\n>>>> So now I still owe John 1 BTC, however it's not immediately clear if\n>>>> it's safe to send to him without waiting $n transactions. However even\n>>>> for a small $n, this breaks my promise to pay him immediately.\n>>>> One possible solution is to only consider a transaction \"replaceable\" if it has change, so if the original transaction confirms -- payments can immediately be made that source the change, and provide safety in a reorg.\n>>>> However, this will only work <50% of the time for me (most transactions\n>>>> don't have change) and opens a pandora's box of complexity.\n>>>\n>>> Most transactions don't have change?! Under what circumstance? For most\n>>> use-cases the reverse is true: almost all all transactions have change, because\n>>> it's rare for the inputs to exactly math the requested payment.\n>>>\n>>> https://petertodd.org 'peter'[:-1]@petertodd.org\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180123/42431dec/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-23T22:49:34",
                "message_text_only": "On Tue, Jan 23, 2018 at 10:19 PM, Rhavar via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Interesting. I didn't think about this before, but it seems like bip125 is\n> rather incentive incompatible right now? If we're assuming a competitive\n> mempool, it really doesn't seem generally rational to accept a replacement\n> transaction of a lower fee rate.\n\nBIP125 replacement requires that the fee rate increases.  The text of\nthe BIP document is written in a confusing way that doesn't make this\nclear."
            },
            {
                "author": "Peter Todd",
                "date": "2018-01-24T07:44:53",
                "message_text_only": "On Tue, Jan 23, 2018 at 10:49:34PM +0000, Gregory Maxwell via bitcoin-dev wrote:\n> On Tue, Jan 23, 2018 at 10:19 PM, Rhavar via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > Interesting. I didn't think about this before, but it seems like bip125 is\n> > rather incentive incompatible right now? If we're assuming a competitive\n> > mempool, it really doesn't seem generally rational to accept a replacement\n> > transaction of a lower fee rate.\n> \n> BIP125 replacement requires that the fee rate increases.  The text of\n> the BIP document is written in a confusing way that doesn't make this\n> clear.\n\nIn fact I considered only requiring an increase in fee rate, based on the\ntheory that if absolute fee went down, the transaction must be smaller and thus\nminers could overall earn more from the additional transactions they could fit\ninto their block. But to do that properly requires considering whether or not\nthat's actually true in the particular state the mempool as a whole happens to\nbe in, so I ditched that idea early on for the much simpler criteria of both a\nfeerate and absolute fee increase.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180124/473f7652/attachment.sig>"
            },
            {
                "author": "Alan Evans",
                "date": "2018-01-24T13:43:29",
                "message_text_only": "So, OP, in your scenario, you have 1 transaction in the mempool, A, then\nyou want to spend the change before confirmation, so you broadcast a new\ntransaction, B, which replaces A.\n\n> Because the size of the merged transaction is smaller than the original\ntransactions, unless there is a considerable feerate bump, this rule isn't\npossible to observe.\n\nI'm confused, the mempool only sees 1 transaction at a time, first A, then\nlater B. \" the original transactions\", plural, should not exist in the\nmempool.\n\nB's fee and rate needs to be larger than A's, but B will be greater than or\nequal to A anyway. So, just increasing the fee rate will cause a larger fee\nanyway.\n\nAm I missing something?\n\n\nOn Wed, Jan 24, 2018 at 3:44 AM, Peter Todd via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Tue, Jan 23, 2018 at 10:49:34PM +0000, Gregory Maxwell via bitcoin-dev\n> wrote:\n> > On Tue, Jan 23, 2018 at 10:19 PM, Rhavar via bitcoin-dev\n> > <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > > Interesting. I didn't think about this before, but it seems like\n> bip125 is\n> > > rather incentive incompatible right now? If we're assuming a\n> competitive\n> > > mempool, it really doesn't seem generally rational to accept a\n> replacement\n> > > transaction of a lower fee rate.\n> >\n> > BIP125 replacement requires that the fee rate increases.  The text of\n> > the BIP document is written in a confusing way that doesn't make this\n> > clear.\n>\n> In fact I considered only requiring an increase in fee rate, based on the\n> theory that if absolute fee went down, the transaction must be smaller and\n> thus\n> miners could overall earn more from the additional transactions they could\n> fit\n> into their block. But to do that properly requires considering whether or\n> not\n> that's actually true in the particular state the mempool as a whole\n> happens to\n> be in, so I ditched that idea early on for the much simpler criteria of\n> both a\n> feerate and absolute fee increase.\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180124/398e0de6/attachment.html>"
            },
            {
                "author": "Rhavar",
                "date": "2018-01-24T16:05:01",
                "message_text_only": ">I'm confused, the mempool\u00a0only sees 1 transaction at a time, first A, then later B. \"the original transactions\", plural, should not exist in the mempool.\n>\n>B's fee and rate needs to be larger than A's, but B will be greater than or equal to A anyway. So, just increasing the fee rate will cause a larger fee anyway.\n>\n>Am I missing something?\n\nKind of. The first case is that you do the \"smarter\" type of merging, where you get an original transaction and then say add an additional output(s) to it.\n\nThe issue with this, is from a practical perspective is _very_ complex. Because you really need to do a lot of tracking to see which of the two transactions actually confirm. And if you are promising fast payments, you can be stuck in a weird limbo state where you're waiting for the original one to \"safely\" confirm before it's safe to make a re-payment (even a non-malicious will likely contain the replacement).\n\nbip125 already supports this use-case, but I will suggest that the logic to deploy this is sufficiently complex that no one is going to attempt any time in the near future.\n\n\nBut \"retroactive transaction merging\" is actually pretty approachable problem for a service to implement. You just get N valid transactions you've made, merge them into one. Strip extraneous inputs[1], and combine and alter the change amount.\n\nThe reason this is so appealing to implement, is there is very little complexity. If the \"retroactive transaction merge\" fails, or doesn't get confirmed, it actually has no impact. If it does get confirmed, that's just pure cost-savings.\n\nHowever, the rules of bip125 currently make it (unnecessarily?) unappealing, because I can never lower the absolute amount of fees I pay. Hence I think it'd be pretty sweet if they could be relaxed to support this if it can be done in a pretty risk free way.\n\n\n\n[1] Need to be very careful with that, if you're ever merging a merged transaction.\n\n\n>\n>\n>On Wed, Jan 24, 2018 at 3:44 AM, Peter Todd via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>On Tue, Jan 23, 2018 at 10:49:34PM +0000, Gregory Maxwell via bitcoin-dev wrote:\n>> > On Tue, Jan 23, 2018 at 10:19 PM, Rhavar via bitcoin-dev\n>> > <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> > > Interesting. I didn't think about this before, but it seems like bip125 is\n>> > > rather incentive incompatible right now? If we're assuming a competitive\n>> > > mempool, it really doesn't seem generally rational to accept a replacement\n>> > > transaction of a lower fee rate.\n>> >\n>> > BIP125 replacement requires that the fee rate increases.\u00a0 The text of\n>> > the BIP document is written in a confusing way that doesn't make this\n>> > clear.\n>>\n>>In fact I considered only requiring an increase in fee rate, based on the\n>> theory that if absolute fee went down, the transaction must be smaller and thus\n>> miners could overall earn more from the additional transactions they could fit\n>> into their block. But to do that properly requires considering whether or not\n>> that's actually true in the particular state the mempool as a whole happens to\n>> be in, so I ditched that idea early on for the much simpler criteria of both a\n>> feerate and absolute fee increase.\n>>\n>> --\n>>https://petertodd.org 'peter'[:-1]@petertodd.org\n>>\n>>_______________________________________________\n>> bitcoin-dev mailing list\n>>bitcoin-dev at lists.linuxfoundation.org\n>>https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>"
            },
            {
                "author": "Sjors Provoost",
                "date": "2018-01-28T16:43:34",
                "message_text_only": "I can see how merging after the fact could be more practical than appending existing transactions.\n\nI think what Moral Agent suggested is the same as your original proposal, namely dropping rule 3. Only fee per weight unit increase from rule 4 would matter.\n\nThe minimum per WU increase could be far higher than the minimum relay fee. The few times I\u2019ve used RBF in practice I increased the fee by at least 50%. Rule 4 could be made more strict. I don\u2019t know what number, if any, would address concerns about relay spam?\n\nThis wouldn\u2019t be backward compatible. Does that matter as long as there\u2019s enough nodes that follow the new rules? Is there a punishment for relaying transactions that violate rule 3? Could a recipient using the older rules be mislead (in a way that\u2019s worse than the fact that RBF allows the sender to replace the transaction with anything they want anyway)?\n\nPeter Todd wrote:\n> You'd also be able to push others' txs out of the mempool.\nCan you elaborate on this issue?\n\nAnd wrote:\n> payment service for instance where a large number of deposits are aggregated into a smaller number of payments\n\nSo this would involve wallets (of users who deposit coins) cooperating with an exchange API to consolidate in-mempool transactions?\n\nAnd wrote:\n\n> In fact I considered only requiring an increase in fee rate, based on the\ntheory that if absolute fee went down, the transaction must be smaller and thus\nminers could overall earn more from the additional transactions they could fit\ninto their block. But to do that properly requires considering whether or not\nthat's actually true in the particular state the mempool as a whole happens to\nbe in, so I ditched that idea early on for the much simpler criteria of both a\nfeerate and absolute fee increase.\n\nWhy would you need to consider the whole mempool? Let\u2019s say a miner is considering to replace transaction A and B with transaction C, where C pays a higher fee per byte than both A and B. This creates space for ~ one additional transaction in the block. It seems to me the miner only needs to check that the lowest fee per weight transaction > min_fee(A,B). At least in first approximation.\n\nSjors\n\n> Op 24 jan. 2018, om 17:05 heeft Rhavar via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:\n> \n> \n>> I'm confused, the mempool only sees 1 transaction at a time, first A, then later B. \"the original transactions\", plural, should not exist in the mempool.\n>> \n>> B's fee and rate needs to be larger than A's, but B will be greater than or equal to A anyway. So, just increasing the fee rate will cause a larger fee anyway.\n>> \n>> Am I missing something?\n> \n> Kind of. The first case is that you do the \"smarter\" type of merging, where you get an original transaction and then say add an additional output(s) to it.\n> \n> The issue with this, is from a practical perspective is _very_ complex. Because you really need to do a lot of tracking to see which of the two transactions actually confirm. And if you are promising fast payments, you can be stuck in a weird limbo state where you're waiting for the original one to \"safely\" confirm before it's safe to make a re-payment (even a non-malicious will likely contain the replacement).\n> \n> bip125 already supports this use-case, but I will suggest that the logic to deploy this is sufficiently complex that no one is going to attempt any time in the near future.\n> \n> \n> But \"retroactive transaction merging\" is actually pretty approachable problem for a service to implement. You just get N valid transactions you've made, merge them into one. Strip extraneous inputs[1], and combine and alter the change amount.\n> \n> The reason this is so appealing to implement, is there is very little complexity. If the \"retroactive transaction merge\" fails, or doesn't get confirmed, it actually has no impact. If it does get confirmed, that's just pure cost-savings.\n> \n> However, the rules of bip125 currently make it (unnecessarily?) unappealing, because I can never lower the absolute amount of fees I pay. Hence I think it'd be pretty sweet if they could be relaxed to support this if it can be done in a pretty risk free way.\n> \n> \n> \n> [1] Need to be very careful with that, if you're ever merging a merged transaction.\n> \n> \n>> \n>> \n>> On Wed, Jan 24, 2018 at 3:44 AM, Peter Todd via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> On Tue, Jan 23, 2018 at 10:49:34PM +0000, Gregory Maxwell via bitcoin-dev wrote:\n>>>> On Tue, Jan 23, 2018 at 10:19 PM, Rhavar via bitcoin-dev\n>>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>> Interesting. I didn't think about this before, but it seems like bip125 is\n>>>>> rather incentive incompatible right now? If we're assuming a competitive\n>>>>> mempool, it really doesn't seem generally rational to accept a replacement\n>>>>> transaction of a lower fee rate.\n>>>> \n>>>> BIP125 replacement requires that the fee rate increases.  The text of\n>>>> the BIP document is written in a confusing way that doesn't make this\n>>>> clear.\n>>> \n>>> In fact I considered only requiring an increase in fee rate, based on the\n>>> theory that if absolute fee went down, the transaction must be smaller and thus\n>>> miners could overall earn more from the additional transactions they could fit\n>>> into their block. But to do that properly requires considering whether or not\n>>> that's actually true in the particular state the mempool as a whole happens to\n>>> be in, so I ditched that idea early on for the much simpler criteria of both a\n>>> feerate and absolute fee increase.\n>>> \n>>> --\n>>> https://petertodd.org 'peter'[:-1]@petertodd.org\n>>>"
            },
            {
                "author": "David A. Harding",
                "date": "2018-01-28T17:29:48",
                "message_text_only": "On Sun, Jan 28, 2018 at 05:43:34PM +0100, Sjors Provoost via bitcoin-dev wrote:\n> Peter Todd wrote:\n> > In fact I considered only requiring an increase in fee rate, based on the\n> > theory that if absolute fee went down, the transaction must be smaller and thus\n> > miners could overall earn more from the additional transactions they could fit\n> > into their block. But to do that properly requires considering whether or not\n> > that's actually true in the particular state the mempool as a whole happens to\n> > be in, so I ditched that idea early on for the much simpler criteria of both a\n> > feerate and absolute fee increase.\n> \n> Why would you need to consider the whole mempool? \n\nImagine a miner is only concerned with creating the next block and his\nmempool currently only has 750,000 vbytes in it.  If two 250-vbyte\ntransactions each paying a feerate of 100 nanobitcoins per vbyte (50k\ntotal) are replaced with one 325-vbyte transaction paying a feerate of\n120 nBTC (39k total), the miner's potential income from mining the next\nblock is reduced by 11k nBTC.\n\nMoving away from this easily worked example, the problem can still exist\neven if a miner has enough transactions to fill the next block.  For\nreplacement consideration only by increased feerate to be guaranteed\nmore profitable, one has to assume the mempool contains an effectively\ncontinuous distribution of feerates.  That may one day be true of the\nmempool (it would be good, because it helps keep block production\nregular sans subsidy) but it's often not the case these days.\n\n-Dave\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 819 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180128/f2431b67/attachment.sig>"
            },
            {
                "author": "Rhavar",
                "date": "2018-01-28T17:58:11",
                "message_text_only": "I don't think this is a realistic concern. The incentive compatibility _already_ exists (just in reverse: miners are refusing transactions that would increase their total fees in the next block), and as the mempool is already generally competitive enough it's actually worse the way it is.\n\nBut I don't think it makes sense to take a zealous approach on \"incentive compatibility\". Bitcoin is already built on a whole bunch of incentive incompatible behaviors, even things as simple as \"change outputs\" (you'd be better off privately giving your transaction to trusted miners without change, who deduct the min fee they would've needed and refund the rest OOB). Not to mention, we expect miners to avoid reorgs and stuff even if it's in their short-term interest.\n\nAt least personally, I think DoS risks are the real concern.\n\n-Ryan\n\n-------- Original Message --------\nOn January 28, 2018 12:29 PM, David A. Harding <dave at dtrt.org> wrote:\n\n> On Sun, Jan 28, 2018 at 05:43:34PM +0100, Sjors Provoost via bitcoin-dev wrote:\n>\n>> Peter Todd wrote:\n>>\n>>> In fact I considered only requiring an increase in fee rate, based on the\n>>> theory that if absolute fee went down, the transaction must be smaller and thus\n>>> miners could overall earn more from the additional transactions they could fit\n>>> into their block. But to do that properly requires considering whether or not\n>>> that's actually true in the particular state the mempool as a whole happens to\n>>> be in, so I ditched that idea early on for the much simpler criteria of both a\n>>> feerate and absolute fee increase.\n>>\n>> Why would you need to consider the whole mempool?\n>\n> Imagine a miner is only concerned with creating the next block and his\n> mempool currently only has 750,000 vbytes in it. If two 250-vbyte\n> transactions each paying a feerate of 100 nanobitcoins per vbyte (50k\n> total) are replaced with one 325-vbyte transaction paying a feerate of\n> 120 nBTC (39k total), the miner's potential income from mining the next\n> block is reduced by 11k nBTC.\n>\n> Moving away from this easily worked example, the problem can still exist\n> even if a miner has enough transactions to fill the next block. For\n> replacement consideration only by increased feerate to be guaranteed\n> more profitable, one has to assume the mempool contains an effectively\n> continuous distribution of feerates. That may one day be true of the\n> mempool (it would be good, because it helps keep block production\n> regular sans subsidy) but it's often not the case these days.\n>\n> -Dave\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180128/bc4e57d3/attachment-0001.html>"
            },
            {
                "author": "Moral Agent",
                "date": "2018-01-28T18:08:33",
                "message_text_only": "As you point out, depending on the mempool, sometimes a miner makes more\nfee by including A and B, while other times a miner makes more fee by\nincluding C (the replacement for A and B) and D (a hypothetical transaction\nthat cannot be fit into a block that contains A and B but can be fit into a\nblock with C.\n\nSo what are we to make of this? Is it better to relay C or better to not\nrelay C?\n\nClearly it is better for the miner if they know about C, because knowing\nabout C costs them nothing, but not knowing about C will sometimes result\nin them earning less fees.\n\nClearly it is better for the people who are creating C for those\ntransactions to be mined instead of the more expensive A and B transactions.\n\nEveryone else is better off in that more transactions would get included in\nblocks.\n\nA concern about burdening full nodes with extra transactions to relay that\nmay not be more profitable to mine than the transactions they replace is\nstill rational -- though intuitively it seems like there would be a limit\non how many times an attacker could cheaply reorganize transactions into\nsomething with a higher fee rate.\n\nPerhaps there are also concerns with reconstruction of blocks from compact\nblocks, given that miners would have more decisions to make about which tx\nto include?\n\n\n\nOn Sun, Jan 28, 2018 at 12:29 PM, David A. Harding via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Sun, Jan 28, 2018 at 05:43:34PM +0100, Sjors Provoost via bitcoin-dev\n> wrote:\n> > Peter Todd wrote:\n> > > In fact I considered only requiring an increase in fee rate, based on\n> the\n> > > theory that if absolute fee went down, the transaction must be smaller\n> and thus\n> > > miners could overall earn more from the additional transactions they\n> could fit\n> > > into their block. But to do that properly requires considering whether\n> or not\n> > > that's actually true in the particular state the mempool as a whole\n> happens to\n> > > be in, so I ditched that idea early on for the much simpler criteria\n> of both a\n> > > feerate and absolute fee increase.\n> >\n> > Why would you need to consider the whole mempool?\n>\n> Imagine a miner is only concerned with creating the next block and his\n> mempool currently only has 750,000 vbytes in it.  If two 250-vbyte\n> transactions each paying a feerate of 100 nanobitcoins per vbyte (50k\n> total) are replaced with one 325-vbyte transaction paying a feerate of\n> 120 nBTC (39k total), the miner's potential income from mining the next\n> block is reduced by 11k nBTC.\n>\n> Moving away from this easily worked example, the problem can still exist\n> even if a miner has enough transactions to fill the next block.  For\n> replacement consideration only by increased feerate to be guaranteed\n> more profitable, one has to assume the mempool contains an effectively\n> continuous distribution of feerates.  That may one day be true of the\n> mempool (it would be good, because it helps keep block production\n> regular sans subsidy) but it's often not the case these days.\n>\n> -Dave\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180128/3c990f38/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-23T21:31:00",
                "message_text_only": "On Mon, Jan 22, 2018 at 8:00 PM, Peter Todd via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Most transactions don't have change?! Under what circumstance? For most\n> use-cases the reverse is true: almost all all transactions have change, because\n> it's rare for the inputs to exactly math the requested payment.\n\nIt's quite easy to get no change with a not-dumb algorithm selecting\ncoins if you have a decent number of outputs well under the value\nyou're paying.\n\nThe number of ways n choose m combines grows exponentially, and you\nonly need to get close enough over the right value so that you're\npaying excess fees equal or less than the cost of the change (which\nshould include the current cost output itself as well as estimated\ncost of the future signature to spend it).\n\nAchow101 and Murch have code to implement an efficient algorithm for\nfinding these solutions for Bitcoin core which will hopefully get in\nsoon."
            },
            {
                "author": "Peter Todd",
                "date": "2018-01-24T07:28:35",
                "message_text_only": "On Tue, Jan 23, 2018 at 09:31:00PM +0000, Gregory Maxwell wrote:\n> On Mon, Jan 22, 2018 at 8:00 PM, Peter Todd via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > Most transactions don't have change?! Under what circumstance? For most\n> > use-cases the reverse is true: almost all all transactions have change, because\n> > it's rare for the inputs to exactly math the requested payment.\n> \n> It's quite easy to get no change with a not-dumb algorithm selecting\n> coins if you have a decent number of outputs well under the value\n> you're paying.\n> \n> The number of ways n choose m combines grows exponentially, and you\n> only need to get close enough over the right value so that you're\n> paying excess fees equal or less than the cost of the change (which\n> should include the current cost output itself as well as estimated\n> cost of the future signature to spend it).\n> \n> Achow101 and Murch have code to implement an efficient algorithm for\n> finding these solutions for Bitcoin core which will hopefully get in\n> soon.\n\nOh, Bitcoin Core doesn't already do that? I though that was what the (rather\ncomplex) knapsack code was supposed to be doing.\n\nIn any case, you're assuming that there actually are a large number of outputs.\nThat's not likely to be the case in most \"consumer-like\" use-cases where the\nnumber of deposits into the wallet is relatively low compared to the number of\nwithdrawls as coins are spent in smaller amounts; that's the pattern most of my\nBitcoin usage follows, particularly as I keep the amount of funds in my hot\nwallets low.\n\nHaving said that, Rhavar's usage patterns could easily be different; I'd be\ncompletely wrong in the case of a payment service for instance where a large\nnumber of deposits are aggregated into a smaller number of payments; that\nuse-case happens to be a particularly interesting one for using tx replacement\nto add outputs, so my criticism was definitely premature.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180124/e656471f/attachment.sig>"
            },
            {
                "author": "Rhavar",
                "date": "2018-01-22T18:18:14",
                "message_text_only": "> If you spent your change from transaction A, that would be safe. There'd be no way you John could end up with 2 BTC from you then.\n\nYes, that's what the following paragraph says -- along with it's limitations =)\n\n-Ryan\n\n-------- Original Message --------\nOn January 22, 2018 1:16 PM, Alan Evans <thealanevans at gmail.com> wrote:\n\n>> So now I still owe John 1 BTC, however it's not immediately clear if it's safe to send to him\n>\n> If you spent your change from transaction A, that would be safe. There'd be no way you John could end up with 2 BTC from you then.\n>\n> On Mon, Jan 22, 2018 at 1:40 PM, Rhavar via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> So my half-baked idea is very simple:\n>>\n>> Allow users to merge multiple unconfirmed transactions, stripping extraneous inputs and change as they go.\n>>\n>> This is currently not possible because of the bip125 rule:\n>> \"The replacement transaction pays an absolute fee of at least the sum paid by the original transactions.\"\n>>\n>> Because the size of the merged transaction is smaller than the original transactions, unless there is a considerable feerate bump, this rule isn't possible to observe.\n>>\n>> I my question is: is it possible or reasonable to relax this rule? If this rule was removed in its entirety, does it introduce any DoS vectors? Or can it be changed to allow my use-case?\n>>\n>> ---\n>> Full backstory: I have been trying to use bip125 (Opt-in Full Replace-by-Fee) to do \"transaction merging\" on the fly. Let's say that I owe John 1 bitcoin, and have promised to pay him immediately: Instead of creating a whole new transaction if I have an in-flight (unconfirmed) transaction, I can follow the rules of bip125 to create a replacement that accomplishes this goal.\n>>\n>> From a \"coin selection\" point of view, this was significantly easier than\n>> I had anticipated. I was able to encode the rules in my linear model and\n>> feed in all my unspent and in-flight transactions and it can solve it without difficulty.\n>>\n>> However, the real problem is tracking the mess. Consider this sequence of events:\n>> 1) I have unconfirmed transaction A\n>> 2) I replace it with B, which pays John 1 BTC\n>> 3) Transaction A gets confirmed\n>>\n>> So now I still owe John 1 BTC, however it's not immediately clear if\n>> it's safe to send to him without waiting $n transactions. However even\n>> for a small $n, this breaks my promise to pay him immediately.\n>>\n>> One possible solution is to only consider a transaction \"replaceable\" if it has change, so if the original transaction confirms -- payments can immediately be made that source the change, and provide safety in a reorg.\n>>\n>> However, this will only work <50% of the time for me (most transactions\n>> don't have change) and opens a pandora's box of complexity.\n>>\n>> There's a few other hacks you can do to make it work in a few more cases, but nothing that is realistic to expect anyone to implement any time soon.\n>>\n>> However, if there was a straight foward way to merge N unconfirmed transactions, it would be easy get into production, and potentially offer some pretty nice savings for everyone.\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180122/f0b58cf0/attachment-0001.html>"
            },
            {
                "author": "Moral Agent",
                "date": "2018-01-22T18:50:31",
                "message_text_only": "Along the same lines, I wonder if unrelated people with tx that are not\nconfirming could cooperate to merge their disparate tx into a CoinJoin tx\nwith a higher fee rate?\n\nPerhaps they could even replace old tx with economically equivalent summary\ntransactions?\n\nThe mempool seems like nature's accumulator for pre-mining compression\nopportunities.\n\nOn Mon, Jan 22, 2018 at 1:18 PM, Rhavar via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> > If you spent your change from transaction A, that would be safe. There'd\n> be no way you John could end up with 2 BTC from you then.\n>\n> Yes, that's what the following paragraph says -- along with it's\n> limitations =)\n>\n> -Ryan\n>\n>\n> -------- Original Message --------\n> On January 22, 2018 1:16 PM, Alan Evans <thealanevans at gmail.com> wrote:\n>\n> > So now I still owe John 1 BTC, however it's not immediately clear if it's\n> safe to send to him\n>\n> If you spent your change from transaction A, that would be safe. There'd\n> be no way you John could end up with 2 BTC from you then.\n>\n> On Mon, Jan 22, 2018 at 1:40 PM, Rhavar via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> So my half-baked idea is very simple:\n>>\n>> Allow users to merge multiple unconfirmed transactions, stripping\n>> extraneous inputs and change as they go.\n>>\n>> This is currently not possible because of the bip125 rule:\n>> \"The replacement transaction pays an absolute fee of at least the sum\n>> paid by the original transactions.\"\n>>\n>> Because the size of the merged transaction is smaller than the original\n>> transactions, unless there is a considerable feerate bump, this rule isn't\n>> possible to observe.\n>>\n>>\n>> I my question is: is it possible or reasonable to relax this rule? If\n>> this rule was removed in its entirety, does it introduce any DoS vectors?\n>> Or can it be changed to allow my use-case?\n>>\n>>\n>> ---\n>> Full backstory: I have been trying to use bip125 (Opt-in Full\n>> Replace-by-Fee) to do \"transaction merging\" on the fly. Let's say that I\n>> owe John 1 bitcoin, and have promised to pay him immediately: Instead of\n>> creating a whole new transaction if I have an in-flight (unconfirmed)\n>> transaction, I can follow the rules of bip125 to create a replacement that\n>> accomplishes this goal.\n>>\n>> From a \"coin selection\" point of view, this was significantly easier than\n>> I had anticipated. I was able to encode the rules in my linear model and\n>> feed in all my unspent and in-flight transactions and it can solve it\n>> without difficulty.\n>>\n>> However, the real problem is tracking the mess. Consider this sequence of\n>> events:\n>> 1) I have unconfirmed transaction A\n>> 2) I replace it with B, which pays John 1 BTC\n>> 3) Transaction A gets confirmed\n>>\n>> So now I still owe John 1 BTC, however it's not immediately clear if\n>> it's safe to send to him without waiting $n transactions. However even\n>> for a small $n, this breaks my promise to pay him immediately.\n>>\n>> One possible solution is to only consider a transaction \"replaceable\" if\n>> it has change, so if the original transaction confirms -- payments can\n>> immediately be made that source the change, and provide safety in a reorg.\n>>\n>> However, this will only work <50% of the time for me (most transactions\n>> don't have change) and opens a pandora's box of complexity.\n>>\n>> There's a few other hacks you can do to make it work in a few more cases,\n>> but nothing that is realistic to expect anyone to implement any time soon.\n>>\n>> However, if there was a straight foward way to merge N unconfirmed\n>> transactions, it would be easy get into production, and potentially offer\n>> some pretty nice savings for everyone.\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180122/8273b051/attachment.html>"
            },
            {
                "author": "Rhavar",
                "date": "2018-01-22T18:59:34",
                "message_text_only": "> Perhaps they could even replace old tx with economically equivalent summary transactions?\n\nI imagine with schnorr signatures, the incentives will emerge for that to make sense. But right now if I want to merge my transaction with an untrusted party in general we're only really going to be saving like 12 bytes of overhead or something. But if I'm merging my own transactions, I can get that fixed overhead, strip extraneous inputs and merge my change outputs (which also means in the future it's cheaper to spend).\n\nAlthough it's obviously a lot worse for privacy, I do like the pattern of broadcast the transaction standalone and then merge it for savings. It helps keep the more or less fire-and-forget style, without a ridiculous amount of complexity \"if this happens, do this, if this, then this, ...\"\n\n-Ryan\n\n-Ryan\n\n-------- Original Message --------\nOn January 22, 2018 1:50 PM, Moral Agent <ethan.scruples at gmail.com> wrote:\n\n> Along the same lines, I wonder if unrelated people with tx that are not confirming could cooperate to merge their disparate tx into a CoinJoin tx with a higher fee rate?\n>\n> Perhaps they could even replace old tx with economically equivalent summary transactions?\n>\n> The mempool seems like nature's accumulator for pre-mining compression opportunities.\n>\n> On Mon, Jan 22, 2018 at 1:18 PM, Rhavar via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>>> If you spent your change from transaction A, that would be safe. There'd be no way you John could end up with 2 BTC from you then.\n>>\n>> Yes, that's what the following paragraph says -- along with it's limitations =)\n>>\n>> -Ryan\n>>\n>> -------- Original Message --------\n>> On January 22, 2018 1:16 PM, Alan Evans <thealanevans at gmail.com> wrote:\n>>\n>>>> So now I still owe John 1 BTC, however it's not immediately clear if it's safe to send to him\n>>>\n>>> If you spent your change from transaction A, that would be safe. There'd be no way you John could end up with 2 BTC from you then.\n>>>\n>>> On Mon, Jan 22, 2018 at 1:40 PM, Rhavar via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> So my half-baked idea is very simple:\n>>>>\n>>>> Allow users to merge multiple unconfirmed transactions, stripping extraneous inputs and change as they go.\n>>>>\n>>>> This is currently not possible because of the bip125 rule:\n>>>> \"The replacement transaction pays an absolute fee of at least the sum paid by the original transactions.\"\n>>>>\n>>>> Because the size of the merged transaction is smaller than the original transactions, unless there is a considerable feerate bump, this rule isn't possible to observe.\n>>>>\n>>>> I my question is: is it possible or reasonable to relax this rule? If this rule was removed in its entirety, does it introduce any DoS vectors? Or can it be changed to allow my use-case?\n>>>>\n>>>> ---\n>>>> Full backstory: I have been trying to use bip125 (Opt-in Full Replace-by-Fee) to do \"transaction merging\" on the fly. Let's say that I owe John 1 bitcoin, and have promised to pay him immediately: Instead of creating a whole new transaction if I have an in-flight (unconfirmed) transaction, I can follow the rules of bip125 to create a replacement that accomplishes this goal.\n>>>>\n>>>> From a \"coin selection\" point of view, this was significantly easier than\n>>>> I had anticipated. I was able to encode the rules in my linear model and\n>>>> feed in all my unspent and in-flight transactions and it can solve it without difficulty.\n>>>>\n>>>> However, the real problem is tracking the mess. Consider this sequence of events:\n>>>> 1) I have unconfirmed transaction A\n>>>> 2) I replace it with B, which pays John 1 BTC\n>>>> 3) Transaction A gets confirmed\n>>>>\n>>>> So now I still owe John 1 BTC, however it's not immediately clear if\n>>>> it's safe to send to him without waiting $n transactions. However even\n>>>> for a small $n, this breaks my promise to pay him immediately.\n>>>>\n>>>> One possible solution is to only consider a transaction \"replaceable\" if it has change, so if the original transaction confirms -- payments can immediately be made that source the change, and provide safety in a reorg.\n>>>>\n>>>> However, this will only work <50% of the time for me (most transactions\n>>>> don't have change) and opens a pandora's box of complexity.\n>>>>\n>>>> There's a few other hacks you can do to make it work in a few more cases, but nothing that is realistic to expect anyone to implement any time soon.\n>>>>\n>>>> However, if there was a straight foward way to merge N unconfirmed transactions, it would be easy get into production, and potentially offer some pretty nice savings for everyone.\n>>>>\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180122/074be1a4/attachment.html>"
            },
            {
                "author": "Adam Ficsor",
                "date": "2018-01-23T23:31:59",
                "message_text_only": "> It's quite easy to get no change with a not-dumb algorithm selecting\ncoins if you have a decent number of outputs well under the value\nyou're paying.\n\nI have been playing around quite a lot these lines, too and created some\ncontent that is worth to look at:\nhttps://github.com/nopara73/ZeroLink/#coin-selection\nAlso, you can try a simpler privacy oriented coin control implementation\nwith HiddenWallet:\nhttps://medium.com/@nopara73/coin-control-is-must-learn-if-you-care-about-your-privacy-in-bitcoin-33b9a5f224a2\n\n-- \nBest,\n\u00c1d\u00e1m\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180124/7ad7b524/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Transaction Merging (bip125 relaxation)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "David A. Harding",
                "Adam Ficsor",
                "Peter Todd",
                "Gregory Maxwell",
                "Sjors Provoost",
                "Moral Agent",
                "Rhavar",
                "Alan Evans"
            ],
            "messages_count": 21,
            "total_messages_chars_count": 66015
        }
    },
    {
        "title": "[bitcoin-dev] Blockchain Voluntary Fork (Split) Proposal (Chaofan Li)",
        "thread_messages": [
            {
                "author": "Ilan Oh",
                "date": "2018-01-22T19:01:02",
                "message_text_only": "How do you handle the mining on each chain ?\n\nThe chain with the most mining power will tend to have more value.\n\nAlso blocks are not mined equally and 1 chain will be longer than the other\nthus faster thus more valuable.\n\nIt seems to be a sidechain proposal with the exact same protocol.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180122/17485223/attachment.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2018-01-22T19:59:39",
                "message_text_only": "> On Jan 22, 2018, at 11:01 AM, Ilan Oh via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> The chain with the most mining power will tend to have more value.\n\nI believe you have the causality on that backwards. The tokens which are worth more value will attract more mining hash rate. Miners respond to cash-out value, they don\u2019t set it."
            },
            {
                "author": "Eric Voskuil",
                "date": "2018-01-22T22:52:23",
                "message_text_only": "This is true but confuses people because obviously miners must commit capital to mining before any block space can exist to have value. The reason for the misunderstanding is that miners don\u2019t simply respond, they anticipate. All production, and therefore capital investment, is the result of anticipation of future returns, not an attempt to chase past returns.\n\nThe first miner anticipated that the then-worthless \u201ctokens\u201d he was mining would have a future value. Turns out he was right. Others have been wrong, which is the nature of betting on future prices. But if nobody does it, there are no products.\n\ne\n\n> On Jan 22, 2018, at 11:59, Mark Friedenbach via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> \n>> On Jan 22, 2018, at 11:01 AM, Ilan Oh via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> \n>> The chain with the most mining power will tend to have more value.\n> \n> I believe you have the causality on that backwards. The tokens which are worth more value will attract more mining hash rate. Miners respond to cash-out value, they don\u2019t set it.\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Chaofan Li",
                "date": "2018-01-23T00:38:10",
                "message_text_only": "Miners are most likely to be  equally distributed between the two almost\nsame chains.\nIf one chain is faster, according to the difficulty adjustment scheme, it\nwill become more difficult to mine.\nThe two chain should have similar chain generation rates with similar\ndifficulty and similar length.\nor the miners will be attracted to the chain easier to mine,\nand more miners will make the chain generation rate increase and then,\nafter difficulty adjustment, harder to mine.\nEquilibrium will be achieved.\n\nAll the above are based on one assumption: the two chains have the same\nvalue initially or miners believe they will  have  the same value finally.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180122/7828930b/attachment-0001.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2018-01-23T04:57:46",
                "message_text_only": "On 01/22/2018 04:38 PM, Chaofan Li via bitcoin-dev wrote:\n> Miners are most likely to be\u00a0 equally distributed between the two almost\n> same chains.\n\nThis is irrelevant as miners don't determine the utility of a money,\nthey anticipate it. However you don't have to accept this to recognize\nthe error of the argument below...\n\n> If one chain is faster, according to the difficulty adjustment scheme,\n> it will become more difficult to mine.\n\nMining difficulty controls the block period, not miner return on capital.\n\n> The two chain should have similar chain generation rates with similar\n> difficulty and similar length.\n\nThis is the consequence of the presumed common regulation of the block\nperiod. It matters not how useful are either of the monies.\n\n> or the miners will be attracted to the chain easier to mine,\u00a0\n> and more miners will make the chain generation rate increase and then,\n> after difficulty adjustment, harder to mine.\n\nYou are conflating difficulty with profitability. These are not the same\nthing. A chain can be more difficult and less profitable and the\nreverse. Profitability is controlled by competition, as it is in all\nmarkets. Competition is controlled by the cost of capital, which is in\nturn controlled by time preference. Mining seeks the same level of\nprofitability for any coin, regardless of how difficultly. This applies\nto all industry - difficulty does not regulate profit, it's just a cost.\n\n> Equilibrium will be achieved.> All the above are based on one assumption: the two chains have the same\n> value initially or miners believe they will\u00a0 have\u00a0 the same value finally.\n\nActually the opposite is the case. Even if we could start at a point of\nperfect equality, the smallest change in the number of merchants or\nhuman perception of the money (as examples), would lead one to be\nslightly better. All things being equal that alone would lead to\nelimination of one money in favor of the other.\n\nOne money is inherently better than two, as there is an exchange cost\nbetween them. In the absence of exchange controls the better money gets\nused, and in this case that can simply be the result of a slightly\nlarger network (or perception of it).\n\ne\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180122/ed6da88f/attachment.sig>"
            },
            {
                "author": "Chaofan Li",
                "date": "2018-01-23T05:47:27",
                "message_text_only": "The human perception of difference will be eliminated.\nWill your bank tell you whether your balance means coins or paper money?\nIf wallets and exchanges only show the total amount of btc rather than\nbtc.0 and btc.1, there is no human perception difference.\n\nAlso note that one valid address is automatically valid on the other chain,\nwhich means you can send money through any one chain. As long as one has\nthe private key, he/she can get the money anyway. So there is no difference\nbetween number of merchants. The merchant \u2018s address is valid on both\nchains.\n\nThe exchange cost would be trivial. People don\u2019t need to exchange two same\nthing.\n\nChaofan\n\n\n\nOn Mon, Jan 22, 2018 at 10:57 PM Eric Voskuil <eric at voskuil.org> wrote:\n\n> On 01/22/2018 04:38 PM, Chaofan Li via bitcoin-dev wrote:\n> > Miners are most likely to be  equally distributed between the two almost\n> > same chains.\n>\n> This is irrelevant as miners don't determine the utility of a money,\n> they anticipate it. However you don't have to accept this to recognize\n> the error of the argument below...\n>\n> > If one chain is faster, according to the difficulty adjustment scheme,\n> > it will become more difficult to mine.\n>\n> Mining difficulty controls the block period, not miner return on capital.\n>\n> > The two chain should have similar chain generation rates with similar\n> > difficulty and similar length.\n>\n> This is the consequence of the presumed common regulation of the block\n> period. It matters not how useful are either of the monies.\n>\n> > or the miners will be attracted to the chain easier to mine,\n> > and more miners will make the chain generation rate increase and then,\n> > after difficulty adjustment, harder to mine.\n>\n> You are conflating difficulty with profitability. These are not the same\n> thing. A chain can be more difficult and less profitable and the\n> reverse. Profitability is controlled by competition, as it is in all\n> markets. Competition is controlled by the cost of capital, which is in\n> turn controlled by time preference. Mining seeks the same level of\n> profitability for any coin, regardless of how difficultly. This applies\n> to all industry - difficulty does not regulate profit, it's just a cost.\n>\n> > Equilibrium will be achieved.> All the above are based on one\n> assumption: the two chains have the same\n> > value initially or miners believe they will  have  the same value\n> finally.\n>\n> Actually the opposite is the case. Even if we could start at a point of\n> perfect equality, the smallest change in the number of merchants or\n> human perception of the money (as examples), would lead one to be\n> slightly better. All things being equal that alone would lead to\n> elimination of one money in favor of the other.\n>\n> One money is inherently better than two, as there is an exchange cost\n> between them. In the absence of exchange controls the better money gets\n> used, and in this case that can simply be the result of a slightly\n> larger network (or perception of it).\n>\n> e\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180123/16978647/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-01-30T05:32:58",
                "message_text_only": "Good Morning Chaofan Li,\n\n> The human perception of difference will be eliminated.\n> Will your bank tell you whether your balance means coins or paper money?\n> If wallets and exchanges only show the total amount of btc rather than btc.0 and btc.1, there is no human perception difference.\n\nThis returns my initial question.\n\nWhat ensures that a paper money with \"10 Dollar\" on it, is same as 10 coins each with \"1 Dollar\" on it?\n\nThis is the principle of fungibility, and means I can exchange a paper with \"10 Dollar\" on it for 10 coins with \"1 Dollar\" on it, because by government fiat, such an exchange is valid for all cases.\n\nWhat ensures that btc.0 and btc.1 are indistinguishable from a human perception?\n\n> Also note that one valid address is automatically valid on the other chain, which means you can send money through any one chain. As long as one has the private key, he/she can get the money anyway. So there is no difference between number of merchants. The merchant \u2018s address is valid on both chains.\n>\n> The exchange cost would be trivial. People don\u2019t need to exchange two same thing.\n\nYou are talking about sidechains.  In every sidechain proposal, there is always some mechanism (SPV proof-of-work, drivechain proof-of-voting, proof-of-mainstake...) that ensures that a sidechain coin is exchangeable for a mainchain coin, and from there, that every sidechain coin is exchangeable for every other sidechain coin.  I.e. that a smart contract with \"1 BTC\" on it is exchangeable for a mainchain UTXO of value \"1 BTC\".\n\nA mere split is not enough.  As I brought up, what makes your proposal different from 2X, BCash, etc.?\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180130/faa9616f/attachment.html>"
            },
            {
                "author": "Chaofan Li",
                "date": "2018-01-30T06:20:35",
                "message_text_only": "Hi ZmnSCPxj,\n\n\nOn Mon, Jan 29, 2018 at 9:32 PM, ZmnSCPxj wrote:\n>What ensures that a paper money with \"10 Dollar\" on it, is same as 10\ncoins each with \"1 Dollar\" on it?\n>This is the principle of fungibility, and means I can exchange a paper\nwith \"10 Dollar\" on it for 10 coins with \"1 Dollar\" on it, because by\ngovernment fiat, such an exchange is valid for all cases.\n>What ensures that btc.0 and btc.1 are indistinguishable from a human\nperception?\n\nThis is a good question. Does anyone think about why the bitcoins generated\nfrom different blocks have the same value? Some of them are still\ndistinguishable ( if they are not combined with others sent out).  Would\nthe bitcoins that can be traced back to the block where it was generated\nbe worth different from others ?   If one day Satoshi released\nhis/her/their bitcoins  , would the bitcoins from the first several blocks\nmined by Satoshi be worth more?\n\nI think for fungibility, it is not like either it has fungibility or it has\nno fungibility. There should be a value of fungibility (e.g. from 0 to 1)\nthat can be measured or evaluated.\n\nChaofan\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180129/2db54fc6/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Blockchain Voluntary Fork (Split) Proposal (Chaofan Li)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Eric Voskuil",
                "Chaofan Li",
                "Ilan Oh",
                "ZmnSCPxj",
                "Mark Friedenbach"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 11728
        }
    },
    {
        "title": "[bitcoin-dev] Taproot: Privacy preserving switchable scripting",
        "thread_messages": [
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-23T00:30:06",
                "message_text_only": "Interest in merkelized scriptPubKeys (e.g. MAST) is driven by two main\nareas: efficiency and privacy. Efficiency because unexecuted forks of\na script can avoid ever hitting the chain, and privacy because hiding\nunexecuted code leaves scripts indistinguishable to the extent that\ntheir only differences are in the unexecuted parts.\n\nAs Mark Friedenbach and others have pointed out before it is almost\nalways the case that interesting scripts have a logical top level\nbranch which allows satisfaction of the contract with nothing other\nthan a signature by all parties.  Other branches would only be used\nwhere some participant is failing to cooperate. More strongly stated,\nI believe that _any_ contract with a fixed finite participant set\nupfront can be and should be represented as an OR between an N-of-N\nand whatever more complex contract you might want to represent.\n\nOne point that comes up while talking about merkelized scripts is can\nwe go about making fancier contract use cases as indistinguishable as\npossible from the most common and boring payments. Otherwise, if the\nanonymity set of fancy usage is only other fancy usage it may not be\nvery large in practice. One suggestion has been that ordinary\nchecksig-only scripts should include a dummy branch for the rest of\nthe tree (e.g. a random value hash), making it look like there are\npotentially alternative rules when there aren't really.  The negative\nside of this is an additional 32-byte overhead for the overwhelmingly\ncommon case which doesn't need it.  I think the privacy gains are\nworth doing such a thing, but different people reason differently\nabout these trade-offs.\n\nIt turns out, however, that there is no need to make a trade-off.  The\nspecial case of a top level \"threshold-signature OR\narbitrary-conditions\" can be made indistinguishable from a normal\none-party signature, with no overhead at all, with a special\ndelegating CHECKSIG which I call Taproot.\n\nLet's say we want to create a coin that can be redeemed by either\nAlice && Bob   or by CSV-timelock && Bob.\n\nAlice has public A, Bob has pubkey B.\n\nWe compute the 2-of-2 aggregate key C = A + B.  (Simplified; to\nprotect against rogue key attacks you may want to use the MuSig key\naggregation function [1])\n\nWe form our timelock script S =  \"<timeout> OP_CSV OP_DROP B OP_CHECKSIGVERIFY\"\n\nNow we tweak C to produce P which is the key we'll publish: P = C + H(C||S)G.\n\n(This is the attack hardened pay-to-contract construction described in [2])\n\nThen we pay to a scriptPubKey of [Taproot supporting version] [EC point P].\n\nNow Alice and Bob-- assuming they are both online and agree about the\nresolution of their contract-- can jointly form a 2 of 2 signature for\nP, and spend as if it were a payment to a single party (one of them\njust needs to add H(C||S) to their private key).\n\nAlternatively, the Taproot consensus rules would allow this script to\nbe satisfied by someone who provides the network with C (the original\ncombined pubkey), S, and does whatever S requires-- e.g. passes the\nCSV check and provides Bob's signature. With this information the\nnetwork can verify that C + H(C||S) == P.\n\nSo in the all-sign case there is zero overhead; and no one can tell\nthat the contract alternative exists. In the alternative redemption\nbranch the only overhead is revealing the original combined pubkey\nand, of course, the existence of the contract is made public.\n\nThis composes just fine with whatever other merkelized script system\nwe might care to use, as the S can be whatever kind of data we want,\nincluding the root of some tree.\n\nMy example shows 2-of-2 but it works the same for any number of\nparticipants (and with setup interaction any threshold of\nparticipants, so long as you don't mind an inability to tell which\nmembers signed off).\n\nThe verification computational complexity of signature path is\nobviously the same as any other plain signature (since its\nindistinguishable). Verification of the branch redemption requires a\nhash and a multiplication with a constant point which is strictly more\nefficient than a signature verification and could be efficiently fused\ninto batch signature validation.\n\nThe nearest competitor to this idea that I can come up with would\nsupporting a simple delegation where the output can be spent by the\nnamed key, or a spending transaction could provide a script along with\na signature of that script by the named key, delegating control to the\nsigned script. Before paying into that escrow Alice/Bob would\nconstruct this signature. This idea is equally efficient in the common\ncase, but larger and slower to verify in the alternative spend case.\nSetting up the signature requires additional interaction between\nparticipants and the resulting signature must be durably stored and\ncouldn't just be recomputed using single-party information.\n\nI believe this construction will allow the largest possible anonymity\nset for fixed party smart contracts by making them look like the\nsimplest possible payments. It accomplishes this without any overhead\nin the common case, invoking any sketchy or impractical techniques,\nrequiring extra rounds of interaction between contract participants,\nand without requiring the durable storage of other data.\n\n\n[1] https://eprint.iacr.org/2018/068\n[2] https://blockstream.com/sidechains.pdf Appendix A"
            },
            {
                "author": "Chris Belcher",
                "date": "2018-01-23T01:55:07",
                "message_text_only": "This sounds like a useful idea for improving the privacy of coinswap.\nTraditionally coinswap mixing had an anonymity set related to the number\nof multisig transactions being used on the blockchain. With the new tech\nof Schnorr, MAST and now this Taproot, with sufficient adoption\ncoinswap's anonymity set could be much higher, potentially including\nalmost every other on-chain transaction.\n\n[1] https://bitcointalk.org/index.php?topic=321228.0\n[2] https://github.com/AdamISZ/CoinSwapCS\n\nOn 23/01/18 00:30, Gregory Maxwell via bitcoin-dev wrote:\n> Interest in merkelized scriptPubKeys (e.g. MAST) is driven by two main\n> areas: efficiency and privacy. Efficiency because unexecuted forks of\n> a script can avoid ever hitting the chain, and privacy because hiding\n> unexecuted code leaves scripts indistinguishable to the extent that\n> their only differences are in the unexecuted parts.\n> \n> As Mark Friedenbach and others have pointed out before it is almost\n> always the case that interesting scripts have a logical top level\n> branch which allows satisfaction of the contract with nothing other\n> than a signature by all parties.  Other branches would only be used\n> where some participant is failing to cooperate. More strongly stated,\n> I believe that _any_ contract with a fixed finite participant set\n> upfront can be and should be represented as an OR between an N-of-N\n> and whatever more complex contract you might want to represent.\n> \n> One point that comes up while talking about merkelized scripts is can\n> we go about making fancier contract use cases as indistinguishable as\n> possible from the most common and boring payments. Otherwise, if the\n> anonymity set of fancy usage is only other fancy usage it may not be\n> very large in practice. One suggestion has been that ordinary\n> checksig-only scripts should include a dummy branch for the rest of\n> the tree (e.g. a random value hash), making it look like there are\n> potentially alternative rules when there aren't really.  The negative\n> side of this is an additional 32-byte overhead for the overwhelmingly\n> common case which doesn't need it.  I think the privacy gains are\n> worth doing such a thing, but different people reason differently\n> about these trade-offs.\n> \n> It turns out, however, that there is no need to make a trade-off.  The\n> special case of a top level \"threshold-signature OR\n> arbitrary-conditions\" can be made indistinguishable from a normal\n> one-party signature, with no overhead at all, with a special\n> delegating CHECKSIG which I call Taproot.\n> \n> Let's say we want to create a coin that can be redeemed by either\n> Alice && Bob   or by CSV-timelock && Bob.\n> \n> Alice has public A, Bob has pubkey B.\n> \n> We compute the 2-of-2 aggregate key C = A + B.  (Simplified; to\n> protect against rogue key attacks you may want to use the MuSig key\n> aggregation function [1])\n> \n> We form our timelock script S =  \"<timeout> OP_CSV OP_DROP B OP_CHECKSIGVERIFY\"\n> \n> Now we tweak C to produce P which is the key we'll publish: P = C + H(C||S)G.\n> \n> (This is the attack hardened pay-to-contract construction described in [2])\n> \n> Then we pay to a scriptPubKey of [Taproot supporting version] [EC point P].\n> \n> Now Alice and Bob-- assuming they are both online and agree about the\n> resolution of their contract-- can jointly form a 2 of 2 signature for\n> P, and spend as if it were a payment to a single party (one of them\n> just needs to add H(C||S) to their private key).\n> \n> Alternatively, the Taproot consensus rules would allow this script to\n> be satisfied by someone who provides the network with C (the original\n> combined pubkey), S, and does whatever S requires-- e.g. passes the\n> CSV check and provides Bob's signature. With this information the\n> network can verify that C + H(C||S) == P.\n> \n> So in the all-sign case there is zero overhead; and no one can tell\n> that the contract alternative exists. In the alternative redemption\n> branch the only overhead is revealing the original combined pubkey\n> and, of course, the existence of the contract is made public.\n> \n> This composes just fine with whatever other merkelized script system\n> we might care to use, as the S can be whatever kind of data we want,\n> including the root of some tree.\n> \n> My example shows 2-of-2 but it works the same for any number of\n> participants (and with setup interaction any threshold of\n> participants, so long as you don't mind an inability to tell which\n> members signed off).\n> \n> The verification computational complexity of signature path is\n> obviously the same as any other plain signature (since its\n> indistinguishable). Verification of the branch redemption requires a\n> hash and a multiplication with a constant point which is strictly more\n> efficient than a signature verification and could be efficiently fused\n> into batch signature validation.\n> \n> The nearest competitor to this idea that I can come up with would\n> supporting a simple delegation where the output can be spent by the\n> named key, or a spending transaction could provide a script along with\n> a signature of that script by the named key, delegating control to the\n> signed script. Before paying into that escrow Alice/Bob would\n> construct this signature. This idea is equally efficient in the common\n> case, but larger and slower to verify in the alternative spend case.\n> Setting up the signature requires additional interaction between\n> participants and the resulting signature must be durably stored and\n> couldn't just be recomputed using single-party information.\n> \n> I believe this construction will allow the largest possible anonymity\n> set for fixed party smart contracts by making them look like the\n> simplest possible payments. It accomplishes this without any overhead\n> in the common case, invoking any sketchy or impractical techniques,\n> requiring extra rounds of interaction between contract participants,\n> and without requiring the durable storage of other data.\n> \n> \n> [1] https://eprint.iacr.org/2018/068\n> [2] https://blockstream.com/sidechains.pdf Appendix A\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Matt Corallo",
                "date": "2018-01-23T02:51:51",
                "message_text_only": "Thanks Greg!\n\nI'd be hesitant to deploy a MAST proposal without this clever application of pay-to-contract-hash now! Looks like the overhead over a more-naive MAST construction is rather trivial, too!\n\nMatt\n\nOn January 23, 2018 12:30:06 AM UTC, Gregory Maxwell via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>Interest in merkelized scriptPubKeys (e.g. MAST) is driven by two main\n>areas: efficiency and privacy. Efficiency because unexecuted forks of\n>a script can avoid ever hitting the chain, and privacy because hiding\n>unexecuted code leaves scripts indistinguishable to the extent that\n>their only differences are in the unexecuted parts.\n>\n>As Mark Friedenbach and others have pointed out before it is almost\n>always the case that interesting scripts have a logical top level\n>branch which allows satisfaction of the contract with nothing other\n>than a signature by all parties.  Other branches would only be used\n>where some participant is failing to cooperate. More strongly stated,\n>I believe that _any_ contract with a fixed finite participant set\n>upfront can be and should be represented as an OR between an N-of-N\n>and whatever more complex contract you might want to represent.\n>\n>One point that comes up while talking about merkelized scripts is can\n>we go about making fancier contract use cases as indistinguishable as\n>possible from the most common and boring payments. Otherwise, if the\n>anonymity set of fancy usage is only other fancy usage it may not be\n>very large in practice. One suggestion has been that ordinary\n>checksig-only scripts should include a dummy branch for the rest of\n>the tree (e.g. a random value hash), making it look like there are\n>potentially alternative rules when there aren't really.  The negative\n>side of this is an additional 32-byte overhead for the overwhelmingly\n>common case which doesn't need it.  I think the privacy gains are\n>worth doing such a thing, but different people reason differently\n>about these trade-offs.\n>\n>It turns out, however, that there is no need to make a trade-off.  The\n>special case of a top level \"threshold-signature OR\n>arbitrary-conditions\" can be made indistinguishable from a normal\n>one-party signature, with no overhead at all, with a special\n>delegating CHECKSIG which I call Taproot.\n>\n>Let's say we want to create a coin that can be redeemed by either\n>Alice && Bob   or by CSV-timelock && Bob.\n>\n>Alice has public A, Bob has pubkey B.\n>\n>We compute the 2-of-2 aggregate key C = A + B.  (Simplified; to\n>protect against rogue key attacks you may want to use the MuSig key\n>aggregation function [1])\n>\n>We form our timelock script S =  \"<timeout> OP_CSV OP_DROP B\n>OP_CHECKSIGVERIFY\"\n>\n>Now we tweak C to produce P which is the key we'll publish: P = C +\n>H(C||S)G.\n>\n>(This is the attack hardened pay-to-contract construction described in\n>[2])\n>\n>Then we pay to a scriptPubKey of [Taproot supporting version] [EC point\n>P].\n>\n>Now Alice and Bob-- assuming they are both online and agree about the\n>resolution of their contract-- can jointly form a 2 of 2 signature for\n>P, and spend as if it were a payment to a single party (one of them\n>just needs to add H(C||S) to their private key).\n>\n>Alternatively, the Taproot consensus rules would allow this script to\n>be satisfied by someone who provides the network with C (the original\n>combined pubkey), S, and does whatever S requires-- e.g. passes the\n>CSV check and provides Bob's signature. With this information the\n>network can verify that C + H(C||S) == P.\n>\n>So in the all-sign case there is zero overhead; and no one can tell\n>that the contract alternative exists. In the alternative redemption\n>branch the only overhead is revealing the original combined pubkey\n>and, of course, the existence of the contract is made public.\n>\n>This composes just fine with whatever other merkelized script system\n>we might care to use, as the S can be whatever kind of data we want,\n>including the root of some tree.\n>\n>My example shows 2-of-2 but it works the same for any number of\n>participants (and with setup interaction any threshold of\n>participants, so long as you don't mind an inability to tell which\n>members signed off).\n>\n>The verification computational complexity of signature path is\n>obviously the same as any other plain signature (since its\n>indistinguishable). Verification of the branch redemption requires a\n>hash and a multiplication with a constant point which is strictly more\n>efficient than a signature verification and could be efficiently fused\n>into batch signature validation.\n>\n>The nearest competitor to this idea that I can come up with would\n>supporting a simple delegation where the output can be spent by the\n>named key, or a spending transaction could provide a script along with\n>a signature of that script by the named key, delegating control to the\n>signed script. Before paying into that escrow Alice/Bob would\n>construct this signature. This idea is equally efficient in the common\n>case, but larger and slower to verify in the alternative spend case.\n>Setting up the signature requires additional interaction between\n>participants and the resulting signature must be durably stored and\n>couldn't just be recomputed using single-party information.\n>\n>I believe this construction will allow the largest possible anonymity\n>set for fixed party smart contracts by making them look like the\n>simplest possible payments. It accomplishes this without any overhead\n>in the common case, invoking any sketchy or impractical techniques,\n>requiring extra rounds of interaction between contract participants,\n>and without requiring the durable storage of other data.\n>\n>\n>[1] https://eprint.iacr.org/2018/068\n>[2] https://blockstream.com/sidechains.pdf Appendix A\n>_______________________________________________\n>bitcoin-dev mailing list\n>bitcoin-dev at lists.linuxfoundation.org\n>https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180123/2ff10ec6/attachment-0001.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2018-01-23T14:39:37",
                "message_text_only": "I had the opposite response in private, which I will share here. As recently as Jan 9th feedback on BIP 117 was shared on this list by Pieter Wuille and others suggesting we adopt native MAST template instead of the user programmable combination of BIPs 116 and 117. Part of my response then was, I quote:\n\nI havent the hubris to suggest that we know exactly what a templated MAST *should* look like. It's not used in production anywhere. Even if we did have the foresight, the tail-call semantics allow for other constructions besides MAST and for the sake of the future we should allow such permission-less innovation. The proper sequence of events should be to enable features in a generic way, and then to create specialized templates to save space for common constructions. Not the other way around. [1]\n\nI take this advance as further evidence in favor of this view. As recently as 24 hours ago if you had asked what a native-MAST template would have looked like, the answer would have been something like Johnson Lau\u2019s BIP 114, with some quibbling over details. Taproot is a clearly superior approach. But is it optimal? I don\u2019t think we can claim that now. Optimality of these constructs isn\u2019t something easily proven, with the nearest substitute being unchanging consensus over extended periods of time.\n\nEvery time we add an output type specialization, we introduce a new codepath in the core of the script consensus that must be maintained forever. Take P2SH: from this point forward there is no reason to use it in new applications, ever. But it must be forever supported. In an alternate universe we could have deployed a native MAST proposal, like BIP 114, only to have Taproot-like schemes discovered after activation. That would have been a sucky outcome. It is still the case that we could go for Taproot right now, and then in six months or a year\u2019s time we find an important tweak or a different approach entirely that is even better, but the activation process had already started. That would be a sucky outcome we haven\u2019t avoided yet.\n\nThis is not an argument against template specialization for common code paths, especially those which increase fungibility of coins. I do think we should have a native MAST template eventually, using Taproot or something better. However if I may be allowed I will make an educated guess about the origin of Taproot: I think it\u2019s no coincidence that Greg had this insight and/or wrote it up simultaneous with a push by myself and others for getting MAST features into bitcoin via BIPs 98, 116, and 117, or 114. Cryptographers tend to only think up solutions to problems that are on their minds. And the problems on most people\u2019s minds are primarily those that are deployable today, or otherwise near-term applicable.\n\nBIPS 116 and 117 each provide a reusable component that together happens to enable a generic form of MAST. Even without the workarounds required to avoid CLEANSTACK violations, the resulting MAST template is larger than what is possible with specialization. However let\u2019s not forget that (1) they also enable other applications like honeypots, key trees, and script delegation; and relevant to this conversation (2) they get the MAST feature available for use in production by the wider community. I don\u2019t think I\u2019d personally be willing to bet that we found the optimal MAST structure in Greg\u2019s Taproot until we have people doing interesting production work like multisig wallets, lightning protocol, and the next set of consensus features start putting it into production and exploring edge cases. We may find ways Taproot can be tweaked to enable other applications (like encoding a hash preimage as well) or simplify obscure corner cases.\n\nI feel quite strongly that the correct approach is to add support for generic features to accomplish the underlying goal in a user programmable way, and THEN after activation and some usage consider ways in which common use cases can be made more efficient through output specialization. To take a more obvious example, lightning protocol is still an active area or research and I think it is abundantly clear that we don\u2019t know yet what the globally optimal layer-2 caching protocol will be, even if we have educated guesses as to its broad structure. A proposal right now to standardize a more compact lightning script type would be rightly rejected. It is less obvious but just as true that the same should hold for MAST.\n\nI have argued these points before in favor of permission less innovation first, then application specialization later, in [1] and at the end of the rather long email [2]. I hope you can take the time to read those if you still feel we should take a specialized template approach instead of the user programmable BIPSs 116 and 117.\n\n[1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-January/015537.html <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-January/015537.html>\n[2] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-September/015029.html <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-September/015029.html>\n\n> On Jan 22, 2018, at 6:51 PM, Matt Corallo via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Thanks Greg!\n> \n> I'd be hesitant to deploy a MAST proposal without this clever application of pay-to-contract-hash now! Looks like the overhead over a more-naive MAST construction is rather trivial, too!\n> \n> Matt\n> \n> On January 23, 2018 12:30:06 AM UTC, Gregory Maxwell via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Interest in merkelized scriptPubKeys (e.g. MAST) is driven by two main\n> areas: efficiency and privacy. Efficiency because unexecuted forks of\n> a script can avoid ever hitting the chain, and privacy because hiding\n> unexecuted code leaves scripts indistinguishable to the extent that\n> their only differences are in the unexecuted parts.\n> \n> As Mark Friedenbach and others have pointed out before it is almost\n> always the case that interesting scripts have a logical top level\n> branch which allows satisfaction of the contract with nothing other\n> than a signature by all parties.  Other branches would only be used\n> where some participant is failing to cooperate. More strongly stated,\n> I believe that _any_ contract with a fixed finite participant set\n> upfront can be and should be represented as an OR between an N-of-N\n> and whatever more complex contract you might want to represent.\n> \n> One point that comes up while talking about merkelized scripts is can\n> we go about making fancier contract use cases as indistinguishable as\n> possible from the most common and boring payments. Otherwise, if the\n> anonymity set of fancy usage is only other fancy usage it may not be\n> very large in practice. One suggestion has been that ordinary\n> checksig-only scripts should include a dummy branch for the rest of\n> the tree (e.g. a random value hash), making it look like there are\n> potentially alternative rules when there aren't really.  The negative\n> side of this is an additional 32-byte overhead for the overwhelmingly\n> common case which doesn't need it.  I think the privacy gains are\n> worth doing such a thing, but different people reason differently\n> about these trade-offs.\n> \n> It turns out, however, that there is no need to make a trade-off.  The\n> special case of a top level \"threshold-signature OR\n> arbitrary-conditions\" can be made indistinguishable from a normal\n> one-party signature, with no overhead at all, with a special\n> delegating CHECKSIG which I call Taproot.\n> \n> Let's say we want to create a coin that can be redeemed by either\n> Alice && Bob   or by CSV-timelock && Bob.\n> \n> Alice has public A, Bob has pubkey B.\n> \n> We compute the 2-of-2 aggregate key C = A + B.  (Simplified; to\n> protect against rogue key attacks you may want to use the MuSig key\n> aggregation function [1])\n> \n> We form our timelock script S =  \"<timeout> OP_CSV OP_DROP B OP_CHECKSIGVERIFY\"\n> \n> Now we tweak C to produce P which is the key we'll publish: P = C + H(C||S)G.\n> \n> (This is the attack hardened pay-to-contract construction described in [2])\n> \n> Then we pay to a scriptPubKey of [Taproot supporting version] [EC point P].\n> \n> Now Alice and Bob-- assuming they are both online and agree about the\n> resolution of their contract-- can jointly form a 2 of 2 signature for\n> P, and spend as if it were a payment to a single party (one of them\n> just needs to add H(C||S) to their private key).\n> \n> Alternatively, the Taproot consensus rules would allow this script to\n> be satisfied by someone who provides the network with C (the original\n> combined pubkey), S, and does whatever S requires-- e.g. passes the\n> CSV check and provides Bob's signature. With this information the\n> network can verify that C + H(C||S) == P.\n> \n> So in the all-sign case there is zero overhead; and no one can tell\n> that the contract alternative exists. In the alternative redemption\n> branch the only overhead is revealing the original combined pubkey\n> and, of course, the existence of the contract is made public.\n> \n> This composes just fine with whatever other merkelized script system\n> we might care to use, as the S can be whatever kind of data we want,\n> including the root of some tree.\n> \n> My example shows 2-of-2 but it works the same for any number of\n> participants (and with setup interaction any threshold of\n> participants, so long as you don't mind an inability to tell which\n> members signed off).\n> \n> The verification computational complexity of signature path is\n> obviously the same as any other plain signature (since its\n> indistinguishable). Verification of the branch redemption requires a\n> hash and a multiplication with a constant point which is strictly more\n> efficient than a signature verification and could be efficiently fused\n> into batch signature validation.\n> \n> The nearest competitor to this idea that I can come up with would\n> supporting a simple delegation where the output can be spent by the\n> named key, or a spending transaction could provide a script along with\n> a signature of that script by the named key, delegating control to the\n> signed script. Before paying into that escrow Alice/Bob would\n> construct this signature. This idea is equally efficient in the common\n> case, but larger and slower to verify in the alternative spend case.\n> Setting up the signature requires additional interaction between\n> participants and the resulting signature must be durably stored and\n> couldn't just be recomputed using single-party information.\n> \n> I believe this construction will allow the largest possible anonymity\n> set for fixed party smart contracts by making them look like the\n> simplest possible payments. It accomplishes this without any overhead\n> in the common case, invoking any sketchy or impractical techniques,\n> requiring extra rounds of interaction between contract participants,\n> and without requiring the durable storage of other data.\n> \n> \n> [1] https://eprint.iacr.org/2018/068 <https://eprint.iacr.org/2018/068>\n> [2] https://blockstream.com/sidechains.pdf <https://blockstream.com/sidechains.pdf> Appendix A\n> \n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180123/3b3b7dd0/attachment-0001.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2018-01-23T21:23:21",
                "message_text_only": "The issue with that approach without support for the privacy-encouraging wrapper proposed by Greg here is that it encourages adoption halfway and destroys a lot of the value of the apparent-script monoculture for privacy preservation. Greg's proposal here doesn't change the format of any specific MAST implementation, but instead adds the privacy wrapper that I always felt was missing in existing proposals, without any real additional overhead in many use-cases!\n\nIndeed, permissionless innovation is important, but the huge advantage of providing the privacy wrapper by default here is absolutely massive to the ecosystem and should not be handwaved away for vague possibly-advantages.\n\nMatt\n\nOn January 23, 2018 2:39:37 PM UTC, Mark Friedenbach <mark at friedenbach.org> wrote:\n>I had the opposite response in private, which I will share here. As\n>recently as Jan 9th feedback on BIP 117 was shared on this list by\n>Pieter Wuille and others suggesting we adopt native MAST template\n>instead of the user programmable combination of BIPs 116 and 117. Part\n>of my response then was, I quote:\n>\n>I havent the hubris to suggest that we know exactly what a templated\n>MAST *should* look like. It's not used in production anywhere. Even if\n>we did have the foresight, the tail-call semantics allow for other\n>constructions besides MAST and for the sake of the future we should\n>allow such permission-less innovation. The proper sequence of events\n>should be to enable features in a generic way, and then to create\n>specialized templates to save space for common constructions. Not the\n>other way around. [1]\n>\n>I take this advance as further evidence in favor of this view. As\n>recently as 24 hours ago if you had asked what a native-MAST template\n>would have looked like, the answer would have been something like\n>Johnson Lau\u2019s BIP 114, with some quibbling over details. Taproot is a\n>clearly superior approach. But is it optimal? I don\u2019t think we can\n>claim that now. Optimality of these constructs isn\u2019t something easily\n>proven, with the nearest substitute being unchanging consensus over\n>extended periods of time.\n>\n>Every time we add an output type specialization, we introduce a new\n>codepath in the core of the script consensus that must be maintained\n>forever. Take P2SH: from this point forward there is no reason to use\n>it in new applications, ever. But it must be forever supported. In an\n>alternate universe we could have deployed a native MAST proposal, like\n>BIP 114, only to have Taproot-like schemes discovered after activation.\n>That would have been a sucky outcome. It is still the case that we\n>could go for Taproot right now, and then in six months or a year\u2019s time\n>we find an important tweak or a different approach entirely that is\n>even better, but the activation process had already started. That would\n>be a sucky outcome we haven\u2019t avoided yet.\n>\n>This is not an argument against template specialization for common code\n>paths, especially those which increase fungibility of coins. I do think\n>we should have a native MAST template eventually, using Taproot or\n>something better. However if I may be allowed I will make an educated\n>guess about the origin of Taproot: I think it\u2019s no coincidence that\n>Greg had this insight and/or wrote it up simultaneous with a push by\n>myself and others for getting MAST features into bitcoin via BIPs 98,\n>116, and 117, or 114. Cryptographers tend to only think up solutions to\n>problems that are on their minds. And the problems on most people\u2019s\n>minds are primarily those that are deployable today, or otherwise\n>near-term applicable.\n>\n>BIPS 116 and 117 each provide a reusable component that together\n>happens to enable a generic form of MAST. Even without the workarounds\n>required to avoid CLEANSTACK violations, the resulting MAST template is\n>larger than what is possible with specialization. However let\u2019s not\n>forget that (1) they also enable other applications like honeypots, key\n>trees, and script delegation; and relevant to this conversation (2)\n>they get the MAST feature available for use in production by the wider\n>community. I don\u2019t think I\u2019d personally be willing to bet that we found\n>the optimal MAST structure in Greg\u2019s Taproot until we have people doing\n>interesting production work like multisig wallets, lightning protocol,\n>and the next set of consensus features start putting it into production\n>and exploring edge cases. We may find ways Taproot can be tweaked to\n>enable other applications (like encoding a hash preimage as well) or\n>simplify obscure corner cases.\n>\n>I feel quite strongly that the correct approach is to add support for\n>generic features to accomplish the underlying goal in a user\n>programmable way, and THEN after activation and some usage consider\n>ways in which common use cases can be made more efficient through\n>output specialization. To take a more obvious example, lightning\n>protocol is still an active area or research and I think it is\n>abundantly clear that we don\u2019t know yet what the globally optimal\n>layer-2 caching protocol will be, even if we have educated guesses as\n>to its broad structure. A proposal right now to standardize a more\n>compact lightning script type would be rightly rejected. It is less\n>obvious but just as true that the same should hold for MAST.\n>\n>I have argued these points before in favor of permission less\n>innovation first, then application specialization later, in [1] and at\n>the end of the rather long email [2]. I hope you can take the time to\n>read those if you still feel we should take a specialized template\n>approach instead of the user programmable BIPSs 116 and 117.\n>\n>[1]\n>https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-January/015537.html\n><https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-January/015537.html>\n>[2]\n>https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-September/015029.html\n><https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-September/015029.html>\n>\n>> On Jan 22, 2018, at 6:51 PM, Matt Corallo via bitcoin-dev\n><bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> \n>> Thanks Greg!\n>> \n>> I'd be hesitant to deploy a MAST proposal without this clever\n>application of pay-to-contract-hash now! Looks like the overhead over a\n>more-naive MAST construction is rather trivial, too!\n>> \n>> Matt\n>> \n>> On January 23, 2018 12:30:06 AM UTC, Gregory Maxwell via bitcoin-dev\n><bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> Interest in merkelized scriptPubKeys (e.g. MAST) is driven by two\n>main\n>> areas: efficiency and privacy. Efficiency because unexecuted forks of\n>> a script can avoid ever hitting the chain, and privacy because hiding\n>> unexecuted code leaves scripts indistinguishable to the extent that\n>> their only differences are in the unexecuted parts.\n>> \n>> As Mark Friedenbach and others have pointed out before it is almost\n>> always the case that interesting scripts have a logical top level\n>> branch which allows satisfaction of the contract with nothing other\n>> than a signature by all parties.  Other branches would only be used\n>> where some participant is failing to cooperate. More strongly stated,\n>> I believe that _any_ contract with a fixed finite participant set\n>> upfront can be and should be represented as an OR between an N-of-N\n>> and whatever more complex contract you might want to represent.\n>> \n>> One point that comes up while talking about merkelized scripts is can\n>> we go about making fancier contract use cases as indistinguishable as\n>> possible from the most common and boring payments. Otherwise, if the\n>> anonymity set of fancy usage is only other fancy usage it may not be\n>> very large in practice. One suggestion has been that ordinary\n>> checksig-only scripts should include a dummy branch for the rest of\n>> the tree (e.g. a random value hash), making it look like there are\n>> potentially alternative rules when there aren't really.  The negative\n>> side of this is an additional 32-byte overhead for the overwhelmingly\n>> common case which doesn't need it.  I think the privacy gains are\n>> worth doing such a thing, but different people reason differently\n>> about these trade-offs.\n>> \n>> It turns out, however, that there is no need to make a trade-off. \n>The\n>> special case of a top level \"threshold-signature OR\n>> arbitrary-conditions\" can be made indistinguishable from a normal\n>> one-party signature, with no overhead at all, with a special\n>> delegating CHECKSIG which I call Taproot.\n>> \n>> Let's say we want to create a coin that can be redeemed by either\n>> Alice && Bob   or by CSV-timelock && Bob.\n>> \n>> Alice has public A, Bob has pubkey B.\n>> \n>> We compute the 2-of-2 aggregate key C = A + B.  (Simplified; to\n>> protect against rogue key attacks you may want to use the MuSig key\n>> aggregation function [1])\n>> \n>> We form our timelock script S =  \"<timeout> OP_CSV OP_DROP B\n>OP_CHECKSIGVERIFY\"\n>> \n>> Now we tweak C to produce P which is the key we'll publish: P = C +\n>H(C||S)G.\n>> \n>> (This is the attack hardened pay-to-contract construction described\n>in [2])\n>> \n>> Then we pay to a scriptPubKey of [Taproot supporting version] [EC\n>point P].\n>> \n>> Now Alice and Bob-- assuming they are both online and agree about the\n>> resolution of their contract-- can jointly form a 2 of 2 signature\n>for\n>> P, and spend as if it were a payment to a single party (one of them\n>> just needs to add H(C||S) to their private key).\n>> \n>> Alternatively, the Taproot consensus rules would allow this script to\n>> be satisfied by someone who provides the network with C (the original\n>> combined pubkey), S, and does whatever S requires-- e.g. passes the\n>> CSV check and provides Bob's signature. With this information the\n>> network can verify that C + H(C||S) == P.\n>> \n>> So in the all-sign case there is zero overhead; and no one can tell\n>> that the contract alternative exists. In the alternative redemption\n>> branch the only overhead is revealing the original combined pubkey\n>> and, of course, the existence of the contract is made public.\n>> \n>> This composes just fine with whatever other merkelized script system\n>> we might care to use, as the S can be whatever kind of data we want,\n>> including the root of some tree.\n>> \n>> My example shows 2-of-2 but it works the same for any number of\n>> participants (and with setup interaction any threshold of\n>> participants, so long as you don't mind an inability to tell which\n>> members signed off).\n>> \n>> The verification computational complexity of signature path is\n>> obviously the same as any other plain signature (since its\n>> indistinguishable). Verification of the branch redemption requires a\n>> hash and a multiplication with a constant point which is strictly\n>more\n>> efficient than a signature verification and could be efficiently\n>fused\n>> into batch signature validation.\n>> \n>> The nearest competitor to this idea that I can come up with would\n>> supporting a simple delegation where the output can be spent by the\n>> named key, or a spending transaction could provide a script along\n>with\n>> a signature of that script by the named key, delegating control to\n>the\n>> signed script. Before paying into that escrow Alice/Bob would\n>> construct this signature. This idea is equally efficient in the\n>common\n>> case, but larger and slower to verify in the alternative spend case.\n>> Setting up the signature requires additional interaction between\n>> participants and the resulting signature must be durably stored and\n>> couldn't just be recomputed using single-party information.\n>> \n>> I believe this construction will allow the largest possible anonymity\n>> set for fixed party smart contracts by making them look like the\n>> simplest possible payments. It accomplishes this without any overhead\n>> in the common case, invoking any sketchy or impractical techniques,\n>> requiring extra rounds of interaction between contract participants,\n>> and without requiring the durable storage of other data.\n>> \n>> \n>> [1] https://eprint.iacr.org/2018/068\n><https://eprint.iacr.org/2018/068>\n>> [2] https://blockstream.com/sidechains.pdf\n><https://blockstream.com/sidechains.pdf> Appendix A\n>> \n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n><https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180123/d1e58bc1/attachment-0001.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-23T21:38:13",
                "message_text_only": "On Tue, Jan 23, 2018 at 9:23 PM, Matt Corallo via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> The issue with that approach without support for the privacy-encouraging\n> wrapper proposed by Greg here is that it encourages adoption halfway and\n> destroys a lot of the value of the apparent-script monoculture for privacy\n> preservation. Greg's proposal here doesn't change the format of any specific\n> MAST implementation, but instead adds the privacy wrapper that I always felt\n> was missing in existing proposals, without any real additional overhead in\n> many use-cases!\n>\n> Indeed, permissionless innovation is important, but the huge advantage of\n> providing the privacy wrapper by default here is absolutely massive to the\n> ecosystem and should not be handwaved away for vague possibly-advantages.\n\nEven if to someone who didn't care about anyone's privacy at all,\nnon-taproot is simply inefficient.  In the (I argue) overwhelmingly\ncommon case of everyone-agrees simple hash based branching requires a\n30% overhead to communicate the commitment to the untaken branch (and\nworse in the case of extensive aggregation).  I don't think an\nargument can be sustained in favor of that kind of communications\noverhead."
            },
            {
                "author": "Anthony Towns",
                "date": "2018-01-23T06:44:19",
                "message_text_only": "On Tue, Jan 23, 2018 at 12:30:06AM +0000, Gregory Maxwell via bitcoin-dev wrote:\n> One point that comes up while talking about merkelized scripts is can\n> we go about making fancier contract use cases as indistinguishable as\n> possible from the most common and boring payments.\n\n> Now we tweak C to produce P which is the key we'll publish: P = C + H(C||S)G.\n> (This is the attack hardened pay-to-contract construction described in [2])\n> Then we pay to a scriptPubKey of [Taproot supporting version] [EC point P].\n\nIs this really intended as paying directly to a pubkey, instead of a\npubkey hash?\n\nIf so, isn't that a step backwards with regard to resistance to quantum\nattacks against ECC?\n\nPaying direct to pubkey doesn't seem quite enough to make pay-to-taproot\ncheaper than p2wpkh: the extra 12 bytes in the scriptPubKey would need\nyou to reduce the witness by 48 bytes to maintain the weight, but I think\nyou'd only be saving 33 bytes by not having to reveal the pubkey, and\nanother 6-7 bytes by having a tighter signature encoding than DER. Still,\nthat's pretty close with a difference of only a couple of vbytes per\ninput by my count.\n\nIf it were \"pay-to-taproot-hash\", then presuming taproot hashes were 256\nbit, then p2wpkh would be a full 12 vbytes cheaper due to the shorter\nhash. That might make it hard to maximise the anonymity set. I suppose\na small penalty/discount could be added to align the economic incentives\nthough.\n\nI wonder how this interacts with segwit versioning. I think you'd want\nto have taproot be versioned overall so that you could cope with moving\nto a new signing method (different curve, or something non-ECC based)\neventually, and segwit versioning will handle that already; but maybe\nit would also be a good idea to also have \"S\" include a version, that\ncould be bumped to add new features to script, but left hidden within\nthe hash so that the fact you're using new (or old) features is only\nrevealed when it has to be.\n\nThose nits aside, this seems great.\n\nCheers,\naj"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-23T13:15:38",
                "message_text_only": "On Tue, Jan 23, 2018 at 6:44 AM, Anthony Towns <aj at erisian.com.au> wrote:\n> Is this really intended as paying directly to a pubkey, instead of a\n> pubkey hash?\n>\n> If so, isn't that a step backwards with regard to resistance to quantum\n> attacks against ECC?\n\nYou're reading too much into a description of the idea. It's not a BIP\nor a spec; I tried to provide enough details to make the general idea\nconcrete. I didn't dive into details or optimizations (for example,\nyou can use this with a \"no EC redemption path\" by special casing\nempty C as the point at infinity, and you'd have an output that was\nindistinguishable until spend... yadda yadda).\n\nConsidering the considerable level of address reuse -- I recall prior\nstats that a majority of circulating funds are on addresses that had\npreviously been used, on top of the general race limitations-- I am\nnow dubious to the idea that hashing provides any kind of meaningful\nquantum resistance and somewhat regret introducing that meme to the\nspace in the first place. If we considered quantum resistance a\nmeaningful concern we should address that specifically.  --- so I\ndon't think that should be a factor that drives a decision here.\n\nWhen collision resistance is needed (as I think it clearly is for\ntaproot) you don't get a space savings in the txout from hashing, so\nthere is an argument to use the public key directly at least... but\nit's worth considering.  Direct SPK use is also adventitious for being\nable to efficiently ZKP over the UTXO set, e.g. for private solvency\nproofs, but it isn't absolutely mandatory for that (one can hash\ninside the proof, but it's slower)."
            },
            {
                "author": "Anthony Towns",
                "date": "2018-01-23T22:22:29",
                "message_text_only": "On Tue, Jan 23, 2018 at 01:15:38PM +0000, Gregory Maxwell wrote:\n> On Tue, Jan 23, 2018 at 6:44 AM, Anthony Towns <aj at erisian.com.au> wrote:\n> > Is this really intended as paying directly to a pubkey, instead of a\n> > pubkey hash?\n> > If so, isn't that a step backwards with regard to resistance to quantum\n> > attacks against ECC?\n> Considering the considerable level of address reuse -- I recall prior\n> stats that a majority of circulating funds are on addresses that had\n> previously been used, on top of the general race limitations-- I am\n> now dubious to the idea that hashing provides any kind of meaningful\n> quantum resistance and somewhat regret introducing that meme to the\n> space in the first place. If we considered quantum resistance a\n> meaningful concern we should address that specifically.  --- so I\n> don't think that should be a factor that drives a decision here.\n\nHmm, at least people can choose not to reuse addresses currently --\nif everyone were using taproot and that didn't involve hashing the key,\nthere would be no way for individuals to hedge against quantum attacks\nin case they're ever feasible, at least that I can see (well, without\nmoving their funds out of bitcoin anyway)?\n\nEven \"X + H(X|script)g\" with X being a random point would end up\nattackable, since that would almost always end up corresponding with a\nvalid public key that a successful attack could then find a private key\nfor.\n\n(It seems like using the point at infinity wouldn't work because \nP = 0+H(0||S)g = H(0||S)g, so as soon as you tried to spend it via S,\nsomeone watching the mempool would know H(0||S), which is the secret key\nfor P, and be able to spend it via the pubkey path -- no quantum crypto\nneeded. Or am I missing something?)\n\nAlso, if the people currently reusing addresses tend to cycle the funds\nthrough fairly quickly anyway, they might be able to simply stop doing\nthat when quantum attacks start approaching feasibility. If funds are\nbeing held in reused addresses over the long term, that would be more\nof a problem though...\n\n> When collision resistance is needed (as I think it clearly is for\n> taproot) you don't get a space savings in the txout from hashing, so\n> there is an argument to use the public key directly at least... but\n> it's worth considering.  Direct SPK use is also adventitious for being\n> able to efficiently ZKP over the UTXO set, e.g. for private solvency\n> proofs, but it isn't absolutely mandatory for that (one can hash\n> inside the proof, but it's slower).\n\nYeah, that was one of the assumptions for\nhttp://www.jbonneau.com/doc/DBBCB15-CCS-provisions.pdf iirc. \n\n(Also, pretty sure you mean \"advantageous\", but at least I learnt a new\nword today)\n\nCheers,\naj"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-23T22:45:06",
                "message_text_only": "On Tue, Jan 23, 2018 at 10:22 PM, Anthony Towns <aj at erisian.com.au> wrote:\n> Hmm, at least people can choose not to reuse addresses currently --\n> if everyone were using taproot and that didn't involve hashing the key,\n\nCan you show me a model of quantum computation that is conjectured to\nbe able to solve the discrete log problem but which would take longer\nthan fractions of a second to do so? Quantum computation has to occur\nwithin the coherence lifetime of the system.\n\n> way for individuals to hedge against quantum attacks in case they're ever feasible, at least that I can see (well, without moving their funds out of bitcoin anyway)?\n\nBy using scriptpubkeys with actual security against quantum computers\ninstead of snake-oil.\n\n> (It seems like using the point at infinity wouldn't work because\n\nIndeed, that doesn't work.\n\n> that when quantum attacks start approaching feasibility. If funds are\n> being held in reused addresses over the long term, that would be more\n\nThey are. But I don't believe that is relevant; the attacker would\nsimply steal the coins on spend."
            },
            {
                "author": "Andrew Poelstra",
                "date": "2018-01-24T01:52:57",
                "message_text_only": "On Tue, Jan 23, 2018 at 10:45:06PM +0000, Gregory Maxwell via bitcoin-dev wrote:\n> On Tue, Jan 23, 2018 at 10:22 PM, Anthony Towns <aj at erisian.com.au> wrote:\n> > Hmm, at least people can choose not to reuse addresses currently --\n> > if everyone were using taproot and that didn't involve hashing the key,\n> \n> Can you show me a model of quantum computation that is conjectured to\n> be able to solve the discrete log problem but which would take longer\n> than fractions of a second to do so? Quantum computation has to occur\n> within the coherence lifetime of the system.\n> \n> > way for individuals to hedge against quantum attacks in case they're ever feasible, at least that I can see (well, without moving their funds out of bitcoin anyway)?\n> \n> By using scriptpubkeys with actual security against quantum computers\n> instead of snake-oil.\n> \n> > (It seems like using the point at infinity wouldn't work because\n> \n> Indeed, that doesn't work.\n> \n> > that when quantum attacks start approaching feasibility. If funds are\n> > being held in reused addresses over the long term, that would be more\n> \n> They are. But I don't believe that is relevant; the attacker would\n> simply steal the coins on spend.\n\n\nThen the system would need to be hardforked to allow spending through a\nquantum-resistant ZKP of knowledge of the hashed public key. I expect\nthat in a post-quantum world there will be demand for such a fork,\nespecially if we came into such a world through surprise evidence of\na discrete log break.\n\n-- \nAndrew Poelstra\nMathematics Department, Blockstream\nEmail: apoelstra at wpsoftware.net\nWeb:   https://www.wpsoftware.net/andrew\n\n\"A goose alone, I suppose, can know the loneliness of geese\n who can never find their peace,\n whether north or south or west or east\"\n       --Joanna Newsom\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180124/73e08261/attachment.sig>"
            },
            {
                "author": "Tim Ruffing",
                "date": "2018-01-24T09:28:20",
                "message_text_only": "On Wed, 2018-01-24 at 01:52 +0000, Andrew Poelstra via bitcoin-dev\nwrote:\n> \n> > They are. But I don't believe that is relevant; the attacker would\n> > simply steal the coins on spend.\n> \n> \n> Then the system would need to be hardforked to allow spending through\n> a\n> quantum-resistant ZKP of knowledge of the hashed public key. I expect\n> that in a post-quantum world there will be demand for such a fork,\n> especially if we came into such a world through surprise evidence of\n> a discrete log break.\n> \n\nThere are simpler ways using consensus / waiting instead of zero-\nknowledge, e.g., \n\n1. Include H(classic_pk, tx) to blockchain, wait until confirmed.\n2. Reveal classic_pk, tx\n\nThis is taken from my tweet [1] but now I realize that these are\nbasically Guy Fawkes \"signatures\" [2]. Joseph Bonneau and Andrew Miller\n [3] had the idea to use this for cryptocurrency without asymmetric\ncryptography.\n\nBest,\nTim\n\n[1] https://twitter.com/real_or_random/status/948226830166786048\n[2] https://www.cl.cam.ac.uk/~rja14/Papers/fawkes.pdf\n[3] http://www.jbonneau.com/doc/BM14-SPW-fawkescoin.pdf"
            },
            {
                "author": "Natanael",
                "date": "2018-01-24T12:51:45",
                "message_text_only": "Den 23 jan. 2018 23:45 skrev \"Gregory Maxwell via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org>:\n\nOn Tue, Jan 23, 2018 at 10:22 PM, Anthony Towns <aj at erisian.com.au> wrote:\n> Hmm, at least people can choose not to reuse addresses currently --\n> if everyone were using taproot and that didn't involve hashing the key,\n\nCan you show me a model of quantum computation that is conjectured to\nbe able to solve the discrete log problem but which would take longer\nthan fractions of a second to do so? Quantum computation has to occur\nwithin the coherence lifetime of the system.\n\n\nQuantum computers works like randomized black boxes, you run them in many\ncycles with a certain probability of getting the right answer.\n\nThe trick to them is that they bias the probabilities of their qubits to\nread out the correct answer *more often than at random*, for many classes\nof problems. You (likely) won't get the correct answer immediately.\n\nhttps://en.wikipedia.org/wiki/Quantum_computing\n\nQuoting Wikipedia:\n\n> An algorithm is composed of a fixed sequence of quantum logic gates and a\nproblem is encoded by setting the initial values of the qubits, similar to\nhow a classical computer works. The calculation usually ends with a\nmeasurement, collapsing the system of qubits into one of the 2 n\n{\\displaystyle 2^{n}} 2^{n} pure states, where each qubit is zero or one,\ndecomposing into a classical state. The outcome can therefore be at most n\n{\\displaystyle n} n classical bits of information (or, if the algorithm did\nnot end with a measurement, the result is an unobserved quantum state).\nQuantum algorithms are often probabilistic, in that they provide the\ncorrect solution only with a certain known probability.\n\nA non programmed QC is essentially an RNG driven by quantum effects. You\njust get random bits.\n\nA programmed one will need to run the and program over and over until you\ncan derive the correct answer from one of its outputs. How fast this goes\ndepends on the problem and the algorithm.\n\nMost people here have heard of Grover's algorithm, it would crack a\nsymmetric 256 bit key in approximately 2^128 QC cycles - completely\nimpractical. Shor's algorithm is the dangerous one for ECC since it cracks\ncurrent keys at \"practical\" speeds.\n\nhttps://eprint.iacr.org/2017/598 - resource estimates, in terms of size of\nthe QC. Does not address implementation speed.\n\nI can't seem to find specific details, but I remember having seen estimates\nof around 2^40 cycles in practical implementations for 256 bit ECC (this\nassumes use error correction schemes, QC machines with small some\nimperfections, and more). Unfortunately I can't find a source for this\nestimate. I've seen lower estimates too, but they seem entirely\ntheoretical.\n\nRead-out time for QC:s is indeed insignificant, in terms of measuring the\nstate of the qubits after a complete cycle.\n\nProgramming time, time to prepared for readout, reset, reprogramming, etc,\nthat will all take a little longer. In particular with more qubits\ninvolved, since they all need to be in superposition and be coherent at\nsome point. Also, you still have to parse all the different outputs (on a\nclassical computer) to find your answer among them.\nVery very optimistic cycle speeds are in the GHz range, and then that's\nstill on the order of ~15 minutes for 2^40 cycles. Since we don't even have\na proper general purpose QC yet, nor one with usable amounts of qubits, we\ndon't even know if we can make them run at a cycle per second, or per\nminute...\n\nHowever if somebody *does* build a fast QC that's nearly ideal, then\nBitcoin's typical use of ECC would be in immediate danger. The most\noptimistic QC plausible would indeed be able to crack keys in under a\nminute. But my own wild guess is that for the next few decades none will be\nfaster than a runtime measured in weeks for cracking keys.\n\n---\n\nSidenote, I'm strongly in favor of implementing early support for the\nFawkes scheme mentioned previously.\n\nWe could even patch it on top of classical transactions - you can only\nbreak ECC with a known public key, so just commit to the signed transaction\ninto the blockchain before publishing it. Then afterwards you publish the\ntransaction itself, with a reference to the commitment. That transaction\ncan then be assumed legit simply because there was no room to crack the key\nbefore the commitment, and the transaction matches the commitment.\n\nNever reuse keys, and you're safe against QC:s.\n\nSidenote: There's a risk here with interception, insertion of a new\ncommitment and getting the new transaction into the blockchain first.\nHowever, I would suggest a mining policy here were two known conflicting\ntransactions with commitments are resolved such that the one with the\noldest commitment wins. How to address detection of conflicting\ntransactions with commitments older than confirmed transactions isn't\nobvious. Some of these may be fully intentional by the original owner, such\nas a regretted transaction.\n\nAnother sidenote: HD wallets with hash based hardened derivation should\nalso be safe in various circumstances, near completely safe in the case\nwhere they're defined such that knowing an individual private key, which is\nnot the root key,  is not enough to derive any other in your wallet.\nHD schemes that only prevent derivation of parent keypairs in the tree\nwould require that you never use a key derived from another already used or\npublished public key.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180124/10b6b113/attachment-0001.html>"
            },
            {
                "author": "Tim Ruffing",
                "date": "2018-01-24T15:38:11",
                "message_text_only": "On Wed, 2018-01-24 at 13:51 +0100, Natanael via bitcoin-dev wrote:\n> Sidenote: There's a risk here with interception, insertion of a new\n> commitment and getting the new transaction into the blockchain first.\n> However, I would suggest a mining policy here were two known\n> conflicting transactions with commitments are resolved such that the\n> one with the oldest commitment wins. How to address detection of\n> conflicting transactions with commitments older than confirmed\n> transactions isn't obvious. Some of these may be fully intentional by\n> the original owner, such as a regretted transaction.\n\nOkay, I think my proposal was wrong...\n\nThis looks better (feel free to break again):\n1. Commit (H(classic_pk, tx), tx) to the blockchain, wait until confirmed\n2. Reveal classic_pk in the blockchain\n\nThen the tx in the first valid commitment wins. If the attacker\nintercepts classic_pk, it won't help him. He cannot create the first\nvalid commitment, because it is created already. (The reason is that\nthe decommitment is canonical now; for all commitments, the\ndecommitment is just classic_pk.)\n\nBy the way, maybe I'm stating the obvious but Taproot (or similar) is\nindeed very nice for outputs generated in the future: You can have a\npath for a classical signature scheme and a path for a quantum-secure\nscheme.\n\nBest,\nTim"
            },
            {
                "author": "Natanael",
                "date": "2018-01-24T18:51:27",
                "message_text_only": "Den 24 jan. 2018 16:38 skrev \"Tim Ruffing via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org>:\n\nOkay, I think my proposal was wrong...\n\nThis looks better (feel free to break again):\n1. Commit (H(classic_pk, tx), tx) to the blockchain, wait until confirmed\n2. Reveal classic_pk in the blockchain\n\nThen the tx in the first valid commitment wins. If the attacker\nintercepts classic_pk, it won't help him. He cannot create the first\nvalid commitment, because it is created already. (The reason is that\nthe decommitment is canonical now; for all commitments, the\ndecommitment is just classic_pk.)\n\n\nThat's not the type of attack I'm imagining. Both versions of your scheme\nare essentially equivalent in terms of this attack.\n\nIntended steps:\n1: You publish a hash commitment.\n2: The hash ends up in the blockchain.\n3: You publish the transaction itself, and it matches the hash commitment.\n4: Because it matches, miners includes it. It's now in the blockchain.\n\nAttack:\n1: You publish a hash commitment.\n2: The hash ends up the blockchain.\n3: You publish the transaction itself, it matches the hash commitment.\n4: The attacker mess with the network somehow to prevent your transaction\nfrom reaching the miners.\n5: The attacker cracks your keypair, and makes his own commitment hash for\nhis own theft transaction.\n6: Once that commitment is in the blockchain, he publishes his own theft\ntransaction.\n7: The attacker's theft transaction gets into the blockchain.\n8 (optionally): The miners finally see your original transaction with the\nolder commitment, but now the theft transaction can't be undone. There's\nnothing to do about it, nor a way to know if it's intentional or not.\nAnybody not verifying commitments only sees a doublespend attempt.\n\n---\n\nMore speculation, not really a serious proposal:\n\nI can imagine one way to reduce the probability of success for the attack\nby publishing encrypted transactions as the commitment, to then publish the\nkey - the effect of this is that the key is easier to propagate quickly\nacross the network than a full transaction, making it harder to succeed\nwith a network based attack. This naive version by itself is however a\nmajor DoS vector against the network.\n\nYou could, in some kind of fork, redefine how blocks are processed such\nthat you can prune all encrypted transactions that have not had the key\npublished within X blocks. The validation rules would work such that to\npublish the key for an encrypted transaction in a new block, that\ntransaction must both be recent enough, be valid by itself, and also not\nconflict with any other existing plaintext / decrypted transactions in the\nblockchain.\n\nBlocks wouldn't necessarily even need to include the encrypted transactions\nduring propagation. This works because encrypted transactions have zero\neffect until the key is published. In this case you'd effectively be\nrequired to publish your encrypted transaction twice to ensure the raw data\nisn't lost, once to get into a block and again together with the key to get\nit settled.\n\nSince miners will likely keep at least the most recent encrypted\ntransactions cached to speed up validation, this is faster to settle than\nto publish the committed transaction as mentioned in the beginning. This\nincreases your chances to get your key into the blockchain to settle your\ntransaction before the attacker completes his attack, versus pushing a full\ntransaction that miners haven't seen before.\n\nThis version would still allow DoS against miners caching all encrypted\ntransactions. However, if efficient Zero-knowledge proofs became practical\nthen you can use one to prove your encrypted transaction valid, even\nagainst the UTXO set and in terms of not colliding with existing\ncommitments - in this case the DoS attack properties are nearly identical\nto standard transactions.\nIf you want to change a committed transaction, you'd need to let the\ncommitment expire.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180124/c42ae892/attachment.html>"
            },
            {
                "author": "Tim Ruffing",
                "date": "2018-01-24T23:22:05",
                "message_text_only": "On Wed, 2018-01-24 at 19:51 +0100, Natanael wrote:\n> \n> That's not the type of attack I'm imagining. Both versions of your\n> scheme are essentially equivalent in terms of this attack. \n> \n> Intended steps: \n> 1: You publish a hash commitment. \n> 2: The hash ends up in the blockchain. \n> 3: You publish the transaction itself, and it matches the hash\n> commitment. \n> 4: Because it matches, miners includes it. It's now in the\n> blockchain. \n\nI think you misread my second proposal. The first step is not only to\npublish the hash but to publish a *pair* consisting of the hash and the\ntransaction.\n\nIf the attacker changes the transaction on the wire, the user does not\ncare and will try again.\n\nBy the way: As described here, everybody could do this first step and\nflood the blockchain with it. We cannot immediately subtract a fee,\nbecause it's not clear that some transaction will take place at all. So\nwe need to take the fee from somewhere else or do something else to\nprevent spam. But that's entirely different issue..."
            },
            {
                "author": "Natanael",
                "date": "2018-01-25T00:09:31",
                "message_text_only": "Den 25 jan. 2018 00:22 skrev \"Tim Ruffing via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org>:\n\n\nI think you misread my second proposal. The first step is not only to\npublish the hash but to publish a *pair* consisting of the hash and the\ntransaction.\n\nIf the attacker changes the transaction on the wire, the user does not\ncare and will try again.\n\n\nI guess I assumed you meant it otherwise because I didn't assume you\nintended a commitment to the full transaction just without the asymmetric\nkey material.\n\nYou could treat it the same way as in my suggestion, let it expire and\nprune it if the key material isn't published in time.\n\nHowever... A sufficiently powerful attacker can deploy as soon as he sees\nyour published signature and key, delay its propagation to the miners,\nforce expiration and then *still* repeat the attack with his own forgery.\n\nHonestly, as long as we need to allow any form of expiry + relying on\npublication of the vulnerable algorithms result for verification, I think\nthe weakness will remain.\n\nNo expiration hurts in multiple ways like via DoS, or by locking in\npotentially wrong (or straight up malicious) transactions.\n\n---\n\nThere's one way out, I believe, which is quantum safe Zero-knowledge\nproofs. Currently STARK:s are one variant presumed quantum safe. It would\nbe used to completely substitute the publication of the public key and\nsignatures, and this way we don't even need two-step commitments.\n\nIt does however likely require a hardfork to apply to old transactions. (I\ncan imagine an extension block type softfork method, in which case old\nUTXO:s get locked on the mainchain to create equivalent valued extension\nblock funds.)\n\nWithout practical ZKP,  and presuming no powerful QC attackers with the\nability to control the network (basically NSA level attackers), I do think\nthe Fawkes signature scheme is sufficient. Quantum attacks are likely to be\nvery expensive anyway, for the foreseeable future.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180125/45fe3cec/attachment.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2018-01-27T17:07:25",
                "message_text_only": "On Tue, Jan 23, 2018 at 1:44 AM, Anthony Towns via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Tue, Jan 23, 2018 at 12:30:06AM +0000, Gregory Maxwell via bitcoin-dev\n> wrote:\n> > One point that comes up while talking about merkelized scripts is can\n> > we go about making fancier contract use cases as indistinguishable as\n> > possible from the most common and boring payments.\n>\n> > Now we tweak C to produce P which is the key we'll publish: P = C +\n> H(C||S)G.\n> > (This is the attack hardened pay-to-contract construction described in\n> [2])\n> > Then we pay to a scriptPubKey of [Taproot supporting version] [EC point\n> P].\n>\n> Is this really intended as paying directly to a pubkey, instead of a\n> pubkey hash?\n>\n> If so, isn't that a step backwards with regard to resistance to quantum\n> attacks against ECC?\n>\n> Paying direct to pubkey doesn't seem quite enough to make pay-to-taproot\n> cheaper than p2wpkh: the extra 12 bytes in the scriptPubKey would need\n> you to reduce the witness by 48 bytes to maintain the weight, but I think\n> you'd only be saving 33 bytes by not having to reveal the pubkey, and\n> another 6-7 bytes by having a tighter signature encoding than DER. Still,\n> that's pretty close with a difference of only a couple of vbytes per\n> input by my count.\n>\n\nI've been thinking about your comment, and I think your concern can be\naddressed.  Taproot would almost certainly be deployed in conjunction with\ncross-input signature aggregation.  Because aggregation doesn't work with\nECDSA, only those signatures using Taproot and other Schnorr signatures\nwould be available for aggregation.  Just having the ability to support\ncross-input signature aggregation may be motivation enough for ordinary\npub-key users to switch to Taproot.  However, there is more.\n\nCross-input signature aggregation probably requires a new field to be added\nto the P2P transaction structure to hold the aggregated signature, since\nthere isn't really a good place to put it in the existing structure (there\nare games you can play to make it fit, but I think it is worthwhile).  The\nobvious way add block commitments to a new tx field is via the witness\nreserved value mechanism present in BIP 141.  At this point I think there\nwill be some leeway to adjust the discount on the weight of this new\naggregated signature tx field so that even a single input taproot using the\naggregated signature system (here an aggregation of 1 signature) ends up no\nmore expensive than a single input segwit P2WPKH.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180127/d64b250e/attachment.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2018-01-27T17:23:12",
                "message_text_only": "Gah, please no. I see no material reason why cross-input signature aggregation shouldn't have the signatures in the first n-1 inputs replaced with something like a single-byte push where a signature is required to indicate aggregation, and the combined signature in the last input at whatever position the signature is required.\n\nOn January 27, 2018 5:07:25 PM UTC, Russell O'Connor via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n-snip-\n>Cross-input signature aggregation probably requires a new field to be\n>added\n>to the P2P transaction structure to hold the aggregated signature,\n>since\n>there isn't really a good place to put it in the existing structure\n>(there\n>are games you can play to make it fit, but I think it is worthwhile). \n>The\n>obvious way add block commitments to a new tx field is via the witness\n>reserved value mechanism present in BIP 141.  At this point I think\n>there\n>will be some leeway to adjust the discount on the weight of this new\n>aggregated signature tx field so that even a single input taproot using\n>the\n>aggregated signature system (here an aggregation of 1 signature) ends\n>up no\n>more expensive than a single input segwit P2WPKH."
            },
            {
                "author": "Greg Sanders",
                "date": "2018-01-23T15:43:59",
                "message_text_only": "Interesting parallels to current Elements sidechain peg-in functionality.\nUser tweaks the watchmen(BTC holder) pubkey using P2CH, committing to a\nscript that is used on the *sidechain side* as spending authorization for\nthat bitcoin output rather than mainnet.\n\nI think composing the two can be done as:\n\nP = C' + H(C'||S')G + H(C||S)G\n\nwhere C is redefined as `C' + H(C'||S')G`, which for Bitcoin consensus\npurposes is just a single pubkey.\n\n\n\nOn Mon, Jan 22, 2018 at 7:30 PM, Gregory Maxwell via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Interest in merkelized scriptPubKeys (e.g. MAST) is driven by two main\n> areas: efficiency and privacy. Efficiency because unexecuted forks of\n> a script can avoid ever hitting the chain, and privacy because hiding\n> unexecuted code leaves scripts indistinguishable to the extent that\n> their only differences are in the unexecuted parts.\n>\n> As Mark Friedenbach and others have pointed out before it is almost\n> always the case that interesting scripts have a logical top level\n> branch which allows satisfaction of the contract with nothing other\n> than a signature by all parties.  Other branches would only be used\n> where some participant is failing to cooperate. More strongly stated,\n> I believe that _any_ contract with a fixed finite participant set\n> upfront can be and should be represented as an OR between an N-of-N\n> and whatever more complex contract you might want to represent.\n>\n> One point that comes up while talking about merkelized scripts is can\n> we go about making fancier contract use cases as indistinguishable as\n> possible from the most common and boring payments. Otherwise, if the\n> anonymity set of fancy usage is only other fancy usage it may not be\n> very large in practice. One suggestion has been that ordinary\n> checksig-only scripts should include a dummy branch for the rest of\n> the tree (e.g. a random value hash), making it look like there are\n> potentially alternative rules when there aren't really.  The negative\n> side of this is an additional 32-byte overhead for the overwhelmingly\n> common case which doesn't need it.  I think the privacy gains are\n> worth doing such a thing, but different people reason differently\n> about these trade-offs.\n>\n> It turns out, however, that there is no need to make a trade-off.  The\n> special case of a top level \"threshold-signature OR\n> arbitrary-conditions\" can be made indistinguishable from a normal\n> one-party signature, with no overhead at all, with a special\n> delegating CHECKSIG which I call Taproot.\n>\n> Let's say we want to create a coin that can be redeemed by either\n> Alice && Bob   or by CSV-timelock && Bob.\n>\n> Alice has public A, Bob has pubkey B.\n>\n> We compute the 2-of-2 aggregate key C = A + B.  (Simplified; to\n> protect against rogue key attacks you may want to use the MuSig key\n> aggregation function [1])\n>\n> We form our timelock script S =  \"<timeout> OP_CSV OP_DROP B\n> OP_CHECKSIGVERIFY\"\n>\n> Now we tweak C to produce P which is the key we'll publish: P = C +\n> H(C||S)G.\n>\n> (This is the attack hardened pay-to-contract construction described in [2])\n>\n> Then we pay to a scriptPubKey of [Taproot supporting version] [EC point P].\n>\n> Now Alice and Bob-- assuming they are both online and agree about the\n> resolution of their contract-- can jointly form a 2 of 2 signature for\n> P, and spend as if it were a payment to a single party (one of them\n> just needs to add H(C||S) to their private key).\n>\n> Alternatively, the Taproot consensus rules would allow this script to\n> be satisfied by someone who provides the network with C (the original\n> combined pubkey), S, and does whatever S requires-- e.g. passes the\n> CSV check and provides Bob's signature. With this information the\n> network can verify that C + H(C||S) == P.\n>\n> So in the all-sign case there is zero overhead; and no one can tell\n> that the contract alternative exists. In the alternative redemption\n> branch the only overhead is revealing the original combined pubkey\n> and, of course, the existence of the contract is made public.\n>\n> This composes just fine with whatever other merkelized script system\n> we might care to use, as the S can be whatever kind of data we want,\n> including the root of some tree.\n>\n> My example shows 2-of-2 but it works the same for any number of\n> participants (and with setup interaction any threshold of\n> participants, so long as you don't mind an inability to tell which\n> members signed off).\n>\n> The verification computational complexity of signature path is\n> obviously the same as any other plain signature (since its\n> indistinguishable). Verification of the branch redemption requires a\n> hash and a multiplication with a constant point which is strictly more\n> efficient than a signature verification and could be efficiently fused\n> into batch signature validation.\n>\n> The nearest competitor to this idea that I can come up with would\n> supporting a simple delegation where the output can be spent by the\n> named key, or a spending transaction could provide a script along with\n> a signature of that script by the named key, delegating control to the\n> signed script. Before paying into that escrow Alice/Bob would\n> construct this signature. This idea is equally efficient in the common\n> case, but larger and slower to verify in the alternative spend case.\n> Setting up the signature requires additional interaction between\n> participants and the resulting signature must be durably stored and\n> couldn't just be recomputed using single-party information.\n>\n> I believe this construction will allow the largest possible anonymity\n> set for fixed party smart contracts by making them look like the\n> simplest possible payments. It accomplishes this without any overhead\n> in the common case, invoking any sketchy or impractical techniques,\n> requiring extra rounds of interaction between contract participants,\n> and without requiring the durable storage of other data.\n>\n>\n> [1] https://eprint.iacr.org/2018/068\n> [2] https://blockstream.com/sidechains.pdf Appendix A\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180123/ded288f9/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-26T21:34:39",
                "message_text_only": "On Tue, Jan 23, 2018 at 12:30 AM, Gregory Maxwell <greg at xiph.org> wrote:\n> It turns out, however, that there is no need to make a trade-off.  The\n> special case of a top level \"threshold-signature OR\n> arbitrary-conditions\" can be made indistinguishable from a normal\n> one-party signature, with no overhead at all, with a special\n> delegating CHECKSIG which I call Taproot.\n\nKeeping in mind that a single public point can stand in for any\nmonotone function of public keys, a taproot branch is only needed for\naccountability (being able to tell from public data which branches\nwere used) or when conditions other than public keys are required e.g.\nCSV + a monotone function of keys.\n\nI believe that with scriptless-scripts most of hash preimages can be\naccomplished without an actual hash pre-image condition.\n\nAre there other simple and very useful/general preconditions that\nwould be useful ANDed with a monotone function of public keys like is\nthe case for CSV?\n\nI ask because recursive taproot by itself isn't very interesting,\nsince (other than accountability) there is no gain to not just merging\nthe alternative, but if there are additional conditions then it can be\nuseful. E.g.\n\n[pubkey]\n      \\-[pubkey]&&CSV\n             \\-[fancy script]\n\nSo it might make sense to support a taproot construction that can\nnest, where interior nested keys have a CSV/CLTV predicate. But are\nthere other simple predicates that cover a lot of cases?\n\n\n[Aside: _please_ change the subject lines for further discussion about\nquantum computers;]"
            }
        ],
        "thread_summary": {
            "title": "Taproot: Privacy preserving switchable scripting",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Chris Belcher",
                "Natanael",
                "Anthony Towns",
                "Andrew Poelstra",
                "Tim Ruffing",
                "Russell O'Connor",
                "Gregory Maxwell",
                "Matt Corallo",
                "Mark Friedenbach",
                "Greg Sanders"
            ],
            "messages_count": 21,
            "total_messages_chars_count": 80077
        }
    },
    {
        "title": "[bitcoin-dev]  Recovery of old UTXOs in a post-quantum world",
        "thread_messages": [
            {
                "author": "Tim Ruffing",
                "date": "2018-01-26T13:14:14",
                "message_text_only": "(changing the subject... ;))\n\nMy proposal does not include any form of expiration, so I don't see how\nit should be vulnerable to the described attack.\n\nTo make this a little bit more detailed:\n\nThe user has one or more single standard UTXOs all with ECDSA public\nkey classic_pk and thus address SHA256(RIPEMD160((classic_pk)). The\ncorresponding secret key is classic_sk. Let MAC be a quantum-secure\nmessage-authentication code, e.g., MAC(k,x)=H(k||x) for a suitable hash\nfunction, e.g, BLAKE2 or SHA3.\n\nThe idea is to (ab)use the public key classic_pk as a key for the MAC. \n\nTo spend an UTXO with a transaction tx, the user does the following:\n   1. Create and publish a \"transaction\" c that references the address\n      SHA256(RIPEMD160((classic_pk)) and contains the following data: \n      MAC(classic_pk,tx))||tx\n   2. Wait until c is confirmed. (If it does not confirm, send it again as\n      usual).\n   3. Create and publish a \"transaction\" d with the following data:\n      classic_pk||Sign(classic_sk, tx)\n\nConsensus rules:\nA transaction d=classic_pk||sig spends all UTXOs with\naddress SHA256(RIPEMD160(classic_pk)), applying the effects of tx, if\nthere exists a transaction c=mac||tx in the blockchain such that \n   1. c is the first transaction (among all referencing the address) in\n      the blockchain where mac is a valid MAC for message tx under correct\n      key classic_pk\n   2. sig is valid ECDSA signature over tx under public key classic_pk\n\nc-transactions never expire. \n\nIf the user has not published classic_pk before, this should be secure\nagainst quantum attackers:\nBefore step 2, the MAC key k=classic_pk is only known to the user. So\nthe only valid c that the attacker can produce has the real transaction\ntx, because a different transaction tx' requires the attacker to forge\nthe MAC. Since the user waits for confirmation, the first c in the\nblockchain fulfilling conditions 1 and 2 has been created by the user.\n\nEven if classic_pk is known, this is no less secure than \"classic\nspending\", because we require an ECDSA signature on tx.\n\nI'm pretty confident that I'm not overlooking an obvious attack. If I'm\nwrong then please describe exactly the steps of the user and the\nattacker. \n\nBest,\nTim \n\n\nOn Thu, 2018-01-25 at 01:09 +0100, Natanael wrote:\n> \n> Den 25 jan. 2018 00:22 skrev \"Tim Ruffing via bitcoin-dev\" <bitcoin-d\n> ev at lists.linuxfoundation.org>:\n> > I think you misread my second proposal. The first step is not only\n> > to\n> > publish the hash but to publish a *pair* consisting of the hash and\n> > the\n> > transaction.\n> > \n> > If the attacker changes the transaction on the wire, the user does\n> > not\n> > care and will try again.\n> \n> I guess I assumed you meant it otherwise because I didn't assume you\n> intended a commitment to the full transaction just without the\n> asymmetric key material. \n> \n> You could treat it the same way as in my suggestion, let it expire\n> and prune it if the key material isn't published in time. \n> \n> However... A sufficiently powerful attacker can deploy as soon as he\n> sees your published signature and key, delay its propagation to the\n> miners, force expiration and then *still* repeat the attack with his\n> own forgery. \n> \n> Honestly, as long as we need to allow any form of expiry + relying on\n> publication of the vulnerable algorithms result for verification, I\n> think the weakness will remain. \n> \n> No expiration hurts in multiple ways like via DoS, or by locking in\n> potentially wrong (or straight up malicious) transactions.\n> \n> ---\n> \n> There's one way out, I believe, which is quantum safe Zero-knowledge\n> proofs. Currently STARK:s are one variant presumed quantum safe. It\n> would be used to completely substitute the publication of the public\n> key and signatures, and this way we don't even need two-step\n> commitments. \n> \n> It does however likely require a hardfork to apply to old\n> transactions. (I can imagine an extension block type softfork method,\n> in which case old UTXO:s get locked on the mainchain to create\n> equivalent valued extension block funds.)\n> \n> Without practical ZKP,  and presuming no powerful QC attackers with\n> the ability to control the network (basically NSA level attackers), I\n> do think the Fawkes signature scheme is sufficient. Quantum attacks\n> are likely to be very expensive anyway, for the foreseeable future."
            }
        ],
        "thread_summary": {
            "title": "Recovery of old UTXOs in a post-quantum world",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Tim Ruffing"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4353
        }
    },
    {
        "title": "[bitcoin-dev] BIP16 enforcement change in V0.16",
        "thread_messages": [
            {
                "author": "John Newbery",
                "date": "2018-01-23T21:56:50",
                "message_text_only": "The upcoming v0.16 release contains a slight change to the way that BIP16\nis enforced, by basing activation on block height instead of block time.\nThis brings BIP 16 enforcement in line with BIP 34, BIP 66 and BIP 65.\n\nThis has no impact on consensus since BIP 16 was activated before the last\ncheckpoint and is buried under >300,000 blocks.\n\nI've written up the changes in the BIP style below, although I don't think\nthis necessarily requires a full BIP. BIP 16 enforcement will likely change\nagain with https://github.com/bitcoin/bitcoin/pull/11739 in the next\nbitcoin core release, so a formal proposal for this as a BIP will quickly\nbe superseded.\n\n<pre>\n  BIP: ??\n  Layer: Consensus\n  Title: Buried Deployments (P2SH)\n  Author: John Newbery <john at chaincode.com>\n  Comments-Summary: No comments yet\n  Comments-URI: https://github.com/bitcoin/bips/wiki/Comments:BIP-????\n  Status: Draft\n  Type: Informational\n  Created: 2018-01-22\n  License: CC-0\n</pre>\n\n\n==Abstract==\n\nEnforce BIP 16 consensus rules based on block height rather than block time.\n\n==Background==\n\nBIP 16 was deployed via a hardcoded flag day consensus rule change. Prior\nto the date of the consensus rule change being fixed, the miners signaled\nreadiness for the change by placing the string \"/P2SH/\" in the scriptSig of\nthe coinbase transaction txIn. The rule change was originally intended to\ncome into effect on 15 Feb 2012, but due to lack of miner signaling, the\nactivation date was pushed back to April 1st 2012. See [\nhttps://github.com/bitcoin/bips/blob/master/bip-0034.mediawiki The BIP 16\nspecification] for full details on the deployment method. The final\nactivation method was via a hardcoded block time of 1333238400 (April 1st\n2012).\n\nNow that the chain has long since passed the block at which the P2SH\nconsensus rule was activated, we can (as a simplification) replace the\ntrigger mechanism by caching the block height at which those consensus\nrules became enforced.\n\n==Motivation==\n\nActivating the BIP 16 consensus change based on block time has several\ndisadvantages:\n\n* The consensus change can be activated and later deactivated in the same\nchain (since block time is not necessarily monotonically increasing).\n* It is less flexible for constructing test chains for testing P2SH and\nother soft fork activation\n\nThe flag day activation mechanism for code deployments was deprecated in\nfavor of [https://github.com/bitcoin/bips/blob/master/bip-0034.mediawiki\nIsSuperMajority] deployments, and later by [\nhttps://github.com/bitcoin/bips/blob/master/bip-0009.mediawiki version\nbits] deployments.\n\nBIP 34, BIP 65, and BIP 66 deployments were later 'buried' by [\nhttps://github.com/bitcoin/bips/blob/master/bip-0090.mediawiki BIP 90] with\nsimple height checks. This simplification of the consensus rules reduced\nthe technical debt associated with deployment of those consensus changes.\n\nThis BIP changes the BIP 16 activation method to also be a 'buried'\ndeployment, activating at the block height that BIP 16 actually activated.\nFor the mainnet chain, this is block height 173805.\n\n==Considerations==\n\nJust as for the buried BIP 34, BIP 65 and BIP 66 deployments, it is\ntechnically possible for this to be a non-backwards compatible change. For\nexample, if an alternate chain were created in which block height 173805\nwas reached after April 1st 2012, and a block with height <173805 but block\ntime after April 1st 2012 included an invalid P2SH spend, older software\nwould see that chain as invalid, but newer software implementing this\nchange would not.\n\nSee [https://github.com/bitcoin/bips/blob/master/bip-0090.mediawiki BIP 90]\nfor justification of why this class of change is acceptable. As of January\n2018, BIP 16 is buried by over 300,000 blocks. BIP 16 activation is also\nprotected by checkpoints (the most recent of which is at height 295000).\n\n==Specification==\n\nThe BIP 16 activation height is set to 173805.\n\nTo determine whether to enforce BIP 16 on a given block, we just compare\nthe height of the block being validated with the stored activation height:\n\n    // Start enforcing P2SH (BIP16)\n    if (pindex->nHeight >= consensusparams.BIP16Height) {\n        flags |= SCRIPT_VERIFY_P2SH;\n    }\n\nSee the implementation for additional details.\n\n==Implementation==\n\nhttps://github.com/bitcoin/bitcoin/commit/18e071841e83044b47aa45c3e98c0796a407d445\n\n==Acknowledgements==\n\nThanks to Russ Yanofsky, Marco Falke and Suhas Daftuar for suggestions and\nfeedback.\n\n==Copyright==\n\nThis document is placed in the public domain.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180123/79e117ee/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP16 enforcement change in V0.16",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "John Newbery"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4704
        }
    },
    {
        "title": "[bitcoin-dev] 2 step confirmation system",
        "thread_messages": [
            {
                "author": "rmcc4444",
                "date": "2018-01-24T00:42:56",
                "message_text_only": "I know from speaking to my friends not involved with Bitcoin that two of\ntheir major concerns are as follows:\n\n1. They are afraid if they fat finger the address there is nothing they can\ndo about it and not get their Bitcoin back.\n\nand/or\n\n2. They would like to at least have the option to use some sort of 2 step\nconfirmation system when dealing ith people they do not know. For example,\nafter sending the Bitcoin to a seller they would like to be able to do a\nfinal approval of the tm transaction. If the 2 people involved in the\ntransaction approve of it within X hours, the coin returns to the original\nperson. This system would basically act as an escrow.\n\nThis 2 step system could work with both of these.\n\nI apologize if this is the incorrect place to post this. I did not know\nwhere else to share these thoughts.\n\nThanks for your time.\n\n\n\n-- \n\n\n** This message was likely sent using voice to text. Please ignore any\ntypos.**\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180124/8e5ad367/attachment.html>"
            },
            {
                "author": "Rhavar",
                "date": "2018-01-24T02:05:00",
                "message_text_only": "1. Bitcoin addresses contain a \"checksum\", which means it's pretty much impossible to fat finger any address. (Note: most altcoins don't seem to do this, so fat-fingering is very much a risk). If you can send to an address, you can be sure there is no mistake.\n\nHowever, there is a real risk of malware. I see on a daily basis people who send to the *wrong* address, because for example they have malware on their computer which replaces a the intended address with one controlled by the malware author. So verifying you are sending to the correct address is very much still a concern, but there's no risk you type a 2 instead of 3 and send to the wrong place.\n\n2.  Google \"bitcoin multisig\" and \"bitcoin escrow\". In the core bitcoin protocol there's a lot of support that enables stuff like that -- but nothing that is really commonly used. I've done some very large deals with bitcoin, with the use of \"2 of 3 multisig\" (basically 2 of: me, counter-party, arbitrator)  need to sign off on it. However it's a big pain in the ass, with poor tooling and expensive transactions. Unless you're dealing with 100+ bitcoin, it's a lot easier for everyone to just use a trusted (single party) escrow.\n\n-Ryan\n\n-------- Original Message --------\nOn January 23, 2018 7:42 PM, rmcc4444 via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I know from speaking to my friends not involved with Bitcoin that two of their major concerns are as follows:\n>\n> 1. They are afraid if they fat finger the address there is nothing they can do about it and not get their Bitcoin back.\n>\n> and/or\n>\n> 2. They would like to at least have the option to use some sort of 2 step confirmation system when dealing ith people they do not know. For example, after sending the Bitcoin to a seller they would like to be able to do a final approval of the tm transaction. If the 2 people involved in the transaction approve of it within X hours, the coin returns to the original person. This system would basically act as an escrow.\n>\n> This 2 step system could work with both of these.\n>\n> I apologize if this is the incorrect place to post this. I did not know where else to share these thoughts.\n>\n> Thanks for your time.\n>\n> --\n>\n> ** This message was likely sent using voice to text. Please ignore any typos.**\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180123/a3a02516/attachment-0001.html>"
            },
            {
                "author": "Weiwu Zhang",
                "date": "2018-01-30T01:23:13",
                "message_text_only": "On Wed, 24 Jan 2018, rmcc4444 via bitcoin-dev wrote:\n\n> I know from speaking to my friends not involved with Bitcoin that two of\n> their major concerns are as follows:\u00a0\n> 1. They are afraid if they fat finger the address there is nothing they can\n> do about it and not get their Bitcoin back.\n\nI can empathize with this. A friend of mine, an artificial intelligence\nexpert of the biggest bank in our country with a degree in math and IQ\nof 150, copied his merchant's Bitcoin address as his and sent to a\ncolleague to ask for a repayment. As a result, the merchant got paid\ntwice. That was back a few years ago when Bitcoin could be used for\npurchasing goods.\n\nThere are a few ways to address this issue.\n\nFor starter, the beneficiary's wallet can generate a signed payment\nrequest instead of just an address. The AI expert, in his case,\nwouldn't be able to generate a payment request for the merchant\nbecause he doesn't have the merchant's key. The payment request can\nhave a timestamp for the sender to spot the reuse of old request. There\nare advanced methods to go down this route, e.g. in the cases where\nthere is an invoice, or buyer's public key is known, these can be\nassociated with the payment request or be used in some homomorphic\nmagic to generate very special addresses to receive the money.\n\nThen, there is the option of sending the transaction (in a private\nchannel) to the beneficiary instead of broadcasting the\ntransaction. The beneficiary, we trust, will not broadcast the\ntransaction if he would not receive money as a result of it or he sees\nthe transaction wasn't constructed correctly to his wish. In fact, he\nmay not be able to even see the transaction without the right private\nkey to generate a decoding session key. This method solves another\nuse-case: deniable payment. It's not unusual for a WeChat user to deny\nanother WeChat user's Red Packt (\"I don't take bribes, sir!\"). If it is\nwith Bitcoin, the beneficiary certainly does not want to pay the\ntransaction fee again just to nullify the previous payment to him. In\na more illustrative example, I like to give away free Bitcoins after\nmy lectures, but many of the students won't redeem their share because\nmoney isn't the only motivation for their studies. I admit that money\nis my motivation after all and I wish to reclaim the money that was\nnot redeemed by students. (I stopped this practise when giving away\nBitcoin costs more than the amount given.)\n\nFinally, there is multi-sig. I'll cover that in answering the 2nd\nsection of your email.\n\n> 2. They would like to at least have the option to use some sort of 2 step\n> confirmation system when dealing ith people they do not know. For example,\n> after sending the Bitcoin to a seller they would like to be able to do a\n> final approval of the tm transaction. If the 2 people involved in the\n> transaction approve of it within X hours, the coin returns to the original\n> person. This system would basically act as an escrow.\n\nThere is the case of escrow with an arbitrator and escrow without an\narbitrator. We know that the beneficiary can always send the money\nback by looking up the input address. Given that he alone has this\npower, whether or not the other person agrees, to reimburse, it is a\nmoot point to require two people to co-sign anything. Therefore, the\ncase without arbitrageur is usually depended on time or revealing an x\nto a known hash. This can go complicated so I'll turn around\nand talk about the case with arbitrageur.\n\nThe case with an arbitrator was explained by Rhavar. It can be\nelaborately built in a sheltered model, where a compromised arbitrator\ncan only revert transactions, not to steal. You can build fine-tuned\nfeatures with Rhavar's model, like setting a 90-day grace period where\nthe beneficiary cannot claim the money, in order to leave ample time\nfor the arbitrator to revert the transaction should he need to do so.\n\nAs Rhavar pointed out, it's too costly to be practical for daily\ntransactions. Back in 2012 when I learned about multi-sig, I hopped\nmulti-sig grew popular before the blockchain gets full so that people\nhave the opportunity to witness the power of Bitcoin. It unfortunately\ndidn't happen.\n\nAll of the methods I mentioned does not require any change to the\nBitcoin network or Bitcoin Blockchain. The wallet is the weakest link\nin this chain. A wallet developer can go ahead and implement all these\nwithout negotiating with Bitcoin developers.\n\nP.S. I remark that I consistently use the word beneficiary because the\nother choices like \"receiver\" or \"recipient\" are often meant for the\nreceiving of messages (e.g. in a private channel), who doesn't have to\nbe the beneficiary (e.g. an arbitrator receives a lot of\nmessages).\n\nI check mail lists weekly so, sorry for the late reply."
            }
        ],
        "thread_summary": {
            "title": "2 step confirmation system",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Weiwu Zhang",
                "Rhavar",
                "rmcc4444"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 8369
        }
    },
    {
        "title": "[bitcoin-dev] Why is deriving public key from the signature not used in Segwit?",
        "thread_messages": [
            {
                "author": "\u0410\u0440\u0442\u0451\u043c \u041b\u0438\u0442\u0432\u0438\u043d\u043e\u0432\u0438\u0447",
                "date": "2018-01-24T03:50:10",
                "message_text_only": "Greetings.\n\nI wanted to ask what was the rationale behind still having both public\nkey and signature in Segwit witness?\n\nAs is known for a while, the public key can be derived from the\nsignature and a quadrant byte, a trick that is successfully used both\nin Bitcoin message signing algorithm and in Ethereum transaction\nsignatures. The later in particular suggests that this is a perfectly\nfunctional and secure alternative.\nLeaving out the public key would have saved 33 bytes per signature,\nwhich is quite a lot.\n\nSo, the question is - was there a good reason to do it the old way\n(security, performance, privacy, something else?), or was it something\nthat haven't been thought of/considered at the time?"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-24T04:25:28",
                "message_text_only": "On Wed, Jan 24, 2018 at 3:50 AM, \u0410\u0440\u0442\u0451\u043c \u041b\u0438\u0442\u0432\u0438\u043d\u043e\u0432\u0438\u0447 via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Greetings.\n>\n> I wanted to ask what was the rationale behind still having both public\n> key and signature in Segwit witness?\n>\n> As is known for a while, the public key can be derived from the\n> signature and a quadrant byte, a trick that is successfully used both\n> in Bitcoin message signing algorithm and in Ethereum transaction\n> signatures. The later in particular suggests that this is a perfectly\n> functional and secure alternative.\n> Leaving out the public key would have saved 33 bytes per signature,\n> which is quite a lot.\n>\n> So, the question is - was there a good reason to do it the old way\n> (security, performance, privacy, something else?), or was it something\n> that haven't been thought of/considered at the time?\n\nIt is slow to verify, incompatible with batch validation, doesn't save\nspace if hashing isn't used, and is potentially patent encumbered."
            },
            {
                "author": "Aymeric Vitte",
                "date": "2018-01-24T10:24:55",
                "message_text_only": "34 bytes in fact\n\nI have asked already the question at least twice on this list pointing\nout the fact that pubkey is there now even for standard p2pkh\ntransactions and it was not the case some time ago\n\nBut I never got any answer regarding what motivated this change\n(compared to the previous behavior) and when, so whether I am missing\nsomething obvious, whether nobody wants to answer\n\nTxs without pubkey are now rejected then what is the element in the code\n(protocol, version, etc) that \"decided\" this?\n\n\nLe 24/01/2018 \u00e0 05:25, Gregory Maxwell via bitcoin-dev a \u00e9crit\u00a0:\n> On Wed, Jan 24, 2018 at 3:50 AM, \u0410\u0440\u0442\u0451\u043c \u041b\u0438\u0442\u0432\u0438\u043d\u043e\u0432\u0438\u0447 via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> Greetings.\n>>\n>> I wanted to ask what was the rationale behind still having both public\n>> key and signature in Segwit witness?\n>>\n>> As is known for a while, the public key can be derived from the\n>> signature and a quadrant byte, a trick that is successfully used both\n>> in Bitcoin message signing algorithm and in Ethereum transaction\n>> signatures. The later in particular suggests that this is a perfectly\n>> functional and secure alternative.\n>> Leaving out the public key would have saved 33 bytes per signature,\n>> which is quite a lot.\n>>\n>> So, the question is - was there a good reason to do it the old way\n>> (security, performance, privacy, something else?), or was it something\n>> that haven't been thought of/considered at the time?\n> It is slow to verify, incompatible with batch validation, doesn't save\n> space if hashing isn't used, and is potentially patent encumbered.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-- \nBitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions\nZcash wallets made simple: https://github.com/Ayms/zcash-wallets\nBitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets\nGet the torrent dynamic blocklist: http://peersm.com/getblocklist\nCheck the 10 M passwords list: http://peersm.com/findmyass\nAnti-spies and private torrents, dynamic blocklist: http://torrent-live.org\nPeersm : http://www.peersm.com\ntorrent-live: https://github.com/Ayms/torrent-live\nnode-Tor : https://www.github.com/Ayms/node-Tor\nGitHub : https://www.github.com/Ayms"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-24T10:31:35",
                "message_text_only": "On Wed, Jan 24, 2018 at 10:24 AM, Aymeric Vitte <vitteaymeric at gmail.com> wrote:\n> out the fact that pubkey is there now even for standard p2pkh\n> transactions and it was not the case some time ago\n>\n> But I never got any answer regarding what motivated this change\n> (compared to the previous behavior) and when, so whether I am missing\n> something obvious, whether nobody wants to answer\n\nNo such behaviour ever existed, you are simply mistaken."
            },
            {
                "author": "Aymeric Vitte",
                "date": "2018-01-24T11:16:30",
                "message_text_only": "Then what about\nhttps://blockchain.info/tx/226a8b08dc46a00e9ecec5567a303a0b354bef3c1674476eb5e4b627b2ace493?format=hex\n?\n\nScriptsig:\n\n473044022057a1234709270325e7215200f982546304cf465971cbd55d54231ead54ef1a7802207a82e93ef2b0f87188abe87bccb67ee9d5c650b1b58948e5b1c80ba1b4c43dc301\n\nNo pubkey...\n\n\nLe 24/01/2018 \u00e0 11:31, Gregory Maxwell a \u00e9crit\u00a0:\n> On Wed, Jan 24, 2018 at 10:24 AM, Aymeric Vitte <vitteaymeric at gmail.com> wrote:\n>> out the fact that pubkey is there now even for standard p2pkh\n>> transactions and it was not the case some time ago\n>>\n>> But I never got any answer regarding what motivated this change\n>> (compared to the previous behavior) and when, so whether I am missing\n>> something obvious, whether nobody wants to answer\n> No such behaviour ever existed, you are simply mistaken.\n\n-- \nBitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions\nZcash wallets made simple: https://github.com/Ayms/zcash-wallets\nBitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets\nGet the torrent dynamic blocklist: http://peersm.com/getblocklist\nCheck the 10 M passwords list: http://peersm.com/findmyass\nAnti-spies and private torrents, dynamic blocklist: http://torrent-live.org\nPeersm : http://www.peersm.com\ntorrent-live: https://github.com/Ayms/torrent-live\nnode-Tor : https://www.github.com/Ayms/node-Tor\nGitHub : https://www.github.com/Ayms"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-24T11:35:49",
                "message_text_only": "On Wed, Jan 24, 2018 at 11:16 AM, Aymeric Vitte <vitteaymeric at gmail.com> wrote:\n> Then what about\n> https://blockchain.info/tx/226a8b08dc46a00e9ecec5567a303a0b354bef3c1674476eb5e4b627b2ace493?format=hex\n> ?\n>\n> Scriptsig:\n>\n> 473044022057a1234709270325e7215200f982546304cf465971cbd55d54231ead54ef1a7802207a82e93ef2b0f87188abe87bccb67ee9d5c650b1b58948e5b1c80ba1b4c43dc301\n>\n> No pubkey...\n\nBecause the pubkey is in the scriptPubKey of vout 0 of\n40872a376e98a1f8b285827c2ad8c5b3eec7d779d752dc3a4adda5d9bb70f3b5 which\nit is spending."
            },
            {
                "author": "Aymeric Vitte",
                "date": "2018-01-24T12:03:55",
                "message_text_only": "Indeed... I would have bet that I had other examples with p2pkh this\ntime but apparently I imagined it\n\n\nLe 24/01/2018 \u00e0 12:35, Gregory Maxwell a \u00e9crit\u00a0:\n> On Wed, Jan 24, 2018 at 11:16 AM, Aymeric Vitte <vitteaymeric at gmail.com> wrote:\n>> Then what about\n>> https://blockchain.info/tx/226a8b08dc46a00e9ecec5567a303a0b354bef3c1674476eb5e4b627b2ace493?format=hex\n>> ?\n>>\n>> Scriptsig:\n>>\n>> 473044022057a1234709270325e7215200f982546304cf465971cbd55d54231ead54ef1a7802207a82e93ef2b0f87188abe87bccb67ee9d5c650b1b58948e5b1c80ba1b4c43dc301\n>>\n>> No pubkey...\n> Because the pubkey is in the scriptPubKey of vout 0 of\n> 40872a376e98a1f8b285827c2ad8c5b3eec7d779d752dc3a4adda5d9bb70f3b5 which\n> it is spending.\n\n-- \nBitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions\nZcash wallets made simple: https://github.com/Ayms/zcash-wallets\nBitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets\nGet the torrent dynamic blocklist: http://peersm.com/getblocklist\nCheck the 10 M passwords list: http://peersm.com/findmyass\nAnti-spies and private torrents, dynamic blocklist: http://torrent-live.org\nPeersm : http://www.peersm.com\ntorrent-live: https://github.com/Ayms/torrent-live\nnode-Tor : https://www.github.com/Ayms/node-Tor\nGitHub : https://www.github.com/Ayms"
            }
        ],
        "thread_summary": {
            "title": "Why is deriving public key from the signature not used in Segwit?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "\u0410\u0440\u0442\u0451\u043c \u041b\u0438\u0442\u0432\u0438\u043d\u043e\u0432\u0438\u0447",
                "Gregory Maxwell",
                "Aymeric Vitte"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 7713
        }
    },
    {
        "title": "[bitcoin-dev] Merge of protocol",
        "thread_messages": [
            {
                "author": "Ilan Oh",
                "date": "2018-01-24T11:56:04",
                "message_text_only": "2017 was fork year,\n\nIs it technically possible to merge two protocoles ? And thus bringing the\nstrength of both into one resulting coin.\n\nI would not be surprized to see a lot of altcoin wanting to merge with\nbitcoin or between them, especially with LN current development, if it is\npossible,\n\nIf anyone has ideas or ressources on this,\n\nThanks\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180124/729c342b/attachment.html>"
            },
            {
                "author": "Tier Nolan",
                "date": "2018-01-24T15:02:38",
                "message_text_only": "If the communities behind two coins wanted to merge, it would be possible,\nbut difficulty and risky.\n\nIt represents a hard fork on both chains.  Not only does each coin's\ncommunity need to agree, the two communities need to agree with each other.\n\nThey would both have to agree the join point.  The merge block would have 2\nparents.\n\n\nA <- B <- C <- D\n                 \\\n                    J1 <- J2 <- J3 <- J4\n                 /\nw <- x <- y <- z\n\n\nIn the above example, A, B, C, D is one chain and w, x, y, z is the other.\nThey combine and then J1, J2, J3, J4 is the combined chain.\n\nSince block \"J1\" has 2 parents, it commits to the state of the 2 legacy\nchains.  If you have coins in each chain at D or z, then you get coins in\nthe joint chain.\n\nThey would both need to agree on what the rules are for their new chain.\nSince it is a (double) hard fork, they can do pretty much anything they\nwant.\n\nThe combined chain could continue as before.  It would be a combined chain\nand each user's coin total would be unaffected.  The advantage of doing\nthat is that it causes minimum economic disruption to users.  The mining\npower for both chains would be applied to the joint chain, so they combine\ntheir security.\n\nAlternatively, they could agree on an exchange rate.  Users would be given\njoint-coins in exchange for their coins on the 2 legacy chains.\n\nFor something like Bitcoin Cash and Bitcoin, they could have a\nre-combination rule.  1 Bitcoin-Recombined = 1 BTC + 1 BCH.  That doesn't\nseem very likely though and also there are more BCH coins than BTC coins.\n\nIt might be worth moving this to bitcoin-discuss, since it isn't really\nBitcoin protocol discussion.\n\n\nWed, Jan 24, 2018 at 11:56 AM, Ilan Oh via bitcoin-dev <bitcoin-dev at lists.\nlinuxfoundation.org> wrote:\n\n> 2017 was fork year,\n>\n> Is it technically possible to merge two protocoles ? And thus bringing the\n> strength of both into one resulting coin.\n>\n> I would not be surprized to see a lot of altcoin wanting to merge with\n> bitcoin or between them, especially with LN current development, if it is\n> possible,\n>\n> If anyone has ideas or ressources on this,\n>\n> Thanks\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180124/beca5030/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Merge of protocol",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Tier Nolan",
                "Ilan Oh"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 3043
        }
    },
    {
        "title": "[bitcoin-dev] Fix or withdraw BIP120/121?",
        "thread_messages": [
            {
                "author": "Kalle Rosenbaum",
                "date": "2018-01-26T15:52:10",
                "message_text_only": "Hi\n\nThere is an inherent problem with BIP120, Proof of Payment: If there\nis a soft fork, a server that verifies PoPs will accept a PoP as valid\nwithout checking any of the new Bitcoin rules.\n\nFor example, a server will be fooled by a segwit transaction, because\nthe server doesn't have a witness to verify and consequently will\naccept any PoP with an empty scriptSig.\n\nBesides this problem, on-chain payments are not hot anymore and\ninterest, or need, for PoP as a concept seems low.\n\nI have no good solution for the soft fork problem. Requiring all\nsoftware that uses PoP to upgrade to a new PoP specification on each\nsoft-fork is not good enough. Do you have any ideas on how to fix it?\n\nIf there is no good solution to the soft-fork issue, I suggest that I\nwithdraw BIP120 and BIP121.\n\nAs for current implementations: I know that Mycelium implements\nBIP120, but I'm not sure if there is any other software, besides my\nown, implementing it. If you know of any, please let me know so I can\ndiscuss it with them.\n\nRegards,\n/Kalle"
            }
        ],
        "thread_summary": {
            "title": "Fix or withdraw BIP120/121?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Kalle Rosenbaum"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1029
        }
    },
    {
        "title": "[bitcoin-dev] Proposal: rewarding fees to next block miner",
        "thread_messages": [
            {
                "author": "Nathan Parker",
                "date": "2018-01-27T08:45:10",
                "message_text_only": "Miners can fill their blocks with transactions paying very high fees at no\ncost because they get the fees back to themselves. They can do this for\ndifferent purposes, like trying to increase the recommended fee. Here I\npropose a backwards-compatible solution to this problem.\n\nThe solution would be to reward the fees of the current block to the miner\nof the next block (or X blocks after the current one). That way, if a miner\nfloods its own block with very high fee transactions, those fees are no\nlonger given back to itself, but to the miner of future blocks which could\npotentially be anyone. Flooding blocks with fake txs is now discouraged.\nHowever, filling blocks with real transactions paying real fees is still\nencouraged because you could be the one to mine the block that would claim\nthis reward.\n\nThe way to implement this in a backwards-compatible fashion would be to\nenforce miners to set an anyone-can-spend output in the coinbase\ntransaction of the block (by adding this as a rule for verifying new\nblocks). The miner of 100 blocks after the current one can add a secondary\ntransaction spending this block's anyone-can-spend coinbase transaction\n(due to the coinbase needing 100 blocks to mature) and thus claiming the\nfunds. This way, the block reward of a block X is always transferred to the\nminer of block X+100.\n\nImplementing this would require a soft-fork. Since that secondary\ntransaction needs no signature whatsoever, the overhead caused by that\nextra transaction is negligible.\n\nPossible Downside: When the fork is activated, the miners won\u2019t get any\nreward for mining blocks for a period of 100 blocks. They could choose to\npower off the mining equipment for maintenance or to save power over that\nperiod, so the hashrate could drop temporarily. However, if the hashrate\ndrops too much, blocks would take much longer to mine, and miners wouldn\u2019t\nwant that either since they want to go through those 100 reward-less blocks\nas soon as possible so they can start getting rewards from mining again.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180127/70e96d79/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-27T19:06:41",
                "message_text_only": "Not incentive compatible. Miners would prefer to include transactions\npaying fees via alternative mechanisms (anyone can spend outputs,\ndirect pay to miner outputs, or completely out of band), if they even\npaid attention to internal fees at all they would give a lot more\nweight to direct payment fees. Users would accordingly pay much lower\nfees if they used these alternatives instead of directly, so the\nequlibrium state is almost everyone bypassing.   Bypass fee mechenisms\nhave been supported by miners since 2011 too, so it isn't just\nconjecture.\n\nOn Sat, Jan 27, 2018 at 8:45 AM, Nathan Parker via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Miners can fill their blocks with transactions paying very high fees at no\n> cost because they get the fees back to themselves. They can do this for\n> different purposes, like trying to increase the recommended fee. Here I\n> propose a backwards-compatible solution to this problem.\n>\n> The solution would be to reward the fees of the current block to the miner\n> of the next block (or X blocks after the current one). That way, if a miner\n> floods its own block with very high fee transactions, those fees are no\n> longer given back to itself, but to the miner of future blocks which could\n> potentially be anyone. Flooding blocks with fake txs is now discouraged.\n> However, filling blocks with real transactions paying real fees is still\n> encouraged because you could be the one to mine the block that would claim\n> this reward.\n>\n> The way to implement this in a backwards-compatible fashion would be to\n> enforce miners to set an anyone-can-spend output in the coinbase transaction\n> of the block (by adding this as a rule for verifying new blocks). The miner\n> of 100 blocks after the current one can add a secondary transaction spending\n> this block's anyone-can-spend coinbase transaction (due to the coinbase\n> needing 100 blocks to mature) and thus claiming the funds. This way, the\n> block reward of a block X is always transferred to the miner of block X+100.\n>\n> Implementing this would require a soft-fork. Since that secondary\n> transaction needs no signature whatsoever, the overhead caused by that extra\n> transaction is negligible.\n>\n> Possible Downside: When the fork is activated, the miners won\u2019t get any\n> reward for mining blocks for a period of 100 blocks. They could choose to\n> power off the mining equipment for maintenance or to save power over that\n> period, so the hashrate could drop temporarily. However, if the hashrate\n> drops too much, blocks would take much longer to mine, and miners wouldn\u2019t\n> want that either since they want to go through those 100 reward-less blocks\n> as soon as possible so they can start getting rewards from mining again.\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2018-01-27T23:48:10",
                "message_text_only": "The OP premise is flawed:\n\nhttps://github.com/libbitcoin/libbitcoin/wiki/Fee-Recovery-Fallacy\n\nas is the idea that side fees are incentive incompatible:\n\nhttps://github.com/libbitcoin/libbitcoin/wiki/Side-Fee-Fallacy\n\ne\n\nOn 01/27/2018 11:06 AM, Gregory Maxwell via bitcoin-dev wrote:\n> Not incentive compatible. Miners would prefer to include transactions\n> paying fees via alternative mechanisms (anyone can spend outputs,\n> direct pay to miner outputs, or completely out of band), if they even\n> paid attention to internal fees at all they would give a lot more\n> weight to direct payment fees. Users would accordingly pay much lower\n> fees if they used these alternatives instead of directly, so the\n> equlibrium state is almost everyone bypassing.   Bypass fee mechenisms\n> have been supported by miners since 2011 too, so it isn't just\n> conjecture.\n> \n> On Sat, Jan 27, 2018 at 8:45 AM, Nathan Parker via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> Miners can fill their blocks with transactions paying very high fees at no\n>> cost because they get the fees back to themselves. They can do this for\n>> different purposes, like trying to increase the recommended fee. Here I\n>> propose a backwards-compatible solution to this problem.\n>>\n>> The solution would be to reward the fees of the current block to the miner\n>> of the next block (or X blocks after the current one). That way, if a miner\n>> floods its own block with very high fee transactions, those fees are no\n>> longer given back to itself, but to the miner of future blocks which could\n>> potentially be anyone. Flooding blocks with fake txs is now discouraged.\n>> However, filling blocks with real transactions paying real fees is still\n>> encouraged because you could be the one to mine the block that would claim\n>> this reward.\n>>\n>> The way to implement this in a backwards-compatible fashion would be to\n>> enforce miners to set an anyone-can-spend output in the coinbase transaction\n>> of the block (by adding this as a rule for verifying new blocks). The miner\n>> of 100 blocks after the current one can add a secondary transaction spending\n>> this block's anyone-can-spend coinbase transaction (due to the coinbase\n>> needing 100 blocks to mature) and thus claiming the funds. This way, the\n>> block reward of a block X is always transferred to the miner of block X+100.\n>>\n>> Implementing this would require a soft-fork. Since that secondary\n>> transaction needs no signature whatsoever, the overhead caused by that extra\n>> transaction is negligible.\n>>\n>> Possible Downside: When the fork is activated, the miners won\u2019t get any\n>> reward for mining blocks for a period of 100 blocks. They could choose to\n>> power off the mining equipment for maintenance or to save power over that\n>> period, so the hashrate could drop temporarily. However, if the hashrate\n>> drops too much, blocks would take much longer to mine, and miners wouldn\u2019t\n>> want that either since they want to go through those 100 reward-less blocks\n>> as soon as possible so they can start getting rewards from mining again.\n>>\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180127/f4627e13/attachment.sig>"
            },
            {
                "author": "Lucas Clemente Vella",
                "date": "2018-01-28T16:54:36",
                "message_text_only": "If the miner wants to force fees up, why would he fill up a block with\nplaceholder high fee transactions, instead of simply cutting off\ntransactions paying less fee than he is willing to take? Is there any\nevidence someone is doing such a thing for whatever reason?\n\n2018-01-27 6:45 GMT-02:00 Nathan Parker via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org>:\n\n> Miners can fill their blocks with transactions paying very high fees at no\n> cost because they get the fees back to themselves. They can do this for\n> different purposes, like trying to increase the recommended fee. Here I\n> propose a backwards-compatible solution to this problem.\n>\n> The solution would be to reward the fees of the current block to the miner\n> of the next block (or X blocks after the current one). That way, if a miner\n> floods its own block with very high fee transactions, those fees are no\n> longer given back to itself, but to the miner of future blocks which could\n> potentially be anyone. Flooding blocks with fake txs is now discouraged.\n> However, filling blocks with real transactions paying real fees is still\n> encouraged because you could be the one to mine the block that would claim\n> this reward.\n>\n> The way to implement this in a backwards-compatible fashion would be to\n> enforce miners to set an anyone-can-spend output in the coinbase\n> transaction of the block (by adding this as a rule for verifying new\n> blocks). The miner of 100 blocks after the current one can add a secondary\n> transaction spending this block's anyone-can-spend coinbase transaction\n> (due to the coinbase needing 100 blocks to mature) and thus claiming the\n> funds. This way, the block reward of a block X is always transferred to the\n> miner of block X+100.\n>\n> Implementing this would require a soft-fork. Since that secondary\n> transaction needs no signature whatsoever, the overhead caused by that\n> extra transaction is negligible.\n>\n> Possible Downside: When the fork is activated, the miners won\u2019t get any\n> reward for mining blocks for a period of 100 blocks. They could choose to\n> power off the mining equipment for maintenance or to save power over that\n> period, so the hashrate could drop temporarily. However, if the hashrate\n> drops too much, blocks would take much longer to mine, and miners wouldn\u2019t\n> want that either since they want to go through those 100 reward-less blocks\n> as soon as possible so they can start getting rewards from mining again.\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n\n\n-- \nLucas Clemente Vella\nlvella at gmail.com\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180128/712c01bf/attachment.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2018-01-29T00:46:51",
                "message_text_only": "Miners accept less than the optimal (i.e. highest net fee) set of\ntransactions all the time. The reason is that it takes too much time to\ncompute the optimal set. All other things being equal, the miner who is\nmore efficient at computing a set is more profitable.\n\nIntentionally not accepting the most optimal set possible is a cost, not\na source of increased returns. Miners can raise the historical fee level\nby paying this real cost, just as can any other person (by submitting a\ncompetitive-fee transaction). They cannot \"recover\" this cost. They have\nno place of advantage in terms of competing for block space.\n\nFinally, historical prices do not determine future prices. Current\ncompetition for block space determines future prices.\n\ne\n\nOn 01/28/2018 08:54 AM, Lucas Clemente Vella via bitcoin-dev wrote:\n> If the miner wants to force fees up, why would he fill up a block with\n> placeholder high fee transactions, instead of simply cutting off\n> transactions paying less fee than he is willing to take? Is there any\n> evidence someone is doing such a thing for whatever reason?\n>\n> 2018-01-27 6:45 GMT-02:00 Nathan Parker via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org\n> <mailto:bitcoin-dev at lists.linuxfoundation.org>>:\n> \n>     Miners can fill their blocks with transactions paying very high fees\n>     at no cost because they get the fees back to themselves. They can do\n>     this for different purposes, like trying to increase the recommended\n>     fee. Here I propose a backwards-compatible solution to this problem.\n> \n>     The solution would be to reward the fees of the current block to the\n>     miner of the next block (or X blocks after the current one). That\n>     way, if a miner floods its own block with very high fee\n>     transactions, those fees are no longer given back to itself, but to\n>     the miner of future blocks which could potentially be anyone.\n>     Flooding blocks with fake txs is now discouraged. However, filling\n>     blocks with real transactions paying real fees is still encouraged\n>     because you could be the one to mine the block that would claim this\n>     reward.\n> \n>     The way to implement this in a backwards-compatible fashion would be\n>     to enforce miners to set an anyone-can-spend output in the coinbase\n>     transaction of the block (by adding this as a rule for verifying new\n>     blocks). The miner of 100 blocks after the current one can add a\n>     secondary transaction spending this block's anyone-can-spend\n>     coinbase transaction (due to the coinbase needing 100 blocks to\n>     mature) and thus claiming the funds. This way, the block reward of a\n>     block X is always transferred to the miner of block X+100.\n> \n>     Implementing this would require a soft-fork. Since that secondary\n>     transaction needs no signature whatsoever, the overhead caused by\n>     that extra transaction is negligible.\n> \n>     Possible Downside: When the fork is activated, the miners won\u2019t get\n>     any reward for mining blocks for a period of 100 blocks. They could\n>     choose to power off the mining equipment for maintenance or to save\n>     power over that period, so the hashrate could drop temporarily.\n>     However, if the hashrate drops too much, blocks would take much\n>     longer to mine, and miners wouldn\u2019t want that either since they want\n>     to go through those 100 reward-less blocks as soon as possible so\n>     they can start getting rewards from mining again.\n> \n> \n> \n>     _______________________________________________\n>     bitcoin-dev mailing list\n>     bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n> \n> \n> \n> \n> -- \n> Lucas Clemente Vella\n> lvella at gmail.com <mailto:lvella at gmail.com>\n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180128/5e6da2a0/attachment.sig>"
            },
            {
                "author": "George Balch",
                "date": "2018-01-29T01:44:08",
                "message_text_only": "If miners leave transactions out of a block they do pay a cost by not being\nrewarded those fees.  If they include their own spam transactions to get\nback the fee they gain nothing.  Since blocks can have fees resulting in\nhundreds of thousands of dollars, it would seem unlikely that miners incur\na huge cost for not including transactions.\n\nOn Sun, Jan 28, 2018 at 8:54 AM, Lucas Clemente Vella via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> If the miner wants to force fees up, why would he fill up a block with\n> placeholder high fee transactions, instead of simply cutting off\n> transactions paying less fee than he is willing to take? Is there any\n> evidence someone is doing such a thing for whatever reason?\n>\n> 2018-01-27 6:45 GMT-02:00 Nathan Parker via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org>:\n>\n>> Miners can fill their blocks with transactions paying very high fees at\n>> no cost because they get the fees back to themselves. They can do this for\n>> different purposes, like trying to increase the recommended fee. Here I\n>> propose a backwards-compatible solution to this problem.\n>>\n>> The solution would be to reward the fees of the current block to the\n>> miner of the next block (or X blocks after the current one). That way, if a\n>> miner floods its own block with very high fee transactions, those fees are\n>> no longer given back to itself, but to the miner of future blocks which\n>> could potentially be anyone. Flooding blocks with fake txs is now\n>> discouraged. However, filling blocks with real transactions paying real\n>> fees is still encouraged because you could be the one to mine the block\n>> that would claim this reward.\n>>\n>> The way to implement this in a backwards-compatible fashion would be to\n>> enforce miners to set an anyone-can-spend output in the coinbase\n>> transaction of the block (by adding this as a rule for verifying new\n>> blocks). The miner of 100 blocks after the current one can add a secondary\n>> transaction spending this block's anyone-can-spend coinbase transaction\n>> (due to the coinbase needing 100 blocks to mature) and thus claiming the\n>> funds. This way, the block reward of a block X is always transferred to the\n>> miner of block X+100.\n>>\n>> Implementing this would require a soft-fork. Since that secondary\n>> transaction needs no signature whatsoever, the overhead caused by that\n>> extra transaction is negligible.\n>>\n>> Possible Downside: When the fork is activated, the miners won\u2019t get any\n>> reward for mining blocks for a period of 100 blocks. They could choose to\n>> power off the mining equipment for maintenance or to save power over that\n>> period, so the hashrate could drop temporarily. However, if the hashrate\n>> drops too much, blocks would take much longer to mine, and miners wouldn\u2019t\n>> want that either since they want to go through those 100 reward-less blocks\n>> as soon as possible so they can start getting rewards from mining again.\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>\n>\n> --\n> Lucas Clemente Vella\n> lvella at gmail.com\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180128/dc779353/attachment.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2018-01-29T04:49:10",
                "message_text_only": "Your statements contradict each other.\n\nThis is not a question of whether it is a \"huge\" cost, but whether there\nis an problem of incentive compatibility, which there is not. Miners\nincur the opportunity cost of the space that they mine that does not\ninclude the most optimal fees, which is equal in value to those forgone\nfees.\n\nIf miners exclude available higher-fee transactions, or mine empty\nspace, or mine their own \"recovery\" transactions, they are merely\npurchasing block space at market rates, just like everyone else.\n\nThe only difference is that they are getting nothing in return, while\neveryone else is presumably getting a useful monetary transfer. In other\nwords, they are losing value to do this. Therefore the incentive is to\nnot do so. But again, the option to do so is perfectly incentive compatible.\n\nI'm not sure who cooked up this myth about miners gaining advantage over\nthose who buy block space by mining empty space, rejecting higher-fee\ntransactions, and/or mining \"recovery\" transactions, but the idea is\ncomplete nonsense.\n\ne\n\nOn 01/28/2018 05:44 PM, George Balch via bitcoin-dev wrote:\n> If miners leave transactions out of a block they do pay a cost by not\n> being rewarded those fees.\u00a0 If they include their own spam transactions\n> to get back the fee they gain nothing.\u00a0 Since blocks can have fees\n> resulting in hundreds of thousands of dollars, it would seem unlikely\n> that miners incur a huge cost for not including transactions.\n> \n> On Sun, Jan 28, 2018 at 8:54 AM, Lucas Clemente Vella via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org\n> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> \n>     If the miner wants to force fees up, why would he fill up a block\n>     with placeholder high fee transactions, instead of simply cutting\n>     off transactions paying less fee than he is willing to take? Is\n>     there any evidence someone is doing such a thing for whatever reason?\n> \n>     2018-01-27 6:45 GMT-02:00 Nathan Parker via bitcoin-dev\n>     <bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>>:\n> \n>         Miners can fill their blocks with transactions paying very high\n>         fees at no cost because they get the fees back to themselves.\n>         They can do this for different purposes, like trying to increase\n>         the recommended fee. Here I propose a backwards-compatible\n>         solution to this problem.\n> \n>         The solution would be to reward the fees of the current block to\n>         the miner of the next block (or X blocks after the current one).\n>         That way, if a miner floods its own block with very high fee\n>         transactions, those fees are no longer given back to itself, but\n>         to the miner of future blocks which could potentially be anyone.\n>         Flooding blocks with fake txs is now discouraged. However,\n>         filling blocks with real transactions paying real fees is still\n>         encouraged because you could be the one to mine the block that\n>         would claim this reward.\n> \n>         The way to implement this in a backwards-compatible fashion\n>         would be to enforce miners to set an anyone-can-spend output in\n>         the coinbase transaction of the block (by adding this as a rule\n>         for verifying new blocks). The miner of 100 blocks after the\n>         current one can add a secondary transaction spending this\n>         block's anyone-can-spend coinbase transaction (due to the\n>         coinbase needing 100 blocks to mature) and thus claiming the\n>         funds. This way, the block reward of a block X is always\n>         transferred to the miner of block X+100.\n> \n>         Implementing this would require a soft-fork. Since that\n>         secondary transaction needs no signature whatsoever, the\n>         overhead caused by that extra transaction is negligible.\n> \n>         Possible Downside: When the fork is activated, the miners won\u2019t\n>         get any reward for mining blocks for a period of 100 blocks.\n>         They could choose to power off the mining equipment for\n>         maintenance or to save power over that period, so the hashrate\n>         could drop temporarily. However, if the hashrate drops too much,\n>         blocks would take much longer to mine, and miners wouldn\u2019t want\n>         that either since they want to go through those 100 reward-less\n>         blocks as soon as possible so they can start getting rewards\n>         from mining again.\n> \n> \n> \n>         _______________________________________________\n>         bitcoin-dev mailing list\n>         bitcoin-dev at lists.linuxfoundation.org\n>         <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>         <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n> \n> \n> \n> \n>     -- \n>     Lucas Clemente Vella\n>     lvella at gmail.com <mailto:lvella at gmail.com>\n> \n>     _______________________________________________\n>     bitcoin-dev mailing list\n>     bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n> \n> \n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180128/bec08c2b/attachment-0001.sig>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-29T21:22:25",
                "message_text_only": "On Mon, Jan 29, 2018 at 4:49 AM, Eric Voskuil via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> I'm not sure who cooked up this myth about miners gaining advantage over\n> those who buy block space by mining empty space, rejecting higher-fee\n> transactions, and/or mining \"recovery\" transactions, but the idea is\n> complete nonsense.\n\nI agree.\n\nSteel-manning it, I guess I could argue that empty blocks are slightly\nmore conspicuous and might invite retaliation especially given the\nhigh levels of mining centralization creates retaliation exposure. ...\nbut dummy transactions are hardly less conspicuous, many nodes log now\nwhen blocks show up containing txn that they've never seen before.\nMoreover, inexplicably underfilled blocks are produced (e.g. by\nbitmain's antpool) and no retaliation seems to be forthcoming."
            },
            {
                "author": "Eric Voskuil",
                "date": "2018-01-29T23:21:48",
                "message_text_only": "On 01/29/2018 01:22 PM, Gregory Maxwell wrote:\n> On Mon, Jan 29, 2018 at 4:49 AM, Eric Voskuil via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> I'm not sure who cooked up this myth about miners gaining advantage over\n>> those who buy block space by mining empty space, rejecting higher-fee\n>> transactions, and/or mining \"recovery\" transactions, but the idea is\n>> complete nonsense.\n> \n> I agree.\n> \n> Steel-manning it, I guess I could argue that empty blocks are slightly\n> more conspicuous and might invite retaliation especially given the\n> high levels of mining centralization creates retaliation exposure. ...\n> but dummy transactions are hardly less conspicuous, many nodes log now\n> when blocks show up containing txn that they've never seen before.\n> Moreover, inexplicably underfilled blocks are produced (e.g. by\n> bitmain's antpool) and no retaliation seems to be forthcoming.\n\nIt's not clear to me what would be the reason for retaliation, given\nthere is no more harm in a miner purchasing a block than Coinbase\nsubmitting enough transactions to fill a block. Both pay the market rate\nfor the space. But since the former results in a loss, a financial\nconsequence (\"retaliation\") is inherent.\n\nIf a farmer destroys his/her own apple crop he loses money. It may be\nvery conspicuous, but nobody would retaliate as only the farmer's own\nproperty was affected. Customers would just get their apples elsewhere.\nBlock space created by a miner is property that belongs to the miner, it\ncan be sold or not sold.\n\ne\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180129/3c12d82b/attachment.sig>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-30T01:59:48",
                "message_text_only": "On Mon, Jan 29, 2018 at 11:21 PM, Eric Voskuil <eric at voskuil.org> wrote:\n> Block space created by a miner is property that belongs to the miner, it\n> can be sold or not sold.\n\nThat case would be stronger when there is no more subsidy, but we\ncollectively the uses of Bitcoin are currently paying miners around\n$130k USD per block in the form of inflation for the job of honestly\ncomplying with the Bitcoin protocol.\n\nI don't think you can argue that they have any more right to do that\nthan any of us have a right to run software that invalidates their\ncoinbase outputs when they do; which would be the sort of retaliation\nthey might get targeted with."
            },
            {
                "author": "Eric Voskuil",
                "date": "2018-01-30T03:52:21",
                "message_text_only": "On 01/29/2018 05:59 PM, Gregory Maxwell wrote:\n> On Mon, Jan 29, 2018 at 11:21 PM, Eric Voskuil <eric at voskuil.org> wrote:\n>> Block space created by a miner is property that belongs to the miner, it\n>> can be sold or not sold.\n> \n> That case would be stronger when there is no more subsidy, but we\n> collectively the uses of Bitcoin are currently paying miners around\n> $130k USD per block in the form of inflation for the job of honestly\n> complying with the Bitcoin protocol.\n\nThe miner who creates a block owns the block, he/she has selected the\ntransactions and directs the reward. The case for this could hardly be\nstronger.\n\nThe fact that there is subsidy implies that *part* of the cost of\ncreating the block is offset. But by not accepting the highest fee\ntransactions the miner is still accepting a net loss by purchasing the\nspace for himself. The hash power generated by the miner to create the\nblock contributes to confirmation security to a greater degree than for\nwhich he has been rewarded.\n\nYou seem to be implying that there is dishonesty involved in purchasing\nblock space, or that it is somehow possible to earn reward while not\ncomplying with the protocol. There is no honest or dishonest compliance\nwith a protocol, there is just compliance or non-compliance.\n\n> I don't think you can argue that they have any more right to do that\n> than any of us have a right to run software that invalidates their\n> coinbase outputs when they do; which would be the sort of retaliation\n> they might get targeted with.\n\nEveryone can do whatever they want with their own machines, and I\nhaven't argued otherwise. As far as \"rights\" go, Bitcoin doesn't care.\nI'm not one who has regularly raised hard fork fears while at the same\ntime threatening them. My objective is to dispel flawed reasoning, not\nto negotiate for the rights of some group over another.\n\nSome economic theories that get thrown around are baffling, this idea of\n\"retaliation\" among them. Presumably the objective is to reduce\ntransaction confirmation costs. The theory would be that mining empty\nblocks or mining own transactions is \"unfairly\" increasing revenue to\nminers. Despite the incorrectness of this theory, the proposed cure\nattempts to reduce returns to miners. However the consequence of\nreducing returns to miners is simply a reduction of hash power (as the\nleast efficient miners become insolvent). Miners will continue to earn\nthe same rate of return on their capital as always. And the cost of\ntransactions will remain the same...\n\nThe presumed mechanism of the proposed retaliation is also baffling. A\nminer (or anyone) can always create transactions, pay fees, and send\nthem out to the network. Given that we presume transactions without\nidentity, it is not possible (or desirable) to detect the source of\ntransactions. Maybe the assumption is that sending such transactions out\nto the network would not satisfy the miner's objective, since the fees\ncannot be \"recovered\". But this is the original flaw. Fees spent to\none's self cannot be recovered either! So if a miner wants to blow money\nby filling up blocks with market fee transactions, they will be able to\ndo so at the same cost no matter how one tries to \"retaliate\".\n\ne\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180129/33843370/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Proposal: rewarding fees to next block miner",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Eric Voskuil",
                "Lucas Clemente Vella",
                "Gregory Maxwell",
                "Nathan Parker",
                "George Balch"
            ],
            "messages_count": 11,
            "total_messages_chars_count": 32371
        }
    },
    {
        "title": "[bitcoin-dev] Does Lightning require millisatoshi unit?",
        "thread_messages": [
            {
                "author": "Damian Williamson",
                "date": "2018-01-28T11:05:59",
                "message_text_only": "It seems in a document that I was referenced with this very question that the unit for creating invoices on Lightning is millisatoshi. Do we really need to invoice for 1000 millisatoshi for a 1 sat transaction?\n\n\nhttps://github.com/ElementsProject/lightning/blob/master/README.md#sending-and-receiving-payments\n\n[https://avatars2.githubusercontent.com/u/12729539?s=400&v=4]<https://github.com/ElementsProject/lightning/blob/master/README.md#sending-and-receiving-payments>\n\nlightning/README.md at master \u00b7 ElementsProject/lightning ...<https://github.com/ElementsProject/lightning/blob/master/README.md#sending-and-receiving-payments>\ngithub.com\nc-lightning is a standard compliant implementation of the Lightning Network protocol. The Lightning Network is a scalability solution for Bitcoin, enabling secure and ...\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180128/e0ffdc17/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Does Lightning require millisatoshi unit?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Damian Williamson"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1006
        }
    },
    {
        "title": "[bitcoin-dev] NIST 8202 Blockchain Technology Overview",
        "thread_messages": [
            {
                "author": "CANNON",
                "date": "2018-01-29T00:40:32",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nJanuary 20 2018\n\n(I am also forwarding this message to the bitcoin mailing list just in case there\nare other technological errors that could use correction in this draft paper or\nanything that should be added with my comments.)\n\nTo the authors of this paper,\nI am commenting on Draft NISTIR 8202 Blockchain Technology Overview located at\nhttps://csrc.nist.gov/CSRC/media/Publications/nistir/8202/draft/documents/nistir8202-draft.pdf\n\nJust in case that document is modified or removed I have also downloaded\nit to redistribute this error ridden draft at a later point if neccesary,\nand I also had the Internet Archive save a copy here for sake of archival reasons\nto give context to this message.\n\nhttps://web.archive.org/web/20180124170359/https://csrc.nist.gov/CSRC/media/Publications/nistir/8202/draft/documents/nistir8202-draft.pdf\n\nThere are a couple things I would like to contribute on regarding some\ncorrections needed in this paper. I must say, the content in this paper is\nmaking me doubt the credibility of the NIST. I am starting to wonder if the\nNIST is also incompetent with lack of credibility just like with most other\ngovernment institutions. Falsified information published as truth such as this\nonly expose their ignorance and incompetence and also propagate such ignorance\nto other institutions and people whom rely on NIST for information or research.\nThe information presented in this paper is technologically invalid and contains\nfalse information. I understand that mistakes happen, but this specific section\nregarding \"8.1.2 Bitcoin Cash (BCC)\" is obviously written without prior research.\nEven if research was done no citation is included to back these claims.\nI ask you to please conduct research and validate information before publishing it,\nespecially when the credibility of the NIST is at stake.\n\nI will proceed to outline some corrections.\n\n1. Bitcoin Cash uses the ticker BCH, BCC is the ticker for BitConnectCoin\n\n2. \"When SegWit was activated, it caused a hard fork\"\nThis is incorrect information. Segwit was not a hardfork. Rather segwit was\na softfork meaning that it is backwards compatible with unupgraded nodes and\nminers. With it being a softfork it actually prevents a fork in the blockchain\nby still being valid to unupgraded nodes and miners. Because segregated witness\nis not a hardfork its use is optional.\n\n3. \"and all the mining nodes and users who did not want to change started\ncalling the original Bitcoin blockchain Bitcoin Cash (BCC)\"\nThe original bitcoin blockchain is still called Bitcoin. Segwit did not create\nany fork in the blockchain. Bitcoin Cash however was a hard fork that resulted\nin a forked blockchain and new altcoin.\nBitcoin is Bitcoin,\nBitcoin Cash is Bitcoin Cash.\n\n4. \"Technically, Bitcoin is a fork and Bitcoin Cash is the original\nblockchain.\"\nTechnically, that statement is not truth.\n\nBitcoin Cash was forked from the original Bitcoin blockchain to create\nthe altcoin \"Bitcoin Cash\" (BCH) by people whom believe that the blocksize\nshould be large enough to accomodate all individual transactions on the main\nchain. Without going into any of my personal opinions of which one is better\n(bitcoin vs. \"bitcoin cash\") technically Bitcoin Cash was a hardfork and is\nnot the original chain but a forked one. It is a hardfork as the blocks\ngenerated by BCH are incompatible with BTC nodes. Because of this lack of\nbackwards compatibility, and the resulting fork in blockchain is why BCH is\ntechnically a hardfork.\n\nThis is just one section of this paper I have read thus far. It makes me\nwonder how many other fallacies are throughout this paper. I also wonder how\nmany other NIST papers exist out of draft form that contain errors. Even\nthe smallest amount of research could have prevented this in the case of\nthis paper, unless you are intentionally pushing false information.\n\nI hope these comments are of benefit to the improvement of this paper.\n\nCannon\nPGP Fingerprint: 2BB5 15CD 66E7 4E28 45DC 6494 A5A2 2879 3F06 E832 \nEmail: cannon at cannon-ciota.info\n\nNOTICE: ALL EMAIL CORRESPONDENCE NOT SIGNED/ENCRYPTED WITH PGP SHOULD \nBE CONSIDERED POTENTIALLY FORGED, AND NOT PRIVATE.\n\n-----BEGIN PGP SIGNATURE-----\n\niQIcBAEBCgAGBQJabmySAAoJEAYDai9lH2mwVPcP/ika01NHFMBbxVU9OKc4Ibrd\n12MpWW2sgvB14dm8NIuh/xQeFpxGjKvkwWCzqj0pSOE+WClVdK573MJcZF1hqnR4\niPNIr3noR632Hyl9V3Cst5hg5BiUmwETpsyDXG7q7Oj/bX3QAR+psjahk2H2gA6v\ni4m1BP4052eRymznJ8aRQc1ak23C4ylLvjC3RRfNmXozG77N4w+tQvFXq45yQam+\nnh/8EIck5D9vNTOtVgzgjVqQwfDgUsxgClqHGLNiUOSSievCQLhz1WynDZZSlKmf\nY1Gd70fBpHdrhLBe/SOLglZXPU2BTlicUoN/t9P+5i4qzPfNxfMW9eRi/Urd4sJX\nINUuEUMJ2m5EspFjv3rMT19ELts8WhGskBq/4OCT8Wlb9arzhvrDySzLdX5ij75V\nDhIX1r3CMDVN4HNb1V4M+Je4Wgle7oh+LS2QDjBnw3IMfjF37j+3OXiRDrlAkE30\nGNg0SooANGBvMIMdjnc8fwIV/TxeNh0vEj8M2a4VjbthiDT4L1a4CzxOqT3eWbvB\nYHUdz+hwSnydkj5EhyC2e0XN3zqvgSNYoE8HTvKG78ik49bZpxkssEuMWC5N+KM8\nj2pgzbVdJXu08mwxrgf2wylUpR630WAEXkcVg3rOw+irPl1U0VxzNL8eNFZehMe6\nnuUyXL4VMlApOgesmrCI\n=RQoE\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "CANNON",
                "date": "2018-01-30T01:43:22",
                "message_text_only": "-------- Forwarded Message --------\nSubject: RE: NIST 8202 Blockchain Technology Overview\nDate: Mon, 29 Jan 2018 12:25:05 +0000\nFrom: Yaga, Dylan (Fed) <dylan.yaga at nist.gov>\nTo: CANNON <cannon at cannon-ciota.info>\n\nThank you for your comments.\nYou, along with many others, expressed concern on section 8.1.2.\nTo help foster a full transparency approach on the editing of this section, I am sending the revised section to you for further comment. \n\n8.1.2\tBitcoin Cash (BCH)\nIn 2017, Bitcoin users adopted an improvement proposal for Segregated Witness (known as SegWit, where transactions are split into two segments: transactional data, and signature data) through a soft fork. SegWit made it possible to store transactional data in a more compact form while maintaining backwards compatibility.  However, a group of users had different opinions on how Bitcoin should evolve \u2013 and developed a hard fork of the Bitcoin blockchain titled Bitcoin Cash. Rather than implementing the SegWit changes, the developers of Bitcoin Cash decided to simply increase the blocksize. When the hard fork occurred, people had access to the same amount of coins on Bitcoin and Bitcoin Cash."
            },
            {
                "author": "CANNON",
                "date": "2018-01-30T03:30:21",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nOn 01/30/2018 01:43 AM, CANNON via bitcoin-dev wrote:\n> \n> \n> -------- Forwarded Message --------\n> Subject: RE: NIST 8202 Blockchain Technology Overview\n> Date: Mon, 29 Jan 2018 12:25:05 +0000\n> From: Yaga, Dylan (Fed) <dylan.yaga at nist.gov>\n> To: CANNON <cannon at cannon-ciota.info>\n> \n> Thank you for your comments.\n> You, along with many others, expressed concern on section 8.1.2.\n> To help foster a full transparency approach on the editing of this section, I am sending the revised section to you for further comment. \n> \n> 8.1.2\tBitcoin Cash (BCH)\n> In 2017, Bitcoin users adopted an improvement proposal for Segregated Witness (known as SegWit, where transactions are split into two segments: transactional data, and signature data) through a soft fork. SegWit made it possible to store transactional data in a more compact form while maintaining backwards compatibility.  However, a group of users had different opinions on how Bitcoin should evolve  and developed a hard fork of the Bitcoin blockchain titled Bitcoin Cash. Rather than implementing the SegWit changes, the developers of Bitcoin Cash decided to simply increase the blocksize. When the hard fork occurred, people had access to the same amount of coins on Bitcoin and Bitcoin Cash.\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n\nThis is much better than the original. My question, the part where it says segwit makes transactions more compact, I thought that transactions are not more compact but rather they just take advantage of extra blockspace beyond that of 1 MB? Yes they would appear to be more compact to un-upgraded nodes due to the witness being stripped, but the transactions are not actually more compact right?\n-----BEGIN PGP SIGNATURE-----\n\niQIcBAEBCgAGBQJab+afAAoJEAYDai9lH2mwCDAP/RRpExXmnPzlvxuhhJ+8gSlc\nQRZHVa0nJ2SETTZnQSa+0t8dBO9ROYSnDHuMEqz/ba8o00Rce8icxQvCGOO29OSK\nCru7/UJzYTwnt5mK2ljpUB1Fsx96fAPxfg4QMeDCRe+O5LLkH1als1GGVOwlFnLu\nBAV0MoCljWzBxokf0ax8+ZHHYEaKe+Fj9PKby7CZrqQKoL9PkI/n7EvqICUdTCu5\ntAz9SNIBVtUxgGx/ZY96hvBx0zorV1IQEWchQ50oh/V+TgmnOW4njQOKc4TcSgfp\nTKpRFs8Zd7TzeIS/85GX0APGypchxdjlBaV0EORTO9GYFo7nKlzHkIGOF9Er+E6q\nII4qjbKLc5d/wwCIA8MHFW0Vxwv2+0ztApaWAFW42+LeHERaPCzi4NEy5quqvmsE\nIiTaGebl2XbTd0I+aB6WWsScTUmfXrt+NL05kwE0KDylY/mSwYMgYjP95X1Mci7X\nrcJRf6/pP607EiHlq3MmDlyt4TrYBp9FVVjdjvM+sD8wz72FhWeYJQdyF8t1ToOD\nU/ItNsxl5Jx9JvCkBXoX+6MMZ91W7D2x04Ur3OMRmy/lOoztOYAdlKy0tMyRqfCi\nL81apfjvmTaR2OTWhCawgZGLXGJcfOG5ECuXC90B6il5Jsts/XwyFMN2Fa1iZB50\ncZwF3ySKxoVtpsf/vTW7\n=feRa\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "Peter Todd",
                "date": "2018-01-30T07:22:55",
                "message_text_only": "On Tue, Jan 30, 2018 at 03:30:21AM +0000, CANNON via bitcoin-dev wrote:\n> On 01/30/2018 01:43 AM, CANNON via bitcoin-dev wrote:\n> > \n> > \n> > -------- Forwarded Message --------\n> > Subject: RE: NIST 8202 Blockchain Technology Overview\n> > Date: Mon, 29 Jan 2018 12:25:05 +0000\n> > From: Yaga, Dylan (Fed) <dylan.yaga at nist.gov>\n> > To: CANNON <cannon at cannon-ciota.info>\n> > \n> > Thank you for your comments.\n> > You, along with many others, expressed concern on section 8.1.2.\n> > To help foster a full transparency approach on the editing of this section, I am sending the revised section to you for further comment. \n> > \n> > 8.1.2\tBitcoin Cash (BCH)\n> > In 2017, Bitcoin users adopted an improvement proposal for Segregated Witness (known as SegWit, where transactions are split into two segments: transactional data, and signature data) through a soft fork. SegWit made it possible to store transactional data in a more compact form while maintaining backwards compatibility.  However, a group of users had different opinions on how Bitcoin should evolve  and developed a hard fork of the Bitcoin blockchain titled Bitcoin Cash. Rather than implementing the SegWit changes, the developers of Bitcoin Cash decided to simply increase the blocksize. When the hard fork occurred, people had access to the same amount of coins on Bitcoin and Bitcoin Cash.\n> > \n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> > \n> \n> This is much better than the original. My question, the part where it says segwit makes transactions more compact, I thought that transactions are not more compact but rather they just take advantage of extra blockspace beyond that of 1 MB? Yes they would appear to be more compact to un-upgraded nodes due to the witness being stripped, but the transactions are not actually more compact right?\n\nThat's absolutely right; this is why segwit is a blocksize increase first and\nforemost rather than some kind of transaction size optimization.\n\nIt'd be good to get that corrected as well.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 488 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180130/2bacacf2/attachment.sig>"
            },
            {
                "author": "CANNON",
                "date": "2018-01-29T01:08:24",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nSlight correction to email I just posted titled \"NIST 8202 Blockchain Technology Overview\"\nThe date in top of email states Jan 20, corrected date is Jan 28th which can be validated\nalso by verifying my signature (gpg includes timestamp when signing).\n\nI also sent email with corrected date to NIST comments email address.\n-----BEGIN PGP SIGNATURE-----\n\niQIcBAEBCgAGBQJabnPNAAoJEAYDai9lH2mwzywP/Rr5qlkfihE6SkUZrMRp2G1R\njANSEOMgH3yj7UmNKO2Xqzw93ZyNxNIVAL7z2ru2A6D0ziPgMOUKzyTXbDDpqtJR\nmvnI0pe50UpDIbpBMx18X6pGw97LlnEYR81UKeEUPJWDzE1auJiuBr+teHMqVA5O\nDjGqYVQM/3LEK2yeKfYcTtxBqnHE3jwGnqV7AviHT6KqxmKuLQe18Rs+wNR9wmWO\nRYSsp3lD0sIYAC/snZx1c3NrwnB5kbwTbISzYLF5wK6WOcguoUPTFnZ7x1uEHImt\npbDdgDKnkuUusHTGQJEz+0xYjugcYImP12nx73qrUUJBq17g9BdfhdBGlRXabIzu\nSTRDw3gwnoqfXcJLeJ8/3ICauA8TCkugp8vXXbQ+Gk5G/DXMYokR/DvxmTzWmvky\n58vhrKOEFvVz9FBd6OALVbghQFVC8vtqvXB+AoM5bzHASlN+yOpt7wC4EOROla6f\nqSusq3xvp3aybui5tmlTOQtvMV4kxxoqA/HFmJ/Wdxm3/oQdGCHw5qrlMtjILuM5\nB5l+7UDbIiw6Vvi/ouGP7OekzJkTZo1tYY/95yXfg3I9cjv6wgEaRzHrVjF3o/FP\nFQL4GN/Fnjz7E8VQ/w0ttJ+sRyoIMvd16FcRRIC0LzpsczlWuhpBfdxuSry80Loi\ngztvxP9+MJVhJ5kZ27BJ\n=BxwT\n-----END PGP SIGNATURE-----"
            }
        ],
        "thread_summary": {
            "title": "NIST 8202 Blockchain Technology Overview",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Peter Todd",
                "CANNON"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 12530
        }
    },
    {
        "title": "[bitcoin-dev] How accurate are the Bitcoin timestamps?",
        "thread_messages": [
            {
                "author": "Neiman",
                "date": "2018-01-29T13:34:20",
                "message_text_only": "First time posting here, please be gentle.\n\nI'm doing a research project about blockchain timestamping. There are many\nsuch projects, including the fantastic OpenTimestamps.\n\nAll of the projects essentially save some data in a block, and rely on the\nblock timestamp as a proof that this data existed at some specific time.\n\nBut how accurate are Bitcoins timestamps?\n\nI didn't find any discussion or research regarding Bitcoin timestamp\naccuracy (also not in the history of this mailing list). I share here a\nsimple analysis of timestamp accuracy, and a suggestion how to improve it.\n\nBasic observations and questions:\n-------------------------------------------\n*1.* It seems to me that the timestamp is not the time that the block was\ncreated. Ideally, it's the time that the miner started to try to mine the\nblock. However, as timestamps may also be used as a source of variety for\nhashes, the exact meaning of its value is unclear.\n\nIf this is true, then there's a strange phenomena to observe in\nblockchain.info and blockexplorer.com: the timestamps of blocks equals the\nreceiving times.\n\nAm I wrong in my understanding, or is there a mistake in those websites?\n\n*2.* Timestamps are not necessary to avoid double-spending. A simple\nordering of blocks is sufficient, so exchanging timestamps with enumeration\nwould work double-spending wise. Permissioned consensus protocols, such as\nhyperledger, indeed have no timestamps (in version 1.0).\n\nAs far as I could tell, timestamps are included in Bitcoin's protocol\n*only* to adjust the difficulty of PoW.\n\nDirect control of timestamp accuracy:\n-----------------------------------------------\nThe only element in the protocol that I found to control timestamp accuracy\nis based on the network time concept.\n\nThe Bitcoin protocol defines \u201cnetwork time\u201d for each node. The network time\nis the median time of the other clients, but only if\n    1. there are at least 5 connected, and\n    2. the difference between the median time and the nodes own system time\nis less than 70 minutes.\n\nThen new blocks are accepted by the peers if their timestamps is\n    1. less than the network time plus 2 hours, and\n    2. greater than the median timestamp of previous 11 blocks.\n\nThe first rule supplies a 2 hour upper bound for timestamp accuracy.\n\nHowever, the second rule doesn't give a tight lower bound. Actually, no\nlower bound is given at all if no assumption is made about the median. If\nwe assume the median to be accurate enough at some timepoint, then we're\nonly assured that any future timestamp is no bigger than this specific\nmedian, which is not much information.\n\nFurther analysis can be made under different assumptions. For example,\nwhat's the accuracy if holders of 51% of the computational power create\nhonest timestamps? But unfortunately, I don't see any good reason to work\nunder such an assumptions.\n\nThe second rule cannot be strengthened to be similar to the first one\n(i.e., nodes don't accept blocks less than network time minus 2 hours). The\nreason is that nodes cannot differentiate if it's a new block with\ndishonest timestamp, an old block with an old timestamps (with many other\nblocks coming) or simply a new block that took a long time to mine.\n\nIndirect control of timestamps accuracy:\n--------------------------------------------------\nIf we assume that miners have no motive to increase difficulty\nartificially, then the PoW adjusting algorithm yields a second mechanism of\naccuracy control.\n\nThe adjustment rules are given in pow.cpp (bitcoin-core source, version\n0.15.1), in the function 'CalculateNextWorkRequired', by the formula (with\nsome additional adjustments which I omit):\n\n    (old_target* (time_of_last_block_in_2016_blocks_interval -\ntime_of_first_block_in_2016_blocks_interval) )/time_of_two_weeks\n\nIt uses a simple average of block time in the last 2016 blocks. But such\naverages ignore any values besides the first and last one in the interval.\nHence, if the difficulty is constant, the following sequence is valid from\nboth the protocol and the miners incentives point of views:\n\n    1, 2, 3,\u2026., 2015, 1209600 (time of two weeks), 2017, 2018, 2019,\u2026.,\n4031, 1209600*2, 4033, 4044, \u2026\n\nIf we want to be pedantic, the best lower bound for a block timestamp is\nthe timestamp of the block that closes the adjustment interval in which it\nresides.\n\nPossible improvement:\n-----------------------------\nWe may consider exchanging average with standard deviation in the\ndifficulty adjustment formula. It both better mirrors changes in the hash\npower along the interval, and disables the option to manipulate timestamps\nwithout affecting the difficulty.\n\nI'm aware that this change requires a hardfork, and won't happen any time\nsoon. But does it make sense to add it to a potential future hard fork?\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180129/66a8d265/attachment.html>"
            },
            {
                "author": "Tier Nolan",
                "date": "2018-01-29T21:40:44",
                "message_text_only": "On Mon, Jan 29, 2018 at 1:34 PM, Neiman via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> *2.* Timestamps are not necessary to avoid double-spending. A simple\n> ordering of blocks is sufficient, so exchanging timestamps with enumeration\n> would work double-spending wise. Permissioned consensus protocols, such as\n> hyperledger, indeed have no timestamps (in version 1.0).\n>\n\nThe timestamps simply needs to be reasonably accurate.  Their main purpose\nis to allow difficulty updates.\n\nThey can also be used to check that the node has caught up.\n\n\n> It uses a simple average of block time in the last 2016 blocks. But such\n> averages ignore any values besides the first and last one in the interval.\n> Hence, if the difficulty is constant, the following sequence is valid from\n> both the protocol and the miners incentives point of views:\n>\n>     1, 2, 3,\u2026., 2015, 1209600 (time of two weeks), 2017, 2018, 2019,\u2026.,\n> 4031, 1209600*2, 4033, 4044, \u2026\n>\n\nMuch of Bitcoin operates on the assumption that a majority of miners are\nhonest.  If 50%+ of miners set their timestamp reasonably accurately (say\nwithin 10 mins), then the actual timestamp will move forward at the same\nrate as real time.\n\nDishonest miners could set their timestamp as low as possible, but the\nmedian would move foward if more than half of the timestamps move forward.\n\n\n> If we want to be pedantic, the best lower bound for a block timestamp is\n> the timestamp of the block that closes the adjustment interval in which it\n> resides.\n>\n\nIf you are assuming that the miners are majority dishonest, then they can\nset the limit to anything as long as they don't move it more than 2 hours\ninto the future.\n\nThe miners could set their timestamps so that they increase 1 week fake\ntime every 2 weeks real time and reject any blocks more than 2 hours ahead\nof their fake time.  The difficulty would settle so that one block occurs\nevery 20 mins.\n\n\n>\n> Possible improvement:\n> -----------------------------\n> We may consider exchanging average with standard deviation in the\n> difficulty adjustment formula. It both better mirrors changes in the hash\n> power along the interval, and disables the option to manipulate timestamps\n> without affecting the difficulty.\n>\n> I'm aware that this change requires a hardfork, and won't happen any time\n> soon. But does it make sense to add it to a potential future hard fork?\n>\n\nFor check locktime, the median of the last 11 blocks is used as an improved\nindicator of what the actual real time is.  Again, it assumes that a\nmajority of the miners are honest.\n\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180129/0d61ce0b/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2018-01-29T21:54:23",
                "message_text_only": "On Mon, Jan 29, 2018 at 9:40 PM, Tier Nolan via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> For check locktime, the median of the last 11 blocks is used as an improved\n> indicator of what the actual real time is.  Again, it assumes that a\n> majority of the miners are honest.\n\nIt would be more accurate to say that the median is not used for\nimproved accuracy but to mitigate a consensus incompatibility:\n\nIf the block's own timestamp were used for nlocktime and time based\nnlocks were common on the network each miner would maximize their fee\nincome by setting the value as high as they could get away with.  What\nconcerned us wasn't so much that this would make the times less\naccurate (though it would) but rather that it would create an\nincentive for a runaway situation that could harm network stability\n(e.g. with all miners cranking times against the 2hr window, then\ncreating pressure for miners to accept further and further in the\nfuture; each responding to his own local incentives).\n\nThis incentive incompatibility could have been addressed e.g. by using\nthe prior block's time, but since the protocol doesn't require times\nto be monotone (and for good reason!) the simple implementation of\nthat wouldn't have been a soft-fork.  The 11 block MTP worked out\nnicely because the protocol already required new times to be larger\nthan that.\n\nThe timestamps in Bitcoin aren't intended to be particularly accurate.\nThey're used only for controlling the difficulty, and the adjustment\nwindow is large enough that there isn't much distortion that can be\naccomplished there.  It's not clear to me that much better can really\nbe done... if there were tighter time requirements in the protocol\nminers would address them by running NTP which as an _astounding_ lack\nof security in terms of how it is commonly deployed.  As far as I\nknow, I'm the only person whos ever mined blocks with their own\nstratum 1 time source.\n\nIf times need to be accurate Bitcoin would need to use a rather\ndifferent design (e.g. each block would commit to the observation time\nof the prior N blocks, and an iterative algorithm would solve for each\nblocks time and each miners local offset).\n\nIIRC open-timestamp calendar servers provide more precise\ntime-stamping under the assumption that the calendar server is\nbehaving correctly."
            },
            {
                "author": "Peter Todd",
                "date": "2018-01-30T07:27:16",
                "message_text_only": "On Mon, Jan 29, 2018 at 09:54:23PM +0000, Gregory Maxwell via bitcoin-dev wrote:\n> If times need to be accurate Bitcoin would need to use a rather\n> different design (e.g. each block would commit to the observation time\n> of the prior N blocks, and an iterative algorithm would solve for each\n> blocks time and each miners local offset).\n> \n> IIRC open-timestamp calendar servers provide more precise\n> time-stamping under the assumption that the calendar server is\n> behaving correctly.\n\nThat is incorrect. The OpenTimestamps servers are specifically designed not to\nbe trusted, and thus do not make any cryptographically verifiable attestations\nas to when timestamps were created.\n\nIn the future I expect to add a trusted timestamping scheme via disposable keys\nto the OpenTimestamps protocol, but that work isn't yet complete:\n\nhttps://lists.opentimestamps.org/pipermail/ots-dev/2017-May/000001.html\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 488 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180130/ebd74375/attachment.sig>"
            },
            {
                "author": "Neiman",
                "date": "2018-01-30T10:53:41",
                "message_text_only": "On Mon, Jan 29, 2018 at 10:54 PM, Gregory Maxwell via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Mon, Jan 29, 2018 at 9:40 PM, Tier Nolan via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>  if there were tighter time requirements in the protocol\n> miners would address them by running NTP which as an _astounding_ lack\n> of security in terms of how it is commonly deployed.\n>\n\nCould you say a few more words about this lack of security? Or share a link\nif you have one. I know very little about NTPs.\n\n\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180130/75a5c9a7/attachment.html>"
            },
            {
                "author": "Neiman",
                "date": "2018-01-30T10:52:21",
                "message_text_only": "On Mon, Jan 29, 2018 at 10:40 PM, Tier Nolan via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> Much of Bitcoin operates on the assumption that a majority of miners are\n> honest.  If 50%+ of miners set their timestamp reasonably accurately (say\n> within 10 mins), then the actual timestamp will move forward at the same\n> rate as real time.\n>\n\nThank you for replying. I agree that under the 50%+ assumption, timestamps\nare reasonably accurately, but I fail to see a reason to make this\nassumption.\n\nI'm comfortable with the 50%+ assumption regarding ledger manipulation\n(double-spending, deletion of transactions etc.). I'm much less comfortable\nwith it regarding timestamps manipulation.\n\nConsider the following situation:\n(1) miners are selfish,\n(2) miners have a financial incentive to be dishonest.\n\n(1) is a common state on how miners function nowadays. (2) is the case that\ninterests us when coming to do this analysis.\n\nIn the case of ledger manipulation, the 50%+ assumption is not because we\nassume that miners are good-hearted (this violates (1)). It is there due to\nan assumption that the financial damage to a miner would be bigger than the\ngain in (2). This happens since a ledge manipulation may cause miners to\nlose block rewards, and certainly will devaluate Bitcoin, an asset which\nthey possess.\n\nIn the case of timestamps manipulation, I don't see any financial damage\ncaused to miners. Timestamps manipulation (besides the 2016*n blocks) won't\nharm the function of Bitcoin, and may even go undetected (it seems to me\nthat the main blockchain explorers don't track it). I don't see a\njustification for the 50%+ assumption here.\n\n\n>\n> Dishonest miners could set their timestamp as low as possible, but the\n> median would move foward if more than half of the timestamps move forward.\n>\n>\n>> If we want to be pedantic, the best lower bound for a block timestamp is\n>> the timestamp of the block that closes the adjustment interval in which it\n>> resides.\n>>\n>\n> If you are assuming that the miners are majority dishonest, then they can\n> set the limit to anything as long as they don't move it more than 2 hours\n> into the future.\n>\n> The miners could set their timestamps so that they increase 1 week fake\n> time every 2 weeks real time and reject any blocks more than 2 hours ahead\n> of their fake time.  The difficulty would settle so that one block occurs\n> every 20 mins.\n>\n>\n>>\n>> Possible improvement:\n>> -----------------------------\n>> We may consider exchanging average with standard deviation in the\n>> difficulty adjustment formula. It both better mirrors changes in the hash\n>> power along the interval, and disables the option to manipulate timestamps\n>> without affecting the difficulty.\n>>\n>> I'm aware that this change requires a hardfork, and won't happen any time\n>> soon. But does it make sense to add it to a potential future hard fork?\n>>\n>\n> For check locktime, the median of the last 11 blocks is used as an\n> improved indicator of what the actual real time is.  Again, it assumes that\n> a majority of the miners are honest.\n>\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180130/dcc2af82/attachment-0001.html>"
            },
            {
                "author": "George Balch",
                "date": "2018-01-29T21:53:06",
                "message_text_only": "The terms \"simple ordering of blocks\" and timestamp are essentially the\nsame thing.\n\nOn Jan 29, 2018 1:16 PM, \"Neiman via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> First time posting here, please be gentle.\n>\n> I'm doing a research project about blockchain timestamping. There are many\n> such projects, including the fantastic OpenTimestamps.\n>\n> All of the projects essentially save some data in a block, and rely on the\n> block timestamp as a proof that this data existed at some specific time.\n>\n> But how accurate are Bitcoins timestamps?\n>\n> I didn't find any discussion or research regarding Bitcoin timestamp\n> accuracy (also not in the history of this mailing list). I share here a\n> simple analysis of timestamp accuracy, and a suggestion how to improve it.\n>\n> Basic observations and questions:\n> -------------------------------------------\n> *1.* It seems to me that the timestamp is not the time that the block was\n> created. Ideally, it's the time that the miner started to try to mine the\n> block. However, as timestamps may also be used as a source of variety for\n> hashes, the exact meaning of its value is unclear.\n>\n> If this is true, then there's a strange phenomena to observe in\n> blockchain.info and blockexplorer.com: the timestamps of blocks equals\n> the receiving times.\n>\n> Am I wrong in my understanding, or is there a mistake in those websites?\n>\n> *2.* Timestamps are not necessary to avoid double-spending. A simple\n> ordering of blocks is sufficient, so exchanging timestamps with enumeration\n> would work double-spending wise. Permissioned consensus protocols, such as\n> hyperledger, indeed have no timestamps (in version 1.0).\n>\n> As far as I could tell, timestamps are included in Bitcoin's protocol\n> *only* to adjust the difficulty of PoW.\n>\n> Direct control of timestamp accuracy:\n> -----------------------------------------------\n> The only element in the protocol that I found to control timestamp\n> accuracy is based on the network time concept.\n>\n> The Bitcoin protocol defines \u201cnetwork time\u201d for each node. The network\n> time is the median time of the other clients, but only if\n>     1. there are at least 5 connected, and\n>     2. the difference between the median time and the nodes own system\n> time is less than 70 minutes.\n>\n> Then new blocks are accepted by the peers if their timestamps is\n>     1. less than the network time plus 2 hours, and\n>     2. greater than the median timestamp of previous 11 blocks.\n>\n> The first rule supplies a 2 hour upper bound for timestamp accuracy.\n>\n> However, the second rule doesn't give a tight lower bound. Actually, no\n> lower bound is given at all if no assumption is made about the median. If\n> we assume the median to be accurate enough at some timepoint, then we're\n> only assured that any future timestamp is no bigger than this specific\n> median, which is not much information.\n>\n> Further analysis can be made under different assumptions. For example,\n> what's the accuracy if holders of 51% of the computational power create\n> honest timestamps? But unfortunately, I don't see any good reason to work\n> under such an assumptions.\n>\n> The second rule cannot be strengthened to be similar to the first one\n> (i.e., nodes don't accept blocks less than network time minus 2 hours). The\n> reason is that nodes cannot differentiate if it's a new block with\n> dishonest timestamp, an old block with an old timestamps (with many other\n> blocks coming) or simply a new block that took a long time to mine.\n>\n> Indirect control of timestamps accuracy:\n> --------------------------------------------------\n> If we assume that miners have no motive to increase difficulty\n> artificially, then the PoW adjusting algorithm yields a second mechanism of\n> accuracy control.\n>\n> The adjustment rules are given in pow.cpp (bitcoin-core source, version\n> 0.15.1), in the function 'CalculateNextWorkRequired', by the formula (with\n> some additional adjustments which I omit):\n>\n>     (old_target* (time_of_last_block_in_2016_blocks_interval -\n> time_of_first_block_in_2016_blocks_interval) )/time_of_two_weeks\n>\n> It uses a simple average of block time in the last 2016 blocks. But such\n> averages ignore any values besides the first and last one in the interval.\n> Hence, if the difficulty is constant, the following sequence is valid from\n> both the protocol and the miners incentives point of views:\n>\n>     1, 2, 3,\u2026., 2015, 1209600 (time of two weeks), 2017, 2018, 2019,\u2026.,\n> 4031, 1209600*2, 4033, 4044, \u2026\n>\n> If we want to be pedantic, the best lower bound for a block timestamp is\n> the timestamp of the block that closes the adjustment interval in which it\n> resides.\n>\n> Possible improvement:\n> -----------------------------\n> We may consider exchanging average with standard deviation in the\n> difficulty adjustment formula. It both better mirrors changes in the hash\n> power along the interval, and disables the option to manipulate timestamps\n> without affecting the difficulty.\n>\n> I'm aware that this change requires a hardfork, and won't happen any time\n> soon. But does it make sense to add it to a potential future hard fork?\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180129/71830c72/attachment-0001.html>"
            },
            {
                "author": "Bryan Bishop",
                "date": "2018-01-29T22:23:46",
                "message_text_only": "On Mon, Jan 29, 2018 at 7:34 AM, Neiman via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> But how accurate are Bitcoins timestamps?\n>\n\nA perspective on block timestamp and opentimestamps can be found here:\nhttps://lists.w3.org/Archives/Public/public-blockchain/2016Sep/0076.html\n\n- Bryan\nhttp://heybryan.org/\n1 512 203 0507\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180129/ff2b1170/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "How accurate are the Bitcoin timestamps?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Bryan Bishop",
                "Peter Todd",
                "Tier Nolan",
                "Gregory Maxwell",
                "Neiman",
                "George Balch"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 22114
        }
    },
    {
        "title": "[bitcoin-dev] Design approaches for Signature Aggregation",
        "thread_messages": [
            {
                "author": "Russell O'Connor",
                "date": "2018-01-30T19:12:31",
                "message_text_only": "On Sat, Jan 27, 2018 at 12:23 PM, Matt Corallo <lf-lists at mattcorallo.com>\nwrote:\n\n> Gah, please no. I see no material reason why cross-input signature\n> aggregation shouldn't have the signatures in the first n-1 inputs replaced\n> with something like a single-byte push where a signature is required to\n> indicate aggregation, and the combined signature in the last input at\n> whatever position the signature is required.\n>\n\nThat would be the expedient approach.\n\nI want to preface what I'm about to write by first stating that I think the\ncross-input signature aggregation is the most important forthcoming\ndevelopment for Bitcoin and I would be very happy to have any solution for\nit deployed in any workable form.  Also, it is difficult to discuss pros\nand cons of various designs without concrete proposals, but perhaps we can\ntry to say some things about various design approaches while still saying\nsomething useful.\n\nI think there are some issues with the expedient proposal for signature\naggregation.  The problems begin with the arbitrary choice of which input\nwitness will be the canonical choice for holding the aggregated signature.\nWe want to strictly define which input is the canonical choice for holding\nthe aggregated signature because we wish to avoid introducing new witness\nmalleability vectors.  However, the definition of the canonical input is\nsomewhat complicated.  Because not all inputs are necessarily participating\nthe aggregation, the canonical choice of input necessarily depends on the\nrun-time behavior of all the other input Scripts in the transaction.  This\ncomplicates the specification and makes the implementation somewhat\nerror-prone.\n\nFurthermore designing the canonical choice of input for the aggregated\nsignature to support future extensions of new script versions or new\nopcodes that may want to participate in signature aggregation (for example,\nadding CHECKSIGFROMSTACK later) is going to be extraordinarily difficult, I\nthink.  I don't know how it could even be done.\n\nOn the other hand, the extended-transaction approach supports a clean model\nof script semantics whereby the signature aggregation is supported via a\nnew writer (aka logging) side-effect for Script[1].  In this model, rather\nthan the semantics of Script returning only failure or success, Script\ninstead results in either failure or conditional success plus a log of\nadditional constraints that need to be satisfied for the transaction to be\nvalid.  In the case of signature aggregation, these constraints are of the\nform \"I require cryptographic evidence that there is a signature on message\nM from public key P\".  The aggregated signature in the extension of the\ntransaction provides a witness that demonstrates all the constraints\nemitted by all the scripts are satisfied.\n\nEven in the extended-transaction approach, supporting future extensions of\nnew script versions or new opcodes that may want to participate in\nsignature aggregation is going to be very difficult.  However, I do have\nsome half-baked ideas (that you will probably like even less) on how we\ncould support new script versions and new opcodes based on this idea of a\nwriter side-effect model of Script semantics.  I hope that designing\nsupport for extendable signature aggregation isn't infeasible.\n\nI think that the cleaner semantic model of the extended-transaction\napproach is by itself enough reason to prefer it over the expedient\napproach, but reasonable people can disagree about this.  However, there\nare even larger issues lurking which appear when we start looking for\nunintended semantic consequences of the expedient design.  This is a common\nproblem with expedient approaches.  It is hard enough to come up with a\ndesign that enables a new feature, but it is even harder to come up with a\ndesign that enables a new feature without enabling other, unintended\n\"features\".  I worry that people do not pay enough attention to the later,\nafter achieving the former. This sort of thing happened with OP_EVAL in bip\n12.  In that situation, the goal was to create a design that enabled pay to\nscript hash, and OP_EVAL does achieve that in a very straightforward way.\nHowever, the unintended semantic consequences was that bip 12 also enable\nunbounded recursion[2] and extended the class of functions definable by\nscript all the way to the entire class of all computable functions.\n\nWe can find unintended semantic consequences of the expedient approach to\nsignature aggregation by looking at the ways it fails to fit into the\nwriter side-effect model for signature aggregation.\n\nA. Firstly, we notice that scripts can determine whether or not they are in\ncanonical position or not by checking the length of their signature data.\nThis is an effect that goes beyond the abilities of just allowing signature\naggregation.  We can build scripts that can only be redeemed when they are,\nor aren't the ones holding the aggregated signature.\n\nB. In the presence of sufficient computation power[3], I expect that\nscripts can recover the public keys and signed message data of the\naggregated data, using the same methods used in Enchancing Bitcoin\nTransactions with Covenants\n<http://fc17.ifca.ai/bitcoin/papers/bitcoin17-final28.pdf>. With this\nability, the script in canonical position can determine what messages are\nbeing signed by other inputs, and which public keys they have chosen to\nuse.  Perhaps a script could enforce a whitelist or blacklist of\napproved/disapproved public keys that it is willing or unwilling to be\naggregated with, etc.\n\nC. Scripts can subvert the use the public keys being aggregated themselves\nfor the purpose of communicate arbitrary data to other script inputs.  With\naggregated CHECKSIGFROMSTACK, scripts can directly use signed messages for\nthis communication.\n\nI'm not trying to say that the above are good or bad things, after all\nsignature aggregation is an interactive process so it is expected that\nusers could decide which keys they are willing to aggregate with.  What I'm\ntrying to say is that the expedient proposal has a host of unintended\nsemantic consequences and the above list is only the ones that I can think\nof off the top of my head.  I do not even know the full extent of what we\nwill be enabling with this design but it seems to include adding a\nsubversive unidirectional cross-input communication channel for Script. Is\nthat really a feature we want to be bundling with a signature aggregation\nproposal?\n\nI believe that the extended-transaction design is the conservative design.\nI conjecture that one can build a reduction from scripts supporting\nsignature aggregation in the extended-transaction design to scripts that\ndon't support signature aggregation, while preserving the same security\nproperties. (The proposed reduction would \"simply\" replace every aggregated\nsignature call with a non-aggregated signature call.)  If this conjecture\nholds, that means we can prove that the extended-transaction design is only\nan optimization and doesn't have any further unintended semantic\nconsequences.  In particular, we see that the expedient approach doesn't\nhave such a reduction proof because scripts that are using the expedient\ndesign for cross-input communication cannot be modeled by scripts that\ndon't have the signature aggregation ability.\n\nI would be disappointed if we end up taking the expedient approach to\nsignature aggregation (but still very happy that we get signature\naggregation), and there are probably other designs for signature\naggregation beyond the two designs I'm discussing here.\n\n-- \nRussell\n\n[1]For those familiar with using monads to model side-effects, we can model\nthe output of Script as a (M Bool) value where M is a writer monad over the\nmonoid of a set of formal constraints, or some other small variant of this\nmodel.  I know that the word monad makes some people's eyes glaze over, but\nI'm not trying to use jargon here to exclude people; I'm trying to use\njargon here to be precise about what it means to formally model\ncomputational side-effects for those who are familiar how to do that sort\nof thing.\n\n[2]Due to an attempt at a gas limit, OP_EVAL wasn't not intended to enable\nunbounded computation in practice.  However when talking about the formal\nexpressiveness of a programming language we usually discard these sorts of\nlimits, such as stack size limits, gas limits etc.  Those limits are there\nto prevent denial of service attacks against Bitcoin consensus.  The limits\nare not designed to enforce language and security properties through the\nrestriction of computational expressiveness.\n\n[3]Here sufficient computation power means that we have access to functions\nlike CHECKSIGFROMSTACK and/or basic operations on elliptic curves and hash\nfunctions.  These are all pure functions that can be defined by logical\ngates. Since bitcoin script has boolean logic operations, they technically\nfall into scope of what is ostensibly definable by script.  Nevertheless,\nthese sorts of functions could reasonably appear in a Bitcoin Script 2.0 as\nthey would make a host of new protocols practical.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180130/0d07d20c/attachment-0001.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2018-01-30T23:25:55",
                "message_text_only": "On Tue, Jan 30, 2018 at 2:12 PM, Russell O'Connor <roconnor at blockstream.io>\nwrote:\n\n>\n> and there are probably other designs for signature aggregation beyond the\n> two designs I'm discussing here.\n>\n\nFor example, in private communication Pieter suggested putting the\naggregate signature data into the top of the first segwit v1+ input witness\n(and pop it off before evaluation of the input script) whether or not that\ninput is participating in the aggregation or not.  This makes this\ncanonical choice of position independent of the runtime behaviour of other\nscripts and also prevents the script from accessing the aggregate signature\ndata itself, while still fitting it into the existing witness data\nstructure. (It doesn't let us toy with the weights of aggregated signature,\nbut I hope people will still be motivated to use taproot solely over P2WPKH\nbased on having the option to perform aggregation.)\n\nBeing able to allow aggregation to be compatible with future script or\nopcode upgrades is still very difficult to design.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20180130/f2aaff7d/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Design approaches for Signature Aggregation",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Russell O'Connor"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 10476
        }
    }
]